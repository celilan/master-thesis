title,authors,year_published,number,volume,journal,type,content,doi,file,cleaned_content
Contrastive autoencoder for anomaly detection in multivariate time series,Hao Zhou and Ke Yu and Xuan Zhang and Guanlin Wu and Anis Yazidi,2022,,610,Information Sciences,article,"Contrastive autoencoder for anomaly detection in multivariate
time series
Hao Zhou a, Ke Yu a,⇑, Xuan Zhang b, Guanlin Wu a, Anis Yazidi c,d,e
a Beijing University of Posts and Telecommunications, Beijing, China
b Norwegian Research Centre AS, Grimstad, Norway
c Oslo Metropolitan University, Oslo, Norway
d Norwegian University of Science and Technology, Trondheim, Norway
e Oslo University Hospital, Oslo, Norway
a r t i c l e
i n f o
Article history:
Received 21 April 2022
Received in revised form 24 July 2022
Accepted 28 July 2022
Available online 3 August 2022
Keywords:
Anomaly detection
Multivariate time series
Autoencoder
Contrastive learning
Data augmentation
a b s t r a c t
With the proliferation of the Internet of Things, a large amount of multivariate time series
(MTS) data is being produced daily by industrial systems, corresponding in many cases to
life-critical tasks. The recent anomaly detection researches focus on using deep learning
methods to construct a normal proﬁle for MTS. However, without proper constraints, these
methods cannot capture the dependencies and dynamics of MTS and thus fail to model the
normal pattern, resulting in unsatisfactory performance. This paper proposes CAE-AD, a
novel contrastive autoencoder for anomaly detection in MTS, by introducing multi-
grained contrasting methods to extract normal data pattern. First, to capture the temporal
dependency of series, a projection layer is employed and a novel contextual contrasting
method is applied to learn the robust temporal representation. Second, the projected series
is transformed into two different views by using time-domain and frequency-domain data
augmentation. Last, an instance contrasting method is proposed to learn local invariant
characteristics. The experimental results show that CAE-AD achieves an F1-score ranging
from 0.9119 to 0.9376 on the three public datasets, outperforming the baseline methods.
 2022 Elsevier Inc. All rights reserved.
1. Introduction
With the proliferation of the Internet of Things (IoT), a large amount of MTS data is generated constantly by industrial
systems [18,15]. Since these data are usually associated with critical missions, monitoring them for unveiling anomalies
is crucial. In simple terms, anomaly detection in MTS aims to detect the time stamps of the series where the observations
deviate largely from the normal values or where unusual temporal patterns emerge.
Anomaly detection is a well-established research topic that has attracted a lot of research attention over the last decades.
In early stage, researchers have focused on methods for detecting anomalies in univariate time series data [19,4,17,41,28].
Within the context of modern industrial systems, a device is usually monitored by a multitude of sensors, each of which
measures a distinct variable. Diagnosing MTS data with multiple monitoring indicators is essential to ensure the normal
https://doi.org/10.1016/j.ins.2022.07.179
0020-0255/ 2022 Elsevier Inc. All rights reserved.
Abbreviations: MTS, multivariate time series.
⇑Corresponding author.
E-mail addresses: zhouh@bupt.edu.cn (H. Zhou), yuke@bupt.edu.cn (K. Yu), xuan.z.jiao@gmail.com (X. Zhang), wuguanlin@bupt.edu.cn (G. Wu),
anisy@oslomet.no (A. Yazidi).
Information Sciences 610 (2022) 266–280
Contents lists available at ScienceDirect
Information Sciences
journal homepage: www.elsevier.com/locate/ins
 operations of industrial systems. Further, abnormal readings are usually difﬁcult to be annotated from a large amount of sen-
sor data, making little or even no labels available in MTS. The supervised methods [33,23,31] are unfeasible in this case. Thus,
we focus on identifying anomalies in MTS using unsupervised methods.
Unsupervised anomaly detection methods in MTS are challenging with temporal dependency and dynamic variability. In
the unsupervised setting, models are designed to construct a normal proﬁle through a large amount of normal time series
data. Those that behave very differently from the normal pattern are detected as anomalies. The classic unsupervised time
series anomaly detection methods, such as classiﬁcation-based models (e.g., one-class SVM [12,36]), distance-based models
(e.g., KNN [5]) and clustering-based models, (e.g., k-means [20]), ignore the temporal dependency in MTS, resulting in infe-
rior performance.
Recently, autoencoder-based methods have received a lot of attention, owing to their ability to learn informative repre-
sentation. The state-of-the-art anomaly detection methods usually apply well-designed autoencoders to capture normal pat-
terns of MTS data, e.g., LSTM-based encoder-decoder model [26], adversarial training based autoencoder [3,27], and
variational autoencoder [30,9], etc. Here, point-to-point reconstruction or prediction criteria are usually used to detect
anomalies. However, due to the complexity of temporal dependency in MTS, the single point-wise context information can-
not comprehensively characterize the temporal pattern of MTS data. Moreover, the normal pattern may change dynamically
over time. Autoencoder-based models will suffer from an overﬁtting problem if no proper regularization is applied. There-
fore, these methods fail to construct an accurate proﬁle for normal data and are incapable of learning robust representation,
resulting in unsatisfactory performance in practice.
In this paper, we propose a contrastive autoencoder for anomaly detection in MTS, namely CAE-AD. Contrastive learning
has been proved successful to learn transformation-invariant representation of data in various domains, such as image clas-
siﬁcation [6], audio [29] and language understanding [13]. Combining autoencoder with the contrastive loss for the window-
segmented MTS, we ﬁnd that it is capable of capturing invariant information from the dynamically changing time series,
which improves the robustness of the representation for autoencoder. However, the window-wise method is insufﬁcient
for obtaining ﬁne-grained temporal representation. Therefore, we expand this method with multi-contrasting to explore
point-wise and window-wise temporal information, which helps construct a normal proﬁle in MTS.
Going beyond previous autoencoder-based methods, the proposed CAE-AD is able to model the temporal and dynamic
features of time series. More precisely, we ﬁrst utilize the attention mechanism to capture the temporal dependency. Unlike
commonly used positional coding methods, we adopt a contextual contrasting method to learn the position information.
Subsequently, we explore data augmentation in the time and frequency domain, which helps obtain different views of
the same segment. After that, a shared-weight encoder is developed to encode the augmented data and an instance contrast-
ing method is proposed to capture the local invariant characteristics of latent variables. With the proposed multi-grained
contrasting (the contextual contrasting and instance contrasting), CAE-AD can learn the robust representation of MTS.
Finally, an LSTM decoder is devised and the reconstruction errors are further utilized to detect anomalies. Extensive exper-
iments are conducted to validate the effectiveness of the proposed method.
The main contributions of the paper are summarized as follows:
 We propose a novel approach to detect anomalies in MTS, namely CAE-AD. Contrastive learning method is utilized to
enhance the ability of the autoencoder for constructing a robust proﬁle for normal data, making abnormal data more dis-
tinguishable to be detected.
 Simple but efﬁcient data augmentation methods are designed for MTS in the CAE-AD framework. We explore augmenta-
tion for MTS in both the time and frequency domains. This helps select positive pairs for contrasting and encourages
learning dynamic behaviours of MTS data.
 Multi-grained contrasting methods are proposed to learn the robust representations of MTS. First, we propose contextual
contrasting to extract the temporal dependency of MTS. Second, we propose instance contrasting to further capture local
invariant characteristics of MTS. With multi-grained contrasting methods, CAE-AD can comprehensively learn multi-scale
contextual information.
 We conduct extensive experiments to evaluate the performance of CAE-AD on three public datasets. The experiment
results demonstrate that the performance of CAE-AD outperforms state-of-the-art baselines.
The remainder of the paper is organized as follows: In Section 2, we provide an overview of the related work. In Section 3,
we introduce the CAE-AD framework and anomaly detection in detail. The experimental results and analyses are presented
in Section 4 before concluding the paper in the last section.
2. Related Work
2.1. Anomaly Detection
MTS anomaly detection has recently become a popular research topic. There is an abundance of literature on MTS anom-
aly detection. Traditional methods of anomaly detection in MTS mostly resort to statistical methods. In [5], Chaovalitwongse
et al. suggested a distance-based model based on KNN to classify abnormal MTS data. In [21], an improved variant of the
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
267
 distance-based model was proposed, and the authors took the angular relationship among the data points into account. Iso-
lation Forest was utilized in [24], where the authors isolated outliers by dividing the data set. Although these methods are
highly efﬁcient, they do not consider the long-term temporal dependency of MTS data.
Methods based on deep learning have recently achieved signiﬁcant performance improvement for anomaly detection in
MTS data. LSTM-NDT [18] applied LSTM to model the temporal dependence and detected anomalies based on prediction
errors. The transformer-based methods have also gained a lot of attention. Anomaly Transformer [39] explored the self-
attention weight for anomalies and proposed a minimax training strategy to amplify the difference between normal and
abnormal data. GTA [7] used a transformer-based structure to learn a graph structure, which helped capture temporal
dependency in MTS. TranAD [35] proposed a transformer-based model for anomaly detection and used adversarial training
and self-conditioning technologies to improve the performance.
The autoencoder-based model has become popular recently, where the encoder is employed to reduce the dimensionality
of MTS data while the decoder aims to reconstruct the MTS. By minimizing the reconstruction errors, the autoencoder-based
model can capture the normal pattern of the data, and reconstruction errors are further used to detect anomalies. For exam-
ple, EncDec-AD [26] utilized LSTM as the basic cell of the encoder and decoder. LSTM-VAE [30] combined LSTM and VAE, but
it ignored the dependence of stochastic variables. An approach reckoned as OmniAnomaly was proposed in [34] and it is
based on a stochastic recurrent neural network that learnt normal data patterns by modelling robust representations of
MTS data. MAD-GAN [22] adopted the GAN framework to capture the time and space information of the data.
2.2. Contrastive Learning
Invariant information plays a crucial role in inter-domain or intra-domain tasks with noise perturbations. For example,
CMCH was proposed by [2] to learn the consistent representation of hash codes for multi-modal data, which utilized the
invariant information in multi-modal data to construct the informative latent space. MIAN [42] proposed modality-
invariant asymmetric networks to preserve the semantic similarity, and proposed a conditional variational information bot-
tleneck network to learn modality-invariant information.
Unlike these supervised methods, contrastive learning methods learn the transformation-invariant representation of data
in a self-supervised setting. The main idea of contrastive learning is to reduce the distance between similar samples in the
feature space and maximize the distance between different samples in the same space. CPC [29] used autoregressive models
to predict future values in latent space and proposed InfoNCE loss to train the network for obtaining robust data represen-
tations. MoCo [16] further considered the limitation of obtaining negative samples and built a dynamic dictionary to look up
sample pairs for contrasting. SimCLR [6] discussed the signiﬁcant role of data augmentation in contrastive learning and pro-
posed a learnable nonlinear transformation module to improve the quality of contrastive representation vectors.
Applying contrastive learning to time series data, TS-TCC [11] proposed a self-supervised framework with multiple con-
trasting methods to learn informative time-series representation. TS2Vec [40] proposed a hierarchical contrasting method to
learn multi-grained contextual information of time series. In this work, we develop a contrastive autoencoder representation
learning and anomaly detection of MTS.
3. Proposed Model
We ﬁrst present the problem description of anomaly detection in MTS data. Then, we give an overview of the CAE-AD
framework and explain its main modules. Finally, we describe in detail the proposed model and anomaly detection.
3.1. Problem Description
In this paper, we focus on detecting anomalies in MTS data. Let xt 2 Rm denotes the vector of dimension m at time step t,
where xt;i 2 R denotes the value of ith
variable at time step t. Multivariate time series can be expressed as
X ¼ fx1; x2; . . . ; xNg; X 2 RNm, where N is the length of the observed sequence. A anomaly score St is calculated at timestep
t. The point is detected as an anomaly if the anomaly score is greater than a speciﬁed threshold.
3.2. Overview of the Framework
The CAE-AD framework is shown in Fig. 1, which consists of three parts: data preprocessing, learning representation, and
anomaly detection.
First, we normalize the data and divide them via windows during data preprocessing. Second, we propose a Contrastive
Autoencoder model to learn the representation of MTS. As demonstrated in the bottom of Fig. 1, a projection layer is imple-
mented to learn the embedding, and then we design two types of data augmentation methods in the time domain and fre-
quency domain respectively, which is helpful to generate different views of the sequence data. The multi-grained contrasting
method is proposed to capture the temporal dependency and local-invariant characteristics of the data. Finally, the anomaly
score of each timestep is calculated based on the reconstruction error.
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
268
 3.3. Preprocessing
For the input MTS data X ¼ fx1; x2; . . . ; xNg, normalization is ﬁrst applied to scale the data. The observations at the current
timestep depend on historical observations of the data. To capture the temporal dependency, we introduce a sliding window
in the CAE-AD framework. As shown in Fig. 2, we obtain continuous data segments as the input of CAE-AD using a sliding
window with the interval of l. For example, a window of observations can be expressed as x1:w ¼ ½x1; x2; . . . ;
xw; x1:w 2 Rwm, where w is the window size and m is the dimension of the data.
3.4. Representation Model
In the CAE-AD, we ﬁrst employ a projection layer and propose contextual contrasting to learn the temporal embedding of
MTS data. Then we explore data augmentation methods for time series and propose instance contrasting to encourage
robustness of representation. Last, an LSTM decoder is adopted to reconstruct the MTS data.
3.4.1. Projection Layer
Contrastive learning aims at maximizing the similarity between the same samples of different views while minimizing
the similarity between different samples to learn invariant characteristics. In order to select the positive pairs for contrasting,
we explore different data augmentation methods to obtain various views of the data, which is considered critical in con-
trastive learning [6].
Simple transformations are commonly used for time series augmentation, such as cropping, ﬂipping, and jittering, etc.
However, it is not always appropriate to directly transform the original time series data. For example, the raw data may have
an upward trend. If the cropping operation removes this trend, the augmented time series may represent a different mode
while the previous contrastive learning strategy will deem both time series, original and augmented, similar. To overcome
this problem, we employ a projection layer. We ﬁrst project the MTS data, and its embedding after projection layer can be
used for data augmentation to supplement domain-speciﬁc knowledge [10].
In order to capture the temporal dependency of the data, we adopt the attention mechanism [38] as the projection layer.
A mask is used to prevent future data information leakage, and all attention scores of the future data are assigned zeros. For a
Fig. 2. Data preprocessing. A sliding window is adopted to slice the sequences.
Fig. 1. The overall framework of CAE-AD. We ﬁrst conduct data normalization and segment the MTS using a sliding window. Then contrastive autoencoder
is adopted to the learned robust representation of time series data. Finally, reconstruction errors are utilized to detect anomalies.
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
269
 window of the data x1:w ¼ ½x1; x2 . . . ; xw, where w is the window size, linear transformations are utilized to obtain the query
matrix Q, the key matrix K and the value matrix V respectively, where Q ¼ ½x1; . . . ; xwTWQ and WQ is a learnable matrix. The
embedding after attention mechanism can be expressed by the following formula.
a1:w ¼ softmax QKT
ﬃﬃﬃﬃﬃ
m
p
 Mask
 
!
V;
ð1Þ
where a1:w ¼ ½a1; a2; . . . ; aw; a1:w 2 Rwm denotes the sequence of embeddings at 2 Rm. Symbol  denotes element-wise
operation and KT is the transpose of K. Mask is a lower triangular matrix, which means that the data at timestep t only focus
on current and historical information. For example, the embedding at only pays attention to the information of x1:t.
3.4.2. Contextual Contrasting
The attention mechanism ignores the position information. To include position information, we propose contextual con-
trasting to learn the relative position of the MTS data.
The embedding at has a higher similarity to the representation of neighbor timesteps at1; atþ1, while has a lower sim-
ilarity to representation of distant timesteps. Contextual contrasting aims at reducing the distance between neighbouring
timesteps in the embedding space while increasing the distance between different timesteps in the embedding space, which
can be expressed as follows:
l
ði;tÞ
cont ¼  log expðcosðaðiÞ
t ; aðiÞ
t1Þ=sÞ þ expðcosðaðiÞ
t ; aðiÞ
tþ1Þ=sÞ
X
w
k¼1
I½k–t expðcosðaðiÞ
t ; aðiÞ
k Þ=sÞ
;
Lcont ¼ 1
Nw
X
Nw
i¼1
X
w
t¼1
l
ði;tÞ
cont;
where lði;tÞ
cont denotes the loss function at timestep t in the i-th window. Nw is the total number of windows. I½k–t 2 f0; 1g is an
indicator function, and it equals to 1 if k – t, and 0 otherwise. s is the temperature parameter. Cosine function is utilized to
measure the similarity among the embeddings.
The embeddings obtained by the attention mechanism do not include position information. There are certain articles
[38,32,25] that have studied positional coding. However, those methods directly add the position information to the data, so
that the data information may interfere with the position information. Alternatively, we adopt contextual contrasting to learn
the position information in the embedding space, which provides a new view for the positional coding of the attention
mechanism.
3.4.3. Data Augmentation
To make full use of the properties of the MTS, we explore data augmentation methods for the embeddings of the projec-
tion layer in both time and frequency domains respectively.
In the time domain, we add Gaussian noise Nð0; R1Þ for the embeddings to generate similar samples, where R1 ¼ diagðr1Þ
and r1 is the deviation. In frequency main, we perform a two-dimensional Discrete Fourier Transform on the embeddings
a1:w ¼ ½a1; a2; . . . ; aw to obtain the spectrum Fðu;vÞ.
Fðu;vÞ
¼
1
wm
X
w1
t¼0
X
m1
k¼0
at;k expðj2pðut=w þ vk=mÞÞ
¼ Aðu;vÞ expðjhðu;vÞÞ;
ð3Þ
where u ¼ 0; 1 . . . ; w  1 and v ¼ 0; 1; . . . ; m  1 denote the indices of frequencies, w and m are window size and dimension
of the embeddings at respectively. Furthermore, Fðu;vÞ can also be expressed as the combination of amplitude spectrum
Aðu;vÞ and phase spectrum hðu;vÞ.
We add Gaussian noise Nð0; R2Þ for the amplitude spectrum Aðu;vÞ and phase spectrum hðu;vÞ, respectively, where
R2 ¼ diagðr2Þ and r2 control the deviation of noise. Then, Inverse Discrete Fourier Transform (IDFT) is conducted to convert
the frequency domain data into time-domain data. Finally, we take the real part as the augmented data, as shown in the equa-
tion below:
fðt; kÞ ¼ Real½IDFTðFðu;vÞÞ
IDFT ¼
1
wm
X
w1
u¼0
X
m1
v¼0
Fðu;vÞ expðj2pðut=m þ vk=wÞÞ;
ð4Þ
where t ¼ 0; 1; . . . ; w  1, and k ¼ 0; 1; . . . ; m  1 denote the timestep and the dimension of the augmented data f ðt; kÞ
respectively.
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
270
 The proposed data augmentation methods help generate different views of the observed sequence and obtain positive
pairs for instance constrasting.
3.4.4. Instance Contrasting
We obtain two views of the data after time-domain and frequency-domain data augmentation. Then the augmented data
is sent to LSTM siamese encoders to obtain low-dimensional latent variables, where LSTM siamese encoders are composed of
two shared-weights LSTM neural networks. Finally, instance contrasting is applied to learn local invariant information of
latent variables.
The two views of MTS data in the same window are positive pairs, while the MTS data in different windows are consid-
ered as negative pairs. Intuitively, Instance contrasting encourages maximizing the similarity of the different augmented
data from the same window while minimizing the similarity of data from different windows, which aims to learn invariant
information of the two types of augmented data. As shown in Fig. 3, The positive pair of latent variables can be expressed as
ðzt; zþ
t Þ, and the instance contrastive loss is shown in the equation below:
l
ði;tÞ
inst ¼  log
expðcosðzðiÞ
t ;zðiÞþ
t
Þ=sÞ
X
B
k¼1
½expðcosðzðiÞ
t ;zðiÞþ
k
Þ=sÞþI½k–t expðcosðzðiÞ
t ;zðiÞ
k Þ=sÞ
;
Linst ¼ 1
Nb
X
Nb
i¼1
X
B
t¼1
l
ði;tÞ
inst;
ð5Þ
where B is the minibatch size, and Nb is the number of the minibatches. Given the positive pair ðzðiÞ
t ; zðiÞþ
i;t Þ of the t-th window
in the i-th minibatch, we calculate the contrastive loss lði;tÞ
inst using cosin similarity. s is the temperature parameter.
Instance contrasting works in window level, and contextual contrasting works in timestep level. The multi-grained con-
trasting methods can learn the ﬁne-grained and coarse-grained information for time series. By combining the two types of
contrastive losses, CAE-AD framework is capable of learning the representation from multiple scales. Furthermore, contex-
tual contrasting and instance contrasting permit the framework to learn complementary information so that the represen-
tation can better reconstruct the normal MTS.
3.4.5. LSTM Decoder
The main goal of the decoder is to reconstruct the data. We conduct a recurrent decoding method as shown in Fig. 3.
Speciﬁcally, we ﬁrst concatenate the latent variables ½z; zþ as the initial information, and an LSTM cell is applied to recon-
struct the data at the ﬁrst timestep, namely, ^x1. Then, the reconstruction data ^x1 is concatenated with the hidden state of the
decoder for the reconstruction at the next timestep, namely ^x2. The reconstruction method can be formulated as:
^xt ¼
Wrgðconcat½z; zþÞ;
if t ¼ 0
WrgðWzconcat½ht; d
xt1Þ;
if t ¼ 1; 2; . . . w  1; :

ð6Þ
where Wz; Wr are the learnable weight matrices. ht and ^xt denote the t-th hidden state of the decoder and the t-th output of
the decoder respectively. We use LSTM network as the decoder gð:Þ, as shown in Fig. 3.
Fig. 3. Detailed Neural Network of CAE-AD. In the detailed framework, q; k;v denote the query, key and value vector of attention mechanism, respectively.
The green blocks represent the raw data fx1; x2; . . . ; xwg, the embeddings fa1; a2; . . . ; awg and the reconstructed data f ^x1; ^x2; . . . ; ^
xwg, respectively. The latent
variables ðz1; zþ
1 Þ is a positive pair in the same window, and fðz1; z2Þ; . . . ; ðz1; zBÞ; ðz1; zþ
2 Þ; . . . ; ðz1; zþ
B Þg are negative pairs in difﬁent windows of the minibatch.
fh1; h2; . . . ; hwg are hidden states of the LSTM decoder.
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
271
 The reconstruction loss can be expressed by:
Lrecon ¼
1
wNw
X
Nw
i¼1
X
w
t¼1
ð^xðiÞ
t  xðiÞ
t Þ
2;
ð7Þ
where w; Nw are the window size and the number of windows, respectively. ^xðiÞ
t ; xðiÞ
t
are the reconstruction and raw data at
timestep t in the i-th window, respectively.
The overall loss function can be expressed as the summation of reconstruction loss, contextual contrastive loss, and
instance contrastive loss, as shown in Eq. (8). Our goal is to minimize the overall loss so as to learn the normal pattern of
the data.
L ¼ Lrecon þ k1Lcont þ k2Linst;
ð8Þ
where Lrecon; Lcont; Linst represent reconstruction loss, contextual contrastive loss, and instance contrastive loss respectively.
k1, and k2 are hyperparameters. The training procedure is summarized in Algorithm1.
Algorithm1: CAE-AD training
Input: The preprocessed training dataset X
Output: The trained network with parameters h
1: Initialize the network parameters h
2: repeat
3:
/* Samples for model inputs */
x1:w  X
4:
/* Contextual contrastive loss using Eq. (2) */
Lcont  
1
Nw
PNw
i¼1
Pw
t¼1lði;tÞ
cont
5:
/* Instance contrastive loss using Eq. (5) */
Linst  1
Nb
PNb
i¼1
PB
t¼1lði;tÞ
inst
6:
/* Reconstruction loss using Eq. (7) */
Lrecon  
1
wNw
PNw
i¼1
Pw
t¼1ð^xðiÞ
t  xðiÞ
t Þ
2
7:
/* Overall loss using Eq. (8) */
Lðx1:w; hÞ  Lrecon þ k1Lcont þ k2Linst
8:
/* Optimize the parameters */
h  AdamðLðx1:w; hÞÞ
9: until convergence
3.5. Anomaly Detection
Historical information is essential for MTS data, so we utilize the previous reconstruction errors to calculate the anomaly
score St of xt at the current timestep t, as:
St ¼ 1
w
X
t
i¼twþ1
ð^xi  xiÞ
2;
ð9Þ
where ^xi is the reconstructed MTS data, and the window size is w.
We hypothesis that anomalies appear in low-density regions. The CAE-AD is optimized using clean dataset without
anomalies to learn the normal pattern. In test process, the test data will be mapped to the normal latent space and the latent
vectors z will be close to each other due to the effect of multi-grained contrasting. If an anomaly point x0 does not conform
the normal pattern, then it will have a low probability pðx0jzÞ to perform reconstruction, which leads to a high reconstruction
error. Thus, a higher anomaly score means that the data at timestep t is more likely to be an anomalous value. Otherwise, it is
considered as normal data. The choice of the threshold depends on the application scenario, and many studies [18,34] con-
ﬁgure the threshold dynamically based on anomaly scores. In this paper, we focus on designing the framework for learning
robust representation and performing better reconstruction. We enumerate all thresholds and select the one with the best F1
score as the previous works [3,9] done.
4. Experiments
In this section, extensive experiments are conducted to evaluate the performance of CAE-AD. First, we compare CAE-AD
with the state-of-the-art models. Subsequently, three variants of the CAE-AD framework are constructed to validate the
effectiveness of two proposed contrastive losses. Furthermore, parameter sensitivity and ablation study experiments are also
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
272
 conducted to learn the response of CAE-AD in different settings. Last, visualization experiments are carried out to demon-
strate the representation of latent variables.
4.1. Datasets
Three public datasets are adopted in our experiments. The properties of the datasets are summarized in Table 1.
Server Machine Dataset (SMD)1. SMD is a new 5-week-long dataset from a large Internet company collected and publicly
published by [34]. SMD dataset is divided into 28 subsets and each subset is collected from a server machine with 38 monitoring
indicators.
Soil Moisture Active Passive (SMAP)2 satellite Datasets and Mars Science Laboratory (MSL)2 rover Datasets. SMAP and MSL data-
sets are real-world and expert-labeled telemetry data from NASA [18]. The SMAP/MSL datasets contain 55/27 subsets, each of
which has 25/55 channels.
4.2. Evaluation Metrics
Precision (Pre), Recall (Rec), and F1 score are used to evaluate the performance of CAE-AD and baselines. In our experi-
ments, we enumerate all thresholds and use the best F1-score to evaluate the performance, which is also called F1-best
[26,34,9].
Anomalous observations usually appear in consecutive segments. Therefore, we utilize the point-adjust approach to
detect anomalies. Speciﬁcally, if any observation in the ground truth abnormal segment is detected correctly, all observa-
tions in the segment are considered to be detected correctly. Otherwise, all the observations in the abnormal segment are
not identiﬁed.
4.3. Baseline Models
We compare our model with nine unsupervised methods for MTS data anomaly detection as follows. Note that only our
proposed framework CAE-AD considers the local invariant characteristics of MTS data.
iForest [24]. An ensemble model to isolate anomalies by randomly selecting a feature and randomly splitting the obser-
vations. However, temporal information is not considered in iForest.
EncDec-AD [26]. A Seq2seq model to detection anomaly for multivariate time series data. LSTM network is used to con-
duct an encoder and decoder, which can capture the temporal dependence of time series data.
LSTM-NDT [18]. A prediction-based model, which uses the LSTM network to predict the telemetry data and the prediction
errors are the measures of anomaly scores.
OmniAnomaly [34]. A stochastic model to learn the robust representation of the MTS data. The reconstruction probabil-
ities are utilized to calculate the anomaly scores.
Transformer-AD [38]. A prediction-based model using transformer encoder to detect anomalies. First, we construct a
transformer encoder with multi-head attention mechanism and positional encoding following the literature. And then a
mask is used to prevent future information leakage. Finally, a fully-connected layer is constructed to predict the MTS data,
and the prediction errors are employed to calculate anomaly scores.
USAD [3]. A anomaly detection method based on two autoencoders, which are trained in an adversarial way to recon-
struct data. The reconstruction errors of two autoencoders are utilized to calculate anomaly scores.
DROCC [14]. A one-class based anomaly detection method, which utilizes adversarial training to learn robust represen-
tation of data.
RANSynCoders [1]. A anomaly detection approach based on bootstrapped autoencoders, which learns synchronized rep-
resentation of data.
GANF [8]. A density-based anomaly detection method. GANF uses a graph-based encoder to model relationships of dif-
ferent dimensions and utilizes a conditional normalizing ﬂow to estimate the density. Lower densities indicate more likely
anomalies.
4.4. Performance Evaluation
In our experiments, we implement CAE-AD based on PyTorch. The hidden size of the LSTM encoder is 64, and the dimen-
sion of latent variable z is 18 empirically. The deviation of Gaussian noise r1;r2 and the temperature parameter s are set to
0.5, 0.5 and 0.25 empirically in our experiment, respectively. The hidden state of the decoder and the reconstruction data are
concatenated and transformed by the fully-connected neural network to conduct the input of the LSTM decoder. The window
size w and sliding window interval l are 36 and 10, respectively.
1 https://github.com/NetManAIOps/OmniAnomaly
2 https://github.com/khundman/telemanom
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
273
 Results and Analysis. Table 2 reports the precision, recall, and the F1-best scores of CAE-AD and other baseline models.
We use bold font for the best F1 score and underline font for the second-best F1 score. As demonstrated in Table 2, the per-
formance of CAE-AD outperforms all the baseline models. Speciﬁcally, the F1-best score of CAE-AD is 0.9376 on SMD data-
sets, which is slightly higher than that of OmniAnomaly and far better than the other methods. For SMAP and MSL datasets,
CAE-AD achieves the F1-best score of 0.9302 and 0.9119 respectively. The case studies of CAE-AD are shown in Fig. 4a and
Fig. 4b, demonstrating that CAE-AD can correctly detect the abnormal points. The abnormal timesteps of SMD machine-1–1
datasets are relatively concentrated, while the abnormal timesteps of SMD machine-2–3 datasets are relatively scattered.
CAE-AD achieves stable performance in the two subsets, which further validates the ability of CAE-AD to learn normal pat-
terns of MTS data.
IForest [24] randomly selects features and splits the values to separate abnormal points, but the temporal dependency of
MTS data is not considered. Compared with SMAP and MSL datasets, the SMD datasets contain more extreme abnormal val-
ues with sudden peaks or valleys, which are easy for iForest to isolate. So iForest presents a lower performance on SMAP and
MSL datasets with the F1-best score of 0.5738 and 0.4762, respectively.
EncDec-AD [26] is a seq2seq based model with LSTM encoder-decoder structure. This method models normal time series
behaviour, and utilizes reconstruction errors to detect anomalies. LSTM encoder and decoder are employed to capture tem-
poral features of time series, so EncDec-AD achieves a better performance than iForest. But this method can not characterize
the dynamics of time series.
LSTM-NDT [18] is a prediction-based model with one LSTM layer, which takes temporal information into consideration.
For SMAP and MSL datasets, LSTM-NDT predicts the telemetry data for the next time step using the historical telemetry data
for the ﬁrst channel and the one-hot encoded information for the other channels. The results show that LSTM-NDT achieves
high F1-best scores of 0.9147 on SMAP datasets. However, due to the complex network states and high dimensional data on
SMD dataset, LSTM-NDT fails to capture the normal pattern and performs poorly.
OmniAnomaly [34] conducts a stochastic recurrent neural network to learn the robust representation of MTS data and
achieves the second F1-best scores on SMD datasets. However, OmniAnomaly ignores the local invariant information, and
the noise data can be given high anomalous scores that may be mistaken for abnormal points. CAE-AD introduces instance
contrasting, which is helpful for latent variables to learn the local invariant property of MTS, and data augmentation methods
Table 1
The properties of the datasets.
Dataset
Subset
Dimension
Train
Test
Anomalies(%)
SMD
28
38
708405
708420
4.16
SMAP
55
25
135183
427617
13.13
MSL
27
55
58317
73729
10.72
Table 2
Experiment Results: the precision, recall and F1best scores of baselines and CAE-AD. The highest F1best score is bolded, and the second best result is underlined.
SMD
SMAP
MSL
Method
Pre
Rec
F1best
Pre
Rec
F1best
Pre
Rec
F1best
iForest [24]
0.5424
0.8957
0.6757
0.6481
0.5147
0.5738
0.5556
0.4167
0.4762
EncDec-AD [26]
0.9014
0.6764
0.7729
0.9814
0.7794
0.8688
0.931
0.75
0.8307
LSTM-NDT [18]
0.4726
0.7213
0.5711
0.8676
0.9672
0.9147
0.8056
0.9375
0.8656
OmniAnomaly [34]
0.9260
0.9149
0.9204
0.9502
0.5482
0.6953
0.9245
0.8502
0.8858
Transformer-AD [38]
0.8390
0.7242
0.7745
0.9076
0.8676
0.8872
0.9667
0.8056
0.8787
USAD [3]
0.7951
0.9418
0.8622
0.9032
0.8235
0.8615
0.8684
0.9167
0.8918
DROCC [14]
0.7469
0.7905
0.7681
0.4788
0.9881
0.6451
0.5944
0.9641
0.7354
RANSynCoders [1]
0.7536
0.8451
0.7967
0.9413
0.2116
0.3455
0.2862
0.9385
0.4386
GANF [8]
0.6408
0.8532
0.7319
0.6141
0.9869
0.7571
0.4720
0.9854
0.6383
CAE-AD
0.9265
0.9491
0.9376
0.8824
0.9836
0.9302
0.8611
0.9688
0.9119
Fig. 4. Case study of anomaly score on SMD machine-1–1 and SMD machine-2–3 datasets. The red region highlights the truth anomaly intervals.
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
274
 in the time domain and frequency domain enhance the anti-noise capability of CAE-AD. Consequently, the OmniAnomaly
method has a lower recall rate than our CAE-AD.
Transformer-AD [38] utilizes multi-head attention to learn the dependent information among different timesteps. As
demonstrated in Table 2, Transformer-AD achieves F1-best scores of 0.7745 and 0.8787 on SMD and MSL datasets respec-
tively, which performs better than iForest and LSTM-NDT. The reason is that the attention mechanism calculates attention
scores of the input sequence and can capture historical information of input data at each time stamp, while LSTM-based
methods selectively retain historical information, which may miss certain useful information. Therefore, Transformer-AD
has better overall performance than LTSM-based methods, such as LSTM-NDT. However, Transformer-AD does not consider
the inherent nature of MTS, such as local time invariance, and it performs inferior to CAE-AD.
USAD [3] conducts two autoencoders with one encoder and two decoders. In the training phase, USAD adversely trains
two autoencoders, and aims to amplify the reconstruction errors of anomalies. With proper regularization, USAD is capable
to utilize the advantages of autoencoder framework and achieves the second F1-best scores on MSL datasets. However, USAD
framework may also amplify the noises in the inference phase. Consequently, USAD obtains inferior overall performances
with respect to CAE-AD.
DROCC [14] utilizes the gradient-ascent method to generate anomalous instances, which alleviates the representation
collapse problem. However, the real-world data distribution is complex and the generated anomalies may not match the
ground-truth anomalies. CAE-AD only focuses on modelling normal data patterns, so it is demonstrated that DROCC per-
forms inferior to CAE-AD on all three datasets.
RANSynCoders [1] learns the synchronous representation in MTS data, and applies bootstrapped autoencoders to learn
the reconstructed lower bound and upper bound. Anomalies are identiﬁed by comparing the inputs and the decoded bounds.
For SMAP and MSL datasets, the ﬁrst dimension is telemetry data, and the other dimensions are 0/1 switch data. These
switch data contain a lot of zero elements and it is difﬁcult for the bootstrap aggregation based autoencoders to reconstruct
them. Therefore, it shows that RANSynCoders performs poorly in SMAP and MSL datasets.
GANF [8] uses a graph-based dependency encoder to learn correlate information in series dimension and applies condi-
tional normalizing ﬂows to model the densities of MST. However, GANF ignores the intrinsic invariant characteristics and
does not constrain the adjacency matrix of nodes. As demonstrated in Table 2, the performance of GANF is lower than
CAE-AD.
In summary, CAE-AD outperforms the baseline methods on the three public datasets. The autoencoder structure of CAE-
AD helps to obtain the reconstructions of time series, which is the key design that can be easily adapted to different datasets
for the anomaly detection task. Moreover, the multi-grained contrasting method helps the CAE-AD model to learn multi-
granularity temporal-dependent information, which enables the model to accurately construct a normal proﬁle and makes
abnormal data more discriminative.
4.5. Multi-grained Contrasting Analysis
In order to demonstrate the effectiveness of the contextual contrasting and instance contrasting, we evaluate the perfor-
mance of CAE-AD and the three variants, namely CAE-Inst-AD, CAE-Cont-AD and AE-AD. Among them, CAE-Inst-AD retains
the instance contrastive loss, while removing the contextual contrastive loss. CAE-Cont-AD leaves the contextual contrastive
loss while removing the instance contrastive loss. AE-AD is constructed using the LSTM autoencoder without any contrastive
loss. With the comparative experiments, we learn the response of CAE-AD to the proposed contextual contrastive loss and
instance contrastive loss.
As shown in Fig. 5, CAE-AD achieves the best performance on the three datasets and AE-AD achieves the lowest overall
performance. AE-AD models normal time series behaviour, and utilizes reconstruction errors to detect anomalies. However,
without multi-grained contrasting methods, AE-AD can not comprehensively describe the multi-scale temporal information
Fig. 5. F1-best of CAE-AD and the variants of CAE-Inst-AD, CAE-Cont-AD and AE-AD on SMD, SMAP and MSL datasets.
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
275
 of data, so it fails to learn steady normal data patterns, which further indicates that proper regularization for autoencoder
based model is necessary to improve the reconstruction abilities.
CAE-Cont-AD obtains F1-best scores of 0.8942, 0.9206, and 0.8656 on SMD, SMAP, and MSL datasets respectively. CAE-
Inst-AD has lower performance compared to CAE-Cont-AD. The reason is probably that contextual contrastive loss aims
to maximize the similarity of the observations at neighbouring timesteps and minimize the similarity at distant timesteps.
By considering timestep-level observations, contextual contrasting can learn ﬁne-grained contextual information of MTS
data. However, instance contrastive loss maximizes the similarity of different views of the observations in the same window
while minimizing the similarity of the observations in different windows within the minibatch. Considering window-level
observations, instance contrasting can learn coarse-grained contextual information, which is also called local invariant char-
acteristics of MTS data. Without contextual contrastive loss, CAE-Inst-AD may not perform well for reconstruction. Therefore,
CAE-Cont-AD achieves higher F1-best scores than CAE-Inst-AD for SMD, SMAP, and MSL datasets.
Meanwhile, without instance contrastive loss, CAE-Cont-AD fails to capture local invariant characteristics of MTS data, so
it demonstrates inferior performance to CAE-AD. Compared with the three variants, CAE-AD conducts multi-grained con-
trasting, so the latent variables can capture both temporal-dependent and local invariant characteristics, which validates
that contextual contrasting and instance contrasting are complementary. Therefore, CAE-AD can extract the normal data pat-
tern and demonstrate superior performance.
To sum up, the autoencoder model trained with multiple well-designed contrastive losses outperforms the typical
autoencoder, which proves that our multi-grained contrasting methods are key designs in CAE-AD.
4.6. Parameter Sensitivity
In this subsection, we study the effects of different parameters on the performance of CAE-AD. The main parameters of
our proposed method contain the window size w, sliding window interval l, dimension of latent variables z, and the dimen-
sion of hidden states h in the encoder. All the experiments in this section are conducted on machine-1–6 of the SMD dataset.
The ﬁrst case we study is how window size w affects the performance of CAE-AD. The larger the window size, the more
information the model can obtain. We use different window sizes w ¼ ½10; 20; 30; 40; 100. As shown in Fig. 6(a), the best
result is achieved for window size w ¼ 30. It is observed that a smaller window size tends to yield a lower F1-best score,
Fig. 6. The sensitivity of different parameters on machine-1–6 dataset of SMD. F1-best, Precision and recall are demonstrated to evaluate the responses of
CAE-AD to (a) different window sizes w, (b) different sliding window intervals l, (c) different dimensions of latent variables z, (d) different dimensions of
hidden states h in the encoder.
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
276
 since CAE-AD is not capable of describing the correlation of different timesteps when the input sequence contains less infor-
mation. Historical reconstruction errors are used to calculate the anomaly score of the data at the last timestep in the win-
dow. If a window is too large and may contain longer segments of anomalies, the normal data at the last timestep in the
window will obtain a higher anomaly score and thus can be misjudged as an abnormal point. So, a larger window size
demonstrates a lower F1-best score. For server machine datasets, a proper range from 20 to 40 can achieve better
performance.
The second factor we learn is how CAE-AD responds to different sliding window intervals l. During data preprocessing, a
sliding window is used to obtain a sequence of observations, and the sliding window interval affects the size of repeated
observations. Fig. 6(b) summaries the obtained results for different intervals l ¼ ½5; 10; 15; 20; 30. We observe that CAE-
AD achieves the highest F1-best score when the interval reaches 10, and larger intervals lead to inferior performance. The
reason may be that larger intervals contain less repeated observations, so CAE-AD may fail to capture the temporal depen-
dency of continuous observations.
Next, we explore the impacts of the dimension of latent variables z. Fig. 6(c) demonstrates the F1-best scores of different
dimensions of latent variables z ¼ ½5; 10; 20; 30; 50. We can observe that the lower dimensions of latent variables obtain bet-
ter performance. The reason may be that the encoder is capable of reducing the dimension of latent variables. A higher
dimension of latent variables may contain more noises, so it is difﬁcult to learn the normal pattern in high dimension fea-
tures, which indicates that we can choose the dimension of latent variables lower than the dimension of raw observations.
Finally, we analyze the impact of the dimension of hidden states in the encoder. We explore different dimensions of hid-
den states h ¼ ½10; 20; 40; 60; 100 in our experiments. As Fig. 6(d) shows, CAE-AD achieves a stable performance when hid-
den dimension reaches 40. When the hidden dimensions in the shared-weights encoder are higher than 40, it is observed
that hidden dimensions are sightly sensitive to the performance of CAE-AD. The reason is that the multi-grained contrasting
plays an important role in capturing normal data patterns, and the parameters or the network of the encoder can have a
wider range of choices.
4.7. Ablation Study
In this section, we study the effect of each part of our model. Speciﬁcally, we repeat our experiments with/without key
modules. As demonstrated in Table 3, our proposed model CAE-AD achieves the best performance on the SMD dataset.
Directly removing the attention module and not using the contextual contrasting loss (CAE-AD_WO_ATTENTION_CONT),
the F1 score drops by 22.77% compared to the Baseline. Further, we use a fully-connected neural network to replace the
attention mechanism and retain the contextual contrastive loss (CAE-AD_WO_ATTENTION), and the performance is much
improved compared to removing it directly, which proves that both the attention mechanism and contextual contrasting
method work together to learn the temporal representation of data.
Besides, we also remove the time-domain data augmentation marked as CAE-AD_WO_FREQAUG and the frequency-
domain data augmentation marked as CAE-AD_WO_TIMEAUG in turn and only use the single data augmentation method
to generate different views of MTS. The results show that the model does not perform well in this case, which validates that
various data augmentation methods help comprehensively describe dynamic characteristics in MTS. Finally, we replace the
well-designed LSTM decoder with a simple fully-connected network (CAE-AD_WO_DECODER). The results show that the
performance drops sharply compared to the Baseline. This is because the latent vector z does not directly contain the infor-
mation at all time steps, so the sequential decoding method is necessary for the decoder to explore the dependency charac-
teristics of MTS. These ablation studies validate that each module in our model is useful and necessary.
4.8. Visualization of Latent Variables
To further demonstrate the effectiveness of CAE-AD to learn the normal data pattern, we conduct an additional experi-
ment for the visualization of latent variables.
CAE-AD is a reconstruction-based model. For a window of MTS data, the siamese encoders compress raw data to a latent
variable, and then the decoder reconstructs the data. Contrastive Autoencoder learns the normal data patterns training on
the normal data. If an abnormal observation appears as an input to the contrastive autoencoder, our model will encode
Table 3
Ablation study on SMD dataset.
Model
Pre
Rec
F1best
CAE-AD
0.9265
0.9491
0.9376
CAE-AD_WO_ATTENTION_CONT
0.6550
0.7749
0.7099
CAE-AD_WO_ATTENTION
0.8172
0.8183
0.8177
CAE-AD_WO_FREQAUG
0.8678
0.6362
0.7342
CAE-AD_WO_TIMEAUG
0.6625
0.6879
0.6750
CAE-AD_WO_DECODER
0.4312
0.8182
0.5648
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
277
 the observation to normal latent variable z. In this case, the reconstruction largely deviates from the actual one, and then the
abnormal observation is detected correctly.
Speciﬁcally, we select the machine-1–1 subset of SMD datasets to obtain the latent variables, and employ t-Distributed t-
SNE (Stochastic Neighbor Embedding) [37] to visualize the latent variables. As shown in Fig. 7(a), each point means a latent
variable and the corresponding colour represents the timestep of the observation. Latent variables are close to each other in
contextual data and far from each other among distant data, which indicates that contextual contrasting and instance con-
trasting are important for learning multi-scale contextual information. We highlight the latent variables of abnormal obser-
vations with the red colour, as shown in Fig. 7(b). The distribution of abnormal latent variables is similar to normal latent
variables, indicating that CAE-AD can explicitly learn the representations of the normal data pattern.
5. Discussion
In this paper, we novelly combine the contrastive loss and mean square error (MSE) loss to jointly train a well-designed
contrastive antoencoder framework for anomaly detection task. Typical antoencoder only uses MSE loss to train the model
for extracting detailed information of reconstructed data, but the MSE loss is sensitive to anomalies, which may lead to infe-
rior performance in anomaly detection task. For example, if the training data contain very few anomaly points, then MSE loss
will penalize the model to ﬁt these anomalies, which makes autoencoder model fail to construct a normal proﬁle. Contrastive
learning methods are able to learn invariant information in the data, so the contrastive loss is not sensitive to noisy data.
However, is it feasible to use only contrastive loss to learn normal data pattern?.
To discuss this question, we simplify the contrastive loss in Eq. (5) as the following formula:
Linst ¼ E
X½log
f enðxt; ztÞ
X
xj2X
f enðxj; ztÞ
;
ð10Þ
Where numerator is the positive sample, and the denominator is the sum of one positive sample and all negative samples.
In our case, f enðxt; ztÞ ¼ expðcosðzt; zþ
t Þ=sÞ. The contrastive loss can be considered as categorical cross-entropy loss with prob-
ability pðd ¼ tjX; ztÞ / f enðxt; ztÞ=P
xj2Xf enðxj; ztÞ to correctly classify the positive sample, where the indicator d ¼ t means xt is
a positive sample.
As proven in previous literature [29], f enðxt; ztÞ / pðxtjztÞ=pðxtÞ, which means this function descripts the mutual informa-
tion between xt and zt. However, in practice, adjacent or periodic time series segments xjðj – tÞ may also have strong corre-
lations with zt and the mutual information between them will be large, resulting in a higher probability pðd ¼ jjX; ztÞ. Thus, xj
will be misclassiﬁed as a positive sample. This problem can be avoided by using a MSE loss to encourage the model to learn
details of reconstruction information. Consequently, only contrastive loss is insufﬁcient to learn the optimal normal pattern.
We carefully combine the advantages of the contrastive loss and MSE loss and propose a well-designed contrastive
autoencoder framework. In our proposed framework, the autoencoder is capable of capturing detailed information to recon-
struct input time series and the contrastive loss can encourage the model to learn invariant information, which improves the
model’s ability to deal with noisy data. As the experimental results shown, this combination is proved to be effective and
necessary for improving anomaly detection performance.
6. Conclusion
This paper proposes a novel contrastive autoencoder for anomaly detection in MTS data, namely CAE-AD. The CAE-AD
framework ﬁrst generates two different views for each segment by applying data augmentation in both the time domain
Fig. 7. Visualization of latent variables on machine-1–1 of SMD. Each point means a latent variable and the corresponding color represents the timestep.
Specially, red points are latent variables of abnormal points.
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
278
 and frequency domain. Then multi-grained contrasting methods are proposed to learn robust representation in multiple
scales of MTS. Contextual contrasting learns temporal features by applying attention mechanism, and instance contrasting
learns invariant features within two augmented views of the same sample. The multi-grained contrasting methods are able
capture temporal-dependent and local invariant characteristics in MTS data. The experimental results show that CAE-AD
outperforms the baseline models and each module in CAE-AD is effective. Furthermore, visualization of learned representa-
tions demonstrates the capability of CAE-AD to model the normal data pattern.
For future work, the dynamic threshold selection method will be explored, and more real-world data will be used for
experiments to improve the robustness of CAE-AD. We will extend the CAE-AD model to multi-modal datasets and consider
improved methods for the long-tail problem in various datasets.
CRediT authorship contribution statement
Hao Zhou: Conceptualization, Methodology, Software, Investigation, Visualization, Formal analysis, Writing - original
draft. Ke Yu: Conceptualization, Funding acquisition, Resources, Supervision, Writing - review & editing. Xuan Zhang: Fund-
ing acquisition, Supervision, Writing - review & editing. Guanlin Wu: Data curation, Investigation, Validation. Anis Yazidi:
Investigation, Supervision, Writing - review & editing.
Data availability
Data will be made available on request.
Declaration of Competing Interest
The authors declare that they have no known competing ﬁnancial interests or personal relationships that could have
appeared to inﬂuence the work reported in this paper.
Acknowledgements
This work is partially supported by: the National Natural Science Foundation of China under the Grant No. 61601046 and
61171098; the 111 Project of China under the Grant No. B08004; and the project Spacetime Vision: Towards Unsupervised
Learning in the 4D World ﬁnanced by the EEA and Norway Grants 2014–2021 under the Grant No. EEA-RO-NO-2018–04.
This work is also supported by BUPT Excellent Ph.D. Students Foundation under the Grant No. CX2022149.
References
[1] Ahmed Abdulaal, Zhuanghua Liu, Tomer Lancewicki, Practical approach to asynchronous multivariate time series anomaly detection and localization,
in: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, 2021, pp. 2485–2494.
[2] Junfeng An, Haoyang Luo, Zheng Zhang, Lei Zhu, Lu. Guangming, Cognitive multi-modal consistent hashing with ﬂexible semantic transformation,
Information Processing & Management 59 (1) (2022) 102743.
[3] Julien Audibert, Pietro Michiardi, Frédéric Guyard, Sébastien Marti, Maria A Zuluaga, Usad: Unsupervised anomaly detection on multivariate time
series, in: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 2020, pp. 3395–3404.
[4] Sabyasachi Basu, Martin Meckesheimer, Automatic outlier detection for time series: An application to sensor data, Knowledge and Information
Systems 11 (2) (2007) 137–154.
[5] Wanpracha Art Chaovalitwongse, Ya.-Ju. Fan, Rajesh C Sachdeo, On the time series k-nearest neighbor classiﬁcation of abnormal brain activity, IEEE
Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans 37 (6) (2007) 1005–1016.
[6] Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton, A simple framework for contrastive learning of visual representations, in:
International Conference on Machine Learning, PMLR, 2020, pp. 1597–1607.
[7] Zekai Chen, Dingshuo Chen, Xiao Zhang, Zixuan Yuan, Xiuzhen Cheng, Learning graph structures with transformer for multivariate time series anomaly
detection in iot, IEEE Internet of Things Journal (2021).
[8] Enyan Dai, Jie Chen, Graph-augmented normalizing ﬂows for anomaly detection of multiple time series, in: International Conference on Learning
Representations, 2022, pp. 1–16.
[9] Liang Dai, Tao Lin, Chang Liu, Bo Jiang, Yanwei Liu, Zhen Xu, and Zhi-Li Zhang. Sdfvae: Static and dynamic factorized vae for anomaly detection of
multivariate cdn kpis. In Proceedings of the Web Conference 2021, pages 3076–3086, 2021.
[10] Terrance DeVries and Graham W Taylor. Dataset augmentation in feature space. arXiv:1702.05538, 2017.
[11] Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, Chee Keong Kwoh, Xiaoli Li, and Cuntai Guan. Time-series representation learning via
temporal and contextual contrasting. arXiv:2106.14112, 2021.
[12] Sarah M Erfani, Sutharshan Rajasegarar, Shanika Karunasekera, Christopher Leckie, High-dimensional and large-scale anomaly detection using a linear
one-class svm with deep learning, Pattern Recognition 58 (2016) 121–134.
[13] Hongchao Fang, Sicheng Wang, Meng Zhou, Jiayuan Ding, and Pengtao Xie. Cert: Contrastive self-supervised learning for language understanding.
arXiv preprint arXiv:2005.12766, 2020.
[14] Sachin Goyal, Aditi Raghunathan, Moksh Jain, Harsha Vardhan Simhadri, and Prateek Jain. Drocc: Deep robust one-class classiﬁcation. In International
Conference on Machine Learning, pages 3711–3721. PMLR, 2020.
[15] Lansheng Han, Man Zhou, Wenjing Jia, Zakaria Dalil, Xu. Xingbo, Intrusion detection model of wireless sensor networks based on game theory and an
autoregressive model, Information sciences 476 (2019) 491–504.
[16] Kaiming He, Haoqi Fan, Wu. Yuxin, Saining Xie, Ross Girshick, Momentum contrast for unsupervised visual representation learning, in: Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 9729–9738.
[17] David J Hill, Barbara S Minsker, Anomaly detection in streaming environmental sensor data: A data-driven modeling approach, Environmental
Modelling & Software 25 (9) (2010) 1014–1022.
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
279
 [18] Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, Tom Soderstrom, Detecting spacecraft anomalies using lstms and
nonparametric dynamic thresholding, in: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining,
2018, pp. 387–395.
[19] Eamonn Keogh, Jessica Lin, Fu. Ada, Hot sax: Efﬁciently ﬁnding the most unusual time series subsequence, in: Fifth IEEE International Conference on
Data Mining (ICDM), IEEE, 2005, p. 8.
[20] Istvan Kiss, Béla Genge, Piroska Haller, Gheorghe Sebestyén, Data clustering-based anomaly detection in industrial control systems, in: 2014 IEEE 10th
International Conference on Intelligent Computer Communication and Processing (ICCP), IEEE, 2014, pp. 275–281.
[21] Hans-Peter Kriegel, Matthias Schubert, Arthur Zimek, Angle-based outlier detection in high-dimensional data, in: Proceedings of the 14th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining, 2008, pp. 444–452.
[22] Dan Li, Dacheng Chen, Baihong Jin, Lei Shi, Jonathan Goh, and See-Kiong Ng. Mad-gan: Multivariate anomaly detection for time series data with
generative adversarial networks. In International Conference on Artiﬁcial Neural Networks, pages 703–716. Springer, 2019.
[23] Dapeng Liu, Youjian Zhao, Haowen Xu, Yongqian Sun, Dan Pei, Jiao Luo, Xiaowei Jing, and Mei Feng. Opprentice: Towards practical and automatic
anomaly detection through machine learning. In Proceedings of the 2015 Internet Measurement Conference, pages 211–224, 2015.
[24] Fei Tony Liu, Kai Ming Ting, Zhi-Hua Zhou, Isolation forest, in: Eighth IEEE International Conference on Data Mining (ICDM), IEEE, 2008, pp. 413–422.
[25] Xuanqing Liu, Yu. Hsiang-Fu, Inderjit Dhillon, Cho-Jui Hsieh, Learning to encode position for transformer with continuous dynamical model, in:
International Conference on Machine Learning, PMLR, 2020, pp. 6327–6335.
[26] Pankaj Malhotra, Anusha Ramakrishnan, Gaurangi Anand, Lovekesh Vig, Puneet Agarwal, and Gautam Shroff. Lstm-based encoder-decoder for multi-
sensor anomaly detection. arXiv:1607.00148, 2016.
[27] Xuying Meng, Suhang Wang, Zhimin Liang, Di Yao, Jihua Zhou, Yujun Zhang, Semi-supervised anomaly detection in dynamic communication networks,
Information Sciences 571 (2021) 527–542.
[28] Mohsin Munir, Shoaib Ahmed Siddiqui, Andreas Dengel, Sheraz Ahmed, Deepant: A deep learning approach for unsupervised anomaly detection in
time series, IEEE Access 7 (2018) 1991–2005.
[29] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predictive coding. arXiv:1807.03748, 2018.
[30] Daehyung Park, Yuuna Hoshi, Charles C Kemp, A multimodal anomaly detector for robot-assisted feeding using an lstm-based variational autoencoder,
IEEE Robotics and Automation Letters 3 (3) (2018) 1544–1551.
[31] Daehyung Park, Hokeun Kim, Yuuna Hoshi, Zackory Erickson, Ariel Kapusta, Charles C Kemp, A multimodal execution monitor with anomaly
classiﬁcation for robot-assisted feeding, in: 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), IEEE, 2017, pp. 5406–
5413.
[32] Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani. Self-attention with relative position representations. arXiv:1803.02155, 2018.
[33] Taeshik Shon, Jongsub Moon, A hybrid machine learning approach to network anomaly detection, Information Sciences 177 (18) (2007) 3799–3821.
[34] Su. Ya, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, Dan Pei, Robust anomaly detection for multivariate time series through stochastic recurrent
neural network, in: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 2019, pp. 2828–2837.
[35] Shreshth Tuli, Giuliano Casale, and Nicholas R Jennings. Tranad: Deep transformer networks for anomaly detection in multivariate time series data.
arXiv preprint arXiv:2201.07284, 2022.
[36] Mehmet Turkoz, Sangahn Kim, Youngdoo Son, Myong K Jeong, Elsayed A Elsayed, Generalized support vector data description for anomaly detection,
Pattern Recognition 100 (2020) 107119.
[37] Laurens Van Der Maaten, Accelerating t-sne using tree-based algorithms, The Journal of Machine Learning Research 15 (1) (2014) 3221–3245.
[38] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need.
In Advances in Neural Information Processing Systems, pages 5998–6008, 2017.
[39] Xu. Jiehui, Wu. Haixu, Jianmin Wang, Mingsheng Long, Anomaly transformer: Time series anomaly detection with association discrepancy, in:
International Conference on Learning Representations, 2022.
[40] Zhihan Yue, Yujing Wang, Juanyong Duan, Tianmeng Yang, Congrui Huang, Yunhai Tong, and Bixiong Xu. Ts2vec: Towards universal representation of
time series. arXiv:2106.10466, 2021.
[41] Yang Zhang, Nicholas A.S. Hamm, Nirvana Meratnia, Alfred Stein, M. Van De Voort, Paul J.M. Havinga, Statistics-based outlier detection for wireless
sensor networks, International Journal of Geographical Information Science 26 (8) (2012) 1373–1392.
[42] Zheng Zhang, Haoyang Luo, Lei Zhu, Guangming Lu, and Heng Tao Shen. Modality-invariant asymmetric networks for cross-modal hashing. IEEE
Transactions on Knowledge and Data Engineering, 2022.
H. Zhou, K. Yu, X. Zhang et al.
Information Sciences 610 (2022) 266–280
280
",https://doi.org/10.1016/j.ins.2022.07.179,doc16,"Contrastive autoencoder for anomaly detection in multivariate time series Hao Zhou a, Ke Yu a,⇑, Xuan Zhang b, Guanlin Wu a, Anis Yazidi c,d,e a Beijing University of Posts and Telecommunications, Beijing, China b Norwegian Research Centre AS, Grimstad, Norway c Oslo Metropolitan University, Oslo, Norway d Norwegian University of Science and Technology, Trondheim, Norway e Oslo University Hospital, Oslo, Norway a r t i c l e i n f o Article history: Received 21 April 2022 Received in revised form 24 July 2022 Accepted 28 July 2022 Available online 3 August 2022 Keywords: Anomaly detection Multivariate time series Autoencoder Contrastive learning Data augmentation a b s t r a c t With the proliferation of the Internet of Things, a large amount of multivariate time series (MTS) data is being produced daily by industrial systems, corresponding in many cases to life-critical tasks. The recent anomaly detection researches focus on using deep learning methods to construct a normal proﬁle for MTS. However, without proper constraints, these methods cannot capture the dependencies and dynamics of MTS and thus fail to model the normal pattern, resulting in unsatisfactory performance. This paper proposes CAE-AD, a novel contrastive autoencoder for anomaly detection in MTS, by introducing multi- grained contrasting methods to extract normal data pattern. First, to capture the temporal dependency of series, a projection layer is employed and a novel contextual contrasting method is applied to learn the robust temporal representation. Second, the projected series is transformed into two different views by using time-domain and frequency-domain data augmentation. Last, an instance contrasting method is proposed to learn local invariant characteristics. The experimental results show that CAE-AD achieves an F1-score ranging from 0.9119 to 0.9376 on the three public datasets, outperforming the baseline methods.  2022 Elsevier Inc. All rights reserved. 1. Introduction With the proliferation of the Internet of Things (IoT), a large amount of MTS data is generated constantly by industrial systems [18,15]. Since these data are usually associated with critical missions, monitoring them for unveiling anomalies is crucial. In simple terms, anomaly detection in MTS aims to detect the time stamps of the series where the observations deviate largely from the normal values or where unusual temporal patterns emerge. Anomaly detection is a well-established research topic that has attracted a lot of research attention over the last decades. In early stage, researchers have focused on methods for detecting anomalies in univariate time series data [19,4,17,41,28]. Within the context of modern industrial systems, a device is usually monitored by a multitude of sensors, each of which measures a distinct variable. Diagnosing MTS data with multiple monitoring indicators is essential to ensure the normal 0020-0255/ 2022 Elsevier Inc. All rights reserved. Abbreviations: MTS, multivariate time series. ⇑Corresponding author. E-mail addresses: zhouh@bupt.edu.cn (H. Zhou), yuke@bupt.edu.cn (K. Yu), xuan.z.jiao@gmail.com (X. Zhang), wuguanlin@bupt.edu.cn (G. Wu), anisy@oslomet.no (A. Yazidi). Information Sciences 610 (2022) 266–280 Contents lists available at ScienceDirect Information Sciences journal homepage: www.elsevier.com/locate/ins operations of industrial systems. Further, abnormal readings are usually difﬁcult to be annotated from a large amount of sen- sor data, making little or even no labels available in MTS. The supervised methods [33,23,31] are unfeasible in this case. Thus, we focus on identifying anomalies in MTS using unsupervised methods. Unsupervised anomaly detection methods in MTS are challenging with temporal dependency and dynamic variability. In the unsupervised setting, models are designed to construct a normal proﬁle through a large amount of normal time series data. Those that behave very differently from the normal pattern are detected as anomalies. The classic unsupervised time series anomaly detection methods, such as classiﬁcation-based models (e.g., one-class SVM [12,36]), distance-based models (e.g., KNN [5]) and clustering-based models, (e.g., k-means [20]), ignore the temporal dependency in MTS, resulting in infe- rior performance. Recently, autoencoder-based methods have received a lot of attention, owing to their ability to learn informative repre- sentation. The state-of-the-art anomaly detection methods usually apply well-designed autoencoders to capture normal pat- terns of MTS data, e.g., LSTM-based encoder-decoder model [26], adversarial training based autoencoder [3,27], and variational autoencoder [30,9], etc. Here, point-to-point reconstruction or prediction criteria are usually used to detect anomalies. However, due to the complexity of temporal dependency in MTS, the single point-wise context information can- not comprehensively characterize the temporal pattern of MTS data. Moreover, the normal pattern may change dynamically over time. Autoencoder-based models will suffer from an overﬁtting problem if no proper regularization is applied. There- fore, these methods fail to construct an accurate proﬁle for normal data and are incapable of learning robust representation, resulting in unsatisfactory performance in practice. In this paper, we propose a contrastive autoencoder for anomaly detection in MTS, namely CAE-AD. Contrastive learning has been proved successful to learn transformation-invariant representation of data in various domains, such as image clas- siﬁcation [6], audio [29] and language understanding [13]. Combining autoencoder with the contrastive loss for the window- segmented MTS, we ﬁnd that it is capable of capturing invariant information from the dynamically changing time series, which improves the robustness of the representation for autoencoder. However, the window-wise method is insufﬁcient for obtaining ﬁne-grained temporal representation. Therefore, we expand this method with multi-contrasting to explore point-wise and window-wise temporal information, which helps construct a normal proﬁle in MTS. Going beyond previous autoencoder-based methods, the proposed CAE-AD is able to model the temporal and dynamic features of time series. More precisely, we ﬁrst utilize the attention mechanism to capture the temporal dependency. Unlike commonly used positional coding methods, we adopt a contextual contrasting method to learn the position information. Subsequently, we explore data augmentation in the time and frequency domain, which helps obtain different views of the same segment. After that, a shared-weight encoder is developed to encode the augmented data and an instance contrast- ing method is proposed to capture the local invariant characteristics of latent variables. With the proposed multi-grained contrasting (the contextual contrasting and instance contrasting), CAE-AD can learn the robust representation of MTS. Finally, an LSTM decoder is devised and the reconstruction errors are further utilized to detect anomalies. Extensive exper- iments are conducted to validate the effectiveness of the proposed method. The main contributions of the paper are summarized as follows:  We propose a novel approach to detect anomalies in MTS, namely CAE-AD. Contrastive learning method is utilized to enhance the ability of the autoencoder for constructing a robust proﬁle for normal data, making abnormal data more dis- tinguishable to be detected.  Simple but efﬁcient data augmentation methods are designed for MTS in the CAE-AD framework. We explore augmenta- tion for MTS in both the time and frequency domains. This helps select positive pairs for contrasting and encourages learning dynamic behaviours of MTS data.  Multi-grained contrasting methods are proposed to learn the robust representations of MTS. First, we propose contextual contrasting to extract the temporal dependency of MTS. Second, we propose instance contrasting to further capture local invariant characteristics of MTS. With multi-grained contrasting methods, CAE-AD can comprehensively learn multi-scale contextual information.  We conduct extensive experiments to evaluate the performance of CAE-AD on three public datasets. The experiment results demonstrate that the performance of CAE-AD outperforms state-of-the-art baselines. The remainder of the paper is organized as follows: In Section 2, we provide an overview of the related work. In Section 3, we introduce the CAE-AD framework and anomaly detection in detail. The experimental results and analyses are presented in Section 4 before concluding the paper in the last section. 2. Related Work 2.1. Anomaly Detection MTS anomaly detection has recently become a popular research topic. There is an abundance of literature on MTS anom- aly detection. Traditional methods of anomaly detection in MTS mostly resort to statistical methods. In [5], Chaovalitwongse et al. suggested a distance-based model based on KNN to classify abnormal MTS data. In [21], an improved variant of the H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 267 distance-based model was proposed, and the authors took the angular relationship among the data points into account. Iso- lation Forest was utilized in [24], where the authors isolated outliers by dividing the data set. Although these methods are highly efﬁcient, they do not consider the long-term temporal dependency of MTS data. Methods based on deep learning have recently achieved signiﬁcant performance improvement for anomaly detection in MTS data. LSTM-NDT [18] applied LSTM to model the temporal dependence and detected anomalies based on prediction errors. The transformer-based methods have also gained a lot of attention. Anomaly Transformer [39] explored the self- attention weight for anomalies and proposed a minimax training strategy to amplify the difference between normal and abnormal data. GTA [7] used a transformer-based structure to learn a graph structure, which helped capture temporal dependency in MTS. TranAD [35] proposed a transformer-based model for anomaly detection and used adversarial training and self-conditioning technologies to improve the performance. The autoencoder-based model has become popular recently, where the encoder is employed to reduce the dimensionality of MTS data while the decoder aims to reconstruct the MTS. By minimizing the reconstruction errors, the autoencoder-based model can capture the normal pattern of the data, and reconstruction errors are further used to detect anomalies. For exam- ple, EncDec-AD [26] utilized LSTM as the basic cell of the encoder and decoder. LSTM-VAE [30] combined LSTM and VAE, but it ignored the dependence of stochastic variables. An approach reckoned as OmniAnomaly was proposed in [34] and it is based on a stochastic recurrent neural network that learnt normal data patterns by modelling robust representations of MTS data. MAD-GAN [22] adopted the GAN framework to capture the time and space information of the data. 2.2. Contrastive Learning Invariant information plays a crucial role in inter-domain or intra-domain tasks with noise perturbations. For example, CMCH was proposed by [2] to learn the consistent representation of hash codes for multi-modal data, which utilized the invariant information in multi-modal data to construct the informative latent space. MIAN [42] proposed modality- invariant asymmetric networks to preserve the semantic similarity, and proposed a conditional variational information bot- tleneck network to learn modality-invariant information. Unlike these supervised methods, contrastive learning methods learn the transformation-invariant representation of data in a self-supervised setting. The main idea of contrastive learning is to reduce the distance between similar samples in the feature space and maximize the distance between different samples in the same space. CPC [29] used autoregressive models to predict future values in latent space and proposed InfoNCE loss to train the network for obtaining robust data represen- tations. MoCo [16] further considered the limitation of obtaining negative samples and built a dynamic dictionary to look up sample pairs for contrasting. SimCLR [6] discussed the signiﬁcant role of data augmentation in contrastive learning and pro- posed a learnable nonlinear transformation module to improve the quality of contrastive representation vectors. Applying contrastive learning to time series data, TS-TCC [11] proposed a self-supervised framework with multiple con- trasting methods to learn informative time-series representation. TS2Vec [40] proposed a hierarchical contrasting method to learn multi-grained contextual information of time series. In this work, we develop a contrastive autoencoder representation learning and anomaly detection of MTS. 3. Proposed Model We ﬁrst present the problem description of anomaly detection in MTS data. Then, we give an overview of the CAE-AD framework and explain its main modules. Finally, we describe in detail the proposed model and anomaly detection. 3.1. Problem Description In this paper, we focus on detecting anomalies in MTS data. Let xt 2 Rm denotes the vector of dimension m at time step t, where xt;i 2 R denotes the value of ith variable at time step t. Multivariate time series can be expressed as X ¼ fx1; x2; . . . ; xNg; X 2 RNm, where N is the length of the observed sequence. A anomaly score St is calculated at timestep t. The point is detected as an anomaly if the anomaly score is greater than a speciﬁed threshold. 3.2. Overview of the Framework The CAE-AD framework is shown in Fig. 1, which consists of three parts: data preprocessing, learning representation, and anomaly detection. First, we normalize the data and divide them via windows during data preprocessing. Second, we propose a Contrastive Autoencoder model to learn the representation of MTS. As demonstrated in the bottom of Fig. 1, a projection layer is imple- mented to learn the embedding, and then we design two types of data augmentation methods in the time domain and fre- quency domain respectively, which is helpful to generate different views of the sequence data. The multi-grained contrasting method is proposed to capture the temporal dependency and local-invariant characteristics of the data. Finally, the anomaly score of each timestep is calculated based on the reconstruction error. H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 268 3.3. Preprocessing For the input MTS data X ¼ fx1; x2; . . . ; xNg, normalization is ﬁrst applied to scale the data. The observations at the current timestep depend on historical observations of the data. To capture the temporal dependency, we introduce a sliding window in the CAE-AD framework. As shown in Fig. 2, we obtain continuous data segments as the input of CAE-AD using a sliding window with the interval of l. For example, a window of observations can be expressed as x1:w ¼ ½x1; x2; . . . ; xw; x1:w 2 Rwm, where w is the window size and m is the dimension of the data. 3.4. Representation Model In the CAE-AD, we ﬁrst employ a projection layer and propose contextual contrasting to learn the temporal embedding of MTS data. Then we explore data augmentation methods for time series and propose instance contrasting to encourage robustness of representation. Last, an LSTM decoder is adopted to reconstruct the MTS data. 3.4.1. Projection Layer Contrastive learning aims at maximizing the similarity between the same samples of different views while minimizing the similarity between different samples to learn invariant characteristics. In order to select the positive pairs for contrasting, we explore different data augmentation methods to obtain various views of the data, which is considered critical in con- trastive learning [6]. Simple transformations are commonly used for time series augmentation, such as cropping, ﬂipping, and jittering, etc. However, it is not always appropriate to directly transform the original time series data. For example, the raw data may have an upward trend. If the cropping operation removes this trend, the augmented time series may represent a different mode while the previous contrastive learning strategy will deem both time series, original and augmented, similar. To overcome this problem, we employ a projection layer. We ﬁrst project the MTS data, and its embedding after projection layer can be used for data augmentation to supplement domain-speciﬁc knowledge [10]. In order to capture the temporal dependency of the data, we adopt the attention mechanism [38] as the projection layer. A mask is used to prevent future data information leakage, and all attention scores of the future data are assigned zeros. For a Fig. 2. Data preprocessing. A sliding window is adopted to slice the sequences. Fig. 1. The overall framework of CAE-AD. We ﬁrst conduct data normalization and segment the MTS using a sliding window. Then contrastive autoencoder is adopted to the learned robust representation of time series data. Finally, reconstruction errors are utilized to detect anomalies. H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 269 window of the data x1:w ¼ ½x1; x2 . . . ; xw, where w is the window size, linear transformations are utilized to obtain the query matrix Q, the key matrix K and the value matrix V respectively, where Q ¼ ½x1; . . . ; xwTWQ and WQ is a learnable matrix. The embedding after attention mechanism can be expressed by the following formula. a1:w ¼ softmax QKT ﬃﬃﬃﬃﬃ m p  Mask ! V; ð1Þ where a1:w ¼ ½a1; a2; . . . ; aw; a1:w 2 Rwm denotes the sequence of embeddings at 2 Rm. Symbol  denotes element-wise operation and KT is the transpose of K. Mask is a lower triangular matrix, which means that the data at timestep t only focus on current and historical information. For example, the embedding at only pays attention to the information of x1:t. 3.4.2. Contextual Contrasting The attention mechanism ignores the position information. To include position information, we propose contextual con- trasting to learn the relative position of the MTS data. The embedding at has a higher similarity to the representation of neighbor timesteps at1; atþ1, while has a lower sim- ilarity to representation of distant timesteps. Contextual contrasting aims at reducing the distance between neighbouring timesteps in the embedding space while increasing the distance between different timesteps in the embedding space, which can be expressed as follows: l ði;tÞ cont ¼  log expðcosðaðiÞ t ; aðiÞ t1Þ=sÞ þ expðcosðaðiÞ t ; aðiÞ tþ1Þ=sÞ X w k¼1 I½k–t expðcosðaðiÞ t ; aðiÞ k Þ=sÞ ; Lcont ¼ 1 Nw X Nw i¼1 X w t¼1 l ði;tÞ cont; where lði;tÞ cont denotes the loss function at timestep t in the i-th window. Nw is the total number of windows. I½k–t 2 f0; 1g is an indicator function, and it equals to 1 if k – t, and 0 otherwise. s is the temperature parameter. Cosine function is utilized to measure the similarity among the embeddings. The embeddings obtained by the attention mechanism do not include position information. There are certain articles [38,32,25] that have studied positional coding. However, those methods directly add the position information to the data, so that the data information may interfere with the position information. Alternatively, we adopt contextual contrasting to learn the position information in the embedding space, which provides a new view for the positional coding of the attention mechanism. 3.4.3. Data Augmentation To make full use of the properties of the MTS, we explore data augmentation methods for the embeddings of the projec- tion layer in both time and frequency domains respectively. In the time domain, we add Gaussian noise Nð0; R1Þ for the embeddings to generate similar samples, where R1 ¼ diagðr1Þ and r1 is the deviation. In frequency main, we perform a two-dimensional Discrete Fourier Transform on the embeddings a1:w ¼ ½a1; a2; . . . ; aw to obtain the spectrum Fðu;vÞ. Fðu;vÞ ¼ 1 wm X w1 t¼0 X m1 k¼0 at;k expðj2pðut=w þ vk=mÞÞ ¼ Aðu;vÞ expðjhðu;vÞÞ; ð3Þ where u ¼ 0; 1 . . . ; w  1 and v ¼ 0; 1; . . . ; m  1 denote the indices of frequencies, w and m are window size and dimension of the embeddings at respectively. Furthermore, Fðu;vÞ can also be expressed as the combination of amplitude spectrum Aðu;vÞ and phase spectrum hðu;vÞ. We add Gaussian noise Nð0; R2Þ for the amplitude spectrum Aðu;vÞ and phase spectrum hðu;vÞ, respectively, where R2 ¼ diagðr2Þ and r2 control the deviation of noise. Then, Inverse Discrete Fourier Transform (IDFT) is conducted to convert the frequency domain data into time-domain data. Finally, we take the real part as the augmented data, as shown in the equa- tion below: fðt; kÞ ¼ Real½IDFTðFðu;vÞÞ IDFT ¼ 1 wm X w1 u¼0 X m1 v¼0 Fðu;vÞ expðj2pðut=m þ vk=wÞÞ; ð4Þ where t ¼ 0; 1; . . . ; w  1, and k ¼ 0; 1; . . . ; m  1 denote the timestep and the dimension of the augmented data f ðt; kÞ respectively. H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 270 The proposed data augmentation methods help generate different views of the observed sequence and obtain positive pairs for instance constrasting. 3.4.4. Instance Contrasting We obtain two views of the data after time-domain and frequency-domain data augmentation. Then the augmented data is sent to LSTM siamese encoders to obtain low-dimensional latent variables, where LSTM siamese encoders are composed of two shared-weights LSTM neural networks. Finally, instance contrasting is applied to learn local invariant information of latent variables. The two views of MTS data in the same window are positive pairs, while the MTS data in different windows are consid- ered as negative pairs. Intuitively, Instance contrasting encourages maximizing the similarity of the different augmented data from the same window while minimizing the similarity of data from different windows, which aims to learn invariant information of the two types of augmented data. As shown in Fig. 3, The positive pair of latent variables can be expressed as ðzt; zþ t Þ, and the instance contrastive loss is shown in the equation below: l ði;tÞ inst ¼  log expðcosðzðiÞ t ;zðiÞþ t Þ=sÞ X B k¼1 ½expðcosðzðiÞ t ;zðiÞþ k Þ=sÞþI½k–t expðcosðzðiÞ t ;zðiÞ k Þ=sÞ ; Linst ¼ 1 Nb X Nb i¼1 X B t¼1 l ði;tÞ inst; ð5Þ where B is the minibatch size, and Nb is the number of the minibatches. Given the positive pair ðzðiÞ t ; zðiÞþ i;t Þ of the t-th window in the i-th minibatch, we calculate the contrastive loss lði;tÞ inst using cosin similarity. s is the temperature parameter. Instance contrasting works in window level, and contextual contrasting works in timestep level. The multi-grained con- trasting methods can learn the ﬁne-grained and coarse-grained information for time series. By combining the two types of contrastive losses, CAE-AD framework is capable of learning the representation from multiple scales. Furthermore, contex- tual contrasting and instance contrasting permit the framework to learn complementary information so that the represen- tation can better reconstruct the normal MTS. 3.4.5. LSTM Decoder The main goal of the decoder is to reconstruct the data. We conduct a recurrent decoding method as shown in Fig. 3. Speciﬁcally, we ﬁrst concatenate the latent variables ½z; zþ as the initial information, and an LSTM cell is applied to recon- struct the data at the ﬁrst timestep, namely, ^x1. Then, the reconstruction data ^x1 is concatenated with the hidden state of the decoder for the reconstruction at the next timestep, namely ^x2. The reconstruction method can be formulated as: ^xt ¼ Wrgðconcat½z; zþÞ; if t ¼ 0 WrgðWzconcat½ht; d xt1Þ; if t ¼ 1; 2; . . . w  1; :  ð6Þ where Wz; Wr are the learnable weight matrices. ht and ^xt denote the t-th hidden state of the decoder and the t-th output of the decoder respectively. We use LSTM network as the decoder gð:Þ, as shown in Fig. 3. Fig. 3. Detailed Neural Network of CAE-AD. In the detailed framework, q; k;v denote the query, key and value vector of attention mechanism, respectively. The green blocks represent the raw data fx1; x2; . . . ; xwg, the embeddings fa1; a2; . . . ; awg and the reconstructed data f ^x1; ^x2; . . . ; ^ xwg, respectively. The latent variables ðz1; zþ 1 Þ is a positive pair in the same window, and fðz1; z2Þ; . . . ; ðz1; zBÞ; ðz1; zþ 2 Þ; . . . ; ðz1; zþ B Þg are negative pairs in difﬁent windows of the minibatch. fh1; h2; . . . ; hwg are hidden states of the LSTM decoder. H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 271 The reconstruction loss can be expressed by: Lrecon ¼ 1 wNw X Nw i¼1 X w t¼1 ð^xðiÞ t  xðiÞ t Þ 2; ð7Þ where w; Nw are the window size and the number of windows, respectively. ^xðiÞ t ; xðiÞ t are the reconstruction and raw data at timestep t in the i-th window, respectively. The overall loss function can be expressed as the summation of reconstruction loss, contextual contrastive loss, and instance contrastive loss, as shown in Eq. (8). Our goal is to minimize the overall loss so as to learn the normal pattern of the data. L ¼ Lrecon þ k1Lcont þ k2Linst; ð8Þ where Lrecon; Lcont; Linst represent reconstruction loss, contextual contrastive loss, and instance contrastive loss respectively. k1, and k2 are hyperparameters. The training procedure is summarized in Algorithm1. Algorithm1: CAE-AD training Input: The preprocessed training dataset X Output: The trained network with parameters h 1: Initialize the network parameters h 2: repeat 3: /* Samples for model inputs */ x1:w  X 4: /* Contextual contrastive loss using Eq. (2) */ Lcont 1 Nw PNw i¼1 Pw t¼1lði;tÞ cont 5: /* Instance contrastive loss using Eq. (5) */ Linst 1 Nb PNb i¼1 PB t¼1lði;tÞ inst 6: /* Reconstruction loss using Eq. (7) */ Lrecon 1 wNw PNw i¼1 Pw t¼1ð^xðiÞ t  xðiÞ t Þ 2 7: /* Overall loss using Eq. (8) */ Lðx1:w; hÞ Lrecon þ k1Lcont þ k2Linst 8: /* Optimize the parameters */ h AdamðLðx1:w; hÞÞ 9: until convergence 3.5. Anomaly Detection Historical information is essential for MTS data, so we utilize the previous reconstruction errors to calculate the anomaly score St of xt at the current timestep t, as: St ¼ 1 w X t i¼twþ1 ð^xi  xiÞ 2; ð9Þ where ^xi is the reconstructed MTS data, and the window size is w. We hypothesis that anomalies appear in low-density regions. The CAE-AD is optimized using clean dataset without anomalies to learn the normal pattern. In test process, the test data will be mapped to the normal latent space and the latent vectors z will be close to each other due to the effect of multi-grained contrasting. If an anomaly point x0 does not conform the normal pattern, then it will have a low probability pðx0jzÞ to perform reconstruction, which leads to a high reconstruction error. Thus, a higher anomaly score means that the data at timestep t is more likely to be an anomalous value. Otherwise, it is considered as normal data. The choice of the threshold depends on the application scenario, and many studies [18,34] con- ﬁgure the threshold dynamically based on anomaly scores. In this paper, we focus on designing the framework for learning robust representation and performing better reconstruction. We enumerate all thresholds and select the one with the best F1 score as the previous works [3,9] done. 4. Experiments In this section, extensive experiments are conducted to evaluate the performance of CAE-AD. First, we compare CAE-AD with the state-of-the-art models. Subsequently, three variants of the CAE-AD framework are constructed to validate the effectiveness of two proposed contrastive losses. Furthermore, parameter sensitivity and ablation study experiments are also H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 272 conducted to learn the response of CAE-AD in different settings. Last, visualization experiments are carried out to demon- strate the representation of latent variables. 4.1. Datasets Three public datasets are adopted in our experiments. The properties of the datasets are summarized in Table 1. Server Machine Dataset (SMD)1. SMD is a new 5-week-long dataset from a large Internet company collected and publicly published by [34]. SMD dataset is divided into 28 subsets and each subset is collected from a server machine with 38 monitoring indicators. Soil Moisture Active Passive (SMAP)2 satellite Datasets and Mars Science Laboratory (MSL)2 rover Datasets. SMAP and MSL data- sets are real-world and expert-labeled telemetry data from NASA [18]. The SMAP/MSL datasets contain 55/27 subsets, each of which has 25/55 channels. 4.2. Evaluation Metrics Precision (Pre), Recall (Rec), and F1 score are used to evaluate the performance of CAE-AD and baselines. In our experi- ments, we enumerate all thresholds and use the best F1-score to evaluate the performance, which is also called F1-best [26,34,9]. Anomalous observations usually appear in consecutive segments. Therefore, we utilize the point-adjust approach to detect anomalies. Speciﬁcally, if any observation in the ground truth abnormal segment is detected correctly, all observa- tions in the segment are considered to be detected correctly. Otherwise, all the observations in the abnormal segment are not identiﬁed. 4.3. Baseline Models We compare our model with nine unsupervised methods for MTS data anomaly detection as follows. Note that only our proposed framework CAE-AD considers the local invariant characteristics of MTS data. iForest [24]. An ensemble model to isolate anomalies by randomly selecting a feature and randomly splitting the obser- vations. However, temporal information is not considered in iForest. EncDec-AD [26]. A Seq2seq model to detection anomaly for multivariate time series data. LSTM network is used to con- duct an encoder and decoder, which can capture the temporal dependence of time series data. LSTM-NDT [18]. A prediction-based model, which uses the LSTM network to predict the telemetry data and the prediction errors are the measures of anomaly scores. OmniAnomaly [34]. A stochastic model to learn the robust representation of the MTS data. The reconstruction probabil- ities are utilized to calculate the anomaly scores. Transformer-AD [38]. A prediction-based model using transformer encoder to detect anomalies. First, we construct a transformer encoder with multi-head attention mechanism and positional encoding following the literature. And then a mask is used to prevent future information leakage. Finally, a fully-connected layer is constructed to predict the MTS data, and the prediction errors are employed to calculate anomaly scores. USAD [3]. A anomaly detection method based on two autoencoders, which are trained in an adversarial way to recon- struct data. The reconstruction errors of two autoencoders are utilized to calculate anomaly scores. DROCC [14]. A one-class based anomaly detection method, which utilizes adversarial training to learn robust represen- tation of data. RANSynCoders [1]. A anomaly detection approach based on bootstrapped autoencoders, which learns synchronized rep- resentation of data. GANF [8]. A density-based anomaly detection method. GANF uses a graph-based encoder to model relationships of dif- ferent dimensions and utilizes a conditional normalizing ﬂow to estimate the density. Lower densities indicate more likely anomalies. 4.4. Performance Evaluation In our experiments, we implement CAE-AD based on PyTorch. The hidden size of the LSTM encoder is 64, and the dimen- sion of latent variable z is 18 empirically. The deviation of Gaussian noise r1;r2 and the temperature parameter s are set to 0.5, 0.5 and 0.25 empirically in our experiment, respectively. The hidden state of the decoder and the reconstruction data are concatenated and transformed by the fully-connected neural network to conduct the input of the LSTM decoder. The window size w and sliding window interval l are 36 and 10, respectively. 1 2 H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 273 Results and Analysis. Table 2 reports the precision, recall, and the F1-best scores of CAE-AD and other baseline models. We use bold font for the best F1 score and underline font for the second-best F1 score. As demonstrated in Table 2, the per- formance of CAE-AD outperforms all the baseline models. Speciﬁcally, the F1-best score of CAE-AD is 0.9376 on SMD data- sets, which is slightly higher than that of OmniAnomaly and far better than the other methods. For SMAP and MSL datasets, CAE-AD achieves the F1-best score of 0.9302 and 0.9119 respectively. The case studies of CAE-AD are shown in Fig. 4a and Fig. 4b, demonstrating that CAE-AD can correctly detect the abnormal points. The abnormal timesteps of SMD machine-1–1 datasets are relatively concentrated, while the abnormal timesteps of SMD machine-2–3 datasets are relatively scattered. CAE-AD achieves stable performance in the two subsets, which further validates the ability of CAE-AD to learn normal pat- terns of MTS data. IForest [24] randomly selects features and splits the values to separate abnormal points, but the temporal dependency of MTS data is not considered. Compared with SMAP and MSL datasets, the SMD datasets contain more extreme abnormal val- ues with sudden peaks or valleys, which are easy for iForest to isolate. So iForest presents a lower performance on SMAP and MSL datasets with the F1-best score of 0.5738 and 0.4762, respectively. EncDec-AD [26] is a seq2seq based model with LSTM encoder-decoder structure. This method models normal time series behaviour, and utilizes reconstruction errors to detect anomalies. LSTM encoder and decoder are employed to capture tem- poral features of time series, so EncDec-AD achieves a better performance than iForest. But this method can not characterize the dynamics of time series. LSTM-NDT [18] is a prediction-based model with one LSTM layer, which takes temporal information into consideration. For SMAP and MSL datasets, LSTM-NDT predicts the telemetry data for the next time step using the historical telemetry data for the ﬁrst channel and the one-hot encoded information for the other channels. The results show that LSTM-NDT achieves high F1-best scores of 0.9147 on SMAP datasets. However, due to the complex network states and high dimensional data on SMD dataset, LSTM-NDT fails to capture the normal pattern and performs poorly. OmniAnomaly [34] conducts a stochastic recurrent neural network to learn the robust representation of MTS data and achieves the second F1-best scores on SMD datasets. However, OmniAnomaly ignores the local invariant information, and the noise data can be given high anomalous scores that may be mistaken for abnormal points. CAE-AD introduces instance contrasting, which is helpful for latent variables to learn the local invariant property of MTS, and data augmentation methods Table 1 The properties of the datasets. Dataset Subset Dimension Train Test Anomalies(%) SMD 28 38 708405 708420 4.16 SMAP 55 25 135183 427617 13.13 MSL 27 55 58317 73729 10.72 Table 2 Experiment Results: the precision, recall and F1best scores of baselines and CAE-AD. The highest F1best score is bolded, and the second best result is underlined. SMD SMAP MSL Method Pre Rec F1best Pre Rec F1best Pre Rec F1best iForest [24] 0.5424 0.8957 0.6757 0.6481 0.5147 0.5738 0.5556 0.4167 0.4762 EncDec-AD [26] 0.9014 0.6764 0.7729 0.9814 0.7794 0.8688 0.931 0.75 0.8307 LSTM-NDT [18] 0.4726 0.7213 0.5711 0.8676 0.9672 0.9147 0.8056 0.9375 0.8656 OmniAnomaly [34] 0.9260 0.9149 0.9204 0.9502 0.5482 0.6953 0.9245 0.8502 0.8858 Transformer-AD [38] 0.8390 0.7242 0.7745 0.9076 0.8676 0.8872 0.9667 0.8056 0.8787 USAD [3] 0.7951 0.9418 0.8622 0.9032 0.8235 0.8615 0.8684 0.9167 0.8918 DROCC [14] 0.7469 0.7905 0.7681 0.4788 0.9881 0.6451 0.5944 0.9641 0.7354 RANSynCoders [1] 0.7536 0.8451 0.7967 0.9413 0.2116 0.3455 0.2862 0.9385 0.4386 GANF [8] 0.6408 0.8532 0.7319 0.6141 0.9869 0.7571 0.4720 0.9854 0.6383 CAE-AD 0.9265 0.9491 0.9376 0.8824 0.9836 0.9302 0.8611 0.9688 0.9119 Fig. 4. Case study of anomaly score on SMD machine-1–1 and SMD machine-2–3 datasets. The red region highlights the truth anomaly intervals. H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 274 in the time domain and frequency domain enhance the anti-noise capability of CAE-AD. Consequently, the OmniAnomaly method has a lower recall rate than our CAE-AD. Transformer-AD [38] utilizes multi-head attention to learn the dependent information among different timesteps. As demonstrated in Table 2, Transformer-AD achieves F1-best scores of 0.7745 and 0.8787 on SMD and MSL datasets respec- tively, which performs better than iForest and LSTM-NDT. The reason is that the attention mechanism calculates attention scores of the input sequence and can capture historical information of input data at each time stamp, while LSTM-based methods selectively retain historical information, which may miss certain useful information. Therefore, Transformer-AD has better overall performance than LTSM-based methods, such as LSTM-NDT. However, Transformer-AD does not consider the inherent nature of MTS, such as local time invariance, and it performs inferior to CAE-AD. USAD [3] conducts two autoencoders with one encoder and two decoders. In the training phase, USAD adversely trains two autoencoders, and aims to amplify the reconstruction errors of anomalies. With proper regularization, USAD is capable to utilize the advantages of autoencoder framework and achieves the second F1-best scores on MSL datasets. However, USAD framework may also amplify the noises in the inference phase. Consequently, USAD obtains inferior overall performances with respect to CAE-AD. DROCC [14] utilizes the gradient-ascent method to generate anomalous instances, which alleviates the representation collapse problem. However, the real-world data distribution is complex and the generated anomalies may not match the ground-truth anomalies. CAE-AD only focuses on modelling normal data patterns, so it is demonstrated that DROCC per- forms inferior to CAE-AD on all three datasets. RANSynCoders [1] learns the synchronous representation in MTS data, and applies bootstrapped autoencoders to learn the reconstructed lower bound and upper bound. Anomalies are identiﬁed by comparing the inputs and the decoded bounds. For SMAP and MSL datasets, the ﬁrst dimension is telemetry data, and the other dimensions are 0/1 switch data. These switch data contain a lot of zero elements and it is difﬁcult for the bootstrap aggregation based autoencoders to reconstruct them. Therefore, it shows that RANSynCoders performs poorly in SMAP and MSL datasets. GANF [8] uses a graph-based dependency encoder to learn correlate information in series dimension and applies condi- tional normalizing ﬂows to model the densities of MST. However, GANF ignores the intrinsic invariant characteristics and does not constrain the adjacency matrix of nodes. As demonstrated in Table 2, the performance of GANF is lower than CAE-AD. In summary, CAE-AD outperforms the baseline methods on the three public datasets. The autoencoder structure of CAE- AD helps to obtain the reconstructions of time series, which is the key design that can be easily adapted to different datasets for the anomaly detection task. Moreover, the multi-grained contrasting method helps the CAE-AD model to learn multi- granularity temporal-dependent information, which enables the model to accurately construct a normal proﬁle and makes abnormal data more discriminative. 4.5. Multi-grained Contrasting Analysis In order to demonstrate the effectiveness of the contextual contrasting and instance contrasting, we evaluate the perfor- mance of CAE-AD and the three variants, namely CAE-Inst-AD, CAE-Cont-AD and AE-AD. Among them, CAE-Inst-AD retains the instance contrastive loss, while removing the contextual contrastive loss. CAE-Cont-AD leaves the contextual contrastive loss while removing the instance contrastive loss. AE-AD is constructed using the LSTM autoencoder without any contrastive loss. With the comparative experiments, we learn the response of CAE-AD to the proposed contextual contrastive loss and instance contrastive loss. As shown in Fig. 5, CAE-AD achieves the best performance on the three datasets and AE-AD achieves the lowest overall performance. AE-AD models normal time series behaviour, and utilizes reconstruction errors to detect anomalies. However, without multi-grained contrasting methods, AE-AD can not comprehensively describe the multi-scale temporal information Fig. 5. F1-best of CAE-AD and the variants of CAE-Inst-AD, CAE-Cont-AD and AE-AD on SMD, SMAP and MSL datasets. H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 275 of data, so it fails to learn steady normal data patterns, which further indicates that proper regularization for autoencoder based model is necessary to improve the reconstruction abilities. CAE-Cont-AD obtains F1-best scores of 0.8942, 0.9206, and 0.8656 on SMD, SMAP, and MSL datasets respectively. CAE- Inst-AD has lower performance compared to CAE-Cont-AD. The reason is probably that contextual contrastive loss aims to maximize the similarity of the observations at neighbouring timesteps and minimize the similarity at distant timesteps. By considering timestep-level observations, contextual contrasting can learn ﬁne-grained contextual information of MTS data. However, instance contrastive loss maximizes the similarity of different views of the observations in the same window while minimizing the similarity of the observations in different windows within the minibatch. Considering window-level observations, instance contrasting can learn coarse-grained contextual information, which is also called local invariant char- acteristics of MTS data. Without contextual contrastive loss, CAE-Inst-AD may not perform well for reconstruction. Therefore, CAE-Cont-AD achieves higher F1-best scores than CAE-Inst-AD for SMD, SMAP, and MSL datasets. Meanwhile, without instance contrastive loss, CAE-Cont-AD fails to capture local invariant characteristics of MTS data, so it demonstrates inferior performance to CAE-AD. Compared with the three variants, CAE-AD conducts multi-grained con- trasting, so the latent variables can capture both temporal-dependent and local invariant characteristics, which validates that contextual contrasting and instance contrasting are complementary. Therefore, CAE-AD can extract the normal data pat- tern and demonstrate superior performance. To sum up, the autoencoder model trained with multiple well-designed contrastive losses outperforms the typical autoencoder, which proves that our multi-grained contrasting methods are key designs in CAE-AD. 4.6. Parameter Sensitivity In this subsection, we study the effects of different parameters on the performance of CAE-AD. The main parameters of our proposed method contain the window size w, sliding window interval l, dimension of latent variables z, and the dimen- sion of hidden states h in the encoder. All the experiments in this section are conducted on machine-1–6 of the SMD dataset. The ﬁrst case we study is how window size w affects the performance of CAE-AD. The larger the window size, the more information the model can obtain. We use different window sizes w ¼ ½10; 20; 30; 40; 100. As shown in Fig. 6(a), the best result is achieved for window size w ¼ 30. It is observed that a smaller window size tends to yield a lower F1-best score, Fig. 6. The sensitivity of different parameters on machine-1–6 dataset of SMD. F1-best, Precision and recall are demonstrated to evaluate the responses of CAE-AD to (a) different window sizes w, (b) different sliding window intervals l, (c) different dimensions of latent variables z, (d) different dimensions of hidden states h in the encoder. H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 276 since CAE-AD is not capable of describing the correlation of different timesteps when the input sequence contains less infor- mation. Historical reconstruction errors are used to calculate the anomaly score of the data at the last timestep in the win- dow. If a window is too large and may contain longer segments of anomalies, the normal data at the last timestep in the window will obtain a higher anomaly score and thus can be misjudged as an abnormal point. So, a larger window size demonstrates a lower F1-best score. For server machine datasets, a proper range from 20 to 40 can achieve better performance. The second factor we learn is how CAE-AD responds to different sliding window intervals l. During data preprocessing, a sliding window is used to obtain a sequence of observations, and the sliding window interval affects the size of repeated observations. Fig. 6(b) summaries the obtained results for different intervals l ¼ ½5; 10; 15; 20; 30. We observe that CAE- AD achieves the highest F1-best score when the interval reaches 10, and larger intervals lead to inferior performance. The reason may be that larger intervals contain less repeated observations, so CAE-AD may fail to capture the temporal depen- dency of continuous observations. Next, we explore the impacts of the dimension of latent variables z. Fig. 6(c) demonstrates the F1-best scores of different dimensions of latent variables z ¼ ½5; 10; 20; 30; 50. We can observe that the lower dimensions of latent variables obtain bet- ter performance. The reason may be that the encoder is capable of reducing the dimension of latent variables. A higher dimension of latent variables may contain more noises, so it is difﬁcult to learn the normal pattern in high dimension fea- tures, which indicates that we can choose the dimension of latent variables lower than the dimension of raw observations. Finally, we analyze the impact of the dimension of hidden states in the encoder. We explore different dimensions of hid- den states h ¼ ½10; 20; 40; 60; 100 in our experiments. As Fig. 6(d) shows, CAE-AD achieves a stable performance when hid- den dimension reaches 40. When the hidden dimensions in the shared-weights encoder are higher than 40, it is observed that hidden dimensions are sightly sensitive to the performance of CAE-AD. The reason is that the multi-grained contrasting plays an important role in capturing normal data patterns, and the parameters or the network of the encoder can have a wider range of choices. 4.7. Ablation Study In this section, we study the effect of each part of our model. Speciﬁcally, we repeat our experiments with/without key modules. As demonstrated in Table 3, our proposed model CAE-AD achieves the best performance on the SMD dataset. Directly removing the attention module and not using the contextual contrasting loss (CAE-AD_WO_ATTENTION_CONT), the F1 score drops by 22.77% compared to the Baseline. Further, we use a fully-connected neural network to replace the attention mechanism and retain the contextual contrastive loss (CAE-AD_WO_ATTENTION), and the performance is much improved compared to removing it directly, which proves that both the attention mechanism and contextual contrasting method work together to learn the temporal representation of data. Besides, we also remove the time-domain data augmentation marked as CAE-AD_WO_FREQAUG and the frequency- domain data augmentation marked as CAE-AD_WO_TIMEAUG in turn and only use the single data augmentation method to generate different views of MTS. The results show that the model does not perform well in this case, which validates that various data augmentation methods help comprehensively describe dynamic characteristics in MTS. Finally, we replace the well-designed LSTM decoder with a simple fully-connected network (CAE-AD_WO_DECODER). The results show that the performance drops sharply compared to the Baseline. This is because the latent vector z does not directly contain the infor- mation at all time steps, so the sequential decoding method is necessary for the decoder to explore the dependency charac- teristics of MTS. These ablation studies validate that each module in our model is useful and necessary. 4.8. Visualization of Latent Variables To further demonstrate the effectiveness of CAE-AD to learn the normal data pattern, we conduct an additional experi- ment for the visualization of latent variables. CAE-AD is a reconstruction-based model. For a window of MTS data, the siamese encoders compress raw data to a latent variable, and then the decoder reconstructs the data. Contrastive Autoencoder learns the normal data patterns training on the normal data. If an abnormal observation appears as an input to the contrastive autoencoder, our model will encode Table 3 Ablation study on SMD dataset. Model Pre Rec F1best CAE-AD 0.9265 0.9491 0.9376 CAE-AD_WO_ATTENTION_CONT 0.6550 0.7749 0.7099 CAE-AD_WO_ATTENTION 0.8172 0.8183 0.8177 CAE-AD_WO_FREQAUG 0.8678 0.6362 0.7342 CAE-AD_WO_TIMEAUG 0.6625 0.6879 0.6750 CAE-AD_WO_DECODER 0.4312 0.8182 0.5648 H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 277 the observation to normal latent variable z. In this case, the reconstruction largely deviates from the actual one, and then the abnormal observation is detected correctly. Speciﬁcally, we select the machine-1–1 subset of SMD datasets to obtain the latent variables, and employ t-Distributed t- SNE (Stochastic Neighbor Embedding) [37] to visualize the latent variables. As shown in Fig. 7(a), each point means a latent variable and the corresponding colour represents the timestep of the observation. Latent variables are close to each other in contextual data and far from each other among distant data, which indicates that contextual contrasting and instance con- trasting are important for learning multi-scale contextual information. We highlight the latent variables of abnormal obser- vations with the red colour, as shown in Fig. 7(b). The distribution of abnormal latent variables is similar to normal latent variables, indicating that CAE-AD can explicitly learn the representations of the normal data pattern. 5. Discussion In this paper, we novelly combine the contrastive loss and mean square error (MSE) loss to jointly train a well-designed contrastive antoencoder framework for anomaly detection task. Typical antoencoder only uses MSE loss to train the model for extracting detailed information of reconstructed data, but the MSE loss is sensitive to anomalies, which may lead to infe- rior performance in anomaly detection task. For example, if the training data contain very few anomaly points, then MSE loss will penalize the model to ﬁt these anomalies, which makes autoencoder model fail to construct a normal proﬁle. Contrastive learning methods are able to learn invariant information in the data, so the contrastive loss is not sensitive to noisy data. However, is it feasible to use only contrastive loss to learn normal data pattern?. To discuss this question, we simplify the contrastive loss in Eq. (5) as the following formula: Linst ¼ E X½log f enðxt; ztÞ X xj2X f enðxj; ztÞ ; ð10Þ Where numerator is the positive sample, and the denominator is the sum of one positive sample and all negative samples. In our case, f enðxt; ztÞ ¼ expðcosðzt; zþ t Þ=sÞ. The contrastive loss can be considered as categorical cross-entropy loss with prob- ability pðd ¼ tjX; ztÞ / f enðxt; ztÞ=P xj2Xf enðxj; ztÞ to correctly classify the positive sample, where the indicator d ¼ t means xt is a positive sample. As proven in previous literature [29], f enðxt; ztÞ / pðxtjztÞ=pðxtÞ, which means this function descripts the mutual informa- tion between xt and zt. However, in practice, adjacent or periodic time series segments xjðj – tÞ may also have strong corre- lations with zt and the mutual information between them will be large, resulting in a higher probability pðd ¼ jjX; ztÞ. Thus, xj will be misclassiﬁed as a positive sample. This problem can be avoided by using a MSE loss to encourage the model to learn details of reconstruction information. Consequently, only contrastive loss is insufﬁcient to learn the optimal normal pattern. We carefully combine the advantages of the contrastive loss and MSE loss and propose a well-designed contrastive autoencoder framework. In our proposed framework, the autoencoder is capable of capturing detailed information to recon- struct input time series and the contrastive loss can encourage the model to learn invariant information, which improves the model’s ability to deal with noisy data. As the experimental results shown, this combination is proved to be effective and necessary for improving anomaly detection performance. 6. Conclusion This paper proposes a novel contrastive autoencoder for anomaly detection in MTS data, namely CAE-AD. The CAE-AD framework ﬁrst generates two different views for each segment by applying data augmentation in both the time domain Fig. 7. Visualization of latent variables on machine-1–1 of SMD. Each point means a latent variable and the corresponding color represents the timestep. Specially, red points are latent variables of abnormal points. H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 278 and frequency domain. Then multi-grained contrasting methods are proposed to learn robust representation in multiple scales of MTS. Contextual contrasting learns temporal features by applying attention mechanism, and instance contrasting learns invariant features within two augmented views of the same sample. The multi-grained contrasting methods are able capture temporal-dependent and local invariant characteristics in MTS data. The experimental results show that CAE-AD outperforms the baseline models and each module in CAE-AD is effective. Furthermore, visualization of learned representa- tions demonstrates the capability of CAE-AD to model the normal data pattern. For future work, the dynamic threshold selection method will be explored, and more real-world data will be used for experiments to improve the robustness of CAE-AD. We will extend the CAE-AD model to multi-modal datasets and consider improved methods for the long-tail problem in various datasets. CRediT authorship contribution statement Hao Zhou: Conceptualization, Methodology, Software, Investigation, Visualization, Formal analysis, Writing - original draft. Ke Yu: Conceptualization, Funding acquisition, Resources, Supervision, Writing - review & editing. Xuan Zhang: Fund- ing acquisition, Supervision, Writing - review & editing. Guanlin Wu: Data curation, Investigation, Validation. Anis Yazidi: Investigation, Supervision, Writing - review & editing. Data availability Data will be made available on request. Declaration of Competing Interest The authors declare that they have no known competing ﬁnancial interests or personal relationships that could have appeared to inﬂuence the work reported in this paper. Acknowledgements This work is partially supported by: the National Natural Science Foundation of China under the Grant No. 61601046 and 61171098; the 111 Project of China under the Grant No. B08004; and the project Spacetime Vision: Towards Unsupervised Learning in the 4D World ﬁnanced by the EEA and Norway Grants 2014–2021 under the Grant No. EEA-RO-NO-2018–04. This work is also supported by BUPT Excellent Ph.D. Students Foundation under the Grant No. CX2022149. References [1] Ahmed Abdulaal, Zhuanghua Liu, Tomer Lancewicki, Practical approach to asynchronous multivariate time series anomaly detection and localization, in: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, 2021, pp. 2485–2494. [2] Junfeng An, Haoyang Luo, Zheng Zhang, Lei Zhu, Lu. Guangming, Cognitive multi-modal consistent hashing with ﬂexible semantic transformation, Information Processing & Management 59 (1) (2022) 102743. [3] Julien Audibert, Pietro Michiardi, Frédéric Guyard, Sébastien Marti, Maria A Zuluaga, Usad: Unsupervised anomaly detection on multivariate time series, in: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 2020, pp. 3395–3404. [4] Sabyasachi Basu, Martin Meckesheimer, Automatic outlier detection for time series: An application to sensor data, Knowledge and Information Systems 11 (2) (2007) 137–154. [5] Wanpracha Art Chaovalitwongse, Ya.-Ju. Fan, Rajesh C Sachdeo, On the time series k-nearest neighbor classiﬁcation of abnormal brain activity, IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans 37 (6) (2007) 1005–1016. [6] Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton, A simple framework for contrastive learning of visual representations, in: International Conference on Machine Learning, PMLR, 2020, pp. 1597–1607. [7] Zekai Chen, Dingshuo Chen, Xiao Zhang, Zixuan Yuan, Xiuzhen Cheng, Learning graph structures with transformer for multivariate time series anomaly detection in iot, IEEE Internet of Things Journal (2021). [8] Enyan Dai, Jie Chen, Graph-augmented normalizing ﬂows for anomaly detection of multiple time series, in: International Conference on Learning Representations, 2022, pp. 1–16. [9] Liang Dai, Tao Lin, Chang Liu, Bo Jiang, Yanwei Liu, Zhen Xu, and Zhi-Li Zhang. Sdfvae: Static and dynamic factorized vae for anomaly detection of multivariate cdn kpis. In Proceedings of the Web Conference 2021, pages 3076–3086, 2021. [10] Terrance DeVries and Graham W Taylor. Dataset augmentation in feature space. arXiv:1702.05538, 2017. [11] Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, Chee Keong Kwoh, Xiaoli Li, and Cuntai Guan. Time-series representation learning via temporal and contextual contrasting. arXiv:2106.14112, 2021. [12] Sarah M Erfani, Sutharshan Rajasegarar, Shanika Karunasekera, Christopher Leckie, High-dimensional and large-scale anomaly detection using a linear one-class svm with deep learning, Pattern Recognition 58 (2016) 121–134. [13] Hongchao Fang, Sicheng Wang, Meng Zhou, Jiayuan Ding, and Pengtao Xie. Cert: Contrastive self-supervised learning for language understanding. arXiv preprint arXiv:2005.12766, 2020. [14] Sachin Goyal, Aditi Raghunathan, Moksh Jain, Harsha Vardhan Simhadri, and Prateek Jain. Drocc: Deep robust one-class classiﬁcation. In International Conference on Machine Learning, pages 3711–3721. PMLR, 2020. [15] Lansheng Han, Man Zhou, Wenjing Jia, Zakaria Dalil, Xu. Xingbo, Intrusion detection model of wireless sensor networks based on game theory and an autoregressive model, Information sciences 476 (2019) 491–504. [16] Kaiming He, Haoqi Fan, Wu. Yuxin, Saining Xie, Ross Girshick, Momentum contrast for unsupervised visual representation learning, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 9729–9738. [17] David J Hill, Barbara S Minsker, Anomaly detection in streaming environmental sensor data: A data-driven modeling approach, Environmental Modelling & Software 25 (9) (2010) 1014–1022. H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 279 [18] Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, Tom Soderstrom, Detecting spacecraft anomalies using lstms and nonparametric dynamic thresholding, in: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 2018, pp. 387–395. [19] Eamonn Keogh, Jessica Lin, Fu. Ada, Hot sax: Efﬁciently ﬁnding the most unusual time series subsequence, in: Fifth IEEE International Conference on Data Mining (ICDM), IEEE, 2005, p. 8. [20] Istvan Kiss, Béla Genge, Piroska Haller, Gheorghe Sebestyén, Data clustering-based anomaly detection in industrial control systems, in: 2014 IEEE 10th International Conference on Intelligent Computer Communication and Processing (ICCP), IEEE, 2014, pp. 275–281. [21] Hans-Peter Kriegel, Matthias Schubert, Arthur Zimek, Angle-based outlier detection in high-dimensional data, in: Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2008, pp. 444–452. [22] Dan Li, Dacheng Chen, Baihong Jin, Lei Shi, Jonathan Goh, and See-Kiong Ng. Mad-gan: Multivariate anomaly detection for time series data with generative adversarial networks. In International Conference on Artiﬁcial Neural Networks, pages 703–716. Springer, 2019. [23] Dapeng Liu, Youjian Zhao, Haowen Xu, Yongqian Sun, Dan Pei, Jiao Luo, Xiaowei Jing, and Mei Feng. Opprentice: Towards practical and automatic anomaly detection through machine learning. In Proceedings of the 2015 Internet Measurement Conference, pages 211–224, 2015. [24] Fei Tony Liu, Kai Ming Ting, Zhi-Hua Zhou, Isolation forest, in: Eighth IEEE International Conference on Data Mining (ICDM), IEEE, 2008, pp. 413–422. [25] Xuanqing Liu, Yu. Hsiang-Fu, Inderjit Dhillon, Cho-Jui Hsieh, Learning to encode position for transformer with continuous dynamical model, in: International Conference on Machine Learning, PMLR, 2020, pp. 6327–6335. [26] Pankaj Malhotra, Anusha Ramakrishnan, Gaurangi Anand, Lovekesh Vig, Puneet Agarwal, and Gautam Shroff. Lstm-based encoder-decoder for multi- sensor anomaly detection. arXiv:1607.00148, 2016. [27] Xuying Meng, Suhang Wang, Zhimin Liang, Di Yao, Jihua Zhou, Yujun Zhang, Semi-supervised anomaly detection in dynamic communication networks, Information Sciences 571 (2021) 527–542. [28] Mohsin Munir, Shoaib Ahmed Siddiqui, Andreas Dengel, Sheraz Ahmed, Deepant: A deep learning approach for unsupervised anomaly detection in time series, IEEE Access 7 (2018) 1991–2005. [29] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predictive coding. arXiv:1807.03748, 2018. [30] Daehyung Park, Yuuna Hoshi, Charles C Kemp, A multimodal anomaly detector for robot-assisted feeding using an lstm-based variational autoencoder, IEEE Robotics and Automation Letters 3 (3) (2018) 1544–1551. [31] Daehyung Park, Hokeun Kim, Yuuna Hoshi, Zackory Erickson, Ariel Kapusta, Charles C Kemp, A multimodal execution monitor with anomaly classiﬁcation for robot-assisted feeding, in: 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), IEEE, 2017, pp. 5406– 5413. [32] Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani. Self-attention with relative position representations. arXiv:1803.02155, 2018. [33] Taeshik Shon, Jongsub Moon, A hybrid machine learning approach to network anomaly detection, Information Sciences 177 (18) (2007) 3799–3821. [34] Su. Ya, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, Dan Pei, Robust anomaly detection for multivariate time series through stochastic recurrent neural network, in: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 2019, pp. 2828–2837. [35] Shreshth Tuli, Giuliano Casale, and Nicholas R Jennings. Tranad: Deep transformer networks for anomaly detection in multivariate time series data. arXiv preprint arXiv:2201.07284, 2022. [36] Mehmet Turkoz, Sangahn Kim, Youngdoo Son, Myong K Jeong, Elsayed A Elsayed, Generalized support vector data description for anomaly detection, Pattern Recognition 100 (2020) 107119. [37] Laurens Van Der Maaten, Accelerating t-sne using tree-based algorithms, The Journal of Machine Learning Research 15 (1) (2014) 3221–3245. [38] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, pages 5998–6008, 2017. [39] Xu. Jiehui, Wu. Haixu, Jianmin Wang, Mingsheng Long, Anomaly transformer: Time series anomaly detection with association discrepancy, in: International Conference on Learning Representations, 2022. [40] Zhihan Yue, Yujing Wang, Juanyong Duan, Tianmeng Yang, Congrui Huang, Yunhai Tong, and Bixiong Xu. Ts2vec: Towards universal representation of time series. arXiv:2106.10466, 2021. [41] Yang Zhang, Nicholas A.S. Hamm, Nirvana Meratnia, Alfred Stein, M. Van De Voort, Paul J.M. Havinga, Statistics-based outlier detection for wireless sensor networks, International Journal of Geographical Information Science 26 (8) (2012) 1373–1392. [42] Zheng Zhang, Haoyang Luo, Lei Zhu, Guangming Lu, and Heng Tao Shen. Modality-invariant asymmetric networks for cross-modal hashing. IEEE Transactions on Knowledge and Data Engineering, 2022. H. Zhou, K. Yu, X. Zhang et al. Information Sciences 610 (2022) 266–280 280"
Detection of abnormality in wireless capsule endoscopy images using fractal features,Samir Jain and Ayan Seal and Aparajita Ojha and Ondrej Krejcar and Jan Bureš and Ilja Tachecí and Anis Yazidi,2020,,127,Computers in Biology and Medicine,article,"Computers in Biology and Medicine 127 (2020) 104094
Available online 27 October 2020
0010-4825/© 2020 Elsevier Ltd. All rights reserved.
Detection of abnormality in wireless capsule endoscopy images using 
fractal features 
Samir Jain a, Ayan Seal a,b,*, Aparajita Ojha a, Ondrej Krejcar b,c, Jan Bureˇs d, Ilja Tachecí d, 
Anis Yazidi e 
a PDPM Indian Institute of Information Technology Design and Manufacturing, Jabalpur, 482005, India 
b Center for Basic and Applied Research, Faculty of Informatics and Management, University of Hradec Kralove, Hradecka, 1249, Hradec Kralove, 50003, Czech 
Republic 
c Malaysia Japan International Institute of Technology, Universiti Teknologi Malaysia, Jalan Sultan Yahya Petra, 54100, Kuala Lumpur, Malaysia 
d Second Department of Internal Medicine-Gastroenterology, Charles University, Faculty of Medicine in Hradec Kralove, University Hospital Hradec Kralove, Sokolska 
581, Hradec Kralove, 50005, Czech Republic 
e Artificial Intelligence Lab, Oslo Metropolitan University, 460167, Norway   
A R T I C L E  I N F O   
Keywords: 
Wireless capsule endoscopy 
Anomaly detection 
Fractal dimensions 
Differential box-counting 
A B S T R A C T   
One of the most recent non-invasive technologies to examine the gastrointestinal tract is wireless capsule 
endoscopy (WCE). As there are thousands of endoscopic images in an 8–15 h long video, an evaluator has to pay 
constant attention for a relatively long time (60–120 min). Therefore the possibility of the presence of patho­
logical findings in a few images (displayed for evaluation for a few seconds only) brings a significant risk of 
missing the pathology with all negative consequences for the patient. Hence, manually reviewing a video to 
identify abnormal images is not only a tedious and time consuming task that overwhelms human attention but 
also is error prone. In this paper, a method is proposed for the automatic detection of abnormal WCE images. The 
differential box counting method is used for the extraction of fractal dimension (FD) of WCE images and the 
random forest based ensemble classifier is used for the identification of abnormal frames. The FD is a well-known 
technique for extraction of features related to texture, smoothness, and roughness. In this paper, FDs are 
extracted from pixel-blocks of WCE images and are fed to the classifier for identification of images with ab­
normalities. To determine a suitable pixel block size for FD feature extraction, various sizes of blocks are 
considered and are fed into six frequently used classifiers separately, and the block size of 7 × 7 giving the best 
performance is empirically determined. Further, the selection of the random forest ensemble classifier is also 
done using the same empirical study. Performance of the proposed method is evaluated on two datasets con­
taining WCE frames. Results demonstrate that the proposed method outperforms some of the state-of-the-art 
methods with AUC of 85% and 99% on Dataset-I and Dataset-II respectively.   
1. Introduction 
Nowadays, wireless capsule endoscopy (WCE) based gastrointestinal 
endoscopy (GIE) is preferred by medical practitioners or endoscopists to 
examine some parts of the gastrointestinal tract due to non-invasive 
nature compared to conventional endoscopy procedures such as 
gastroscopy and colonoscopy with associated discomfort observed in 
patients [1–4]. WCE has become the standard diagnostic method in the 
field of small intestinal diseases. 
Generally, a capsule of size 10 × 25 mm equipped with a tiny optical 
camera, LED light source, signal transmitter, and the battery is 
swallowed by a patient that travels through the esophagus, stomach, 
small intestine, and large bowel. However, the size of a capsule may vary 
from manufacturer to manufacturer. The tiny camera placed inside the 
capsule captures data in the form of a video which is sent to a sensing 
device tied over the waist of the patient. Generally, the camera records 
videos at a rate of 2–6 frames per second, in a typical WCE video that can 
be of 8–15 h long. A WCE video may consist of more than 50, 000 frames 
in general [5] which makes it a tedious task to carefully watch the whole 
video and search for abnormalities. Computer-aided diagnosis (CAD) 
tools can assist medical practitioners to identify abnormal image(s) by 
exploiting computer vision algorithms with high precision. Due to 
* Corresponding author. PDPM Indian Institute of Information Technology Design and Manufacturing, Jabalpur, 482005, India. 
E-mail address: ayan@iiitdmj.ac.in (A. Seal).  
Contents lists available at ScienceDirect 
Computers in Biology and Medicine 
journal homepage: http://www.elsevier.com/locate/compbiomed 
https://doi.org/10.1016/j.compbiomed.2020.104094 
Received 5 July 2020; Received in revised form 23 October 2020; Accepted 23 October 2020   
 Computers in Biology and Medicine 127 (2020) 104094
2
significant growth of artificial intelligence based vision techniques, their 
applications in bio-medical imaging, and especially in WCE video pro­
cessing have also been explored by many researchers (see for e.g. 
Ref. [6–13]). In WCE images, complexity and diversity of texture and 
color information in different types of pathologies pose challenges in 
designing a fully automatic CAD diagnostic system with high reliability. 
Nonetheless, semi-automatic CAD systems help significantly reduce the 
time to analyze a video by a professional evaluator in-order to eliminate 
normal frames. The task of an evaluator is then primarily the second 
reading of findings marked as abnormal (pathological) by the CAD 
system and elimination of false-positive frames. Various approaches 
have been presented over the years for specific types of abnormality 
detection such as bleeding [9,14], ulcers [12,15], and polyps [10,16]. 
These methods range from image processing, to machine learning and 
more recent methods based on deep learning architectures [7,8,10–12, 
17–20]. Some recent approaches focus on covering a broad range of 
abnormalities instead of only specific type of abnormalities, which are 
more useful for devising automatic CAD diagnostic tools for investiga­
tion of WCE frames [10,20]. In this work, a CAD tool is designed and 
developed to identify abnormal image(s) in WCE videos that cover a 
broad range of abnormalities. A random forest (RF) ensemble-based 
classifier is trained to identify abnormal images using the fractal 
dimension (FD) of the image pixel blocks. Main contributions of the 
present work are as follows:  
• Differential Box Counting (DBC) based FD method is employed to 
quantify the textures of 24-bit color RGB images of WCE videos, as 
the anomalies exhibit different textural properties. This improves the 
efficiency of the CAD tool in detecting anomalies.  
• In addition to RGB channels, the L component of the CIE-Lab color 
space model of images is utilized for enriching the textural infor­
mation as it closely matches the human perception of lightness [21].  
• To compensate for class imbalance in the WCE datasets which are 
generally highly imbalanced and small, synthetic minority over­
sampling technique (SMOTE) [22] is applied on the feature set.  
• Selection of the RF ensemble classifier is made through an empirical 
study on six most frequently used classifiers in the literature, namely 
k-nearest neighbor (KNN), support vector machine (SVM), extreme 
learning machine (ELM), naive bayes (NB), decision tree (DT), and 
RF. The CAD tool using the DBC based FD and RF classifier out­
performs some of the state-of-the-art methods as illustrated in section 
4.4. 
The rest of the work is organized into five sections. Section 2 presents 
a brief overview of existing methods. The proposed methodology with 
its background is described in Section 3. Section 4 is devoted to exper­
imental analysis and performance evaluation of the proposed approach. 
In this section, a comparison with existing approaches is also presented. 
Section 5 presents the concluding remarks and future scope of the pro­
posed work. 
2. Related work 
Detection of abnormalities in WCE images using computer vision 
techniques is not a new area of research; it started ever since the WCE 
systems were introduced for healthcare in 2001. Growth of WCE market 
led to the development of sophisticated computer vision techniques for 
detection of abnormal frames using image processing and machine 
learning techniques. Over the last two decades, numerous techniques 
have been presented by researchers using different machine learning 
algorithms and feature extraction methods [23]. 
It is well known that feature extraction plays a crucial role in ma­
chine learning algorithms and finding a suitable feature extraction 
method for a particular problem is always a challenge. Early studies on 
WCE image analysis were focused on detection of bleeding abnormality 
[6,7,24,25]. Recent trend shows a paradigm shift towards design of CAD 
systems that cover a broad range of abnormalities like vascular, ulcers, 
polyps, instead of a single or similar type of abnormalities. A brief 
overview of some of the existing methods is presented in Table 1, where 
we give details about the problem, feature extraction methods, classi­
fiers, and the performance of the methods on different metrics. It may be 
noticed that SVM, ANN, and, KNN have been the popular choices of 
classifiers for abnormal frame detection. Various feature extraction 
methods like speed-up robust feature (SURF) [15], color and word his­
tograms [24–27], local binary pattern (LBP) [6], Log-Gabor wavelet 
transform [28], and, gray level co-occurrence matrix (GLCM) [12] have 
been used for WCE image analysis. 
In the WCE images, color information plays a crucial role in identi­
fication of abnormality. For example, when bleeding images are to be 
identified, the Red channel in RGB space is more important over other 
channels. Al-Rahayfeh et al. [18] suggested range-ratio-color condition 
for classifying bleeding frames. They identified that bleeding regions 
contain pixels with higher red channel values and lower values of green 
and blue channels. Therefore, a range of pixel values in each channel 
was considered for the identification of bleeding locations with 98% 
accuracy. Similar to the range-ratio-color method, Kundu et al. [8] 
fetched region of interest (ROI) on normalized RGB planes for bleeding 
frame classification. Pixels were selected based on a linear separability 
condition between red, blue, and green planes. The histogram was then 
computed on extracted ROI and the bleeding frames were identified 
with 98.3% accuracy using KNN classifier. The images were extracted 
from videos provided by Medtronic [29]. 
Often the presence of noise in WCE images adversely affects accuracy 
of the system, based on individual pixel features which get distorted due 
to noise. To overcome this problem, Liu et al. [24] considered 
block-based color histogram features and used SVM classifier for the 
identification of abnormal images. Specificity and sensitivity were re­
ported to be 99% in Ref. [24]. Lv et al. [25] combined color and spatial 
information for extracting features using a pyramid of color invariant 
histograms over the HSI color space. They employed the whole image 
and its extracted features to identify bleeding images with an accuracy 
of 97.9% on dataset of videos [29]. The capability of method being 
invariant to light intensity was made possible with the help of hue 
channel of HSI color space. Ghosh et al. [14] have introduced the 
concept of color histogram of block statistics (CHOBS) that computes 
statistical features over blocks of pixels for creating histograms to 
identify bleeding images with an accuracy of 99.2% on the publicly 
available WCE video dataset provided by Medtronic [29]. 
Sainju et al. [26], extracted statistical features like mean, standard 
deviation, skew, and energy from each channel of the RGB color space of 
pixel intensities. Bleeding images were classified by calculating the 
first-order histogram yielding a classification accuracy of 89%. Yuan 
et al. [9] contemplated the idea of a word-based color histogram by 
applying k-means clustering on pixels of normal and abnormal images. 
Clusters were created using YCbCr color space representation of images. 
Individual pixels were then mapped to different clusters according to 
their distance with a cluster. The classification accuracy of 95.8% was 
reported by authors in Ref. [9] with 80 clusters. As this method involved 
clustering, the performance varied with cluster size in a convex fashion 
where optimal cluster size was determined and tuned. 
Histograms based on concrete color plane pixel values were common 
in all the aforementioned methods. Since different color models have 
their own advantages, WCE images have also been experimented by 
researchers using CMYK, HSI, YCbCr, and, CIE-Lab color space models 
([9,15,17,25]). Iakovidis et al. [15], have employed image trans­
formation to CIE-Lab color space and applied SURF on color channels to 
select the salient points. The minimum and the maximum values of each 
color component are calculated over a square neighborhood of salient 
pixels for extraction of features. An average value of 89.2% of the Area 
under Curve (AUC) was reported in Ref. [15] with a minimum AUC of 
69.9% in case of angiectasias on KID Dataset 1 [30]. A customized color 
model close to the CMYK color model was devised by Novozamsky et al. 
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 127 (2020) 104094
3
[17] in which, both color and spatial properties were adopted for the 
identification of bleeding images. They have achieved a true positive 
percentage of 98% in classifying bleeding images on a private dataset. 
For the identification of anomalies like ulcers, polyps, villous 
oedema, aphthae etc., textural features are quite useful, since some kind 
of abnormalities can only be identified using their texture. Color features 
of such abnormal regions in an image are quite like those of normal 
regions in some of the abnormalities. In view of this many researchers 
have considered a combination of color and textural features for WCE 
image and video analysis. Meng et al. [6] have dealt with the problem of 
differentiating normal images from bleeding images by exploiting LBP 
as the textural feature extractor. These LBP features alongwith with the 
chrominance moments extracted from the HSI color plane were used to 
classify abnormal WCE images. Classification performance was evalu­
ated with zeroth, first, and second-order chrominance moments and the 
authors have reported that the zero-order chrominance moment pro­
vided the highest accuracy of 92.4% on a private WCE dataset provided 
by Prince of Wales Hospital, Hong Kong. Karkanis et al. [7] employed 
the wavelet transformation of second-order statistics on each WCE 
image for the extraction of texture features to detect polyps where 
97.2% accuracy was yielded. When the WCE capsule travels through the 
digestive tract, there is a possibility of lower luminance which affects the 
quality of the WCE image. This problem was addressed by Chen et al. in 
Ref. [28], where the Log-Gabor wavelet transform was applied to rectify 
the problem of non-uniform luminance. In addition to the Log-Gabor 
Table 1 
A brief overview of state-of-the-art methods for detecting abnormality in WCE 
images.  
Authors 
Purpose 
Feature 
Extraction 
Method 
ML 
classifier 
Classification 
Results 
Karkanis et al. 
[7], 2001 
Lesion 
detection 
Statistical 
information of 
second order 
discrete wavelet 
transform 
ANN 
Accuracy: 
95.50% 
Liu et al. [34], 
2008 
Bleeding 
detection 
Raw color pixel 
values 
SVM 
Sensitivity: 
99.64%, 
Specificity: 
99.58% 
Li et al. [6], 
2009 
Bleeding 
detection 
Chrominance 
moment and 
LBP is computed 
in HSI color 
space 
ANN 
Accuracy: 
92.40%, 
Sensitivity: 
93.20%, 
Specificity: 
91.60% 
Al-Ryalfeh 
et al. [18], 
2010 
Bleeding 
detection 
Range of color 
pixel values and 
ratio of them 
Pixel count 
as 
threshold 
Accuracy: 
98.00% 
Lv at al. [25], 
2011 
Bleeding 
detection 
Pyramid of color 
invariant 
histogram 
SVM 
Accuracy: 
97.90%, 
Sensitivity: 
97.80%, 
Specificity: 
98.00% 
Sainju et al. 
[26], 2013 
Bleeding 
detection 
Histogram 
Probability 
ANN 
Accuracy: 
89.00% 
Iakovidis 
et al. [15], 
2014 
Lesion 
detection 
WCE images are 
converted into 
CIE-Lab color 
space and 
salient points 
are extracted 
using speedup 
robust features 
(SURF) method 
SVM 
Accuracy: 
94.50%, 
Sensitivity: 
96.00%, 
Specificity: 
84.60% 
Yuan et al. 
[9], 2015 
Bleeding 
detection 
Histogram on 
bag-of-visual- 
words using K- 
size color 
clusters 
KNN 
Accuracy: 
95.75%, 
Sensitivity: 
92.00%, 
Specificity: 
96.50% 
Novozamsky 
et al. [17], 
2016 
Bleeding 
detection 
Threshold set on 
pixel values 
based on new 
color model 
close to CMYK 
color model in 
which red color 
is enhanced 
Threshold 
on pixel 
count 
TP:96.41%, 
FP:21.81% 
Jia et al. [31], 
2017 
Bleeding 
detection 
CNN combined 
with 
handcrafted 
(HC) features in 
which histogram 
is computed 
over the count of 
pixels in each 
centroid when 
the image pixels 
are clustered 
using K-means 
clustering 
algorithm 
Softmax 
Recall: 91.00%, 
Precision: 
94.79%, F1- 
score: 92.85% 
Chen et al. 
[28], 2017 
Bleeding 
detection 
Log-gabor filter 
bank, histogram 
and color 
features 
SVM 
Accuracy: 
98.97%, 
Sensitivity: 
94.07%, 
Specificity: 
99.15% 
Yuan et al. 
[16], 2017 
Polyp 
detection 
Sparse 
autoencoder 
Softmax 
Accuracy: 
98.17%  
Table 1 (continued) 
Authors 
Purpose 
Feature 
Extraction 
Method 
ML 
classifier 
Classification 
Results 
with hybrid loss 
function 
employing KL 
divergence with 
an image 
manifold 
constraint. 
Kundu et al. 
[8], 2018 
Bleeding 
detection 
Histogram 
computed over 
normalized 
green planes 
KNN 
Accuracy: 
97.86%, 
Sensitivity: 
95.20%, 
Specificity: 
98.32% 
Iakovidis 
et al. [10], 
2018 
Anomaly 
detection 
5-layer CNN, 
Activation Maps 
CNN 
Accuracy: 
89.90%, 
Sensitivity: 
90.70%, 
Specificity: 
88.20% 
Sadasivan 
et al. [13], 
2019 
Anomaly 
detection 
A CNN trained 
on normal and 
abnormal 
patches of size 
64 × 64 
obtained from 
WCE images of 
size 320 × 320  
CNN 
AUC: 95.36% 
Xiao et al. 
[11], 2020 
Lesion 
detection 
CNN based 
object detection 
using YOLOv3 
network. 
Softmax 
(CNN) 
Mean Average 
Precision 
(mAP): 93.50% 
Khan et al. 
[12], 2020 
Ulcer and 
bleeding 
detection 
CNN with 
transfer learning 
on VGG-16 and 
GLCM which are 
fused and 
relevant features 
are selected by 
applying 
particle swarm 
optimization 
technique. 
Cubic SVM 
Accuracy: 
98.40%, 
Sensitivity: 
98.33%, 
Precision: 
98.36%, F1- 
score: 98.34%, 
AUC: 100%  
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 127 (2020) 104094
4
filter, gray-level histogram and color features were combined for the 
detection of bleeding as an abnormality which reached to classification 
accuracy of 98.97% where the WCE dataset was provided by Ankon 
Incorporation, Wuhan, China. Devising algorithms to extract features 
need thorough knowledge about the behavior of abnormalities which 
sometimes becomes difficult if some of the observations are missed. It 
can be reduced if an algorithm is capable of extracting the features 
automatically. 
In the last decade deep learning has become very popular due to its 
outstanding performance in some of the most challenging computer 
vision tasks. Deep learning is a kind of representation learning in which 
data features are extracted automatically. Due to huge success of deep 
learning in other domains, it has attracted the attention of people 
working on WCE image and video analysis too. Convolutional neural 
networks (CNNs), which are the basic building blocks of deep learning 
algorithms, have been proposed by many researchers for accurate clas­
sification of WCE images (see, e.g. Refs. [19,20,31], and references 
therein). However, the current deep learning algorithms face challenge 
if the datasets are small and imbalance, which is the case with WCE 
image datasets. As a result, CNNs often get trapped in overfitting, and do 
not generalize well [32,33]. Nonetheless, deep learning architectures 
are being explored in the WCE image and video analytics and some 
promising results have been reported recently [10,11,13]. 
The related work discussed above manifest the importance of color 
and texture features for WCE image analysis in the block based 
approach. The present work, focuses on efficient feature extraction using 
the concept of DBC based FD on blocks of WCE images, computed over 
the individual color channel, exploiting both color and textural (FD) 
information. The problem of highly imbalanced small dataset is also 
addressed by applying the well known SMOTE method for data 
augmentation. It is worthwhile to mention that the proposed method 
covers a broad range of abnormalities in WCE images and can classify 
abnormal images with high accuracy and, AUC. 
In the next section, the proposed method is discussed in detail. 
3. Methodology 
In this section, a method is proposed for abnormality detection in 
WCE images using FD and RF algorithm. The choice of machine learning 
classification algorithm is based on an empirical study with six different 
ML algorithms on two different datasets, one of which is a publicly 
available dataset, namely KID dataset [30] and the other being private 
dataset [17]. Each algorithm uses the FD of image pixel blocks and the 
best performing method is chosen for abnormality detection in WCE 
images. To begin our discussion on the methodology of the proposed 
work, we first give a brief introduction to the concept of FD in the 
context of images. 
3.1. Fractal dimension 
FD has been an active research topic over the past decades owing to 
its noticeable applications such as texture segmentation [35], 
bio-metrics [36,37], cancer diagnosis [38], pattern recognition [39], 
MRI image analysis [40], image fusion [21,41] and others [42]. FD 
measures the self-similar contents of an image [43]. One may notice that 
abnormalities in WCE images are complex objects with varying shapes, 
sizes, color, and textures. Moreover, anomalies are highly irregular 
natural shapes which can be correlated with fractal features (see Fig. 4). 
There exist many methods in the literature to measure the FD of images. 
The DBC method is one of the most frequently deployed methods due to 
its simplicity and computational efficiency [44]. 
The DBC method was introduced by Sarkar et al. [44] to estimate the 
FD of a gray-scale image. According to the DBC method, FD Fd(K) of a 
fractal set K is defined in an n-dimensional Euclidean space by Eq. (1). 
Fd(K) = log(Bs)
log(1/s),
(1)  
such that s ∕= 1 and Bs is the number of boxes at scale s required to cover 
the fractal set K. An image I of size N × N is mapped into three- 
dimensional space as shown in Fig. 1, where x −
coordinate and y −
coordinate are used to denote the dimensions of I while z −
coordinate 
represents the gray-level intensity of I. The image plane is divided into 
non-overlapping grids of size g × g pixels. Here, g is an integer and it 
varies from 2 to N/2. If g is not divisible by N then zeros are padded in 
the boundary of I. A grid s will have a scale of value g/N. Let bs be the 
number of boxes of size g × g × h each representing gray-level variations 
of a particular grid, where h is the height which can be calculated using 
Eq. (2).where Q is the total number of gray-levels. Let qmax and qmin be 
the maximum and the minimum intensity values of the (i, j)th grid 
respectively. The number of boxes bs(i, j) required to cover the (i, j)th 
grid can be computed using Eq. (3). 
bs(i, j) =
⌈qmax
h
⌉
−
⌈qmin
h
⌉
+ 1,
(3)  
where 
⌈
qmax
h
⌉
and
⌈
qmin
h
⌉
denote the box numbers containing the maximum 
and minimum gray-levels on the (i, j)th grid respectively. Therefore, the 
total count of boxes termed as Bs at scale s can be calculated using Eq. 
(4). 
Bs(i, j) =
∑
i,j
bs(i, j),
(4)  
where Bs represents the surface roughness in image I. Now, FD of I is the 
slope of the line obtained by fitting the points 
(
log
(
1
s
)
, log(Bs)
)
∀s using 
linear least squares regression (LLS). Since the value of FD is a scalar 
quantity, it may not be sufficient to use as a feature for a classification 
problem. In the present paper, an image is divided into square pixel 
Fig. 1. A sketch showing corresponding a grid with computable parameters to 
find the number of boxes using DBC method. 
h = gQ
N ,
(2)    
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 127 (2020) 104094
5
blocks of equal size and instead of considering the value of FD as a 
feature, the number of boxes bs of each block s in an image I are used as 
features for the identification of abnormal images. Several methods [35, 
43,45–51] exist in literature to estimate FD of an image and each has its 
own merits and limitations. A brief overview of some of these methods is 
reported in Table 2. For more details on DBC based FD estimation 
methods, interested readers are referred to Ref. [42]. 
3.2. Proposed method 
A schematic block diagram of the proposed CAD system is shown in 
Fig. 2. As shown in the figure, the proposed method consists of two steps: 
feature extraction and classification. Class balancing is performed on the 
dataset containing extracted features after the first step. In the first step, 
R, G, B, and L channels are extracted from WCE images. The L channel is 
obtained by converting the RGB color image into its CIE-Lab color space 
representation [52]. Then a DBC method is applied on the blocks 
extracted from each channel to extricate features. To select a suitable 
DBC based FD estimation method for WCE images, eight different DBC 
based FD methods listed in Table 2 are initially chosen and their per­
formances are compared on two WCE image datasets used in the present 
work. The best performing DBC method given in Ref. [43] is selected for 
FD feature computation in the present study (see Tables 3–6). In color 
theory, the lightness component also known as a tone represents the 
brightness of color in an image. It is used as one of the color appearance 
parameters. In relation to GI anomalies, the lightness component plays 
an important role since some anomalies are very close to normal regions 
in the case when color is used as a discriminator. For example, light red 
color in the intestinal walls may represent normal regions whereas dark 
red gives a clue of a bleeding spot. Since RGB models do not have an 
explicit lightness component where color integrants are dissociated from 
luminance components and they struggle to give information related to 
luminosity [21]. The L channel in CIE-Lab color space is employed to 
extract the lightness component (luminosity) by converting the image 
from RGB to CIE-Lab. It may also be mentioned that the L channel is also 
close to human vision. Since a and b channels of CIE-Lab color space also 
describe the color, they are ignored. 
In the second step, the set of extracted block features is split into train 
and test subsets. Similar to the selection of the most suited DBC method 
for feature extraction, a classifier is selected by evaluating the 
performance of six most frequently used classification methods on the 
WCE dataset. The best performing classifier is observed to be RF clas­
sifier (see Tables 3–6). The proposed ML model is trained, tested, and 
finally deployed for WCE image analysis. 
We now proceed to discuss the proposed feature extraction algorithm 
in detail. Algorithm 1 takes as an input, an RGB image IN×N and produces 
a feature vector F1×v, where v is the total number of blocks obtained from 
the R, G, B and L channels of the image. Each channel block is of size g ×
g. The DBC or number of boxes bs in each block is computed by Eq. (3). 
Finally, all the features obtained from each channel are concatenated to 
form a feature vector F (F1×v), which is fed into ML algorithms. 
Algorithm 1.
Extraction of fractal features (EFF) algorithm.  
3.3. Synthetic minority oversampling technique 
The WCE datasets considered in this work are highly imbalanced and 
biased towards normal images. Therefore, if we apply ML algorithms on 
an imbalanced dataset, classification results will be inclined towards the 
majority class. So, in this case, the classifier will classify abnormal im­
ages as normal and will falsely result in overall high accuracy. This 
problem can be solved by either oversampling minority class or by 
under-sampling majority class in-order to balance the number of sam­
ples in each class. SMOTE [22] uses an oversampling technique by 
generating auxiliary samples of minority class from real instances 
through a linear combination of two similar samples using the nearest 
neighbor and structural similarity index. So, we can prevent over-fitting 
and generalize the results. In this work, the SMOTE considers SVM with 
linear kernel and 5 nearest neighbours while augmenting data of the 
minority class. 
3.4. Machine learning algorithms 
Generally, it is a tedious task to select an ML algorithm, which best 
suits the data. In this study, six ML algorithms namely KNN [53], SVM 
[54], ELM [55,56], NB [57], DT [58], RF [59–61] are adopted and their 
performances are evaluated on WCE image datasets. Each classifier is 
tuned in such a way that it can give its best performance. The KNN al­
gorithm depends on a user defined number k and finding a suitable value 
of k is a difficult task if it is not known a-priori. In this study, the value of 
k is determined experimentally. SVM with linear and cubic polynomial 
Table 2 
DBC methods and corresponding parameters.  
Methods 
Block size 
Box height 
Box-count in (i,j)th grid 
DBC [44] 
N
2  
gQ
N  
⌈qmax
h
⌉
−
⌈qmin
h
⌉
+ 1   
RDBC [45] 
⌈N
g
⌉
+ 1 ≤−
⌈N
g −1
⌉
gQ
N  
⌈qmax −qmin
h
⌉
SDBC [46] 
N
2  
S 
⌈qmax −qmin + 1
h
⌉
DBC, Li [47] 
N
2  
g −1
0.5(Imax −Imin)
⎧
⎨
⎩
⌈qmax −qmin
h
⌉
ifqmax ∕= qmin
1
ifqmax = qmin    
DBC, Li [48] 
g −1
2  
gQ
N  
⌈qmax −qmin
h
⌉
DBC, Liu [49] 
N
2  
gQ
N  
⎧
⎨
⎩
⌈qmax −qmin + 1
h
⌉
ifqmax ∕= qmin
1
ifqmax = qmin    
DBC, Lai [50] 
N
2  
g(Imax −Imin + 1)
N  
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
⌈qmax −qmin + 1
h
⌉
ifqmax ∕= qmin
1
ifqmax = qmin ∕= 0
0
ifqmax = qmin = 0    
DBC, Panigrahy [43] 
N
2  
2g
N  
⌈qtmax −qtmin + 1
h
⌉
ip
g(g + 1)/2 ,       
where, ip is number of pixels grid   
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 127 (2020) 104094
6
kernels were initially evaluated and the cubic SVM is selected due to its 
better performance. The regularization parameter c, in the SVM is set to 
1 with a squared L2 penalty term in order to avoid over-fitting. Gener­
ally, a lower c value makes the decision surface smoother while a higher 
c value helps in better classification. The ELM is implemented with 10 
neurons in its hidden layer and tanh activation function with a logistic 
regressor exploited for classification. NB classifiers differ mainly by the 
assumptions that they make regarding the distribution of features. In 
this study, the Gaussian NB classifier with normal distribution is used 
after transforming the features into a normal distribution. In this work, 
for implementing the DT, Gini [62] index is adopted as a measure of 
impurity for classification. The Gini impurity gives nearly the same 
Fig. 2. A Schematic block diagram representing the proposed methodology for WCE image classification.  
Table 3 
Accuracy scored in different DBC methods using various classifiers for abnormal WCE image detection.  
Methods 
Dataset-I 
Dataset-II 
ELM 
KNN 
NB 
DT 
SVM 
RF 
ELM 
KNN 
NB 
DT 
SVM 
RF 
DBC [44] 
0.52 
0.58 
0.52 
0.76 
0.80 
0.83 
0.47 
0.68 
0.70 
0.89 
0.98 
0.98 
RDBC [45] 
0.57 
0.60 
0.54 
0.76 
0.80 
0.84 
0.48 
0.69 
0.70 
0.90 
0.98 
0.98 
SDBC [46] 
0.58 
0.60 
0.68 
0.71 
0.80 
0.83 
0.50 
0.71 
0.70 
0.90 
0.98 
0.97 
DBC, Li [47] 
0.58 
0.59 
0.63 
0.71 
0.79 
0.84 
0.49 
0.68 
0.73 
0.91 
0.97 
0.99 
DBC, Li [48] 
0.55 
0.48 
0.64 
0.72 
0.79 
0.83 
0.50 
0.69 
0.73 
0.90 
0.98 
0.98 
DBC, Liu [49] 
0.57 
0.59 
0.64 
0.70 
0.79 
0.83 
0.47 
0.69 
0.72 
0.95 
0.98 
0.99 
DBC, Lai [50] 
0.54 
0.61 
0.64 
0.71 
0.76 
0.81 
0.49 
0.68 
0.70 
0.91 
0.98 
0.98 
DBC, Panigrahy [43] 
0.60 
0.58 
0.58 
0.75 
0.80 
0.85 
0.50 
0.70 
0.70 
0.91 
0.98 
0.99  
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 127 (2020) 104094
7
results as entropy gives, however, Gini is faster than entropy. The 
maximum depth of tree is taken as 50 which is determined experimen­
tally that best suits the given dataset. Since the RF uses DTs, the Gini 
index is again employed for all its material advantages. The maximum 
depth of each DT is not fixed and maximum number estimators (DT) are 
taken as 500, which are decided by trial and error method. 
4. Experimental results and discussion 
4.1. Environment setting 
The proposed work is implemented in Python language using the 
Anaconda environment installed on Windows 10. The system is coupled 
with 8 GB of RAM and Intel Core i7 4th generation CPU. 
4.2. Dataset description 
In this study, one publicly available benchmark dataset [30] and one 
private dataset [17] are adopted to evaluate the proposed method. Both 
the datasets are referred to as Dataset-I and Dataset-II. A brief descrip­
tion of each of these datasets is as follows: 
4.2.1. Dataset-I 
Dataset-I is also known as KID and it consists of images and videos. In 
the present work, only images are considered. In this dataset, all the 
images are of size 360 × 360 pixels, acquired by MicroCam sensor [10] 
in RGB color space. The Dataset-I is further divided into KID Dataset 1 
[15] and KID Dataset 2 [10]. On the one hand, KID Dataset 1 contains 77 
images covering abnormalities like angioectasias, aphthae, chylous 
cysts, polypoid lesions, villous oedema, bleeding, lymphangiectasias, 
ulcers, and stenoses. While, KID Dataset 2 [10], consists of 2371 images 
of miscellaneous findings of polypoid, vascular and, inflammatory le­
sions, and normal images of esophagus, stomach, small bowel, and 
colon. Therefore, a total of 670 abnormal and 1778 normal images are 
considered in this study. After removing unwanted black borders the 
size of images reduces to 320 × 320 pixels. 
4.2.2. Dataset-II 
Dataset-II consists of 37 WCE videos in which 21 videos are of pa­
tients with abnormal findings whereas 16 videos are related to the 
subjects with normal findings evaluated by an experienced physician. 
Initially, frames are separated from all the videos to create a WCE image 
dataset. Out of these frames, 309 images are selected and labeled as 
abnormal depending upon the ground truths available with every video 
file whereas 2063 images are labeled as normal. Each image is an RGB 
color image of size 288 × 288 pixels. The WCE apparatus employed 
while creating this dataset is EndoCapsule developed by Olympus which 
produces frames at the rate of 2fps [17]. Anomalies such as lipoma (9), 
xanthoma (3), erosion (26), ulcer (149), aphthous lesions (23), ery­
thema (61), villious (29), and bleeding (9) are covered in the dataset 
Table 4 
Precision scored in different DBC methods through various classifiers in abnormal WCE image detection.  
Methods 
Dataset-I 
Dataset-II 
ELM 
KNN 
NB 
DT 
SVM 
RF 
ELM 
KNN 
NB 
DT 
SVM 
RF 
DBC [44] 
0.51 
0.70 
0.68 
0.77 
0.82 
0.83 
0.48 
0.80 
0.72 
0.89 
0.98 
0.98 
RDBC [45] 
0.58 
0.73 
0.63 
0.76 
0.82 
0.85 
0.48 
0.80 
0.73 
0.91 
0.98 
0.98 
SDBC [46] 
0.60 
0.72 
0.68 
0.70 
0.82 
0.83 
0.50 
0.80 
0.71 
0.90 
0.98 
0.97 
DBC, Li [47] 
0.58 
0.71 
0.63 
0.72 
0.81 
0.83 
0.49 
0.80 
0.75 
0.90 
0.98 
0.99 
DBC, Li [48] 
0.54 
0.69 
0.64 
0.73 
0.81 
0.84 
0.50 
0.80 
0.75 
0.90 
0.98 
0.98 
DBC, Liu [49] 
0.57 
0.72 
0.66 
0.71 
0.81 
0.84 
0.47 
0.80 
0.74 
0.91 
0.98 
0.99 
DBC, Lai [50] 
0.54 
0.72 
0.66 
0.71 
0.78 
0.82 
0.49 
0.80 
0.72 
0.91 
0.98 
0.98 
DBC, Panigrahy [43] 
0.61 
0.71 
0.63 
0.75 
0.82 
0.86 
0.66 
0.81 
0.75 
0.91 
0.98 
0.99  
Table 5 
Recall scored in different DBC methods with various classifiers in abnormal WCE image detection.  
Methods 
Dataset-I 
Dataset-II 
ELM 
KNN 
NB 
DT 
SVM 
RF 
ELM 
KNN 
NB 
DT 
SVM 
RF 
DBC [44] 
0.51 
0.58 
0.52 
0.76 
0.79 
0.83 
0.48 
0.68 
0.70 
0.89 
0.98 
0.98 
RDBC [45] 
0.56 
0.61 
0.54 
0.76 
0.80 
0.84 
0.48 
0.69 
0.70 
0.90 
0.98 
0.98 
SDBC [46] 
0.58 
0.60 
0.67 
0.71 
0.79 
0.83 
0.50 
0.70 
0.70 
0.90 
0.98 
0.97 
DBC, Li [47] 
0.58 
0.58 
0.63 
0.71 
0.79 
0.84 
0.50 
0.68 
0.73 
0.90 
0.97 
0.99 
DBC, Li [48] 
0.57 
0.58 
0.64 
0.74 
0.81 
0.82 
0.51 
0.69 
0.73 
0.90 
0.98 
0.98 
DBC, Liu [49] 
0.56 
0.59 
0.64 
0.71 
0.80 
0.83 
0.47 
0.68 
0.72 
0.91 
0.98 
0.99 
DBC, Lai [50] 
0.54 
0.61 
0.64 
0.71 
0.76 
0.81 
0.49 
0.68 
0.71 
0.91 
0.98 
0.98 
DBC, Panigrahy [43] 
0.60 
0.58 
0.57 
0.75 
0.80 
0.85 
0.49 
0.70 
0.70 
0.91 
0.98 
0.99  
Table 6 
F1-score obtained from different DBC methods on various classifiers in abnormal WCE image detection.  
Methods 
Dataset-I 
Dataset-II 
ELM 
KNN 
NB 
DT 
SVM 
RF 
ELM 
KNN 
NB 
DT 
SVM 
RF 
DBC [44] 
0.51 
0.63 
0.42 
0.77 
0.80 
0.83 
0.48 
0.68 
0.69 
0.89 
0.98 
0.98 
RDBC [45] 
0.56 
0.66 
0.44 
0.76 
0.81 
0.84 
0.48 
0.69 
0.69 
0.90 
0.98 
0.98 
SDBC [46] 
0.56 
0.53 
0.68 
0.70 
0.80 
0.83 
0.50 
0.66 
0.69 
0.90 
0.98 
0.97 
DBC, Li [47] 
0.58 
0.52 
0.63 
0.71 
0.79 
0.83 
0.50 
0.65 
0.72 
0.90 
0.98 
0.99 
DBC, Li [48] 
0.55 
0.53 
0.65 
0.73 
0.81 
0.83 
0.50 
0.65 
0.72 
0.90 
0.98 
0.98 
DBC, Liu [49] 
0.56 
0.52 
0.64 
0.71 
0.80 
0.83 
0.46 
0.65 
0.71 
0.91 
0.98 
0.99 
DBC, Lai [50] 
0.53 
0.54 
0.63 
0.71 
0.76 
0.81 
0.48 
0.64 
0.70 
0.91 
0.98 
0.98 
DBC, Panigrahy [43] 
0.60 
0.50 
0.54 
0.75 
0.80 
0.85 
0.48 
0.66 
0.69 
0.91 
0.98 
0.99  
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 127 (2020) 104094
8
where the number inside parenthesis denotes the number of images of a 
particular anomaly. 
All the experiments are performed on both the datasets separately. 
Each dataset is randomly divided into train and test sets in a ratio of 
80 : 20. The datasets are biased towards normal images as the count of 
normal images are more than abnormal images. Thus, class balancing is 
needed otherwise, results will get affected more by the class with normal 
images. Therefore features of the abnormal class are over-sampled to 
match with the number of features of normal images using SMOTE [22]. 
4.3. Evaluation metrics 
In this work, the classification performance of the proposed method 
is done based on a standard metric named accuracy [63–65]. Accuracy 
measures the ratio of correct predictions over all predictions. Mathe­
matically, it is defined by Eq. (5). 
Accuracy =
TP + TN
TP + FP + TN + FN,
(5)  
where TP, TN, FP, and FN denote true positive, true negative, false 
positive, and false negative predictions respectively. However, accuracy 
is not enough due to the accuracy paradox [63]. So, other metrics 
namely, precision, recall, and F1-score are also considered in this study, 
which are computed by Eqs. (6)–(8) respectively. 
Precision =
TP
TP + FP
(6)  
Recall =
TP
TP + FN
(7)  
F1 −score = 2 × Precision × Recall
Precision + Recall
(8) 
Precision quantifies the fraction of actual over predicted positive 
images whereas recall is the fraction of actual abnormal images over 
correctly classified abnormal images. Moreover, F1-score provides a 
single score that balances both the concerns of precision and recall. The 
classification performance is also tested using area under the receiver 
operating characteristic curves (AUC). The receiver operating charac­
teristic (ROC) curve depicts the relationship between specificity and 
sensitivity and also we can find the relative trade-offs between true 
positive rates (TPR) and false positive rates (FPR). AUC is scale-invariant 
and it does not consider the classification threshold. Since, AUC gives a 
probabilistic value that a random positive sample is ranked higher than a 
negative sample, therefore, higher AUC is always desirable. 
4.4. Results and comparison 
In this study, a total of 7 experiments are conducted. In the first 
experiment, all the DBC methods mentioned in Table 2 are implemented 
on the datasets for extracting features, which are fed into the ML algo­
rithms namely, KNN, SVM, ELM, NB, DT, and RF separately. The per­
formances of state-of-the-art DBC methods are computed using four 
evaluation metrics namely, accuracy, precision, recall, and F1-score 
discussed in Section 4.3. Values of these metrics obtained by applying 
various DBC methods are reported in Tables 3–6 respectively. It is clear 
from Tables 3–6 that the improved DBC method devised by Panigrahy 
et al. [43] with RF classifier yields the highest accuracy of 85% and 99% 
when compared with other DBC methods in both the datasets. Hence, 
this method is preferred for the extraction of fractal features in the 
proposed method. Moreover, it can be deduced from the results that the 
RF outperforms all the other classifiers considered in the study whereas 
the SVM performs marginally lower than RF. In this study, RF is the only 
ensemble classifier that is considered. It utilizes unpruned DTs as weak 
classifiers. The DTs take data samples as inputs and produce the results 
independently. Then, the mode of outputs of each of these DTs is 
considered as final. Since, DTs lag in giving good results due to over­
fitting raised during training, RF mitigates this problem by averaging the 
result produced by DT. Probably this might be the reason for better 
performance of RF. 
In the second experiment, the proposed method paired with the RF 
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 127 (2020) 104094
9
classifier is also tested on RGB, HSV, CIE-Lab, and the adopted hybrid 
color spaces and the obtained results are shown in Fig. 3. It is observed 
from Fig. 3 that converting the WCE image originally in RGB plane to 
HSV and CIE-Lab spaces are giving better results, however, the perfor­
mance is even better when the L channel is integrated with RGB color 
space achieving the highest AUC of 85% and 99% on Dataset-I and 
Dataset-II respectively. When the HSV color space is considered, 83% 
and 97% AUCs are reached on the Dataset-I and Dataset-II respectively. 
However, the results obtained using HSV and CIE-Lab color spaces are 
almost identical. 
As features are extracted in block-wise fashion, it is necessary to find 
the block size for which extracted features give the best classification 
results. In the third experiment, features are computed by applying the 
proposed technique on different block sizes varying from 3 to 13 with a 
step size of 2 while keeping an eye on the performance in terms of ac­
curacy. Block size greater than 13 does not seem to be lucrative since the 
contribution of pixels belonging to abnormal regions of smaller size may 
be ignored in the larger block size. The performance of the proposed 
method with respect to the block size is shown in Table 7. It is clear from 
the table that features extracted with the block size of 7 give the best 
result in both the datasets, although marginally. 
Table 8 shows the size of each image in pixels, the length of a feature 
vector of each channel in an image, the total length of a feature vector of 
four channels, and the number of normal and abnormal images in both 
the datasets. Table 9 reports the size of the feature matrices of both the 
datasets before and after data augmentation using SMOTE. To test the 
effect of SMOTE, the proposed method is evaluated with and without 
applying SMOTE on the extracted features. The results reported in 
Table 10 show that the performance of the proposed model is better in 
both the datasets when the SMOTE is utilized. This is the fourth exper­
iment in the series of experiments performed in the present study. 
In the fifth experiment, the proposed method is compared with six 
state-of-the-art methods namely, Range Ratios Color [8], Raw Histo­
gram [24], CHOBS [14], Color histogram [26], and weak CNN [10]. The 
performances of these methods are reported in Table 11. 5-fold 
cross-validation is performed to ensure that the results are not biased 
with respect to the choice of samples in training and testing sets. The 
Fig. 3. Performance of the proposed method on different color spaces and 
suggested a combination of RGB with L on the Dataset-I and the Dataset-II. (For 
interpretation of the references to colour in this figure legend, the reader is 
referred to the web version of this article.) 
Table 7 
Effect of block size on accuracy score of the proposed method in Dataset-I and 
Dataset-II.  
Block size 
Dataset-I 
Dataset-II 
3 × 3  
0.838 
0.991 
5 × 5  
0.826 
0.985 
7 × 7  
0.850 
0.992 
9 × 9  
0.833 
0.985 
11 × 11  
0.841 
0.990 
13 × 13  
0.845 
0.987 
The best classification results are highlighted by the bold characters. 
Table 8 
The length of the feature vector of both the datasets before applying SMOTE.  
Dataset 
Image size 
in 
Length of a 
feature vector 
Length of a 
feature vector 
Number of 
normal/ 
pixels 
of each channel 
of four channels 
abnormal WCE 
images 
Dataset- 
I 
320 ×
320 × 3  
2025 
8100 
1776/670  
Dataset- 
II 
288 ×
288 × 3  
1681 
6724 
2063/309   
Table 9 
The size of the feature matrices of both the datasets before and after data 
augmentation using SMOTE.   
Dataset-I 
Dataset-II 
Feature 
matrix of 
Feature 
matrix of 
Feature 
matrix of 
Feature 
matrix of 
normal 
images 
abnormal 
images 
normal 
images 
abnormal 
images 
Before applying 
SMOTE 
1776 ×
8100  
670 × 8100  
1776 ×
8100  
1776 × 8100  
After applying 
SMOTE 
2063 ×
6724  
309 × 6724  
2063 ×
6724  
2063 × 6724   
Table 10 
Comparing performance of the proposed technique with and without applying 
SMOTE on computed features.  
Metrics 
With SMOTE 
Without SMOTE 
Dataset-I 
Dataset-II 
Dataset-I 
Dataset-II 
Accuracy 
0.85 
0.99 
0.74 
0.92 
Precision 
0.86 
0.99 
0.68 
0.93 
Recall 
0.85 
0.99 
0.74 
0.92 
F1-score 
0.85 
0.99 
0.66 
0.90 
AUC 
0.85 
0.99 
0.52 
0.69  
Table 11 
Classification results of the proposed method with other state-of-the-art 
methods.  
Features 
Dataset-I 
Dataset-II 
Accuracy 
F1- 
score 
AUC 
Accuracy 
F1- 
score 
AUC 
Range Ratios 
Color [8] 
0.65 
0.42 
0.53 
0.85 
0.79 
0.80 
Raw histogram 
[24] 
0.73 
0.61 
0.50 
0.92 
0.90 
0.72 
Bag of Words [9] 
0.80 
0.79 
0.79 
0.91 
0.89 
0.85 
CHOBS [14] 
0.73 
0.72 
0.66 
0.97 
0.96 
0.92 
Weak CNN [10] 
0.82 
0.87 
0.85 
0.97 
0.96 
0.97 
Proposed 
Method 
0.85 
0.84 
0.85 
0.99 
0.99 
0.99 
The best classification results are highlighted by the bold characters. 
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 127 (2020) 104094
10
proposed method demonstrates superior performance in terms of accu­
racy when compared with all state-of-the-art methods. However, the 
weak CNN, introduced by Iakovidis et al. [10] performs better than the 
proposed method on Dataset-I, in terms of F1-score and AUC. The Weak 
CNN introduced by Iakovidis et al. [10] contains five convolution layers 
such that the first four layers are followed by a max-pool layer each and 
the last one is followed by three fully connected layers. The last layer is 
the classification layer that uses a softmax classifier for identification of 
abnormal images. Nonetheless, the proposed method is observed to be 
better than Weak CNN [10] on Dataset-II with respect to all the three 
measures and on Dataset-I with respect to accuracy. To check if the 
difference in the performance is significant, Student’s t-Test is per­
formed which is detailed as follows. 
In the sixth experiment, the Student’s t-Test [66] is performed on the 
accuracy scores of the proposed method and the Weak CNN introduced 
in Ref. [10] to find out if the difference in the accuracy scores of the two 
methods is significant. Accuracy is recorded on ten rounds of experi­
ments using the test datasets and statistical values like mean, variance, 
and the standard deviation of accuracy scores are computed, which are 
listed in Table 12. After the application of the t-test, the p-value comes 
out to be close to 0 in Dataset-I whereas it is near to 0.005 in Dataset-II as 
listed in Table 13. This indicates that there is 0% and less than 0.5% 
percent chance of getting the same results from both the methods on 
Dataset-I and Dataset-II respectively. 
Accurate identification of texture patterns plays an important role in 
detection of abnormalities in WCE images. Some of the existing textural 
descriptors like Haralick features [67], LBP [68] and KAZE features [69] 
have demonstrated their capabilities in many computer vision problems 
including those in biomedical imaging. In view of this, a comparison of 
the proposed method is made with the above three feature descriptors 
keeping RF as the classifier. Results of this seventh experiment are 
presented in Table 14. This shows that the proposed DBC based FD 
features performs better on both the datasets. 
4.5. Discussion 
The results presented in the previous section demonstrate that the 
proposed method performs better than some of the existing methods on 
both the datasets. Fig. 4 shows the visualization of features representing 
abnormalities in images using the extracted features with the blocks size 
of 7 × 7. Here the example image A from the Dataset-II is of size 288 ×
288 × 3. A is transformed into a 41 × 41 image named B which is the 
visualization of feature vector representing the differential box counts of 
R channel in A. It may be noted that distinct colors are assigned to 
different pixel values. It may be observed that the regions where a pa­
thology exists in image A, can be distinctly seen in B which are repre­
sented as pixels having values equal to the box-count of a block in the 
corresponding region of the original image. It is observed that abnormal 
regions normally lead to greater box height producing larger box-count 
values. This distinctive capability of the feature extractor is possibly a 
reason for better performance of the proposed method. 
Although classification accuracy of the proposed method is high 
close to 99% in Dataset-II, there is always a possibility of getting FP and 
TN results. Fig. 5 gives FP and TP classification results of sixteen 
randomly selected samples from normal and abnormal images of 
Dataset-II, as produced by the proposed method. The FP results are 
investigated for the identification of the reason behind inaccurate results 
on the application of the proposed method. It is observed that some 
normal regions have a texture similar to abnormal regions therefore few 
normal images are falsely classified as abnormal under FP of a normal 
category. Since the size of an abnormality can be either very small 
especially when it is read inside 7 × 7 windows, the contribution of the 
anomalous features will be negligible which falsely makes an abnormal 
image predicted as normal. As the image is divided into blocks, pixels 
containing abnormality may get distributed into more than one block 
and the blocks in the boundary of abnormality can generate features 
defining normal regions. Probably these reasons are responsible for the 
prediction of false positive results. 
5. Conclusion 
In this study, a relatively new approach for detection of abnormality 
in WCE images is discussed. Instead of considering global features, this 
work focuses on block-wise local features. The local features are 
extracted from four color channels of each image by the DBC based FD 
method introduced in Refs. [43]. The SMOTE is adopted to overcome the 
Table 12 
Statistical values computed on accuracy scores recorded on 10 rounds of WCNN 
[10] and the proposed method.  
Metrics 
WCNN [10] 
Proposed Method 
Mean 
Variance 
Standard 
Deviation 
Mean 
Variance 
Standard 
Deviation 
Dataset- 
I 
0.78 
7.6 ×
10−5  
0.009 
0.84 
1.6 ×
10−5  
0.004 
Dataset- 
II 
0.97 
6.5 ×
10−5  
0.004 
0.98 
2.5 ×
10−5  
0.005  
Table 13 
Student’s t-Test results on accuracy scores of the proposed method and Weak 
CNN [10].  
Dataset 
t-statistic 
p-value 
Dataset-I 
−
18.77  
2.89 × 10−13  
Dataset-II 
−
3.16  
5.39 × 10−3   
Table 14 
Comparison of the proposed method with other textural feature descriptors.  
Features 
Dataset-I 
Dataset-II 
Accuracy 
F1- 
score 
AUC 
Accuracy 
F1- 
score 
AUC 
Haralick [67] 
0.77 
0.78 
0.77 
0.94 
0.94 
0.93 
LBP [68] 
0.82 
0.82 
0.83 
0.96 
0.97 
0.96 
KAZE [69] 
0.72 
0.60 
0.65 
0.86 
0.80 
0.85 
Proposed 
Method 
0.85 
0.85 
0.85 
0.99 
0.98 
0.99  
Fig. 4. An example of WCE image with its corresponding features. (A) A 288 ×
288 × 3 WCE image containing abnormal findings. (B) A 41 × 41 image rep­
resenting features computed from DBC method on R channel of image A con­
verted into an image for visualization. Bold lines showing correlation of 
abnormalities in A with pixels representing box-count in B highlighted with 
light blue color. (For interpretation of the references to colour in this figure 
legend, the reader is referred to the web version of this article.) 
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 127 (2020) 104094
11
high imbalance problem. The experimental results illustrate that the 
proposed method outperforms some of the state-of-the-art methods in 
terms of accuracy, and F1-score when the block size is 7. These datasets 
are small and highly imbalanced, it would be good to test the proposed 
method on other datasets as well. As a future work, we aim to tackle 
localization of abnormality and not only detecting the presence of it. 
Declaration of competing interest 
The authors declare no conflict of interest. 
Acknowledgment 
The authors would like to express their sincere thanks to the anon­
ymous reviewers whose comments and suggestions have helped in 
improving the quality of the paper. This work is partially supported by 
the project “Prediction of diseases through computer assisted diagnosis 
system using images captured by minimally-invasive and non-invasive 
modalities”, Computer Science and Engineering, PDPM Indian Insti­
tute of Information Technology, Design and Manufacturing, Jabalpur 
India (under ID: SPARC-MHRD-231). This work is also partially sup­
ported by the project IT4Neuro(degeneration), reg. nr. CZ.02.1.01/0.0/ 
0.0/18_069/0010054 and by the project “Smart Solutions in Ubiquitous 
Computing Environments”, Grant Agency of Excellence, University of 
Hradec Kralove, Faculty of Informatics and Management, Czech Re­
public (under ID: UHK-FIM-GE-2020). 
Appendix A. Supplementary data 
Supplementary data to this article can be found online at https://doi. 
org/10.1016/j.compbiomed.2020.104094. 
References 
[1] F. Gong, C. Swain, T. Mills, An endorobot for gastrointestinal endoscopy, Gut 35 
(1994) S52. 
[2] G. Iddan, G. Meron, A. Glukhovsky, P. Swain, Wireless capsule endoscopy, Nature 
405 (6785) (2000), 417–417. 
[3] M. Mylonaki, A. Fritscher-Ravens, P. Swain, Wireless capsule endoscopy: a 
comparison with push enteroscopy in patients with gastroscopy and colonoscopy 
negative gastrointestinal bleeding, Gut 52 (8) (2003) 1122–1126. 
[4] I. Tachecí, Kapslov´a Endoskopie, Nucleus HK, 2008. 
[5] A. Koulaouzidis, D.K. Iakovidis, A. Karargyris, J.N. Plevris, Optimizing lesion 
detection in small-bowel capsule endoscopy: from present problems to future 
solutions, Expet Rev. Gastroenterol. Hepatol. 9 (2) (2015) 217–235. 
[6] B. Li, M.Q.-H. Meng, Computer-aided detection of bleeding regions for capsule 
endoscopy images, IEEE Trans. Biomed. Eng. 56 (4) (2009) 1032–1039. 
[7] S.A. Karkanis, D.K. Iakovidis, D. Karras, D. Maroulis, Detection of lesions in 
endoscopic video using textural descriptors on wavelet domain supported by 
artificial neural network architectures, in: Proceedings 2001 International 
Conference on Image Processing (Cat. No. 01CH37205), vol. 2, IEEE, 2001, 
pp. 833–836. 
[8] A.K. Kundu, S.A. Fattah, M.N. Rizve, An automatic bleeding frame and region 
detection scheme for wireless capsule endoscopy videos based on interplane 
intensity variation profile in normalized rgb color space, J. Healthcare Eng. (2018), 
9423062. 
[9] Y. Yuan, B. Li, M.Q.-H. Meng, Bleeding frame and region detection in the wireless 
capsule endoscopy video, IEEE J.Biomed. Health Inf. 20 (2) (2015) 624–630. 
[10] D.K. Iakovidis, S.V. Georgakopoulos, M. Vasilakakis, A. Koulaouzidis, V. 
P. Plagianakos, Detecting and locating gastrointestinal anomalies using deep 
learning and iterative cluster unification, IEEE Trans. Med. Imag. 37 (10) (2018) 
2196–2210. 
[11] Z. Xiao, L.N. Feng, A study on wireless capsule endoscopy for small intestinal 
lesions detection based on deep learning target detection, IEEE Access 8 (2020) 
159017–159026. 
[12] M.A. Khan, S. Kadry, M. Alhaisoni, Y. Nam, Y. Zhang, V. Rajinikanth, M.S. Sarfraz, 
Computer-aided gastrointestinal diseases analysis from wireless capsule 
endoscopy: a framework of best features selection, IEEE Access 8 (2020) 
132850–132859. 
[13] V.S. Sadasivan, C.S. Seelamantula, High accuracy patch-level classification of 
wireless capsule endoscopy images using a convolutional neural network, in: 2019 
IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), IEEE, 
2019, pp. 96–99. 
[14] T. Ghosh, S.A. Fattah, K.A. Wahid, Chobs: color histogram of block statistics for 
automatic bleeding detection in wireless capsule endoscopy video, IEEE J.Transl. 
Eng. Health Med. 6 (2018) 1–12. 
[15] D.K. Iakovidis, A. Koulaouzidis, Automatic lesion detection in wireless capsule 
endoscopy––a simple solution for a complex problem, in: 2014 IEEE International 
Conference on Image Processing (ICIP), IEEE, 2014, pp. 2236–2240. 
[16] Y. Yuan, M.Q.-H. Meng, Deep learning for polyp recognition in wireless capsule 
endoscopy images, Med. Phys. 44 (4) (2017) 1379–1389. 
[17] A. Novoz´amskỳ, J. Flusser, I. Tachecí, L. Sulík, J. Bureˇs, O. Krejcar, Automatic 
blood detection in capsule endoscopy video, J. Biomed. Optic. 21 (12) (2016), 
126007. 
[18] A. A. Al-Rahayfeh, A. A. Abuzneid, Detection of Bleeding in Wireless Capsule 
Endoscopy Images Using Range Ratio Color, arXiv preprint arXiv:1005.5439. 
Fig. 5. An illustration of correctly classified and mis-classified WCE images using the proposed method where blue ellipses show presence of abnormality in correctly 
classified abnormal images and red ellipses shows pathology in mis-classified abnormal images. (For interpretation of the references to colour in this figure legend, 
the reader is referred to the web version of this article.) 
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 127 (2020) 104094
12
[19] X. Jia, M.Q.-H. Meng, A deep convolutional neural network for bleeding detection 
in wireless capsule endoscopy images, in: 2016 38th Annual International 
Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), IEEE, 
2016, pp. 639–642. 
[20] A.K. Sekuboyina, S.T. Devarakonda, C.S. Seelamantula, A convolutional neural 
network approach for abnormality detection in wireless capsule endoscopy, in: 
2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017), 
IEEE, 2017, pp. 1057–1060. 
[21] C. Panigrahy, A. Seal, N.K. Mahato, Fractal dimension of synthesized and natural 
color images in lab space, Pattern Anal. Appl. 23 (2) (2020) 819–836. 
[22] N.V. Chawla, K.W. Bowyer, L.O. Hall, W.P. Kegelmeyer, Smote: synthetic minority 
over-sampling technique, J. Artif. Intell. Res. 16 (2002) 321–357. 
[23] A.S. Ashour, N. Dey, W.S. Mohamed, J.G. Tromp, R.S. Sherratt, F. Shi, L. Moraru, 
Colored video analysis in wireless capsule endoscopy: a survey of state-of-the-art, 
Curr. Med. Imag. 16 (1) (2020). 
[24] J. Liu, X. Yuan, Obscure bleeding detection in endoscopy images using support 
vector machines, Optim. Eng. 10 (2) (2009) 289–299. 
[25] G. Lv, G. Yan, Z. Wang, Bleeding detection in wireless capsule endoscopy images 
based on color invariants and spatial pyramids using support vector machines, in: 
2011 Annual International Conference of the IEEE Engineering in Medicine and 
Biology Society, IEEE, 2011, pp. 6643–6646. 
[26] S. Sainju, F.M. Bui, K. Wahid, Bleeding detection in wireless capsule endoscopy 
based on color features from histogram probability, in: 2013 26th IEEE Canadian 
Conference on Electrical and Computer Engineering (CCECE), IEEE, 2013, pp. 1–4. 
[27] Y. Yuan, B. Li, M.Q.-H. Meng, Improved bag of feature for automatic polyp 
detection in wireless capsule endoscopy images, IEEE Trans. Autom. Sci. Eng. 13 
(2) (2015) 529–535. 
[28] H. Chen, S. Wang, Y. Ding, D. Qian, Saliency-based bleeding localization for 
wireless capsule endoscopy diagnosis, Int. J. Biomed. Imag. 2017 (2017), 8147632. 
[29] Medtronic, Capsule Endoscopy Products. URL http://capsuleendoscopy.org/. 
[30] A. Koulaouzidis, D.K. Iakovidis, D.E. Yung, E. Rondonotti, U. Kopylov, J.N. Plevris, 
E. Toth, A. Eliakim, G.W. Johansson, W. Marlicz, et al., Kid project: an internet- 
based digital video atlas of capsule endoscopy for research purposes, Endosc. Int. 
Open 5 (6) (2017) E477. 
[31] X. Jia, M.Q.-H. Meng, Gastrointestinal bleeding detection in wireless capsule 
endoscopy images using handcrafted and cnn features, in: 2017 39th Annual 
International Conference of the IEEE Engineering in Medicine and Biology Society 
(EMBC), IEEE, 2017, pp. 3154–3157. 
[32] Z. Li, K. Kamnitsas, B. Glocker, Overfitting of neural nets under class imbalance: 
analysis and improvements for segmentation, in: International Conference on 
Medical Image Computing and Computer-Assisted Intervention, Springer, 2019, 
pp. 402–410. 
[33] Q. Xu, M. Zhang, Z. Gu, G. Pan, Overfitting remedy by sparsifying regularization on 
fully-connected layers of cnns, Neurocomputing 328 (2019) 69–74. 
[34] S. Liu, An improved differential box-counting approach to compute fractal 
dimension of gray-level image, in: 2008 International Symposium on Information 
Science and Engineering, vol. 1, IEEE, 2008, pp. 303–306. 
[35] B.B. Chaudhuri, N. Sarkar, Texture segmentation using fractal dimension, IEEE 
Trans. Pattern Anal. Mach. Intell. 17 (1) (1995) 72–77. 
[36] L. Yu, D. Zhang, K. Wang, W. Yang, Coarse iris classification using box-counting to 
estimate fractal dimensions, Pattern Recogn. 38 (11) (2005) 1791–1798. 
[37] A. Seal, C. Panigrahy, Human authentication based on fusion of thermal and visible 
face images, Multimed. Tool. Appl. 78 (21) (2019) 30373–30395. 
[38] A.N. Esgiar, R.N. Naguib, B.S. Sharif, M.K. Bennett, A. Murray, Fractal analysis in 
the detection of colonic cancer images, IEEE Trans. Inf. Technol. Biomed. 6 (1) 
(2002) 54–58. 
[39] H. Eguiraun Martínez, M. K. L´opez de Ipi˜na Pe˜na, M. Falarza, M. Iciar, Application 
of Entropy and Fractal Dimension Analyses to the Pattern Recognition of 
Contaminated Fish Responses in Aquaculture. 
[40] I. Jamaludin, M.C. Azemin, A. Sapuan, A. Zainuddin, R. Hassan, 2d and 3d 
complexity analysis on mri images using fractal dimension, J. Telecommun. 
Electron. Comput. Eng. 10 (1–8) (2018) 161–164. 
[41] C. Panigrahy, A. Seal, N. Mahato, Mri and spect image fusion using a weighted 
parameter adaptive dual channel pcnn, in: IEEE Signal Process. Lett.Pubmed 
Partial Author articletitle stitle stitle Volume Page, 27, 2020, pp. 690–694. 
[42] C. Panigrahy, A. Seal, N.K. Mahato, D. Bhattacharjee, Differential box counting 
methods for estimating fractal dimension of gray-scale images: a survey, Chaos, 
Solitons & Fractals 126 (2019) 178–202. 
[43] C. Panigrahy, A. Seal, N.K. Mahato, Quantitative texture measurement of gray- 
scale images: fractal dimension using an improved differential box counting 
method, Measurement 147 (2019), 106859. 
[44] N. Sarkar, B.B. Chaudhuri, An efficient differential box-counting approach to 
compute fractal dimension of image, IEEE Trans. Syst. Man Cybern. 24 (1) (1994) 
115–120. 
[45] X. Jin, S. Ong, et al., A practical method for estimating fractal dimension, Pattern 
Recogn. Lett. 16 (5) (1995) 457–464. 
[46] W.-S. Chen, S.-Y. Yuan, C.-M. Hsieh, Two algorithms to estimate fractal dimension 
of gray-level images, Opt. Eng. 42 (8) (2003) 2452–2465. 
[47] J. Li, C. Sun, Q. Du, A new box-counting method for estimation of image fractal 
dimension, in: 2006 International Conference on Image Processing, IEEE, 2006, 
pp. 3029–3032. 
[48] J. Li, Q. Du, C. Sun, An improved box-counting method for image fractal dimension 
estimation, Pattern Recogn. 42 (11) (2009) 2460–2469. 
[49] Y. Liu, L. Chen, H. Wang, L. Jiang, Y. Zhang, J. Zhao, D. Wang, Y. Zhao, Y. Song, An 
improved differential box-counting method to estimate fractal dimensions of gray- 
level images, J. Vis. Commun. Image Represent. 25 (5) (2014) 1102–1111. 
[50] K. Lai, C. Li, T. He, L. Chen, K. Yu, W. Zhou, Study on an improved differential box- 
counting approach for gray-level variation of images, in: 2016 10th International 
Conference on Sensing Technology (ICST), IEEE, 2016, pp. 1–6. 
[51] M. Long, F. Peng, A box-counting method with adaptable box height for measuring 
the fractal feature of images, Radioengineering 22 (1) (2013) 208–213. 
[52] C. Panigrahy, A. Seal, N.K. Mahato, Fractal dimension of synthesized and natural 
color images in lab space, Pattern Anal. Appl. 23 (2) (2019) 819–836. 
[53] P. Cunningham, S. J. Delany, K-Nearest Neighbour Classifiers–, arXiv preprint 
arXiv:2004.04523. 
[54] J. Kim, B. Kim, S. Savarese, Comparing image classification methods: K-nearest- 
neighbor and support-vector-machines, in: Proceedings of the 6th WSEAS 
International Conference on Computer Engineering and Applications, and 
Proceedings of the 2012 American Conference on Applied Mathematics, vol. 1001, 
2012, 48109–2122. 
[55] Z. Wang, G. Yu, Y. Kang, Y. Zhao, Q. Qu, Breast tumor detection in digital 
mammography based on extreme learning machine, Neurocomputing 128 (2014) 
175–184. 
[56] A. Seal, P.P.N. Reddy, P. Chaithanya, A. Meghana, K. Jahnavi, O. Krejcar, 
R. Hudak, An eeg database and its initial benchmark emotion classification 
performance, Comput. and Math. Meth. Med. 2020 (2020), 8303465. 
[57] N. Friedman, D. Geiger, M. Goldszmidt, Bayesian network classifiers, Mach. Learn. 
29 (2–3) (1997) 131–163. 
[58] B.J. Erickson, P. Korfiatis, Z. Akkus, T.L. Kline, Machine learning for medical 
imaging, Radiographics 37 (2) (2017) 505–515. 
[59] A. Seal, D. Bhattacharjee, M. Nasipuri, D. Rodríguez-Esparrag´on, E. Menasalvas, 
C. Gonzalo-Martin, Pet-ct image fusion using random forest and `a-trous wavelet 
transform, Int. J. Numer. Meth. Biomed. Eng. 34 (3) (2018), e2933. 
[60] A. Seal, D. Bhattacharjee, M. Nasipuri, Human face recognition using random 
forest based fusion of `a-trous wavelet transform coefficients from thermal and 
visible images, AEU-Int. J. Electron. Commun. 70 (8) (2016) 1041–1049. 
[61] A. Seal, A. Garcia-Pedrero, D. Bhattacharjee, M. Nasipuri, M. Lillo-Saavedra, 
E. Menasalvas, C. Gonzalo-Martin, Multi-scale rois selection for classifying multi- 
spectral images, Multidimens. Syst. Signal Process. (2019) 1–25. 
[62] L.E. Raileanu, K. Stoffel, Theoretical comparison between the gini index and 
information gain criteria, Ann. Math. Artif. Intell. 41 (1) (2004) 77–93. 
[63] K.K. Sharma, A. Seal, Modeling uncertain data using Monte Carlo integration 
method for clustering, Expert Syst. Appl. 137 (2019) 100–116. 
[64] K.K. Sharma, A. Seal, Clustering analysis using an adaptive fused distance, Eng. 
Appl. Artif. Intell. 96 (2020) 103928. 
[65] K.K. Sharma, A. Seal, Multi-view spectral clustering for uncertain objects, Inf. Sci. 
547 (8) (2020) 723–745. 
[66] L. Johnston, Student’s t-test, J. Qual. Technol. 2 (4) (1970) 243–245. 
[67] A. Porebski, N. Vandenbroucke, L. Macaire, Haralick feature extraction from lbp 
images for color texture classification, in: 2008 First Workshops on Image 
Processing Theory, Tools and Applications, IEEE, 2008, pp. 1–8. 
[68] A.F. Constantinescu, M. Ionescu, I. Rogoveanu, M.E. Ciurea, C.T. Streba, V. 
F. Iovanescu, S.A. Artene, C.C. Vere, Analysis of wireless capsule endoscopy images 
using local binary patterns, Appl. Med. Inf. 36 (2) (2015) 31–42. 
[69] P.F. Alcantarilla, A. Bartoli, A.J. Davison, Kaze features, in: European Conference 
on Computer Vision, Springer, 2012, pp. 214–227. 
S. Jain et al.                                                                                                                                                                                                                                     
",https://doi.org/10.1016/j.compbiomed.2020.104094,doc17,"Computers in Biology and Medicine 127 (2020) 104094 Available online 27 October 2020 0010-4825/© 2020 Elsevier Ltd. All rights reserved. Detection of abnormality in wireless capsule endoscopy images using fractal features Samir Jain a, Ayan Seal a,b,*, Aparajita Ojha a, Ondrej Krejcar b,c, Jan Bureˇs d, Ilja Tachecí d, Anis Yazidi e a PDPM Indian Institute of Information Technology Design and Manufacturing, Jabalpur, 482005, India b Center for Basic and Applied Research, Faculty of Informatics and Management, University of Hradec Kralove, Hradecka, 1249, Hradec Kralove, 50003, Czech Republic c Malaysia Japan International Institute of Technology, Universiti Teknologi Malaysia, Jalan Sultan Yahya Petra, 54100, Kuala Lumpur, Malaysia d Second Department of Internal Medicine-Gastroenterology, Charles University, Faculty of Medicine in Hradec Kralove, University Hospital Hradec Kralove, Sokolska 581, Hradec Kralove, 50005, Czech Republic e Artificial Intelligence Lab, Oslo Metropolitan University, 460167, Norway A R T I C L E I N F O Keywords: Wireless capsule endoscopy Anomaly detection Fractal dimensions Differential box-counting A B S T R A C T One of the most recent non-invasive technologies to examine the gastrointestinal tract is wireless capsule endoscopy (WCE). As there are thousands of endoscopic images in an 8–15 h long video, an evaluator has to pay constant attention for a relatively long time (60–120 min). Therefore the possibility of the presence of patho­ logical findings in a few images (displayed for evaluation for a few seconds only) brings a significant risk of missing the pathology with all negative consequences for the patient. Hence, manually reviewing a video to identify abnormal images is not only a tedious and time consuming task that overwhelms human attention but also is error prone. In this paper, a method is proposed for the automatic detection of abnormal WCE images. The differential box counting method is used for the extraction of fractal dimension (FD) of WCE images and the random forest based ensemble classifier is used for the identification of abnormal frames. The FD is a well-known technique for extraction of features related to texture, smoothness, and roughness. In this paper, FDs are extracted from pixel-blocks of WCE images and are fed to the classifier for identification of images with ab­ normalities. To determine a suitable pixel block size for FD feature extraction, various sizes of blocks are considered and are fed into six frequently used classifiers separately, and the block size of 7 × 7 giving the best performance is empirically determined. Further, the selection of the random forest ensemble classifier is also done using the same empirical study. Performance of the proposed method is evaluated on two datasets con­ taining WCE frames. Results demonstrate that the proposed method outperforms some of the state-of-the-art methods with AUC of 85% and 99% on Dataset-I and Dataset-II respectively. 1. Introduction Nowadays, wireless capsule endoscopy (WCE) based gastrointestinal endoscopy (GIE) is preferred by medical practitioners or endoscopists to examine some parts of the gastrointestinal tract due to non-invasive nature compared to conventional endoscopy procedures such as gastroscopy and colonoscopy with associated discomfort observed in patients [1–4]. WCE has become the standard diagnostic method in the field of small intestinal diseases. Generally, a capsule of size 10 × 25 mm equipped with a tiny optical camera, LED light source, signal transmitter, and the battery is swallowed by a patient that travels through the esophagus, stomach, small intestine, and large bowel. However, the size of a capsule may vary from manufacturer to manufacturer. The tiny camera placed inside the capsule captures data in the form of a video which is sent to a sensing device tied over the waist of the patient. Generally, the camera records videos at a rate of 2–6 frames per second, in a typical WCE video that can be of 8–15 h long. A WCE video may consist of more than 50, 000 frames in general [5] which makes it a tedious task to carefully watch the whole video and search for abnormalities. Computer-aided diagnosis (CAD) tools can assist medical practitioners to identify abnormal image(s) by exploiting computer vision algorithms with high precision. Due to * Corresponding author. PDPM Indian Institute of Information Technology Design and Manufacturing, Jabalpur, 482005, India. E-mail address: ayan@iiitdmj.ac.in (A. Seal). Contents lists available at ScienceDirect Computers in Biology and Medicine journal homepage: Received 5 July 2020; Received in revised form 23 October 2020; Accepted 23 October 2020 Computers in Biology and Medicine 127 (2020) 104094 2 significant growth of artificial intelligence based vision techniques, their applications in bio-medical imaging, and especially in WCE video pro­ cessing have also been explored by many researchers (see for e.g. Ref. [6–13]). In WCE images, complexity and diversity of texture and color information in different types of pathologies pose challenges in designing a fully automatic CAD diagnostic system with high reliability. Nonetheless, semi-automatic CAD systems help significantly reduce the time to analyze a video by a professional evaluator in-order to eliminate normal frames. The task of an evaluator is then primarily the second reading of findings marked as abnormal (pathological) by the CAD system and elimination of false-positive frames. Various approaches have been presented over the years for specific types of abnormality detection such as bleeding [9,14], ulcers [12,15], and polyps [10,16]. These methods range from image processing, to machine learning and more recent methods based on deep learning architectures [7,8,10–12, 17–20]. Some recent approaches focus on covering a broad range of abnormalities instead of only specific type of abnormalities, which are more useful for devising automatic CAD diagnostic tools for investiga­ tion of WCE frames [10,20]. In this work, a CAD tool is designed and developed to identify abnormal image(s) in WCE videos that cover a broad range of abnormalities. A random forest (RF) ensemble-based classifier is trained to identify abnormal images using the fractal dimension (FD) of the image pixel blocks. Main contributions of the present work are as follows: • Differential Box Counting (DBC) based FD method is employed to quantify the textures of 24-bit color RGB images of WCE videos, as the anomalies exhibit different textural properties. This improves the efficiency of the CAD tool in detecting anomalies. • In addition to RGB channels, the L component of the CIE-Lab color space model of images is utilized for enriching the textural infor­ mation as it closely matches the human perception of lightness [21]. • To compensate for class imbalance in the WCE datasets which are generally highly imbalanced and small, synthetic minority over­ sampling technique (SMOTE) [22] is applied on the feature set. • Selection of the RF ensemble classifier is made through an empirical study on six most frequently used classifiers in the literature, namely k-nearest neighbor (KNN), support vector machine (SVM), extreme learning machine (ELM), naive bayes (NB), decision tree (DT), and RF. The CAD tool using the DBC based FD and RF classifier out­ performs some of the state-of-the-art methods as illustrated in section 4.4. The rest of the work is organized into five sections. Section 2 presents a brief overview of existing methods. The proposed methodology with its background is described in Section 3. Section 4 is devoted to exper­ imental analysis and performance evaluation of the proposed approach. In this section, a comparison with existing approaches is also presented. Section 5 presents the concluding remarks and future scope of the pro­ posed work. 2. Related work Detection of abnormalities in WCE images using computer vision techniques is not a new area of research; it started ever since the WCE systems were introduced for healthcare in 2001. Growth of WCE market led to the development of sophisticated computer vision techniques for detection of abnormal frames using image processing and machine learning techniques. Over the last two decades, numerous techniques have been presented by researchers using different machine learning algorithms and feature extraction methods [23]. It is well known that feature extraction plays a crucial role in ma­ chine learning algorithms and finding a suitable feature extraction method for a particular problem is always a challenge. Early studies on WCE image analysis were focused on detection of bleeding abnormality [6,7,24,25]. Recent trend shows a paradigm shift towards design of CAD systems that cover a broad range of abnormalities like vascular, ulcers, polyps, instead of a single or similar type of abnormalities. A brief overview of some of the existing methods is presented in Table 1, where we give details about the problem, feature extraction methods, classi­ fiers, and the performance of the methods on different metrics. It may be noticed that SVM, ANN, and, KNN have been the popular choices of classifiers for abnormal frame detection. Various feature extraction methods like speed-up robust feature (SURF) [15], color and word his­ tograms [24–27], local binary pattern (LBP) [6], Log-Gabor wavelet transform [28], and, gray level co-occurrence matrix (GLCM) [12] have been used for WCE image analysis. In the WCE images, color information plays a crucial role in identi­ fication of abnormality. For example, when bleeding images are to be identified, the Red channel in RGB space is more important over other channels. Al-Rahayfeh et al. [18] suggested range-ratio-color condition for classifying bleeding frames. They identified that bleeding regions contain pixels with higher red channel values and lower values of green and blue channels. Therefore, a range of pixel values in each channel was considered for the identification of bleeding locations with 98% accuracy. Similar to the range-ratio-color method, Kundu et al. [8] fetched region of interest (ROI) on normalized RGB planes for bleeding frame classification. Pixels were selected based on a linear separability condition between red, blue, and green planes. The histogram was then computed on extracted ROI and the bleeding frames were identified with 98.3% accuracy using KNN classifier. The images were extracted from videos provided by Medtronic [29]. Often the presence of noise in WCE images adversely affects accuracy of the system, based on individual pixel features which get distorted due to noise. To overcome this problem, Liu et al. [24] considered block-based color histogram features and used SVM classifier for the identification of abnormal images. Specificity and sensitivity were re­ ported to be 99% in Ref. [24]. Lv et al. [25] combined color and spatial information for extracting features using a pyramid of color invariant histograms over the HSI color space. They employed the whole image and its extracted features to identify bleeding images with an accuracy of 97.9% on dataset of videos [29]. The capability of method being invariant to light intensity was made possible with the help of hue channel of HSI color space. Ghosh et al. [14] have introduced the concept of color histogram of block statistics (CHOBS) that computes statistical features over blocks of pixels for creating histograms to identify bleeding images with an accuracy of 99.2% on the publicly available WCE video dataset provided by Medtronic [29]. Sainju et al. [26], extracted statistical features like mean, standard deviation, skew, and energy from each channel of the RGB color space of pixel intensities. Bleeding images were classified by calculating the first-order histogram yielding a classification accuracy of 89%. Yuan et al. [9] contemplated the idea of a word-based color histogram by applying k-means clustering on pixels of normal and abnormal images. Clusters were created using YCbCr color space representation of images. Individual pixels were then mapped to different clusters according to their distance with a cluster. The classification accuracy of 95.8% was reported by authors in Ref. [9] with 80 clusters. As this method involved clustering, the performance varied with cluster size in a convex fashion where optimal cluster size was determined and tuned. Histograms based on concrete color plane pixel values were common in all the aforementioned methods. Since different color models have their own advantages, WCE images have also been experimented by researchers using CMYK, HSI, YCbCr, and, CIE-Lab color space models ([9,15,17,25]). Iakovidis et al. [15], have employed image trans­ formation to CIE-Lab color space and applied SURF on color channels to select the salient points. The minimum and the maximum values of each color component are calculated over a square neighborhood of salient pixels for extraction of features. An average value of 89.2% of the Area under Curve (AUC) was reported in Ref. [15] with a minimum AUC of 69.9% in case of angiectasias on KID Dataset 1 [30]. A customized color model close to the CMYK color model was devised by Novozamsky et al. S. Jain et al. Computers in Biology and Medicine 127 (2020) 104094 3 [17] in which, both color and spatial properties were adopted for the identification of bleeding images. They have achieved a true positive percentage of 98% in classifying bleeding images on a private dataset. For the identification of anomalies like ulcers, polyps, villous oedema, aphthae etc., textural features are quite useful, since some kind of abnormalities can only be identified using their texture. Color features of such abnormal regions in an image are quite like those of normal regions in some of the abnormalities. In view of this many researchers have considered a combination of color and textural features for WCE image and video analysis. Meng et al. [6] have dealt with the problem of differentiating normal images from bleeding images by exploiting LBP as the textural feature extractor. These LBP features alongwith with the chrominance moments extracted from the HSI color plane were used to classify abnormal WCE images. Classification performance was evalu­ ated with zeroth, first, and second-order chrominance moments and the authors have reported that the zero-order chrominance moment pro­ vided the highest accuracy of 92.4% on a private WCE dataset provided by Prince of Wales Hospital, Hong Kong. Karkanis et al. [7] employed the wavelet transformation of second-order statistics on each WCE image for the extraction of texture features to detect polyps where 97.2% accuracy was yielded. When the WCE capsule travels through the digestive tract, there is a possibility of lower luminance which affects the quality of the WCE image. This problem was addressed by Chen et al. in Ref. [28], where the Log-Gabor wavelet transform was applied to rectify the problem of non-uniform luminance. In addition to the Log-Gabor Table 1 A brief overview of state-of-the-art methods for detecting abnormality in WCE images. Authors Purpose Feature Extraction Method ML classifier Classification Results Karkanis et al. [7], 2001 Lesion detection Statistical information of second order discrete wavelet transform ANN Accuracy: 95.50% Liu et al. [34], 2008 Bleeding detection Raw color pixel values SVM Sensitivity: 99.64%, Specificity: 99.58% Li et al. [6], 2009 Bleeding detection Chrominance moment and LBP is computed in HSI color space ANN Accuracy: 92.40%, Sensitivity: 93.20%, Specificity: 91.60% Al-Ryalfeh et al. [18], 2010 Bleeding detection Range of color pixel values and ratio of them Pixel count as threshold Accuracy: 98.00% Lv at al. [25], 2011 Bleeding detection Pyramid of color invariant histogram SVM Accuracy: 97.90%, Sensitivity: 97.80%, Specificity: 98.00% Sainju et al. [26], 2013 Bleeding detection Histogram Probability ANN Accuracy: 89.00% Iakovidis et al. [15], 2014 Lesion detection WCE images are converted into CIE-Lab color space and salient points are extracted using speedup robust features (SURF) method SVM Accuracy: 94.50%, Sensitivity: 96.00%, Specificity: 84.60% Yuan et al. [9], 2015 Bleeding detection Histogram on bag-of-visual- words using K- size color clusters KNN Accuracy: 95.75%, Sensitivity: 92.00%, Specificity: 96.50% Novozamsky et al. [17], 2016 Bleeding detection Threshold set on pixel values based on new color model close to CMYK color model in which red color is enhanced Threshold on pixel count TP:96.41%, FP:21.81% Jia et al. [31], 2017 Bleeding detection CNN combined with handcrafted (HC) features in which histogram is computed over the count of pixels in each centroid when the image pixels are clustered using K-means clustering algorithm Softmax Recall: 91.00%, Precision: 94.79%, F1- score: 92.85% Chen et al. [28], 2017 Bleeding detection Log-gabor filter bank, histogram and color features SVM Accuracy: 98.97%, Sensitivity: 94.07%, Specificity: 99.15% Yuan et al. [16], 2017 Polyp detection Sparse autoencoder Softmax Accuracy: 98.17% Table 1 (continued) Authors Purpose Feature Extraction Method ML classifier Classification Results with hybrid loss function employing KL divergence with an image manifold constraint. Kundu et al. [8], 2018 Bleeding detection Histogram computed over normalized green planes KNN Accuracy: 97.86%, Sensitivity: 95.20%, Specificity: 98.32% Iakovidis et al. [10], 2018 Anomaly detection 5-layer CNN, Activation Maps CNN Accuracy: 89.90%, Sensitivity: 90.70%, Specificity: 88.20% Sadasivan et al. [13], 2019 Anomaly detection A CNN trained on normal and abnormal patches of size 64 × 64 obtained from WCE images of size 320 × 320 CNN AUC: 95.36% Xiao et al. [11], 2020 Lesion detection CNN based object detection using YOLOv3 network. Softmax (CNN) Mean Average Precision (mAP): 93.50% Khan et al. [12], 2020 Ulcer and bleeding detection CNN with transfer learning on VGG-16 and GLCM which are fused and relevant features are selected by applying particle swarm optimization technique. Cubic SVM Accuracy: 98.40%, Sensitivity: 98.33%, Precision: 98.36%, F1- score: 98.34%, AUC: 100% S. Jain et al. Computers in Biology and Medicine 127 (2020) 104094 4 filter, gray-level histogram and color features were combined for the detection of bleeding as an abnormality which reached to classification accuracy of 98.97% where the WCE dataset was provided by Ankon Incorporation, Wuhan, China. Devising algorithms to extract features need thorough knowledge about the behavior of abnormalities which sometimes becomes difficult if some of the observations are missed. It can be reduced if an algorithm is capable of extracting the features automatically. In the last decade deep learning has become very popular due to its outstanding performance in some of the most challenging computer vision tasks. Deep learning is a kind of representation learning in which data features are extracted automatically. Due to huge success of deep learning in other domains, it has attracted the attention of people working on WCE image and video analysis too. Convolutional neural networks (CNNs), which are the basic building blocks of deep learning algorithms, have been proposed by many researchers for accurate clas­ sification of WCE images (see, e.g. Refs. [19,20,31], and references therein). However, the current deep learning algorithms face challenge if the datasets are small and imbalance, which is the case with WCE image datasets. As a result, CNNs often get trapped in overfitting, and do not generalize well [32,33]. Nonetheless, deep learning architectures are being explored in the WCE image and video analytics and some promising results have been reported recently [10,11,13]. The related work discussed above manifest the importance of color and texture features for WCE image analysis in the block based approach. The present work, focuses on efficient feature extraction using the concept of DBC based FD on blocks of WCE images, computed over the individual color channel, exploiting both color and textural (FD) information. The problem of highly imbalanced small dataset is also addressed by applying the well known SMOTE method for data augmentation. It is worthwhile to mention that the proposed method covers a broad range of abnormalities in WCE images and can classify abnormal images with high accuracy and, AUC. In the next section, the proposed method is discussed in detail. 3. Methodology In this section, a method is proposed for abnormality detection in WCE images using FD and RF algorithm. The choice of machine learning classification algorithm is based on an empirical study with six different ML algorithms on two different datasets, one of which is a publicly available dataset, namely KID dataset [30] and the other being private dataset [17]. Each algorithm uses the FD of image pixel blocks and the best performing method is chosen for abnormality detection in WCE images. To begin our discussion on the methodology of the proposed work, we first give a brief introduction to the concept of FD in the context of images. 3.1. Fractal dimension FD has been an active research topic over the past decades owing to its noticeable applications such as texture segmentation [35], bio-metrics [36,37], cancer diagnosis [38], pattern recognition [39], MRI image analysis [40], image fusion [21,41] and others [42]. FD measures the self-similar contents of an image [43]. One may notice that abnormalities in WCE images are complex objects with varying shapes, sizes, color, and textures. Moreover, anomalies are highly irregular natural shapes which can be correlated with fractal features (see Fig. 4). There exist many methods in the literature to measure the FD of images. The DBC method is one of the most frequently deployed methods due to its simplicity and computational efficiency [44]. The DBC method was introduced by Sarkar et al. [44] to estimate the FD of a gray-scale image. According to the DBC method, FD Fd(K) of a fractal set K is defined in an n-dimensional Euclidean space by Eq. (1). Fd(K) = log(Bs) log(1/s), (1) such that s ∕= 1 and Bs is the number of boxes at scale s required to cover the fractal set K. An image I of size N × N is mapped into three- dimensional space as shown in Fig. 1, where x − coordinate and y − coordinate are used to denote the dimensions of I while z − coordinate represents the gray-level intensity of I. The image plane is divided into non-overlapping grids of size g × g pixels. Here, g is an integer and it varies from 2 to N/2. If g is not divisible by N then zeros are padded in the boundary of I. A grid s will have a scale of value g/N. Let bs be the number of boxes of size g × g × h each representing gray-level variations of a particular grid, where h is the height which can be calculated using Eq. (2).where Q is the total number of gray-levels. Let qmax and qmin be the maximum and the minimum intensity values of the (i, j)th grid respectively. The number of boxes bs(i, j) required to cover the (i, j)th grid can be computed using Eq. (3). bs(i, j) = ⌈qmax h ⌉ − ⌈qmin h ⌉ + 1, (3) where ⌈ qmax h ⌉ and ⌈ qmin h ⌉ denote the box numbers containing the maximum and minimum gray-levels on the (i, j)th grid respectively. Therefore, the total count of boxes termed as Bs at scale s can be calculated using Eq. (4). Bs(i, j) = ∑ i,j bs(i, j), (4) where Bs represents the surface roughness in image I. Now, FD of I is the slope of the line obtained by fitting the points ( log ( 1 s ) , log(Bs) ) ∀s using linear least squares regression (LLS). Since the value of FD is a scalar quantity, it may not be sufficient to use as a feature for a classification problem. In the present paper, an image is divided into square pixel Fig. 1. A sketch showing corresponding a grid with computable parameters to find the number of boxes using DBC method. h = gQ N , (2) S. Jain et al. Computers in Biology and Medicine 127 (2020) 104094 5 blocks of equal size and instead of considering the value of FD as a feature, the number of boxes bs of each block s in an image I are used as features for the identification of abnormal images. Several methods [35, 43,45–51] exist in literature to estimate FD of an image and each has its own merits and limitations. A brief overview of some of these methods is reported in Table 2. For more details on DBC based FD estimation methods, interested readers are referred to Ref. [42]. 3.2. Proposed method A schematic block diagram of the proposed CAD system is shown in Fig. 2. As shown in the figure, the proposed method consists of two steps: feature extraction and classification. Class balancing is performed on the dataset containing extracted features after the first step. In the first step, R, G, B, and L channels are extracted from WCE images. The L channel is obtained by converting the RGB color image into its CIE-Lab color space representation [52]. Then a DBC method is applied on the blocks extracted from each channel to extricate features. To select a suitable DBC based FD estimation method for WCE images, eight different DBC based FD methods listed in Table 2 are initially chosen and their per­ formances are compared on two WCE image datasets used in the present work. The best performing DBC method given in Ref. [43] is selected for FD feature computation in the present study (see Tables 3–6). In color theory, the lightness component also known as a tone represents the brightness of color in an image. It is used as one of the color appearance parameters. In relation to GI anomalies, the lightness component plays an important role since some anomalies are very close to normal regions in the case when color is used as a discriminator. For example, light red color in the intestinal walls may represent normal regions whereas dark red gives a clue of a bleeding spot. Since RGB models do not have an explicit lightness component where color integrants are dissociated from luminance components and they struggle to give information related to luminosity [21]. The L channel in CIE-Lab color space is employed to extract the lightness component (luminosity) by converting the image from RGB to CIE-Lab. It may also be mentioned that the L channel is also close to human vision. Since a and b channels of CIE-Lab color space also describe the color, they are ignored. In the second step, the set of extracted block features is split into train and test subsets. Similar to the selection of the most suited DBC method for feature extraction, a classifier is selected by evaluating the performance of six most frequently used classification methods on the WCE dataset. The best performing classifier is observed to be RF clas­ sifier (see Tables 3–6). The proposed ML model is trained, tested, and finally deployed for WCE image analysis. We now proceed to discuss the proposed feature extraction algorithm in detail. Algorithm 1 takes as an input, an RGB image IN×N and produces a feature vector F1×v, where v is the total number of blocks obtained from the R, G, B and L channels of the image. Each channel block is of size g × g. The DBC or number of boxes bs in each block is computed by Eq. (3). Finally, all the features obtained from each channel are concatenated to form a feature vector F (F1×v), which is fed into ML algorithms. Algorithm 1. Extraction of fractal features (EFF) algorithm. 3.3. Synthetic minority oversampling technique The WCE datasets considered in this work are highly imbalanced and biased towards normal images. Therefore, if we apply ML algorithms on an imbalanced dataset, classification results will be inclined towards the majority class. So, in this case, the classifier will classify abnormal im­ ages as normal and will falsely result in overall high accuracy. This problem can be solved by either oversampling minority class or by under-sampling majority class in-order to balance the number of sam­ ples in each class. SMOTE [22] uses an oversampling technique by generating auxiliary samples of minority class from real instances through a linear combination of two similar samples using the nearest neighbor and structural similarity index. So, we can prevent over-fitting and generalize the results. In this work, the SMOTE considers SVM with linear kernel and 5 nearest neighbours while augmenting data of the minority class. 3.4. Machine learning algorithms Generally, it is a tedious task to select an ML algorithm, which best suits the data. In this study, six ML algorithms namely KNN [53], SVM [54], ELM [55,56], NB [57], DT [58], RF [59–61] are adopted and their performances are evaluated on WCE image datasets. Each classifier is tuned in such a way that it can give its best performance. The KNN al­ gorithm depends on a user defined number k and finding a suitable value of k is a difficult task if it is not known a-priori. In this study, the value of k is determined experimentally. SVM with linear and cubic polynomial Table 2 DBC methods and corresponding parameters. Methods Block size Box height Box-count in (i,j)th grid DBC [44] N 2 gQ N ⌈qmax h ⌉ − ⌈qmin h ⌉ + 1 RDBC [45] ⌈N g ⌉ + 1 ≤− ⌈N g −1 ⌉ gQ N ⌈qmax −qmin h ⌉ SDBC [46] N 2 S ⌈qmax −qmin + 1 h ⌉ DBC, Li [47] N 2 g −1 0.5(Imax −Imin) ⎧ ⎨ ⎩ ⌈qmax −qmin h ⌉ ifqmax ∕= qmin 1 ifqmax = qmin DBC, Li [48] g −1 2 gQ N ⌈qmax −qmin h ⌉ DBC, Liu [49] N 2 gQ N ⎧ ⎨ ⎩ ⌈qmax −qmin + 1 h ⌉ ifqmax ∕= qmin 1 ifqmax = qmin DBC, Lai [50] N 2 g(Imax −Imin + 1) N ⎧ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎩ ⌈qmax −qmin + 1 h ⌉ ifqmax ∕= qmin 1 ifqmax = qmin ∕= 0 0 ifqmax = qmin = 0 DBC, Panigrahy [43] N 2 2g N ⌈qtmax −qtmin + 1 h ⌉ ip g(g + 1)/2 , where, ip is number of pixels grid S. Jain et al. Computers in Biology and Medicine 127 (2020) 104094 6 kernels were initially evaluated and the cubic SVM is selected due to its better performance. The regularization parameter c, in the SVM is set to 1 with a squared L2 penalty term in order to avoid over-fitting. Gener­ ally, a lower c value makes the decision surface smoother while a higher c value helps in better classification. The ELM is implemented with 10 neurons in its hidden layer and tanh activation function with a logistic regressor exploited for classification. NB classifiers differ mainly by the assumptions that they make regarding the distribution of features. In this study, the Gaussian NB classifier with normal distribution is used after transforming the features into a normal distribution. In this work, for implementing the DT, Gini [62] index is adopted as a measure of impurity for classification. The Gini impurity gives nearly the same Fig. 2. A Schematic block diagram representing the proposed methodology for WCE image classification. Table 3 Accuracy scored in different DBC methods using various classifiers for abnormal WCE image detection. Methods Dataset-I Dataset-II ELM KNN NB DT SVM RF ELM KNN NB DT SVM RF DBC [44] 0.52 0.58 0.52 0.76 0.80 0.83 0.47 0.68 0.70 0.89 0.98 0.98 RDBC [45] 0.57 0.60 0.54 0.76 0.80 0.84 0.48 0.69 0.70 0.90 0.98 0.98 SDBC [46] 0.58 0.60 0.68 0.71 0.80 0.83 0.50 0.71 0.70 0.90 0.98 0.97 DBC, Li [47] 0.58 0.59 0.63 0.71 0.79 0.84 0.49 0.68 0.73 0.91 0.97 0.99 DBC, Li [48] 0.55 0.48 0.64 0.72 0.79 0.83 0.50 0.69 0.73 0.90 0.98 0.98 DBC, Liu [49] 0.57 0.59 0.64 0.70 0.79 0.83 0.47 0.69 0.72 0.95 0.98 0.99 DBC, Lai [50] 0.54 0.61 0.64 0.71 0.76 0.81 0.49 0.68 0.70 0.91 0.98 0.98 DBC, Panigrahy [43] 0.60 0.58 0.58 0.75 0.80 0.85 0.50 0.70 0.70 0.91 0.98 0.99 S. Jain et al. Computers in Biology and Medicine 127 (2020) 104094 7 results as entropy gives, however, Gini is faster than entropy. The maximum depth of tree is taken as 50 which is determined experimen­ tally that best suits the given dataset. Since the RF uses DTs, the Gini index is again employed for all its material advantages. The maximum depth of each DT is not fixed and maximum number estimators (DT) are taken as 500, which are decided by trial and error method. 4. Experimental results and discussion 4.1. Environment setting The proposed work is implemented in Python language using the Anaconda environment installed on Windows 10. The system is coupled with 8 GB of RAM and Intel Core i7 4th generation CPU. 4.2. Dataset description In this study, one publicly available benchmark dataset [30] and one private dataset [17] are adopted to evaluate the proposed method. Both the datasets are referred to as Dataset-I and Dataset-II. A brief descrip­ tion of each of these datasets is as follows: 4.2.1. Dataset-I Dataset-I is also known as KID and it consists of images and videos. In the present work, only images are considered. In this dataset, all the images are of size 360 × 360 pixels, acquired by MicroCam sensor [10] in RGB color space. The Dataset-I is further divided into KID Dataset 1 [15] and KID Dataset 2 [10]. On the one hand, KID Dataset 1 contains 77 images covering abnormalities like angioectasias, aphthae, chylous cysts, polypoid lesions, villous oedema, bleeding, lymphangiectasias, ulcers, and stenoses. While, KID Dataset 2 [10], consists of 2371 images of miscellaneous findings of polypoid, vascular and, inflammatory le­ sions, and normal images of esophagus, stomach, small bowel, and colon. Therefore, a total of 670 abnormal and 1778 normal images are considered in this study. After removing unwanted black borders the size of images reduces to 320 × 320 pixels. 4.2.2. Dataset-II Dataset-II consists of 37 WCE videos in which 21 videos are of pa­ tients with abnormal findings whereas 16 videos are related to the subjects with normal findings evaluated by an experienced physician. Initially, frames are separated from all the videos to create a WCE image dataset. Out of these frames, 309 images are selected and labeled as abnormal depending upon the ground truths available with every video file whereas 2063 images are labeled as normal. Each image is an RGB color image of size 288 × 288 pixels. The WCE apparatus employed while creating this dataset is EndoCapsule developed by Olympus which produces frames at the rate of 2fps [17]. Anomalies such as lipoma (9), xanthoma (3), erosion (26), ulcer (149), aphthous lesions (23), ery­ thema (61), villious (29), and bleeding (9) are covered in the dataset Table 4 Precision scored in different DBC methods through various classifiers in abnormal WCE image detection. Methods Dataset-I Dataset-II ELM KNN NB DT SVM RF ELM KNN NB DT SVM RF DBC [44] 0.51 0.70 0.68 0.77 0.82 0.83 0.48 0.80 0.72 0.89 0.98 0.98 RDBC [45] 0.58 0.73 0.63 0.76 0.82 0.85 0.48 0.80 0.73 0.91 0.98 0.98 SDBC [46] 0.60 0.72 0.68 0.70 0.82 0.83 0.50 0.80 0.71 0.90 0.98 0.97 DBC, Li [47] 0.58 0.71 0.63 0.72 0.81 0.83 0.49 0.80 0.75 0.90 0.98 0.99 DBC, Li [48] 0.54 0.69 0.64 0.73 0.81 0.84 0.50 0.80 0.75 0.90 0.98 0.98 DBC, Liu [49] 0.57 0.72 0.66 0.71 0.81 0.84 0.47 0.80 0.74 0.91 0.98 0.99 DBC, Lai [50] 0.54 0.72 0.66 0.71 0.78 0.82 0.49 0.80 0.72 0.91 0.98 0.98 DBC, Panigrahy [43] 0.61 0.71 0.63 0.75 0.82 0.86 0.66 0.81 0.75 0.91 0.98 0.99 Table 5 Recall scored in different DBC methods with various classifiers in abnormal WCE image detection. Methods Dataset-I Dataset-II ELM KNN NB DT SVM RF ELM KNN NB DT SVM RF DBC [44] 0.51 0.58 0.52 0.76 0.79 0.83 0.48 0.68 0.70 0.89 0.98 0.98 RDBC [45] 0.56 0.61 0.54 0.76 0.80 0.84 0.48 0.69 0.70 0.90 0.98 0.98 SDBC [46] 0.58 0.60 0.67 0.71 0.79 0.83 0.50 0.70 0.70 0.90 0.98 0.97 DBC, Li [47] 0.58 0.58 0.63 0.71 0.79 0.84 0.50 0.68 0.73 0.90 0.97 0.99 DBC, Li [48] 0.57 0.58 0.64 0.74 0.81 0.82 0.51 0.69 0.73 0.90 0.98 0.98 DBC, Liu [49] 0.56 0.59 0.64 0.71 0.80 0.83 0.47 0.68 0.72 0.91 0.98 0.99 DBC, Lai [50] 0.54 0.61 0.64 0.71 0.76 0.81 0.49 0.68 0.71 0.91 0.98 0.98 DBC, Panigrahy [43] 0.60 0.58 0.57 0.75 0.80 0.85 0.49 0.70 0.70 0.91 0.98 0.99 Table 6 F1-score obtained from different DBC methods on various classifiers in abnormal WCE image detection. Methods Dataset-I Dataset-II ELM KNN NB DT SVM RF ELM KNN NB DT SVM RF DBC [44] 0.51 0.63 0.42 0.77 0.80 0.83 0.48 0.68 0.69 0.89 0.98 0.98 RDBC [45] 0.56 0.66 0.44 0.76 0.81 0.84 0.48 0.69 0.69 0.90 0.98 0.98 SDBC [46] 0.56 0.53 0.68 0.70 0.80 0.83 0.50 0.66 0.69 0.90 0.98 0.97 DBC, Li [47] 0.58 0.52 0.63 0.71 0.79 0.83 0.50 0.65 0.72 0.90 0.98 0.99 DBC, Li [48] 0.55 0.53 0.65 0.73 0.81 0.83 0.50 0.65 0.72 0.90 0.98 0.98 DBC, Liu [49] 0.56 0.52 0.64 0.71 0.80 0.83 0.46 0.65 0.71 0.91 0.98 0.99 DBC, Lai [50] 0.53 0.54 0.63 0.71 0.76 0.81 0.48 0.64 0.70 0.91 0.98 0.98 DBC, Panigrahy [43] 0.60 0.50 0.54 0.75 0.80 0.85 0.48 0.66 0.69 0.91 0.98 0.99 S. Jain et al. Computers in Biology and Medicine 127 (2020) 104094 8 where the number inside parenthesis denotes the number of images of a particular anomaly. All the experiments are performed on both the datasets separately. Each dataset is randomly divided into train and test sets in a ratio of 80 : 20. The datasets are biased towards normal images as the count of normal images are more than abnormal images. Thus, class balancing is needed otherwise, results will get affected more by the class with normal images. Therefore features of the abnormal class are over-sampled to match with the number of features of normal images using SMOTE [22]. 4.3. Evaluation metrics In this work, the classification performance of the proposed method is done based on a standard metric named accuracy [63–65]. Accuracy measures the ratio of correct predictions over all predictions. Mathe­ matically, it is defined by Eq. (5). Accuracy = TP + TN TP + FP + TN + FN, (5) where TP, TN, FP, and FN denote true positive, true negative, false positive, and false negative predictions respectively. However, accuracy is not enough due to the accuracy paradox [63]. So, other metrics namely, precision, recall, and F1-score are also considered in this study, which are computed by Eqs. (6)–(8) respectively. Precision = TP TP + FP (6) Recall = TP TP + FN (7) F1 −score = 2 × Precision × Recall Precision + Recall (8) Precision quantifies the fraction of actual over predicted positive images whereas recall is the fraction of actual abnormal images over correctly classified abnormal images. Moreover, F1-score provides a single score that balances both the concerns of precision and recall. The classification performance is also tested using area under the receiver operating characteristic curves (AUC). The receiver operating charac­ teristic (ROC) curve depicts the relationship between specificity and sensitivity and also we can find the relative trade-offs between true positive rates (TPR) and false positive rates (FPR). AUC is scale-invariant and it does not consider the classification threshold. Since, AUC gives a probabilistic value that a random positive sample is ranked higher than a negative sample, therefore, higher AUC is always desirable. 4.4. Results and comparison In this study, a total of 7 experiments are conducted. In the first experiment, all the DBC methods mentioned in Table 2 are implemented on the datasets for extracting features, which are fed into the ML algo­ rithms namely, KNN, SVM, ELM, NB, DT, and RF separately. The per­ formances of state-of-the-art DBC methods are computed using four evaluation metrics namely, accuracy, precision, recall, and F1-score discussed in Section 4.3. Values of these metrics obtained by applying various DBC methods are reported in Tables 3–6 respectively. It is clear from Tables 3–6 that the improved DBC method devised by Panigrahy et al. [43] with RF classifier yields the highest accuracy of 85% and 99% when compared with other DBC methods in both the datasets. Hence, this method is preferred for the extraction of fractal features in the proposed method. Moreover, it can be deduced from the results that the RF outperforms all the other classifiers considered in the study whereas the SVM performs marginally lower than RF. In this study, RF is the only ensemble classifier that is considered. It utilizes unpruned DTs as weak classifiers. The DTs take data samples as inputs and produce the results independently. Then, the mode of outputs of each of these DTs is considered as final. Since, DTs lag in giving good results due to over­ fitting raised during training, RF mitigates this problem by averaging the result produced by DT. Probably this might be the reason for better performance of RF. In the second experiment, the proposed method paired with the RF S. Jain et al. Computers in Biology and Medicine 127 (2020) 104094 9 classifier is also tested on RGB, HSV, CIE-Lab, and the adopted hybrid color spaces and the obtained results are shown in Fig. 3. It is observed from Fig. 3 that converting the WCE image originally in RGB plane to HSV and CIE-Lab spaces are giving better results, however, the perfor­ mance is even better when the L channel is integrated with RGB color space achieving the highest AUC of 85% and 99% on Dataset-I and Dataset-II respectively. When the HSV color space is considered, 83% and 97% AUCs are reached on the Dataset-I and Dataset-II respectively. However, the results obtained using HSV and CIE-Lab color spaces are almost identical. As features are extracted in block-wise fashion, it is necessary to find the block size for which extracted features give the best classification results. In the third experiment, features are computed by applying the proposed technique on different block sizes varying from 3 to 13 with a step size of 2 while keeping an eye on the performance in terms of ac­ curacy. Block size greater than 13 does not seem to be lucrative since the contribution of pixels belonging to abnormal regions of smaller size may be ignored in the larger block size. The performance of the proposed method with respect to the block size is shown in Table 7. It is clear from the table that features extracted with the block size of 7 give the best result in both the datasets, although marginally. Table 8 shows the size of each image in pixels, the length of a feature vector of each channel in an image, the total length of a feature vector of four channels, and the number of normal and abnormal images in both the datasets. Table 9 reports the size of the feature matrices of both the datasets before and after data augmentation using SMOTE. To test the effect of SMOTE, the proposed method is evaluated with and without applying SMOTE on the extracted features. The results reported in Table 10 show that the performance of the proposed model is better in both the datasets when the SMOTE is utilized. This is the fourth exper­ iment in the series of experiments performed in the present study. In the fifth experiment, the proposed method is compared with six state-of-the-art methods namely, Range Ratios Color [8], Raw Histo­ gram [24], CHOBS [14], Color histogram [26], and weak CNN [10]. The performances of these methods are reported in Table 11. 5-fold cross-validation is performed to ensure that the results are not biased with respect to the choice of samples in training and testing sets. The Fig. 3. Performance of the proposed method on different color spaces and suggested a combination of RGB with L on the Dataset-I and the Dataset-II. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) Table 7 Effect of block size on accuracy score of the proposed method in Dataset-I and Dataset-II. Block size Dataset-I Dataset-II 3 × 3 0.838 0.991 5 × 5 0.826 0.985 7 × 7 0.850 0.992 9 × 9 0.833 0.985 11 × 11 0.841 0.990 13 × 13 0.845 0.987 The best classification results are highlighted by the bold characters. Table 8 The length of the feature vector of both the datasets before applying SMOTE. Dataset Image size in Length of a feature vector Length of a feature vector Number of normal/ pixels of each channel of four channels abnormal WCE images Dataset- I 320 × 320 × 3 2025 8100 1776/670 Dataset- II 288 × 288 × 3 1681 6724 2063/309 Table 9 The size of the feature matrices of both the datasets before and after data augmentation using SMOTE. Dataset-I Dataset-II Feature matrix of Feature matrix of Feature matrix of Feature matrix of normal images abnormal images normal images abnormal images Before applying SMOTE 1776 × 8100 670 × 8100 1776 × 8100 1776 × 8100 After applying SMOTE 2063 × 6724 309 × 6724 2063 × 6724 2063 × 6724 Table 10 Comparing performance of the proposed technique with and without applying SMOTE on computed features. Metrics With SMOTE Without SMOTE Dataset-I Dataset-II Dataset-I Dataset-II Accuracy 0.85 0.99 0.74 0.92 Precision 0.86 0.99 0.68 0.93 Recall 0.85 0.99 0.74 0.92 F1-score 0.85 0.99 0.66 0.90 AUC 0.85 0.99 0.52 0.69 Table 11 Classification results of the proposed method with other state-of-the-art methods. Features Dataset-I Dataset-II Accuracy F1- score AUC Accuracy F1- score AUC Range Ratios Color [8] 0.65 0.42 0.53 0.85 0.79 0.80 Raw histogram [24] 0.73 0.61 0.50 0.92 0.90 0.72 Bag of Words [9] 0.80 0.79 0.79 0.91 0.89 0.85 CHOBS [14] 0.73 0.72 0.66 0.97 0.96 0.92 Weak CNN [10] 0.82 0.87 0.85 0.97 0.96 0.97 Proposed Method 0.85 0.84 0.85 0.99 0.99 0.99 The best classification results are highlighted by the bold characters. S. Jain et al. Computers in Biology and Medicine 127 (2020) 104094 10 proposed method demonstrates superior performance in terms of accu­ racy when compared with all state-of-the-art methods. However, the weak CNN, introduced by Iakovidis et al. [10] performs better than the proposed method on Dataset-I, in terms of F1-score and AUC. The Weak CNN introduced by Iakovidis et al. [10] contains five convolution layers such that the first four layers are followed by a max-pool layer each and the last one is followed by three fully connected layers. The last layer is the classification layer that uses a softmax classifier for identification of abnormal images. Nonetheless, the proposed method is observed to be better than Weak CNN [10] on Dataset-II with respect to all the three measures and on Dataset-I with respect to accuracy. To check if the difference in the performance is significant, Student’s t-Test is per­ formed which is detailed as follows. In the sixth experiment, the Student’s t-Test [66] is performed on the accuracy scores of the proposed method and the Weak CNN introduced in Ref. [10] to find out if the difference in the accuracy scores of the two methods is significant. Accuracy is recorded on ten rounds of experi­ ments using the test datasets and statistical values like mean, variance, and the standard deviation of accuracy scores are computed, which are listed in Table 12. After the application of the t-test, the p-value comes out to be close to 0 in Dataset-I whereas it is near to 0.005 in Dataset-II as listed in Table 13. This indicates that there is 0% and less than 0.5% percent chance of getting the same results from both the methods on Dataset-I and Dataset-II respectively. Accurate identification of texture patterns plays an important role in detection of abnormalities in WCE images. Some of the existing textural descriptors like Haralick features [67], LBP [68] and KAZE features [69] have demonstrated their capabilities in many computer vision problems including those in biomedical imaging. In view of this, a comparison of the proposed method is made with the above three feature descriptors keeping RF as the classifier. Results of this seventh experiment are presented in Table 14. This shows that the proposed DBC based FD features performs better on both the datasets. 4.5. Discussion The results presented in the previous section demonstrate that the proposed method performs better than some of the existing methods on both the datasets. Fig. 4 shows the visualization of features representing abnormalities in images using the extracted features with the blocks size of 7 × 7. Here the example image A from the Dataset-II is of size 288 × 288 × 3. A is transformed into a 41 × 41 image named B which is the visualization of feature vector representing the differential box counts of R channel in A. It may be noted that distinct colors are assigned to different pixel values. It may be observed that the regions where a pa­ thology exists in image A, can be distinctly seen in B which are repre­ sented as pixels having values equal to the box-count of a block in the corresponding region of the original image. It is observed that abnormal regions normally lead to greater box height producing larger box-count values. This distinctive capability of the feature extractor is possibly a reason for better performance of the proposed method. Although classification accuracy of the proposed method is high close to 99% in Dataset-II, there is always a possibility of getting FP and TN results. Fig. 5 gives FP and TP classification results of sixteen randomly selected samples from normal and abnormal images of Dataset-II, as produced by the proposed method. The FP results are investigated for the identification of the reason behind inaccurate results on the application of the proposed method. It is observed that some normal regions have a texture similar to abnormal regions therefore few normal images are falsely classified as abnormal under FP of a normal category. Since the size of an abnormality can be either very small especially when it is read inside 7 × 7 windows, the contribution of the anomalous features will be negligible which falsely makes an abnormal image predicted as normal. As the image is divided into blocks, pixels containing abnormality may get distributed into more than one block and the blocks in the boundary of abnormality can generate features defining normal regions. Probably these reasons are responsible for the prediction of false positive results. 5. Conclusion In this study, a relatively new approach for detection of abnormality in WCE images is discussed. Instead of considering global features, this work focuses on block-wise local features. The local features are extracted from four color channels of each image by the DBC based FD method introduced in Refs. [43]. The SMOTE is adopted to overcome the Table 12 Statistical values computed on accuracy scores recorded on 10 rounds of WCNN [10] and the proposed method. Metrics WCNN [10] Proposed Method Mean Variance Standard Deviation Mean Variance Standard Deviation Dataset- I 0.78 7.6 × 10−5 0.009 0.84 1.6 × 10−5 0.004 Dataset- II 0.97 6.5 × 10−5 0.004 0.98 2.5 × 10−5 0.005 Table 13 Student’s t-Test results on accuracy scores of the proposed method and Weak CNN [10]. Dataset t-statistic p-value Dataset-I − 18.77 2.89 × 10−13 Dataset-II − 3.16 5.39 × 10−3 Table 14 Comparison of the proposed method with other textural feature descriptors. Features Dataset-I Dataset-II Accuracy F1- score AUC Accuracy F1- score AUC Haralick [67] 0.77 0.78 0.77 0.94 0.94 0.93 LBP [68] 0.82 0.82 0.83 0.96 0.97 0.96 KAZE [69] 0.72 0.60 0.65 0.86 0.80 0.85 Proposed Method 0.85 0.85 0.85 0.99 0.98 0.99 Fig. 4. An example of WCE image with its corresponding features. (A) A 288 × 288 × 3 WCE image containing abnormal findings. (B) A 41 × 41 image rep­ resenting features computed from DBC method on R channel of image A con­ verted into an image for visualization. Bold lines showing correlation of abnormalities in A with pixels representing box-count in B highlighted with light blue color. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) S. Jain et al. Computers in Biology and Medicine 127 (2020) 104094 11 high imbalance problem. The experimental results illustrate that the proposed method outperforms some of the state-of-the-art methods in terms of accuracy, and F1-score when the block size is 7. These datasets are small and highly imbalanced, it would be good to test the proposed method on other datasets as well. As a future work, we aim to tackle localization of abnormality and not only detecting the presence of it. Declaration of competing interest The authors declare no conflict of interest. Acknowledgment The authors would like to express their sincere thanks to the anon­ ymous reviewers whose comments and suggestions have helped in improving the quality of the paper. This work is partially supported by the project “Prediction of diseases through computer assisted diagnosis system using images captured by minimally-invasive and non-invasive modalities”, Computer Science and Engineering, PDPM Indian Insti­ tute of Information Technology, Design and Manufacturing, Jabalpur India (under ID: SPARC-MHRD-231). This work is also partially sup­ ported by the project IT4Neuro(degeneration), reg. nr. CZ.02.1.01/0.0/ 0.0/18_069/0010054 and by the project “Smart Solutions in Ubiquitous Computing Environments”, Grant Agency of Excellence, University of Hradec Kralove, Faculty of Informatics and Management, Czech Re­ public (under ID: UHK-FIM-GE-2020). Appendix A. Supplementary data Supplementary data to this article can be found online at org/10.1016/j.compbiomed.2020.104094. References [1] F. Gong, C. Swain, T. Mills, An endorobot for gastrointestinal endoscopy, Gut 35 (1994) S52. [2] G. Iddan, G. Meron, A. Glukhovsky, P. Swain, Wireless capsule endoscopy, Nature 405 (6785) (2000), 417–417. [3] M. Mylonaki, A. Fritscher-Ravens, P. Swain, Wireless capsule endoscopy: a comparison with push enteroscopy in patients with gastroscopy and colonoscopy negative gastrointestinal bleeding, Gut 52 (8) (2003) 1122–1126. [4] I. Tachecí, Kapslov´a Endoskopie, Nucleus HK, 2008. [5] A. Koulaouzidis, D.K. Iakovidis, A. Karargyris, J.N. Plevris, Optimizing lesion detection in small-bowel capsule endoscopy: from present problems to future solutions, Expet Rev. Gastroenterol. Hepatol. 9 (2) (2015) 217–235. [6] B. Li, M.Q.-H. Meng, Computer-aided detection of bleeding regions for capsule endoscopy images, IEEE Trans. Biomed. Eng. 56 (4) (2009) 1032–1039. [7] S.A. Karkanis, D.K. Iakovidis, D. Karras, D. Maroulis, Detection of lesions in endoscopic video using textural descriptors on wavelet domain supported by artificial neural network architectures, in: Proceedings 2001 International Conference on Image Processing (Cat. No. 01CH37205), vol. 2, IEEE, 2001, pp. 833–836. [8] A.K. Kundu, S.A. Fattah, M.N. Rizve, An automatic bleeding frame and region detection scheme for wireless capsule endoscopy videos based on interplane intensity variation profile in normalized rgb color space, J. Healthcare Eng. (2018), 9423062. [9] Y. Yuan, B. Li, M.Q.-H. Meng, Bleeding frame and region detection in the wireless capsule endoscopy video, IEEE J.Biomed. Health Inf. 20 (2) (2015) 624–630. [10] D.K. Iakovidis, S.V. Georgakopoulos, M. Vasilakakis, A. Koulaouzidis, V. P. Plagianakos, Detecting and locating gastrointestinal anomalies using deep learning and iterative cluster unification, IEEE Trans. Med. Imag. 37 (10) (2018) 2196–2210. [11] Z. Xiao, L.N. Feng, A study on wireless capsule endoscopy for small intestinal lesions detection based on deep learning target detection, IEEE Access 8 (2020) 159017–159026. [12] M.A. Khan, S. Kadry, M. Alhaisoni, Y. Nam, Y. Zhang, V. Rajinikanth, M.S. Sarfraz, Computer-aided gastrointestinal diseases analysis from wireless capsule endoscopy: a framework of best features selection, IEEE Access 8 (2020) 132850–132859. [13] V.S. Sadasivan, C.S. Seelamantula, High accuracy patch-level classification of wireless capsule endoscopy images using a convolutional neural network, in: 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), IEEE, 2019, pp. 96–99. [14] T. Ghosh, S.A. Fattah, K.A. Wahid, Chobs: color histogram of block statistics for automatic bleeding detection in wireless capsule endoscopy video, IEEE J.Transl. Eng. Health Med. 6 (2018) 1–12. [15] D.K. Iakovidis, A. Koulaouzidis, Automatic lesion detection in wireless capsule endoscopy––a simple solution for a complex problem, in: 2014 IEEE International Conference on Image Processing (ICIP), IEEE, 2014, pp. 2236–2240. [16] Y. Yuan, M.Q.-H. Meng, Deep learning for polyp recognition in wireless capsule endoscopy images, Med. Phys. 44 (4) (2017) 1379–1389. [17] A. Novoz´amskỳ, J. Flusser, I. Tachecí, L. Sulík, J. Bureˇs, O. Krejcar, Automatic blood detection in capsule endoscopy video, J. Biomed. Optic. 21 (12) (2016), 126007. [18] A. A. Al-Rahayfeh, A. A. Abuzneid, Detection of Bleeding in Wireless Capsule Endoscopy Images Using Range Ratio Color, arXiv preprint arXiv:1005.5439. Fig. 5. An illustration of correctly classified and mis-classified WCE images using the proposed method where blue ellipses show presence of abnormality in correctly classified abnormal images and red ellipses shows pathology in mis-classified abnormal images. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.) S. Jain et al. Computers in Biology and Medicine 127 (2020) 104094 12 [19] X. Jia, M.Q.-H. Meng, A deep convolutional neural network for bleeding detection in wireless capsule endoscopy images, in: 2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), IEEE, 2016, pp. 639–642. [20] A.K. Sekuboyina, S.T. Devarakonda, C.S. Seelamantula, A convolutional neural network approach for abnormality detection in wireless capsule endoscopy, in: 2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017), IEEE, 2017, pp. 1057–1060. [21] C. Panigrahy, A. Seal, N.K. Mahato, Fractal dimension of synthesized and natural color images in lab space, Pattern Anal. Appl. 23 (2) (2020) 819–836. [22] N.V. Chawla, K.W. Bowyer, L.O. Hall, W.P. Kegelmeyer, Smote: synthetic minority over-sampling technique, J. Artif. Intell. Res. 16 (2002) 321–357. [23] A.S. Ashour, N. Dey, W.S. Mohamed, J.G. Tromp, R.S. Sherratt, F. Shi, L. Moraru, Colored video analysis in wireless capsule endoscopy: a survey of state-of-the-art, Curr. Med. Imag. 16 (1) (2020). [24] J. Liu, X. Yuan, Obscure bleeding detection in endoscopy images using support vector machines, Optim. Eng. 10 (2) (2009) 289–299. [25] G. Lv, G. Yan, Z. Wang, Bleeding detection in wireless capsule endoscopy images based on color invariants and spatial pyramids using support vector machines, in: 2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, IEEE, 2011, pp. 6643–6646. [26] S. Sainju, F.M. Bui, K. Wahid, Bleeding detection in wireless capsule endoscopy based on color features from histogram probability, in: 2013 26th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE), IEEE, 2013, pp. 1–4. [27] Y. Yuan, B. Li, M.Q.-H. Meng, Improved bag of feature for automatic polyp detection in wireless capsule endoscopy images, IEEE Trans. Autom. Sci. Eng. 13 (2) (2015) 529–535. [28] H. Chen, S. Wang, Y. Ding, D. Qian, Saliency-based bleeding localization for wireless capsule endoscopy diagnosis, Int. J. Biomed. Imag. 2017 (2017), 8147632. [29] Medtronic, Capsule Endoscopy Products. URL [30] A. Koulaouzidis, D.K. Iakovidis, D.E. Yung, E. Rondonotti, U. Kopylov, J.N. Plevris, E. Toth, A. Eliakim, G.W. Johansson, W. Marlicz, et al., Kid project: an internet- based digital video atlas of capsule endoscopy for research purposes, Endosc. Int. Open 5 (6) (2017) E477. [31] X. Jia, M.Q.-H. Meng, Gastrointestinal bleeding detection in wireless capsule endoscopy images using handcrafted and cnn features, in: 2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), IEEE, 2017, pp. 3154–3157. [32] Z. Li, K. Kamnitsas, B. Glocker, Overfitting of neural nets under class imbalance: analysis and improvements for segmentation, in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer, 2019, pp. 402–410. [33] Q. Xu, M. Zhang, Z. Gu, G. Pan, Overfitting remedy by sparsifying regularization on fully-connected layers of cnns, Neurocomputing 328 (2019) 69–74. [34] S. Liu, An improved differential box-counting approach to compute fractal dimension of gray-level image, in: 2008 International Symposium on Information Science and Engineering, vol. 1, IEEE, 2008, pp. 303–306. [35] B.B. Chaudhuri, N. Sarkar, Texture segmentation using fractal dimension, IEEE Trans. Pattern Anal. Mach. Intell. 17 (1) (1995) 72–77. [36] L. Yu, D. Zhang, K. Wang, W. Yang, Coarse iris classification using box-counting to estimate fractal dimensions, Pattern Recogn. 38 (11) (2005) 1791–1798. [37] A. Seal, C. Panigrahy, Human authentication based on fusion of thermal and visible face images, Multimed. Tool. Appl. 78 (21) (2019) 30373–30395. [38] A.N. Esgiar, R.N. Naguib, B.S. Sharif, M.K. Bennett, A. Murray, Fractal analysis in the detection of colonic cancer images, IEEE Trans. Inf. Technol. Biomed. 6 (1) (2002) 54–58. [39] H. Eguiraun Martínez, M. K. L´opez de Ipi˜na Pe˜na, M. Falarza, M. Iciar, Application of Entropy and Fractal Dimension Analyses to the Pattern Recognition of Contaminated Fish Responses in Aquaculture. [40] I. Jamaludin, M.C. Azemin, A. Sapuan, A. Zainuddin, R. Hassan, 2d and 3d complexity analysis on mri images using fractal dimension, J. Telecommun. Electron. Comput. Eng. 10 (1–8) (2018) 161–164. [41] C. Panigrahy, A. Seal, N. Mahato, Mri and spect image fusion using a weighted parameter adaptive dual channel pcnn, in: IEEE Signal Process. Lett.Pubmed Partial Author articletitle stitle stitle Volume Page, 27, 2020, pp. 690–694. [42] C. Panigrahy, A. Seal, N.K. Mahato, D. Bhattacharjee, Differential box counting methods for estimating fractal dimension of gray-scale images: a survey, Chaos, Solitons & Fractals 126 (2019) 178–202. [43] C. Panigrahy, A. Seal, N.K. Mahato, Quantitative texture measurement of gray- scale images: fractal dimension using an improved differential box counting method, Measurement 147 (2019), 106859. [44] N. Sarkar, B.B. Chaudhuri, An efficient differential box-counting approach to compute fractal dimension of image, IEEE Trans. Syst. Man Cybern. 24 (1) (1994) 115–120. [45] X. Jin, S. Ong, et al., A practical method for estimating fractal dimension, Pattern Recogn. Lett. 16 (5) (1995) 457–464. [46] W.-S. Chen, S.-Y. Yuan, C.-M. Hsieh, Two algorithms to estimate fractal dimension of gray-level images, Opt. Eng. 42 (8) (2003) 2452–2465. [47] J. Li, C. Sun, Q. Du, A new box-counting method for estimation of image fractal dimension, in: 2006 International Conference on Image Processing, IEEE, 2006, pp. 3029–3032. [48] J. Li, Q. Du, C. Sun, An improved box-counting method for image fractal dimension estimation, Pattern Recogn. 42 (11) (2009) 2460–2469. [49] Y. Liu, L. Chen, H. Wang, L. Jiang, Y. Zhang, J. Zhao, D. Wang, Y. Zhao, Y. Song, An improved differential box-counting method to estimate fractal dimensions of gray- level images, J. Vis. Commun. Image Represent. 25 (5) (2014) 1102–1111. [50] K. Lai, C. Li, T. He, L. Chen, K. Yu, W. Zhou, Study on an improved differential box- counting approach for gray-level variation of images, in: 2016 10th International Conference on Sensing Technology (ICST), IEEE, 2016, pp. 1–6. [51] M. Long, F. Peng, A box-counting method with adaptable box height for measuring the fractal feature of images, Radioengineering 22 (1) (2013) 208–213. [52] C. Panigrahy, A. Seal, N.K. Mahato, Fractal dimension of synthesized and natural color images in lab space, Pattern Anal. Appl. 23 (2) (2019) 819–836. [53] P. Cunningham, S. J. Delany, K-Nearest Neighbour Classifiers–, arXiv preprint arXiv:2004.04523. [54] J. Kim, B. Kim, S. Savarese, Comparing image classification methods: K-nearest- neighbor and support-vector-machines, in: Proceedings of the 6th WSEAS International Conference on Computer Engineering and Applications, and Proceedings of the 2012 American Conference on Applied Mathematics, vol. 1001, 2012, 48109–2122. [55] Z. Wang, G. Yu, Y. Kang, Y. Zhao, Q. Qu, Breast tumor detection in digital mammography based on extreme learning machine, Neurocomputing 128 (2014) 175–184. [56] A. Seal, P.P.N. Reddy, P. Chaithanya, A. Meghana, K. Jahnavi, O. Krejcar, R. Hudak, An eeg database and its initial benchmark emotion classification performance, Comput. and Math. Meth. Med. 2020 (2020), 8303465. [57] N. Friedman, D. Geiger, M. Goldszmidt, Bayesian network classifiers, Mach. Learn. 29 (2–3) (1997) 131–163. [58] B.J. Erickson, P. Korfiatis, Z. Akkus, T.L. Kline, Machine learning for medical imaging, Radiographics 37 (2) (2017) 505–515. [59] A. Seal, D. Bhattacharjee, M. Nasipuri, D. Rodríguez-Esparrag´on, E. Menasalvas, C. Gonzalo-Martin, Pet-ct image fusion using random forest and `a-trous wavelet transform, Int. J. Numer. Meth. Biomed. Eng. 34 (3) (2018), e2933. [60] A. Seal, D. Bhattacharjee, M. Nasipuri, Human face recognition using random forest based fusion of `a-trous wavelet transform coefficients from thermal and visible images, AEU-Int. J. Electron. Commun. 70 (8) (2016) 1041–1049. [61] A. Seal, A. Garcia-Pedrero, D. Bhattacharjee, M. Nasipuri, M. Lillo-Saavedra, E. Menasalvas, C. Gonzalo-Martin, Multi-scale rois selection for classifying multi- spectral images, Multidimens. Syst. Signal Process. (2019) 1–25. [62] L.E. Raileanu, K. Stoffel, Theoretical comparison between the gini index and information gain criteria, Ann. Math. Artif. Intell. 41 (1) (2004) 77–93. [63] K.K. Sharma, A. Seal, Modeling uncertain data using Monte Carlo integration method for clustering, Expert Syst. Appl. 137 (2019) 100–116. [64] K.K. Sharma, A. Seal, Clustering analysis using an adaptive fused distance, Eng. Appl. Artif. Intell. 96 (2020) 103928. [65] K.K. Sharma, A. Seal, Multi-view spectral clustering for uncertain objects, Inf. Sci. 547 (8) (2020) 723–745. [66] L. Johnston, Student’s t-test, J. Qual. Technol. 2 (4) (1970) 243–245. [67] A. Porebski, N. Vandenbroucke, L. Macaire, Haralick feature extraction from lbp images for color texture classification, in: 2008 First Workshops on Image Processing Theory, Tools and Applications, IEEE, 2008, pp. 1–8. [68] A.F. Constantinescu, M. Ionescu, I. Rogoveanu, M.E. Ciurea, C.T. Streba, V. F. Iovanescu, S.A. Artene, C.C. Vere, Analysis of wireless capsule endoscopy images using local binary patterns, Appl. Med. Inf. 36 (2) (2015) 31–42. [69] P.F. Alcantarilla, A. Bartoli, A.J. Davison, Kaze features, in: European Conference on Computer Vision, Springer, 2012, pp. 214–227. S. Jain et al."
Single image dehazing using a new color channel,Geet Sahu and Ayan Seal and Ondrej Krejcar and Anis Yazidi,2021,,74,Journal of Visual Communication and Image Representation,article,"J. Vis. Commun. Image R. 74 (2021) 103008
Available online 21 December 2020
1047-3203/© 2020 Elsevier Inc. All rights reserved.
Contents lists available at ScienceDirect
J. Vis. Commun. Image R.
journal homepage: www.elsevier.com/locate/jvci
Full length article
Single image dehazing using a new color channel✩
Geet Sahu a, Ayan Seal a,b,∗, Ondrej Krejcar b,c, Anis Yazidi d
a PDPM Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, 482005, India
b Center for Basic and Applied Science, Faculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 500 03 Hradec Kralove, Czech
Republic
c Malaysia-Japan International Institute of Technology (MJIIT), Universiti Teknologi Malaysia, Jalan Sultan Yahya Petra, 54100 Kuala Lumpur, Malaysia
d Research Group in Applied Artificial Intelligence, Oslo Metropolitan University, 460167, Norway
A R T I C L E
I N F O
Keywords:
Image dehazing
Atmospheric light
Radiance
Illuminance scaling factor
A B S T R A C T
Images with hazy scene suffer from low-contrast, which reduces the visible quality of the scene, thus making
object detection a more challenging task. Low-contrast can result from foggy weather conditions during image
acquisition. Dehazing is a process of removal of haze from the photography of a hazy scene. Single-image
dehazing based on dark channel priors are well-known techniques in this field. However, the performance
of such techniques is limited to priors or constraints. Moreover, this type of method fails when images have
sky-region. So, a method is proposed, which can restore the visibility of hazy images. First, a hazy image is
divided into blocks of size 32 × 32, then the score of each block is calculated to select a block having the
highest score. Atmospheric light is calculated from the selected block. A new color channel is considered to
remove atmospheric scattering, obtained channel value and atmospheric light are then used to calculate the
transmission map in the second step. Third, radiance is computed using a transmission map and atmospheric
light. The illumination scaling factor is adopted to enhance the quality of a dehazed image in the final
step. Experiments are performed on six datasets namely, I-HAZE, O-HAZE, BSDS500, FRIDA, RESIDE dataset
and natural images from Google. The proposed method is compared against 11 state-of-the-art methods. The
performance is analyzed using fourteen quantitative evaluation metrics. All the results demonstrate that the
proposed method outperforms 11 state-of-the-art methods in most of the cases.
1. Introduction
Natural images and their perception play an important role in image
visualization and understanding. Bright images can improve the preci-
sion of computer vision applications such as surveillance [1], object
detection [2], image classification [3], image/video retrieval [4], and
land cover identification in remote sensing images [5] through proper
understanding. Therefore, a clear image is an essential requirement
in image processing and computer vision-based tasks. However, it is
always hard to capture clear images, especially in degraded visibility
conditions. Haze present in the atmosphere degrades the visibility of
images drastically. It could be in the form of fog, smoke, dust, or
mist. The haze particles pervert or sometimes completely cease the
light rays emanating from the image. Light rays scatter in different
directions when they strike with atmospheric particles. The amount of
scattering depends on the distance between the image and the camera.
Although haze is a natural phenomenon, most cameras cannot always
cope up with such type of environment. The camera captures the
✩This paper has been recommended for acceptance by Zicheng Liu.
∗Corresponding author at: PDPM Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, 482005, India.
E-mail address: ayan@iiitdmj.ac.in (A. Seal).
light coming from the image, blended with light coming from other
directions called the airlight. Haze in images results in faded color, low
contrast, and loss in the visibility of the image. Reduction of visibility
in images causes a problem in camera-guided vehicles, autonomous
vehicle and navigation based systems. Depth analysis, color preserva-
tion and visibility enhancement are the challenging tasks for dehazing.
Therefore, an efficient algorithm is needed to remove haze from the
captured scenes and thus for making computer vision applications more
reliable.
In [6], Koschmieder presented an image formation model, also
known as the degradation model that is widely used in dehazing. Eq. (1)
is used to formally describe the model. It consists of two atmospheric
scattering characteristics namely, direct attenuation and airlight. The
former one describes the amount of unscattered light, 𝐽(𝑚)𝑡(𝑚), which
travels directly from the image to the camera. In contrast, the latter one,
𝐴(1−𝑡(𝑚)), is the amount of light coming from the scattered atmospheric
particle. The degradation model is also portrayed in Fig. 1, where the
https://doi.org/10.1016/j.jvcir.2020.103008
Received 9 March 2020; Received in revised form 12 November 2020; Accepted 13 December 2020
 Journal of Visual Communication and Image Representation 74 (2021) 103008
2
G. Sahu et al.
blue and red dashed lines denote the direct attenuation and airlight
respectively.
𝐼(𝑚) = 𝐽(𝑚)𝑡(𝑚) + 𝐴(1 −𝑡(𝑚)),
(1)
where 𝐼is the captured hazy scene, 𝐽is the scene radiance which
is needed to recover, 𝑡is the medium transmission. The function 𝑡in
the above equation can be expressed as 𝑡(𝑚) = 𝑒𝛽∗𝑑(𝑚), where 𝛽is
atmospheric scattering coefficient and 𝑑(𝑚) is the distance between an
object and a camera, 𝐴is the global atmospheric light, and 𝑚is the
pixel coordinates.
Existing image dehazing methods can be broadly classified into
groups: traditional approaches and learning-based methods. Traditional
methods are further categorized into the method based on a phys-
ical models such as polarimetric image dehazing [7–9] and image
enhancement method such as linear transformation [10], structure-
preserving [11], histogram-based [12,13], wavelet-based [14,15],
retinex methods [16–18] and dark channel prior (DCP) [19–24]. Simi-
larly, learning-based methods use machine learning and deep learning
approaches [25–31] for dehazing. All the above mentioned methods
are discussed here briefly. Polarimetric methods depend on the de-
gree of polarization. Different methods considered this phenomenon
for dehazing. Schechner et al. [7] and Shwartz et al. [8] presented
polarized filters-based methods. Multiple images of the same scene
having different degrees of polarization are required for these methods.
However, these methods fail since polarizing filters are not able to
gain rapid changes in the scene. These techniques [7,8] used multiple
images of the same scene, which is difficult to capture in real-time.
Therefore, single image dehazing methods [20,21,25,26] are getting
more attention in recent years. However, all these works are based on
some assumptions. In [32], Gao et al. presented a multi-focus fusion
method for dehazing. First, an atmospheric light was estimated from
the sky region, then a fast local Laplacian filtering with adaptive
boundary constraint was introduced to refine the transmission map
by reducing oversaturation in the image. Finally, a multi-focus image
fusion method was applied to recover the image. Qi et al. [11] dis-
cussed a structure-preserving method for dehazing. First, the minimum
channel of the hazy image was estimated, then the structure detail
of the minimum channel was considered as a reference image. The
minimum channel was filtered to derive an initial airlight, which was
refined further by joint bilateral filter guided by reference image.
Atmospheric light was calculated using a quad-tree subdivision method.
Finally, radiance was stored using the atmospheric attenuation model.
Further, the histogram equalization (HE) method was explored to
enhance the contrast of a hazy image by increasing the gray distribution
of images. In [12,13], contrast limited adaptive HE was combined
with the finite impulse response filter and weiner filter to enhance
the contrast of images. However, the performance of HE method is
not satisfactory for color images. The wavelet transform method is
considered for image dehazing. He et al. [14] offered an optical model
and regularized optimization for restoring images. First, they converted
non-convex, bilinear problem to a convex, linear optimization problem
by estimating the atmosphere light constant and then they applied
multilevel Haar wavelet transform. The optimization was achieved by
applying the algorithm to the low-frequency sub-band decomposition of
the original image to accelerate the processing speed. Further, Khmag
et al. [15] employed mean vector L2-norm to estimate the transmission
map and enhanced it by second-generation wavelet transform filter.
However, color-shift occurred in the resulting images. Moreover, the
Retinex based methods were also considered for image enhancement.
The principal concept of the Retinex method is to derive reflectance and
illuminance component of an image which is further used to remove
haze. Yang et al. [16] combined sub-block local information using
an adaptive filter to calculate the luminance of an image. Further,
Hu et al. [17] utilized bilateral filtering to estimate the illumination
component. In [18], Shu et al. presented a multi-scale Retinex image
enhancement method on sub-band image decomposition to enhance
the contrast of the image. Retinex methods are easy to implement,
however, it causes a halo effect in images and make it too bright.
Further, He et al. [19] described a DCP method for single image
dehazing. According to the DCP method, most of the local patches
in outdoor haze-free color images have very low-intensity values in
at least one color channel. Transmission map and atmospheric light
were estimated based on the above said assumption. However, the
DCP does not work well if the image consists of a sky region [33].
Galdran [34] dehazed the image without estimating the transmission
map. The gamma correction operations were employed to artificially
under-expose images. Further, the images were dehazed using a multi-
scale Laplacian blending scheme. Fang [35] presented a fast variational
method. First, the transmission map was estimated by a window based
adaptive method based on the celebrated DCP. The transmission map
was then converted into a depth map to built a new variational model
and restore the image. Later, Wang et al. [36] combined the DCP with
the total variation models namely, layered total variation, multichannel
total variation, and color total variation regularizers, for dehazing. Fast
split Bregman algorithms were explained to improve the efficiency of
the models. Further, Hou et al. [37,38] considered the DCP method in
underwater images by employing underwater total variation models to
restore images. Recently, learning-based methods are gaining attention
due to their ability to learn features automatically. Tang et al. [25] used
the random forest to estimate the transmission map and refined it by a
guided filter. Further, the image degradation model and white balance
restoration were exploited to restore the image. In [26], Zhu et al. pre-
sented a color attenuation prior and linear model to estimate the depth
map. They utilized supervised learning to learn model parameters,
which helped to better estimate the transmission map. In [27], Gui et al.
exploited Support Vector Machine (SVM) for dehazing. First, the feature
vectors were extracted using the dark channel histogram and texture
features of the hazy images. The feature vectors were then trained
by the SVM algorithm to realize the automatic binary classification of
images. Second, the dehazing methods processed the classified hazy
image and the dehazed image was evaluated based on the performance
of different dehazing methods. Finally, this model helped to produce a
better dehazed image. Further, in [28], Cai et al. presented DehazeNet
to extract features from hazy images and used non-linear functions
to estimate the transmission map of the input image. Moreover, Ren
et al. [29] suggested a multi-scale convolutional neural network, which
computes a coarse transmission map using coarseNet, then feeds the
resultant transmission map to the second CNN of FineNet to refine
transmission map. Since the above mentioned models uses CNN to
estimate the transmission map and further process it to get a dehazed
image, therefore, Li et al. [30] and Guo et al. [31] presented dehazing
network to predict a dehazed image directly. Although deep learning-
based methods give better results. However, these methods suffer from
several problems [39]. First, they require immense amount of training
time. Second, they are greedy in terms of data, meaning they require
a huge amount of data. Finally, most of the models are trained on
synthetic data. Hence, the generalization problem can occur.
Therefore, a new DCP based method is introduced for dehazing
images in this study. The salient contributions are as follows:
• Atmospheric light is estimated by dividing an image into blocks,
then the score of each block is computed. The block having the
highest score is further picked for calculating the atmospheric
light.
• A new color model is adopted to calculate the transmission map,
which is further used for computing radiance.
• At last, we enhance the dehazed image using the illuminance
scaling factor to improve its visibility.
Since the complexity of deep learning-based methods are relatively
high in terms of time and data, only traditional methods are considered
for comparison in this study. All the experiments are performed on
 Journal of Visual Communication and Image Representation 74 (2021) 103008
3
G. Sahu et al.
Fig. 1. Image degradation model. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)
six publicly available benchmark datasets namely, O-HAZE [40], I-
HAZE [41], Berkeley Segmentation Dataset (BSDS500) [42], REalistic
Single Image DEhazing (RESIDE) [43], Foggy Road Image DAtabase
(FRIDA) [44] and natural hazy images from Google. The proposed
method is compared with 11 state-of-the-art methods based on ten full
reference and six no-reference quality assessment metrics. The empiri-
cal results illustrate that the proposed DCP based method outperforms
11 state-of-the-art methods in most of the cases.
The rest of the work is organized as follows: Section 2 describes the
material and methods used in this work. A new color model to estimate
the transmission map and a novel method to calculate atmospheric
light are described in Section 3. Experimental results are reported
in Section 4. The proposed method is also compared with eleven
state-of-the-art methods in Section 4. Finally, Section 5 concludes this
work.
2. Material and method
This section first discusses the DCP method followed by a detailed
survey of the DCP based state-of-the-art methods.
2.1. DCP method
Based on the fact that haze depends on unknown depth, dehazing is
therefore very challenging. Many methods were presented to measure
the depth of haze. One of the popular methods is DCP. This method is
based on the statistics of haze-free outdoor images. It is observed that
most of the RGB images have very low-intensity pixels in at least one
color channel of the non-sky patches. The thickness of the haze can
be estimated directly using prior information, which helps further to
generate a haze-free image. Algorithm 1 describes the approach used by
He et al. [19] to obtain a dehazed image. All the steps of DCP method
are as follows:
• Dark Channel
He et al. [19] experimented to investigate the features of haze-
free images. They observed that there are some pixels whose
intensity values are nearly zero in a local patch of the image.
Moreover, they formed a separate channel comprising of these
low-intensity pixels and named it a dark channel that is defined
in Eq. (2).
𝐽𝑑𝑎𝑟𝑘(𝑚) = 𝑚𝑖𝑛𝑐∈{𝑅,𝐺,𝐵}(𝑚𝑖𝑛𝑝(𝐽𝑐(𝑝))),
(2)
where 𝐽is the input image, 𝑐is a particular color channel of 𝐽, 𝑝
is a local patch centered at 𝑚, 𝐽𝑑𝑎𝑟𝑘is the dark channel of image
𝐽and 𝑚is the pixel coordinate.
• Atmospheric Light
Atmospheric light was calculated by selecting the top 0.1% bright-
est pixels from 𝐽𝑑𝑎𝑟𝑘then mapping these chosen values to the
input image and the highest intensity pixel was then selected as
atmospheric light.
• Transmission map
The transmission map of the image was derived using the degra-
dation model described in Eq. (1). Applying minimum operation
patch-wise on both sides of Eq. (1), He et al. got
𝑚𝑖𝑛𝑝(𝐼𝑐(𝑚)) = 𝑡(𝑚)𝑚𝑖𝑛𝑝(𝐽𝑐(𝑚)) + 𝐴𝑐(1 −𝑡(𝑚)),
(3)
Now, by applying minimum operation channel-wise on Eq. (3),
He et al. show
𝑚𝑖𝑛𝑐
(
𝑚𝑖𝑛𝑝
( 𝐼𝑐(𝑚)
𝐴𝑐
))
= 𝑡(𝑚)𝑚𝑖𝑛𝑐
(
𝑚𝑖𝑛𝑝
( 𝐽𝑐(𝑚)
𝐴𝑐
))
+ (1 −𝑡(𝑚)),
(4)
Since 𝐽𝑑𝑎𝑟𝑘of the haze-free image tends to zero and atmospheric
light is always positive, therefore
𝑚𝑖𝑛𝑐
(
𝑚𝑖𝑛𝑝
( 𝐽𝑐(𝑚)
𝐴𝑐
))
= 0,
(5)
Substituting Eq. (5) in Eq. (4), transmission map can be derived
as:
𝑡(𝑚) = 1 −𝑚𝑖𝑛𝑐
(
𝑚𝑖𝑛𝑝
( 𝐼𝑐(𝑚)
𝐴𝑐
))
,
(6)
Since a small amount of haze is always present in natural images,
to preserve the naturalness of images, a small amount of haze was
introduced in the form of constant 𝜔(0 < 𝜔≤1) in Eq. (6):
𝑡(𝑚) = 1 −𝜔𝑚𝑖𝑛𝑐
(
𝑚𝑖𝑛𝑝
( 𝐼𝑐(𝑚)
𝐴𝑐
))
,
(7)
The transmission map was estimated using Eq. (7) contains block
effects. Therefore, it was further refined using soft matting to get
smooth transmission.
• Radiance
Radiance was calculated using an estimated transmission map and
atmospheric light. Radiance is derived from Eq. (1) and can be
calculated as shown in Eq. (8).
𝐽(𝑚) = 𝐼𝑐(𝑚) −𝐴𝑐
𝑚𝑎𝑥(𝑡(𝑚), 𝑡0) + 𝐴𝑐,
(8)
The transmission was restricted to a lower bound 𝑡0, used to
preserve a small amount of haze in the restored image.
 Journal of Visual Communication and Image Representation 74 (2021) 103008
4
G. Sahu et al.
Algorithm 1 DCP based dehazing method
Input: Hazy Image, 𝐼
Output: Radiance, 𝐽
1: Find
dark
channel
prior
of
hazy
image
𝐼,
𝐽dark(𝑚)
=
𝑚𝑖𝑛c∈{R,G,B}(𝑚𝑖𝑛p(𝐽c(𝑝)))
2: Select 0.1% brightest pixel from 𝐽𝑑𝑎𝑟𝑘.
3: Pick highest intensity value from 𝐼as atmospheric light.
4: Calculate transmission, 𝑡(𝑚) = 1 −𝜔𝑚𝑖𝑛𝑐(𝑚𝑖𝑛𝑝( 𝐼𝑐(𝑚)
𝐴𝑐))
5: Refine transmission using soft matting.
6: Finally compute radiance, 𝐽(𝑚) =
𝐼𝑐(𝑚)−𝐴𝑐
𝑚𝑎𝑥(𝑡(𝑚),𝑡0) + 𝐴𝑐
Dehazing based on DCP method [19] is useful however, the images
obtained after dehazing generally introduce artifacts, halo effects and
distortion of edges and color in images. Even the time complexity of
this method is very high due to soft matting operation. Estimation of
atmospheric light also fails when the image contains some brighter ob-
jects and the major drawback of this method is that it is not applicable
for images containing sky region. It results in a color-shift in the sky
region, which makes images look darker.
2.2. DCP based methods
In literature, there are many methods based on DCP. In this sec-
tion, we present a few of them briefly. He et al. [19] used DCP and
refined transmission map using soft matting, however, their method
generates images with artifacts and color distortion. Later, Colores
et al. [24] removed artifact using pixel-wise maximum operation in the
modified dark channel. Moreover, Zhao et al. [45] presented a Trans-
mission MisEstimated (TME) recognition method to distinguish the
TME and non-TME regions. They calculated pixel-wise and patch-wise
transmission maps separately, then they combined both transmission
maps optimally using a multi-scale optimal fusion scheme to avoid
the misestimated transmission region. The multi-scale optimal fusion
was used further into patch-wise dehazing to suppress halo artifacts.
Tan et al. [46] calculated a coarse transmission map, then refined it
using a fine transmission map to remove halo effects. Cheng et al. [47]
estimated dark channels using two different patch sizes, one large and
another small. The hybrid DCP technique was considered to avoid
the generation of artifacts. Xiao and Gan [48] estimated atmospheric
light through median filter then refined it using guided joint bilateral
filtering to generate a new atmosphere light. This modified atmospheric
light removes color distortion from the image. Long et al. [49] exploited
a low-pass Gaussian filter to refine atmosphere veil. Lin and Wang [50]
considered improved guided filtering to estimate the transmission map.
Ancuti and Ancuti [51] applied local white balance and contrast en-
hancement procedure to remove haze from images. The result yields
visually pleasing images however, it is not physically valid. Moreover,
Zhu et al. [33] presented a fusion of luminance and DCP method. The
luminance of the image was employed to calculate the transmission
map of the sky region. They combined the transmission map calculated
from the sky and non-sky regions to compute the overall transmission
map. Further, they used the DCP method to remove haze from image.
However, the method introduced more brightness in the images that are
already brighter therefore the dehazed image looks unnatural. Further,
Sahu and Seal [52] presented two luminance stretching models to
adjust the brightness of the dehazed image to some extent.
After investigating all the existing methods based on DCP, it is
observed that the main challenges of dehazing are to estimate the
atmospheric light and the transmission map. It is noted that the at-
mospheric light cannot be precisely determined by just picking x%
brightest pixel from the dark channel of the whole image. A previous
study [53] revealed that global atmospheric light influences error in
calculation. Even the transmission map cannot be generated accurately
by only applying dark channel operation on the image. The limitations
of the above mentioned DCP based state-of-the-art methods illustrate
that there is a chance to devise a DCP based method, which can further
enhance the quality of a dehazed image.
3. Proposed work
In this section, the proposed method is discussed for generating a
dehazed image from the input hazy image. Several steps associated with
the proposed method are shown in Fig. 2. The different steps involved
in the proposed method are as follows:
3.1. Atmospheric light
It is clear from Section 2 that the DCP method considered a global
approach while estimating an atmospheric light. It is also observed
that the global approach suffers from limitations as discussed in the
same section. Therefore, instead of considering a global atmospheric
light, the proposed method estimates atmospheric light from the local
region. Initially, an image, 𝐼, is divided into equal-sized blocks, as
shown in Fig. 3. Although, it is a challenging task to decide the size
of an ideal block, the best block size is determined by conducting
several experiments using varying block sizes, 𝑏. It is observed that the
proposed method achieved the best dehazed images when the block
size is 32 × 32, which is considered throughout this study. However,
the results of all the experiments are beyond the scope of this study.
A typical block, 𝐵𝑖, consists of 32 × 32 = 1024 pixels. Then the score
of each 𝐵𝑖is computed as the average pixel value subtracted by the
standard deviation of the pixel values within that block. The candidate
block, 𝐵𝑢, marked by green color in Fig. 3, is selected, which has the
highest score, 𝑀𝑎𝑥. Then to avoid the effects of suspended particles,
we pick the top 1% of 1024 pixels i.e., 10 brightest pixels of the dark
channel of the candidate block. Here, we consider the top 1% brightest
pixels instead of 0.1% brightest pixels, since 0.1% will correspond to a
single pixel and single pixel can be a noisy pixel which will lead to the
wrong estimation of atmospheric light. Further, the selected pixels are
mapped to the original image. Then the median value of the selected
pixels is computed. We consider the median value as it is less affected
by noises or outliers. Finally, the median value is considered as the
atmospheric light, 𝐴. Algorithm 2 gives a brief description of each step
followed to estimate 𝐴.
Algorithm 2 Procedure for estimating the atmospheric light
Input: Hazy Image, 𝐼
Output: Atmospheric light, 𝐴
1: Divide the input into blocks of size 𝑏.
⊳𝑏is taken as 32×32
2: 𝑀𝑎𝑥= 0
3: for all blocks, 𝐵𝑖, in I do
4:
𝑠(𝑖) = 𝜇(𝐵𝑖) −𝜎(𝐵𝑖)
⊳𝜇is mean and 𝜎is standard deviation
5:
𝑀𝑎𝑥= 𝑚𝑎𝑥(𝑀𝑎𝑥, 𝑠(𝑖))
6: end for
7: Select block 𝐵𝑢having 𝑀𝑎𝑥value
8: for l=1 to row do
⊳row and col of 𝐵𝑢, which are 32 in this case
9:
for k=1 to col do
10:
𝑑𝑎𝑟𝑘= 𝐷𝐶(𝐵𝑢)
⊳DC is dark channel
11:
end for
12: end for
13: Select the top h% brightest pixels from 𝑑𝑎𝑟𝑘
⊳ℎis taken as 1%
14: 𝐴= 𝑚𝑒𝑑𝑖𝑎𝑛(𝐵𝑢(ℎ))
The informed reader would notice that our algorithm differs from
the main stream of state-of-the-art algorithms which rather operate
with segmenting an image into two regions namely, sky and non-sky
regions, then extracting the atmospheric light from the sky region. Our
proposed method does not segment an image into the above-mentioned
two regions explicitly. Instead of considering a segmentation algorithm
for dividing an image into two regions, we apply Algorithm 2 to
compute atmospheric light. Algorithm 2 divides an image into several
equal-sized blocks and then atmospheric light is calculated from a
 Journal of Visual Communication and Image Representation 74 (2021) 103008
5
G. Sahu et al.
Fig. 2. Different steps involved in the proposed method are (a) Image in N channel, (b) Calculation of atmospheric light, (c) Generation of transmission map, (d) Refinement of
transmission map, (e) Dehazed image and (f) Enhancement of dehazed image.
Fig. 3. Selection of a block having the maximum score, 𝑀𝑎𝑥. Here, the box marked by green color indicates the candidate block, 𝐵𝑢.
block, which is selected based on statistical features namely, mean and
standard deviation. We thus did not opt for a segmentation phase using
for instance grab cut explicitly because not only it incurs an additional
computational cost but it also does not necessarily improve the re-
sults. We have tested indeed two very recent methods for extracting
the atmospheric light involving the grab cut segmentation algorithm
[54,55]. However, these results are not included in the manuscript
because, in most cases, the grab cut algorithm fails to separate the sky
region from an image. On the other hand, the proposed Algorithm 2
computes atmospheric light from the sky region in most of the cases.
Nevertheless, sometimes Algorithm 2 fails especially when images are
captured in indoor conditions.
3.2. Transmission map
In almost every DCP based methods, transmission map is calculated
using Eq. (9).
𝑡(𝑚) = 1 −𝜔𝑚𝑖𝑛𝑐∈{𝑅,𝐺,𝐵}
(
𝑚𝑖𝑛𝑝
𝐼𝑐(𝑝)
𝐴𝑐
)
,
(9)
where 𝑐is a particular color channel of 𝐼, 𝑝is a local patch centered
at 𝑚, 𝜔(0 < 𝜔≤1) is a constant used to preserve a small amount
of haze in image. However, the value estimated using Eq. (9) is not
accurate always. Therefore, a new color channel, 𝑁, is adopted to
calculate the transmission map. The motivation behind the use of
a new color channel is as follows. It is observed that illumination
present in the sky region of an image is not uniform or homogeneous
and it happens due to the difference in atmospheric scattering angles.
Moreover, the inhomogeneous brightness distribution of an image,
especially the sky region, creates a serious issue while estimating the
transmission map. So, a relatively new color channel is adopted to the
removal of atmospheric scattering. The new channel is computed using
Eq. (10) [56].
𝑁= 𝜙−(𝛼−𝛽),
(10)
where 𝜙is known as the panchromatic channel and it refers to the
channel which is sensitive to all visible colors. In other words, 𝜙is also
called gray-scale image obtained by 𝜙= 0.299𝑅+0.587𝐺+0.114𝐵, where
𝑅, 𝐺, 𝐵are the red, green, and blue channels of an RGB color image,
 Journal of Visual Communication and Image Representation 74 (2021) 103008
6
G. Sahu et al.
Table 1
Value of score corresponding to each block of Fig. 3.
Blocks
Score
0.7780
0.8053
0.7898
0.7326
0.7705
0.7427
0.7220
0.6336
0.3157
0.5389
0.6266
0.6092
0.6476
0.5797
0.5631
0.4532
0.1767
0.3073
0.4157
0.4168
0.3828
0.4424
0.4021
0.3935
0.2004
0.2600
0.3133
0.3136
0.2493
0.3450
0.3506
0.3647
0.1853
0.2371
0.2709
0.2812
0.1943
0.2438
0.3169
0.2628
0.1673
0.1554
0.1895
0.1983
0.2085
0.2376
0.2319
0.1859
0.2679
0.1993
0.1907
0.1882
0.1567
0.2399
0.2034
0.1642
0.2234
0.2360
0.2333
0.1747
0.1681
0.2077
0.1964
0.1856
Table 2
Comparison of the RMSE value between the ground truth and the estimated atmospheric light of the ten images taken from FRIDA dataset [44].
Images
M1 [19]
M2 [48]
M3 [49]
M4 [50]
M5 [47]
M6 [46]
M7 [26]
M8 [33]
M10 [24]
M11 [45]
M12
img1
0.0350(2)
0.7480
0.0649
0.0651
0.0379(3)
0.0350(2)
0.0757
0.7478
0.0523
0.0350(2)
0.0348(1)
img2
0.0406(2)
0.7480
0.0913
0.0466
0.0608
0.0407(3)
0.0863
0.7477
0.0560
0.0406(2)
0.0402(1)
img3
0.0478(2)
0.7847
0.0874
0.0851
0.0638
0.0479(3)
0.0874
0.7847
0.0614
0.0478(2)
0.0473(1)
img4
0.0482(2)
0.7847
0.0739
0.0869
0.0489
0.0482(2)
0.0482(2)
0.7847
0.0488(3)
0.0482(2)
0.0478(1)
img5
0.0401(2)
0.8353
0.0606
0.1164
0.0406
0.0401(2)
0.0401(2)
0.8353
0.0405(3)
0.0401(2)
0.0400(1)
img6
0.0398(2)
0.8353
0.0771
0.1167
0.0431(3)
0.0398(2)
0.0398(2)
0.8353
0.0431
0.0398(2)
0.0395(1)
img7
0.0151(3)
0.8466
0.0341
0.0122(1)
0.0152
0.0151(3)
0.0151(3)
0.8464
0.0155
0.0151(3)
0.0150(2)
img8
0.0151(3)
0.8466
0.0224
0.0122(1)
0.0151(3)
0.0151(3)
0.0151(3)
0.8464
0.0151(3)
0.0151(3)
0.0148(2)
img9
0.0172(3)
0.8466
0.0172(3)
0.0144(1)
0.0172(3)
0.0172(3)
0.0172(3)
0.8464
0.0173
0.0172(3)
0.0171(2)
img10
0.0339(2)
0.9143
0.0407
0.0660
0.0339(2)
0.0339(2)
0.0339(2)
0.9141
0.0341(3)
0.0339(2)
0.0337(1)
Table 3
Names of the ten images taken from RESIDE dataset [43] and their estimated RMSE values by various methods.
Images
M1 [19]
M2 [48]
M3 [49]
M4 [50]
M5 [47]
M6 [46]
M7 [26]
M8 [33]
M10 [24]
M11 [45]
M12
img11
0.3949(2)
0.7777
0.8257
0.6803
0.7189
0.6594(3)
0.6674
0.7515
0.6983
0.8795
0.1851(1)
img12
0.5509(2)
0.7643
0.8097
0.6713
0.7081
0.6553
0.6155(3)
0.7093
0.6906
0.8588
0.3812(1)
img13
0.9784
0.0690
0.0977
0.0908
0.0528(2)
0.0362(1)
0.1562
0.0632
0.0552(3)
0.2011
0.6530
img14
0.4840(2)
0.8004
0.8550
0.7069
0.7403
0.6747(3)
0.7216
0.7361
0.7176
0.9044
0.2963(1)
img15
0.6670(2)
0.7722
0.7756
0.7320
0.7449
0.7307(3)
0.7687
0.7647
0.7614
0.7828
0.3371(1)
img16
0.7456
0.6855
0.7333
0.5649
0.6304
0.5611
0.4443(3)
0.5747
0.6028
0.4335(2)
0.3051(1)
img17
0.9789
0.0913
0.1211
0.0699
0.0702
0.0490(2)
0.1651
0.0730
0.0515(3)
0.2041
0.0283(1)
img18
0.9784
0.0751
0.1028
0.0720
0.0579
0.0411(3)
0.1058
0.0476
0.0378(2)
0.2064
0.0149(1)
img19
0.9784
0.0951
0.1217
0.0795
0.0721
0.0526(2)
0.4607
0.0711
0.0552(3)
0.2064
0.0258(1)
img20
0.9784
0.0786
0.1087
0.0890
0.0589
0.0419(2)
0.4327
0.0546
0.0475(3)
0.2059
0.0103(1)
respectively. The 𝛼= 𝑚𝑎𝑥{𝑅, 𝐺, 𝐵} is called the bright channel and it
denotes the maximum value of each pixel in an RGB color image. The
𝛽= 𝑚𝑖𝑛{𝑅, 𝐺, 𝐵} is known as the dark channel and it represents the
channel of the minimum value of each pixel in a RGB color image.
In general, the blue and red channels are the bright and the dark
channels respectively for most of the images with the sky regions. The
difference between the blue and red channels represents the deviation
of the atmospheric scattering of each pixel in the visible range, which
can be considered as the atmospheric background for estimating the
transmission map in this study. The modified equation to compute the
transmission map is shown in Eq. (11). An experiment is performed to
prove the correctness of Eq. (11), which will be discussed in Section 4.
𝑡(𝑚) = 1 −𝜔𝑚𝑖𝑛𝑝
( 𝑁(𝑝)
𝐴
)
,
(11)
where 𝜔and 𝑝are taken as 0.85 and 15, respectively. The coarse trans-
mission map calculated using Eq. (11) suffers from block artifacts and
halo effects because transmission is not always constant in the patch.
Therefore, filters are used to refine the transmission in order to remove
noise. Several filters, for example, bilateral filter, gaussian filter, soft
matting, cross-bilateral filter, and guided filter were considered for the
refinement. One of the previous studies [57] revealed that soft matting,
cross-bilateral filter, and guided filter provide sharper transmission
maps than gaussian and bilateral filters. Moreover, Lee [57] proved
that the soft matting performed the best, and the cross-bilateral and
guided filters stood in second. However, the time complexity of the
guided filter is low as compared to others. The complexity is expressed
as O(N), where N is the total number of pixel of 𝐼[58]. Moreover, a
guided filter performs edge-preserving smoothing operation on 𝐼using
the information of the guidance image. Further, it does not suffers from
the gradient reversal artifacts that can be observed while using bilateral
filter. The output image, ̂𝑡, can be represented as a linear combination
of the guidance image, 𝐼, in a guided filter. Here, the guided filter is
used to optimize the transmission map as shown in Eq. (12).
̂𝑡𝑖= 𝑎𝑚𝐼𝑖+ 𝑏𝑚, ∀𝑖𝜖𝑤𝑚,
(12)
where 𝑎𝑚and 𝑏𝑚are two constants in window 𝑤𝑚centered at pixel 𝑚.
The value of 𝑎𝑚and 𝑏𝑚are obtained by Eqs. (13) and (14), respectively.
𝑎𝑚=
1
|𝑤|
∑
𝑖𝜖𝑤𝑚𝐼𝑖𝑡𝑖−𝜇𝑚𝑡′
𝑚
𝜎2
𝑚+ 𝜖
,
(13)
𝑏𝑚= 𝑡′
𝑚−𝑎𝑚𝜇𝑚,
(14)
where 𝑡is the coarse transmission map, 𝜎2
𝑚is the variance, 𝜇𝑚is the
mean of 𝐼, 𝑡′ =
1
|𝑤|
∑
𝑖𝜖𝑤𝑚𝑡𝑖, and |𝑤| is the total number of pixels in
filter 𝑤𝑚.
3.3. Radiance
After calculating 𝐴and 𝑡using the above said methods, the radiance
of an image is recovered by the Eq. (1). However, the direct attenuation
 Journal of Visual Communication and Image Representation 74 (2021) 103008
7
G. Sahu et al.
Fig. 4. Illustration of results of atmospheric light estimation algorithm. Red box indicates the selected block.
Fig. 5. (a) A sample image, ‘img11’, of RESIDE [43] dataset, (b) given transmission map, obtained transmission maps by, (c) M1 [19], (d) M2 [48], (e) M3 [49], (f) M4 [50], (g)
M5 [47], (h) M6 [46], (i) M7 [26], (j) M8 [33], (k) M10 [24], (l) M11 [45] and (m) M12.
 Journal of Visual Communication and Image Representation 74 (2021) 103008
8
G. Sahu et al.
Fig. 6. (a) A sample image, ‘img12’, of RESIDE [43] dataset, (b) given transmission map, obtained transmission maps by (c) M1 [19], (d) M2 [48], (e) M3 [49], (f) M4 [50], (g)
M5 [47], (h) M6 [46], (i) M7 [26], (j) M8 [33], (k) M10 [24], (l) M11 [45] and (m) M12.
 Journal of Visual Communication and Image Representation 74 (2021) 103008
9
G. Sahu et al.
Fig. 7. Image dehazing results of twelve different methods on BSDS500 [42] dataset, (a) hazy image, (b) ground truth image, output of (c) M1 [19], (d) M2 [48], (e) M3 [49],
(f) M4 [50], (g) M5 [47], (h) M6 [46], (i) M7 [26], (j) M8 [33], (k) M9 [34], (l) M10 [24], (m) M11 [45] and (n) M12.
term 𝐽(𝑚)𝑡(𝑚) may be close to zero when the transmission 𝑡(𝑚) is close
to zero [29]. Therefore, the transmission map is restricted by a constant
𝑡0. Finally, the scene radiance 𝐽(𝑚) is recovered using Eq. (15).
𝐽(𝑚) = 𝐼𝑐(𝑚) −𝐴𝑐
𝑚𝑎𝑥(̂𝑡(𝑚), 𝑡0)
+ 𝐴𝑐,
(15)
here value of 𝑡0 is taken as 0.1.
3.4. Enhancement
After the restoration of radiance, it is being observed that an image
becomes either too bright or too dark. Therefore, to improve the visi-
bility of the image, adjustment of illuminance is required. Illuminance
scaling factor [25] is used to adjust the illumination of the image, which
is calculated using Eq. (16).
𝑠(𝑚) =
𝛶𝐽(𝑚)𝛶𝐼(𝑚) + 𝜏𝛶1.5
𝐼(𝑚)
𝛶3
𝐽(𝑚) + 𝜏𝛶1.5
𝐼(𝑚)
,
(16)
where 𝑠(𝑚) is the illuminance scaling factor, 𝛶𝐽is the illumination
intensity of the dehazed image, 𝛶𝐼is the illumination intensity of the
input image, 𝜏is a constant taken as 1.2. Thus, the enhanced image can
be obtained by using Eq. (17):
𝐸(𝑚) = 𝐽𝑐(𝑚) ∗𝑠(𝑚),
(17)
where 𝐸is the enhanced haze-free image. All the steps of the proposed
method are written in the form of an Algorithm 3.
Algorithm 3 Removal of haze
Input: Hazy Image 𝐼and atmospheric light 𝐴
Output: Enhanced Image, 𝐸
1: Find 𝑁, 𝑁= 𝜙−(𝛼−𝛽)
2: Calculate 𝐴using Algorithm 2
3: for all pixels m, do
4:
Estimate transmission, 𝑡(𝑚) = 1 −𝜔𝑚𝑖𝑛p( 𝑁(𝑝)
𝐴)
5: end for
6: Refine transmission map using guided filter
7: Compute radiance, 𝐽(𝑚) =
𝐼𝑐(𝑚)−𝐴𝑐
𝑚𝑎𝑥(𝑡(𝑚),𝑡0) + 𝐴𝑐
8: for all pixels m, do
9:
Calculate illuminance scaling factor, 𝑠(𝑚) =
𝛶J(m)𝛶I(m)+𝜏𝛶1.5
𝐼(𝑚)
𝛶3
𝐽(𝑚)+𝜏𝛶1.5
𝐼(𝑚)
10: end for
11: Enhanced image, 𝐸(𝑚) = 𝐽c(𝑚) ∗𝑠(𝑚)
 Journal of Visual Communication and Image Representation 74 (2021) 103008
10
G. Sahu et al.
Fig. 8. Image dehazing results of twelve different methods on I-HAZE [41] dataset, (a) hazy image, (b) ground truth image, output of (c) M1 [19], (d) M2 [48], (e) M3 [49], (f)
M4 [50], (g) M5 [47], (h) M6 [46], (i) M7 [26], (j) M8 [33], (k) M9 [34], (l) M10 [24], (m) M11 [45] and (n) M12.
4. Experimental results and discussion
All the experiments are performed in MATLAB R2018a using a PC
having Intel(R) Core™i7-4770 CPU @ 3.40 GHz and 4 GB RAM.
4.1. Database description
To evaluate the performance of the proposed method, six datasets
namely, O-HAZE, I-HAZE, BSDS500, RESIDE, FRIDA, and natural hazy
images from Google, are used. The reason behind including many
datasets is to compare the performance on various environmental con-
ditions. The O-HAZE dataset consists of 45 outdoor scene pairs of real
hazy and corresponding haze-free images. The I-HAZE dataset contains
35 pairs of hazy and corresponding haze-free indoor images. All the
hazy images were captured in a real hazy environment generated by
professional haze machines maintaining the same value of illumina-
tion parameters. The BSDS500 consists of 500 natural images. All the
images are clear; there is no haze present in them. One hundred and
twenty-five images are selected randomly from BSDS500 and synthetic
haze is introduced to make corresponding hazy images. Besides this,
RESIDE dataset is also considered to compare the transmission map
estimated by the proposed method with other state-of-the-art methods
for knowing which method determines a transmission map close to
the actual. It consists of real and synthetic hazy images along with
their transmission maps. So, we compare all the methods based on
the produced transmission maps. The FRIDA dataset is considered to
validate the atmospheric light estimation algorithm. The FRIDA dataset
consists of 90 synthetic images of 18 urban road scenes. Each fog-free
image is associated with four foggy images and a depth map. Different
kinds of fog are added on each of the 4 associated images namely,
uniform fog, heterogeneous fog, cloudy fog, and cloudy heterogeneous
fog.
4.2. Computational protocols
Based on the qualitative evaluation, quantitative evaluation, and
execution time, the performance of the proposed method is compared
with eleven state-of-the-art methods, which are as follows:
• M1: Single image haze removal using DCP [19]
• M2: Fast image dehazing using guided joint bilateral filter [48]
 Journal of Visual Communication and Image Representation 74 (2021) 103008
11
G. Sahu et al.
Fig. 9. Image dehazing results of twelve different methods on O-HAZE [40] dataset, (a) hazy image, (b) ground truth image, output of (c) M1 [19], (d) M2 [48], (e) M3 [49],
(f) M4 [50], (g) M5 [47], (h) M6 [46], (i) M7 [26], (j) M8 [33], (k) M9 [34], (l) M10 [24], (m) M11 [45] and (n) M12.
• M3: Fast haze removal for a single remote sensing image using
DCP [49]
• M4: Dehazing for image and video using guided filter [50]
• M5: Visibility enhancement of single hazy images using hybrid
DCP [47]
• M6: Fast single-image defogging [46]
• M7: A fast single image haze removal algorithm using color
attenuation prior [26]
• M8: Haze removal method for natural restoration of images with
sky [33]
• M9: Image dehazing by artificial multiple-exposure image fu-
sion [34]
• M10: Efficient single image dehazing by modifying the DCP [24]
• M11: Multi-scale optimal fusion model for single image dehaz-
ing [45]
• M12: The proposed method
4.3. Results and comparison
Three experiments are mainly conducted in this study. The aim
of the first experiment is to know how good 𝑀12 is as compared
to 𝑀1–𝑀11 while estimating atmospheric light. Here, Fig. 3 is again
considered. The score of each 𝐵𝑖is calculated using Algorithm 2 and is
tabulated in Table 1. The block, 𝐵𝑢, having the highest score, 𝑀𝑎𝑥, is
highlighted by green color in Fig. 3. The highest score is also marked by
bold character in Table 1. Moreover, Fig. 4 shows the region bounded
by a rectangle, indicating the block used for estimation of atmospheric
light, 𝐴. It can be observed that the candidate block, 𝐵𝑢, is selected from
the sky region. Further, FRIDA dataset is used for objective analysis.
The fog-free images and their respective depth maps are taken from
the FRIDA dataset. A foggy image is formed using Eq. (1). However, the
value of atmospheric light is provided manually as an input to create a
foggy image. Then, algorithm 2 is employed to calculate an atmospheric
light. An evaluation metric named root means square error (RMSE) [59]
is considered, which computes the value of the RMSE between the input
and the estimated atmospheric lights. The ideal value of the RMSE is 0.
Table 2 reports the values of the RMSE obtained by 𝑀1 −𝑀12 except
𝑀9 for ten randomly chosen sample images from the FRIDA dataset. A
rank either 1st or 2nd or 3rd is assigned to each method for each image,
which is enclosed within the bracket. It is clear from Table 2 that the
𝑀12 stands the 1st for most of the images since the values of the RMSE
are less as compared to other state-of-the-art methods. However, 𝑀4
estimates the atmospheric light better than others for some images. All
the results of Table 2 illustrate that the 𝑀12 is more consistent while
estimating an atmospheric light from a foggy image, which shows the
effectiveness of the 𝑀12 over 𝑀1–𝑀11.
The objective of the second experiment is to determine which
method estimates the transmission map better than others. So, the
 Journal of Visual Communication and Image Representation 74 (2021) 103008
12
G. Sahu et al.
Fig. 10. Image dehazing results of twelve different methods on natural hazy images taken from Google, from top to bottom rows: original images, output of M1 [19], M2 [48],
M3 [49], M4 [50], M5 [47], M6 [46], M7 [26], M8 [33], M9 [34], M10 [24], M11 [45] and M12.
RESIDE dataset is considered only because it has synthetic hazy images
and their transmission maps. Ten images are considered randomly from
the RESIDE dataset for this experiment. However, the transmission
maps obtained by all the methods except 𝑀9 on two synthetic hazy
images namely, ‘img11’ and ‘img12’ including themselves are shown in
Figs. 5 and 6 respectively. Since 𝑀9 does not estimate an atmospheric
light and transmission map, it is not considered in the first two experi-
ments. It is clear from both Figs. 5 and 6 that the visual quality of the
transmission map obtained by the 𝑀12 is better than the transmission
maps generated by 𝑀1–𝑀11 methods. Hence, the 𝑀12 outperforms the
other eleven state-of-the-art methods, 𝑀1–𝑀11. However, the visual
quality is measured by the human visual system (HVS) and it may vary
from person to person. Thus, it is not a unique and sufficient criterion.
So, quantitative evaluation is required. Again the RMSE is adopted.
Now, the value of RMSE is obtained between the given transmission
map and the transmission map obtained by 𝑀1 −𝑀12 except for the
𝑀9 on 10 randomly selected images from the RESIDE dataset and the
achieved values of the RMSE are noted in Table 3. Again a rank is
 Journal of Visual Communication and Image Representation 74 (2021) 103008
13
G. Sahu et al.
Table 4
The average values of fourteen quantitative evaluation metrics on BSDS500 [42] dataset.
Dataset
Metrics
M1 [19]
M2 [48]
M3 [49]
M4 [50]
M5 [47]
M6 [46]
M7 [26]
M8 [33]
M9 [34]
M10 [24]
M11 [45]
M12
BSDS500
SSIM
0.0041(3)
0.0015
0.0022
0.0020
0.0018
0.0022
0.0027
0.9445(2)
0.0026
0.0021
0.0031
0.9608(1)
PSNR
6.6111(3)
6.5719
6.6033
6.5918
6.5855
6.6012
6.0331
22.216(2)
6.0991
6.5982
6.6060
49.859(1)
MSE
15667.5
15785.2
15685.6
15725.2
15747.4
15698.7
15209.4(3)
390.32(2)
15837.7
15701.1
15685.1
104.37(1)
RMSE
122.09(3)
122.59
122.18
122.38
122.28
122.22
178.46
19.75(2)
125.31
122.25
122.16
3.230(1)
GMSD
0.00024(2)
0.000501
0.00047
0.00046
0.00043
0.00035
0.00016
0.35735
0.00018
0.00029(3)
0.00042
0.00002(1)
BIAS
0.9939(3)
0.9971
0.9944
0.9958
0.9947
0.9950
0.9957
0.0661(2)
0.9959
0.9951
0.9943
0.0202(1)
FSIM
0.4773
0.4550
0.4619
0.4743
0.4616
0.4744
0.5092(3)
0.9526(2)
0.5089
0.4691
0.4668
0.9973(1)
FSIMc
0.4628
0.4417
0.4482
0.4604
0.4480
0.4606
0.5024(3)
0.9515(2)
0.5020
0.4552
0.4530
0.9973(1)
RFSIM
0.9345
0.9517
0.9547(3)
0.9123
0.9255
0.9354
0.9704(1)
0.0004
0.9698(2)
0.9448
0.8942
0.0049
ERGAS
112.926
113.236
112.917
113.100
112.883
113.013
103.85(3)
11.487(2)
103.87
113.040
112.935
21.801(1)
BRISQUE
17.307(2)
22.136
22.145
24.512
30.169
24.514
23.142
24.6805
20.629
17.049(1)
33.586
20.585(3)
NIQE
3.458(2)
4.051
4.125
3.552
5.191
3.769
4.200
3.590
3.518
3.468(3)
4.958
3.451(1)
CEIQ
2.422
2.635(2)
1.402
1.402
2.603
2.574
1.402
2.382
2.285
2.377
2.728(1)
2.608(3)
E
0
6.7566
6.9070(3)
0
6.9708(2)
7.0661
0
0
6.7346
6.7789
7.3780(1)
6.8592
Table 5
The average values of fourteen quantitative evaluation metrics on I-HAZE [41] dataset.
Dataset
Metrics
M1 [19]
M2 [48]
M3 [49]
M4 [50]
M5 [47]
M6 [46]
M7 [26]
M8 [33]
M9 [34]
M10 [24]
M11 [45]
M12
I-HAZE
SSIM
0.0043
0.0030
0.0032
0.0031
0.0031
0.0036
0.0058
0.5739(1)
0.0061(3)
0.0033
0.0049
0.5342(2)
PSNR
5.8343
5.8084
5.8142
5.8115
5.8128
5.8230
6.9557
12.6206(2)
6.9634(3)
5.8145
5.8418
15.840(1)
MSE
17003.9
17105.9
17082.2
17093.4
17087.9
17048.1
13728.6
3556.4(2)
13708.6(3)
17072.3
16975.1
6981.2(1)
RMSE
130.33
130.72
130.63
130.67
130.65
130.50
115.89
59.635(1)
115.80(3)
130.59
130.22
90.239(2)
GMSD
0.00026(1)
0.00051
0.00049
0.00044
0.00044
0.00039
0.00038(3)
0.2752
0.00028(2)
0.00038
0.00044
0.00043
BIAS
0.9962
0.9990
0.9980
0.9982
0.9982
0.9972
0.9296(3)
0.3271(2)
0.9958
0.9975
0.9962
0.1348(1)
FSIM
0.5731
0.5431
0.5288
0.5405
0.5556
0.5565
0.5835(3)
0.8596(1)
0.5289
0.5622
0.5614
0.8474(2)
FSIMc
0.5663
0.5364
0.5223
0.5340
0.5506
0.5498
0.5775(3)
0.8509(1)
0.5193
0.5553
0.5402
0.8505(2)
RFSIM
0.9485
0.9730(2)
0.9938(1)
0.9583
0.9385
0.9167
0.9296
0.0005
0.9560
0.9379
0.8827
0.9605(3)
ERGAS
114.722(3)
114.993
114.889
114.914
114.841
114.805
117.089
51.992(1)
116.996
114.845
114.694
74.422(2)
BRISQUE
29.983
15.226(2)
28.435
26.743
9.714(1)
18.059
19.237
28.598
25.179
26.477
17.797
16.520(3)
NIQE
3.225
3.535
3.423
3.902
4.092
3.375
4.127
3.102(3)
3.254
3.354
2.457(1)
2.990(2)
CEIQ
2.373
2.309
1.402
1.402
2.282
2.429
1.402
2.600
2.631(2)
2.505
2.762(1)
2.608(3)
E
0.6828
5.9665
6.8917
0
6.3748
6.7219
0
0
6.9630(2)
6.5706
6.9234(3)
7.2362(1)
Table 6
The average values of fourteen quantitative evaluation metrics on O-HAZE [40] dataset.
Dataset
Metrics
M1 [19]
M2 [48]
M3 [49]
M4 [50]
M5 [47]
M6 [46]
M7 [26]
M8 [33]
M9 [34]
M10 [24]
M11 [45]
M12
0-HAZE
SSIM
0.0027
0.0008
0.0012
0.0013
0.0014
0.0017
0.0019
0.3456(2)
0.0017
0.0017
0.0028(3)
0.9643(1)
PSNR
7.3819
7.3551
7.3622
7.3652
7.3617
7.3639
7.3852
7.3697
8.3101(3)
8.2685
8.3103(2)
52.407(1)
MSE
11886.1
11919.4
10305.2
9687.7(2)
10306.9(3)
11935.1
11876.9
11959.2
11939.7
11931.3
11941.1
3734.9(1)
RMSE
109.01
109.34
109.26
109.22
109.26
109.16
99.797(3)
98.42(2)
99.802
109.239
108.972
61.114(1)
GMSD
0.00026(2)
0.00057
0.00057
0.00046
0.00047
0.00047
0.00033
0.30609
0.00029(3)
0.00042
0.00041
0.00004(1)
BIAS
0.9955(3)
0.9989
0.9977
0.9972
0.9975
0.9967
0.9960
0.7084(2)
0.9955
0.9971
0.9955
0.6197(1)
FSIM
0.3220
0.2981
0.3005
0.3143
0.3159
0.3144
0.3648
0.7632(2)
0.3666(3)
0.3151
0.3222
0.9694(1)
FSIMc
0.3182(2)
0.2945
0.2971
0.3105
0.3143
0.3107
0.3690
0.7923(2)
0.3707(3)
0.3113
0.3186
0.9694(1)
RFSIM
0.9707
0.9707(3)
0.9773(2)
0.9552
0.9449
0.9436
0.9613
0.00049
0.9774(1)
0.9519
0.9440
0.9638
ERGAS
108.023(3)
108.349
108.224
108.183
108.213
108.125
109.90
70.775(2)
109.86
108.172
108.003
52.446(1)
BRISQUE
24.992
21.426
23.532
24.501
23.507
14.999(2)
21.847
17.243(3)
18.147
14.326(1)
19.675
23.719
NIQE
2.327(1)
2.439
2.549
2.684
3.529
2.442
2.537
2.683
2.651
2.561
3.345(2)
2.396(3)
CEIQ
2.545
2.236
1.402
1.402
2.420
2.581
1.402
2.631(2)
2.388
2.530
2.643(1)
2.588(3)
E
0.7666
6.7620
6.9888
0
6.6064
6.9411(3)
0.0009
0
6.6141
6.6884
7.3901(1)
6.9545(2)
Table 7
The average values of four no-reference quantitative evaluation metrics on natural hazy images shown in Fig. 10.
Metrics
Image
M1 [19]
M2 [48]
M3 [49]
M4 [50]
M5 [47]
M6 [46]
M7 [26]
M8 [33]
M9 [34]
M10 [24]
M11 [45]
M12
BRISQUE
img1
21.991
6.067(2)
17.447
15.825
24.229
13.952
10.479
11.931
5.002(1)
15.824
28.630
9.516(3)
img2
15.612(2)
12.748(1)
35.236
45.729
29.801
28.337
44.412
21.716
42.723
24.326
35.763
21.639(3)
img3
36.377
31.600
28.497
36.137
19.160(2)
35.174
44.429
35.151
9.751(1)
37.616
28.487(3)
41.708
img4
21.232(1)
36.399
33.358
44.654
39.845
32.835
42.821
29.289(2)
32.775
31.389
38.913
31.342(3)
NIEQ
img1
2.417(2)
2.601
2.754
2.645
3.970
2.665
3.102
2.562(3)
2.650
4.041
4.507
2.375(1)
img2
3.133
2.507(1)
3.126
10.515
2.978(2)
3.204
12.346
3.095
4.293
3.564
4.212
3.090(3)
img3
3.730(2)
3.477(1)
4.511
3.872
6.032
3.888
4.634
3.748(3)
5.056
4.835
5.962
3.953
img4
5.487(1)
7.031
12.463
7.064
8.684
6.509
6.134(2)
9.322
6.535
7.628
9.433
6.194(3)
CEIQ
img1
2.456
1.915
2.459
1.402
2.270
2.435
1.402
2.462
2.548(3)
2.470
2.614(1)
2.613(2)
img2
2.678(2)
2.138
1.855
1.759
2.597
2.671
1.402
2.556
2.675(3)
2.583
2.683(1)
2.607
img3
2.553
1.983
1.820
1.402
2.528
2.612(2)
1.402
2.579
2.600(3)
2.405
2.627(1)
2.600(3)
img4
2.395
2.541
2.498
1.402
2.607
2.626(2)
1.402
2.628(1)
2.624(3)
2.615
2.540
2.626(2)
E
img1
16.109
12.999
−4.754
−4.754
15.125
15.843
−4.754
16.539(2)
16.394(3)
16.100
17.586
17.203(1)
img2
18.047(2)
12.639
−4.754
−2.080
17.357
17.978(3)
−4.511
18.286(1)
17.253
17.142
17.933
17.978(3)
img3
17.512
12.247
−4.754
−4.754
16.980
17.717(2)
−4.754
17.086
16.952
16.479
17.604(3)
17.913(1)
img4
15.244
15.528
14.640
−4.754
15.929
16.341(3)
−4.754
16.306
16.929(2)
16.306
15.655
17.078(1)
 Journal of Visual Communication and Image Representation 74 (2021) 103008
14
G. Sahu et al.
Fig. 11. Comparison of haze removal methods with respect to the execution time.
assigned to the first three methods based on their performances. The
first three ranks are depicted within a bracket. All the results of Table 3
suggest that 𝑀12 generates lower RMSE values in most of the cases as
compared to 𝑀1–𝑀11. However, for some images, the performance of
𝑀6 is even better than the 𝑀12. However, the transmission map alone
is not sufficient. The performance of all the methods would be judged
based on the quality of a dehazed image.
The third experiment is conducted to compare the performances
of all the methods based on the generated dehazed images. Here, the
performance of each method is evaluated on three datasets namely,
BSDS500, I-HAZE and O-HAZE using ten full-reference quality metrics
viz., Structural Similarity Index Measure (SSIM) [60,61], Peak Signal to
Noise Ratio (PSNR) [62], Mean Square Error (MSE), RMSE [59], Gradi-
ent Magnitude Similarity Deviation (GMSD) [63], BIAS, Feature SIMi-
larity Index (FSIM) [64], an extended form of Feature SIMilarity Index
(FSIMc) [64], Riesz-transform based Feature SIMilarity (RFSIM) [65],
and relative dimensionless global error (ERGAS) [66] and four no-
reference quality assessment metrics namely, Blind/Referenceless im-
age spatial quality evaluator (BRISQUE) [67], natural image quality
evaluator (NIQE) [68], contrast enhancement based contrast-changed
image quality measure (CEIQ) [69] and entropy (E) [70–72]. The
values of SSIM, GMSD, BIAS, FSIM, FSIMc, and RFSIM vary from 0
to 1. However, the preferred value for SSIM, FSIM, FSIMc, and RFSIM
is 1, likewise the preferred value of GMSD, BIAS is 0. Similarly, the
value of PSNR, MSE, RMSE, ERGAS, BRISQUE, NIQE, CEIQ, and E lies
in between 0 and infinity. The expected value of MSE, RMSE, ERGAS,
and NIQE is 0 whereas PSNR, BRISQUE, CEIQ, and E requires a higher
value. A sample image is taken from each dataset, which is displayed in
Figs. 7a, 8a, and 9a, respectively. Their ground truth images are shown
in Figs. 7b, 8b, and 9b. The dehazed images of Figs. 7a, 8a generated by
various methods are shown in Figs. 7c–k, 8c–k, and 9c–k respectively.
After analyzing the visual quality of all the dehazed images shown in
Figs. 7, 8, and 9, anyone can say that the 𝑀8 method generates much
better dehazed images than others because all the images are brighter
and clearer. At the same time, a drastic color-shift is also observed in
the dehazed images produced by 𝑀8. On the other hand, a color-shift
is less in the dehazed images produced by 𝑀12. Moreover, dehazed
images achieved by the 𝑀12 are reasonably brighter and clearer. So, we
can conclude that the 𝑀12 better restores the visual quality of a hazy
image compared to 𝑀1–𝑀11. However, the images that we consider
from three datasets, all are synthesized images. Therefore, methods
𝑀1 −𝑀12 are executed on natural hazy images. Four natural haze
images are downloaded from Google. Fig. 10 shows four natural images
and their dehazed images obtained by 𝑀1 −𝑀12. It may apparently
seem that the result obtained by 𝑀3, 𝑀5 and 𝑀10 are visually better,
however color-shift occurred in the images and the brightness of the
images have been degraded. It is clear from Fig. 10 that the 𝑀12 better
remove haze from images with a less color-shift.
As we said earlier that the quality evaluation done by HVS is
not alone sufficient, so quantitative analysis is equally important. All
the methods, 𝑀1 −𝑀12, are executed on all the images taken from
BSDS500, I-HAZE, and O-HAZE datasets individually and the average
values of all the fourteen metrics are reported in Tables 4, 5, and 6
respectively. Similarly, quantitative results of natural hazy images are
shown in Table 7, however, ground truth images are not available for
natural hazy images, therefore, no-reference metrics are only consid-
ered for evaluation. After analyzing all the results of Tables 4, 5, 6, and
7, a rank is assigned to each method, which is marked by superscript
numbers. If the rank of a method is 1 it means this method is the
best among all. So, Tables 4, 5, 6, and 7 illustrate that the proposed
method, M12, comes first in most of the cases. In some cases, the M12
is stood as either 2nd or 3rd. However, the results of other methods are
not consistent, therefore, all the results demonstrate that the proposed
method is relatively better than 11 state-of-the-art methods. In this
study, the computation time of each method is also measured because
it is also an important factor to evaluate the performance of a method.
The computation time of all methods is shown in Fig. 11. The 𝑥-axis
of Fig. 11 represents the name of all the methods and the proposed
method and the 𝑦-axis denotes execution time in seconds. Computation
time is calculated as the average of the execution time of all images of
respective dataset. It can be seen that the execution time of 𝑀12 is not
pretty good, but it is acceptable.
5. Conclusion
In this study, a single image dehazing algorithm in a relatively
new color channel is proposed, which consists of four steps namely,
calculation of atmospheric light, transmission map, radiance, and en-
hancement of the dehazed image. The proposed method is capable to
restore visibility of the scene. The proposed method is implemented
 Journal of Visual Communication and Image Representation 74 (2021) 103008
15
G. Sahu et al.
on six datasets namely, I-HAZE, O-HAZE, BSDS500, RESIDE, FRIDA,
and Google dataset. It is compared with 11 state-of-the-art methods
using fourteen quantitative evaluation metrics. The proposed method
performs well on images of BSDS500 and O-HAZE datasets. On the
other hand, the performance of the proposed method is satisfactory on
the images taken from I-HAZE and it may happen due to block-wise at-
mospheric light estimation procedure. Since the block-wise atmospheric
light estimation procedure selects a block from the sky region in most
of the cases while computing 𝐴and there is no sky region in indoor
images, therefore the value calculated as 𝐴is not precise. It may lead
to performance degradation in the case of images of the I-HAZE dataset.
Although the results are acceptable for indoor images, further research
to generate realistic and visually pleasing images is worth conducting.
Acknowledgments
This work is partially supported by the project ‘‘Prediction of
diseases through computer assisted diagnosis system using images
captured by minimally-invasive and non-invasive modalities’’, Com-
puter Science and Engineering, PDPM Indian Institute of Information
Technology, Design and Manufacturing, Jabalpur India (under ID:
SPARC-MHRD-231). This work is also partially supported by the project
at (2020/2204), Grant Agency of Excellence, University of Hradec
Kralove, Faculty of Informatics and Management, Czech Republic and
by the project at Universiti Teknologi Malaysia (UTM) under Research
University Grant Vot-20H04, Malaysia Research University Network
(MRUN) Vot 4L876 and the Fundamental Research Grant Scheme
(FRGS) Vot5F073 supported under Ministry of Education Malaysia for
the completion of the research.
Declaration of competing interest
The authors declare that they have no known competing finan-
cial interests or personal relationships that could have appeared to
influence the work reported in this paper.
References
[1] D.
Shabna,
C.
Manikandababu,
An
efficient
haze
removal
algorithm
for
surveillance video, Int. J. Innov. Res. Sci. Eng. Technol. 5 (5) (2016).
[2] Gong Chen, Heqin Zhou, Jiefeng Yan, A novel method for moving object
detection in foggy day, in: Eighth ACIS International Conference on Soft-
ware Engineering, Artificial Intelligence, Networking, and Parallel/Distributed
Computing, SNPD 2007, Vol. 2, IEEE, 2007, pp. 53–58.
[3] Yanting Pei, Yaping Huang, Qi Zou, Yuhang Lu, Song Wang, Does haze removal
help cnn-based image classification? in: Proceedings of the European Conference
on Computer Vision, ECCV, 2018, pp. 682–697.
[4] Boyi Li, Xiulian Peng, Zhangyang Wang, Jizheng Xu, Dan Feng, End-to-end united
video dehazing and detection, in: Thirty-Second AAAI Conference on Artificial
Intelligence, 2018.
[5] Qi Liu, Xinbo Gao, Lihuo He, Wen Lu, Haze removal for a single visible remote
sensing image, Signal Process. 137 (2017) 33–43.
[6] Harald Koschmieder, Theorie der horizontalen Sichtweite, Beitr. Phys. Freien
Atmos. (1924) 33–53.
[7] Yoav Y. Schechner, Srinivasa G. Narasimhan, Shree K. Nayar, Instant dehazing
of images using polarization, in: Proceedings of the 2001 IEEE Computer Society
Conference on Computer Vision and Pattern Recognition. CVPR 2001, volume 1,
IEEE, 2001, I–I.
[8] Sarit Shwartz, Einav Namer, Yoav Y. Schechner, Blind haze separation, in: 2006
IEEE Computer Society Conference on Computer Vision and Pattern Recognition,
CVPR’06, volume 2, IEEE, 2006, pp. 1984–1991.
[9] Pu Xia, Xuebin Liu, Image dehazing technique based on polarimetric spectral
analysis, Optik 127 (18) (2016) 7350–7358.
[10] Guangyi Ge, Zhenzhong Wei, Jingxin Zhao, Fast single-image dehazing using
linear transformation, Optik 126 (21) (2015) 3245–3252.
[11] Miao Qi, Qiaohong Hao, Qingji Guan, Jun Kong, You Zhang, Image dehazing
based on structure preserving, Optik 126 (22) (2015) 3400–3406.
[12] Garima Yadav, Saurabh Maheshwari, Anjali Agarwal, Foggy image enhancement
using contrast limited adaptive histogram equalization of digitally filtered
image: Performance improvement, in: 2014 International Conference on Ad-
vances in Computing, Communications and Informatics, ICACCI, IEEE, 2014, pp.
2225–2231.
[13] Muna F. Al-Sammaraie, Contrast enhancement of roads images with foggy scenes
based on histogram equalization, in: 2015 10th International Conference on
Computer Science & Education, ICCSE, IEEE, 2015, pp. 95–101.
[14] Jiaxi He, Frank Z. Xing, Ran Yang, Cishen Zhang, Fast single image dehazing
via multilevel wavelet transform based optimization, 2019, arXiv preprint arXiv:
1904.08573.
[15] Asem Khmag, S.A.R. Al-Haddad, Bahareh Kalantar, et al., Single image dehazing
using second-generation wavelet transforms and the mean vector L2-norm, Vis.
Comput. 34 (5) (2018) 675–688.
[16] Yang Wanting, Wang Ronggui, Fang Shuai, Zhang Xuan, Variable filter Retinex
algorithm for foggy image enhancement, J. Comput.-Aided Des. Comput. Graph.
6 (010) (2010).
[17] Wei-wei Hu, Rong-gui Wang, Shuai Fang, Qiong Hu, Retinex algorithm for image
enhancement based on bilateral filtering, J. Eng. Graph. 2 (2010) 104–109.
[18] T. Shu, Y.F. Liu, B. Deng, Y.P. Tan, B.Q. Chen, Multi-scale Retinex algorithm for
the foggy image enhancement based on sub-band decomposition, J. Jishou Univ.
36 (1) (2015) 40–45.
[19] Kaiming He, Jian Sun, Xiaoou Tang, Single image haze removal using dark
channel prior, IEEE Trans. Pattern Anal. Mach. Intell. 33 (12) (2010) 2341–2353.
[20] Kristofor B. Gibson, Dung T. Vo, Truong Q. Nguyen, An investigation of dehazing
effects on image and video coding, IEEE Trans. Image Process. 21 (2) (2011)
662–673.
[21] Shih-Chia Huang, Bo-Hao Chen, Wei-Jheng Wang, Visibility restoration of single
hazy images captured in real-world weather conditions, IEEE Trans. Circuits Syst.
Video Technol. 24 (10) (2014) 1814–1824.
[22] Yunan Li, Qiguang Miao, Jianfeng Song, Yining Quan, Weisheng Li, Single image
haze removal based on haze physical characteristics and adaptive sky region
detection, Neurocomputing 182 (2016) 221–234.
[23] Irfan Riaz, Teng Yu, Yawar Rehman, Hyunchul Shin, Single image dehazing via
reliability guided fusion, J. Vis. Commun. Image Represent. 40 (2016) 85–97.
[24] Sebastián Salazar-Colores, Juan-Manuel Ramos-Arreguín, Jesús-Carlos Pedraza-
Ortega, J Rodríguez-Reséndiz, Efficient single image dehazing by modifying the
dark channel prior, EURASIP J. Image Video Process. 2019 (1) (2019) 66.
[25] Ketan Tang, Jianchao Yang, Jue Wang, Investigating haze-relevant features in a
learning framework for image dehazing, in: Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, 2014, pp. 2995–3000.
[26] Qingsong Zhu, Jiaming Mai, Ling Shao, A fast single image haze removal
algorithm using color attenuation prior, IEEE Trans. Image Process. 24 (11)
(2015) 3522–3533.
[27] Bian Gui, Yuhua Zhu, Tong Zhen, Adaptive single image dehazing method based
on support vector machine, J. Vis. Commun. Image Represent. (2020) 102792.
[28] Bolun Cai, Xiangmin Xu, Kui Jia, Chunmei Qing, Dacheng Tao, Dehazenet: An
end-to-end system for single image haze removal, IEEE Trans. Image Process. 25
(11) (2016) 5187–5198.
[29] Wenqi Ren, Si Liu, Hua Zhang, Jinshan Pan, Xiaochun Cao, Ming-Hsuan
Yang, Single image dehazing via multi-scale convolutional neural networks, in:
European Conference on Computer Vision, Springer, 2016, pp. 154–169.
[30] Boyi Li, Xiulian Peng, Zhangyang Wang, Jizheng Xu, Dan Feng, Aod-net: All-in-
one dehazing network, in: Proceedings of the IEEE International Conference on
Computer Vision, 2017, pp. 4770–4778.
[31] Fan Guo, Xin Zhao, Jin Tang, Hui Peng, Lijue Liu, Beiji Zou, Single image
dehazing based on fusion strategy, Neurocomputing 378 (2020) 9–23.
[32] Yin Gao, Yijing Su, Qiming Li, Jun Li, Single fog image restoration with
multi-focus image fusion, J. Vis. Commun. Image Represent. 55 (2018) 586–595.
[33] Yingying Zhu, Gaoyang Tang, Xiaoyan Zhang, Jianmin Jiang, Qi Tian, Haze
removal method for natural restoration of images with sky, Neurocomputing
275 (2018) 499–510.
[34] Adrian Galdran, Image dehazing by artificial multiple-exposure image fusion,
Signal Process. 149 (2018) 135–147.
[35] Faming Fang, Fang Li, Tieyong Zeng, Single image dehazing and denoising: A
fast variational approach, SIAM J. Imaging Sci. 7 (2) (2014) 969–996.
[36] Zhi Wang, Guojia Hou, Zhenkuan Pan, Guodong Wang, Single image dehazing
and denoising combining dark channel prior and variational models, IET Comput.
Vis. 12 (4) (2017) 393–402.
[37] Guojia Hou, Jingming Li, Guodong Wang, Huan Yang, Baoxiang Huang,
Zhenkuan Pan, A novel dark channel prior guided variational framework for
underwater image restoration, J. Vis. Commun. Image Represent. 66 (2020)
102732.
[38] Guojia Hou, Jingming Li, Guodong Wang, Zhenkuan Pan, Xin Zhao, Underwater
image dehazing and denoising via curvature variation regularization, Multimedia
Tools Appl., 1–21.
[39] Giuseppe
Ciaburro,
Neural
Networks
with
R:
smart
Models
using
CNN,
RNN, Deep Learning, and Artificial Intelligence Principles, Packt Publishing,
Birmingham, UK, 2017.
[40] Codruta O. Ancuti, Cosmin Ancuti, Radu Timofte, Christophe De Vleeschouwer,
O-HAZE: A dehazing benchmark with real hazy and haze-free outdoor images, in:
IEEE Conference on Computer Vision and Pattern Recognition, NTIRE Workshop,
NTIRE CVPR’18, 2018.
[41] Codruta O. Ancuti, Cosmin Ancuti, Radu Timofte, Christophe De Vleeschouwer,
I-HAZE: A dehazing benchmark with real hazy and haze-free indoor images,
2018, arXiv:1804.05091v1.
 Journal of Visual Communication and Image Representation 74 (2021) 103008
16
G. Sahu et al.
[42] Berkeley Segmentation Data Set, Benchmarks 500 (BSDS500), 2011, URL http:
//www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html.
[43] Boyi Li, Wenqi Ren, Dengpan Fu, Dacheng Tao, Dan Feng, Wenjun Zeng,
Zhangyang Wang, Benchmarking single-image dehazing and beyond, IEEE Trans.
Image Process. 28 (1) (2019) 492–505.
[44] Jean-Philippe Tarel, Nicolas Hautiere, Aurélien Cord, Dominique Gruyer, Hous-
sam Halmaoui, Improved visibility of road scene images under heterogeneous
fog, in: 2010 IEEE Intelligent Vehicles Symposium, IEEE, 2010, pp. 478–485.
[45] Dong Zhao, Long Xu, Yihua Yan, Jie Chen, Ling-Yu Duan, Multi-scale optimal
fusion model for single image dehazing, Signal Process., Image Commun. 74
(2019) 253–265.
[46] Zhiming Tan, Xianghui Bai, Bingrong Wang, Akihiro Higashi, Fast single-image
defogging, Fujitsu Sci. Tech. J. 50 (1) (2014) 60–65.
[47] Yi-Jui Cheng, Bo-Hao Chen, Shih-Chia Huang, Sy-Yen Kuo, Andrey Kopylov, Oleg
Seredint, Leonid Mestetskiy, Boris Vishnyakov, Yury Vizilter, Oleg Vygolov, et
al., Visibility enhancement of single hazy images using hybrid dark channel prior,
in: 2013 IEEE International Conference on Systems, Man, and Cybernetics, IEEE,
2013, pp. 3627–3632.
[48] Chunxia Xiao, Jiajia Gan, Fast image dehazing using guided joint bilateral filter,
Vis. Comput. 28 (6–8) (2012) 713–721.
[49] Jiao Long, Zhenwei Shi, Wei Tang, Fast haze removal for a single remote sensing
image using dark channel prior, in: 2012 International Conference on Computer
Vision in Remote Sensing, IEEE, 2012, pp. 132–135.
[50] Zheqi Lin, Xuansheng Wang, Dehazing for image and video using guided filter,
Appl. Sci. 2 (2012) 123–127.
[51] Codruta Orniana Ancuti, Cosmin Ancuti, Single image dehazing by multi-scale
fusion, IEEE Trans. Image Process. 22 (8) (2013) 3271–3282.
[52] Geet Sahu, Ayan Seal, Image dehazing based on luminance stretching, in:
2019 International Conference on Information Technology, ICIT, IEEE, 2019, pp.
388–393.
[53] Chia-Hung Yeh, Li-Wei Kang, Ming-Sui Lee, Cheng-Yang Lin, Haze effect removal
from image via haze density estimation in optical model, Opt. Express 21 (22)
(2013) 27127–27141.
[54] Luyan Tong, Fenglin Wei, Yupeng Pan, Kai Wang, Study on the extraction of
target contours of underwater images, in: International Conference on Artificial
Intelligence and Security, Springer, 2020, pp. 339–349.
[55] M. Sudhakar, M.J.anaki Meena, An efficient interactive segmentation algorithm
using color correction for underwater images, Wirel. Netw. (2019) 1–12.
[56] Jun Yang, Qilong Min, Weitao Lu, Ying Ma, Wen Yao, Tianshu Lu, An RGB
channel operation for removal of the difference of atmospheric scattering and
its application on total sky cloud detection, Atmos. Meas. Tech. 10 (3) (2017)
1191–1201.
[57] Sungmin Lee, Seokmin Yun, Ju-Hun Nam, Chee Sun Won, Seung-Won Jung,
A review on dark channel prior based image dehazing algorithms, EURASIP J.
Image Video Process. 2016 (1) (2016) 4.
[58] Jiahao Pang, Oscar C. Au, Zheng Guo, Improved single image dehazing using
guided filter, in: Proc. APSIPA ASC, 2011, pp. 1–4.
[59] Liviu Florin Zoran, Quality evaluation of multiresolution remote sensing images
fusion, UPB Sci. Bull. C 71 (2009) 38–52.
[60] Animesh Sengupta, Ayan Seal, Chinmaya Panigrahy, Ondrej Krejcar, Anis
Yazidi, Edge information based image fusion metrics using fractional order
differentiation and sigmoidal functions, IEEE Access 8 (2020) 88385–88398.
[61] Chinmaya Panigrahy, Ayan Seal, Nihar Kumar Mahato, Ondrej Krejcar, Enrique
Herrera-Viedma, Multi-focus image fusion using fractal dimension, Appl. Opt. 59
(19) (2020) 5642–5655.
[62] Ayan
Seal,
Debotosh
Bhattacharjee,
Mita
Nasipuri,
Dionisio
Rodríguez-
Esparragón, Ernestina Menasalvas, Consuelo Gonzalo-Martin, PET-CT Image
fusion using random forest and à-trous wavelet transform, Int. J. Numer. Methods
Biomed. Eng. 34 (3) (2018) e2933.
[63] Wufeng Xue, Lei Zhang, Xuanqin Mou, Alan C. Bovik, Gradient magnitude
similarity deviation: A highly efficient perceptual image quality index, IEEE
Trans. Image Process. 23 (2) (2013) 684–695.
[64] Lin Zhang, Lei Zhang, Xuanqin Mou, David Zhang, FSIM: A feature similarity
index for image quality assessment, IEEE Trans. Image Process. 20 (8) (2011)
2378–2386.
[65] Lin Zhang, Lei Zhang, Xuanqin Mou, RFSIM: A feature based image quality
assessment metric using Riesz transforms, in: 2010 IEEE International Conference
on Image Processing, IEEE, 2010, pp. 321–324.
[66] Qian Du, Nicholas H. Younan, Roger King, Vijay P. Shah, On the performance
evaluation of pan-sharpening techniques, IEEE Geosci. Remote Sens. Lett. 4 (4)
(2007) 518–522.
[67] Anish Mittal, Anush Krishna Moorthy, Alan Conrad Bovik, No-reference image
quality assessment in the spatial domain, IEEE Trans. Image Process. 21 (12)
(2012) 4695–4708.
[68] Anish Mittal, Rajiv Soundararajan, Alan C. Bovik, Making a ‘‘completely blind’’
image quality analyzer, IEEE Signal Process. Lett. 20 (3) (2012) 209–212.
[69] Jia Yan, Jie Li, Xin Fu, No-reference quality assessment of contrast-distorted
images using contrast enhancement, 2019, arXiv preprint arXiv:1904.08879.
[70] Chinmaya Panigrahy, Ayan Seal, Nihar Kumar Mahato, MRI and SPECT image
fusion using a weighted parameter adaptive dual channel PCNN, IEEE Signal
Process. Lett. 27 (2020) 690–694.
[71] Chinmaya Panigrahy, Ayan Seal, Nihar Kumar Mahato, Fractal dimension based
parameter adaptive dual channel PCNN for multi-focus image fusion, Opt. Lasers
Eng. 133 (2020) 106141.
[72] Ayan Seal, Debotosh Bhattacharjee, Mita Nasipuri, Human face recognition using
random forest based fusion of à-trous wavelet transform coefficients from thermal
and visible images, AEU-Int. J. Electron. Commun. 70 (8) (2016) 1041–1049.
",https://doi.org/10.1016/j.jvcir.2020.103008,doc15,"J. Vis. Commun. Image R. 74 (2021) 103008 Available online 21 December 2020 1047-3203/© 2020 Elsevier Inc. All rights reserved. Contents lists available at ScienceDirect J. Vis. Commun. Image R. journal homepage: www.elsevier.com/locate/jvci Full length article Single image dehazing using a new color channel✩ Geet Sahu a, Ayan Seal a,b,∗, Ondrej Krejcar b,c, Anis Yazidi d a PDPM Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, 482005, India b Center for Basic and Applied Science, Faculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 500 03 Hradec Kralove, Czech Republic c Malaysia-Japan International Institute of Technology (MJIIT), Universiti Teknologi Malaysia, Jalan Sultan Yahya Petra, 54100 Kuala Lumpur, Malaysia d Research Group in Applied Artificial Intelligence, Oslo Metropolitan University, 460167, Norway A R T I C L E I N F O Keywords: Image dehazing Atmospheric light Radiance Illuminance scaling factor A B S T R A C T Images with hazy scene suffer from low-contrast, which reduces the visible quality of the scene, thus making object detection a more challenging task. Low-contrast can result from foggy weather conditions during image acquisition. Dehazing is a process of removal of haze from the photography of a hazy scene. Single-image dehazing based on dark channel priors are well-known techniques in this field. However, the performance of such techniques is limited to priors or constraints. Moreover, this type of method fails when images have sky-region. So, a method is proposed, which can restore the visibility of hazy images. First, a hazy image is divided into blocks of size 32 × 32, then the score of each block is calculated to select a block having the highest score. Atmospheric light is calculated from the selected block. A new color channel is considered to remove atmospheric scattering, obtained channel value and atmospheric light are then used to calculate the transmission map in the second step. Third, radiance is computed using a transmission map and atmospheric light. The illumination scaling factor is adopted to enhance the quality of a dehazed image in the final step. Experiments are performed on six datasets namely, I-HAZE, O-HAZE, BSDS500, FRIDA, RESIDE dataset and natural images from Google. The proposed method is compared against 11 state-of-the-art methods. The performance is analyzed using fourteen quantitative evaluation metrics. All the results demonstrate that the proposed method outperforms 11 state-of-the-art methods in most of the cases. 1. Introduction Natural images and their perception play an important role in image visualization and understanding. Bright images can improve the preci- sion of computer vision applications such as surveillance [1], object detection [2], image classification [3], image/video retrieval [4], and land cover identification in remote sensing images [5] through proper understanding. Therefore, a clear image is an essential requirement in image processing and computer vision-based tasks. However, it is always hard to capture clear images, especially in degraded visibility conditions. Haze present in the atmosphere degrades the visibility of images drastically. It could be in the form of fog, smoke, dust, or mist. The haze particles pervert or sometimes completely cease the light rays emanating from the image. Light rays scatter in different directions when they strike with atmospheric particles. The amount of scattering depends on the distance between the image and the camera. Although haze is a natural phenomenon, most cameras cannot always cope up with such type of environment. The camera captures the ✩This paper has been recommended for acceptance by Zicheng Liu. ∗Corresponding author at: PDPM Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, 482005, India. E-mail address: ayan@iiitdmj.ac.in (A. Seal). light coming from the image, blended with light coming from other directions called the airlight. Haze in images results in faded color, low contrast, and loss in the visibility of the image. Reduction of visibility in images causes a problem in camera-guided vehicles, autonomous vehicle and navigation based systems. Depth analysis, color preserva- tion and visibility enhancement are the challenging tasks for dehazing. Therefore, an efficient algorithm is needed to remove haze from the captured scenes and thus for making computer vision applications more reliable. In [6], Koschmieder presented an image formation model, also known as the degradation model that is widely used in dehazing. Eq. (1) is used to formally describe the model. It consists of two atmospheric scattering characteristics namely, direct attenuation and airlight. The former one describes the amount of unscattered light, 𝐽(𝑚)𝑡(𝑚), which travels directly from the image to the camera. In contrast, the latter one, 𝐴(1−𝑡(𝑚)), is the amount of light coming from the scattered atmospheric particle. The degradation model is also portrayed in Fig. 1, where the Received 9 March 2020; Received in revised form 12 November 2020; Accepted 13 December 2020 Journal of Visual Communication and Image Representation 74 (2021) 103008 2 G. Sahu et al. blue and red dashed lines denote the direct attenuation and airlight respectively. 𝐼(𝑚) = 𝐽(𝑚)𝑡(𝑚) + 𝐴(1 −𝑡(𝑚)), (1) where 𝐼is the captured hazy scene, 𝐽is the scene radiance which is needed to recover, 𝑡is the medium transmission. The function 𝑡in the above equation can be expressed as 𝑡(𝑚) = 𝑒𝛽∗𝑑(𝑚), where 𝛽is atmospheric scattering coefficient and 𝑑(𝑚) is the distance between an object and a camera, 𝐴is the global atmospheric light, and 𝑚is the pixel coordinates. Existing image dehazing methods can be broadly classified into groups: traditional approaches and learning-based methods. Traditional methods are further categorized into the method based on a phys- ical models such as polarimetric image dehazing [7–9] and image enhancement method such as linear transformation [10], structure- preserving [11], histogram-based [12,13], wavelet-based [14,15], retinex methods [16–18] and dark channel prior (DCP) [19–24]. Simi- larly, learning-based methods use machine learning and deep learning approaches [25–31] for dehazing. All the above mentioned methods are discussed here briefly. Polarimetric methods depend on the de- gree of polarization. Different methods considered this phenomenon for dehazing. Schechner et al. [7] and Shwartz et al. [8] presented polarized filters-based methods. Multiple images of the same scene having different degrees of polarization are required for these methods. However, these methods fail since polarizing filters are not able to gain rapid changes in the scene. These techniques [7,8] used multiple images of the same scene, which is difficult to capture in real-time. Therefore, single image dehazing methods [20,21,25,26] are getting more attention in recent years. However, all these works are based on some assumptions. In [32], Gao et al. presented a multi-focus fusion method for dehazing. First, an atmospheric light was estimated from the sky region, then a fast local Laplacian filtering with adaptive boundary constraint was introduced to refine the transmission map by reducing oversaturation in the image. Finally, a multi-focus image fusion method was applied to recover the image. Qi et al. [11] dis- cussed a structure-preserving method for dehazing. First, the minimum channel of the hazy image was estimated, then the structure detail of the minimum channel was considered as a reference image. The minimum channel was filtered to derive an initial airlight, which was refined further by joint bilateral filter guided by reference image. Atmospheric light was calculated using a quad-tree subdivision method. Finally, radiance was stored using the atmospheric attenuation model. Further, the histogram equalization (HE) method was explored to enhance the contrast of a hazy image by increasing the gray distribution of images. In [12,13], contrast limited adaptive HE was combined with the finite impulse response filter and weiner filter to enhance the contrast of images. However, the performance of HE method is not satisfactory for color images. The wavelet transform method is considered for image dehazing. He et al. [14] offered an optical model and regularized optimization for restoring images. First, they converted non-convex, bilinear problem to a convex, linear optimization problem by estimating the atmosphere light constant and then they applied multilevel Haar wavelet transform. The optimization was achieved by applying the algorithm to the low-frequency sub-band decomposition of the original image to accelerate the processing speed. Further, Khmag et al. [15] employed mean vector L2-norm to estimate the transmission map and enhanced it by second-generation wavelet transform filter. However, color-shift occurred in the resulting images. Moreover, the Retinex based methods were also considered for image enhancement. The principal concept of the Retinex method is to derive reflectance and illuminance component of an image which is further used to remove haze. Yang et al. [16] combined sub-block local information using an adaptive filter to calculate the luminance of an image. Further, Hu et al. [17] utilized bilateral filtering to estimate the illumination component. In [18], Shu et al. presented a multi-scale Retinex image enhancement method on sub-band image decomposition to enhance the contrast of the image. Retinex methods are easy to implement, however, it causes a halo effect in images and make it too bright. Further, He et al. [19] described a DCP method for single image dehazing. According to the DCP method, most of the local patches in outdoor haze-free color images have very low-intensity values in at least one color channel. Transmission map and atmospheric light were estimated based on the above said assumption. However, the DCP does not work well if the image consists of a sky region [33]. Galdran [34] dehazed the image without estimating the transmission map. The gamma correction operations were employed to artificially under-expose images. Further, the images were dehazed using a multi- scale Laplacian blending scheme. Fang [35] presented a fast variational method. First, the transmission map was estimated by a window based adaptive method based on the celebrated DCP. The transmission map was then converted into a depth map to built a new variational model and restore the image. Later, Wang et al. [36] combined the DCP with the total variation models namely, layered total variation, multichannel total variation, and color total variation regularizers, for dehazing. Fast split Bregman algorithms were explained to improve the efficiency of the models. Further, Hou et al. [37,38] considered the DCP method in underwater images by employing underwater total variation models to restore images. Recently, learning-based methods are gaining attention due to their ability to learn features automatically. Tang et al. [25] used the random forest to estimate the transmission map and refined it by a guided filter. Further, the image degradation model and white balance restoration were exploited to restore the image. In [26], Zhu et al. pre- sented a color attenuation prior and linear model to estimate the depth map. They utilized supervised learning to learn model parameters, which helped to better estimate the transmission map. In [27], Gui et al. exploited Support Vector Machine (SVM) for dehazing. First, the feature vectors were extracted using the dark channel histogram and texture features of the hazy images. The feature vectors were then trained by the SVM algorithm to realize the automatic binary classification of images. Second, the dehazing methods processed the classified hazy image and the dehazed image was evaluated based on the performance of different dehazing methods. Finally, this model helped to produce a better dehazed image. Further, in [28], Cai et al. presented DehazeNet to extract features from hazy images and used non-linear functions to estimate the transmission map of the input image. Moreover, Ren et al. [29] suggested a multi-scale convolutional neural network, which computes a coarse transmission map using coarseNet, then feeds the resultant transmission map to the second CNN of FineNet to refine transmission map. Since the above mentioned models uses CNN to estimate the transmission map and further process it to get a dehazed image, therefore, Li et al. [30] and Guo et al. [31] presented dehazing network to predict a dehazed image directly. Although deep learning- based methods give better results. However, these methods suffer from several problems [39]. First, they require immense amount of training time. Second, they are greedy in terms of data, meaning they require a huge amount of data. Finally, most of the models are trained on synthetic data. Hence, the generalization problem can occur. Therefore, a new DCP based method is introduced for dehazing images in this study. The salient contributions are as follows: • Atmospheric light is estimated by dividing an image into blocks, then the score of each block is computed. The block having the highest score is further picked for calculating the atmospheric light. • A new color model is adopted to calculate the transmission map, which is further used for computing radiance. • At last, we enhance the dehazed image using the illuminance scaling factor to improve its visibility. Since the complexity of deep learning-based methods are relatively high in terms of time and data, only traditional methods are considered for comparison in this study. All the experiments are performed on Journal of Visual Communication and Image Representation 74 (2021) 103008 3 G. Sahu et al. Fig. 1. Image degradation model. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.) six publicly available benchmark datasets namely, O-HAZE [40], I- HAZE [41], Berkeley Segmentation Dataset (BSDS500) [42], REalistic Single Image DEhazing (RESIDE) [43], Foggy Road Image DAtabase (FRIDA) [44] and natural hazy images from Google. The proposed method is compared with 11 state-of-the-art methods based on ten full reference and six no-reference quality assessment metrics. The empiri- cal results illustrate that the proposed DCP based method outperforms 11 state-of-the-art methods in most of the cases. The rest of the work is organized as follows: Section 2 describes the material and methods used in this work. A new color model to estimate the transmission map and a novel method to calculate atmospheric light are described in Section 3. Experimental results are reported in Section 4. The proposed method is also compared with eleven state-of-the-art methods in Section 4. Finally, Section 5 concludes this work. 2. Material and method This section first discusses the DCP method followed by a detailed survey of the DCP based state-of-the-art methods. 2.1. DCP method Based on the fact that haze depends on unknown depth, dehazing is therefore very challenging. Many methods were presented to measure the depth of haze. One of the popular methods is DCP. This method is based on the statistics of haze-free outdoor images. It is observed that most of the RGB images have very low-intensity pixels in at least one color channel of the non-sky patches. The thickness of the haze can be estimated directly using prior information, which helps further to generate a haze-free image. Algorithm 1 describes the approach used by He et al. [19] to obtain a dehazed image. All the steps of DCP method are as follows: • Dark Channel He et al. [19] experimented to investigate the features of haze- free images. They observed that there are some pixels whose intensity values are nearly zero in a local patch of the image. Moreover, they formed a separate channel comprising of these low-intensity pixels and named it a dark channel that is defined in Eq. (2). 𝐽𝑑𝑎𝑟𝑘(𝑚) = 𝑚𝑖𝑛𝑐∈{𝑅,𝐺,𝐵}(𝑚𝑖𝑛𝑝(𝐽𝑐(𝑝))), (2) where 𝐽is the input image, 𝑐is a particular color channel of 𝐽, 𝑝 is a local patch centered at 𝑚, 𝐽𝑑𝑎𝑟𝑘is the dark channel of image 𝐽and 𝑚is the pixel coordinate. • Atmospheric Light Atmospheric light was calculated by selecting the top 0.1% bright- est pixels from 𝐽𝑑𝑎𝑟𝑘then mapping these chosen values to the input image and the highest intensity pixel was then selected as atmospheric light. • Transmission map The transmission map of the image was derived using the degra- dation model described in Eq. (1). Applying minimum operation patch-wise on both sides of Eq. (1), He et al. got 𝑚𝑖𝑛𝑝(𝐼𝑐(𝑚)) = 𝑡(𝑚)𝑚𝑖𝑛𝑝(𝐽𝑐(𝑚)) + 𝐴𝑐(1 −𝑡(𝑚)), (3) Now, by applying minimum operation channel-wise on Eq. (3), He et al. show 𝑚𝑖𝑛𝑐 ( 𝑚𝑖𝑛𝑝 ( 𝐼𝑐(𝑚) 𝐴𝑐 )) = 𝑡(𝑚)𝑚𝑖𝑛𝑐 ( 𝑚𝑖𝑛𝑝 ( 𝐽𝑐(𝑚) 𝐴𝑐 )) + (1 −𝑡(𝑚)), (4) Since 𝐽𝑑𝑎𝑟𝑘of the haze-free image tends to zero and atmospheric light is always positive, therefore 𝑚𝑖𝑛𝑐 ( 𝑚𝑖𝑛𝑝 ( 𝐽𝑐(𝑚) 𝐴𝑐 )) = 0, (5) Substituting Eq. (5) in Eq. (4), transmission map can be derived as: 𝑡(𝑚) = 1 −𝑚𝑖𝑛𝑐 ( 𝑚𝑖𝑛𝑝 ( 𝐼𝑐(𝑚) 𝐴𝑐 )) , (6) Since a small amount of haze is always present in natural images, to preserve the naturalness of images, a small amount of haze was introduced in the form of constant 𝜔(0 < 𝜔≤1) in Eq. (6): 𝑡(𝑚) = 1 −𝜔𝑚𝑖𝑛𝑐 ( 𝑚𝑖𝑛𝑝 ( 𝐼𝑐(𝑚) 𝐴𝑐 )) , (7) The transmission map was estimated using Eq. (7) contains block effects. Therefore, it was further refined using soft matting to get smooth transmission. • Radiance Radiance was calculated using an estimated transmission map and atmospheric light. Radiance is derived from Eq. (1) and can be calculated as shown in Eq. (8). 𝐽(𝑚) = 𝐼𝑐(𝑚) −𝐴𝑐 𝑚𝑎𝑥(𝑡(𝑚), 𝑡0) + 𝐴𝑐, (8) The transmission was restricted to a lower bound 𝑡0, used to preserve a small amount of haze in the restored image. Journal of Visual Communication and Image Representation 74 (2021) 103008 4 G. Sahu et al. Algorithm 1 DCP based dehazing method Input: Hazy Image, 𝐼 Output: Radiance, 𝐽 1: Find dark channel prior of hazy image 𝐼, 𝐽dark(𝑚) = 𝑚𝑖𝑛c∈{R,G,B}(𝑚𝑖𝑛p(𝐽c(𝑝))) 2: Select 0.1% brightest pixel from 𝐽𝑑𝑎𝑟𝑘. 3: Pick highest intensity value from 𝐼as atmospheric light. 4: Calculate transmission, 𝑡(𝑚) = 1 −𝜔𝑚𝑖𝑛𝑐(𝑚𝑖𝑛𝑝( 𝐼𝑐(𝑚) 𝐴𝑐)) 5: Refine transmission using soft matting. 6: Finally compute radiance, 𝐽(𝑚) = 𝐼𝑐(𝑚)−𝐴𝑐 𝑚𝑎𝑥(𝑡(𝑚),𝑡0) + 𝐴𝑐 Dehazing based on DCP method [19] is useful however, the images obtained after dehazing generally introduce artifacts, halo effects and distortion of edges and color in images. Even the time complexity of this method is very high due to soft matting operation. Estimation of atmospheric light also fails when the image contains some brighter ob- jects and the major drawback of this method is that it is not applicable for images containing sky region. It results in a color-shift in the sky region, which makes images look darker. 2.2. DCP based methods In literature, there are many methods based on DCP. In this sec- tion, we present a few of them briefly. He et al. [19] used DCP and refined transmission map using soft matting, however, their method generates images with artifacts and color distortion. Later, Colores et al. [24] removed artifact using pixel-wise maximum operation in the modified dark channel. Moreover, Zhao et al. [45] presented a Trans- mission MisEstimated (TME) recognition method to distinguish the TME and non-TME regions. They calculated pixel-wise and patch-wise transmission maps separately, then they combined both transmission maps optimally using a multi-scale optimal fusion scheme to avoid the misestimated transmission region. The multi-scale optimal fusion was used further into patch-wise dehazing to suppress halo artifacts. Tan et al. [46] calculated a coarse transmission map, then refined it using a fine transmission map to remove halo effects. Cheng et al. [47] estimated dark channels using two different patch sizes, one large and another small. The hybrid DCP technique was considered to avoid the generation of artifacts. Xiao and Gan [48] estimated atmospheric light through median filter then refined it using guided joint bilateral filtering to generate a new atmosphere light. This modified atmospheric light removes color distortion from the image. Long et al. [49] exploited a low-pass Gaussian filter to refine atmosphere veil. Lin and Wang [50] considered improved guided filtering to estimate the transmission map. Ancuti and Ancuti [51] applied local white balance and contrast en- hancement procedure to remove haze from images. The result yields visually pleasing images however, it is not physically valid. Moreover, Zhu et al. [33] presented a fusion of luminance and DCP method. The luminance of the image was employed to calculate the transmission map of the sky region. They combined the transmission map calculated from the sky and non-sky regions to compute the overall transmission map. Further, they used the DCP method to remove haze from image. However, the method introduced more brightness in the images that are already brighter therefore the dehazed image looks unnatural. Further, Sahu and Seal [52] presented two luminance stretching models to adjust the brightness of the dehazed image to some extent. After investigating all the existing methods based on DCP, it is observed that the main challenges of dehazing are to estimate the atmospheric light and the transmission map. It is noted that the at- mospheric light cannot be precisely determined by just picking x% brightest pixel from the dark channel of the whole image. A previous study [53] revealed that global atmospheric light influences error in calculation. Even the transmission map cannot be generated accurately by only applying dark channel operation on the image. The limitations of the above mentioned DCP based state-of-the-art methods illustrate that there is a chance to devise a DCP based method, which can further enhance the quality of a dehazed image. 3. Proposed work In this section, the proposed method is discussed for generating a dehazed image from the input hazy image. Several steps associated with the proposed method are shown in Fig. 2. The different steps involved in the proposed method are as follows: 3.1. Atmospheric light It is clear from Section 2 that the DCP method considered a global approach while estimating an atmospheric light. It is also observed that the global approach suffers from limitations as discussed in the same section. Therefore, instead of considering a global atmospheric light, the proposed method estimates atmospheric light from the local region. Initially, an image, 𝐼, is divided into equal-sized blocks, as shown in Fig. 3. Although, it is a challenging task to decide the size of an ideal block, the best block size is determined by conducting several experiments using varying block sizes, 𝑏. It is observed that the proposed method achieved the best dehazed images when the block size is 32 × 32, which is considered throughout this study. However, the results of all the experiments are beyond the scope of this study. A typical block, 𝐵𝑖, consists of 32 × 32 = 1024 pixels. Then the score of each 𝐵𝑖is computed as the average pixel value subtracted by the standard deviation of the pixel values within that block. The candidate block, 𝐵𝑢, marked by green color in Fig. 3, is selected, which has the highest score, 𝑀𝑎𝑥. Then to avoid the effects of suspended particles, we pick the top 1% of 1024 pixels i.e., 10 brightest pixels of the dark channel of the candidate block. Here, we consider the top 1% brightest pixels instead of 0.1% brightest pixels, since 0.1% will correspond to a single pixel and single pixel can be a noisy pixel which will lead to the wrong estimation of atmospheric light. Further, the selected pixels are mapped to the original image. Then the median value of the selected pixels is computed. We consider the median value as it is less affected by noises or outliers. Finally, the median value is considered as the atmospheric light, 𝐴. Algorithm 2 gives a brief description of each step followed to estimate 𝐴. Algorithm 2 Procedure for estimating the atmospheric light Input: Hazy Image, 𝐼 Output: Atmospheric light, 𝐴 1: Divide the input into blocks of size 𝑏. ⊳𝑏is taken as 32×32 2: 𝑀𝑎𝑥= 0 3: for all blocks, 𝐵𝑖, in I do 4: 𝑠(𝑖) = 𝜇(𝐵𝑖) −𝜎(𝐵𝑖) ⊳𝜇is mean and 𝜎is standard deviation 5: 𝑀𝑎𝑥= 𝑚𝑎𝑥(𝑀𝑎𝑥, 𝑠(𝑖)) 6: end for 7: Select block 𝐵𝑢having 𝑀𝑎𝑥value 8: for l=1 to row do ⊳row and col of 𝐵𝑢, which are 32 in this case 9: for k=1 to col do 10: 𝑑𝑎𝑟𝑘= 𝐷𝐶(𝐵𝑢) ⊳DC is dark channel 11: end for 12: end for 13: Select the top h% brightest pixels from 𝑑𝑎𝑟𝑘 ⊳ℎis taken as 1% 14: 𝐴= 𝑚𝑒𝑑𝑖𝑎𝑛(𝐵𝑢(ℎ)) The informed reader would notice that our algorithm differs from the main stream of state-of-the-art algorithms which rather operate with segmenting an image into two regions namely, sky and non-sky regions, then extracting the atmospheric light from the sky region. Our proposed method does not segment an image into the above-mentioned two regions explicitly. Instead of considering a segmentation algorithm for dividing an image into two regions, we apply Algorithm 2 to compute atmospheric light. Algorithm 2 divides an image into several equal-sized blocks and then atmospheric light is calculated from a Journal of Visual Communication and Image Representation 74 (2021) 103008 5 G. Sahu et al. Fig. 2. Different steps involved in the proposed method are (a) Image in N channel, (b) Calculation of atmospheric light, (c) Generation of transmission map, (d) Refinement of transmission map, (e) Dehazed image and (f) Enhancement of dehazed image. Fig. 3. Selection of a block having the maximum score, 𝑀𝑎𝑥. Here, the box marked by green color indicates the candidate block, 𝐵𝑢. block, which is selected based on statistical features namely, mean and standard deviation. We thus did not opt for a segmentation phase using for instance grab cut explicitly because not only it incurs an additional computational cost but it also does not necessarily improve the re- sults. We have tested indeed two very recent methods for extracting the atmospheric light involving the grab cut segmentation algorithm [54,55]. However, these results are not included in the manuscript because, in most cases, the grab cut algorithm fails to separate the sky region from an image. On the other hand, the proposed Algorithm 2 computes atmospheric light from the sky region in most of the cases. Nevertheless, sometimes Algorithm 2 fails especially when images are captured in indoor conditions. 3.2. Transmission map In almost every DCP based methods, transmission map is calculated using Eq. (9). 𝑡(𝑚) = 1 −𝜔𝑚𝑖𝑛𝑐∈{𝑅,𝐺,𝐵} ( 𝑚𝑖𝑛𝑝 𝐼𝑐(𝑝) 𝐴𝑐 ) , (9) where 𝑐is a particular color channel of 𝐼, 𝑝is a local patch centered at 𝑚, 𝜔(0 < 𝜔≤1) is a constant used to preserve a small amount of haze in image. However, the value estimated using Eq. (9) is not accurate always. Therefore, a new color channel, 𝑁, is adopted to calculate the transmission map. The motivation behind the use of a new color channel is as follows. It is observed that illumination present in the sky region of an image is not uniform or homogeneous and it happens due to the difference in atmospheric scattering angles. Moreover, the inhomogeneous brightness distribution of an image, especially the sky region, creates a serious issue while estimating the transmission map. So, a relatively new color channel is adopted to the removal of atmospheric scattering. The new channel is computed using Eq. (10) [56]. 𝑁= 𝜙−(𝛼−𝛽), (10) where 𝜙is known as the panchromatic channel and it refers to the channel which is sensitive to all visible colors. In other words, 𝜙is also called gray-scale image obtained by 𝜙= 0.299𝑅+0.587𝐺+0.114𝐵, where 𝑅, 𝐺, 𝐵are the red, green, and blue channels of an RGB color image, Journal of Visual Communication and Image Representation 74 (2021) 103008 6 G. Sahu et al. Table 1 Value of score corresponding to each block of Fig. 3. Blocks Score 0.7780 0.8053 0.7898 0.7326 0.7705 0.7427 0.7220 0.6336 0.3157 0.5389 0.6266 0.6092 0.6476 0.5797 0.5631 0.4532 0.1767 0.3073 0.4157 0.4168 0.3828 0.4424 0.4021 0.3935 0.2004 0.2600 0.3133 0.3136 0.2493 0.3450 0.3506 0.3647 0.1853 0.2371 0.2709 0.2812 0.1943 0.2438 0.3169 0.2628 0.1673 0.1554 0.1895 0.1983 0.2085 0.2376 0.2319 0.1859 0.2679 0.1993 0.1907 0.1882 0.1567 0.2399 0.2034 0.1642 0.2234 0.2360 0.2333 0.1747 0.1681 0.2077 0.1964 0.1856 Table 2 Comparison of the RMSE value between the ground truth and the estimated atmospheric light of the ten images taken from FRIDA dataset [44]. Images M1 [19] M2 [48] M3 [49] M4 [50] M5 [47] M6 [46] M7 [26] M8 [33] M10 [24] M11 [45] M12 img1 0.0350(2) 0.7480 0.0649 0.0651 0.0379(3) 0.0350(2) 0.0757 0.7478 0.0523 0.0350(2) 0.0348(1) img2 0.0406(2) 0.7480 0.0913 0.0466 0.0608 0.0407(3) 0.0863 0.7477 0.0560 0.0406(2) 0.0402(1) img3 0.0478(2) 0.7847 0.0874 0.0851 0.0638 0.0479(3) 0.0874 0.7847 0.0614 0.0478(2) 0.0473(1) img4 0.0482(2) 0.7847 0.0739 0.0869 0.0489 0.0482(2) 0.0482(2) 0.7847 0.0488(3) 0.0482(2) 0.0478(1) img5 0.0401(2) 0.8353 0.0606 0.1164 0.0406 0.0401(2) 0.0401(2) 0.8353 0.0405(3) 0.0401(2) 0.0400(1) img6 0.0398(2) 0.8353 0.0771 0.1167 0.0431(3) 0.0398(2) 0.0398(2) 0.8353 0.0431 0.0398(2) 0.0395(1) img7 0.0151(3) 0.8466 0.0341 0.0122(1) 0.0152 0.0151(3) 0.0151(3) 0.8464 0.0155 0.0151(3) 0.0150(2) img8 0.0151(3) 0.8466 0.0224 0.0122(1) 0.0151(3) 0.0151(3) 0.0151(3) 0.8464 0.0151(3) 0.0151(3) 0.0148(2) img9 0.0172(3) 0.8466 0.0172(3) 0.0144(1) 0.0172(3) 0.0172(3) 0.0172(3) 0.8464 0.0173 0.0172(3) 0.0171(2) img10 0.0339(2) 0.9143 0.0407 0.0660 0.0339(2) 0.0339(2) 0.0339(2) 0.9141 0.0341(3) 0.0339(2) 0.0337(1) Table 3 Names of the ten images taken from RESIDE dataset [43] and their estimated RMSE values by various methods. Images M1 [19] M2 [48] M3 [49] M4 [50] M5 [47] M6 [46] M7 [26] M8 [33] M10 [24] M11 [45] M12 img11 0.3949(2) 0.7777 0.8257 0.6803 0.7189 0.6594(3) 0.6674 0.7515 0.6983 0.8795 0.1851(1) img12 0.5509(2) 0.7643 0.8097 0.6713 0.7081 0.6553 0.6155(3) 0.7093 0.6906 0.8588 0.3812(1) img13 0.9784 0.0690 0.0977 0.0908 0.0528(2) 0.0362(1) 0.1562 0.0632 0.0552(3) 0.2011 0.6530 img14 0.4840(2) 0.8004 0.8550 0.7069 0.7403 0.6747(3) 0.7216 0.7361 0.7176 0.9044 0.2963(1) img15 0.6670(2) 0.7722 0.7756 0.7320 0.7449 0.7307(3) 0.7687 0.7647 0.7614 0.7828 0.3371(1) img16 0.7456 0.6855 0.7333 0.5649 0.6304 0.5611 0.4443(3) 0.5747 0.6028 0.4335(2) 0.3051(1) img17 0.9789 0.0913 0.1211 0.0699 0.0702 0.0490(2) 0.1651 0.0730 0.0515(3) 0.2041 0.0283(1) img18 0.9784 0.0751 0.1028 0.0720 0.0579 0.0411(3) 0.1058 0.0476 0.0378(2) 0.2064 0.0149(1) img19 0.9784 0.0951 0.1217 0.0795 0.0721 0.0526(2) 0.4607 0.0711 0.0552(3) 0.2064 0.0258(1) img20 0.9784 0.0786 0.1087 0.0890 0.0589 0.0419(2) 0.4327 0.0546 0.0475(3) 0.2059 0.0103(1) respectively. The 𝛼= 𝑚𝑎𝑥{𝑅, 𝐺, 𝐵} is called the bright channel and it denotes the maximum value of each pixel in an RGB color image. The 𝛽= 𝑚𝑖𝑛{𝑅, 𝐺, 𝐵} is known as the dark channel and it represents the channel of the minimum value of each pixel in a RGB color image. In general, the blue and red channels are the bright and the dark channels respectively for most of the images with the sky regions. The difference between the blue and red channels represents the deviation of the atmospheric scattering of each pixel in the visible range, which can be considered as the atmospheric background for estimating the transmission map in this study. The modified equation to compute the transmission map is shown in Eq. (11). An experiment is performed to prove the correctness of Eq. (11), which will be discussed in Section 4. 𝑡(𝑚) = 1 −𝜔𝑚𝑖𝑛𝑝 ( 𝑁(𝑝) 𝐴 ) , (11) where 𝜔and 𝑝are taken as 0.85 and 15, respectively. The coarse trans- mission map calculated using Eq. (11) suffers from block artifacts and halo effects because transmission is not always constant in the patch. Therefore, filters are used to refine the transmission in order to remove noise. Several filters, for example, bilateral filter, gaussian filter, soft matting, cross-bilateral filter, and guided filter were considered for the refinement. One of the previous studies [57] revealed that soft matting, cross-bilateral filter, and guided filter provide sharper transmission maps than gaussian and bilateral filters. Moreover, Lee [57] proved that the soft matting performed the best, and the cross-bilateral and guided filters stood in second. However, the time complexity of the guided filter is low as compared to others. The complexity is expressed as O(N), where N is the total number of pixel of 𝐼[58]. Moreover, a guided filter performs edge-preserving smoothing operation on 𝐼using the information of the guidance image. Further, it does not suffers from the gradient reversal artifacts that can be observed while using bilateral filter. The output image, ̂𝑡, can be represented as a linear combination of the guidance image, 𝐼, in a guided filter. Here, the guided filter is used to optimize the transmission map as shown in Eq. (12). ̂𝑡𝑖= 𝑎𝑚𝐼𝑖+ 𝑏𝑚, ∀𝑖𝜖𝑤𝑚, (12) where 𝑎𝑚and 𝑏𝑚are two constants in window 𝑤𝑚centered at pixel 𝑚. The value of 𝑎𝑚and 𝑏𝑚are obtained by Eqs. (13) and (14), respectively. 𝑎𝑚= 1 |𝑤| ∑ 𝑖𝜖𝑤𝑚𝐼𝑖𝑡𝑖−𝜇𝑚𝑡′ 𝑚 𝜎2 𝑚+ 𝜖 , (13) 𝑏𝑚= 𝑡′ 𝑚−𝑎𝑚𝜇𝑚, (14) where 𝑡is the coarse transmission map, 𝜎2 𝑚is the variance, 𝜇𝑚is the mean of 𝐼, 𝑡′ = 1 |𝑤| ∑ 𝑖𝜖𝑤𝑚𝑡𝑖, and |𝑤| is the total number of pixels in filter 𝑤𝑚. 3.3. Radiance After calculating 𝐴and 𝑡using the above said methods, the radiance of an image is recovered by the Eq. (1). However, the direct attenuation Journal of Visual Communication and Image Representation 74 (2021) 103008 7 G. Sahu et al. Fig. 4. Illustration of results of atmospheric light estimation algorithm. Red box indicates the selected block. Fig. 5. (a) A sample image, ‘img11’, of RESIDE [43] dataset, (b) given transmission map, obtained transmission maps by, (c) M1 [19], (d) M2 [48], (e) M3 [49], (f) M4 [50], (g) M5 [47], (h) M6 [46], (i) M7 [26], (j) M8 [33], (k) M10 [24], (l) M11 [45] and (m) M12. Journal of Visual Communication and Image Representation 74 (2021) 103008 8 G. Sahu et al. Fig. 6. (a) A sample image, ‘img12’, of RESIDE [43] dataset, (b) given transmission map, obtained transmission maps by (c) M1 [19], (d) M2 [48], (e) M3 [49], (f) M4 [50], (g) M5 [47], (h) M6 [46], (i) M7 [26], (j) M8 [33], (k) M10 [24], (l) M11 [45] and (m) M12. Journal of Visual Communication and Image Representation 74 (2021) 103008 9 G. Sahu et al. Fig. 7. Image dehazing results of twelve different methods on BSDS500 [42] dataset, (a) hazy image, (b) ground truth image, output of (c) M1 [19], (d) M2 [48], (e) M3 [49], (f) M4 [50], (g) M5 [47], (h) M6 [46], (i) M7 [26], (j) M8 [33], (k) M9 [34], (l) M10 [24], (m) M11 [45] and (n) M12. term 𝐽(𝑚)𝑡(𝑚) may be close to zero when the transmission 𝑡(𝑚) is close to zero [29]. Therefore, the transmission map is restricted by a constant 𝑡0. Finally, the scene radiance 𝐽(𝑚) is recovered using Eq. (15). 𝐽(𝑚) = 𝐼𝑐(𝑚) −𝐴𝑐 𝑚𝑎𝑥(̂𝑡(𝑚), 𝑡0) + 𝐴𝑐, (15) here value of 𝑡0 is taken as 0.1. 3.4. Enhancement After the restoration of radiance, it is being observed that an image becomes either too bright or too dark. Therefore, to improve the visi- bility of the image, adjustment of illuminance is required. Illuminance scaling factor [25] is used to adjust the illumination of the image, which is calculated using Eq. (16). 𝑠(𝑚) = 𝛶𝐽(𝑚)𝛶𝐼(𝑚) + 𝜏𝛶1.5 𝐼(𝑚) 𝛶3 𝐽(𝑚) + 𝜏𝛶1.5 𝐼(𝑚) , (16) where 𝑠(𝑚) is the illuminance scaling factor, 𝛶𝐽is the illumination intensity of the dehazed image, 𝛶𝐼is the illumination intensity of the input image, 𝜏is a constant taken as 1.2. Thus, the enhanced image can be obtained by using Eq. (17): 𝐸(𝑚) = 𝐽𝑐(𝑚) ∗𝑠(𝑚), (17) where 𝐸is the enhanced haze-free image. All the steps of the proposed method are written in the form of an Algorithm 3. Algorithm 3 Removal of haze Input: Hazy Image 𝐼and atmospheric light 𝐴 Output: Enhanced Image, 𝐸 1: Find 𝑁, 𝑁= 𝜙−(𝛼−𝛽) 2: Calculate 𝐴using Algorithm 2 3: for all pixels m, do 4: Estimate transmission, 𝑡(𝑚) = 1 −𝜔𝑚𝑖𝑛p( 𝑁(𝑝) 𝐴) 5: end for 6: Refine transmission map using guided filter 7: Compute radiance, 𝐽(𝑚) = 𝐼𝑐(𝑚)−𝐴𝑐 𝑚𝑎𝑥(𝑡(𝑚),𝑡0) + 𝐴𝑐 8: for all pixels m, do 9: Calculate illuminance scaling factor, 𝑠(𝑚) = 𝛶J(m)𝛶I(m)+𝜏𝛶1.5 𝐼(𝑚) 𝛶3 𝐽(𝑚)+𝜏𝛶1.5 𝐼(𝑚) 10: end for 11: Enhanced image, 𝐸(𝑚) = 𝐽c(𝑚) ∗𝑠(𝑚) Journal of Visual Communication and Image Representation 74 (2021) 103008 10 G. Sahu et al. Fig. 8. Image dehazing results of twelve different methods on I-HAZE [41] dataset, (a) hazy image, (b) ground truth image, output of (c) M1 [19], (d) M2 [48], (e) M3 [49], (f) M4 [50], (g) M5 [47], (h) M6 [46], (i) M7 [26], (j) M8 [33], (k) M9 [34], (l) M10 [24], (m) M11 [45] and (n) M12. 4. Experimental results and discussion All the experiments are performed in MATLAB R2018a using a PC having Intel(R) Core™i7-4770 CPU @ 3.40 GHz and 4 GB RAM. 4.1. Database description To evaluate the performance of the proposed method, six datasets namely, O-HAZE, I-HAZE, BSDS500, RESIDE, FRIDA, and natural hazy images from Google, are used. The reason behind including many datasets is to compare the performance on various environmental con- ditions. The O-HAZE dataset consists of 45 outdoor scene pairs of real hazy and corresponding haze-free images. The I-HAZE dataset contains 35 pairs of hazy and corresponding haze-free indoor images. All the hazy images were captured in a real hazy environment generated by professional haze machines maintaining the same value of illumina- tion parameters. The BSDS500 consists of 500 natural images. All the images are clear; there is no haze present in them. One hundred and twenty-five images are selected randomly from BSDS500 and synthetic haze is introduced to make corresponding hazy images. Besides this, RESIDE dataset is also considered to compare the transmission map estimated by the proposed method with other state-of-the-art methods for knowing which method determines a transmission map close to the actual. It consists of real and synthetic hazy images along with their transmission maps. So, we compare all the methods based on the produced transmission maps. The FRIDA dataset is considered to validate the atmospheric light estimation algorithm. The FRIDA dataset consists of 90 synthetic images of 18 urban road scenes. Each fog-free image is associated with four foggy images and a depth map. Different kinds of fog are added on each of the 4 associated images namely, uniform fog, heterogeneous fog, cloudy fog, and cloudy heterogeneous fog. 4.2. Computational protocols Based on the qualitative evaluation, quantitative evaluation, and execution time, the performance of the proposed method is compared with eleven state-of-the-art methods, which are as follows: • M1: Single image haze removal using DCP [19] • M2: Fast image dehazing using guided joint bilateral filter [48] Journal of Visual Communication and Image Representation 74 (2021) 103008 11 G. Sahu et al. Fig. 9. Image dehazing results of twelve different methods on O-HAZE [40] dataset, (a) hazy image, (b) ground truth image, output of (c) M1 [19], (d) M2 [48], (e) M3 [49], (f) M4 [50], (g) M5 [47], (h) M6 [46], (i) M7 [26], (j) M8 [33], (k) M9 [34], (l) M10 [24], (m) M11 [45] and (n) M12. • M3: Fast haze removal for a single remote sensing image using DCP [49] • M4: Dehazing for image and video using guided filter [50] • M5: Visibility enhancement of single hazy images using hybrid DCP [47] • M6: Fast single-image defogging [46] • M7: A fast single image haze removal algorithm using color attenuation prior [26] • M8: Haze removal method for natural restoration of images with sky [33] • M9: Image dehazing by artificial multiple-exposure image fu- sion [34] • M10: Efficient single image dehazing by modifying the DCP [24] • M11: Multi-scale optimal fusion model for single image dehaz- ing [45] • M12: The proposed method 4.3. Results and comparison Three experiments are mainly conducted in this study. The aim of the first experiment is to know how good 𝑀12 is as compared to 𝑀1–𝑀11 while estimating atmospheric light. Here, Fig. 3 is again considered. The score of each 𝐵𝑖is calculated using Algorithm 2 and is tabulated in Table 1. The block, 𝐵𝑢, having the highest score, 𝑀𝑎𝑥, is highlighted by green color in Fig. 3. The highest score is also marked by bold character in Table 1. Moreover, Fig. 4 shows the region bounded by a rectangle, indicating the block used for estimation of atmospheric light, 𝐴. It can be observed that the candidate block, 𝐵𝑢, is selected from the sky region. Further, FRIDA dataset is used for objective analysis. The fog-free images and their respective depth maps are taken from the FRIDA dataset. A foggy image is formed using Eq. (1). However, the value of atmospheric light is provided manually as an input to create a foggy image. Then, algorithm 2 is employed to calculate an atmospheric light. An evaluation metric named root means square error (RMSE) [59] is considered, which computes the value of the RMSE between the input and the estimated atmospheric lights. The ideal value of the RMSE is 0. Table 2 reports the values of the RMSE obtained by 𝑀1 −𝑀12 except 𝑀9 for ten randomly chosen sample images from the FRIDA dataset. A rank either 1st or 2nd or 3rd is assigned to each method for each image, which is enclosed within the bracket. It is clear from Table 2 that the 𝑀12 stands the 1st for most of the images since the values of the RMSE are less as compared to other state-of-the-art methods. However, 𝑀4 estimates the atmospheric light better than others for some images. All the results of Table 2 illustrate that the 𝑀12 is more consistent while estimating an atmospheric light from a foggy image, which shows the effectiveness of the 𝑀12 over 𝑀1–𝑀11. The objective of the second experiment is to determine which method estimates the transmission map better than others. So, the Journal of Visual Communication and Image Representation 74 (2021) 103008 12 G. Sahu et al. Fig. 10. Image dehazing results of twelve different methods on natural hazy images taken from Google, from top to bottom rows: original images, output of M1 [19], M2 [48], M3 [49], M4 [50], M5 [47], M6 [46], M7 [26], M8 [33], M9 [34], M10 [24], M11 [45] and M12. RESIDE dataset is considered only because it has synthetic hazy images and their transmission maps. Ten images are considered randomly from the RESIDE dataset for this experiment. However, the transmission maps obtained by all the methods except 𝑀9 on two synthetic hazy images namely, ‘img11’ and ‘img12’ including themselves are shown in Figs. 5 and 6 respectively. Since 𝑀9 does not estimate an atmospheric light and transmission map, it is not considered in the first two experi- ments. It is clear from both Figs. 5 and 6 that the visual quality of the transmission map obtained by the 𝑀12 is better than the transmission maps generated by 𝑀1–𝑀11 methods. Hence, the 𝑀12 outperforms the other eleven state-of-the-art methods, 𝑀1–𝑀11. However, the visual quality is measured by the human visual system (HVS) and it may vary from person to person. Thus, it is not a unique and sufficient criterion. So, quantitative evaluation is required. Again the RMSE is adopted. Now, the value of RMSE is obtained between the given transmission map and the transmission map obtained by 𝑀1 −𝑀12 except for the 𝑀9 on 10 randomly selected images from the RESIDE dataset and the achieved values of the RMSE are noted in Table 3. Again a rank is Journal of Visual Communication and Image Representation 74 (2021) 103008 13 G. Sahu et al. Table 4 The average values of fourteen quantitative evaluation metrics on BSDS500 [42] dataset. Dataset Metrics M1 [19] M2 [48] M3 [49] M4 [50] M5 [47] M6 [46] M7 [26] M8 [33] M9 [34] M10 [24] M11 [45] M12 BSDS500 SSIM 0.0041(3) 0.0015 0.0022 0.0020 0.0018 0.0022 0.0027 0.9445(2) 0.0026 0.0021 0.0031 0.9608(1) PSNR 6.6111(3) 6.5719 6.6033 6.5918 6.5855 6.6012 6.0331 22.216(2) 6.0991 6.5982 6.6060 49.859(1) MSE 15667.5 15785.2 15685.6 15725.2 15747.4 15698.7 15209.4(3) 390.32(2) 15837.7 15701.1 15685.1 104.37(1) RMSE 122.09(3) 122.59 122.18 122.38 122.28 122.22 178.46 19.75(2) 125.31 122.25 122.16 3.230(1) GMSD 0.00024(2) 0.000501 0.00047 0.00046 0.00043 0.00035 0.00016 0.35735 0.00018 0.00029(3) 0.00042 0.00002(1) BIAS 0.9939(3) 0.9971 0.9944 0.9958 0.9947 0.9950 0.9957 0.0661(2) 0.9959 0.9951 0.9943 0.0202(1) FSIM 0.4773 0.4550 0.4619 0.4743 0.4616 0.4744 0.5092(3) 0.9526(2) 0.5089 0.4691 0.4668 0.9973(1) FSIMc 0.4628 0.4417 0.4482 0.4604 0.4480 0.4606 0.5024(3) 0.9515(2) 0.5020 0.4552 0.4530 0.9973(1) RFSIM 0.9345 0.9517 0.9547(3) 0.9123 0.9255 0.9354 0.9704(1) 0.0004 0.9698(2) 0.9448 0.8942 0.0049 ERGAS 112.926 113.236 112.917 113.100 112.883 113.013 103.85(3) 11.487(2) 103.87 113.040 112.935 21.801(1) BRISQUE 17.307(2) 22.136 22.145 24.512 30.169 24.514 23.142 24.6805 20.629 17.049(1) 33.586 20.585(3) NIQE 3.458(2) 4.051 4.125 3.552 5.191 3.769 4.200 3.590 3.518 3.468(3) 4.958 3.451(1) CEIQ 2.422 2.635(2) 1.402 1.402 2.603 2.574 1.402 2.382 2.285 2.377 2.728(1) 2.608(3) E 0 6.7566 6.9070(3) 0 6.9708(2) 7.0661 0 0 6.7346 6.7789 7.3780(1) 6.8592 Table 5 The average values of fourteen quantitative evaluation metrics on I-HAZE [41] dataset. Dataset Metrics M1 [19] M2 [48] M3 [49] M4 [50] M5 [47] M6 [46] M7 [26] M8 [33] M9 [34] M10 [24] M11 [45] M12 I-HAZE SSIM 0.0043 0.0030 0.0032 0.0031 0.0031 0.0036 0.0058 0.5739(1) 0.0061(3) 0.0033 0.0049 0.5342(2) PSNR 5.8343 5.8084 5.8142 5.8115 5.8128 5.8230 6.9557 12.6206(2) 6.9634(3) 5.8145 5.8418 15.840(1) MSE 17003.9 17105.9 17082.2 17093.4 17087.9 17048.1 13728.6 3556.4(2) 13708.6(3) 17072.3 16975.1 6981.2(1) RMSE 130.33 130.72 130.63 130.67 130.65 130.50 115.89 59.635(1) 115.80(3) 130.59 130.22 90.239(2) GMSD 0.00026(1) 0.00051 0.00049 0.00044 0.00044 0.00039 0.00038(3) 0.2752 0.00028(2) 0.00038 0.00044 0.00043 BIAS 0.9962 0.9990 0.9980 0.9982 0.9982 0.9972 0.9296(3) 0.3271(2) 0.9958 0.9975 0.9962 0.1348(1) FSIM 0.5731 0.5431 0.5288 0.5405 0.5556 0.5565 0.5835(3) 0.8596(1) 0.5289 0.5622 0.5614 0.8474(2) FSIMc 0.5663 0.5364 0.5223 0.5340 0.5506 0.5498 0.5775(3) 0.8509(1) 0.5193 0.5553 0.5402 0.8505(2) RFSIM 0.9485 0.9730(2) 0.9938(1) 0.9583 0.9385 0.9167 0.9296 0.0005 0.9560 0.9379 0.8827 0.9605(3) ERGAS 114.722(3) 114.993 114.889 114.914 114.841 114.805 117.089 51.992(1) 116.996 114.845 114.694 74.422(2) BRISQUE 29.983 15.226(2) 28.435 26.743 9.714(1) 18.059 19.237 28.598 25.179 26.477 17.797 16.520(3) NIQE 3.225 3.535 3.423 3.902 4.092 3.375 4.127 3.102(3) 3.254 3.354 2.457(1) 2.990(2) CEIQ 2.373 2.309 1.402 1.402 2.282 2.429 1.402 2.600 2.631(2) 2.505 2.762(1) 2.608(3) E 0.6828 5.9665 6.8917 0 6.3748 6.7219 0 0 6.9630(2) 6.5706 6.9234(3) 7.2362(1) Table 6 The average values of fourteen quantitative evaluation metrics on O-HAZE [40] dataset. Dataset Metrics M1 [19] M2 [48] M3 [49] M4 [50] M5 [47] M6 [46] M7 [26] M8 [33] M9 [34] M10 [24] M11 [45] M12 0-HAZE SSIM 0.0027 0.0008 0.0012 0.0013 0.0014 0.0017 0.0019 0.3456(2) 0.0017 0.0017 0.0028(3) 0.9643(1) PSNR 7.3819 7.3551 7.3622 7.3652 7.3617 7.3639 7.3852 7.3697 8.3101(3) 8.2685 8.3103(2) 52.407(1) MSE 11886.1 11919.4 10305.2 9687.7(2) 10306.9(3) 11935.1 11876.9 11959.2 11939.7 11931.3 11941.1 3734.9(1) RMSE 109.01 109.34 109.26 109.22 109.26 109.16 99.797(3) 98.42(2) 99.802 109.239 108.972 61.114(1) GMSD 0.00026(2) 0.00057 0.00057 0.00046 0.00047 0.00047 0.00033 0.30609 0.00029(3) 0.00042 0.00041 0.00004(1) BIAS 0.9955(3) 0.9989 0.9977 0.9972 0.9975 0.9967 0.9960 0.7084(2) 0.9955 0.9971 0.9955 0.6197(1) FSIM 0.3220 0.2981 0.3005 0.3143 0.3159 0.3144 0.3648 0.7632(2) 0.3666(3) 0.3151 0.3222 0.9694(1) FSIMc 0.3182(2) 0.2945 0.2971 0.3105 0.3143 0.3107 0.3690 0.7923(2) 0.3707(3) 0.3113 0.3186 0.9694(1) RFSIM 0.9707 0.9707(3) 0.9773(2) 0.9552 0.9449 0.9436 0.9613 0.00049 0.9774(1) 0.9519 0.9440 0.9638 ERGAS 108.023(3) 108.349 108.224 108.183 108.213 108.125 109.90 70.775(2) 109.86 108.172 108.003 52.446(1) BRISQUE 24.992 21.426 23.532 24.501 23.507 14.999(2) 21.847 17.243(3) 18.147 14.326(1) 19.675 23.719 NIQE 2.327(1) 2.439 2.549 2.684 3.529 2.442 2.537 2.683 2.651 2.561 3.345(2) 2.396(3) CEIQ 2.545 2.236 1.402 1.402 2.420 2.581 1.402 2.631(2) 2.388 2.530 2.643(1) 2.588(3) E 0.7666 6.7620 6.9888 0 6.6064 6.9411(3) 0.0009 0 6.6141 6.6884 7.3901(1) 6.9545(2) Table 7 The average values of four no-reference quantitative evaluation metrics on natural hazy images shown in Fig. 10. Metrics Image M1 [19] M2 [48] M3 [49] M4 [50] M5 [47] M6 [46] M7 [26] M8 [33] M9 [34] M10 [24] M11 [45] M12 BRISQUE img1 21.991 6.067(2) 17.447 15.825 24.229 13.952 10.479 11.931 5.002(1) 15.824 28.630 9.516(3) img2 15.612(2) 12.748(1) 35.236 45.729 29.801 28.337 44.412 21.716 42.723 24.326 35.763 21.639(3) img3 36.377 31.600 28.497 36.137 19.160(2) 35.174 44.429 35.151 9.751(1) 37.616 28.487(3) 41.708 img4 21.232(1) 36.399 33.358 44.654 39.845 32.835 42.821 29.289(2) 32.775 31.389 38.913 31.342(3) NIEQ img1 2.417(2) 2.601 2.754 2.645 3.970 2.665 3.102 2.562(3) 2.650 4.041 4.507 2.375(1) img2 3.133 2.507(1) 3.126 10.515 2.978(2) 3.204 12.346 3.095 4.293 3.564 4.212 3.090(3) img3 3.730(2) 3.477(1) 4.511 3.872 6.032 3.888 4.634 3.748(3) 5.056 4.835 5.962 3.953 img4 5.487(1) 7.031 12.463 7.064 8.684 6.509 6.134(2) 9.322 6.535 7.628 9.433 6.194(3) CEIQ img1 2.456 1.915 2.459 1.402 2.270 2.435 1.402 2.462 2.548(3) 2.470 2.614(1) 2.613(2) img2 2.678(2) 2.138 1.855 1.759 2.597 2.671 1.402 2.556 2.675(3) 2.583 2.683(1) 2.607 img3 2.553 1.983 1.820 1.402 2.528 2.612(2) 1.402 2.579 2.600(3) 2.405 2.627(1) 2.600(3) img4 2.395 2.541 2.498 1.402 2.607 2.626(2) 1.402 2.628(1) 2.624(3) 2.615 2.540 2.626(2) E img1 16.109 12.999 −4.754 −4.754 15.125 15.843 −4.754 16.539(2) 16.394(3) 16.100 17.586 17.203(1) img2 18.047(2) 12.639 −4.754 −2.080 17.357 17.978(3) −4.511 18.286(1) 17.253 17.142 17.933 17.978(3) img3 17.512 12.247 −4.754 −4.754 16.980 17.717(2) −4.754 17.086 16.952 16.479 17.604(3) 17.913(1) img4 15.244 15.528 14.640 −4.754 15.929 16.341(3) −4.754 16.306 16.929(2) 16.306 15.655 17.078(1) Journal of Visual Communication and Image Representation 74 (2021) 103008 14 G. Sahu et al. Fig. 11. Comparison of haze removal methods with respect to the execution time. assigned to the first three methods based on their performances. The first three ranks are depicted within a bracket. All the results of Table 3 suggest that 𝑀12 generates lower RMSE values in most of the cases as compared to 𝑀1–𝑀11. However, for some images, the performance of 𝑀6 is even better than the 𝑀12. However, the transmission map alone is not sufficient. The performance of all the methods would be judged based on the quality of a dehazed image. The third experiment is conducted to compare the performances of all the methods based on the generated dehazed images. Here, the performance of each method is evaluated on three datasets namely, BSDS500, I-HAZE and O-HAZE using ten full-reference quality metrics viz., Structural Similarity Index Measure (SSIM) [60,61], Peak Signal to Noise Ratio (PSNR) [62], Mean Square Error (MSE), RMSE [59], Gradi- ent Magnitude Similarity Deviation (GMSD) [63], BIAS, Feature SIMi- larity Index (FSIM) [64], an extended form of Feature SIMilarity Index (FSIMc) [64], Riesz-transform based Feature SIMilarity (RFSIM) [65], and relative dimensionless global error (ERGAS) [66] and four no- reference quality assessment metrics namely, Blind/Referenceless im- age spatial quality evaluator (BRISQUE) [67], natural image quality evaluator (NIQE) [68], contrast enhancement based contrast-changed image quality measure (CEIQ) [69] and entropy (E) [70–72]. The values of SSIM, GMSD, BIAS, FSIM, FSIMc, and RFSIM vary from 0 to 1. However, the preferred value for SSIM, FSIM, FSIMc, and RFSIM is 1, likewise the preferred value of GMSD, BIAS is 0. Similarly, the value of PSNR, MSE, RMSE, ERGAS, BRISQUE, NIQE, CEIQ, and E lies in between 0 and infinity. The expected value of MSE, RMSE, ERGAS, and NIQE is 0 whereas PSNR, BRISQUE, CEIQ, and E requires a higher value. A sample image is taken from each dataset, which is displayed in Figs. 7a, 8a, and 9a, respectively. Their ground truth images are shown in Figs. 7b, 8b, and 9b. The dehazed images of Figs. 7a, 8a generated by various methods are shown in Figs. 7c–k, 8c–k, and 9c–k respectively. After analyzing the visual quality of all the dehazed images shown in Figs. 7, 8, and 9, anyone can say that the 𝑀8 method generates much better dehazed images than others because all the images are brighter and clearer. At the same time, a drastic color-shift is also observed in the dehazed images produced by 𝑀8. On the other hand, a color-shift is less in the dehazed images produced by 𝑀12. Moreover, dehazed images achieved by the 𝑀12 are reasonably brighter and clearer. So, we can conclude that the 𝑀12 better restores the visual quality of a hazy image compared to 𝑀1–𝑀11. However, the images that we consider from three datasets, all are synthesized images. Therefore, methods 𝑀1 −𝑀12 are executed on natural hazy images. Four natural haze images are downloaded from Google. Fig. 10 shows four natural images and their dehazed images obtained by 𝑀1 −𝑀12. It may apparently seem that the result obtained by 𝑀3, 𝑀5 and 𝑀10 are visually better, however color-shift occurred in the images and the brightness of the images have been degraded. It is clear from Fig. 10 that the 𝑀12 better remove haze from images with a less color-shift. As we said earlier that the quality evaluation done by HVS is not alone sufficient, so quantitative analysis is equally important. All the methods, 𝑀1 −𝑀12, are executed on all the images taken from BSDS500, I-HAZE, and O-HAZE datasets individually and the average values of all the fourteen metrics are reported in Tables 4, 5, and 6 respectively. Similarly, quantitative results of natural hazy images are shown in Table 7, however, ground truth images are not available for natural hazy images, therefore, no-reference metrics are only consid- ered for evaluation. After analyzing all the results of Tables 4, 5, 6, and 7, a rank is assigned to each method, which is marked by superscript numbers. If the rank of a method is 1 it means this method is the best among all. So, Tables 4, 5, 6, and 7 illustrate that the proposed method, M12, comes first in most of the cases. In some cases, the M12 is stood as either 2nd or 3rd. However, the results of other methods are not consistent, therefore, all the results demonstrate that the proposed method is relatively better than 11 state-of-the-art methods. In this study, the computation time of each method is also measured because it is also an important factor to evaluate the performance of a method. The computation time of all methods is shown in Fig. 11. The 𝑥-axis of Fig. 11 represents the name of all the methods and the proposed method and the 𝑦-axis denotes execution time in seconds. Computation time is calculated as the average of the execution time of all images of respective dataset. It can be seen that the execution time of 𝑀12 is not pretty good, but it is acceptable. 5. Conclusion In this study, a single image dehazing algorithm in a relatively new color channel is proposed, which consists of four steps namely, calculation of atmospheric light, transmission map, radiance, and en- hancement of the dehazed image. The proposed method is capable to restore visibility of the scene. The proposed method is implemented Journal of Visual Communication and Image Representation 74 (2021) 103008 15 G. Sahu et al. on six datasets namely, I-HAZE, O-HAZE, BSDS500, RESIDE, FRIDA, and Google dataset. It is compared with 11 state-of-the-art methods using fourteen quantitative evaluation metrics. The proposed method performs well on images of BSDS500 and O-HAZE datasets. On the other hand, the performance of the proposed method is satisfactory on the images taken from I-HAZE and it may happen due to block-wise at- mospheric light estimation procedure. Since the block-wise atmospheric light estimation procedure selects a block from the sky region in most of the cases while computing 𝐴and there is no sky region in indoor images, therefore the value calculated as 𝐴is not precise. It may lead to performance degradation in the case of images of the I-HAZE dataset. Although the results are acceptable for indoor images, further research to generate realistic and visually pleasing images is worth conducting. Acknowledgments This work is partially supported by the project ‘‘Prediction of diseases through computer assisted diagnosis system using images captured by minimally-invasive and non-invasive modalities’’, Com- puter Science and Engineering, PDPM Indian Institute of Information Technology, Design and Manufacturing, Jabalpur India (under ID: SPARC-MHRD-231). This work is also partially supported by the project at (2020/2204), Grant Agency of Excellence, University of Hradec Kralove, Faculty of Informatics and Management, Czech Republic and by the project at Universiti Teknologi Malaysia (UTM) under Research University Grant Vot-20H04, Malaysia Research University Network (MRUN) Vot 4L876 and the Fundamental Research Grant Scheme (FRGS) Vot5F073 supported under Ministry of Education Malaysia for the completion of the research. Declaration of competing interest The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper. References [1] D. Shabna, C. Manikandababu, An efficient haze removal algorithm for surveillance video, Int. J. Innov. Res. Sci. Eng. Technol. 5 (5) (2016). [2] Gong Chen, Heqin Zhou, Jiefeng Yan, A novel method for moving object detection in foggy day, in: Eighth ACIS International Conference on Soft- ware Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing, SNPD 2007, Vol. 2, IEEE, 2007, pp. 53–58. [3] Yanting Pei, Yaping Huang, Qi Zou, Yuhang Lu, Song Wang, Does haze removal help cnn-based image classification? in: Proceedings of the European Conference on Computer Vision, ECCV, 2018, pp. 682–697. [4] Boyi Li, Xiulian Peng, Zhangyang Wang, Jizheng Xu, Dan Feng, End-to-end united video dehazing and detection, in: Thirty-Second AAAI Conference on Artificial Intelligence, 2018. [5] Qi Liu, Xinbo Gao, Lihuo He, Wen Lu, Haze removal for a single visible remote sensing image, Signal Process. 137 (2017) 33–43. [6] Harald Koschmieder, Theorie der horizontalen Sichtweite, Beitr. Phys. Freien Atmos. (1924) 33–53. [7] Yoav Y. Schechner, Srinivasa G. Narasimhan, Shree K. Nayar, Instant dehazing of images using polarization, in: Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001, volume 1, IEEE, 2001, I–I. [8] Sarit Shwartz, Einav Namer, Yoav Y. Schechner, Blind haze separation, in: 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR’06, volume 2, IEEE, 2006, pp. 1984–1991. [9] Pu Xia, Xuebin Liu, Image dehazing technique based on polarimetric spectral analysis, Optik 127 (18) (2016) 7350–7358. [10] Guangyi Ge, Zhenzhong Wei, Jingxin Zhao, Fast single-image dehazing using linear transformation, Optik 126 (21) (2015) 3245–3252. [11] Miao Qi, Qiaohong Hao, Qingji Guan, Jun Kong, You Zhang, Image dehazing based on structure preserving, Optik 126 (22) (2015) 3400–3406. [12] Garima Yadav, Saurabh Maheshwari, Anjali Agarwal, Foggy image enhancement using contrast limited adaptive histogram equalization of digitally filtered image: Performance improvement, in: 2014 International Conference on Ad- vances in Computing, Communications and Informatics, ICACCI, IEEE, 2014, pp. 2225–2231. [13] Muna F. Al-Sammaraie, Contrast enhancement of roads images with foggy scenes based on histogram equalization, in: 2015 10th International Conference on Computer Science & Education, ICCSE, IEEE, 2015, pp. 95–101. [14] Jiaxi He, Frank Z. Xing, Ran Yang, Cishen Zhang, Fast single image dehazing via multilevel wavelet transform based optimization, 2019, arXiv preprint arXiv: 1904.08573. [15] Asem Khmag, S.A.R. Al-Haddad, Bahareh Kalantar, et al., Single image dehazing using second-generation wavelet transforms and the mean vector L2-norm, Vis. Comput. 34 (5) (2018) 675–688. [16] Yang Wanting, Wang Ronggui, Fang Shuai, Zhang Xuan, Variable filter Retinex algorithm for foggy image enhancement, J. Comput.-Aided Des. Comput. Graph. 6 (010) (2010). [17] Wei-wei Hu, Rong-gui Wang, Shuai Fang, Qiong Hu, Retinex algorithm for image enhancement based on bilateral filtering, J. Eng. Graph. 2 (2010) 104–109. [18] T. Shu, Y.F. Liu, B. Deng, Y.P. Tan, B.Q. Chen, Multi-scale Retinex algorithm for the foggy image enhancement based on sub-band decomposition, J. Jishou Univ. 36 (1) (2015) 40–45. [19] Kaiming He, Jian Sun, Xiaoou Tang, Single image haze removal using dark channel prior, IEEE Trans. Pattern Anal. Mach. Intell. 33 (12) (2010) 2341–2353. [20] Kristofor B. Gibson, Dung T. Vo, Truong Q. Nguyen, An investigation of dehazing effects on image and video coding, IEEE Trans. Image Process. 21 (2) (2011) 662–673. [21] Shih-Chia Huang, Bo-Hao Chen, Wei-Jheng Wang, Visibility restoration of single hazy images captured in real-world weather conditions, IEEE Trans. Circuits Syst. Video Technol. 24 (10) (2014) 1814–1824. [22] Yunan Li, Qiguang Miao, Jianfeng Song, Yining Quan, Weisheng Li, Single image haze removal based on haze physical characteristics and adaptive sky region detection, Neurocomputing 182 (2016) 221–234. [23] Irfan Riaz, Teng Yu, Yawar Rehman, Hyunchul Shin, Single image dehazing via reliability guided fusion, J. Vis. Commun. Image Represent. 40 (2016) 85–97. [24] Sebastián Salazar-Colores, Juan-Manuel Ramos-Arreguín, Jesús-Carlos Pedraza- Ortega, J Rodríguez-Reséndiz, Efficient single image dehazing by modifying the dark channel prior, EURASIP J. Image Video Process. 2019 (1) (2019) 66. [25] Ketan Tang, Jianchao Yang, Jue Wang, Investigating haze-relevant features in a learning framework for image dehazing, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014, pp. 2995–3000. [26] Qingsong Zhu, Jiaming Mai, Ling Shao, A fast single image haze removal algorithm using color attenuation prior, IEEE Trans. Image Process. 24 (11) (2015) 3522–3533. [27] Bian Gui, Yuhua Zhu, Tong Zhen, Adaptive single image dehazing method based on support vector machine, J. Vis. Commun. Image Represent. (2020) 102792. [28] Bolun Cai, Xiangmin Xu, Kui Jia, Chunmei Qing, Dacheng Tao, Dehazenet: An end-to-end system for single image haze removal, IEEE Trans. Image Process. 25 (11) (2016) 5187–5198. [29] Wenqi Ren, Si Liu, Hua Zhang, Jinshan Pan, Xiaochun Cao, Ming-Hsuan Yang, Single image dehazing via multi-scale convolutional neural networks, in: European Conference on Computer Vision, Springer, 2016, pp. 154–169. [30] Boyi Li, Xiulian Peng, Zhangyang Wang, Jizheng Xu, Dan Feng, Aod-net: All-in- one dehazing network, in: Proceedings of the IEEE International Conference on Computer Vision, 2017, pp. 4770–4778. [31] Fan Guo, Xin Zhao, Jin Tang, Hui Peng, Lijue Liu, Beiji Zou, Single image dehazing based on fusion strategy, Neurocomputing 378 (2020) 9–23. [32] Yin Gao, Yijing Su, Qiming Li, Jun Li, Single fog image restoration with multi-focus image fusion, J. Vis. Commun. Image Represent. 55 (2018) 586–595. [33] Yingying Zhu, Gaoyang Tang, Xiaoyan Zhang, Jianmin Jiang, Qi Tian, Haze removal method for natural restoration of images with sky, Neurocomputing 275 (2018) 499–510. [34] Adrian Galdran, Image dehazing by artificial multiple-exposure image fusion, Signal Process. 149 (2018) 135–147. [35] Faming Fang, Fang Li, Tieyong Zeng, Single image dehazing and denoising: A fast variational approach, SIAM J. Imaging Sci. 7 (2) (2014) 969–996. [36] Zhi Wang, Guojia Hou, Zhenkuan Pan, Guodong Wang, Single image dehazing and denoising combining dark channel prior and variational models, IET Comput. Vis. 12 (4) (2017) 393–402. [37] Guojia Hou, Jingming Li, Guodong Wang, Huan Yang, Baoxiang Huang, Zhenkuan Pan, A novel dark channel prior guided variational framework for underwater image restoration, J. Vis. Commun. Image Represent. 66 (2020) 102732. [38] Guojia Hou, Jingming Li, Guodong Wang, Zhenkuan Pan, Xin Zhao, Underwater image dehazing and denoising via curvature variation regularization, Multimedia Tools Appl., 1–21. [39] Giuseppe Ciaburro, Neural Networks with R: smart Models using CNN, RNN, Deep Learning, and Artificial Intelligence Principles, Packt Publishing, Birmingham, UK, 2017. [40] Codruta O. Ancuti, Cosmin Ancuti, Radu Timofte, Christophe De Vleeschouwer, O-HAZE: A dehazing benchmark with real hazy and haze-free outdoor images, in: IEEE Conference on Computer Vision and Pattern Recognition, NTIRE Workshop, NTIRE CVPR’18, 2018. [41] Codruta O. Ancuti, Cosmin Ancuti, Radu Timofte, Christophe De Vleeschouwer, I-HAZE: A dehazing benchmark with real hazy and haze-free indoor images, 2018, arXiv:1804.05091v1. Journal of Visual Communication and Image Representation 74 (2021) 103008 16 G. Sahu et al. [42] Berkeley Segmentation Data Set, Benchmarks 500 (BSDS500), 2011, URL http: //www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html. [43] Boyi Li, Wenqi Ren, Dengpan Fu, Dacheng Tao, Dan Feng, Wenjun Zeng, Zhangyang Wang, Benchmarking single-image dehazing and beyond, IEEE Trans. Image Process. 28 (1) (2019) 492–505. [44] Jean-Philippe Tarel, Nicolas Hautiere, Aurélien Cord, Dominique Gruyer, Hous- sam Halmaoui, Improved visibility of road scene images under heterogeneous fog, in: 2010 IEEE Intelligent Vehicles Symposium, IEEE, 2010, pp. 478–485. [45] Dong Zhao, Long Xu, Yihua Yan, Jie Chen, Ling-Yu Duan, Multi-scale optimal fusion model for single image dehazing, Signal Process., Image Commun. 74 (2019) 253–265. [46] Zhiming Tan, Xianghui Bai, Bingrong Wang, Akihiro Higashi, Fast single-image defogging, Fujitsu Sci. Tech. J. 50 (1) (2014) 60–65. [47] Yi-Jui Cheng, Bo-Hao Chen, Shih-Chia Huang, Sy-Yen Kuo, Andrey Kopylov, Oleg Seredint, Leonid Mestetskiy, Boris Vishnyakov, Yury Vizilter, Oleg Vygolov, et al., Visibility enhancement of single hazy images using hybrid dark channel prior, in: 2013 IEEE International Conference on Systems, Man, and Cybernetics, IEEE, 2013, pp. 3627–3632. [48] Chunxia Xiao, Jiajia Gan, Fast image dehazing using guided joint bilateral filter, Vis. Comput. 28 (6–8) (2012) 713–721. [49] Jiao Long, Zhenwei Shi, Wei Tang, Fast haze removal for a single remote sensing image using dark channel prior, in: 2012 International Conference on Computer Vision in Remote Sensing, IEEE, 2012, pp. 132–135. [50] Zheqi Lin, Xuansheng Wang, Dehazing for image and video using guided filter, Appl. Sci. 2 (2012) 123–127. [51] Codruta Orniana Ancuti, Cosmin Ancuti, Single image dehazing by multi-scale fusion, IEEE Trans. Image Process. 22 (8) (2013) 3271–3282. [52] Geet Sahu, Ayan Seal, Image dehazing based on luminance stretching, in: 2019 International Conference on Information Technology, ICIT, IEEE, 2019, pp. 388–393. [53] Chia-Hung Yeh, Li-Wei Kang, Ming-Sui Lee, Cheng-Yang Lin, Haze effect removal from image via haze density estimation in optical model, Opt. Express 21 (22) (2013) 27127–27141. [54] Luyan Tong, Fenglin Wei, Yupeng Pan, Kai Wang, Study on the extraction of target contours of underwater images, in: International Conference on Artificial Intelligence and Security, Springer, 2020, pp. 339–349. [55] M. Sudhakar, M.J.anaki Meena, An efficient interactive segmentation algorithm using color correction for underwater images, Wirel. Netw. (2019) 1–12. [56] Jun Yang, Qilong Min, Weitao Lu, Ying Ma, Wen Yao, Tianshu Lu, An RGB channel operation for removal of the difference of atmospheric scattering and its application on total sky cloud detection, Atmos. Meas. Tech. 10 (3) (2017) 1191–1201. [57] Sungmin Lee, Seokmin Yun, Ju-Hun Nam, Chee Sun Won, Seung-Won Jung, A review on dark channel prior based image dehazing algorithms, EURASIP J. Image Video Process. 2016 (1) (2016) 4. [58] Jiahao Pang, Oscar C. Au, Zheng Guo, Improved single image dehazing using guided filter, in: Proc. APSIPA ASC, 2011, pp. 1–4. [59] Liviu Florin Zoran, Quality evaluation of multiresolution remote sensing images fusion, UPB Sci. Bull. C 71 (2009) 38–52. [60] Animesh Sengupta, Ayan Seal, Chinmaya Panigrahy, Ondrej Krejcar, Anis Yazidi, Edge information based image fusion metrics using fractional order differentiation and sigmoidal functions, IEEE Access 8 (2020) 88385–88398. [61] Chinmaya Panigrahy, Ayan Seal, Nihar Kumar Mahato, Ondrej Krejcar, Enrique Herrera-Viedma, Multi-focus image fusion using fractal dimension, Appl. Opt. 59 (19) (2020) 5642–5655. [62] Ayan Seal, Debotosh Bhattacharjee, Mita Nasipuri, Dionisio Rodríguez- Esparragón, Ernestina Menasalvas, Consuelo Gonzalo-Martin, PET-CT Image fusion using random forest and à-trous wavelet transform, Int. J. Numer. Methods Biomed. Eng. 34 (3) (2018) e2933. [63] Wufeng Xue, Lei Zhang, Xuanqin Mou, Alan C. Bovik, Gradient magnitude similarity deviation: A highly efficient perceptual image quality index, IEEE Trans. Image Process. 23 (2) (2013) 684–695. [64] Lin Zhang, Lei Zhang, Xuanqin Mou, David Zhang, FSIM: A feature similarity index for image quality assessment, IEEE Trans. Image Process. 20 (8) (2011) 2378–2386. [65] Lin Zhang, Lei Zhang, Xuanqin Mou, RFSIM: A feature based image quality assessment metric using Riesz transforms, in: 2010 IEEE International Conference on Image Processing, IEEE, 2010, pp. 321–324. [66] Qian Du, Nicholas H. Younan, Roger King, Vijay P. Shah, On the performance evaluation of pan-sharpening techniques, IEEE Geosci. Remote Sens. Lett. 4 (4) (2007) 518–522. [67] Anish Mittal, Anush Krishna Moorthy, Alan Conrad Bovik, No-reference image quality assessment in the spatial domain, IEEE Trans. Image Process. 21 (12) (2012) 4695–4708. [68] Anish Mittal, Rajiv Soundararajan, Alan C. Bovik, Making a ‘‘completely blind’’ image quality analyzer, IEEE Signal Process. Lett. 20 (3) (2012) 209–212. [69] Jia Yan, Jie Li, Xin Fu, No-reference quality assessment of contrast-distorted images using contrast enhancement, 2019, arXiv preprint arXiv:1904.08879. [70] Chinmaya Panigrahy, Ayan Seal, Nihar Kumar Mahato, MRI and SPECT image fusion using a weighted parameter adaptive dual channel PCNN, IEEE Signal Process. Lett. 27 (2020) 690–694. [71] Chinmaya Panigrahy, Ayan Seal, Nihar Kumar Mahato, Fractal dimension based parameter adaptive dual channel PCNN for multi-focus image fusion, Opt. Lasers Eng. 133 (2020) 106141. [72] Ayan Seal, Debotosh Bhattacharjee, Mita Nasipuri, Human face recognition using random forest based fusion of à-trous wavelet transform coefficients from thermal and visible images, AEU-Int. J. Electron. Commun. 70 (8) (2016) 1041–1049."
Estimating Tukey depth using incremental quantile estimators,Hugo L. Hammer and Anis Yazidi and Håvard Rue,2022,,122,Pattern Recognition,article,"Pattern Recognition 122 (2022) 108339 
Contents lists available at ScienceDirect 
Pattern Recognition 
journal homepage: www.elsevier.com/locate/patcog 
Estimating Tukey depth using incremental quantile estimators 
Hugo L. Hammer a , ∗, Anis Yazidi b , Håvard Rue c 
a OsloMet - Oslo Metropolitan University, Norway Simula Metropolitan Centre for Digital Engineering, Norway 
b OsloMet - Oslo Metropolitan University, Norway 
c King Abdullah University of Science and Technology, Saudi Arabia 
a r t i c l e 
i n f o 
Article history: 
Received 26 August 2020 
Revised 13 September 2021 
Accepted 18 September 2021 
Available online 20 September 2021 
Keywords: 
Data stream 
Incremental quantile estimator 
Distributional patterns 
Real-time analytics 
Tukey depth 
a b s t r a c t 
Measures of distance or how data points are positioned relative to each other are fundamental in pattern 
recognition. The concept of depth measures how deep an arbitrary point is positioned in a dataset, and 
is an interesting concept in this regard. However, while this concept has received a lot of attention in the 
statistical literature, its application within pattern recognition is still limited. 
To increase the applicability of the depth concept in pattern recognition, we address the well-known 
computational challenges associated with the depth concept, by suggesting to estimate depth using in- 
cremental quantile estimators . The suggested algorithm can not only estimate depth when the dataset is 
known in advance, but can also track depth for dynamically varying data streams by using recursive up- 
dates . The tracking ability of the algorithm was demonstrated based on a real-life application associated 
with detecting changes in human activity from real-time accelerometer observations. Given the ﬂexibility 
of the suggested approach, it can detect virtually any kind of changes in the distributional patterns of the 
observations, and thus outperforms detection approaches based on the Mahalanobis distance. 
© 2021 The Authors. Published by Elsevier Ltd. 
This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) 
1. Introduction 
Measures of distance or how data points are positioned relative 
to each other, are fundamental in pattern recognition. For example 
in anomaly detection [9] e.g using auto encoders [4,35] , clustering 
[13,25] or classiﬁcation [17,29] . 
To measure distance or how data points are positioned rela- 
tive to each other, data depth is an interesting concept. Data depth 
measures how deep an arbitrary point is position in a dataset. 
While the concept has received a lot of attention in the statisti- 
cal literature [27] , the application within pattern recognition is still 
limited. There are however some notable exceptions. For exam- 
ple [14,18,19] applied the concept for classiﬁcation and clustering. 
Depth has also been applied to a wide range of disciplines such 
as economy [14,19,21] , health and biology [15,33] , ecology [3] and 
hydrology [5] to name a few. 
The earliest and most popular depth measure is Tukey depth 
[32] . The Tukey depth of a point is deﬁned as the minimum prob- 
ability mass carried by any closed halfspace containing the point. 
However, the computation of Tukey depth for higher dimensions or 
∗Corresponding author. 
E-mail address: hugo.hammer@oslomet.no (H.L. Hammer). 
for even moderate amounts of data is computationally demanding 
which limits its applicability [23] . 
The main aim of this paper is to address these aforemen- 
tioned computational issues, and thus increase the applicabil- 
ity of the depth concept within pattern recognition . Our ap- 
proach takes advantage of the following result from Kong and Miz- 
era [20] according to which the authors deﬁned halfspaces such 
that a speciﬁc portion of the data points are on one side of the 
halfspace. They further showed that contours with a speciﬁc Tukey 
depth can be estimated from the intersection of such halfspaces 
over different directions. Such contours can again be used to esti- 
mate the depth of any point. In order to apply this result to esti- 
mate depth in dimension p, the positions of O (c p−1 ) , c > 1 halfs- 
paces must be estimated requiring estimators that are both mem- 
ory and computationally eﬃcient. In this paper, we therefore sug- 
gest to use incremental quantile estimators to estimate the positions 
of the halfspaces [10,11] . These estimators only need to store a sin- 
gle value in memory, i.e. O (1) , and only need to perform a single 
operation per observation resulting in a computational complexity 
of O (n ) for n observations. As opposed to this, traditional quantile 
estimators have a memory requirement of O (n ) and a O (n log n ) 
computational complexity. However, the computational eﬃciency 
comes with a price and traditional estimators provide more pre- 
cise estimates based on the same observations. 
https://doi.org/10.1016/j.patcog.2021.108339 
0031-3203/© 2021 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) 
 H.L. Hammer, A. Yazidi and H. Rue 
Pattern Recognition 122 (2022) 108339 
Fig. 1. Examples of three halfspaces (blue, green, red) containing the point x . The blue contours represent some probability distribution P. (For interpretation of the references 
to colour in this ﬁgure legend, the reader is referred to the web version of this article.) 
The second aim is to recursively update and even track 
Tukey depth contours of streams of multivariate data in real 
time . A remarkable advantage with incremental quantile estima- 
tors is that they not only can estimate quantiles when the data 
is known in advance, but can recursively update and even track 
quantiles of data streams. Thus, by using incremental quantile 
estimators to estimate halfspaces, Tukey depth contours can be 
tracked in real time. We are not aware of any other method that 
can eﬃciently compute Tukey depth in real-time. 
Finally, the real-world applicability of computing Tukey 
depth in real-time settings is demonstrated where the developed 
methods are used to detect changes in human activity in real-time 
from accelerometer observations. Due the ﬂexibility of the sug- 
gested approach, it can detect virtually any kind of changes in the 
distributional patterns of the accelerometer observation, and out- 
performs popular approaches based on Mahalanobis distance. 
The main contributions of the paper are as follows: 
• We present a new, simple and computationally eﬃcient method 
to compute Tukey depth. 
• The method can even be used to compute Tukey depth in real- 
time, and is to the best of our knowledge the ﬁrst method with 
this ability. 
• The method is applied to detect changes in human activity in 
real-time which demonstrates its usefulness and applicability in 
real-world scenarios. 
The paper is organized as follows. In Section 2 , the concept 
of depth is introduced including some theoretical fundamentals to 
compute Tukey depth. Section 3 provides an eﬃcient procedure to 
estimate Tukey depth. Section 4 presents performance metrics that 
will be used to evaluate the algorithm and Sections 5 and 6 pro- 
vide synthetic and real-life data experiments. 
2. The concept of depth 
Let X = (X 1 , . . . , X p ) T represent a p-dimensional stochastic vec- 
tor with probability distribution P . Let D (x, P ) denote the depth 
function of a point x with respect to the probability distribution P . 
A high (low) value of the depth function refers to a central (outly- 
ing) point of the probability distribution. A general depth function 
is deﬁned by satisfying the natural requirements of aﬃne invari- 
ance, maximality at center, monotonicity relative to deepest point 
and vanishing at inﬁnity [36] . 
The most used depth function is Tukey depth. 
Deﬁnition 1 (Tukey depth) . Let U refer to the set of all vectors 
with unit length. Tukey depth is the minimum probability mass 
carried by any closed halfspace containing the point 
D (x, P ) = inf 
u ∈U P 
u T X ≤u T x 
(1) 
Fig. 1 shows three halfspaces containing the point x . The prob- 
ability mass carried by the red and blue halfspaces are larger than 
for the green halfspace. Thus the probability mass carried by the 
green halfspace is closer to the Tukey depth, which is the mini- 
mum probability mass over all half spaces containing x . Intuitively, 
this is a reasonable and general measure for the centrality of x 
with respect to P . 
Deﬁne α-depth region, directional quantile and directional 
quantile halfspace. 
Deﬁnition 2 (. α-depth region) The α-depth region with respect 
to Tukey depth, D (α) , is deﬁned as the set of points whose depth 
is at least α
D (α) = { x ∈ R p : D (x, P ) ≥α} 
(2) 
The boundary of D (α) is known as the α-depth contour. 
The α-depth regions are closed, convex, and nested for increas- 
ing α. 
Deﬁnition 3 (Directional quantile) . For any unit directional vector 
u ∈ U, deﬁne the directional quantile as 
Q(α, u T X ) = F −1 
u T X (α) 
(3) 
where F −1 
u T X (x ) refers to the inverse of the univariate cumulative 
distribution function of the projection of X on u . 
Deﬁnition 4 (Directional quantile halfspace) . The directional quan- 
tile halfspace is deﬁned as 
H(α, u ) = 
x ∈ R p : u T x ≥Q(α, u T X ) 
(4) 
which is bounded away from the origin at distance Q(α, u T X) by 
the hyperplane with normal vector u . 
Consequently P (X ∈ H(α, u )) = 1 −α for any u ∈ U. 
The estimation procedures in this paper builds on the following 
theorem from [20] . 
Theorem 1. The α-depth region in (2) equals the directional quantile 
envelope 
D (α) = 
 
u ∈U 
H(α, u ) 
(5) 
Tukey depth may not be deﬁned for depths above some thresh- 
old and the intersection becomes empty. 
3. Eﬃcient estimation of tukey depth 
Given a multivariate dataset, in this section we suggest a simple 
procedure to estimate whether an arbitrary point is within or out- 
side an α-depth region. The procedure uses Theorem 1 , and con- 
sists of three parts. 
1. Unit length directional vectors. The generation of uniformly 
distributed directional vectors is simple: Let Z 1 , . . . , Z p be inde- 
pendent standard normally distributed stochastic variables and 
deﬁne Z = (Z 1 , . . . , Z p ) T . Then U = Z/ ∥ Z∥ 2 will be uniformly dis- 
tributed on the unit sphere, where ∥ · ∥ 2 refers to the Euclidean 
2 
 H.L. Hammer, A. Yazidi and H. Rue 
Pattern Recognition 122 (2022) 108339 
norm. This is the procedure used in most of the experiments in 
this paper. However, intuitively, using directional vectors that are 
more equidistantly spread on the unit sphere would be more ef- 
ﬁcient. We thus also considered the following approach accord- 
ing to which we generate many uniformly distributed directional 
vectors, N u , and secondly ﬁlter out directional vectors that are 
closer than some threshold. The approach is however computa- 
tionally demanding, O (N 2 
u p 2 ) . There are other algorithms to gen- 
erate fairly equidistantly spread direction vectors, see e.g spiral al- 
gorithms [30] . We have not evaluated the potential of these algo- 
rithms. 
2. Directional quantiles estimates. The next part is to estimate 
directional quantiles for each directional vector generated above. 
As pointed out in the introduction, we use incremental quantile 
estimators. A prominent example is the DUMIQE algorithm which 
recursively updates directional quantile estimates as follows for ev- 
ery observation u T 
i x j−1 [34] 
 
Q (α, u T 
i X j ) 
← (1 + λα)  
Q (α, u T 
i X j−1 ) , 
if u T 
i x j >  
Q (α, u T 
i X j−1 ) 
 
Q (α, u T 
i X j ) 
← (1 −λ(1 −α))  
Q (α, u T 
i X j−1 ) , 
if u T 
i x j <  
Q (α, u T 
i X j−1 ) 
(6) 
The update is quite intuitive. If the sample u T 
i x j is above (re- 
spectively below) the current estimate, increase (respectively re- 
duce) the corresponding directional quantile estimate. The tuning 
parameter λ > 0 controls the update size. If the data is known be- 
forehand or it comes in the form of a stationary data stream, it 
makes sense to let the value of λ be reduced with time. For non- 
stationary data streams a constant value of λ is more suitable to 
gradually forget old and outdated data [34] . The procedure is de- 
tailed in Algorithm 1 . 
Algorithm 1 Estimating directional quantiles. 
Input: 
u 1 , . . . , u n u // Unit length directional vectors 
x 1 , x 2 , . . . , x n // Dataset 
α, λ
 
Q (α, u T 
i X 0 ) // Initial value 
Method: 
1: for j ∈ 1 , 2 , . . . , n do 
2: 
for i ∈ 1 , 2 , . . . , n u do 
3: 
if u T 
i x j >  
Q (α, u T 
i X j−1 ) then 
4: 
 
Q (α, u T 
i X j ) ← (1 + λα)  
Q (α, u T 
i X j−1 ) 
5: 
else 
6: 
 
Q (α, u T 
i X j ) ← (1 −λ(1 −α))  
Q (α, u T 
i X j−1 ) 
7: 
end if 
8: 
end for 
9: end for 
3. Compute if a point w is within the α-depth region. The di- 
rectional quantile estimates from Algorithm 1 can be used to com- 
pute if w is within all the directional quantile halfspaces and thus, 
according to Theorem 1 , being within the α-depth region. The pro- 
cedure is detailed in Algorithm 2 . The condition in line 2 is based 
on Equation (4) and checks if w is outside of the estimated direc- 
tional quantile halfspace. 
Convergence. The procedure consists of two approximations 1) 
the ﬁnite number of directional vectors and 2) the estimates of 
the true directional quantiles. To ensure convergence, the direc- 
tional vector selection procedure must cover the unit sphere when 
the number of directional vectors goes to inﬁnity and, secondly, 
the directional quantile estimates must converge to the true direc- 
tional quantiles, when the number of observations goes to inﬁn- 
ity. By using the simple procedure above to select uniformly dis- 
tributed directional vectors, the ﬁrst requirement is satisﬁed. Fur- 
ther, [34] and [11] prove the second requirement. 
Algorithm 2 Compute if a point w is within the α-depth region. 
Input: 
 
Q (α, u T 
i X n ) , i = 1 , . . . , n u // Dir. quantile estimates from Algorithm 
1. 
w , i = 1 
InAlphaDepthRegion = True // True (False) if w is within (outside) 
the α-depth region 
Method: 
1: while InAlphaDepthRegion and i ≤n u do 
2: 
if u T 
i w <  
Q (α, u T 
i X n ) then 
3: 
InAlphaDepthRegion = False 
4: 
end if 
5: 
i ← i + 1 
6: end while 
7: Print(”Point w in α-depth region?”, InAlphaDepthRegion) 
Fig. 2. Figure illustrating the approach to measure α-depth contour estimation er- 
ror. The black and blue curves show the true α-depth regions and the envelope 
estimate. The lines with directions v i , i = 1 , . . . , n v are shown in red. (For interpre- 
tation of the references to colour in this ﬁgure legend, the reader is referred to the 
web version of this article.) 
4. Performance metrics 
We suggest to measure error along lines l i , i = 1 , . . . , n v going 
through the center of the true distribution and outward in uni- 
formly distributed directions v i , i = 1 , . . . , n v ( Fig. 2 ). This approach 
scales well with dimension p. 
We suggest two error measures: 
Depth error: Let  
w i,k denote the point of intercept between the 
line, l i , and the envelope and compute the true depth at this point, 
D (  
w i,k , P ) . The error is computed using mean absolute depth error 
(MADE) over all the lines l i , i = 1 , . . . , n v 
MADE k = 1 
n v 
n v 
	 
i =1 
| αk −D (  
w i,k , P ) | 
and again average over envelopes 
MADE = 1 
K 
K 
	 
k =1 
MADE k 
(7) 
To compute MADE for higher dimensions, the true depth must be 
computed for a large set of points  
w i,k . For non-elliptic distribu- 
tions this is computationally demanding and was limited to p ≤6 
in the experiments. For elliptic distributions, and in particular mul- 
tivariate normal distributions, the true depth of any point can be 
computed analytically and thus MADE was computed up to dimen- 
sion p = 10 in the experiments. Details are given in supplementary 
material S.1. Obviously, if we knew that the observations were mul- 
3 
 H.L. Hammer, A. Yazidi and H. Rue 
Pattern Recognition 122 (2022) 108339 
tivariate normally distributed, other depth measures such as Ma- 
halanobis depth would be more natural, but the computations are 
only used to evaluate the performance of the algorithm for high 
dimensions. 
Euclidean distance: Along each line, l i , compute the point of 
intercept between the line and the true α-depth contour of depth 
αk , denoted w i,k . Compute the error as the average Euclidean dis- 
tance (ED) 
ED k = 1 
n v 
n v 
	 
i =1 
∥ w i,k − 
w i,k ∥ 2 
where  
w i,k still refers to the intercept between line l i and the en- 
velope. Further take the average over envelopes 
ED = 1 
K 
K 
	 
k =1 
ED k 
(8) 
5. Synthetic experiments 
In this section, the performance of the algorithms in 
Section 3 are evaluated in several synthetic experiments. The 
experiments focus on streaming data, except in Section 5.2 . In 
Section 6 , the algorithms are demonstrated in a real-life data ex- 
ample. 
All computations were run on a Dell PowerEdge R815 server 
with 64 1.8 GHz AMD CPU processors and Linux Ubuntu operat- 
ing system version 16.04. The experiments were implemented in R 
[28] , but with the most computer intensive parts in C++ integrated 
using Rcpp [7,8] . 
5.1. Synthetic experiments - Static data stream 
Figs. 3 show results of estimating the α = 0 . 1 depth contour for 
a multivariate normally distributed data stream with parameters 
μ = 

0 
0 

,  = 

1 
0 . 82 
0 . 82 
1 

(9) 
Directional quantiles were estimated using DUMIQE with decreas- 
ing values of the tuning parameter, λn = 1 /n . 
We see that a fairly good estimate is achieved with 200 obser- 
vations and that the error is minimal with 20 0 0 observations. A 
similar visualization for the highly non-elliptical and heavy tailed 
lognormal distribution is shown in Figure 7 in supplementary ma- 
terial S.2. Due to the ﬂexibility of the depth concept, the method 
performs equally well for such a distribution. Further, in supple- 
mentary material S.2, a few examples of joint estimation of multi- 
ple α-depth regions using the ShiftQ algorithm are shown. The re- 
sults show that multiple depth regions can eﬃciently be estimated 
for both Gaussian and non-Gaussian distributions. 
Considered now joint estimation of α-depth regions for α = 
0 . 05 , 0 . 2 and 0.4 and for p > 2 . Table 1 shows results for stan- 
dard multivariate normally distributed observation. More detailed 
results are given in Figures 12 and 13 in supplementary material 
S.2. CPU time refers to the computational time needed per α-depth 
region to obtain estimates with a given precision using a single 
CPU core. 
The number of directional vectors (and thus CPU time) in- 
creases with p and estimation precision. The algorithm performs 
very well. For example, for dimension p = 10 , MADE less than 0.02 
is obtained in about 1.5 seconds. MADE < 0 . 01 could be reached 
in shorter CPU time than what is shown in Table 1 using a higher 
number of directional vectors, but this is not explored. 
Now, assume that X = (X 1 , . . . , X p ) T is a multivariate normally 
distributed variable with zero expectation vector and strong de- 
pendencies 
Cov (X i , X j ) = exp (−0 . 2 | i −j| ) , i, j = 1 , . . . , p 
(10) 
Table 1 
Multivariate standard normal distribution case: The second and third columns 
show the CPU time (in seconds) and the number of directional vectors used 
to obtain MADE less than 0.05. The other columns show the same to obtain 
MADE less than 0.02 and 0.01, respectively. 
MADE < 0 . 05 
MADE < 0 . 02 
MADE < 0 . 01 
CPU time 
n u 
CPU time 
n u 
CPU time 
n u 
p = 2 
0.00013 
8 
0.00174 
12 
0.00942 
18 
p = 3 
0.00023 
12 
0.00429 
27 
0.04488 
40 
p = 4 
0.00023 
16 
0.00958 
81 
0.11631 
122 
p = 5 
0.00043 
20 
0.02991 
153 
0.35146 
345 
p = 6 
0.00054 
24 
0.07419 
274 
0.90636 
1386 
p = 8 
0.00334 
72 
0.34695 
1228 
9.83845 
9324 
p = 10 
0.01361 
90 
1.54246 
3450 
104.45206 
88412 
The results are shown in Table 2 . More detailed results are given 
in Figures 14 and 15 in supplementary material S.2. By comparing 
Tables 1 and 2 , we see that the number of directional vectors and 
CPU time needed increase when the variables of X are dependent. 
Let X still represent the multivariate normally distributed vari- 
able with covariances (10) . Table 3 shows results for the multivari- 
ate lognormal distribution Y = exp (X) . More detailed results are 
given in Figures 16 and 17 in supplementary material S.2. 
Tables 2 and 3 show that a speciﬁc level of MADE is reached 
faster for the lognormal distribution than for the multivariate dis- 
tribution documenting that the procedure eﬃciently can character- 
ize non-Gaussian distributions. 
To the best of our knowledge, the algorithm by [23] is the most 
eﬃcient algorithm in the literature to estimate Tukey α-depth re- 
gions. The authors focus on estimating exact trimmed α-depth re- 
gions resulting in complex combinatorial algorithms and the com- 
putation burden explodes with the number of samples. In compar- 
ison, the computational complexity of our algorithm increases lin- 
early with the number of samples. The authors can document esti- 
mation results up to dimension p = 9 , but only when the number 
of samples are restricted to less than 80. The algorithm by [23] is 
not constructed to handle streaming data. 
5.2. Synthetic experiments - Oﬄine setting 
In this section, we compare the performance of the incremen- 
tal quantile estimator, DUMIQE, with state-of-the-art oﬄine quan- 
tile estimators to estimate α-depth regions when data is known in 
advance. State-of-the-art oﬄine quantile estimators are based on 
using weighted averages of consecutive order statistics 
Q(α) = (1 −δ) y [ j] + δy [ j + 1] 
where j−m 
N ≤α < j−m +1 
N , y [ j] is the jth order statistic of the 
sample, m a constant and N the sample size. We use m = α+1 
3 
and δ = Nα + m −j and deﬁne α[ k ] = k −1 / 3 
N+1 / 3 . The sample quan- 
tiles can be read from a linear interpolation between the points 
(α[ k ] , y [ k ]) , k = 1 , . . . , N. The resulting quantile estimates are ap- 
proximately median-unbiased regardless of the distribution of the 
data. This is the method referred to as Type 8 in the quantile 
function in R and is the one recommended by [16] . 
We consider the multivariate normal distribution case with co- 
variance matrix as given in (10) , sample sizes N = 50 0 , 20 0 0, 10 4 
and 5 · 10 4 and dimensions p = 2 and p = 3 . For p = 2 and p = 3 , 
we used 1500 and 7500 directional vectors, respectively, which 
were suﬃciently many to obtain satisfactory performance. 
The results are shown in Table 4 . We see that the estimation er- 
rors using DUMIQE are about 1.5 time that of the oﬄine estimator. 
If fewer directional vectors were used, the differences in estimation 
error were substantially reduced. Further, the computational time 
of the oﬄine estimator is about ten times larger than the DUMIQE 
4 
 H.L. Hammer, A. Yazidi and H. Rue 
Pattern Recognition 122 (2022) 108339 
Fig. 3. Multivariate normal distribution case. Estimation of α-depth region for α = 0 . 1 using n u = 50 directional vectors. The rows from top to bottom show the estimates 
for 20, 200 and 2000 observations. The left and right column show all the half planes and the resulting envelopes in blue, respectively. The black curves show the true 
α-depth contour. (For interpretation of the references to colour in this ﬁgure legend, the reader is referred to the web version of this article.) 
estimator. In other words, if computational time or memory us- 
age are not an issue, the oﬄine estimator combined with a large 
amount of directional vectors will give the most precise estimates 
from the samples. Otherwise, incremental quantile estimators are 
preferable even for oﬄine settings. 
5.3. Synthetic experiments - Dynamically changing data streams 
In this section, we consider the problem of tracking α-depth 
regions of dynamically varying data streams. Fig. 4 illustrates the 
problem. In each panel, the expectation vector of the data stream 
distribution moved from the bottom left to the upper right. At 
the same time the correlation, changed from strongly positive, 0.8, 
to strongly negative, −0 . 8 . For the 10 3 samples case (ﬁrst row), 
the algorithm was able to track the α-depth regions satisfactory. 
With 10 4 samples, the estimates improve signiﬁcantly and with 
10 5 observations, the estimates are very close to the true contours. 
With 10 4 and 10 5 samples, 50 directional vectors give better and 
smoother estimates than 10 directional vectors. 
5 
 H.L. Hammer, A. Yazidi and H. Rue 
Pattern Recognition 122 (2022) 108339 
Table 2 
Multivariate normal distribution case: The second and third columns show the CPU 
time (in seconds) and the number of directional vectors used to obtain a mean abso- 
lute depth error (MADE) less than 0.05, respectively. 
MADE < 0 . 05 
MADE < 0 . 02 
MADE < 0 . 01 
CPU time 
n u 
CPU time 
n u 
CPU time 
n u 
p = 2 
0.00034 
18 
0.00622 
40 
0.03734 
40 
p = 3 
0.00095 
27 
0.03003 
135 
1.38903 
135 
p = 4 
0.00238 
54 
0.13145 
274 
7.47343 
616 
p = 5 
0.01275 
102 
0.43698 
777 
8.47334 
3936 
p = 6 
0.03603 
183 
1.81652 
3118 
45.88106 
15,786 
p = 8 
0.17285 
819 
23.21460 
20,979 
988.12085 
358,438 
p = 10 
0.68053 
2300 
245.91893 
198,927 
- 
- 
Fig. 4. Tracking of α-depth contours for α = 0 . 05 , 0.2 and 0.4: In each panel the gray dots are outcomes from the data stream. The ﬁrst observations from the data stream 
are shown in dark gray and the dots become lighter gray as time progresses. The left and right column show cases with n u = 10 and 50 directional vectors, respectively. The 
rows from top to bottom show cases with a total for 10 3 , 10 4 and 10 5 observations, respectively. 
Evaluation for p > 2 is given below. Due to the computational 
burden of evaluating estimation error of non-elliptic distributions, 
the analysis was restricted to Gaussian distributions. Let X n = 
(X n, 1 , . . . , X n,p ) T be multivariate normally distributed with 
μn,i = E(X n,i ) = sin 
2 π
T n + ψ i 

, i = 1 , . . . , p 
(11) 
where ψ i , i = 1 , . . . , p are independent uniformly distributed vari- 
ables on the interval [0 , 2 π] ensuring that the marginal expecta- 
tions are out of phase. Covariance between X n,i and X n, j is 
Cov (X n,i , X n,j ) = 

0 . 4 sin 
2 π
T n + ψ 

+ 0 . 4 
| i −j| 
(12) 
where ψ is uniformly distributed on the interval [0 , 2 π] . 
6 
 H.L. Hammer, A. Yazidi and H. Rue 
Pattern Recognition 122 (2022) 108339 
Table 3 
Multivariate lognormal distribution case: The second and third columns 
shows the CPU time (in seconds) and the number of directional vectors 
used to obtain a mean absolute depth error (MADE) less than 0.05, respec- 
tively. The fourth and ﬁfth and the sixth and seventh columns show the 
same to obtain MADE less than 0.02 and 0.01, respectively. 
MADE < 0 . 05 
MADE < 0 . 02 
MADE < 0 . 01 
CPU time 
n u 
CPU time 
n u 
CPU time 
n u 
p = 2 
0.00013 
8 
0.00957 
27 
0.11169 
40 
p = 3 
0.00024 
27 
0.01533 
135 
0.56418 
202 
p = 4 
0.00021 
24 
0.03214 
274 
1.64312 
924 
p = 5 
0.00043 
45 
0.14592 
1166 
6.16044 
3936 
p = 6 
0.00053 
54 
0.27431 
2079 
9.30407 
15,786 
Table 4 
Oﬄine experiment: Comparison of the DUMIQE estimator and the estimator 
recommended in [16] to estimate α-depth contours for α = 0 . 05 , 0.2 and 0.4. 
MADE, ED and CPU refers to the error measures in (7) and (8) (multiplied by 
10 3 ) and CPU time used (in seconds), respectively. N refers to the sample size. 
p = 2 
p = 3 
N
Method 
MADE 
ED 
CPU 
MADE 
ED 
CPU 
500 
Oﬄine 
14.9 
43.1 
0.291 
16.9 
40.5 
1.634 
DUMIQE 
25.1 
63.9 
0.045 
34.9 
69.7 
0.288 
2000 
Oﬄine 
7.0 
20.7 
1.421 
7.2 
18.2 
9.489 
DUMIQE 
10.6 
28.5 
0.182 
12.2 
26.5 
1.154 
10 4 
Oﬄine 
3.0 
9.0 
8.761 
3.0 
7.7 
55.12 
DUMIQE 
4.4 
12.1 
0.908 
4.6 
10.6 
5.769 
5 · 10 4 
Oﬄine 
1.3 
4.0 
52.32 
1.3 
3.5 
326.0 
DUMIQE 
1.8 
5.4 
4.542 
2.0 
4.7 
28.84 
Tables 5 to 6 show results tracking α-depth regions for α = 
0 . 05 , 0.2 and 0.4 for periods T = 10 3 and T = 10 4 under optimal 
choices of the tuning parameter 1 More detailed results are given 
in Figures 18 and 19 in supplementary material S.3. For T = 10 3 , 
MADE is around 0.05 and the estimation error does not decrease 
with increasing number of directional vectors which may seem 
surprising. The reason is that if the quantile estimates are poor, 
the intersections of the resulting halfspaces do not necessarily be- 
come better by adding more halfspaces. For T = 10 4 MADE is be- 
tween 0.02 and 0.03. The optimal number of halfspaces increases 
with dimension, but not dramatically. 
The algorithm is computationally very eﬃcient. For dimension 
p = 5 the algorithm can optimally process 10 4 to 10 5 observations 
from a data stream every second on a single CPU processor. 
By using more equidistant directional vectors, we expect reduc- 
tion in the tracking error. Consider the dynamic case above ex- 
cept that the directional vectors are chosen more equidistantly. Di- 
rectional vectors were generated using the ﬁltering procedure in 
Section 3 with N u = 10 n u . 
The results are shown in Table 7 and more detailed results are 
given in Figure 21 in supplementary material S.3. 
By comparing Tables 5 and 6 with 7 , we see that for T = 10 3 
and T = 10 4 , minimum MADE is reduced from 0.045 to 0.040 and 
from 0.0226 to 0.0216, respectively. However, more importantly, 
by using equidistant vectors, the best results are obtained using 
fewer directional vectors. For both T = 10 3 and T = 10 4 , the opti- 
mal number of vectors are reduced from 25 to 10. Finally, we ob- 
serve signiﬁcant improvement if only ﬁve directional vectors were 
used. Using equidistant directional vectors adds an additional com- 
putational cost in the initialization of the algorithm, but results 
into gained peak performance and fewer directional vectors, and 
1 In a practical situation, the history of the data stream can be used to estimate 
(or track) optimal values of the tuning parameters. We are currently working on 
such procedures. 
thus less computation time and memory are needed during track- 
ing. 
6. Real-life data examples 
In this section, we use the algorithm on a real-life dataset re- 
lated to activity change detection. A second real-life data example 
related to real-time event detection using Twitter data is given in 
supplementary material S.4. 
We demonstrate how the algorithm can be used to detect out- 
liers and events and perform classiﬁcations in dynamic settings. 
For example, related to event detection, by characterizing a data 
stream distribution with multiple depth contours, in practice any 
change in the data stream distribution can be detected. Not only 
changes in common properties such as expectation and covariance 
structure, but also changes in shape such as a change from an el- 
liptic to a non-elliptic distribution. 
6.1. Activity change detection 
Activity recognition is a highly active ﬁeld of research where 
sensory information is used to automatically detect and identify 
activities of users. Activity recognition can help for example detect 
sedentary lifestyle and prompt the user to perform healthy exer- 
cises. 
We consider an accelerometer dataset from the WISDM (Wire- 
less Sensor Data Mining) project [22] . Accelerations in x , y and z
directions were observed, with a frequency of 20 observations per 
second, while users were performing the activities walking, jog- 
ging, walking up a stairway and walking down a stairway. A to- 
tal of 36 users were observed and the dataset contains a total of 
989 875 observations. 
Current research focuses on supervised approaches where his- 
toric and annotated activity observations are used to train an ac- 
tivity classiﬁcation model. E.g [22] . trained models such as decision 
trees and neural networks. However, such an approach is highly 
sensitive to any temporal changes in the data, e.g. if the user 
switches to an activity that is not part of the training material 
as a consequence for example of becoming ﬁtter, sick etc. In this 
example we rather take an unsupervised approach and the goal 
is to detect whenever the user changes activity. Since we receive 
20 accelerometer observations per second, it is important that the 
streaming approach is computationally eﬃcient. 
Fig. 5 shows in gray x , y and z acceleration for an arbitrary user. 
The red lines show when the user changed activity. Acceleration 
distributions are fairly stationary within an activity, but with some 
gradual and abrupt changes. The users changed activities in many 
cases as often as every 30 seconds making this a challenging track- 
ing and change detection problem. Fig. 6 shows scatter plots for 
two arbitrary sessions with minimal temporal trend. The simul- 
taneous acceleration distributions vary substantially between ses- 
sions and are often far from being elliptical. Further, even though 
the distributions are different, the mean and covariances are often 
quite similar making the change detection task based on elliptic 
distributions (Mahalanobis distance) challenging. We thus suggest 
the following depth based change detection procedure: 
1. Track α-depth contours of the simultaneous acceleration distri- 
bution by tracking n u directional quantiles using the DUMIQE 
algorithm with tuning parameter λ. 
2. Compute the Euclidean distance between the current α-depth 
contours and the contours h seconds back in time using 
Equation (8) , denoted ED t at time t. 
3. Track the expectation and standard deviation of ED t distribu- 
tion using exponential moving average 
E( ED t ) = (1 −δ) E( ED t−1 ) + δED t 
7 
 H.L. Hammer, A. Yazidi and H. Rue 
Pattern Recognition 122 (2022) 108339 
Table 5 
Tracking of α-depth regions for α = 0 . 05 , 0.2 and 0.4 for the distribution characterized by 
(11) and (12) with a period T = 10 3 . The columns ’Freq’ refer to how many times per mil- 
lisecond the algorithm can update an α-depth region when running on a single 1.8 GHz 
CPU processor. 
p = 2 
p = 3 
p = 4 
p = 5 
n u 
MADE 
Freq 
MADE 
Freq 
MADE 
Freq 
MADE 
Freq 
5 
0.0559 
972.7 
- 
- 
- 
- 
- 
- 
10 
0.0475 
478.9 
0.0577 
486.7 
- 
- 
- 
- 
25 
0.0445 
189.2 
0.0457 
189.7 
0.0510 
184.7 
- 
- 
50 
0.0474 
95.2 
0.0467 
95.1 
0.0492 
93.3 
0.0521 
92.4 
100 
0.0504 
47.9 
0.0502 
47.4 
0.0514 
46.8 
0.0523 
46.4 
200 
- 
- 
0.0536 
23.4 
0.0546 
22.6 
0.0541 
22.7 
500 
- 
- 
- 
- 
0.0590 
9.1 
0.0576 
8.9 
1000 
- 
- 
- 
- 
- 
- 
0.0604 
4.5 
Table 6 
Tracking of α-depth regions for α = 0 . 05 , 0.2 and 0.4 for the distribution characterized by 
(11) and (12) with a period T = 10 4 . The columns ’Freq’ refer to how many times per mil- 
lisecond the algorithm can update an α-depth region when running on a single 1.8 GHz 
CPU processor. 
p = 2 
p = 3 
p = 4 
p = 5 
n u 
MADE 
Freq 
MADE 
Freq 
MADE 
Freq 
MADE 
Freq 
5 
0.0439 
976.3 
- 
- 
- 
- 
- 
- 
10 
0.0305 
480.1 
0.0499 
484.3 
- 
- 
- 
- 
25 
0.0226 
189.2 
0.0318 
188.5 
0.0429 
184.7 
- 
- 
50 
0.0227 
95.4 
0.0277 
94.3 
0.0342 
93.6 
0.0395 
91.1 
100 
0.0236 
48.0 
0.0275 
47.3 
0.0306 
47.0 
0.0337 
46.1 
200 
- 
- 
0.0289 
23.3 
0.0299 
22.7 
0.0312 
22.6 
500 
- 
- 
- 
- 
0.0307 
9.1 
0.0309 
9.0 
1000 
- 
- 
- 
- 
- 
- 
0.0316 
4.5 
Fig. 5. The gray dots show accelerometer observations for an arbitrary user. The red lines show when the user changes activity. (For interpretation of the references to 
colour in this ﬁgure legend, the reader is referred to the web version of this article.) 
8 
 H.L. Hammer, A. Yazidi and H. Rue 
Pattern Recognition 122 (2022) 108339 
Fig. 6. The ﬁrst and the second row show scatterplot of accelerometer observations for two activity sessions. 
Table 7 
Tracking of α-depth regions 
for α = 0 . 05 , 0.2 and 0.4 for 
the distribution characterized 
by (11) and (12) using fairly 
equidistant directional vectors. 
Tracking error is measured us- 
ing MADE. The left and right 
columns show results for T = 
10 3 and 10 4 , respectively. Di- 
mension is p = 2 . 
n u 
T = 10 3 
T = 10 4 
5 
0.0465 
0.0303 
10 
0.0400 
0.0216 
25 
0.0440 
0.0217 
50 
0.0477 
0.0226 
100 
0.0505 
0.0236 
E( ED 2 
t ) = (1 −δ) E( ED 2 
t−1 ) + δED 2 
t 
SD ( ED t ) = 
 
E ( ED t ) 2 −E ( ED 2 
t ) 
4. When the user changes activity, we expect ED t to rapidly in- 
crease. A new activity is detected when ED t is more than 
η standard deviations higher then E ( ED t ) , i.e. ED t ≥E ( ED t ) + 
η SD ( ED t ) . 
5. When a new activity is detected, restart the tracking of the α- 
depth contours and go back to step 1. 
This approach is elegant since by virtue of measuring difference 
in depth contours, it can detect virtually any kind of change in the 
shape of the simultaneous acceleration distribution, for example 
a change from an elliptic to a non-elliptic distribution. Given the 
properties of the observations in this application, this ﬂexibility is 
important. 
We compare the approach against an identical approach except 
that in the ﬁrst part of the algorithm the mean and covariance 
structure (and not depth contours) were tracked using multivari- 
ate exponentially weighted moving average (MEWMA) [24] . 
We measured the performance of the depth and the MEWMA 
approaches for a wide range of values for the tuning parameters. 
As several sessions lasted for only 30 seconds, it was thus impor- 
tant for the tracking algorithms to rapidly adapt to a session be- 
fore a new change of activity took place. In the ﬁrst step of the 
procedures, we thus chose decreasing values of the tuning param- 
eters, but with a minimum value to take into account the dynamic 
changes in accelerations within a session, λt = max { 1 /t, λmin } , and 
tried the values 0.1, 0.05 and 0.01 for λmin 
2 This performed bet- 
ter than using constant values of the tuning parameter. We further 
2 For MEWMA, λt refers to the moving average tuning parameter and λt = 1 /t is 
thus equivalent to the sample mean. 
9 
 H.L. Hammer, A. Yazidi and H. Rue 
Pattern Recognition 122 (2022) 108339 
Table 8 
Change detection example. Results for the depth approach. 
λmin 
δmin 
h 
η
n u 
Precision 
Recall 
F1 score 
Det. delay (sec) 
0.01 
0.01 
100 
8 
20 
0.796 
0.497 
0.612 
1.325 
0.01 
0.01 
100 
8 
50 
0.781 
0.486 
0.599 
1.150 
0.01 
0.05 
200 
8 
20 
0.532 
0.682 
0.597 
1.415 
0.01 
0.05 
50 
8 
50 
0.613 
0.564 
0.587 
1.876 
0.01 
0.01 
200 
8 
20 
0.735 
0.488 
0.587 
1.202 
0.01 
0.05 
200 
8 
50 
0.510 
0.673 
0.580 
1.482 
0.01 
0.01 
200 
8 
50 
0.719 
0.480 
0.575 
1.219 
0.01 
0.05 
100 
8 
20 
0.538 
0.618 
0.575 
1.010 
0.05 
0.10 
200 
8 
20 
0.539 
0.616 
0.575 
1.903 
0.01 
0.05 
50 
8 
20 
0.613 
0.532 
0.570 
1.894 
Table 9 
Change detection example. Results for the MEWMA approach. 
λmin 
δmin 
h 
η
Precision 
Recall 
F1 score 
Det. delay (sec) 
0.01 
0.01 
200 
8 
0.454 
0.697 
0.550 
1.553 
0.05 
0.01 
200 
8 
0.447 
0.697 
0.545 
1.691 
0.05 
0.01 
50 
8 
0.438 
0.699 
0.539 
2.249 
0.01 
0.01 
50 
8 
0.421 
0.711 
0.529 
1.736 
0.01 
0.01 
100 
8 
0.398 
0.737 
0.517 
1.293 
0.05 
0.01 
100 
8 
0.388 
0.711 
0.502 
1.747 
0.05 
0.05 
200 
8 
0.353 
0.760 
0.483 
1.525 
0.05 
0.05 
50 
8 
0.336 
0.818 
0.476 
1.832 
0.05 
0.10 
200 
8 
0.336 
0.803 
0.474 
1.522 
0.01 
0.05 
200 
8 
0.330 
0.777 
0.463 
1.281 
tried the values 0.1, 0.05 and 0.01 for δ, 2.5, 5 and 10 seconds for 
h and 2, 5 and 8 for η. Further, for the depth approach we used 
three depth contours with α equal to 0.2, 0.05 and 0.01 and tried 
n u = 20 or 50 directional vectors. We ran the two change detec- 
tion approaches for the whole dataset for all the combinations of 
the parameters. This resulted in a total of 162 and 81 experiments 
for the depth and the MEWMA approaches, respectively. 
Precision, recall and the F1 score were used to measure perfor- 
mance [31] . If the approach detects more than one change between 
two true changes, we characterize the ﬁrst change as a correct de- 
tection and the others as false detections and deﬁne 
Precision = No. of correct detections 
No. of detections 
Recall = No. of correct detections 
No. true changes 
F1 score = 2 · Precision · Recall 
Precision + Recall 
Tables 8 and 9 show the top ten results with respect to the 
F1 score. The depth approach outperforms the MEWMA with re- 
spect to the F1 score and in addition detects the true changes more 
rapidly. The performance of the depth approach does not seem 
to be particularly sensitive to the number of directional quantiles 
used. 
7. Closing remarks 
In this paper we have presented a computationally and memory 
eﬃcient procedure to estimate and track Tukey α-depth contours 
using incremental quantile estimators. The algorithms use the re- 
sults by [20] according to which the α-depth region equals the di- 
rectional quantile envelope. We further demonstrated how incre- 
mental quantile estimators can be used to eﬃciently estimate the 
directional quantile envelope. By using incremental quantile esti- 
mators, we are able to recursively estimate and track α-depth con- 
tours, and to the best of our knowledge, it is the ﬁrst method in 
the literature with this ability. However, as shown in Section 5.2 , 
if the amount of data is limited, it is better to estimate α-depth 
contours using traditional oﬄine quantile estimators. 
The algorithms estimated Tukey depth contours equally well for 
both elliptic (Gaussian) and non-elliptic distributions. The perfor- 
mance, however, depends on the degree of curvature for the true 
depth contours being closely related to the degree of dependency 
between variables. For static data streams, the algorithm estimated 
a depth contour of dimension p = 10 with a mean absolute error 
in Tukey depth less than 0.01 in 1.2 and 125 minutes for inde- 
pendent and strongly dependent variables, respectively, on a single 
CPU processor. For dynamically changing data streams, even for di- 
mensions as high as p = 5 , the algorithm was able to process tens 
of thousands of observations per second and track depth contours 
with high precision. We have not found any studies that have been 
able to estimate depth contours of such a high dimension and for 
such a large of amount of data, which documents the eﬃciency of 
the algorithm. 
The real-life data examples demonstrate that the procedure is 
useful to track and detect changes in complex distributional pat- 
terns. 
To estimate α-depth contours, the number of directional vec- 
tors, n u , and values of tuning parameters in the incremental quan- 
tile tracking algorithms must be chosen. We are currently work- 
ing on procedures that use information from the history of the 
data stream to recursively update such values. Tukey depth is best 
suited to account for convex features of the distribution of interest. 
However, there exist other modiﬁed depth measures that better ac- 
count for non-convex features [6] . In the future, we plan to extend 
the method in this paper in order to also be applied to these depth 
measures. [1,2,12,26] 
Declaration of Competing Interest 
The authors declare that they have no known competing ﬁnan- 
cial interests or personal relationships that could have appeared to 
inﬂuence the work reported in this paper. 
Supplementary material 
Supplementary material associated with this article can be 
found, in the online version, at doi: 10.1016/j.patcog.2021.108339 . 
References 
[1] N. Alkhamees , M. Fasli , Event detection from social network streams using fre- 
quent pattern mining with dynamic support values, in: Big Data (Big Data), 
2016 IEEE International Conference on, IEEE, 2016, pp. 1670–1679 . 
[2] F. Atefeh , W. Khreich , A survey of techniques for event detection in twitter, 
Comput Intell 31 (1) (2015) 132–164 . 
[3] J.O. Cerdeira , T. Monteiro-Henriques , M.J. Martins , P.C. Silva , D. Alagador , 
A.M. Franco , M.L. Campagnolo , P. Arsénio , F.C. Aguiar , M. Cabeza , Revisit- 
ing niche fundamentals with tukey depth, Methods Ecol. Evol. 9 (12) (2018) 
2349–2361 . 
[4] Y. Chang , Z. Tu , W. Xie , B. Luo , S. Zhang , H. Sui , J. Yuan , Video anomaly detec- 
tion with spatio-temporal dissociation, Pattern Recognit (2021) 108213 . 
10 
 H.L. Hammer, A. Yazidi and H. Rue 
Pattern Recognition 122 (2022) 108339 
[5] F. Chebana , T.B. Ouarda , Depth-based multivariate descriptive statistics with 
hydrological applications, Journal of Geophysical Research: Atmospheres 116 
(D10) (2011) . 
[6] V. Chernozhukov , A. Galichon , M. Hallin , M. Henry , et al. , Monge–kantorovich 
depth, quantiles, ranks and signs, Ann Stat 45 (1) (2017) 223–256 . 
[7] D. Eddelbuettel , Seamless rand c++ integration with rcpp, Springer, New York, 
2013 . ISBN 978-1-4614-6867-7 
[8] D. Eddelbuettel , R. François , Rcpp: seamless r and c++ integration, J Stat Softw 
40 (8) (2011) 1–18 . 
[9] S.M. Erfani , S. Rajasegarar , S. Karunasekera , C. Leckie , High-dimensional and 
large-scale anomaly detection using a linear one-class svm with deep learning, 
Pattern Recognit 58 (2016) 121–134 . 
[10] H.L. Hammer , A. Yazidi , H. Rue , A new quantile tracking algorithm using a gen- 
eralized exponentially weighted average of observations, Applied Intelligence 
49 (4) (2019) 1406–1420 . 
[11] H.L. Hammer , A. Yazidi , H. Rue , Joint tracking of multiple quantiles through 
conditional quantiles, Inf Sci (Ny) 563 (2021) 40–58 . 
[12] M. Hasan , M.A. Orgun , R. Schwitter , A survey on real-time event detec- 
tion from the twitter data stream, Journal of Information Science (2017) . 
0165551517698564 
[13] S. Huang , Z. Kang , Z. Xu , Q. Liu , Robust deep k-means: an effective and simple 
method for data clustering, Pattern Recognit 117 (2021) 107996 . 
[14] M. Hubert , P. Rousseeuw , P. Segaert , Multivariate and functional classiﬁcation 
using depth and distance, Adv Data Anal Classif 11 (3) (2017) 445–466 . 
[15] M. Hubert , P.J. Rousseeuw , P. Segaert , Multivariate functional outlier detection, 
Statistical Methods & Applications 24 (2) (2015) 177–202 . 
[16] R.J. Hyndman , Y. Fan , Sample quantiles in statistical packages, Am Stat 50 (4) 
(1996) 361–365 . 
[17] B.K. Iwana , S. Uchida , Time series classiﬁcation using local distance-based fea- 
tures in multi-modal fusion networks, Pattern Recognit 97 (2020) 107024 . 
[18] R. Jörnsten , Clustering and classiﬁcation based on the l1 data depth, J Multivar 
Anal 90 (1) (2004) 67–89 . 
[19] S. Kim , B.M. Mun , S.J. Bae , Data depth based support vector machines for pre- 
dicting corporate bankruptcy, Applied Intelligence 48 (3) (2018) 791–804 . 
[20] L. Kong , I. Mizera , Quantile tomography: using quantiles with multivariate 
data, Stat Sin (2012) 1589–1610 . 
[21] D. Kosiorowski , Z. Zawadzki , Depthproc an r package for robust exploration 
of multidimensional economic phenomena, arXiv preprint arXiv:1408.4542 
(2014) . 
[22] J.R. Kwapisz , G.M. Weiss , S.A. Moore , Activity recognition using cell phone ac- 
celerometers, ACM SigKDD Explorations Newsletter 12 (2) (2011) 74–82 . 
[23] X. Liu , K. Mosler , P. Mozharovskyi , Fast computation of tukey trimmed re- 
gions and median in dimension p > 2 , Journal of Computational and Graphical 
Statistics (2019) 1–31 . 
[24] C.A. Lowry , W.H. Woodall , C.W. Champ , S.E. Rigdon , A multivariate exponen- 
tially weighted moving average control chart, Technometrics 34 (1) (1992) 
46–53 . 
[25] J. Ma , Y. Zhang , L. Zhang , Discriminative subspace matrix factorization for mul- 
tiview data clustering, Pattern Recognit 111 (2021) 107676 . 
[26] J.-C. Massé, Asymptotics for the tukey depth process, with an application to a 
multivariate trimmed mean, Bernoulli (2004) 397–419 . 
[27] K. Mosler , Depth Statistics, in: Robustness and complex data structures, 
Springer, 2013, pp. 17–34 . 
[28] R Core Team , R: A Language and Environment for Statistical Computing, R 
Foundation for Statistical Computing, 2021 . Vienna, Austria 
[29] N. Rastin , M.Z. Jahromi , M. Taheri , A generalized weighted distance k-nearest 
neighbor for multi-label problems, Pattern Recognit 114 (2021) 107526 . 
[30] E.B. Saff, A.B. Kuijlaars , Distributing many points on a sphere, The mathemati- 
cal intelligencer 19 (1) (1997) 5–11 . 
[31] M. Sokolova , G. Lapalme , A systematic analysis of performance measures 
for classiﬁcation tasks, Information Processing & Management 45 (4) (2009) 
427–437 . 
[32] J.W. Tukey , Mathematics and the picturing of data, in: Proceedings of the in- 
ternational congress of mathematicians, 2, 1975, pp. 523–531 . 
[33] B. Williams , M. Toussaint , A.J. Storkey , Modelling motion primitives and their 
timing in biologically executed movements, in: Advances in neural information 
processing systems, 2008, pp. 1609–1616 . 
[34] A. Yazidi , H. Hammer , Multiplicative update methods for incremental quantile 
estimation, IEEE Trans Cybern 49 (3) (2017) 746–756 . 
[35] V. Zavrtanik , M. Kristan , D. Sko ˇcaj , Reconstruction by inpainting for visual 
anomaly detection, Pattern Recognit 112 (2021) 107706 . 
[36] Y. Zuo , R. Serﬂing , General notions of statistical depth function, Ann Stat 
(20 0 0) 461–482 . 
Hugo Lewi Hammer received the M.Sc. and Ph.D. degrees 
from the Norwegian University of Science and Technology, 
in 2003 and 2008, respectively. He is currently a professor 
with the Department of Computer Science, OsloMet Oslo 
Metropolitan University, Oslo, Norway and an adjunct re- 
search scientist at Simula Metropolitan Centre, Oslo, Nor- 
way. Before joining OsloMet and SimulaMet, he worked 
as a researcher with Norwegian Computer Center, Oslo, 
Norway. His research interests include computer intensive 
statistical methods, machine learning, learning automata 
and stochastic optimization. 
Anis Yazidi received the M.Sc. and Ph.D. degrees from the 
University of Agder, Grimstad, Norway, in 2008 and 2012, 
respectively. He is currently a professor with the De- 
partment of Computer Science OsloMet Oslo Metropoli- 
tan University, Oslo, Norway. Before joining OsloMet, he 
worked as a researcher with Teknova AS, Grimstad, Nor- 
way. His current research interests include machine learn- 
ing, learning automata, stochastic optimization, software- 
deﬁned networks and cloud computing. He led the re- 
search group Autonomous Systems and Networks at 
OsloMet from 2015 to 2018. He is currently the leader 
of the research group Applied Artiﬁcial Intelligence at 
OsloMet. 
Håvard Rue received the M.Sc. and Ph.D. degrees from 
the Norwegian Institute of Technology, in 1988 and 1993, 
respectively. He is currently a professor in statistics with 
the Computer, Electrical and Mathematical Science and 
Engineering Division, King Abdullah University of Sci- 
ence and Technology (KAUST), Saudi Arabia. Before join- 
ing KAUST, he worked as a professor in statistics at Nor- 
wegian University of Science and Technology. His re- 
search interests lie in computational Bayesian statistics 
and Bayesian methodology such as priors, sensitivity and 
robustness. His main body of research is built around the 
R-INLA project ( www.r-inla.org ), which aims to provide a 
practical tool for approximate Bayesian analysis of latent 
Gaussian models, often at extreme data scales. This project also includes effort s to 
use stochastic partial differential equations to represent Gaussian ﬁelds, for the use 
in spatial statistics. He is the leader of the research group Bayesian Computational 
Statistics and Modeling. 
11 
",https://doi.org/10.1016/j.patcog.2021.108339,doc29,"Pattern Recognition 122 (2022) 108339 Contents lists available at ScienceDirect Pattern Recognition journal homepage: www.elsevier.com/locate/patcog Estimating Tukey depth using incremental quantile estimators Hugo L. Hammer a , ∗, Anis Yazidi b , Håvard Rue c a OsloMet - Oslo Metropolitan University, Norway Simula Metropolitan Centre for Digital Engineering, Norway b OsloMet - Oslo Metropolitan University, Norway c King Abdullah University of Science and Technology, Saudi Arabia a r t i c l e i n f o Article history: Received 26 August 2020 Revised 13 September 2021 Accepted 18 September 2021 Available online 20 September 2021 Keywords: Data stream Incremental quantile estimator Distributional patterns Real-time analytics Tukey depth a b s t r a c t Measures of distance or how data points are positioned relative to each other are fundamental in pattern recognition. The concept of depth measures how deep an arbitrary point is positioned in a dataset, and is an interesting concept in this regard. However, while this concept has received a lot of attention in the statistical literature, its application within pattern recognition is still limited. To increase the applicability of the depth concept in pattern recognition, we address the well-known computational challenges associated with the depth concept, by suggesting to estimate depth using in- cremental quantile estimators . The suggested algorithm can not only estimate depth when the dataset is known in advance, but can also track depth for dynamically varying data streams by using recursive up- dates . The tracking ability of the algorithm was demonstrated based on a real-life application associated with detecting changes in human activity from real-time accelerometer observations. Given the ﬂexibility of the suggested approach, it can detect virtually any kind of changes in the distributional patterns of the observations, and thus outperforms detection approaches based on the Mahalanobis distance. © 2021 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license ( ) 1. Introduction Measures of distance or how data points are positioned relative to each other, are fundamental in pattern recognition. For example in anomaly detection [9] e.g using auto encoders [4,35] , clustering [13,25] or classiﬁcation [17,29] . To measure distance or how data points are positioned rela- tive to each other, data depth is an interesting concept. Data depth measures how deep an arbitrary point is position in a dataset. While the concept has received a lot of attention in the statisti- cal literature [27] , the application within pattern recognition is still limited. There are however some notable exceptions. For exam- ple [14,18,19] applied the concept for classiﬁcation and clustering. Depth has also been applied to a wide range of disciplines such as economy [14,19,21] , health and biology [15,33] , ecology [3] and hydrology [5] to name a few. The earliest and most popular depth measure is Tukey depth [32] . The Tukey depth of a point is deﬁned as the minimum prob- ability mass carried by any closed halfspace containing the point. However, the computation of Tukey depth for higher dimensions or ∗Corresponding author. E-mail address: hugo.hammer@oslomet.no (H.L. Hammer). for even moderate amounts of data is computationally demanding which limits its applicability [23] . The main aim of this paper is to address these aforemen- tioned computational issues, and thus increase the applicabil- ity of the depth concept within pattern recognition . Our ap- proach takes advantage of the following result from Kong and Miz- era [20] according to which the authors deﬁned halfspaces such that a speciﬁc portion of the data points are on one side of the halfspace. They further showed that contours with a speciﬁc Tukey depth can be estimated from the intersection of such halfspaces over different directions. Such contours can again be used to esti- mate the depth of any point. In order to apply this result to esti- mate depth in dimension p, the positions of O (c p−1 ) , c > 1 halfs- paces must be estimated requiring estimators that are both mem- ory and computationally eﬃcient. In this paper, we therefore sug- gest to use incremental quantile estimators to estimate the positions of the halfspaces [10,11] . These estimators only need to store a sin- gle value in memory, i.e. O (1) , and only need to perform a single operation per observation resulting in a computational complexity of O (n ) for n observations. As opposed to this, traditional quantile estimators have a memory requirement of O (n ) and a O (n log n ) computational complexity. However, the computational eﬃciency comes with a price and traditional estimators provide more pre- cise estimates based on the same observations. 0031-3203/ H.L. Hammer, A. Yazidi and H. Rue Pattern Recognition 122 (2022) 108339 Fig. 1. Examples of three halfspaces (blue, green, red) containing the point x . The blue contours represent some probability distribution P. (For interpretation of the references to colour in this ﬁgure legend, the reader is referred to the web version of this article.) The second aim is to recursively update and even track Tukey depth contours of streams of multivariate data in real time . A remarkable advantage with incremental quantile estima- tors is that they not only can estimate quantiles when the data is known in advance, but can recursively update and even track quantiles of data streams. Thus, by using incremental quantile estimators to estimate halfspaces, Tukey depth contours can be tracked in real time. We are not aware of any other method that can eﬃciently compute Tukey depth in real-time. Finally, the real-world applicability of computing Tukey depth in real-time settings is demonstrated where the developed methods are used to detect changes in human activity in real-time from accelerometer observations. Due the ﬂexibility of the sug- gested approach, it can detect virtually any kind of changes in the distributional patterns of the accelerometer observation, and out- performs popular approaches based on Mahalanobis distance. The main contributions of the paper are as follows: • We present a new, simple and computationally eﬃcient method to compute Tukey depth. • The method can even be used to compute Tukey depth in real- time, and is to the best of our knowledge the ﬁrst method with this ability. • The method is applied to detect changes in human activity in real-time which demonstrates its usefulness and applicability in real-world scenarios. The paper is organized as follows. In Section 2 , the concept of depth is introduced including some theoretical fundamentals to compute Tukey depth. Section 3 provides an eﬃcient procedure to estimate Tukey depth. Section 4 presents performance metrics that will be used to evaluate the algorithm and Sections 5 and 6 pro- vide synthetic and real-life data experiments. 2. The concept of depth Let X = (X 1 , . . . , X p ) T represent a p-dimensional stochastic vec- tor with probability distribution P . Let D (x, P ) denote the depth function of a point x with respect to the probability distribution P . A high (low) value of the depth function refers to a central (outly- ing) point of the probability distribution. A general depth function is deﬁned by satisfying the natural requirements of aﬃne invari- ance, maximality at center, monotonicity relative to deepest point and vanishing at inﬁnity [36] . The most used depth function is Tukey depth. Deﬁnition 1 (Tukey depth) . Let U refer to the set of all vectors with unit length. Tukey depth is the minimum probability mass carried by any closed halfspace containing the point D (x, P ) = inf u ∈U P  u T X ≤u T x  (1) Fig. 1 shows three halfspaces containing the point x . The prob- ability mass carried by the red and blue halfspaces are larger than for the green halfspace. Thus the probability mass carried by the green halfspace is closer to the Tukey depth, which is the mini- mum probability mass over all half spaces containing x . Intuitively, this is a reasonable and general measure for the centrality of x with respect to P . Deﬁne α-depth region, directional quantile and directional quantile halfspace. Deﬁnition 2 (. α-depth region) The α-depth region with respect to Tukey depth, D (α) , is deﬁned as the set of points whose depth is at least α D (α) = { x ∈ R p : D (x, P ) ≥α} (2) The boundary of D (α) is known as the α-depth contour. The α-depth regions are closed, convex, and nested for increas- ing α. Deﬁnition 3 (Directional quantile) . For any unit directional vector u ∈ U, deﬁne the directional quantile as Q(α, u T X ) = F −1 u T X (α) (3) where F −1 u T X (x ) refers to the inverse of the univariate cumulative distribution function of the projection of X on u . Deﬁnition 4 (Directional quantile halfspace) . The directional quan- tile halfspace is deﬁned as H(α, u ) =  x ∈ R p : u T x ≥Q(α, u T X )  (4) which is bounded away from the origin at distance Q(α, u T X) by the hyperplane with normal vector u . Consequently P (X ∈ H(α, u )) = 1 −α for any u ∈ U. The estimation procedures in this paper builds on the following theorem from [20] . Theorem 1. The α-depth region in (2) equals the directional quantile envelope D (α) =  u ∈U H(α, u ) (5) Tukey depth may not be deﬁned for depths above some thresh- old and the intersection becomes empty. 3. Eﬃcient estimation of tukey depth Given a multivariate dataset, in this section we suggest a simple procedure to estimate whether an arbitrary point is within or out- side an α-depth region. The procedure uses Theorem 1 , and con- sists of three parts. 1. Unit length directional vectors. The generation of uniformly distributed directional vectors is simple: Let Z 1 , . . . , Z p be inde- pendent standard normally distributed stochastic variables and deﬁne Z = (Z 1 , . . . , Z p ) T . Then U = Z/ ∥ Z∥ 2 will be uniformly dis- tributed on the unit sphere, where ∥ · ∥ 2 refers to the Euclidean 2 H.L. Hammer, A. Yazidi and H. Rue Pattern Recognition 122 (2022) 108339 norm. This is the procedure used in most of the experiments in this paper. However, intuitively, using directional vectors that are more equidistantly spread on the unit sphere would be more ef- ﬁcient. We thus also considered the following approach accord- ing to which we generate many uniformly distributed directional vectors, N u , and secondly ﬁlter out directional vectors that are closer than some threshold. The approach is however computa- tionally demanding, O (N 2 u p 2 ) . There are other algorithms to gen- erate fairly equidistantly spread direction vectors, see e.g spiral al- gorithms [30] . We have not evaluated the potential of these algo- rithms. 2. Directional quantiles estimates. The next part is to estimate directional quantiles for each directional vector generated above. As pointed out in the introduction, we use incremental quantile estimators. A prominent example is the DUMIQE algorithm which recursively updates directional quantile estimates as follows for ev- ery observation u T i x j−1 [34]  Q (α, u T i X j ) ← (1 + λα)  Q (α, u T i X j−1 ) , if u T i x j >  Q (α, u T i X j−1 )  Q (α, u T i X j ) ← (1 −λ(1 −α))  Q (α, u T i X j−1 ) , if u T i x j <  Q (α, u T i X j−1 ) (6) The update is quite intuitive. If the sample u T i x j is above (re- spectively below) the current estimate, increase (respectively re- duce) the corresponding directional quantile estimate. The tuning parameter λ > 0 controls the update size. If the data is known be- forehand or it comes in the form of a stationary data stream, it makes sense to let the value of λ be reduced with time. For non- stationary data streams a constant value of λ is more suitable to gradually forget old and outdated data [34] . The procedure is de- tailed in Algorithm 1 . Algorithm 1 Estimating directional quantiles. Input: u 1 , . . . , u n u // Unit length directional vectors x 1 , x 2 , . . . , x n // Dataset α, λ  Q (α, u T i X 0 ) // Initial value Method: 1: for j ∈ 1 , 2 , . . . , n do 2: for i ∈ 1 , 2 , . . . , n u do 3: if u T i x j >  Q (α, u T i X j−1 ) then 4:  Q (α, u T i X j ) ← (1 + λα)  Q (α, u T i X j−1 ) 5: else 6:  Q (α, u T i X j ) ← (1 −λ(1 −α))  Q (α, u T i X j−1 ) 7: end if 8: end for 9: end for 3. Compute if a point w is within the α-depth region. The di- rectional quantile estimates from Algorithm 1 can be used to com- pute if w is within all the directional quantile halfspaces and thus, according to Theorem 1 , being within the α-depth region. The pro- cedure is detailed in Algorithm 2 . The condition in line 2 is based on Equation (4) and checks if w is outside of the estimated direc- tional quantile halfspace. Convergence. The procedure consists of two approximations 1) the ﬁnite number of directional vectors and 2) the estimates of the true directional quantiles. To ensure convergence, the direc- tional vector selection procedure must cover the unit sphere when the number of directional vectors goes to inﬁnity and, secondly, the directional quantile estimates must converge to the true direc- tional quantiles, when the number of observations goes to inﬁn- ity. By using the simple procedure above to select uniformly dis- tributed directional vectors, the ﬁrst requirement is satisﬁed. Fur- ther, [34] and [11] prove the second requirement. Algorithm 2 Compute if a point w is within the α-depth region. Input:  Q (α, u T i X n ) , i = 1 , . . . , n u // Dir. quantile estimates from Algorithm 1. w , i = 1 InAlphaDepthRegion = True // True (False) if w is within (outside) the α-depth region Method: 1: while InAlphaDepthRegion and i ≤n u do 2: if u T i w <  Q (α, u T i X n ) then 3: InAlphaDepthRegion = False 4: end if 5: i ← i + 1 6: end while 7: Print(”Point w in α-depth region?”, InAlphaDepthRegion) Fig. 2. Figure illustrating the approach to measure α-depth contour estimation er- ror. The black and blue curves show the true α-depth regions and the envelope estimate. The lines with directions v i , i = 1 , . . . , n v are shown in red. (For interpre- tation of the references to colour in this ﬁgure legend, the reader is referred to the web version of this article.) 4. Performance metrics We suggest to measure error along lines l i , i = 1 , . . . , n v going through the center of the true distribution and outward in uni- formly distributed directions v i , i = 1 , . . . , n v ( Fig. 2 ). This approach scales well with dimension p. We suggest two error measures: Depth error: Let  w i,k denote the point of intercept between the line, l i , and the envelope and compute the true depth at this point, D (  w i,k , P ) . The error is computed using mean absolute depth error (MADE) over all the lines l i , i = 1 , . . . , n v MADE k = 1 n v n v i =1 | αk −D (  w i,k , P ) | and again average over envelopes MADE = 1 K K k =1 MADE k (7) To compute MADE for higher dimensions, the true depth must be computed for a large set of points  w i,k . For non-elliptic distribu- tions this is computationally demanding and was limited to p ≤6 in the experiments. For elliptic distributions, and in particular mul- tivariate normal distributions, the true depth of any point can be computed analytically and thus MADE was computed up to dimen- sion p = 10 in the experiments. Details are given in supplementary material S.1. Obviously, if we knew that the observations were mul- 3 H.L. Hammer, A. Yazidi and H. Rue Pattern Recognition 122 (2022) 108339 tivariate normally distributed, other depth measures such as Ma- halanobis depth would be more natural, but the computations are only used to evaluate the performance of the algorithm for high dimensions. Euclidean distance: Along each line, l i , compute the point of intercept between the line and the true α-depth contour of depth αk , denoted w i,k . Compute the error as the average Euclidean dis- tance (ED) ED k = 1 n v n v i =1 ∥ w i,k − w i,k ∥ 2 where  w i,k still refers to the intercept between line l i and the en- velope. Further take the average over envelopes ED = 1 K K k =1 ED k (8) 5. Synthetic experiments In this section, the performance of the algorithms in Section 3 are evaluated in several synthetic experiments. The experiments focus on streaming data, except in Section 5.2 . In Section 6 , the algorithms are demonstrated in a real-life data ex- ample. All computations were run on a Dell PowerEdge R815 server with 64 1.8 GHz AMD CPU processors and Linux Ubuntu operat- ing system version 16.04. The experiments were implemented in R [28] , but with the most computer intensive parts in C++ integrated using Rcpp [7,8] . 5.1. Synthetic experiments - Static data stream Figs. 3 show results of estimating the α = 0 . 1 depth contour for a multivariate normally distributed data stream with parameters μ = 0 0 ,  = 1 0 . 82 0 . 82 1 (9) Directional quantiles were estimated using DUMIQE with decreas- ing values of the tuning parameter, λn = 1 /n . We see that a fairly good estimate is achieved with 200 obser- vations and that the error is minimal with 20 0 0 observations. A similar visualization for the highly non-elliptical and heavy tailed lognormal distribution is shown in Figure 7 in supplementary ma- terial S.2. Due to the ﬂexibility of the depth concept, the method performs equally well for such a distribution. Further, in supple- mentary material S.2, a few examples of joint estimation of multi- ple α-depth regions using the ShiftQ algorithm are shown. The re- sults show that multiple depth regions can eﬃciently be estimated for both Gaussian and non-Gaussian distributions. Considered now joint estimation of α-depth regions for α = 0 . 05 , 0 . 2 and 0.4 and for p > 2 . Table 1 shows results for stan- dard multivariate normally distributed observation. More detailed results are given in Figures 12 and 13 in supplementary material S.2. CPU time refers to the computational time needed per α-depth region to obtain estimates with a given precision using a single CPU core. The number of directional vectors (and thus CPU time) in- creases with p and estimation precision. The algorithm performs very well. For example, for dimension p = 10 , MADE less than 0.02 is obtained in about 1.5 seconds. MADE < 0 . 01 could be reached in shorter CPU time than what is shown in Table 1 using a higher number of directional vectors, but this is not explored. Now, assume that X = (X 1 , . . . , X p ) T is a multivariate normally distributed variable with zero expectation vector and strong de- pendencies Cov (X i , X j ) = exp (−0 . 2 | i −j| ) , i, j = 1 , . . . , p (10) Table 1 Multivariate standard normal distribution case: The second and third columns show the CPU time (in seconds) and the number of directional vectors used to obtain MADE less than 0.05. The other columns show the same to obtain MADE less than 0.02 and 0.01, respectively. MADE < 0 . 05 MADE < 0 . 02 MADE < 0 . 01 CPU time n u CPU time n u CPU time n u p = 2 0.00013 8 0.00174 12 0.00942 18 p = 3 0.00023 12 0.00429 27 0.04488 40 p = 4 0.00023 16 0.00958 81 0.11631 122 p = 5 0.00043 20 0.02991 153 0.35146 345 p = 6 0.00054 24 0.07419 274 0.90636 1386 p = 8 0.00334 72 0.34695 1228 9.83845 9324 p = 10 0.01361 90 1.54246 3450 104.45206 88412 The results are shown in Table 2 . More detailed results are given in Figures 14 and 15 in supplementary material S.2. By comparing Tables 1 and 2 , we see that the number of directional vectors and CPU time needed increase when the variables of X are dependent. Let X still represent the multivariate normally distributed vari- able with covariances (10) . Table 3 shows results for the multivari- ate lognormal distribution Y = exp (X) . More detailed results are given in Figures 16 and 17 in supplementary material S.2. Tables 2 and 3 show that a speciﬁc level of MADE is reached faster for the lognormal distribution than for the multivariate dis- tribution documenting that the procedure eﬃciently can character- ize non-Gaussian distributions. To the best of our knowledge, the algorithm by [23] is the most eﬃcient algorithm in the literature to estimate Tukey α-depth re- gions. The authors focus on estimating exact trimmed α-depth re- gions resulting in complex combinatorial algorithms and the com- putation burden explodes with the number of samples. In compar- ison, the computational complexity of our algorithm increases lin- early with the number of samples. The authors can document esti- mation results up to dimension p = 9 , but only when the number of samples are restricted to less than 80. The algorithm by [23] is not constructed to handle streaming data. 5.2. Synthetic experiments - Oﬄine setting In this section, we compare the performance of the incremen- tal quantile estimator, DUMIQE, with state-of-the-art oﬄine quan- tile estimators to estimate α-depth regions when data is known in advance. State-of-the-art oﬄine quantile estimators are based on using weighted averages of consecutive order statistics Q(α) = (1 −δ) y [ j] + δy [ j + 1] where j−m N ≤α < j−m +1 N , y [ j] is the jth order statistic of the sample, m a constant and N the sample size. We use m = α+1 3 and δ = Nα + m −j and deﬁne α[ k ] = k −1 / 3 N+1 / 3 . The sample quan- tiles can be read from a linear interpolation between the points (α[ k ] , y [ k ]) , k = 1 , . . . , N. The resulting quantile estimates are ap- proximately median-unbiased regardless of the distribution of the data. This is the method referred to as Type 8 in the quantile function in R and is the one recommended by [16] . We consider the multivariate normal distribution case with co- variance matrix as given in (10) , sample sizes N = 50 0 , 20 0 0, 10 4 and 5 · 10 4 and dimensions p = 2 and p = 3 . For p = 2 and p = 3 , we used 1500 and 7500 directional vectors, respectively, which were suﬃciently many to obtain satisfactory performance. The results are shown in Table 4 . We see that the estimation er- rors using DUMIQE are about 1.5 time that of the oﬄine estimator. If fewer directional vectors were used, the differences in estimation error were substantially reduced. Further, the computational time of the oﬄine estimator is about ten times larger than the DUMIQE 4 H.L. Hammer, A. Yazidi and H. Rue Pattern Recognition 122 (2022) 108339 Fig. 3. Multivariate normal distribution case. Estimation of α-depth region for α = 0 . 1 using n u = 50 directional vectors. The rows from top to bottom show the estimates for 20, 200 and 2000 observations. The left and right column show all the half planes and the resulting envelopes in blue, respectively. The black curves show the true α-depth contour. (For interpretation of the references to colour in this ﬁgure legend, the reader is referred to the web version of this article.) estimator. In other words, if computational time or memory us- age are not an issue, the oﬄine estimator combined with a large amount of directional vectors will give the most precise estimates from the samples. Otherwise, incremental quantile estimators are preferable even for oﬄine settings. 5.3. Synthetic experiments - Dynamically changing data streams In this section, we consider the problem of tracking α-depth regions of dynamically varying data streams. Fig. 4 illustrates the problem. In each panel, the expectation vector of the data stream distribution moved from the bottom left to the upper right. At the same time the correlation, changed from strongly positive, 0.8, to strongly negative, −0 . 8 . For the 10 3 samples case (ﬁrst row), the algorithm was able to track the α-depth regions satisfactory. With 10 4 samples, the estimates improve signiﬁcantly and with 10 5 observations, the estimates are very close to the true contours. With 10 4 and 10 5 samples, 50 directional vectors give better and smoother estimates than 10 directional vectors. 5 H.L. Hammer, A. Yazidi and H. Rue Pattern Recognition 122 (2022) 108339 Table 2 Multivariate normal distribution case: The second and third columns show the CPU time (in seconds) and the number of directional vectors used to obtain a mean abso- lute depth error (MADE) less than 0.05, respectively. MADE < 0 . 05 MADE < 0 . 02 MADE < 0 . 01 CPU time n u CPU time n u CPU time n u p = 2 0.00034 18 0.00622 40 0.03734 40 p = 3 0.00095 27 0.03003 135 1.38903 135 p = 4 0.00238 54 0.13145 274 7.47343 616 p = 5 0.01275 102 0.43698 777 8.47334 3936 p = 6 0.03603 183 1.81652 3118 45.88106 15,786 p = 8 0.17285 819 23.21460 20,979 988.12085 358,438 p = 10 0.68053 2300 245.91893 198,927 - - Fig. 4. Tracking of α-depth contours for α = 0 . 05 , 0.2 and 0.4: In each panel the gray dots are outcomes from the data stream. The ﬁrst observations from the data stream are shown in dark gray and the dots become lighter gray as time progresses. The left and right column show cases with n u = 10 and 50 directional vectors, respectively. The rows from top to bottom show cases with a total for 10 3 , 10 4 and 10 5 observations, respectively. Evaluation for p > 2 is given below. Due to the computational burden of evaluating estimation error of non-elliptic distributions, the analysis was restricted to Gaussian distributions. Let X n = (X n, 1 , . . . , X n,p ) T be multivariate normally distributed with μn,i = E(X n,i ) = sin 2 π T n + ψ i , i = 1 , . . . , p (11) where ψ i , i = 1 , . . . , p are independent uniformly distributed vari- ables on the interval [0 , 2 π] ensuring that the marginal expecta- tions are out of phase. Covariance between X n,i and X n, j is Cov (X n,i , X n,j ) = 0 . 4 sin 2 π T n + ψ + 0 . 4 | i −j| (12) where ψ is uniformly distributed on the interval [0 , 2 π] . 6 H.L. Hammer, A. Yazidi and H. Rue Pattern Recognition 122 (2022) 108339 Table 3 Multivariate lognormal distribution case: The second and third columns shows the CPU time (in seconds) and the number of directional vectors used to obtain a mean absolute depth error (MADE) less than 0.05, respec- tively. The fourth and ﬁfth and the sixth and seventh columns show the same to obtain MADE less than 0.02 and 0.01, respectively. MADE < 0 . 05 MADE < 0 . 02 MADE < 0 . 01 CPU time n u CPU time n u CPU time n u p = 2 0.00013 8 0.00957 27 0.11169 40 p = 3 0.00024 27 0.01533 135 0.56418 202 p = 4 0.00021 24 0.03214 274 1.64312 924 p = 5 0.00043 45 0.14592 1166 6.16044 3936 p = 6 0.00053 54 0.27431 2079 9.30407 15,786 Table 4 Oﬄine experiment: Comparison of the DUMIQE estimator and the estimator recommended in [16] to estimate α-depth contours for α = 0 . 05 , 0.2 and 0.4. MADE, ED and CPU refers to the error measures in (7) and (8) (multiplied by 10 3 ) and CPU time used (in seconds), respectively. N refers to the sample size. p = 2 p = 3 N Method MADE ED CPU MADE ED CPU 500 Oﬄine 14.9 43.1 0.291 16.9 40.5 1.634 DUMIQE 25.1 63.9 0.045 34.9 69.7 0.288 2000 Oﬄine 7.0 20.7 1.421 7.2 18.2 9.489 DUMIQE 10.6 28.5 0.182 12.2 26.5 1.154 10 4 Oﬄine 3.0 9.0 8.761 3.0 7.7 55.12 DUMIQE 4.4 12.1 0.908 4.6 10.6 5.769 5 · 10 4 Oﬄine 1.3 4.0 52.32 1.3 3.5 326.0 DUMIQE 1.8 5.4 4.542 2.0 4.7 28.84 Tables 5 to 6 show results tracking α-depth regions for α = 0 . 05 , 0.2 and 0.4 for periods T = 10 3 and T = 10 4 under optimal choices of the tuning parameter 1 More detailed results are given in Figures 18 and 19 in supplementary material S.3. For T = 10 3 , MADE is around 0.05 and the estimation error does not decrease with increasing number of directional vectors which may seem surprising. The reason is that if the quantile estimates are poor, the intersections of the resulting halfspaces do not necessarily be- come better by adding more halfspaces. For T = 10 4 MADE is be- tween 0.02 and 0.03. The optimal number of halfspaces increases with dimension, but not dramatically. The algorithm is computationally very eﬃcient. For dimension p = 5 the algorithm can optimally process 10 4 to 10 5 observations from a data stream every second on a single CPU processor. By using more equidistant directional vectors, we expect reduc- tion in the tracking error. Consider the dynamic case above ex- cept that the directional vectors are chosen more equidistantly. Di- rectional vectors were generated using the ﬁltering procedure in Section 3 with N u = 10 n u . The results are shown in Table 7 and more detailed results are given in Figure 21 in supplementary material S.3. By comparing Tables 5 and 6 with 7 , we see that for T = 10 3 and T = 10 4 , minimum MADE is reduced from 0.045 to 0.040 and from 0.0226 to 0.0216, respectively. However, more importantly, by using equidistant vectors, the best results are obtained using fewer directional vectors. For both T = 10 3 and T = 10 4 , the opti- mal number of vectors are reduced from 25 to 10. Finally, we ob- serve signiﬁcant improvement if only ﬁve directional vectors were used. Using equidistant directional vectors adds an additional com- putational cost in the initialization of the algorithm, but results into gained peak performance and fewer directional vectors, and 1 In a practical situation, the history of the data stream can be used to estimate (or track) optimal values of the tuning parameters. We are currently working on such procedures. thus less computation time and memory are needed during track- ing. 6. Real-life data examples In this section, we use the algorithm on a real-life dataset re- lated to activity change detection. A second real-life data example related to real-time event detection using Twitter data is given in supplementary material S.4. We demonstrate how the algorithm can be used to detect out- liers and events and perform classiﬁcations in dynamic settings. For example, related to event detection, by characterizing a data stream distribution with multiple depth contours, in practice any change in the data stream distribution can be detected. Not only changes in common properties such as expectation and covariance structure, but also changes in shape such as a change from an el- liptic to a non-elliptic distribution. 6.1. Activity change detection Activity recognition is a highly active ﬁeld of research where sensory information is used to automatically detect and identify activities of users. Activity recognition can help for example detect sedentary lifestyle and prompt the user to perform healthy exer- cises. We consider an accelerometer dataset from the WISDM (Wire- less Sensor Data Mining) project [22] . Accelerations in x , y and z directions were observed, with a frequency of 20 observations per second, while users were performing the activities walking, jog- ging, walking up a stairway and walking down a stairway. A to- tal of 36 users were observed and the dataset contains a total of 989 875 observations. Current research focuses on supervised approaches where his- toric and annotated activity observations are used to train an ac- tivity classiﬁcation model. E.g [22] . trained models such as decision trees and neural networks. However, such an approach is highly sensitive to any temporal changes in the data, e.g. if the user switches to an activity that is not part of the training material as a consequence for example of becoming ﬁtter, sick etc. In this example we rather take an unsupervised approach and the goal is to detect whenever the user changes activity. Since we receive 20 accelerometer observations per second, it is important that the streaming approach is computationally eﬃcient. Fig. 5 shows in gray x , y and z acceleration for an arbitrary user. The red lines show when the user changed activity. Acceleration distributions are fairly stationary within an activity, but with some gradual and abrupt changes. The users changed activities in many cases as often as every 30 seconds making this a challenging track- ing and change detection problem. Fig. 6 shows scatter plots for two arbitrary sessions with minimal temporal trend. The simul- taneous acceleration distributions vary substantially between ses- sions and are often far from being elliptical. Further, even though the distributions are different, the mean and covariances are often quite similar making the change detection task based on elliptic distributions (Mahalanobis distance) challenging. We thus suggest the following depth based change detection procedure: 1. Track α-depth contours of the simultaneous acceleration distri- bution by tracking n u directional quantiles using the DUMIQE algorithm with tuning parameter λ. 2. Compute the Euclidean distance between the current α-depth contours and the contours h seconds back in time using Equation (8) , denoted ED t at time t. 3. Track the expectation and standard deviation of ED t distribu- tion using exponential moving average E( ED t ) = (1 −δ) E( ED t−1 ) + δED t 7 H.L. Hammer, A. Yazidi and H. Rue Pattern Recognition 122 (2022) 108339 Table 5 Tracking of α-depth regions for α = 0 . 05 , 0.2 and 0.4 for the distribution characterized by (11) and (12) with a period T = 10 3 . The columns ’Freq’ refer to how many times per mil- lisecond the algorithm can update an α-depth region when running on a single 1.8 GHz CPU processor. p = 2 p = 3 p = 4 p = 5 n u MADE Freq MADE Freq MADE Freq MADE Freq 5 0.0559 972.7 - - - - - - 10 0.0475 478.9 0.0577 486.7 - - - - 25 0.0445 189.2 0.0457 189.7 0.0510 184.7 - - 50 0.0474 95.2 0.0467 95.1 0.0492 93.3 0.0521 92.4 100 0.0504 47.9 0.0502 47.4 0.0514 46.8 0.0523 46.4 200 - - 0.0536 23.4 0.0546 22.6 0.0541 22.7 500 - - - - 0.0590 9.1 0.0576 8.9 1000 - - - - - - 0.0604 4.5 Table 6 Tracking of α-depth regions for α = 0 . 05 , 0.2 and 0.4 for the distribution characterized by (11) and (12) with a period T = 10 4 . The columns ’Freq’ refer to how many times per mil- lisecond the algorithm can update an α-depth region when running on a single 1.8 GHz CPU processor. p = 2 p = 3 p = 4 p = 5 n u MADE Freq MADE Freq MADE Freq MADE Freq 5 0.0439 976.3 - - - - - - 10 0.0305 480.1 0.0499 484.3 - - - - 25 0.0226 189.2 0.0318 188.5 0.0429 184.7 - - 50 0.0227 95.4 0.0277 94.3 0.0342 93.6 0.0395 91.1 100 0.0236 48.0 0.0275 47.3 0.0306 47.0 0.0337 46.1 200 - - 0.0289 23.3 0.0299 22.7 0.0312 22.6 500 - - - - 0.0307 9.1 0.0309 9.0 1000 - - - - - - 0.0316 4.5 Fig. 5. The gray dots show accelerometer observations for an arbitrary user. The red lines show when the user changes activity. (For interpretation of the references to colour in this ﬁgure legend, the reader is referred to the web version of this article.) 8 H.L. Hammer, A. Yazidi and H. Rue Pattern Recognition 122 (2022) 108339 Fig. 6. The ﬁrst and the second row show scatterplot of accelerometer observations for two activity sessions. Table 7 Tracking of α-depth regions for α = 0 . 05 , 0.2 and 0.4 for the distribution characterized by (11) and (12) using fairly equidistant directional vectors. Tracking error is measured us- ing MADE. The left and right columns show results for T = 10 3 and 10 4 , respectively. Di- mension is p = 2 . n u T = 10 3 T = 10 4 5 0.0465 0.0303 10 0.0400 0.0216 25 0.0440 0.0217 50 0.0477 0.0226 100 0.0505 0.0236 E( ED 2 t ) = (1 −δ) E( ED 2 t−1 ) + δED 2 t SD ( ED t ) =  E ( ED t ) 2 −E ( ED 2 t ) 4. When the user changes activity, we expect ED t to rapidly in- crease. A new activity is detected when ED t is more than η standard deviations higher then E ( ED t ) , i.e. ED t ≥E ( ED t ) + η SD ( ED t ) . 5. When a new activity is detected, restart the tracking of the α- depth contours and go back to step 1. This approach is elegant since by virtue of measuring difference in depth contours, it can detect virtually any kind of change in the shape of the simultaneous acceleration distribution, for example a change from an elliptic to a non-elliptic distribution. Given the properties of the observations in this application, this ﬂexibility is important. We compare the approach against an identical approach except that in the ﬁrst part of the algorithm the mean and covariance structure (and not depth contours) were tracked using multivari- ate exponentially weighted moving average (MEWMA) [24] . We measured the performance of the depth and the MEWMA approaches for a wide range of values for the tuning parameters. As several sessions lasted for only 30 seconds, it was thus impor- tant for the tracking algorithms to rapidly adapt to a session be- fore a new change of activity took place. In the ﬁrst step of the procedures, we thus chose decreasing values of the tuning param- eters, but with a minimum value to take into account the dynamic changes in accelerations within a session, λt = max { 1 /t, λmin } , and tried the values 0.1, 0.05 and 0.01 for λmin 2 This performed bet- ter than using constant values of the tuning parameter. We further 2 For MEWMA, λt refers to the moving average tuning parameter and λt = 1 /t is thus equivalent to the sample mean. 9 H.L. Hammer, A. Yazidi and H. Rue Pattern Recognition 122 (2022) 108339 Table 8 Change detection example. Results for the depth approach. λmin δmin h η n u Precision Recall F1 score Det. delay (sec) 0.01 0.01 100 8 20 0.796 0.497 0.612 1.325 0.01 0.01 100 8 50 0.781 0.486 0.599 1.150 0.01 0.05 200 8 20 0.532 0.682 0.597 1.415 0.01 0.05 50 8 50 0.613 0.564 0.587 1.876 0.01 0.01 200 8 20 0.735 0.488 0.587 1.202 0.01 0.05 200 8 50 0.510 0.673 0.580 1.482 0.01 0.01 200 8 50 0.719 0.480 0.575 1.219 0.01 0.05 100 8 20 0.538 0.618 0.575 1.010 0.05 0.10 200 8 20 0.539 0.616 0.575 1.903 0.01 0.05 50 8 20 0.613 0.532 0.570 1.894 Table 9 Change detection example. Results for the MEWMA approach. λmin δmin h η Precision Recall F1 score Det. delay (sec) 0.01 0.01 200 8 0.454 0.697 0.550 1.553 0.05 0.01 200 8 0.447 0.697 0.545 1.691 0.05 0.01 50 8 0.438 0.699 0.539 2.249 0.01 0.01 50 8 0.421 0.711 0.529 1.736 0.01 0.01 100 8 0.398 0.737 0.517 1.293 0.05 0.01 100 8 0.388 0.711 0.502 1.747 0.05 0.05 200 8 0.353 0.760 0.483 1.525 0.05 0.05 50 8 0.336 0.818 0.476 1.832 0.05 0.10 200 8 0.336 0.803 0.474 1.522 0.01 0.05 200 8 0.330 0.777 0.463 1.281 tried the values 0.1, 0.05 and 0.01 for δ, 2.5, 5 and 10 seconds for h and 2, 5 and 8 for η. Further, for the depth approach we used three depth contours with α equal to 0.2, 0.05 and 0.01 and tried n u = 20 or 50 directional vectors. We ran the two change detec- tion approaches for the whole dataset for all the combinations of the parameters. This resulted in a total of 162 and 81 experiments for the depth and the MEWMA approaches, respectively. Precision, recall and the F1 score were used to measure perfor- mance [31] . If the approach detects more than one change between two true changes, we characterize the ﬁrst change as a correct de- tection and the others as false detections and deﬁne Precision = No. of correct detections No. of detections Recall = No. of correct detections No. true changes F1 score = 2 · Precision · Recall Precision + Recall Tables 8 and 9 show the top ten results with respect to the F1 score. The depth approach outperforms the MEWMA with re- spect to the F1 score and in addition detects the true changes more rapidly. The performance of the depth approach does not seem to be particularly sensitive to the number of directional quantiles used. 7. Closing remarks In this paper we have presented a computationally and memory eﬃcient procedure to estimate and track Tukey α-depth contours using incremental quantile estimators. The algorithms use the re- sults by [20] according to which the α-depth region equals the di- rectional quantile envelope. We further demonstrated how incre- mental quantile estimators can be used to eﬃciently estimate the directional quantile envelope. By using incremental quantile esti- mators, we are able to recursively estimate and track α-depth con- tours, and to the best of our knowledge, it is the ﬁrst method in the literature with this ability. However, as shown in Section 5.2 , if the amount of data is limited, it is better to estimate α-depth contours using traditional oﬄine quantile estimators. The algorithms estimated Tukey depth contours equally well for both elliptic (Gaussian) and non-elliptic distributions. The perfor- mance, however, depends on the degree of curvature for the true depth contours being closely related to the degree of dependency between variables. For static data streams, the algorithm estimated a depth contour of dimension p = 10 with a mean absolute error in Tukey depth less than 0.01 in 1.2 and 125 minutes for inde- pendent and strongly dependent variables, respectively, on a single CPU processor. For dynamically changing data streams, even for di- mensions as high as p = 5 , the algorithm was able to process tens of thousands of observations per second and track depth contours with high precision. We have not found any studies that have been able to estimate depth contours of such a high dimension and for such a large of amount of data, which documents the eﬃciency of the algorithm. The real-life data examples demonstrate that the procedure is useful to track and detect changes in complex distributional pat- terns. To estimate α-depth contours, the number of directional vec- tors, n u , and values of tuning parameters in the incremental quan- tile tracking algorithms must be chosen. We are currently work- ing on procedures that use information from the history of the data stream to recursively update such values. Tukey depth is best suited to account for convex features of the distribution of interest. However, there exist other modiﬁed depth measures that better ac- count for non-convex features [6] . In the future, we plan to extend the method in this paper in order to also be applied to these depth measures. [1,2,12,26] Declaration of Competing Interest The authors declare that they have no known competing ﬁnan- cial interests or personal relationships that could have appeared to inﬂuence the work reported in this paper. Supplementary material Supplementary material associated with this article can be found, in the online version, at doi: 10.1016/j.patcog.2021.108339 . References [1] N. Alkhamees , M. Fasli , Event detection from social network streams using fre- quent pattern mining with dynamic support values, in: Big Data (Big Data), 2016 IEEE International Conference on, IEEE, 2016, pp. 1670–1679 . [2] F. Atefeh , W. Khreich , A survey of techniques for event detection in twitter, Comput Intell 31 (1) (2015) 132–164 . [3] J.O. Cerdeira , T. Monteiro-Henriques , M.J. Martins , P.C. Silva , D. Alagador , A.M. Franco , M.L. Campagnolo , P. Arsénio , F.C. Aguiar , M. Cabeza , Revisit- ing niche fundamentals with tukey depth, Methods Ecol. Evol. 9 (12) (2018) 2349–2361 . [4] Y. Chang , Z. Tu , W. Xie , B. Luo , S. Zhang , H. Sui , J. Yuan , Video anomaly detec- tion with spatio-temporal dissociation, Pattern Recognit (2021) 108213 . 10 H.L. Hammer, A. Yazidi and H. Rue Pattern Recognition 122 (2022) 108339 [5] F. Chebana , T.B. Ouarda , Depth-based multivariate descriptive statistics with hydrological applications, Journal of Geophysical Research: Atmospheres 116 (D10) (2011) . [6] V. Chernozhukov , A. Galichon , M. Hallin , M. Henry , et al. , Monge–kantorovich depth, quantiles, ranks and signs, Ann Stat 45 (1) (2017) 223–256 . [7] D. Eddelbuettel , Seamless rand c++ integration with rcpp, Springer, New York, 2013 . ISBN 978-1-4614-6867-7 [8] D. Eddelbuettel , R. François , Rcpp: seamless r and c++ integration, J Stat Softw 40 (8) (2011) 1–18 . [9] S.M. Erfani , S. Rajasegarar , S. Karunasekera , C. Leckie , High-dimensional and large-scale anomaly detection using a linear one-class svm with deep learning, Pattern Recognit 58 (2016) 121–134 . [10] H.L. Hammer , A. Yazidi , H. Rue , A new quantile tracking algorithm using a gen- eralized exponentially weighted average of observations, Applied Intelligence 49 (4) (2019) 1406–1420 . [11] H.L. Hammer , A. Yazidi , H. Rue , Joint tracking of multiple quantiles through conditional quantiles, Inf Sci (Ny) 563 (2021) 40–58 . [12] M. Hasan , M.A. Orgun , R. Schwitter , A survey on real-time event detec- tion from the twitter data stream, Journal of Information Science (2017) . 0165551517698564 [13] S. Huang , Z. Kang , Z. Xu , Q. Liu , Robust deep k-means: an effective and simple method for data clustering, Pattern Recognit 117 (2021) 107996 . [14] M. Hubert , P. Rousseeuw , P. Segaert , Multivariate and functional classiﬁcation using depth and distance, Adv Data Anal Classif 11 (3) (2017) 445–466 . [15] M. Hubert , P.J. Rousseeuw , P. Segaert , Multivariate functional outlier detection, Statistical Methods & Applications 24 (2) (2015) 177–202 . [16] R.J. Hyndman , Y. Fan , Sample quantiles in statistical packages, Am Stat 50 (4) (1996) 361–365 . [17] B.K. Iwana , S. Uchida , Time series classiﬁcation using local distance-based fea- tures in multi-modal fusion networks, Pattern Recognit 97 (2020) 107024 . [18] R. Jörnsten , Clustering and classiﬁcation based on the l1 data depth, J Multivar Anal 90 (1) (2004) 67–89 . [19] S. Kim , B.M. Mun , S.J. Bae , Data depth based support vector machines for pre- dicting corporate bankruptcy, Applied Intelligence 48 (3) (2018) 791–804 . [20] L. Kong , I. Mizera , Quantile tomography: using quantiles with multivariate data, Stat Sin (2012) 1589–1610 . [21] D. Kosiorowski , Z. Zawadzki , Depthproc an r package for robust exploration of multidimensional economic phenomena, arXiv preprint arXiv:1408.4542 (2014) . [22] J.R. Kwapisz , G.M. Weiss , S.A. Moore , Activity recognition using cell phone ac- celerometers, ACM SigKDD Explorations Newsletter 12 (2) (2011) 74–82 . [23] X. Liu , K. Mosler , P. Mozharovskyi , Fast computation of tukey trimmed re- gions and median in dimension p > 2 , Journal of Computational and Graphical Statistics (2019) 1–31 . [24] C.A. Lowry , W.H. Woodall , C.W. Champ , S.E. Rigdon , A multivariate exponen- tially weighted moving average control chart, Technometrics 34 (1) (1992) 46–53 . [25] J. Ma , Y. Zhang , L. Zhang , Discriminative subspace matrix factorization for mul- tiview data clustering, Pattern Recognit 111 (2021) 107676 . [26] J.-C. Massé, Asymptotics for the tukey depth process, with an application to a multivariate trimmed mean, Bernoulli (2004) 397–419 . [27] K. Mosler , Depth Statistics, in: Robustness and complex data structures, Springer, 2013, pp. 17–34 . [28] R Core Team , R: A Language and Environment for Statistical Computing, R Foundation for Statistical Computing, 2021 . Vienna, Austria [29] N. Rastin , M.Z. Jahromi , M. Taheri , A generalized weighted distance k-nearest neighbor for multi-label problems, Pattern Recognit 114 (2021) 107526 . [30] E.B. Saff, A.B. Kuijlaars , Distributing many points on a sphere, The mathemati- cal intelligencer 19 (1) (1997) 5–11 . [31] M. Sokolova , G. Lapalme , A systematic analysis of performance measures for classiﬁcation tasks, Information Processing & Management 45 (4) (2009) 427–437 . [32] J.W. Tukey , Mathematics and the picturing of data, in: Proceedings of the in- ternational congress of mathematicians, 2, 1975, pp. 523–531 . [33] B. Williams , M. Toussaint , A.J. Storkey , Modelling motion primitives and their timing in biologically executed movements, in: Advances in neural information processing systems, 2008, pp. 1609–1616 . [34] A. Yazidi , H. Hammer , Multiplicative update methods for incremental quantile estimation, IEEE Trans Cybern 49 (3) (2017) 746–756 . [35] V. Zavrtanik , M. Kristan , D. Sko ˇcaj , Reconstruction by inpainting for visual anomaly detection, Pattern Recognit 112 (2021) 107706 . [36] Y. Zuo , R. Serﬂing , General notions of statistical depth function, Ann Stat (20 0 0) 461–482 . Hugo Lewi Hammer received the M.Sc. and Ph.D. degrees from the Norwegian University of Science and Technology, in 2003 and 2008, respectively. He is currently a professor with the Department of Computer Science, OsloMet Oslo Metropolitan University, Oslo, Norway and an adjunct re- search scientist at Simula Metropolitan Centre, Oslo, Nor- way. Before joining OsloMet and SimulaMet, he worked as a researcher with Norwegian Computer Center, Oslo, Norway. His research interests include computer intensive statistical methods, machine learning, learning automata and stochastic optimization. Anis Yazidi received the M.Sc. and Ph.D. degrees from the University of Agder, Grimstad, Norway, in 2008 and 2012, respectively. He is currently a professor with the De- partment of Computer Science OsloMet Oslo Metropoli- tan University, Oslo, Norway. Before joining OsloMet, he worked as a researcher with Teknova AS, Grimstad, Nor- way. His current research interests include machine learn- ing, learning automata, stochastic optimization, software- deﬁned networks and cloud computing. He led the re- search group Autonomous Systems and Networks at OsloMet from 2015 to 2018. He is currently the leader of the research group Applied Artiﬁcial Intelligence at OsloMet. Håvard Rue received the M.Sc. and Ph.D. degrees from the Norwegian Institute of Technology, in 1988 and 1993, respectively. He is currently a professor in statistics with the Computer, Electrical and Mathematical Science and Engineering Division, King Abdullah University of Sci- ence and Technology (KAUST), Saudi Arabia. Before join- ing KAUST, he worked as a professor in statistics at Nor- wegian University of Science and Technology. His re- search interests lie in computational Bayesian statistics and Bayesian methodology such as priors, sensitivity and robustness. His main body of research is built around the R-INLA project ( www.r-inla.org ), which aims to provide a practical tool for approximate Bayesian analysis of latent Gaussian models, often at extreme data scales. This project also includes effort s to use stochastic partial differential equations to represent Gaussian ﬁelds, for the use in spatial statistics. He is the leader of the research group Bayesian Computational Statistics and Modeling. 11"
Advanced Passive Operating System Fingerprinting Using Machine Learning and Deep Learning,"Hagos, Desta Haileselassie and Løland, Martin and Yazidi, Anis and Kure, Øivind and Engelstad, Paal E.",2020,,,,inproceedings,"Advanced Passive Operating System Fingerprinting
Using Machine Learning and Deep Learning
Desta Haileselassie Hagos∗, Martin Løland†, Anis Yazidi‡, Øivind Kure §, Paal E. Engelstad ¶
∗§¶University of Oslo, Department of Technology Systems, Kjeller, Norway
∗†‡¶Oslo Metropolitan University, Department of Computer Science, Oslo, Norway
Email: ∗destahh@iﬁ.uio.no, †martin.loeland@gmail.com, {‡anis.yazidi, ¶paal.engelstad}@oslomet.no, §oivind.kure@its.uio.no
Abstract—Securing and managing large, complex enterprise
network infrastructure requires capturing and analyzing network
trafﬁc traces in real-time. An accurate passive Operating System
(OS) ﬁngerprinting plays a critical role in effective network
management and cybersecurity protection. Passive ﬁngerprinting
doesn’t send probes that introduce extra load to the network and
hence it has a clear advantage over active ﬁngerprinting since
it also reduces the risk of triggering false alarms. This paper
proposes and evaluates an advanced classiﬁcation approach to
passive OS ﬁngerprinting by leveraging state-of-the-art classical
machine learning and deep learning techniques. Our controlled
experiments on benchmark data, emulated and realistic trafﬁc
is performed using two approaches. Through an Oracle-based
machine learning approach, we found that the underlying TCP
variant is an important feature for predicting the remote OS.
Based on this observation, we develop a sophisticated tool for
OS ﬁngerprinting that ﬁrst predicts the TCP ﬂavor using passive
trafﬁc traces and then uses this prediction as an input feature
for another machine learning algorithm for predicting the remote
OS from passive measurements. This paper takes the passive
ﬁngerprinting problem one step further by introducing the
underlying predicted TCP variant as a distinguishing feature. In
terms of accuracy, we empirically demonstrate that accurately
predicting the TCP variant has the potential to boost the
evaluation performance from 84% to 94% on average across
all our validation scenarios and across different types of trafﬁc
sources. We also demonstrate a practical example of this potential,
by increasing the performance to 91.3% on average using a tool
for TCP variant prediction in an emulated setting. To the best of
our knowledge, this is the ﬁrst study that explores the potential
for using the knowledge of the TCP variant to signiﬁcantly boost
the accuracy of passive OS ﬁngerprinting.
Keywords—Operating
System,
Fingerprinting,
Machine
Learning, Deep Learning, Passive Measurements
I.
INTRODUCTION AND MOTIVATION
As modern network infrastructures grow in size, collecting
detailed relevant knowledge about the dynamic characteristics
and complexity of large heterogeneous networks is crucial
for many purposes e.g., network vulnerability assessment
and monitoring, spam detection, etc. Developing advanced
network security and monitoring techniques are important
for both the research and security practitioners. There has
been a signiﬁcant research work in the context of network
management and cybersecurity on developing network security
tools to ﬁngerprint remote Operating Systems (OSes) [26,
27, 28, 41, 42]. OS ﬁngerprinting is the process of inferring
the OS of a machine operating with TC/IP by a remote
device connected on the Internet without having physical
access to the device [20]. There are many different custom
tools for ﬁngerprinting of the most commonly used OSes
based on the characteristics of its underlying TCP/IP network
stack [20] and this, to a large extent, is due to variability
in how the TCP/IP stack is traditionally implemented across
different OSes [25]. One common approach, for example, is
by collecting the TCP/IP stack basic parameters [23], e.g., IP
initial Time To Live (TTL) default values [5], HTTP packets
using the User-agent ﬁeld [22], Internet Control Message
Protocol (ICMP) requests [29], known open port patterns, TCP
window size [18], TCP Maximum Segment Size (MSS) [31],
IP Don’t Fragment (DF) ﬂag [30], a set of other speciﬁc TCP
options to mention a few. However, in our work, we want to
take this one step further by combining these basic features and
other settings with the underlying TCP variant as a feature in
our model due to the fact that different OSes are doing slightly
different implementations of TCP. Some implementations of
common TCP variants quickly overshoot the size of the
Congestion Window (cwnd) because of differences in the
variant implementations. Hence, we believe that knowing the
implementation of the underlying OS may help us understand
better their exact behavior. It can also help us explore how
to classify an OS when different OSes are implementing the
same TCP variant.
Fingerprinting Techniques: We can determine what OS a
remote computer on the Internet is running by either passively
listening to trafﬁc captured from a network or by actively
sending it packets. The most widely used complementary
remote OS ﬁngerprinting proven approaches that employ a
variety of TCP/IP stack scanning are broadly categorized into
classes of active and passive methods.
• Active Fingerprinting: This technique is based on actively
transmitting one or more specially crafted network
packets with different packet settings or ﬂags to a remote
network device in order to analyze the corresponding
potentially identifying replies [26, 41]. This method
determines knowledge of the underlying OS according
to the received responses from the target device by
examining the network behavior of known TCP/IP
stack [35]. However, since this approach injects additional
trafﬁc to the network by generating active probes, it may
itself trigger alarms and get blocked by ﬁrewall rules and
Network address translators (NATs) [8].
• Passive Fingerprinting: This approach, on the other hand,
inspects and analyzes packets traveling between end hosts
without injecting any trafﬁc into the network [27, 28, 42].
This technique with little resource simply analyzes a
pattern of the OS-speciﬁc information that has already
been sent in the network trafﬁc and compares for a
match with a predeﬁned database that contains a list of
known signatures of different OSes. Passive ﬁngerprinting
doesn’t send probes and hence it has a clear advantage
over active ﬁngerprinting since it reduces the risk of
triggering alarms [8].
978-1-7281-6607-0/20/$31.00 ©2020 IEEE
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 OS ﬁngerprinting can also be performed using classical
techniques known as “banner grabbing”. It is an approach used
to gain detailed information about a remote computer system
on a network and the associated services running on its opened
ports [33]. Using techniques like this, some remote computers
announce their underlying OS freely and running application
services with their versions in use to anyone connecting to
them as part of welcome banners or header information.
Some of the widely used services that serve banner grabbing
are: Telnet, FTP, NetCat, SMTP, etc. However, it is useful
to remember that some of these basic services are effective
against less secure networks.
Potential beneﬁts and applications: Network scanning and
accurate remote OS ﬁngerprinting are the crucial steps for
penetration testing in terms of security and privacy protection.
Note that attackers can also embrace passive ﬁngerprinting
techniques to search for potential victims in a network. For
example, by identifying the OS running on a remote computer
and the list of services it runs, an attacker can target the device
to eavesdrop on the communication between the endpoints
without having physical access to the device. However, we
argue that our work presented here is motivated by a number
of practical applications that can be positively used by network
and system administrators. Passively ﬁngerprinting an OS by
analyzing the packets it generates and transmits over a network
is extremely important in the areas of network management
and computer security for several reasons. For example, it
is useful to explore a network for potential exploitations of
security vulnerabilities which can be exploited by attackers,
auditing, identify critical attacks, reveal new information about
a network user etc. Network administrators can, therefore, use
this OS related information to maintain the security policy and
reliability of their network by conﬁguring a network-based
Intrusion Detection Systems (IDS) [24]. Vulnerabilities and
security threats in a network may result from rogue or
unauthorized devices [38], unsecured internal nodes within
the network, and from external nodes [4]. Hence, passively
ﬁngerprinting an OS has a potential beneﬁt in addressing these
critical problems. This, from an academic point of view, is
Client Oses of sending nodes
Fingerprinter
Receiving nodes 
on the Internet
35.195.9.67
Intermediate node (monitor)
Fig. 1: Network architecture for passive OS ﬁngerprinting by
an intermediate node.
Limitations
of
previous
works: Traditionally, most of
the existing general OS ﬁngerprinting techniques resort to
manually generated signature matching from a database of
heuristics which contains features of widely used OSes. This
means, after comparing the generated signatures, the ﬁrst set
of responses match with the highest conﬁdence against a
database of ﬁngerprints would be used to select the speciﬁc
probable OS. However, manually updating a large number
of signature and managing databases of new OSes adds a
considerable amount of time and hence we may suffer from
the consequences of the lack of recent signature updates of the
known OSes. For example as reported in [22], the last updates
of the ﬁngerprint databases of Ettercap [28] and p0f [42]
date to 2011 and 2014 respectively. Consequently, new OSes
families like Android 4.4 and higher versions of Android,
Windows 10 distributions, etc. will not be recognized by these
tools since they are not included in their ﬁngerprint databases.
Hence, we argue that it is important to consider making use of
a ﬁngerprint database that contains variations of most currently
used OSes and automating these tasks by employing learning
algorithms capable of extracting all possible OS-speciﬁc
features for discovering the underlying OSes. To explore this
idea of applying learning algorithms, we present a uniﬁed
and robust classiﬁcation approach to an advanced passive OS
ﬁngerprinting that leverages both machine learning and deep
learning methods. Our ﬁngerprinting technique is completely
passive meaning that we only need to be able to observe
network trafﬁc from a target machine at any observation point
on the network without injecting any trafﬁc into the network.
Note that the TCP/IP header ﬁelds would not be impacted
by SSL/TLS encryption of the TCP payload. Hence, since
we utilize features that are readable even with encryption,
our approach is independent of whether the ﬂow is encrypted
or not. Figure 1 shows the architecture for implementing our
ﬁngerprinting methodology.
Why machine learning approaches to OS ﬁngerprinting?
There
are
several
limitations
imposed
by
classical
ﬁngerprinting techniques. Passive OS ﬁngerprinting generally
relies on recognizing the default values for various TCP/IP
stack parameters. If a user changes these parameters, the task
of OS ﬁngerprinting becomes much more challenging. Most of
the existing works on ﬁngerprinting provide a little capability
to address this challenge. Motivated by this problem, we
proposed a novel approach by leveraging both machine
learning and deep learning-based techniques that consider the
set of parameters as a whole, rather than individually so that
our model caters for variations in TCP parameters. If a user
changes the initial receive window size, for instance, we may
still be able to recognize the OS from other parameters that
have not been changed (TCP congestion control algorithm,
initial cwnd size, etc.). Note that this depends entirely on
the changes made by the user to the default TCP or OS
stack parameters that are commonly used for signature-based
ﬁngerprinting. The other reason why we create a model by
employing learning techniques is to understand the complex
patterns of the varying values in the TCP header and extract
useful input features. Because machine learning offers new
possibilities as it can extract patterns and general rules for
classiﬁcation. Machine learning can also be more robust to
small variations in the input parameters. In addition to this,
with the use of learning techniques, we argue that avoiding
using manually updated static signature databases has two
potential beneﬁts. Firstly there is no tedious task of creating
these unique ﬁngerprints, all you need is a set of values or
features. The second beneﬁt comes from a known ﬂaw in
many of the existing ﬁngerprinting tools, where a “ﬁrst-match”
policy is applied, meaning that if two ﬁngerprints are equal
the tool would always predict the ﬁrst OS with that exact
ﬁngerprint. However, learning techniques, on the other hand,
make calculated guesses of which of the classes with the
same ﬁngerprint that will be predicted.
interesting and something that needs to be addressed from a
network security research point of view.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 Contributions: We summarize our main contributions below.
• We propose and evaluate a robust approach to OS
ﬁngerprinting from passive measurements by leveraging
machine learning and deep learning techniques.
• We investigate the use of TCP congestion control variant
as a distinguishing feature in passive OS ﬁngerprinting.
• We explore variability in implementations of TCP variant
by different OSes and its effect on classifying remote OS.
• We study the applicability of Recurrent Neural Networks
(RNN)-based models for robust and advanced passive OS
ﬁngerprinting by combining the basic TCP/IP features and
the predicted TCP variant as input vectors.
• We show that the TCP ﬂavor has a great potential for
boosting passive OS ﬁngerprinting.
• We build a universal tool for passive monitoring that can
be applied to ﬁrst estimate the TCP cwnd, second predict
the TCP ﬂavor, and ﬁnally uses the TCP variant as an
input feature to detect the remote computer’s OS.
Roadmap: The rest of the paper is organized as follows.
Section II discusses related work, and Section III presents
the experimental datasets. Section IV presents the machine
learning of the OS ﬁngerprinter. The machine learning of
the TCP variant prediction tool is presented in detail in
Section V. Section VI presents the experimental results without
a known TCP variant which will play the role of baseline. In
order to assess the importance of knowing the TCP variant,
experimental results of all the use cases with an Oracle-given
TCP variant are presented in Section VII. Section VIII presents
the experimental results with the predicted TCP variant.
Section IX presents the transfer learning results. Finally,
Section X concludes our paper and suggests directions for
future research work.
II.
RELATED WORK
Remote OSes ﬁngerprinting has a long history in the
computer security community [2, 22, 23, 26]. TCP/IP header
ﬁngerprinting and any information related to application
protocols are used to identify the underlying OS running
on a remote host either actively or passively [25]. As we
explained in Section I, there are multiple existing tools for
both the predominant active and passive OS ﬁngerprinting
approaches, where Nmap [26] is one of the most prominent
open-source active ﬁngerprinting tools. The work presented
in [36], SYNSCAN, works in a similar fashion to Nmap,
but it performs the ﬁngerprinting task by actively sending a
small number of crafted network packets to a single TCP
port. Xprobe2 [41] is another popular ﬁngerprinting tool,
that relies primarily on ICMP packets, and it depends on
how many changes we make to the default TCP/IP stack
parameters.
Since Xprobe2 does fuzzy ﬁngerprinting with
a signature matching algorithm as an alternative to Nmap,
it means that if we make a lot of changes to the default
TCP/IP stack parameters, the underlying OS will not be
detected. However, Xprobe2 is more robust to small ﬁngerprint
variations as compared to Nmap. As explained above the
other ﬁngerprinting tools, Ettercap [28] and p0f [42], have
not been updated since 2011 and 2014 respectively to include
variations of most widely used modern OSes. For passive OS
ﬁngerprinting to be effective, we believe that the limitations
of these ﬁngerprinting tools need to be addressed. The work
in [23] also demonstrates that the OS ﬁngerprinting accuracy of
the Ettercap and p0f signature databases is low and techniques
to improve performance was proposed. Hence, the paper
presents rule-based machine learning classiﬁers capable of
identifying 75 classes of OSes from TCP/IP packet headers
found in the Ettercap database. They proposed a classiﬁer
technique using k-nearest neighbors (KNN) that returns an
approximate ﬁrst match for an OS from a ﬁngerprint database.
This counters the problem of classifying hosts as unknown if
no exact match is found in the database [23]. However, their
evaluation yielded poor experimental results, rejecting as much
as 84% of the test packets, while 44% of the accepted patterns
were wrongly classiﬁed [23]. The problems contributing to
poor performance was believed to be caused by two main
issues. The ﬁrst reason is substitution errors due to multiple
OSes with exactly the same ﬁngerprint feature values. The
second reason for this poor performance is the high rejection
rate caused by numerous unique feature values derived from
the same OS. After combining the OS classes most often
confused with each other, eliminating all the classes where
the error could not be reduced by combining classes, the error
percentage was reduced to 9.8% with no rejected packets.
A recent study that is most closely related to our work,
and which has also given a comprehensive survey on passive
ﬁngerprinting methods, can be found in [22]. The authors
have employed OS ﬁngerprinting methods in the environment
of wireless networks.
Besides using the three basic TCP/IP
stacks (i.e., TTL, window size, and initial SYN packet size),
the authors suggested also using the user-agent information in
HTTP request headers and communication with OS-speciﬁc
domains can be usable in large dynamic networks [22].
The average accuracy of OS classiﬁcation using the TCP/IP
parameters reported in [22] is 80.88%. Zhang et al.’s paper on
OS detection [43] utilizes only one machine learning technique
namely Support Vector Machine (SVM). However, the testing
error rate of identifying some of the OSes e.g., Mac, Cisco,
FreeBSD, and OpenBSD is 25.80%, 24.22%, 17.71%, and
15.85% respectively [43]. Aksoy et al. [2] have employed
genetic algorithms for identifying packet features suitable
for OS classiﬁcation based on the analysis of the network
TCP/IP packets using machine learning algorithms. However,
most of these previous works use the basic actual TCP/IP
features for evaluating passive OS ﬁngerprinting. Besides,
we believe that these tools have the inability to extract all
possible OS-speciﬁc features for passively ﬁngerprinting the
underlying OSes. In contrast, what separates our contribution
in this paper from the other previous related works is that
our model supports a wider range of TCP/IP network stack
features. As shown in Figure 2, the main goal of our work
presented here is to combine these basic TCP/IP features that
are the basis of OS ﬁngerprinting with the underlying TCP
variant by leveraging both machine learning and deep learning
techniques. This contribution remains largely unexplored and
is not used by existing ﬁngerprinting techniques. Detecting the
implementation of a TCP variant passively is a challenging task
and this, we believe, is the reason why no previous works use
it to passively ﬁngerprint remote OSes. However, in our case,
we already have a general solution for this difﬁculty presented
in our previous works [11, 12, 13]. The reason why we focus
on the implementations of the underlying TCP variant as a
feature in our OS classiﬁer model is due to the fact that
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 different OSes are doing slightly different implementations
of TCP. Hence, we believe that passively observing the
network-level characteristics found in TCP packets can give us
more information about the remote computer’s underlying OS.
We further believe that this will also help us to explore in detail
the long-term characteristics of TCP trafﬁc. To the best of
our knowledge, this is the ﬁrst study of passive ﬁngerprinting
OSes by applying RNN methods combining the basic TCP/IP
features and the underlying TCP variant as input vectors.
III.
EXPERIMENTAL DATASETS
Our machine learning models for OS classiﬁcation is
developed and tested on three datasets, presented below.
A. Benchmark Data
First, we utilize a large benchmark dataset that has been
used for OS ﬁngerprinting in a previous related work [22]. This
dataset is closely aligned with our task. The benchmark dataset
was used in the previous work for OS ﬁngerprinting based on
the HTTP header, while the ambition of our paper is to do
generic ﬁngerprinting based only on the TCP packet ﬁelds.
Since we aim at ﬁngerprinting that is not application-speciﬁc,
the TCP information in the dataset is useful for our purpose,
while the HTTP User-agent information in our experiments
is used only to establish ground truth about the OS that
was used. The benchmark dataset contains 79087345 ﬂows,
activity of 21746 unique users, 253374 WiFi sessions, 25642
unique MAC addresses, and 6104 unique IP addresses, a
ﬁngerprint database of 2078 standard TCP/IP signatures of
51 known unique OSes with a total of 529 variations when
considering major and minor versions [22]. It consists of three
basic TCP/IP network stack features, i.e., initial SYN packet
size, TTL, and TCP window size [22]. After our ﬁrst set of
testing, we realized that the data was severely skewed and
that only a few of the classes contained almost all of the
entries, giving us artiﬁcially good classiﬁcation results. We
then removed most of the very seldom occurring classes and
ended up with 33 reduced classes. We also removed all trafﬁc
that did not contain HTTP User-agent information, since we
could not establish ground truth for this trafﬁc. In addition, we
created a new dataset where all the classes were bucketed into
seven groups, consisting of the six most widely used major OS
families: Android, Linux, Mac OS, Unix, Windows, iOS, and
a seventh class called “Other” for OSes not suited for any of
the other groups. Finally, we ended up distributing all of the
labels equally so that each OS class had the same number of
occurrences. This helps us improve the generalizability of our
model with a uniﬁed approach that encompasses all variations
of the most widely used OSes.
B. Realistic Trafﬁc
While benchmark trafﬁc is useful to link our experiments
to previous related work, we also wanted additional realistic
trafﬁc for which we have more control, and that allows us
to make our own assurances of the quality of the data. Thus,
we passively collected our realistic dataset from TCP trafﬁc
originated from the internal network of the Oslo Metropolitan
University and destined to various hosts on the Internet. First,
we collected data for ﬁxed (non-mobile) desktop computers
(typically using OSes like Windows, Linux, Unix, Mac OSx,
etc.) by using an intermediate node as shown in the network
setup in Figure 1. Then, we passively collected the data that
covered mobile devices, like android and iOS. The latter was
collected from the 5G 4IoT research lab [1, 34] of the Oslo
Metropolitan University.
We spent a signiﬁcant amount of effort in establishing
ground truth, i.e., determining the actual OS that has been
used for each trafﬁc ﬂow. To establish ground truth in the
realistic dataset, we follow two approaches. The ﬁrst approach
was only applicable to the non-mobile desktops, while the
second method was used for both mobile and non-mobile
devices. With the ﬁrst method, we leveraged the DHCP log
messages associated with the non-mobile desktops to derive the
ground truth from the DHCP server of the Oslo Metropolitan
University network that logs the sessions by the MAC address
and name of the device. Since we collect the real data from
the internal network of our university, extracting the DHCP log
messages can give us detailed information about the OSes. We
could, for example, see information about the vendor-speciﬁc
preﬁxes since most of the OS variants are identiﬁed based on
their vendors. The list of device vendor preﬁxes is useful in
revealing the speciﬁc implementation of an OS because most
of the modern OSes from the same device vendor usually
share the same OS kernel and similar network behaviors. For
example, we found out that Apple products often share the
same TCP/IP parameters. The second approach we used to
identify the OS is getting the predeﬁned browser strings that
loosely tell the name of the underlying OS assigned by the
vendor from Webserver.
We believe changing the default device names by all users
is not that common and sometimes discouraged by the vendors,
e.g., Google and Apple OSes. However, the device name
of Linux and Windows OSes could be changed easily by
experienced users which would make passively identifying
these devices hard. Since a number of computer vendors offer
devices with a pre-installed OS and default device name and
MAC address, we can use this information to derive the ground
truth for OS ﬁngerprinting. For example, Apple devices use
a default string name of
“<user>-iPhone”, “<user>-iPad”,
Microsoft uses “Windows-Phone” for its mobile devices, and
Android uses “android-<android−id>”, etc. Our real trafﬁc
covers the communication to and from our university and
hence all trafﬁc whose source and destination IP addresses are
within the subnets of our internal network. Hence the network
administrator of our university has full control over the internal
machines with real IP addresses that are not going to a NAT
gateway, and therefore it is fairly possible to tell whether it is a
laptop or a desktop PC by looking it up in the internal database
owned by the university. However, since it is a dynamic
network we do not have full control over external machines,
because they can be anything behind an IP address that changes
dynamically. This is because there is an endless number of
machines spooﬁng scanning the network and they can appear
as Linux-powered OSes but they could be Windows and vice
versa and this happens because the user may have strongly
tuned the TCP stack to look like something else. It is pretty
hard to certainly say anything about the external computers
because the communication can go through a NAT gateway
possessing another OS type. For example, if a user is connected
to a student wireless network, there is a chance that it may go
to a Linux NAT gateway, and hence from outside the user is
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 seen as Linux NAT which makes it hard to predict whether
the underlying OS is Linux, Mac or Windows. Therefore,
ﬁngerprinting devices behind NAT technology on a distributed
network where a number of devices can hide behind a NAT
is another critical challenge. It is, therefore, worth noting that
establishing ground truth in dynamic networks at a larger scale
remains a challenging problem. Further investigation to explore
these difﬁculties will be done in our future works. Finally,
due to the privacy protection of possibly sensitive data, the
payload of all the network packets collected was removed
and anonymized with a preﬁx-preserving algorithm [7, 39].
Furthermore, we were only allowed to collect TCP headers of
the trafﬁc ﬂows, while we could not collect complete trafﬁc
captures, due to privacy protection and legal reasons.
OS Prediction
Fingerprinter using
Machine Learning/
Deep Learning 
Input features
Packet Size
Window Size
TTL
TCP Variant
Oracle
Predicted TCP Variant
1. Baseline 
Experiment
2. Oracle-based 
Experiment
3. Prediction-based 
Experiment
Fig. 2: The process implemented on the intermediate node for
passive OS ﬁngerprinting.
Bytes in 
Flight
Predicted 
TCP Variant
Predicted cwnd
Intercepted Traffic
Deep Learning/LSTM 
Fig. 3: The process implemented on the monitor for prediction
of the TCP variant of the passively intercepted TCP trafﬁc ﬂow.
An LSTM-based machine learning module predicts the cwnd
from the outstanding bytes-in-ﬂight. In the next step, the cwnd
behavior is used to predict the TCP variant as explained in
further detail in our previous works [11, 12, 13]. The predicted
TCP variant is ﬁnally used as an input feature to the OS
ﬁngerprinting process (see bottom right part of Figure 2).
C. Emulated Trafﬁc
In a real scenario where the OS ﬁngerprinting is going
on continuously in an intermediate node of an enterprise or
production network, the intermediate node will have more
information available than only the TCP header, such as
the trafﬁc proﬁle or the knowledge of congestion or the
outstanding bytes-in-ﬂight of a ﬂow. In our experiments below,
we show how this information can be very useful for OS
ﬁngerprinting. Since we do not have full trafﬁc packet captures
in our benchmark dataset or in our realistic dataset, we needed
an additional dataset that we collected from an emulated
network, where there would be no privacy protection or legal
issues related to our dataset. The architecture of our emulated
network is similar to the network setup shown in Figure 1,
except that all the nodes (the sender, the intermediate node,
and the receiver) are implemented in virtual machines. All
background trafﬁc of the OSes for our emulated scenario is
generated using the iperf [6]. Establishing ground truth is
straightforward, as we have full control of the OSes used
when generating the trafﬁc. In addition to establishing the
ground truth, we also wanted to allow the intermediate node
to establish a prediction of the TCP variant by monitoring the
on-going trafﬁc proﬁle of the TCP ﬂow between the sender and
the receiver. As shown later in the paper, using deﬁnitive or
predicted knowledge of the TCP variant as an additional input
feature to the OS ﬁngerprinting, might boost the ﬁngerprinting
accuracy signiﬁcantly. How the machine learning model for
prediction of the TCP variant in the emulated scenario is
trained and how the TCP variant is subsequently predicted are
presented in the following.
IV.
MACHINE LEARNING OF THE OS FINGERPRINTER
A. Classical Machine Learning Approaches
The OS ﬁngerprinter takes various features as input
parameters, and use machine learning to predict the OS as
shown in Figure 2. Many machine learning techniques could
be used to implement a model for passive OS ﬁngerprinting. In
this paper, we have employed the following most commonly
used classical machine learning methods suitable for our
task. In order to train and test our classiﬁcation models, we
employed every experiment with a ratio of 60% training,
40% testing split, and 5-fold cross-validation setting on all
variations of the features into one learning model.
SVM: In order to perform an efﬁcient multi-class SVM
classiﬁcation through cross-validation, we tuned the SVM
hyperparameters using a GridSearchCV that allows specifying
only
the
ranges
of
values
for
optimal
parameters
by
parallelization construction of the model ﬁtting. Finally, in
our evaluation, we found out that SVM with a Radial Basis
Function (RBF) kernel for classiﬁcation model yields a
substantially better result.
Random Forest (RF): We tuned the meta-estimator by varying
the number of decision trees between 1 and 1000. We found
out that increasing the number of trees more than 10 doesn’t
give much improvement in the classiﬁcation accuracy.
KNN: We applied KNN by testing different values of K
ranging from 5 to 100 followed by a weight function for a
total of 20 observations. The observations have been conducted
in two ways. In the ﬁrst experiment, we set the weight to
uniform. In the second experiment, the points are weighted by
the inverse of their distance, causing closer neighbors to have
greater inﬂuence. Finally, we choose the model that has the
highest accuracy for a given unseen instance.
B. Deep Learning Approaches
To
ﬁnd
the
deeper
characteristics
of
TCP
variants
implemented by respective OSes and exploit the extra
OS-speciﬁc information, we apply the following two neural
network architectures.
Multilayer Perceptron (MLP): In our evaluation, MLP model
with a single-layer feedforward neural network [16, 32] has
been used to classify the different classes of OSes. After
the hyperparameter tuning, we tested our MLP model with
a different number of batch sizes, hidden layers, and nodes
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 (e.g., 0, 1, 2, 32, 64, 128) in each layer. Combining all of
these, a total of 324 models were trained with and without
the default TCP variant. We found out that the results for
both with and without a known TCP variant were almost the
same with an insigniﬁcant drop in the accuracy irrespective of
which hyperparameters performed the best. Finally, 128 nodes
of the network per dataset are trained for 150 epochs with
a batch size of 500 by SGD with momentum of 0.9 and a
constant learning rate of 0.01. However, we learned that SGD
is sensitive in regards to the selection of the learning rate
since it doesn’t automatize the values and we also found that
it suffers from premature convergence and is outperformed
by Adam-based optimization methods. Hence, both Adam
and Nadam gradient-based optimization algorithms ﬁt for our
purpose and that is because we wanted to use an optimization
algorithm that adapts its learning rate dynamically in a way that
doesn’t affect the objective function and learning process of the
model. Our experimental results show that the hyperparameter
tuning baseline experiments by applying tanh as activation
function and Adam optimization algorithm and training the
model for 150 epochs, provides a substantial improvement in
accuracy as compared to the other parameters.
Long Short-Term Memory (LSTM) models: We have
explored an approach to classify the underlying OS from
passive measurements using LSTM-based RNN architecture by
combining the basic TCP/IP features and the underlying TCP
variant shown in Table 2 as input vectors. For more details
about LSTM applied in the context of computer networks, we
refer the reader to our previous paper [12]. We trained our
LSTM model over 150 epochs of the training samples with
a batch size of 32
as values in time-series. We propagate
the input feature vector (x) to the model through a multilayer
LSTM cell followed by a fully connected dense layer of 150
hidden nodes with Rectiﬁed Linear Unit (ReLU) activation
function using the hard sigmoid as recurrent activation for
the different layers that generates an output of a sequence
dimensional vector of predicted OSes (yt). We trained our
LSTM-based learning algorithm without the knowledge of the
input features from the true signatures of the OSes during the
learning phase. We learn the model from the training data and
then ﬁnally predict the test labels from the testing instances on
all variations of the OS-speciﬁc parameters. In order to train
our prediction model more quickly, and get a more stable and
robust to changes OS classiﬁcation model, we have applied
one of the most effective optimization algorithms in the deep
learning community, the Adam stochastic algorithm [19] with
an initial learning rate of 0.001 and exponential decay rates
of the ﬁrst (β1) and second (β2) moments set to 0.9 and 0.999
respectively. We further optimize a wide range of important
hyperparameters related to the neural network topology to
improve the performance of our OS classiﬁcation model.
C. Experimental Hardware Setup
All
our
machine
learning
experiments
are
carried
out using a cluster of HPC machines based upon the
GNU/Linux operating system running a modiﬁed version of
the 4.15.0-39-generic kernel release. The prediction model
is performed on an NVIDIA Tesla K80 GPU accelerator
computing with the following characteristics: Intel(R) Xeon(R)
CPU E5-2670 v3 @2.30GHz, 64 CPU processors, 128 GB
RAM, 12 CPU cores running under Linux 64-bit. All nodes in
the cluster are connected to a low latency 56 Gbit/s Inﬁniband,
gigabit Ethernet, and have access to 600 TiB of BeeGFS
parallel ﬁle system storage.
D. Objectives of our Experiments
The aim of our experiments is to explore the effect of the
TCP variant as an input feature when passively detecting the
underlying OS. To investigate this, we divide our analysis into
three different experiments. First, in the baseline experiment
(Section VI) we carry out the OS ﬁngerprinting without using
a known TCP variant as an input feature. This corresponds
to the simplest state-of-the-art transport layer method, which
is illustrated in the upper part of Figure 2. Since there is a
close connection between existing popular OSes and the TCP
variants they use, our hypothesis was that the potential for
improvement by using the TCP variant as an input feature
would be signiﬁcant. For example, CUBIC [9] is the default
congestion control algorithm as part of the Linux kernel
distribution conﬁgurations from version 2.6.19 onwards. Since
Android devices are also Linux-powered, CUBIC remains
to be the default TCP congestion control algorithm. Many
Windows 7 distributions have been shipped with the default
New Reno [15] and whereas Windows 8 families with
CTCP [37]. Therefore, in the next Oracle-based experiment
(Section VII), we investigate the potential of knowing the
TCP variant, and how much this knowledge might boost the
ﬁngerprinting accuracy. Here we assume that there is an Oracle
that can identify and give the TCP variant used in the TCP
ﬂow that is ﬁngerprinted. This is illustrated in the bottom left
part of Figure 2. However, in a real scenario, the intermediate
node would not have access to deﬁnite knowledge of the TCP
variant (e.g., given by an Oracle). Instead, the intermediate
node might at best try to infer it from the monitored trafﬁc.
Thus, in the third prediction-based experiment (Section VIII),
we ﬁrst allow the intermediate node to predict the TCP variant
passively. This is illustrated in the bottom right part of Figure
2. The OS ﬁngerprinter then uses that TCP variant prediction
as an input feature to make the OS prediction illustrated in
the upper part of Figure 2. The TCP variant is predicted by
analyzing the famous sawtooth pattern behavior of estimated
cwnd of TCP, which is computed based on the outstanding
bytes-in-ﬂight [12, 13]. This is presented in more detail in the
next section. Since the latter experiment requires TCP trafﬁc
details of outstanding bytes-in-ﬂight, which is not available in
our benchmark and realistic datasets, this experiment is only
possible with our emulated dataset.
V.
MACHINE LEARNING OF THE TCP VARIANT
PREDICTION TOOL
The main goal of the experiments in the emulated network
is to use the predicted TCP variant as an additional input
feature to the OS ﬁngerprinting. The TCP variant is predicted
by the process illustrated in Figure 3. As described in sufﬁcient
detail in our previous works [11, 12, 13], we used a database
to match and join the intercepted TCP trafﬁc on both the
intermediate node and the sending node. The outstanding
bytes-in-ﬂight of the trafﬁc (i.e., the number of bytes that have
been sent but not yet acknowledged) is used as input to our
machine learning model to predict the cwnd behaviour of the
trafﬁc. We use LSTM for the machine learning. We trained
and veriﬁed the machine learning model by matching the
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 predicted TCP states with the actual TCP kernel states directly
logged from the Linux kernel. Since we have full control of
the sending nodes, we can track the system-wide TCP state
of every packet that is sent and received from the kernel to
verify our model’s prediction accuracy against the actual TCP
variant by matching with the actual sending TCP states using
the techniques presented in our previous works [11, 12, 13].
After the veriﬁcation, we can run our learning model and get
the cwnd predictions of the TCP stack in use.
Once we can estimate the cwnd of the sender, we can
also infer the multiplicative back-off factor (β) which is an
important feature for uniquely identifying the TCP variants.
Finally, we combine the predicted TCP variant as the basis of
OS ﬁngerprinting with the basic TCP/IP features as shown in
Figure 2. Here, we consider only loss-based TCP congestion
control algorithms, e.g., BIC [40], CUBIC [9], CTCP [37],
Reno [17], and New Reno [15]. Delay-based TCP variants are
investigated in a follow-on paper [14]. Our approach could
also be useful to other TCP variants like Google’s QUIC [21].
QUIC uses packet loss as an indicator of congestion and
supports a number of different congestion control algorithms,
including CUBIC [9] and BBR [3].
VI.
BASELINE EXPERIMENT: RESULTS WITHOUT
KNOWING THE TCP VARIANT
Here we present the results of the machine learning and
deep learning techniques under all the validation scenarios
presented above without a known underlying TCP variant
which will play the role of baseline for the other evaluations.
A. Based on Benchmark Data from Previous Related Work
Looking at Tables I and
II,
both machine learning
and deep learning classiﬁcation techniques have consistently
achieved good levels of precision and recall for all general
classes of OSes except iOS. Quantitatively, iOS, and Mac
OS devices were underrepresented in the benchmark data
from previous related work. Besides, as it is shown in
Figures 4, there is a slightly higher misclassiﬁcation of iOS
as unknown and this is why the precision and recall of iOS
are comparably lower than the rest of OSes. We also believe
that the limited TCP/IP stack basic features could contribute
to the indistinguishability and misclassiﬁcation of OS classes
with the same kernel implementation. The false positives are
easier to notice in the corresponding confusion matrices.
TABLE I: Benchmark data [22] experimental results without
a known TCP variant using SVM, RF, and KNN.
SVM
RF
KNN
OS
Precission
Recall
Precision
Recall
Precision
Recall
Android
0.74
0.88
0.87
0.91
0.87
0.91
Linux
0.85
0.85
0.91
0.90
0.91
0.90
Mac OS
0.65
0.77
0.61
0.83
0.58
0.88
Other
0.91
0.81
0.92
0.81
0.92
0.81
Unix
0.91
0.99
0.94
0.99
0.94
0.99
Windows
0.97
0.88
0.98
0.91
0.98
0.91
iOS
0.73
0.55
0.72
0.53
0.79
0.47
Average
0.83
0.82
0.85
0.84
0.86
0.84
Accuracy
81.96%
84.07%
83.95%
B. Based on Realistic Trafﬁc
Our performance results of the realistic trafﬁc without
a known TCP variant using the machine learning and deep
techniques are presented in Tables III and
IV respectively.
The respective confusion matrices are presented in Figures 5.
TABLE II: Benchmark data [22] experimental results without
a known TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.75
0.92
0.77
0.85
Linux
0.90
0.82
0.83
0.85
Mac OS
0.62
0.81
0.58
0.83
Other
1.00
0.74
0.91
0.81
Unix
0.94
0.99
0.94
0.99
Windows
0.97
0.91
0.97
0.86
iOS
0.67
0.57
0.79
0.48
Average
0.84
0.82
0.83
0.81
Accuracy
82.16%
81.04%
TABLE III: Realistic trafﬁc experimental results without a
known TCP variant using SVM, RF, and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.75
0.89
0.86
0.90
0.84
0.93
Linux
0.89
0.82
0.94
0.89
0.93
0.88
Mac OS
0.63
0.81
0.61
0.82
0.61
0.82
Unix
0.94
0.99
0.94
0.99
0.94
0.99
Windows
0.97
0.89
0.98
0.89
0.98
0.89
iOS
0.88
0.72
0.86
0.73
0.88
0.72
Average
0.85
0.83
0.86
0.85
0.87
0.85
Accuracy
83.43%
85%
85.10%
TABLE IV: Realistic trafﬁc experimental results without a
known TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.81
0.83
0.76
0.86
Linux
0.89
0.79
0.90
0.81
Mac OS
0.61
0.82
0.82
0.79
Unix
0.92
0.99
0.94
0.99
Windows
0.98
0.89
0.97
0.89
iOS
0.84
0.73
0.70
0.92
Average
0.84
0.83
0.83
0.84
Accuracy
83.91%
83.27%
C. Based on Emulated Trafﬁc
Our performance results of the emulated trafﬁc without
a known TCP variant as an input feature using both
machine learning and deep learning techniques are presented
in Tables V and VI respectively. As we can see in the
corresponding confusion matrices presented in Figures 6, there
is a slightly inaccurate classiﬁcation of the Mac OS due to its
underrepresentation. The precision and recall for the rest of the
OSes using machine learning and deep learning techniques are
reasonably good.
TABLE V: Emulated trafﬁc experimental results without a
known TCP variant using SVM, RF and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.74
0.90
0.86
0.90
0.85
0.91
Linux
0.92
0.82
0.94
0.89
0.92
0.90
Mac OS
0.63
0.81
0.61
0.82
0.61
0.82
Unix
0.94
0.99
0.94
0.99
0.94
0.99
Windows
0.97
0.89
0.98
0.89
0.98
0.89
iOS
0.88
0.73
0.86
0.73
0.88
0.73
Average
0.85
0.84
0.86
0.85
0.87
0.85
Accuracy
84.67%
85.73%
85.27%
D. Comparison of Results Without Known TCP Variant
As shown in Tables I, II, III, IV, V, and VI, our
experimental results are pretty consistent. Firstly, we can
see that there is not much difference in performance across
different machine learning and deep learning techniques.
But more importantly, there are not many differences in
performance between results from using different types of
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 (a) SVM
(b) KNN
(c) RF
(d) MLP
(e) LSTM
Fig. 4: Confusion matrix comparison of the machine learning and deep learning techniques using the benchmark data [22].
(a) SVM
(b) KNN
(c) RF
(d) MLP
(e) LSTM
Fig. 5: Confusion matrix comparison of the machine learning and deep learning techniques using a realistic trafﬁc.
TABLE VI: Emulated trafﬁc experimental results without a
known TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.75
0.88
0.91
0.85
Linux
0.93
0.78
0.92
0.74
Mac OS
0.62
0.81
0.86
0.88
Unix
0.92
0.99
0.94
1.00
Windows
0.93
0.91
0.98
0.73
iOS
0.88
0.73
0.82
1.00
Average
0.85
0.83
0.89
0.88
Accuracy
84.05%
88.44%
experimental data. This is intuitively correct, since the OS
ﬁngerprinting is based on the basic TCP/IP packet ﬁelds,
and should not differ much between various types of data,
whether we do evaluation using the benchmark data, real
data or emulated data. Secondly, we believe accuracy in the
range of 82-88% (average value) is perhaps not sufﬁcient for
a product in a real deployment. Our hypothesis is that this
accuracy could be boosted considerably had we only known
the implementation of the underlying TCP variant. We will
explore this hypothesis in the next section.
VII.
ORACLE-BASED EXPERIMENT: RESULTS USING
ORACLE-GIVEN TCP VARIANT
Here we assume that we know exactly the underlying TCP
variant, i.e., we assume it is given by an Oracle. We show
that knowledge of the TCP variant has a great potential for
boosting passive ﬁngerprinting of OSes, and in this section,
we will try to quantify this potential. In the next section, we
will show that much of this potential can be harvested by using
a tool that predicts the TCP variant.
A. Based on Benchmark Data from Previous related Work
Tables VII and VIII show a signiﬁcant performance gain
across all classes of OSes when we assume prior knowledge of
the underlying TCP variant, as compared to the results when
the TCP variant is unknown presented in Tables I and II.
TABLE VII: Benchmark data [22] experimental results with
Oracle-given TCP variant using SVM, RF and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.96
0.99
0.99
0.98
0.99
0.98
Linux
0.86
0.95
0.92
0.95
0.93
0.94
Mac OS
0.98
0.89
0.97
0.92
0.97
0.92
Other
0.93
0.81
0.93
0.81
0.90
0.83
Unix
1.00
1.00
1.00
1.00
1.00
1.00
Windows
0.99
0.89
0.97
0.92
0.99
0.91
iOS
0.75
0.89
0.75
0.91
0.76
0.91
Average
0.92
0.92
0.93
0.93
0.93
0.93
Accuracy
91.71%
92.73%
92.69%
TABLE VIII: Benchmark data [22] experimental results with
Oracle-given TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.96
0.97
0.94
0.97
Linux
0.89
0.92
0.88
0.93
Mac OS
0.96
0.92
0.97
0.88
Other
0.93
0.81
0.84
0.84
Unix
1.00
1.00
1.00
1.00
Windows
0.96
0.92
0.98
0.84
iOS
0.76
0.89
0.73
0.83
Average
0.92
0.92
0.91
0.90
Accuracy
91.91%
90.03%
B. Based on Realistic Trafﬁc
The performance results of the realistic trafﬁc with the
Oracle-given TCP variant presented in Tables IX and X show
the potential of knowing TCP variant given by an Oracle for
passive OS ﬁngerprinting in a realistic scenario.
TABLE
IX:
Realistic
trafﬁc
experimental
results
with
Oracle-given TCP variant using SVM, RF and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.95
1.00
0.99
0.98
0.99
0.98
Linux
0.86
0.91
0.94
0.93
0.92
0.94
Mac OS
0.99
0.90
0.96
0.92
0.97
0.92
Unix
1.00
1.00
1.00
1.00
1.00
1.00
Windows
0.99
0.89
0.99
0.89
0.99
0.89
iOS
0.93
0.96
0.91
0.99
0.92
0.98
Average
0.95
0.95
0.96
0.96
0.96
0.96
Accuracy
94.81%
95.65%
95.69%
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 TABLE
X:
Realistic
trafﬁc
experimental
results
with
Oracle-given TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.98
0.97
0.98
0.97
Linux
0.92
0.92
0.90
0.93
Mac OS
0.96
0.92
0.96
0.92
Unix
1.00
1.00
1.00
1.00
Windows
0.97
0.91
0.99
0.88
iOS
0.92
0.97
0.91
0.98
Average
0.95
0.95
0.95
0.95
Accuracy
94.98%
94.89%
C. Based on Emulated Trafﬁc
Our performance results of the emulated trafﬁc with
the Oracle-given TCP variant using both classical machine
learning and deep learning techniques are presented in
Tables XI and XII. We can see that this shows a signiﬁcant
improvement in performance over the results without a known
TCP variant presented in Tables V and VI. Both machine
learning and deep learning techniques have comparable and
consistent results in terms of accuracy.
TABLE XI: Emulated trafﬁc experimental results with the
Oracle-given TCP variant using SVM, RF, and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.97
0.98
0.99
0.98
0.99
0.98
Linux
0.90
0.91
0.95
0.93
0.92
0.95
Mac OS
0.99
0.90
0.97
0.92
0.97
0.92
Unix
1.00
1.00
1.00
1.00
1.00
1.00
Windows
0.99
0.89
0.97
0.91
0.97
0.91
iOS
0.91
0.98
0.92
0.98
0.93
0.97
Average
0.95
0.95
0.96
0.96
0.96
0.96
Accuracy
95.10%
96.02%
95.83%
TABLE XII: Emulated trafﬁc experimental results with the
Oracle-given TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.98
0.97
0.96
0.98
Linux
0.97
0.89
0.93
0.91
Mac OS
0.93
0.94
0.94
0.92
Unix
1.00
1.00
1.00
1.00
Windows
0.99
0.89
0.98
0.88
iOS
0.91
0.99
0.91
0.97
Average
0.95
0.95
0.95
0.95
Accuracy
95.24%
95.08%
D. Comparison of Results with Oracle-given TCP Variant
Our accuracy results presented in Tables
VII,
VIII,
IX, X, XI, and XII, demonstrate that by knowing the TCP
variant we obtain a considerable performance boost in all our
experimental results, compared to our previous results obtained
without knowledge of the TCP ﬂavor. With an Oracle-given
TCP variant, we obtain a prediction accuracy of 94-96%,
with an average value of 94.1% over all trafﬁc classes and
of 95.4% over only emulated trafﬁc. The accuracy results are
pretty consistent across all scenarios. Comparing these results
with our previous results that do not use the Oracle (84.1%
on average for all trafﬁc types and 85.6% only for emulated
trafﬁc), we observe a solid increase in the OS ﬁngerprinting
performance. This improvement would signiﬁcantly boost
the usefulness of a product to be implemented in a real
enterprise network infrastructure. As in the previous section,
here again, we observe highly consistent performance results
across different machine learning and deep learning techniques
and also between the use of different types of experimental
data. The latter is useful knowledge for the next section since
it means that performance increases obtained over one trafﬁc
type is shown to be amenable to other trafﬁc types as well.
In the next section, we will have to base our evaluation on
emulated data, since we do not have the TCP trafﬁc patterns
of the realistic data or benchmark data at hand. These trafﬁc
patterns are required to be able to passively infer the TCP
variant in the experiments presented in the next section. In this
section, the idealistic Oracle was used only to demonstrate the
potential of knowing the TCP variant, but this is not a realistic
assumption. Thus, in the next section, we will instead base our
evaluation on a TCP variant that is passively predicted by a
deep learning-based tool that we developed and presented in
our previous work [11, 12, 13]. Using this tool, we explore
how close our performance will get to the ideal solution of
having an Oracle.
VIII.
PREDICTION-BASED EXPERIMENT: RESULTS USING
TCP VARIANT PREDICTION
In Section VII, we showed that Oracle-given knowledge
of the TCP variant has a great potential for improving the
passive OS ﬁngerprinting. In reality, however, we don’t have
an Oracle-given TCP variant. Since passively detecting the
TCP variant is a challenging task, this is where our tool from
previous works on predicting the underlying TCP variant from
passive measurements [11, 12, 13] comes into play. In this
Section we use the TCP variant passively predicted by this
tool as an input feature for the passive OS ﬁngerprinting. The
TCP variant is inferred from the famous Additive Increase
and Multiplicative Decrease (AIMD) sawtooth pattern of
TCP’s estimated cwnd computed based on the outstanding
bytes-in-ﬂight. Since we don’t have access to the actual cwnd
of the senders in the benchmark data and realistic trafﬁc, here
we consider only the emulated trafﬁc.
A. Based on Emulated Trafﬁc
In this section, we use a tool to predict the TCP variant
from passive measurements of TCP trafﬁc patterns, and this
prediction is used as input to the passive OS ﬁngerprinting
method presented above. The experimental results of both
techniques are presented in Tables XIII and XIV.
TABLE XIII: Emulated trafﬁc experimental results with
predicted TCP variant using SVM, RF, and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.92
0.96
0.92
0.97
1.00
0.97
Linux
0.79
0.85
0.94
0.82
0.92
0.94
Mac OS
0.96
0.88
0.97
0.87
0.85
0.94
Unix
1.00
1.00
1.00
1.00
1.00
1.00
Windows
0.92
0.78
0.85
0.80
0.88
0.91
iOS
0.85
0.94
0.86
0.96
0.93
0.87
Average
0.90
0.90
0.91
0.91
0.93
0.93
Accuracy
90.01%
91.09%
92.15%
TABLE XIV: Emulated trafﬁc experimental results with
predicted TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.95
0.97
0.92
0.96
Linux
0.98
0.79
0.86
0.90
Mac OS
0.95
0.90
0.95
0.88
Unix
1.00
1.00
1.00
1.00
Windows
0.94
0.77
0.97
0.77
iOS
0.82
0.99
0.88
0.96
Average
0.92
0.91
0.92
0.92
Accuracy
91.45%
91.93%
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 (a) SVM
(b) KNN
(c) RF
(d) MLP
(e) LSTM
Fig. 6: Confusion matrix comparison of the machine learning and deep learning techniques using an emulated trafﬁc.
B. Comparison of results with a predicted TCP variant
Results with emulated data and a passive prediction of
the TCP variant (Tables XIII and XIV) gives an accuracy of
91.3% on average, which comes pretty close to the accuracy
of 95.4% obtained on emulated trafﬁc with the TCP-variant
given by the Oracle. Intuitively, when we do learning based
on the TCP variant prediction, the accuracy must be lower
than the Oracle-given TCP variant, but the question is how
close we can get to the idealistic scenario of having an
Oracle. Our results show that using our tool for TCP variant
prediction gives reasonably good OS ﬁngerprinting accuracies
that come close to the results obtained by using Oracle-given
TCP variant. Even though the performance results with the
TCP variant passively predicted by our deep learning-based
tool are slightly lower as compared to the TCP variant given
by an idealistic Oracle, our performance results of using our
tool are reasonably competitive.
IX.
TRANSFER LEARNING RESULTS
Transfer learning is the ability to take a model trained
in one scenario and apply it for classiﬁcation in a different
scenario. For example, in our case, that means we are able
to train our model on a dataset created in an emulated
network with an Oracle-given TCP variant and apply it for
classiﬁcation of our dataset from the realistic trafﬁc. Results
shown in Tables XV and XVI shows that the learning of the OS
ﬁngerprinter transfers well into other scenarios. Good transfer
learning results indicate that our passive OS ﬁngerprinting
model is able to discern the results of unforeseen scenarios
and still perform reasonably well. In previous works, we have
also demonstrated that the TCP variant predictor performs well
in terms of transfer learning [11, 12, 13].
TABLE XV: Transfer learning experimental results using
SVM, RF, and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.95
1.00
0.98
0.98
0.99
0.98
Linux
0.86
0.91
0.90
0.95
0.92
0.95
Mac OS
0.99
0.90
0.98
0.92
0.97
0.92
Unix
1.00
1.00
1.00
1.00
1.00
1.00
Windows
0.99
0.89
0.98
0.90
0.97
0.91
iOS
0.93
0.96
0.93
0.97
0.93
0.97
Average
0.95
0.95
0.95
0.95
0.96
0.96
Accuracy
94.79%
95.35%
95.76%
X.
CONCLUSION AND FUTURE WORK
In this paper, we proposed and evaluated a novel approach
that attempts to passively ﬁngerprint the underlying remote
OS by leveraging state-of-the-art machine learning and deep
learning techniques under multiple controlled scenarios. We
TABLE XVI: Transfer learning experimental results using
MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.97
0.98
0.97
0.96
Linux
0.95
0.85
0.91
0.91
Mac OS
0.94
0.94
0.96
0.90
Unix
1.00
1.00
1.00
1.00
Windows
0.99
0.89
0.98
0.87
iOS
0.90
0.98
0.90
0.98
Average
0.95
0.95
0.94
0.94
Accuracy
94.72%
94.28%
show that knowing the Oracle-given TCP variant has a great
potential for boosting the classiﬁcation performance of passive
OS ﬁngerprinting. In our setting, we demonstrate that using
the idealistic Oracle has the potential to boost the prediction
accuracy from 84.1% to 94.1% on average across all trafﬁc
types tested, and from 85.6% to 95.4% in an emulated setting.
However, in reality, we don’t have the Oracle-given TCP
variant and hence we don’t know exactly the underlying TCP
ﬂavor. To address this, we demonstrated a method for passive
OS ﬁngerprinting where the cwnd is ﬁrst computed based on
the outstanding bytes-in-ﬂight, then the underlying TCP ﬂavor
is predicted from the estimated cwnd, and ﬁnally, the predicted
TCP variant is used as an input feature to detect the remote
computer’s OS. This is an additional feature that is added to the
basic TCP/IP features that are the basis of OS ﬁngerprinting
in previous works. We demonstrate that our method performs
signiﬁcantly better than not using the predicted TCP variant
as an input feature, increasing the accuracy in our experiment
from 85.6% to 91.3%. The results of this method come close
to the accuracy of 95.4% obtained by using the idealistic
Oracle. To the best of our knowledge, this is the ﬁrst study that
reports the potential of the underlying TCP feature in boosting
signiﬁcantly the accuracy of passive OS ﬁngerprinting. We
further validate and demonstrate the transferability approach
of our OSes classiﬁcation models by conducting a series
of controlled experiments against other scenarios. Through
comparing the experimental results between the benchmark
dataset, realistic, and emulated trafﬁc in terms of accuracy and
confusion matrix, it is clear that our passive OSes classiﬁcation
models are able to discern the results to unforeseen scenarios.
Therefore, we are able to show that the learned passive OS
ﬁngerprinting model by leveraging a pre-trained knowledge of
classiﬁcation techniques from the emulated network performs
reasonably well as it is shown in the experimental results when
it is applied and transferred to a realistic scenario. Lastly,
in all our experiments, we made sure that both the training
and validation accuracies are closer which gives an idea about
the ability of the OSes classiﬁcation models to generalize on
unforeseen scenarios.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 The method presented in this paper, where the cwnd is
ﬁrst computed based on the outstanding bytes-in-ﬂight, then
the underlying TCP ﬂavor is predicted from the estimated
cwnd, is particularly efﬁcient for loss-based TCP variants.
In previous works, we have also developed a tool for the
prediction of delay-based TCP ﬂavors [10]. We plan to extend
the method presented in this paper to also cover delay-based
TCP variants and present it in a follow-on paper [14]. Note
that passively detecting the TCP variant is a challenging task,
which led to a two-step approach, where the TCP variant
prediction of a deep learning-based tool is used as input to
another machine learning method in the next step. However, by
integrating the two machine learning approaches better, there
should be potential for increasing the performance even further
and get even closer to the idealistic results of using an Oracle.
Exploring such optimizations is also left for future work. It
is known that TCP clock drift improves OS ﬁngerprinting
and hence measuring differences in the timing of how the IP
stack works may allow us to predict the underlying OS with
greater assurance in terms of accuracy. We, therefore, argue
for using other TCP options like timestamps and queueing
delay characteristics as an input feature vector for passive OSes
ﬁngerprinting model as another interesting direction. Finally,
in addition to the difﬁculties of establishing ground truth (e.g.,
the TCP variant) at a larger scale on a dynamic network
addressed in Section III, there is a lot of other work to be
done as an extension of our work presented here. For example,
addressing answers to valid questions like: What happens if an
end-user (client) changes default parameters that are the basis
of OS ﬁngerprinting? is one possibility for our future work.
We expect that end-users don’t change parameters often, while
servers may do so if it helps improve performance. We believe
this would make OS ﬁngerprinting potentially hard.
REFERENCES
[1] 5G4IoT. 5G4IoT, 2019.
[2] A. Aksoy, S. Louis, and M. H. Gunes.
Operating system
ﬁngerprinting via automated network trafﬁc analysis. In IEEE
Congress on Evolutionary Computation (CEC). IEEE, 2017.
[3] N. Cardwell, Y. Cheng, C. S. Gunn, S. H. Yeganeh, and
V. Jacobson. BBR: Congestion-based congestion control. 2016.
[4] W. R. Cheswick, S. M. Bellovin, and A. D. Rubin. Firewalls
and Internet security: repelling the wily hacker. Addison-Wesley
Longman Publishing Co., Inc., 2003.
[5] N. Davids. Initial TTL values, 2011.
[6] ESnet. iperf3, 2017.
[7] J. Fan, J. Xu, M. H. Ammar, and S. B. Moon. Preﬁx-preserving
IP
address
anonymization:
measurement-based
security
evaluation and a new cryptography-based scheme. 2004.
[8] L. G. Greenwald and T. J. Thomas.
Toward Undetected
Operating System Fingerprinting. WOOT, 7:1–10, 2007.
[9] S. Ha, I. Rhee, and L. Xu.
CUBIC: a new TCP-friendly
high-speed TCP variant. ACM SIGOPS, 2008.
[10] D. H. Hagos, P. E. Engelstad, and A. Yazidi.
Classiﬁcation
of
Delay-based
TCP
Algorithms
From
Passive
Trafﬁc
Measurements. In 18th NCA. IEEE, 2019.
[11] D. H. Hagos, P. E. Engelstad, A. Yazidi, and Ø. Kure.
A
machine learning approach to TCP state monitoring from
passive measurements. pages 164–171. IEEE, 2018.
[12] D. H. Hagos, P. E. Engelstad, A. Yazidi, and Ø. Kure. Recurrent
Neural Network-based Prediction of TCP Transmission States
from Passive Measurements. In NCA, pages 1–10. IEEE, 2018.
[13] D. H. Hagos, P. E. Engelstad, A. Yazidi, and Ø. Kure. Towards a
Robust and Scalable TCP Flavors Prediction Model from Passive
Trafﬁc. In 2018 27th ICCCN, pages 1–11. IEEE, 2018.
[14] D. H. Hagos, A. Yazidi, P. E. Engelstad, and Ø. Kure.
A
Deep Learning-based Universal Tool for Operating Systems
Fingerprinting from Passive Measurements. 2020. Submitted
for publication.
[15] T. Henderson, S. Floyd, A. Gurtov, and Y. Nishida.
The
NewReno modiﬁcation to TCP’s fast recovery algorithm. RFC
6582, 2012.
[16] K. Hornik, M. Stinchcombe, and H. White.
Multilayer
feedforward networks are universal approximators.
Neural
networks, 1989.
[17] V. Jacobson.
Congestion avoidance and control.
In ACM
SIGCOMM computer communication review. ACM, 1988.
[18] V. Jacobson, R. Braden, and D. Borman. TCP extensions for
high performance. RFC 1323, 1992.
[19] D. P. Kingma and J. Ba.
Adam: A method for stochastic
optimization. arXiv preprint arXiv:1412.6980, 2014.
[20] T. Kohno, A. Broido, and K. C. Claffy. Remote physical device
ﬁngerprinting. IEEE, 2005.
[21] A. Langley, A. Riddoch, A. Wilk, A. Vicente, C. Krasic,
D. Zhang, F. Yang, F. Kouranov, I. Swett, J. Iyengar, et al. The
quic transport protocol: Design and internet-scale deployment.
pages 183–196. ACM, 2017.
[22] M.
Lastovicka,
T.
Jirsik,
P.
Celeda,
S.
Spacek,
and
D. Filakovsky. Passive os ﬁngerprinting methods in the jungle
of wireless networks. In NOMS. IEEE, 2018.
[23] R. Lippmann, D. Fried, K. Piwowarski, and W. Streilein. Passive
operating system identiﬁcation from TCP/IP packet headers. In
Data Mining for Computer Security. Citeseer, 2003.
[24] R. Lippmann, S. Webster, and D. Stetson.
The effect of
identifying vulnerabilities and patching software on the utility
of network intrusion detection. Springer, 2002.
[25] G.
F.
Lyon.
Remote
OS
detection
via
TCP/IP
stack
ﬁngerprinting. Phrack Magazine, 8(54), 1998.
[26] G. F. Lyon. Nmap network scanning: The ofﬁcial Nmap project
guide to network discovery and security scanning. 2009.
[27] Netresec. NetworkMiner, 2007.
[28] A. Ornaghi and M. Valleri. Ettercap, 2015.
[29] J. Postel. Internet control message protocol. RFC 792, 1981.
[30] J. Postel. Internet protocol. RFC 791, 1981.
[31] J. Postel. Transmission control protocol. RFC 793, 1981.
[32] F. Rosenbaltt.
The perceptron–a perciving and recognizing
automation. Cornell Aeronautical Laboratory, 1957.
[33] J. Scambray, S. McClure, and G. Kurtz.
Hacking exposed.
McGraw-Hill Professional, 2000.
[34] SCOTT. European Leadership Joint Undertaking, 2019.
[35] R. Spangler.
Analysis of remote active operating system
ﬁngerprinting tools. University of Wisconsin, 2003.
[36] G. Taleck.
Synscan: Towards complete tcp/ip ﬁngerprinting.
CanSecWest, Vancouver BC, Canada, pages 1–12, 2004.
[37] K. Tan, J. Song, Q. Zhang, and M. Sridharan. A compound
TCP approach for high-speed and long distance networks. In
Proceedings IEEE INFOCOM, 2006.
[38] W. Wei, K. Suh, B. Wang, Y. Gu, J. Kurose, and D. Towsley.
Passive online rogue access point detection using sequential
hypothesis testing with TCP ACK-pairs. ACM, 2007.
[39] J. Xu, J. Fan, M. Ammar, and S. B. Moon. On the design and
performance of preﬁx-preserving IP trafﬁc trace anonymization.
In ACM SIGCOMM, pages 263–266. ACM, 2001.
[40] L. Xu, K. Harfoush, and I. Rhee. Binary increase congestion
control (BIC) for fast long-distance networks. IEEE, 2004.
[41] F. Yarochkin and O. Arkin.
Xprobe2- A’Fuzzy’Approach to
Remote Active Operating System Fingerprinting, 2002.
[42] M. Zalewski. p0f: Passive OS ﬁngerprinting tool. Online at
http://lcamtuf.coredump.cx/p0f3, 2017.
[43] B. Zhang, T. Zou, Y. Wang, and B. Zhang. Remote operation
system detection base on machine learning. IEEE, 2009.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
",10.1109/ICCCN49398.2020.9209694,doc28,"Advanced Passive Operating System Fingerprinting Using Machine Learning and Deep Learning Desta Haileselassie Hagos∗, Martin Løland†, Anis Yazidi‡, Øivind Kure §, Paal E. Engelstad ¶ ∗§¶University of Oslo, Department of Technology Systems, Kjeller, Norway ∗†‡¶Oslo Metropolitan University, Department of Computer Science, Oslo, Norway Email: ∗destahh@iﬁ.uio.no, †martin.loeland@gmail.com, {‡anis.yazidi, ¶paal.engelstad}@oslomet.no, §oivind.kure@its.uio.no Abstract—Securing and managing large, complex enterprise network infrastructure requires capturing and analyzing network trafﬁc traces in real-time. An accurate passive Operating System (OS) ﬁngerprinting plays a critical role in effective network management and cybersecurity protection. Passive ﬁngerprinting doesn’t send probes that introduce extra load to the network and hence it has a clear advantage over active ﬁngerprinting since it also reduces the risk of triggering false alarms. This paper proposes and evaluates an advanced classiﬁcation approach to passive OS ﬁngerprinting by leveraging state-of-the-art classical machine learning and deep learning techniques. Our controlled experiments on benchmark data, emulated and realistic trafﬁc is performed using two approaches. Through an Oracle-based machine learning approach, we found that the underlying TCP variant is an important feature for predicting the remote OS. Based on this observation, we develop a sophisticated tool for OS ﬁngerprinting that ﬁrst predicts the TCP ﬂavor using passive trafﬁc traces and then uses this prediction as an input feature for another machine learning algorithm for predicting the remote OS from passive measurements. This paper takes the passive ﬁngerprinting problem one step further by introducing the underlying predicted TCP variant as a distinguishing feature. In terms of accuracy, we empirically demonstrate that accurately predicting the TCP variant has the potential to boost the evaluation performance from 84% to 94% on average across all our validation scenarios and across different types of trafﬁc sources. We also demonstrate a practical example of this potential, by increasing the performance to 91.3% on average using a tool for TCP variant prediction in an emulated setting. To the best of our knowledge, this is the ﬁrst study that explores the potential for using the knowledge of the TCP variant to signiﬁcantly boost the accuracy of passive OS ﬁngerprinting. Keywords—Operating System, Fingerprinting, Machine Learning, Deep Learning, Passive Measurements I. INTRODUCTION AND MOTIVATION As modern network infrastructures grow in size, collecting detailed relevant knowledge about the dynamic characteristics and complexity of large heterogeneous networks is crucial for many purposes e.g., network vulnerability assessment and monitoring, spam detection, etc. Developing advanced network security and monitoring techniques are important for both the research and security practitioners. There has been a signiﬁcant research work in the context of network management and cybersecurity on developing network security tools to ﬁngerprint remote Operating Systems (OSes) [26, 27, 28, 41, 42]. OS ﬁngerprinting is the process of inferring the OS of a machine operating with TC/IP by a remote device connected on the Internet without having physical access to the device [20]. There are many different custom tools for ﬁngerprinting of the most commonly used OSes based on the characteristics of its underlying TCP/IP network stack [20] and this, to a large extent, is due to variability in how the TCP/IP stack is traditionally implemented across different OSes [25]. One common approach, for example, is by collecting the TCP/IP stack basic parameters [23], e.g., IP initial Time To Live (TTL) default values [5], HTTP packets using the User-agent ﬁeld [22], Internet Control Message Protocol (ICMP) requests [29], known open port patterns, TCP window size [18], TCP Maximum Segment Size (MSS) [31], IP Don’t Fragment (DF) ﬂag [30], a set of other speciﬁc TCP options to mention a few. However, in our work, we want to take this one step further by combining these basic features and other settings with the underlying TCP variant as a feature in our model due to the fact that different OSes are doing slightly different implementations of TCP. Some implementations of common TCP variants quickly overshoot the size of the Congestion Window (cwnd) because of differences in the variant implementations. Hence, we believe that knowing the implementation of the underlying OS may help us understand better their exact behavior. It can also help us explore how to classify an OS when different OSes are implementing the same TCP variant. Fingerprinting Techniques: We can determine what OS a remote computer on the Internet is running by either passively listening to trafﬁc captured from a network or by actively sending it packets. The most widely used complementary remote OS ﬁngerprinting proven approaches that employ a variety of TCP/IP stack scanning are broadly categorized into classes of active and passive methods. • Active Fingerprinting: This technique is based on actively transmitting one or more specially crafted network packets with different packet settings or ﬂags to a remote network device in order to analyze the corresponding potentially identifying replies [26, 41]. This method determines knowledge of the underlying OS according to the received responses from the target device by examining the network behavior of known TCP/IP stack [35]. However, since this approach injects additional trafﬁc to the network by generating active probes, it may itself trigger alarms and get blocked by ﬁrewall rules and Network address translators (NATs) [8]. • Passive Fingerprinting: This approach, on the other hand, inspects and analyzes packets traveling between end hosts without injecting any trafﬁc into the network [27, 28, 42]. This technique with little resource simply analyzes a pattern of the OS-speciﬁc information that has already been sent in the network trafﬁc and compares for a match with a predeﬁned database that contains a list of known signatures of different OSes. Passive ﬁngerprinting doesn’t send probes and hence it has a clear advantage over active ﬁngerprinting since it reduces the risk of triggering alarms [8]. 978-1-7281-6607-0/20/$31.00 ©2020 IEEE Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. OS ﬁngerprinting can also be performed using classical techniques known as “banner grabbing”. It is an approach used to gain detailed information about a remote computer system on a network and the associated services running on its opened ports [33]. Using techniques like this, some remote computers announce their underlying OS freely and running application services with their versions in use to anyone connecting to them as part of welcome banners or header information. Some of the widely used services that serve banner grabbing are: Telnet, FTP, NetCat, SMTP, etc. However, it is useful to remember that some of these basic services are effective against less secure networks. Potential beneﬁts and applications: Network scanning and accurate remote OS ﬁngerprinting are the crucial steps for penetration testing in terms of security and privacy protection. Note that attackers can also embrace passive ﬁngerprinting techniques to search for potential victims in a network. For example, by identifying the OS running on a remote computer and the list of services it runs, an attacker can target the device to eavesdrop on the communication between the endpoints without having physical access to the device. However, we argue that our work presented here is motivated by a number of practical applications that can be positively used by network and system administrators. Passively ﬁngerprinting an OS by analyzing the packets it generates and transmits over a network is extremely important in the areas of network management and computer security for several reasons. For example, it is useful to explore a network for potential exploitations of security vulnerabilities which can be exploited by attackers, auditing, identify critical attacks, reveal new information about a network user etc. Network administrators can, therefore, use this OS related information to maintain the security policy and reliability of their network by conﬁguring a network-based Intrusion Detection Systems (IDS) [24]. Vulnerabilities and security threats in a network may result from rogue or unauthorized devices [38], unsecured internal nodes within the network, and from external nodes [4]. Hence, passively ﬁngerprinting an OS has a potential beneﬁt in addressing these critical problems. This, from an academic point of view, is Client Oses of sending nodes Fingerprinter Receiving nodes on the Internet 35.195.9.67 Intermediate node (monitor) Fig. 1: Network architecture for passive OS ﬁngerprinting by an intermediate node. Limitations of previous works: Traditionally, most of the existing general OS ﬁngerprinting techniques resort to manually generated signature matching from a database of heuristics which contains features of widely used OSes. This means, after comparing the generated signatures, the ﬁrst set of responses match with the highest conﬁdence against a database of ﬁngerprints would be used to select the speciﬁc probable OS. However, manually updating a large number of signature and managing databases of new OSes adds a considerable amount of time and hence we may suffer from the consequences of the lack of recent signature updates of the known OSes. For example as reported in [22], the last updates of the ﬁngerprint databases of Ettercap [28] and p0f [42] date to 2011 and 2014 respectively. Consequently, new OSes families like Android 4.4 and higher versions of Android, Windows 10 distributions, etc. will not be recognized by these tools since they are not included in their ﬁngerprint databases. Hence, we argue that it is important to consider making use of a ﬁngerprint database that contains variations of most currently used OSes and automating these tasks by employing learning algorithms capable of extracting all possible OS-speciﬁc features for discovering the underlying OSes. To explore this idea of applying learning algorithms, we present a uniﬁed and robust classiﬁcation approach to an advanced passive OS ﬁngerprinting that leverages both machine learning and deep learning methods. Our ﬁngerprinting technique is completely passive meaning that we only need to be able to observe network trafﬁc from a target machine at any observation point on the network without injecting any trafﬁc into the network. Note that the TCP/IP header ﬁelds would not be impacted by SSL/TLS encryption of the TCP payload. Hence, since we utilize features that are readable even with encryption, our approach is independent of whether the ﬂow is encrypted or not. Figure 1 shows the architecture for implementing our ﬁngerprinting methodology. Why machine learning approaches to OS ﬁngerprinting? There are several limitations imposed by classical ﬁngerprinting techniques. Passive OS ﬁngerprinting generally relies on recognizing the default values for various TCP/IP stack parameters. If a user changes these parameters, the task of OS ﬁngerprinting becomes much more challenging. Most of the existing works on ﬁngerprinting provide a little capability to address this challenge. Motivated by this problem, we proposed a novel approach by leveraging both machine learning and deep learning-based techniques that consider the set of parameters as a whole, rather than individually so that our model caters for variations in TCP parameters. If a user changes the initial receive window size, for instance, we may still be able to recognize the OS from other parameters that have not been changed (TCP congestion control algorithm, initial cwnd size, etc.). Note that this depends entirely on the changes made by the user to the default TCP or OS stack parameters that are commonly used for signature-based ﬁngerprinting. The other reason why we create a model by employing learning techniques is to understand the complex patterns of the varying values in the TCP header and extract useful input features. Because machine learning offers new possibilities as it can extract patterns and general rules for classiﬁcation. Machine learning can also be more robust to small variations in the input parameters. In addition to this, with the use of learning techniques, we argue that avoiding using manually updated static signature databases has two potential beneﬁts. Firstly there is no tedious task of creating these unique ﬁngerprints, all you need is a set of values or features. The second beneﬁt comes from a known ﬂaw in many of the existing ﬁngerprinting tools, where a “ﬁrst-match” policy is applied, meaning that if two ﬁngerprints are equal the tool would always predict the ﬁrst OS with that exact ﬁngerprint. However, learning techniques, on the other hand, make calculated guesses of which of the classes with the same ﬁngerprint that will be predicted. interesting and something that needs to be addressed from a network security research point of view. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. Contributions: We summarize our main contributions below. • We propose and evaluate a robust approach to OS ﬁngerprinting from passive measurements by leveraging machine learning and deep learning techniques. • We investigate the use of TCP congestion control variant as a distinguishing feature in passive OS ﬁngerprinting. • We explore variability in implementations of TCP variant by different OSes and its effect on classifying remote OS. • We study the applicability of Recurrent Neural Networks (RNN)-based models for robust and advanced passive OS ﬁngerprinting by combining the basic TCP/IP features and the predicted TCP variant as input vectors. • We show that the TCP ﬂavor has a great potential for boosting passive OS ﬁngerprinting. • We build a universal tool for passive monitoring that can be applied to ﬁrst estimate the TCP cwnd, second predict the TCP ﬂavor, and ﬁnally uses the TCP variant as an input feature to detect the remote computer’s OS. Roadmap: The rest of the paper is organized as follows. Section II discusses related work, and Section III presents the experimental datasets. Section IV presents the machine learning of the OS ﬁngerprinter. The machine learning of the TCP variant prediction tool is presented in detail in Section V. Section VI presents the experimental results without a known TCP variant which will play the role of baseline. In order to assess the importance of knowing the TCP variant, experimental results of all the use cases with an Oracle-given TCP variant are presented in Section VII. Section VIII presents the experimental results with the predicted TCP variant. Section IX presents the transfer learning results. Finally, Section X concludes our paper and suggests directions for future research work. II. RELATED WORK Remote OSes ﬁngerprinting has a long history in the computer security community [2, 22, 23, 26]. TCP/IP header ﬁngerprinting and any information related to application protocols are used to identify the underlying OS running on a remote host either actively or passively [25]. As we explained in Section I, there are multiple existing tools for both the predominant active and passive OS ﬁngerprinting approaches, where Nmap [26] is one of the most prominent open-source active ﬁngerprinting tools. The work presented in [36], SYNSCAN, works in a similar fashion to Nmap, but it performs the ﬁngerprinting task by actively sending a small number of crafted network packets to a single TCP port. Xprobe2 [41] is another popular ﬁngerprinting tool, that relies primarily on ICMP packets, and it depends on how many changes we make to the default TCP/IP stack parameters. Since Xprobe2 does fuzzy ﬁngerprinting with a signature matching algorithm as an alternative to Nmap, it means that if we make a lot of changes to the default TCP/IP stack parameters, the underlying OS will not be detected. However, Xprobe2 is more robust to small ﬁngerprint variations as compared to Nmap. As explained above the other ﬁngerprinting tools, Ettercap [28] and p0f [42], have not been updated since 2011 and 2014 respectively to include variations of most widely used modern OSes. For passive OS ﬁngerprinting to be effective, we believe that the limitations of these ﬁngerprinting tools need to be addressed. The work in [23] also demonstrates that the OS ﬁngerprinting accuracy of the Ettercap and p0f signature databases is low and techniques to improve performance was proposed. Hence, the paper presents rule-based machine learning classiﬁers capable of identifying 75 classes of OSes from TCP/IP packet headers found in the Ettercap database. They proposed a classiﬁer technique using k-nearest neighbors (KNN) that returns an approximate ﬁrst match for an OS from a ﬁngerprint database. This counters the problem of classifying hosts as unknown if no exact match is found in the database [23]. However, their evaluation yielded poor experimental results, rejecting as much as 84% of the test packets, while 44% of the accepted patterns were wrongly classiﬁed [23]. The problems contributing to poor performance was believed to be caused by two main issues. The ﬁrst reason is substitution errors due to multiple OSes with exactly the same ﬁngerprint feature values. The second reason for this poor performance is the high rejection rate caused by numerous unique feature values derived from the same OS. After combining the OS classes most often confused with each other, eliminating all the classes where the error could not be reduced by combining classes, the error percentage was reduced to 9.8% with no rejected packets. A recent study that is most closely related to our work, and which has also given a comprehensive survey on passive ﬁngerprinting methods, can be found in [22]. The authors have employed OS ﬁngerprinting methods in the environment of wireless networks. Besides using the three basic TCP/IP stacks (i.e., TTL, window size, and initial SYN packet size), the authors suggested also using the user-agent information in HTTP request headers and communication with OS-speciﬁc domains can be usable in large dynamic networks [22]. The average accuracy of OS classiﬁcation using the TCP/IP parameters reported in [22] is 80.88%. Zhang et al.’s paper on OS detection [43] utilizes only one machine learning technique namely Support Vector Machine (SVM). However, the testing error rate of identifying some of the OSes e.g., Mac, Cisco, FreeBSD, and OpenBSD is 25.80%, 24.22%, 17.71%, and 15.85% respectively [43]. Aksoy et al. [2] have employed genetic algorithms for identifying packet features suitable for OS classiﬁcation based on the analysis of the network TCP/IP packets using machine learning algorithms. However, most of these previous works use the basic actual TCP/IP features for evaluating passive OS ﬁngerprinting. Besides, we believe that these tools have the inability to extract all possible OS-speciﬁc features for passively ﬁngerprinting the underlying OSes. In contrast, what separates our contribution in this paper from the other previous related works is that our model supports a wider range of TCP/IP network stack features. As shown in Figure 2, the main goal of our work presented here is to combine these basic TCP/IP features that are the basis of OS ﬁngerprinting with the underlying TCP variant by leveraging both machine learning and deep learning techniques. This contribution remains largely unexplored and is not used by existing ﬁngerprinting techniques. Detecting the implementation of a TCP variant passively is a challenging task and this, we believe, is the reason why no previous works use it to passively ﬁngerprint remote OSes. However, in our case, we already have a general solution for this difﬁculty presented in our previous works [11, 12, 13]. The reason why we focus on the implementations of the underlying TCP variant as a feature in our OS classiﬁer model is due to the fact that Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. different OSes are doing slightly different implementations of TCP. Hence, we believe that passively observing the network-level characteristics found in TCP packets can give us more information about the remote computer’s underlying OS. We further believe that this will also help us to explore in detail the long-term characteristics of TCP trafﬁc. To the best of our knowledge, this is the ﬁrst study of passive ﬁngerprinting OSes by applying RNN methods combining the basic TCP/IP features and the underlying TCP variant as input vectors. III. EXPERIMENTAL DATASETS Our machine learning models for OS classiﬁcation is developed and tested on three datasets, presented below. A. Benchmark Data First, we utilize a large benchmark dataset that has been used for OS ﬁngerprinting in a previous related work [22]. This dataset is closely aligned with our task. The benchmark dataset was used in the previous work for OS ﬁngerprinting based on the HTTP header, while the ambition of our paper is to do generic ﬁngerprinting based only on the TCP packet ﬁelds. Since we aim at ﬁngerprinting that is not application-speciﬁc, the TCP information in the dataset is useful for our purpose, while the HTTP User-agent information in our experiments is used only to establish ground truth about the OS that was used. The benchmark dataset contains 79087345 ﬂows, activity of 21746 unique users, 253374 WiFi sessions, 25642 unique MAC addresses, and 6104 unique IP addresses, a ﬁngerprint database of 2078 standard TCP/IP signatures of 51 known unique OSes with a total of 529 variations when considering major and minor versions [22]. It consists of three basic TCP/IP network stack features, i.e., initial SYN packet size, TTL, and TCP window size [22]. After our ﬁrst set of testing, we realized that the data was severely skewed and that only a few of the classes contained almost all of the entries, giving us artiﬁcially good classiﬁcation results. We then removed most of the very seldom occurring classes and ended up with 33 reduced classes. We also removed all trafﬁc that did not contain HTTP User-agent information, since we could not establish ground truth for this trafﬁc. In addition, we created a new dataset where all the classes were bucketed into seven groups, consisting of the six most widely used major OS families: Android, Linux, Mac OS, Unix, Windows, iOS, and a seventh class called “Other” for OSes not suited for any of the other groups. Finally, we ended up distributing all of the labels equally so that each OS class had the same number of occurrences. This helps us improve the generalizability of our model with a uniﬁed approach that encompasses all variations of the most widely used OSes. B. Realistic Trafﬁc While benchmark trafﬁc is useful to link our experiments to previous related work, we also wanted additional realistic trafﬁc for which we have more control, and that allows us to make our own assurances of the quality of the data. Thus, we passively collected our realistic dataset from TCP trafﬁc originated from the internal network of the Oslo Metropolitan University and destined to various hosts on the Internet. First, we collected data for ﬁxed (non-mobile) desktop computers (typically using OSes like Windows, Linux, Unix, Mac OSx, etc.) by using an intermediate node as shown in the network setup in Figure 1. Then, we passively collected the data that covered mobile devices, like android and iOS. The latter was collected from the 5G 4IoT research lab [1, 34] of the Oslo Metropolitan University. We spent a signiﬁcant amount of effort in establishing ground truth, i.e., determining the actual OS that has been used for each trafﬁc ﬂow. To establish ground truth in the realistic dataset, we follow two approaches. The ﬁrst approach was only applicable to the non-mobile desktops, while the second method was used for both mobile and non-mobile devices. With the ﬁrst method, we leveraged the DHCP log messages associated with the non-mobile desktops to derive the ground truth from the DHCP server of the Oslo Metropolitan University network that logs the sessions by the MAC address and name of the device. Since we collect the real data from the internal network of our university, extracting the DHCP log messages can give us detailed information about the OSes. We could, for example, see information about the vendor-speciﬁc preﬁxes since most of the OS variants are identiﬁed based on their vendors. The list of device vendor preﬁxes is useful in revealing the speciﬁc implementation of an OS because most of the modern OSes from the same device vendor usually share the same OS kernel and similar network behaviors. For example, we found out that Apple products often share the same TCP/IP parameters. The second approach we used to identify the OS is getting the predeﬁned browser strings that loosely tell the name of the underlying OS assigned by the vendor from Webserver. We believe changing the default device names by all users is not that common and sometimes discouraged by the vendors, e.g., Google and Apple OSes. However, the device name of Linux and Windows OSes could be changed easily by experienced users which would make passively identifying these devices hard. Since a number of computer vendors offer devices with a pre-installed OS and default device name and MAC address, we can use this information to derive the ground truth for OS ﬁngerprinting. For example, Apple devices use a default string name of “<user>-iPhone”, “<user>-iPad”, Microsoft uses “Windows-Phone” for its mobile devices, and Android uses “android-<android−id>”, etc. Our real trafﬁc covers the communication to and from our university and hence all trafﬁc whose source and destination IP addresses are within the subnets of our internal network. Hence the network administrator of our university has full control over the internal machines with real IP addresses that are not going to a NAT gateway, and therefore it is fairly possible to tell whether it is a laptop or a desktop PC by looking it up in the internal database owned by the university. However, since it is a dynamic network we do not have full control over external machines, because they can be anything behind an IP address that changes dynamically. This is because there is an endless number of machines spooﬁng scanning the network and they can appear as Linux-powered OSes but they could be Windows and vice versa and this happens because the user may have strongly tuned the TCP stack to look like something else. It is pretty hard to certainly say anything about the external computers because the communication can go through a NAT gateway possessing another OS type. For example, if a user is connected to a student wireless network, there is a chance that it may go to a Linux NAT gateway, and hence from outside the user is Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. seen as Linux NAT which makes it hard to predict whether the underlying OS is Linux, Mac or Windows. Therefore, ﬁngerprinting devices behind NAT technology on a distributed network where a number of devices can hide behind a NAT is another critical challenge. It is, therefore, worth noting that establishing ground truth in dynamic networks at a larger scale remains a challenging problem. Further investigation to explore these difﬁculties will be done in our future works. Finally, due to the privacy protection of possibly sensitive data, the payload of all the network packets collected was removed and anonymized with a preﬁx-preserving algorithm [7, 39]. Furthermore, we were only allowed to collect TCP headers of the trafﬁc ﬂows, while we could not collect complete trafﬁc captures, due to privacy protection and legal reasons. OS Prediction Fingerprinter using Machine Learning/ Deep Learning Input features Packet Size Window Size TTL TCP Variant Oracle Predicted TCP Variant 1. Baseline Experiment 2. Oracle-based Experiment 3. Prediction-based Experiment Fig. 2: The process implemented on the intermediate node for passive OS ﬁngerprinting. Bytes in Flight Predicted TCP Variant Predicted cwnd Intercepted Traffic Deep Learning/LSTM Fig. 3: The process implemented on the monitor for prediction of the TCP variant of the passively intercepted TCP trafﬁc ﬂow. An LSTM-based machine learning module predicts the cwnd from the outstanding bytes-in-ﬂight. In the next step, the cwnd behavior is used to predict the TCP variant as explained in further detail in our previous works [11, 12, 13]. The predicted TCP variant is ﬁnally used as an input feature to the OS ﬁngerprinting process (see bottom right part of Figure 2). C. Emulated Trafﬁc In a real scenario where the OS ﬁngerprinting is going on continuously in an intermediate node of an enterprise or production network, the intermediate node will have more information available than only the TCP header, such as the trafﬁc proﬁle or the knowledge of congestion or the outstanding bytes-in-ﬂight of a ﬂow. In our experiments below, we show how this information can be very useful for OS ﬁngerprinting. Since we do not have full trafﬁc packet captures in our benchmark dataset or in our realistic dataset, we needed an additional dataset that we collected from an emulated network, where there would be no privacy protection or legal issues related to our dataset. The architecture of our emulated network is similar to the network setup shown in Figure 1, except that all the nodes (the sender, the intermediate node, and the receiver) are implemented in virtual machines. All background trafﬁc of the OSes for our emulated scenario is generated using the iperf [6]. Establishing ground truth is straightforward, as we have full control of the OSes used when generating the trafﬁc. In addition to establishing the ground truth, we also wanted to allow the intermediate node to establish a prediction of the TCP variant by monitoring the on-going trafﬁc proﬁle of the TCP ﬂow between the sender and the receiver. As shown later in the paper, using deﬁnitive or predicted knowledge of the TCP variant as an additional input feature to the OS ﬁngerprinting, might boost the ﬁngerprinting accuracy signiﬁcantly. How the machine learning model for prediction of the TCP variant in the emulated scenario is trained and how the TCP variant is subsequently predicted are presented in the following. IV. MACHINE LEARNING OF THE OS FINGERPRINTER A. Classical Machine Learning Approaches The OS ﬁngerprinter takes various features as input parameters, and use machine learning to predict the OS as shown in Figure 2. Many machine learning techniques could be used to implement a model for passive OS ﬁngerprinting. In this paper, we have employed the following most commonly used classical machine learning methods suitable for our task. In order to train and test our classiﬁcation models, we employed every experiment with a ratio of 60% training, 40% testing split, and 5-fold cross-validation setting on all variations of the features into one learning model. SVM: In order to perform an efﬁcient multi-class SVM classiﬁcation through cross-validation, we tuned the SVM hyperparameters using a GridSearchCV that allows specifying only the ranges of values for optimal parameters by parallelization construction of the model ﬁtting. Finally, in our evaluation, we found out that SVM with a Radial Basis Function (RBF) kernel for classiﬁcation model yields a substantially better result. Random Forest (RF): We tuned the meta-estimator by varying the number of decision trees between 1 and 1000. We found out that increasing the number of trees more than 10 doesn’t give much improvement in the classiﬁcation accuracy. KNN: We applied KNN by testing different values of K ranging from 5 to 100 followed by a weight function for a total of 20 observations. The observations have been conducted in two ways. In the ﬁrst experiment, we set the weight to uniform. In the second experiment, the points are weighted by the inverse of their distance, causing closer neighbors to have greater inﬂuence. Finally, we choose the model that has the highest accuracy for a given unseen instance. B. Deep Learning Approaches To ﬁnd the deeper characteristics of TCP variants implemented by respective OSes and exploit the extra OS-speciﬁc information, we apply the following two neural network architectures. Multilayer Perceptron (MLP): In our evaluation, MLP model with a single-layer feedforward neural network [16, 32] has been used to classify the different classes of OSes. After the hyperparameter tuning, we tested our MLP model with a different number of batch sizes, hidden layers, and nodes Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. (e.g., 0, 1, 2, 32, 64, 128) in each layer. Combining all of these, a total of 324 models were trained with and without the default TCP variant. We found out that the results for both with and without a known TCP variant were almost the same with an insigniﬁcant drop in the accuracy irrespective of which hyperparameters performed the best. Finally, 128 nodes of the network per dataset are trained for 150 epochs with a batch size of 500 by SGD with momentum of 0.9 and a constant learning rate of 0.01. However, we learned that SGD is sensitive in regards to the selection of the learning rate since it doesn’t automatize the values and we also found that it suffers from premature convergence and is outperformed by Adam-based optimization methods. Hence, both Adam and Nadam gradient-based optimization algorithms ﬁt for our purpose and that is because we wanted to use an optimization algorithm that adapts its learning rate dynamically in a way that doesn’t affect the objective function and learning process of the model. Our experimental results show that the hyperparameter tuning baseline experiments by applying tanh as activation function and Adam optimization algorithm and training the model for 150 epochs, provides a substantial improvement in accuracy as compared to the other parameters. Long Short-Term Memory (LSTM) models: We have explored an approach to classify the underlying OS from passive measurements using LSTM-based RNN architecture by combining the basic TCP/IP features and the underlying TCP variant shown in Table 2 as input vectors. For more details about LSTM applied in the context of computer networks, we refer the reader to our previous paper [12]. We trained our LSTM model over 150 epochs of the training samples with a batch size of 32 as values in time-series. We propagate the input feature vector (x) to the model through a multilayer LSTM cell followed by a fully connected dense layer of 150 hidden nodes with Rectiﬁed Linear Unit (ReLU) activation function using the hard sigmoid as recurrent activation for the different layers that generates an output of a sequence dimensional vector of predicted OSes (yt). We trained our LSTM-based learning algorithm without the knowledge of the input features from the true signatures of the OSes during the learning phase. We learn the model from the training data and then ﬁnally predict the test labels from the testing instances on all variations of the OS-speciﬁc parameters. In order to train our prediction model more quickly, and get a more stable and robust to changes OS classiﬁcation model, we have applied one of the most effective optimization algorithms in the deep learning community, the Adam stochastic algorithm [19] with an initial learning rate of 0.001 and exponential decay rates of the ﬁrst (β1) and second (β2) moments set to 0.9 and 0.999 respectively. We further optimize a wide range of important hyperparameters related to the neural network topology to improve the performance of our OS classiﬁcation model. C. Experimental Hardware Setup All our machine learning experiments are carried out using a cluster of HPC machines based upon the GNU/Linux operating system running a modiﬁed version of the 4.15.0-39-generic kernel release. The prediction model is performed on an NVIDIA Tesla K80 GPU accelerator computing with the following characteristics: Intel(R) Xeon(R) CPU E5-2670 v3 @2.30GHz, 64 CPU processors, 128 GB RAM, 12 CPU cores running under Linux 64-bit. All nodes in the cluster are connected to a low latency 56 Gbit/s Inﬁniband, gigabit Ethernet, and have access to 600 TiB of BeeGFS parallel ﬁle system storage. D. Objectives of our Experiments The aim of our experiments is to explore the effect of the TCP variant as an input feature when passively detecting the underlying OS. To investigate this, we divide our analysis into three different experiments. First, in the baseline experiment (Section VI) we carry out the OS ﬁngerprinting without using a known TCP variant as an input feature. This corresponds to the simplest state-of-the-art transport layer method, which is illustrated in the upper part of Figure 2. Since there is a close connection between existing popular OSes and the TCP variants they use, our hypothesis was that the potential for improvement by using the TCP variant as an input feature would be signiﬁcant. For example, CUBIC [9] is the default congestion control algorithm as part of the Linux kernel distribution conﬁgurations from version 2.6.19 onwards. Since Android devices are also Linux-powered, CUBIC remains to be the default TCP congestion control algorithm. Many Windows 7 distributions have been shipped with the default New Reno [15] and whereas Windows 8 families with CTCP [37]. Therefore, in the next Oracle-based experiment (Section VII), we investigate the potential of knowing the TCP variant, and how much this knowledge might boost the ﬁngerprinting accuracy. Here we assume that there is an Oracle that can identify and give the TCP variant used in the TCP ﬂow that is ﬁngerprinted. This is illustrated in the bottom left part of Figure 2. However, in a real scenario, the intermediate node would not have access to deﬁnite knowledge of the TCP variant (e.g., given by an Oracle). Instead, the intermediate node might at best try to infer it from the monitored trafﬁc. Thus, in the third prediction-based experiment (Section VIII), we ﬁrst allow the intermediate node to predict the TCP variant passively. This is illustrated in the bottom right part of Figure 2. The OS ﬁngerprinter then uses that TCP variant prediction as an input feature to make the OS prediction illustrated in the upper part of Figure 2. The TCP variant is predicted by analyzing the famous sawtooth pattern behavior of estimated cwnd of TCP, which is computed based on the outstanding bytes-in-ﬂight [12, 13]. This is presented in more detail in the next section. Since the latter experiment requires TCP trafﬁc details of outstanding bytes-in-ﬂight, which is not available in our benchmark and realistic datasets, this experiment is only possible with our emulated dataset. V. MACHINE LEARNING OF THE TCP VARIANT PREDICTION TOOL The main goal of the experiments in the emulated network is to use the predicted TCP variant as an additional input feature to the OS ﬁngerprinting. The TCP variant is predicted by the process illustrated in Figure 3. As described in sufﬁcient detail in our previous works [11, 12, 13], we used a database to match and join the intercepted TCP trafﬁc on both the intermediate node and the sending node. The outstanding bytes-in-ﬂight of the trafﬁc (i.e., the number of bytes that have been sent but not yet acknowledged) is used as input to our machine learning model to predict the cwnd behaviour of the trafﬁc. We use LSTM for the machine learning. We trained and veriﬁed the machine learning model by matching the Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. predicted TCP states with the actual TCP kernel states directly logged from the Linux kernel. Since we have full control of the sending nodes, we can track the system-wide TCP state of every packet that is sent and received from the kernel to verify our model’s prediction accuracy against the actual TCP variant by matching with the actual sending TCP states using the techniques presented in our previous works [11, 12, 13]. After the veriﬁcation, we can run our learning model and get the cwnd predictions of the TCP stack in use. Once we can estimate the cwnd of the sender, we can also infer the multiplicative back-off factor (β) which is an important feature for uniquely identifying the TCP variants. Finally, we combine the predicted TCP variant as the basis of OS ﬁngerprinting with the basic TCP/IP features as shown in Figure 2. Here, we consider only loss-based TCP congestion control algorithms, e.g., BIC [40], CUBIC [9], CTCP [37], Reno [17], and New Reno [15]. Delay-based TCP variants are investigated in a follow-on paper [14]. Our approach could also be useful to other TCP variants like Google’s QUIC [21]. QUIC uses packet loss as an indicator of congestion and supports a number of different congestion control algorithms, including CUBIC [9] and BBR [3]. VI. BASELINE EXPERIMENT: RESULTS WITHOUT KNOWING THE TCP VARIANT Here we present the results of the machine learning and deep learning techniques under all the validation scenarios presented above without a known underlying TCP variant which will play the role of baseline for the other evaluations. A. Based on Benchmark Data from Previous Related Work Looking at Tables I and II, both machine learning and deep learning classiﬁcation techniques have consistently achieved good levels of precision and recall for all general classes of OSes except iOS. Quantitatively, iOS, and Mac OS devices were underrepresented in the benchmark data from previous related work. Besides, as it is shown in Figures 4, there is a slightly higher misclassiﬁcation of iOS as unknown and this is why the precision and recall of iOS are comparably lower than the rest of OSes. We also believe that the limited TCP/IP stack basic features could contribute to the indistinguishability and misclassiﬁcation of OS classes with the same kernel implementation. The false positives are easier to notice in the corresponding confusion matrices. TABLE I: Benchmark data [22] experimental results without a known TCP variant using SVM, RF, and KNN. SVM RF KNN OS Precission Recall Precision Recall Precision Recall Android 0.74 0.88 0.87 0.91 0.87 0.91 Linux 0.85 0.85 0.91 0.90 0.91 0.90 Mac OS 0.65 0.77 0.61 0.83 0.58 0.88 Other 0.91 0.81 0.92 0.81 0.92 0.81 Unix 0.91 0.99 0.94 0.99 0.94 0.99 Windows 0.97 0.88 0.98 0.91 0.98 0.91 iOS 0.73 0.55 0.72 0.53 0.79 0.47 Average 0.83 0.82 0.85 0.84 0.86 0.84 Accuracy 81.96% 84.07% 83.95% B. Based on Realistic Trafﬁc Our performance results of the realistic trafﬁc without a known TCP variant using the machine learning and deep techniques are presented in Tables III and IV respectively. The respective confusion matrices are presented in Figures 5. TABLE II: Benchmark data [22] experimental results without a known TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.75 0.92 0.77 0.85 Linux 0.90 0.82 0.83 0.85 Mac OS 0.62 0.81 0.58 0.83 Other 1.00 0.74 0.91 0.81 Unix 0.94 0.99 0.94 0.99 Windows 0.97 0.91 0.97 0.86 iOS 0.67 0.57 0.79 0.48 Average 0.84 0.82 0.83 0.81 Accuracy 82.16% 81.04% TABLE III: Realistic trafﬁc experimental results without a known TCP variant using SVM, RF, and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.75 0.89 0.86 0.90 0.84 0.93 Linux 0.89 0.82 0.94 0.89 0.93 0.88 Mac OS 0.63 0.81 0.61 0.82 0.61 0.82 Unix 0.94 0.99 0.94 0.99 0.94 0.99 Windows 0.97 0.89 0.98 0.89 0.98 0.89 iOS 0.88 0.72 0.86 0.73 0.88 0.72 Average 0.85 0.83 0.86 0.85 0.87 0.85 Accuracy 83.43% 85% 85.10% TABLE IV: Realistic trafﬁc experimental results without a known TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.81 0.83 0.76 0.86 Linux 0.89 0.79 0.90 0.81 Mac OS 0.61 0.82 0.82 0.79 Unix 0.92 0.99 0.94 0.99 Windows 0.98 0.89 0.97 0.89 iOS 0.84 0.73 0.70 0.92 Average 0.84 0.83 0.83 0.84 Accuracy 83.91% 83.27% C. Based on Emulated Trafﬁc Our performance results of the emulated trafﬁc without a known TCP variant as an input feature using both machine learning and deep learning techniques are presented in Tables V and VI respectively. As we can see in the corresponding confusion matrices presented in Figures 6, there is a slightly inaccurate classiﬁcation of the Mac OS due to its underrepresentation. The precision and recall for the rest of the OSes using machine learning and deep learning techniques are reasonably good. TABLE V: Emulated trafﬁc experimental results without a known TCP variant using SVM, RF and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.74 0.90 0.86 0.90 0.85 0.91 Linux 0.92 0.82 0.94 0.89 0.92 0.90 Mac OS 0.63 0.81 0.61 0.82 0.61 0.82 Unix 0.94 0.99 0.94 0.99 0.94 0.99 Windows 0.97 0.89 0.98 0.89 0.98 0.89 iOS 0.88 0.73 0.86 0.73 0.88 0.73 Average 0.85 0.84 0.86 0.85 0.87 0.85 Accuracy 84.67% 85.73% 85.27% D. Comparison of Results Without Known TCP Variant As shown in Tables I, II, III, IV, V, and VI, our experimental results are pretty consistent. Firstly, we can see that there is not much difference in performance across different machine learning and deep learning techniques. But more importantly, there are not many differences in performance between results from using different types of Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. (a) SVM (b) KNN (c) RF (d) MLP (e) LSTM Fig. 4: Confusion matrix comparison of the machine learning and deep learning techniques using the benchmark data [22]. (a) SVM (b) KNN (c) RF (d) MLP (e) LSTM Fig. 5: Confusion matrix comparison of the machine learning and deep learning techniques using a realistic trafﬁc. TABLE VI: Emulated trafﬁc experimental results without a known TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.75 0.88 0.91 0.85 Linux 0.93 0.78 0.92 0.74 Mac OS 0.62 0.81 0.86 0.88 Unix 0.92 0.99 0.94 1.00 Windows 0.93 0.91 0.98 0.73 iOS 0.88 0.73 0.82 1.00 Average 0.85 0.83 0.89 0.88 Accuracy 84.05% 88.44% experimental data. This is intuitively correct, since the OS ﬁngerprinting is based on the basic TCP/IP packet ﬁelds, and should not differ much between various types of data, whether we do evaluation using the benchmark data, real data or emulated data. Secondly, we believe accuracy in the range of 82-88% (average value) is perhaps not sufﬁcient for a product in a real deployment. Our hypothesis is that this accuracy could be boosted considerably had we only known the implementation of the underlying TCP variant. We will explore this hypothesis in the next section. VII. ORACLE-BASED EXPERIMENT: RESULTS USING ORACLE-GIVEN TCP VARIANT Here we assume that we know exactly the underlying TCP variant, i.e., we assume it is given by an Oracle. We show that knowledge of the TCP variant has a great potential for boosting passive ﬁngerprinting of OSes, and in this section, we will try to quantify this potential. In the next section, we will show that much of this potential can be harvested by using a tool that predicts the TCP variant. A. Based on Benchmark Data from Previous related Work Tables VII and VIII show a signiﬁcant performance gain across all classes of OSes when we assume prior knowledge of the underlying TCP variant, as compared to the results when the TCP variant is unknown presented in Tables I and II. TABLE VII: Benchmark data [22] experimental results with Oracle-given TCP variant using SVM, RF and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.96 0.99 0.99 0.98 0.99 0.98 Linux 0.86 0.95 0.92 0.95 0.93 0.94 Mac OS 0.98 0.89 0.97 0.92 0.97 0.92 Other 0.93 0.81 0.93 0.81 0.90 0.83 Unix 1.00 1.00 1.00 1.00 1.00 1.00 Windows 0.99 0.89 0.97 0.92 0.99 0.91 iOS 0.75 0.89 0.75 0.91 0.76 0.91 Average 0.92 0.92 0.93 0.93 0.93 0.93 Accuracy 91.71% 92.73% 92.69% TABLE VIII: Benchmark data [22] experimental results with Oracle-given TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.96 0.97 0.94 0.97 Linux 0.89 0.92 0.88 0.93 Mac OS 0.96 0.92 0.97 0.88 Other 0.93 0.81 0.84 0.84 Unix 1.00 1.00 1.00 1.00 Windows 0.96 0.92 0.98 0.84 iOS 0.76 0.89 0.73 0.83 Average 0.92 0.92 0.91 0.90 Accuracy 91.91% 90.03% B. Based on Realistic Trafﬁc The performance results of the realistic trafﬁc with the Oracle-given TCP variant presented in Tables IX and X show the potential of knowing TCP variant given by an Oracle for passive OS ﬁngerprinting in a realistic scenario. TABLE IX: Realistic trafﬁc experimental results with Oracle-given TCP variant using SVM, RF and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.95 1.00 0.99 0.98 0.99 0.98 Linux 0.86 0.91 0.94 0.93 0.92 0.94 Mac OS 0.99 0.90 0.96 0.92 0.97 0.92 Unix 1.00 1.00 1.00 1.00 1.00 1.00 Windows 0.99 0.89 0.99 0.89 0.99 0.89 iOS 0.93 0.96 0.91 0.99 0.92 0.98 Average 0.95 0.95 0.96 0.96 0.96 0.96 Accuracy 94.81% 95.65% 95.69% Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. TABLE X: Realistic trafﬁc experimental results with Oracle-given TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.98 0.97 0.98 0.97 Linux 0.92 0.92 0.90 0.93 Mac OS 0.96 0.92 0.96 0.92 Unix 1.00 1.00 1.00 1.00 Windows 0.97 0.91 0.99 0.88 iOS 0.92 0.97 0.91 0.98 Average 0.95 0.95 0.95 0.95 Accuracy 94.98% 94.89% C. Based on Emulated Trafﬁc Our performance results of the emulated trafﬁc with the Oracle-given TCP variant using both classical machine learning and deep learning techniques are presented in Tables XI and XII. We can see that this shows a signiﬁcant improvement in performance over the results without a known TCP variant presented in Tables V and VI. Both machine learning and deep learning techniques have comparable and consistent results in terms of accuracy. TABLE XI: Emulated trafﬁc experimental results with the Oracle-given TCP variant using SVM, RF, and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.97 0.98 0.99 0.98 0.99 0.98 Linux 0.90 0.91 0.95 0.93 0.92 0.95 Mac OS 0.99 0.90 0.97 0.92 0.97 0.92 Unix 1.00 1.00 1.00 1.00 1.00 1.00 Windows 0.99 0.89 0.97 0.91 0.97 0.91 iOS 0.91 0.98 0.92 0.98 0.93 0.97 Average 0.95 0.95 0.96 0.96 0.96 0.96 Accuracy 95.10% 96.02% 95.83% TABLE XII: Emulated trafﬁc experimental results with the Oracle-given TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.98 0.97 0.96 0.98 Linux 0.97 0.89 0.93 0.91 Mac OS 0.93 0.94 0.94 0.92 Unix 1.00 1.00 1.00 1.00 Windows 0.99 0.89 0.98 0.88 iOS 0.91 0.99 0.91 0.97 Average 0.95 0.95 0.95 0.95 Accuracy 95.24% 95.08% D. Comparison of Results with Oracle-given TCP Variant Our accuracy results presented in Tables VII, VIII, IX, X, XI, and XII, demonstrate that by knowing the TCP variant we obtain a considerable performance boost in all our experimental results, compared to our previous results obtained without knowledge of the TCP ﬂavor. With an Oracle-given TCP variant, we obtain a prediction accuracy of 94-96%, with an average value of 94.1% over all trafﬁc classes and of 95.4% over only emulated trafﬁc. The accuracy results are pretty consistent across all scenarios. Comparing these results with our previous results that do not use the Oracle (84.1% on average for all trafﬁc types and 85.6% only for emulated trafﬁc), we observe a solid increase in the OS ﬁngerprinting performance. This improvement would signiﬁcantly boost the usefulness of a product to be implemented in a real enterprise network infrastructure. As in the previous section, here again, we observe highly consistent performance results across different machine learning and deep learning techniques and also between the use of different types of experimental data. The latter is useful knowledge for the next section since it means that performance increases obtained over one trafﬁc type is shown to be amenable to other trafﬁc types as well. In the next section, we will have to base our evaluation on emulated data, since we do not have the TCP trafﬁc patterns of the realistic data or benchmark data at hand. These trafﬁc patterns are required to be able to passively infer the TCP variant in the experiments presented in the next section. In this section, the idealistic Oracle was used only to demonstrate the potential of knowing the TCP variant, but this is not a realistic assumption. Thus, in the next section, we will instead base our evaluation on a TCP variant that is passively predicted by a deep learning-based tool that we developed and presented in our previous work [11, 12, 13]. Using this tool, we explore how close our performance will get to the ideal solution of having an Oracle. VIII. PREDICTION-BASED EXPERIMENT: RESULTS USING TCP VARIANT PREDICTION In Section VII, we showed that Oracle-given knowledge of the TCP variant has a great potential for improving the passive OS ﬁngerprinting. In reality, however, we don’t have an Oracle-given TCP variant. Since passively detecting the TCP variant is a challenging task, this is where our tool from previous works on predicting the underlying TCP variant from passive measurements [11, 12, 13] comes into play. In this Section we use the TCP variant passively predicted by this tool as an input feature for the passive OS ﬁngerprinting. The TCP variant is inferred from the famous Additive Increase and Multiplicative Decrease (AIMD) sawtooth pattern of TCP’s estimated cwnd computed based on the outstanding bytes-in-ﬂight. Since we don’t have access to the actual cwnd of the senders in the benchmark data and realistic trafﬁc, here we consider only the emulated trafﬁc. A. Based on Emulated Trafﬁc In this section, we use a tool to predict the TCP variant from passive measurements of TCP trafﬁc patterns, and this prediction is used as input to the passive OS ﬁngerprinting method presented above. The experimental results of both techniques are presented in Tables XIII and XIV. TABLE XIII: Emulated trafﬁc experimental results with predicted TCP variant using SVM, RF, and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.92 0.96 0.92 0.97 1.00 0.97 Linux 0.79 0.85 0.94 0.82 0.92 0.94 Mac OS 0.96 0.88 0.97 0.87 0.85 0.94 Unix 1.00 1.00 1.00 1.00 1.00 1.00 Windows 0.92 0.78 0.85 0.80 0.88 0.91 iOS 0.85 0.94 0.86 0.96 0.93 0.87 Average 0.90 0.90 0.91 0.91 0.93 0.93 Accuracy 90.01% 91.09% 92.15% TABLE XIV: Emulated trafﬁc experimental results with predicted TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.95 0.97 0.92 0.96 Linux 0.98 0.79 0.86 0.90 Mac OS 0.95 0.90 0.95 0.88 Unix 1.00 1.00 1.00 1.00 Windows 0.94 0.77 0.97 0.77 iOS 0.82 0.99 0.88 0.96 Average 0.92 0.91 0.92 0.92 Accuracy 91.45% 91.93% Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. (a) SVM (b) KNN (c) RF (d) MLP (e) LSTM Fig. 6: Confusion matrix comparison of the machine learning and deep learning techniques using an emulated trafﬁc. B. Comparison of results with a predicted TCP variant Results with emulated data and a passive prediction of the TCP variant (Tables XIII and XIV) gives an accuracy of 91.3% on average, which comes pretty close to the accuracy of 95.4% obtained on emulated trafﬁc with the TCP-variant given by the Oracle. Intuitively, when we do learning based on the TCP variant prediction, the accuracy must be lower than the Oracle-given TCP variant, but the question is how close we can get to the idealistic scenario of having an Oracle. Our results show that using our tool for TCP variant prediction gives reasonably good OS ﬁngerprinting accuracies that come close to the results obtained by using Oracle-given TCP variant. Even though the performance results with the TCP variant passively predicted by our deep learning-based tool are slightly lower as compared to the TCP variant given by an idealistic Oracle, our performance results of using our tool are reasonably competitive. IX. TRANSFER LEARNING RESULTS Transfer learning is the ability to take a model trained in one scenario and apply it for classiﬁcation in a different scenario. For example, in our case, that means we are able to train our model on a dataset created in an emulated network with an Oracle-given TCP variant and apply it for classiﬁcation of our dataset from the realistic trafﬁc. Results shown in Tables XV and XVI shows that the learning of the OS ﬁngerprinter transfers well into other scenarios. Good transfer learning results indicate that our passive OS ﬁngerprinting model is able to discern the results of unforeseen scenarios and still perform reasonably well. In previous works, we have also demonstrated that the TCP variant predictor performs well in terms of transfer learning [11, 12, 13]. TABLE XV: Transfer learning experimental results using SVM, RF, and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.95 1.00 0.98 0.98 0.99 0.98 Linux 0.86 0.91 0.90 0.95 0.92 0.95 Mac OS 0.99 0.90 0.98 0.92 0.97 0.92 Unix 1.00 1.00 1.00 1.00 1.00 1.00 Windows 0.99 0.89 0.98 0.90 0.97 0.91 iOS 0.93 0.96 0.93 0.97 0.93 0.97 Average 0.95 0.95 0.95 0.95 0.96 0.96 Accuracy 94.79% 95.35% 95.76% X. CONCLUSION AND FUTURE WORK In this paper, we proposed and evaluated a novel approach that attempts to passively ﬁngerprint the underlying remote OS by leveraging state-of-the-art machine learning and deep learning techniques under multiple controlled scenarios. We TABLE XVI: Transfer learning experimental results using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.97 0.98 0.97 0.96 Linux 0.95 0.85 0.91 0.91 Mac OS 0.94 0.94 0.96 0.90 Unix 1.00 1.00 1.00 1.00 Windows 0.99 0.89 0.98 0.87 iOS 0.90 0.98 0.90 0.98 Average 0.95 0.95 0.94 0.94 Accuracy 94.72% 94.28% show that knowing the Oracle-given TCP variant has a great potential for boosting the classiﬁcation performance of passive OS ﬁngerprinting. In our setting, we demonstrate that using the idealistic Oracle has the potential to boost the prediction accuracy from 84.1% to 94.1% on average across all trafﬁc types tested, and from 85.6% to 95.4% in an emulated setting. However, in reality, we don’t have the Oracle-given TCP variant and hence we don’t know exactly the underlying TCP ﬂavor. To address this, we demonstrated a method for passive OS ﬁngerprinting where the cwnd is ﬁrst computed based on the outstanding bytes-in-ﬂight, then the underlying TCP ﬂavor is predicted from the estimated cwnd, and ﬁnally, the predicted TCP variant is used as an input feature to detect the remote computer’s OS. This is an additional feature that is added to the basic TCP/IP features that are the basis of OS ﬁngerprinting in previous works. We demonstrate that our method performs signiﬁcantly better than not using the predicted TCP variant as an input feature, increasing the accuracy in our experiment from 85.6% to 91.3%. The results of this method come close to the accuracy of 95.4% obtained by using the idealistic Oracle. To the best of our knowledge, this is the ﬁrst study that reports the potential of the underlying TCP feature in boosting signiﬁcantly the accuracy of passive OS ﬁngerprinting. We further validate and demonstrate the transferability approach of our OSes classiﬁcation models by conducting a series of controlled experiments against other scenarios. Through comparing the experimental results between the benchmark dataset, realistic, and emulated trafﬁc in terms of accuracy and confusion matrix, it is clear that our passive OSes classiﬁcation models are able to discern the results to unforeseen scenarios. Therefore, we are able to show that the learned passive OS ﬁngerprinting model by leveraging a pre-trained knowledge of classiﬁcation techniques from the emulated network performs reasonably well as it is shown in the experimental results when it is applied and transferred to a realistic scenario. Lastly, in all our experiments, we made sure that both the training and validation accuracies are closer which gives an idea about the ability of the OSes classiﬁcation models to generalize on unforeseen scenarios. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. The method presented in this paper, where the cwnd is ﬁrst computed based on the outstanding bytes-in-ﬂight, then the underlying TCP ﬂavor is predicted from the estimated cwnd, is particularly efﬁcient for loss-based TCP variants. In previous works, we have also developed a tool for the prediction of delay-based TCP ﬂavors [10]. We plan to extend the method presented in this paper to also cover delay-based TCP variants and present it in a follow-on paper [14]. Note that passively detecting the TCP variant is a challenging task, which led to a two-step approach, where the TCP variant prediction of a deep learning-based tool is used as input to another machine learning method in the next step. However, by integrating the two machine learning approaches better, there should be potential for increasing the performance even further and get even closer to the idealistic results of using an Oracle. Exploring such optimizations is also left for future work. It is known that TCP clock drift improves OS ﬁngerprinting and hence measuring differences in the timing of how the IP stack works may allow us to predict the underlying OS with greater assurance in terms of accuracy. We, therefore, argue for using other TCP options like timestamps and queueing delay characteristics as an input feature vector for passive OSes ﬁngerprinting model as another interesting direction. Finally, in addition to the difﬁculties of establishing ground truth (e.g., the TCP variant) at a larger scale on a dynamic network addressed in Section III, there is a lot of other work to be done as an extension of our work presented here. For example, addressing answers to valid questions like: What happens if an end-user (client) changes default parameters that are the basis of OS ﬁngerprinting? is one possibility for our future work. We expect that end-users don’t change parameters often, while servers may do so if it helps improve performance. We believe this would make OS ﬁngerprinting potentially hard. REFERENCES [1] 5G4IoT. 5G4IoT, 2019. [2] A. Aksoy, S. Louis, and M. H. Gunes. Operating system ﬁngerprinting via automated network trafﬁc analysis. In IEEE Congress on Evolutionary Computation (CEC). IEEE, 2017. [3] N. Cardwell, Y. Cheng, C. S. Gunn, S. H. Yeganeh, and V. Jacobson. BBR: Congestion-based congestion control. 2016. [4] W. R. Cheswick, S. M. Bellovin, and A. D. Rubin. Firewalls and Internet security: repelling the wily hacker. Addison-Wesley Longman Publishing Co., Inc., 2003. [5] N. Davids. Initial TTL values, 2011. [6] ESnet. iperf3, 2017. [7] J. Fan, J. Xu, M. H. Ammar, and S. B. Moon. Preﬁx-preserving IP address anonymization: measurement-based security evaluation and a new cryptography-based scheme. 2004. [8] L. G. Greenwald and T. J. Thomas. Toward Undetected Operating System Fingerprinting. WOOT, 7:1–10, 2007. [9] S. Ha, I. Rhee, and L. Xu. CUBIC: a new TCP-friendly high-speed TCP variant. ACM SIGOPS, 2008. [10] D. H. Hagos, P. E. Engelstad, and A. Yazidi. Classiﬁcation of Delay-based TCP Algorithms From Passive Trafﬁc Measurements. In 18th NCA. IEEE, 2019. [11] D. H. Hagos, P. E. Engelstad, A. Yazidi, and Ø. Kure. A machine learning approach to TCP state monitoring from passive measurements. pages 164–171. IEEE, 2018. [12] D. H. Hagos, P. E. Engelstad, A. Yazidi, and Ø. Kure. Recurrent Neural Network-based Prediction of TCP Transmission States from Passive Measurements. In NCA, pages 1–10. IEEE, 2018. [13] D. H. Hagos, P. E. Engelstad, A. Yazidi, and Ø. Kure. Towards a Robust and Scalable TCP Flavors Prediction Model from Passive Trafﬁc. In 2018 27th ICCCN, pages 1–11. IEEE, 2018. [14] D. H. Hagos, A. Yazidi, P. E. Engelstad, and Ø. Kure. A Deep Learning-based Universal Tool for Operating Systems Fingerprinting from Passive Measurements. 2020. Submitted for publication. [15] T. Henderson, S. Floyd, A. Gurtov, and Y. Nishida. The NewReno modiﬁcation to TCP’s fast recovery algorithm. RFC 6582, 2012. [16] K. Hornik, M. Stinchcombe, and H. White. Multilayer feedforward networks are universal approximators. Neural networks, 1989. [17] V. Jacobson. Congestion avoidance and control. In ACM SIGCOMM computer communication review. ACM, 1988. [18] V. Jacobson, R. Braden, and D. Borman. TCP extensions for high performance. RFC 1323, 1992. [19] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. [20] T. Kohno, A. Broido, and K. C. Claffy. Remote physical device ﬁngerprinting. IEEE, 2005. [21] A. Langley, A. Riddoch, A. Wilk, A. Vicente, C. Krasic, D. Zhang, F. Yang, F. Kouranov, I. Swett, J. Iyengar, et al. The quic transport protocol: Design and internet-scale deployment. pages 183–196. ACM, 2017. [22] M. Lastovicka, T. Jirsik, P. Celeda, S. Spacek, and D. Filakovsky. Passive os ﬁngerprinting methods in the jungle of wireless networks. In NOMS. IEEE, 2018. [23] R. Lippmann, D. Fried, K. Piwowarski, and W. Streilein. Passive operating system identiﬁcation from TCP/IP packet headers. In Data Mining for Computer Security. Citeseer, 2003. [24] R. Lippmann, S. Webster, and D. Stetson. The effect of identifying vulnerabilities and patching software on the utility of network intrusion detection. Springer, 2002. [25] G. F. Lyon. Remote OS detection via TCP/IP stack ﬁngerprinting. Phrack Magazine, 8(54), 1998. [26] G. F. Lyon. Nmap network scanning: The ofﬁcial Nmap project guide to network discovery and security scanning. 2009. [27] Netresec. NetworkMiner, 2007. [28] A. Ornaghi and M. Valleri. Ettercap, 2015. [29] J. Postel. Internet control message protocol. RFC 792, 1981. [30] J. Postel. Internet protocol. RFC 791, 1981. [31] J. Postel. Transmission control protocol. RFC 793, 1981. [32] F. Rosenbaltt. The perceptron–a perciving and recognizing automation. Cornell Aeronautical Laboratory, 1957. [33] J. Scambray, S. McClure, and G. Kurtz. Hacking exposed. McGraw-Hill Professional, 2000. [34] SCOTT. European Leadership Joint Undertaking, 2019. [35] R. Spangler. Analysis of remote active operating system ﬁngerprinting tools. University of Wisconsin, 2003. [36] G. Taleck. Synscan: Towards complete tcp/ip ﬁngerprinting. CanSecWest, Vancouver BC, Canada, pages 1–12, 2004. [37] K. Tan, J. Song, Q. Zhang, and M. Sridharan. A compound TCP approach for high-speed and long distance networks. In Proceedings IEEE INFOCOM, 2006. [38] W. Wei, K. Suh, B. Wang, Y. Gu, J. Kurose, and D. Towsley. Passive online rogue access point detection using sequential hypothesis testing with TCP ACK-pairs. ACM, 2007. [39] J. Xu, J. Fan, M. Ammar, and S. B. Moon. On the design and performance of preﬁx-preserving IP trafﬁc trace anonymization. In ACM SIGCOMM, pages 263–266. ACM, 2001. [40] L. Xu, K. Harfoush, and I. Rhee. Binary increase congestion control (BIC) for fast long-distance networks. IEEE, 2004. [41] F. Yarochkin and O. Arkin. Xprobe2- A’Fuzzy’Approach to Remote Active Operating System Fingerprinting, 2002. [42] M. Zalewski. p0f: Passive OS ﬁngerprinting tool. Online at 2017. [43] B. Zhang, T. Zou, Y. Wang, and B. Zhang. Remote operation system detection base on machine learning. IEEE, 2009. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply."
"Artificial intelligence in the fertility clinic: status, pitfalls and possibilities","Riegler, M A and Stensen, M H and Witczak, O and Andersen, J M and Hicks, S A and Hammer, H L and Delbarre, E and Halvorsen, P and Yazidi, A and Holst, N and Haugen, T B",2021,9.0,36,Human Reproduction,article,"...................................................................
Artificial intelligence in the fertility
clinic: status, pitfalls and possibilities
M.A. Riegler
1,*, M.H. Stensen2, O. Witczak3, J.M. Andersen3,
S.A. Hicks1,4, H.L. Hammer1,4, E. Delbarre
3, P. Halvorsen1,4,
A. Yazidi4, N. Holst2, and T.B. Haugen3
1Department of Holistic Systems, Simula Metropolitan Center for Digital Engineering, Oslo, Norway 2Fertilitetssenteret, Oslo, Norway
3Department of Life Sciences and Health, Faculty of Health Sciences, OsloMet—Oslo Metropolitan University, Oslo, Norway
4Department of Computer Science, Faculty of Technology, Art and Design, OsloMet—Oslo Metropolitan University, Oslo, Norway
*Correspondence address. Department of Holistic Systems, Simula Metropolitan Center for Digital Engineering, Oslo 0167, Norway.
E-mail: michael@simula.no
https://orcid.org/0000-0002-3153-2064
Submitted on May 19, 2021; resubmitted on June 21, 2021; editorial decision on June 23, 2021
ABSTRACT: In recent years, the amount of data produced in the ﬁeld of ART has increased exponentially. The diversity of data is large,
ranging from videos to tabular data. At the same time, artiﬁcial intelligence (AI) is progressively used in medical practice and may become
a promising tool to improve success rates with ART. AI models may compensate for the lack of objectivity in several critical procedures in
fertility clinics, especially embryo and sperm assessments. Various models have been developed, and even though several of them show
promising performance, there are still many challenges to overcome. In this review, we present recent research on AI in the context of
ART. We discuss the strengths and weaknesses of the presented methods, especially regarding clinical relevance. We also address the pit-
falls hampering successful use of AI in the clinic and discuss future possibilities and important aspects to make AI truly useful for ART.
Key words: artiﬁcial intelligence / machine learning / ART / embryology / semen analysis / embryo / spermatozoa / fertility / infertility /
algorithm
Introduction
The number of treatments with ART is steadily increasing in Europe,
and in 2016, over 900 000 treatment cycles were performed (Wyns
et al., 2020). Even though there have been gradual improvements in
the success rate, only one-third of the ART cycles result in a live birth,
and only 5% of the aspirated oocytes have the competence to develop
into a child (Lemmen et al., 2016; Wyns et al., 2020). This implies that
there is potential for improvement in the crucial steps in ART treat-
ments, such as the selection of embryos for transfer and the selection
of spermatozoa for ICSI. Improving the ability to select a single em-
bryo with the highest implantation potential could increase live birth
rates and time to pregnancy, as well as minimise the chance of multi-
ple pregnancies due to the transfer of multiple embryos. Likewise, a
more reliable method for sperm selection may increase the success
rates of the ICSI procedure. Furthermore, the disputable clinical value
of semen analysis in male fertility investigation and for ART justifies a
need for improving the methods of sperm evaluation both for diagnos-
tic purposes and for decisions regarding the fertilisation method of the
ART treatment.
Video and image analysis constitutes a major part of ART, and
artificial intelligence (AI) methods are especially suited for image
classification. In addition to videos and images, AI can be used to ana-
lyse other types of data, like text or tabular data. As in other parts of
medicine, AI methods have been introduced in the field of ART. They
have the advantage of objectivity and have the potential to improve
ART, which in some parts are based on subjective assessments.
In this review, we provide an overview of studies found in Embase
(Ovid), where AI methods have been applied in human reproductive
medicine with an emphasis on ART. Furthermore, we discuss how to
avoid the pitfalls and describe the potential use of AI in clinical practice
in the future.
Current challenges in ART
Highly trained personnel in fertility clinics are faced with important and
difficult decisions every day, such as deciding which fertilisation method
to use, which spermatozoon to select for ICSI, and which embryo to
transfer to the uterus. One of the major challenges in the subjective
assessments of embryos is the high intra- and inter-operator variability
which exists in the evaluation of morphology and morphokinetics
(Paternot et al., 2009; Sundvall et al., 2013; Storr et al., 2017). With
time-lapse technology, embryos can be monitored continuously, and
V
C The Author(s) 2021. Published by Oxford University Press on behalf of European Society of Human Reproduction and Embryology. All rights reserved.
For permissions, please email: journals.permissions@oup.com
Human Reproduction, Vol.36, No.9, pp. 2429–2442, 2021
Advance Access Publication on July 29, 2021
doi:10.1093/humrep/deab168
MINI REVIEW
 .............................................................................................................................................................................
the complete process of embryo development is more precisely
assessed. However, there is no evidence that the use of time-lapse
technology has improved live birth rates after ART (Armstrong et al.,
2019).
Whilst sperm morphology has no definite impact on the outcome
after ART, sperm concentration and sperm motility are normally
assessed for deciding whether IVF or ICSI should be used as the fertil-
isation method (Høst et al., 2001). Strikingly, ICSI is increasingly used
irrespective of a male factor infertility diagnosis (Boulet et al., 2015;
Vander Borght and Wyns, 2018). Among the cycles reported in
Europe in 2016, 28% were IVF and 72% ICSI (Wyns et al., 2020), al-
though the male factor accounts for only 20–30% of the diagnoses of
the infertile couples. This is of increasing concern since performing
ICSI instead of IVF in couples where the male partner has a defined
normal semen sample does not increase the live birth rate (Dang
et al., 2021).
Early in the fertility investigation, a standard semen analysis accord-
ing to WHO guidelines (WHO, 2010) is usually performed. This analy-
sis might reveal information essential for deciding whether ART should
be recommended as a treatment. The method is time-consuming and
prone to limited reproducibility and high inter-personnel variation
(Tomlinson, 2016). Several computer-aided sperm analyses (CASA)
systems are available, but they are still most suitable for assessing sper-
matozoa separated from seminal plasma, and their reliability is debat-
able (Mortimer et al., 2015).
When selecting spermatozoa to inject for ICSI, the procedure is
performed by visually evaluating the morphology and motility of sper-
matozoa with an ICSI microscope. This selection process is subjective,
based on a qualitative evaluation of the operator, and not on objective
sperm characteristics.
The potential of AI in ART
New technologies, such as better cameras and data capturing systems,
are rapidly becoming an integrated part of the fertility clinic and result
in a vast amount of stored data, including patient data, embryo time-
lapse videos and sperm videos. In recent years, AI has proved to be a
valuable tool in medicine by analysing large amounts of data (Hosny
et al., 2018; Yang and Bang, 2019). A typical approach for using AI
models in ART can be seen in Fig. 1. In particular, machine learning
(ML), a subfield within AI, refers to algorithms that automatically learn
from data without being explicitly programmed.
An overview of common AI methods used in ART is given in
Fig. 2. Supervised and unsupervised learning are subgroups of ML.
Supervised learning refers to methods that learn from datasets
where the answer (the label) is given for each observation. An ob-
servation within a dataset could be data from an ART cycle, like
an embryo image, and the label regarding whether the embryo
resulted in a pregnancy or not. The algorithm will learn from the
dataset, and the resulting ML model can be used to predict preg-
nancy or not for data from another ART cycle with unknown
labels. Unsupervised learning refers to methods that search for
patterns in unlabelled data, for example, automatically grouping
blastocyst images based on visual features automatically deter-
mined by the algorithm that may correlate with morphological
characteristics. Such visual features can be completely different
from what human observers are able to recognise or may see as
relevant. Artificial neural networks (ANNs) are a class of super-
vised learning, and deep neural networks (DNNs), or deep learn-
ing (DL), refers to especially large and complex ANNs. DL
methods have the ability to learn from unstructured data such as
images or text.
Details of studies discussed in this review can be found in Table I
for embryo related articles and in Table II for sperm related articles.
AI in embryo assessment
Most articles about embryo assessment and selection for transfer
address the prediction of embryo quality, grading and ranking, and
compare the performance of the AI model with an evaluation done by
embryologists (Dirvanauskas et al., 2019; Kanakasabapathy et al., 2019;
Khosravi et al., 2019; Raudonis et al., 2019; Fukunaga et al., 2020;
Bormann et al., 2020a, 2020b; Rad et al., 2020; Zhao et al., 2021). To
make an automatic grading system, the model must learn to locate the
embryo in the dish, segment important features, and then assess and
grade the embryo from manually annotated data. Manual annotations
provided by embryologists are time-consuming to create, leading to
small and sparsely annotated datasets. Therefore, most studies of AI
methods and resulting models in ART can be considered preliminary.
With the development of time-lapse technology, access to image and
video data has become more available, making it possible to utilise this
data to build new AI models. Dirvanauskas et al. (2019) predicted em-
bryo development stages by time-lapse videos using features extracted
from a Convolutional Neural Network (CNN). In one study, an auto-
mated system was established to detect pronuclei in time-lapse images
with the precision almost equivalent to highly skilled embryologists
(Fukunaga et al., 2020). In another study, the zona pellucida (ZP) and
the cytoplasm and pronucleus in zygotes were detected by developing
an algorithm using DL image segmentation technology (Zhao et al.,
2021). One group reported the possibility of identifying human em-
bryo development stages (Raudonis et al., 2019). First, the location of
an embryo in the image was detected by employing a visual image
feature-based classifier. Then, a multi-class prediction model was de-
veloped to predict the cell stage of the embryo using DL. Others
reported a system to detect and assess blastocyst quality by using DL
to detect the ZP area (Rad et al., 2018).
Data augmentation techniques, like cropping and resizing which are
usually used to increase dataset size or variation, were applied to em-
bryo assessment to compensate for the lack of data for training the
DL models (Rad et al., 2020). Augmented images were proven to be
effective in filling the generalisation gap when available data is limited.
Experimental results confirmed that the proposed models were capa-
ble of segmenting trophectoderm (TE) regions.
Inner cell mass (ICM) has been assessed by a computer-based and
semi-automatic grading of human blastocysts (Santos Filho et al.,
2012). A CNN was able to predict ICM and TE grades from a single
frame (a frame is an image extracted from a video), and a recurrent
neural network was applied on top to incorporate temporal informa-
tion of the expanding blastocysts from multiple frames. Additionally,
when evaluating implantation rates for embryos grouped by morphol-
ogy grades, a CNN provided a slightly higher correlation between pre-
dicted embryo quality and implantation ability than did human
2430
Riegler et al.
 .......................................................................
embryologists (Kragh et al., 2019). The use of a CNN trained to as-
sess an embryo’s implantation potential directly, when using euploid
embryos capable of implantation, outperformed 15 trained embryolo-
gists (Bormann et al., 2020a).
In a retrospective analysis of time-lapse videos and clinical outcomes
of 10 000 embryos from eight different IVF clinics across four different
countries, a DL model was built with a high level of predictability re-
garding the embryo implantation likelihood (Tran et al., 2019). A pro-
spective double-blinded study using retrospective data addressed the
variability between embryologists to select embryos for biopsy and
cryopreservation (Bormann et al., 2020b). It was found that the appli-
cation of a DNN could improve the reliability and perform with high
consistency during the process of embryo selection, thereby potentially
improving outcomes.
A DL-based system called Life Whisperer showed a sensitivity of
70% for viable embryos while maintaining a specificity of 61% for
non-viable embryos across three independent blind test sets from
different clinics (Ver Milyea et al., 2020). The model demonstrated
a 25% increase over embryologists for accuracy, and the ranking
comparison demonstrated an improvement of 42% over embryolo-
gists. One embryo ranking model increased the success of ART treat-
ments in oocyte donation programs (Alegre et al., 2021). The
Figure 1. Development of a machine learning model. To implement a machine learning model at the clinic, at ﬁrst a clinically relevant aim
should be deﬁned, and data must be collected in line with this aim. The collected data should then be stored in an appropriate format so that the ma-
chine learning algorithm can process it. The stored data should be split into a training, validation and testing partitions to ensure a robust and thor-
ough evaluation. In the optimal case the testing dataset is provided from an independent source (different clinic, new patients). These parts are then
be used to build a model that is in line with the medical goal. After the model is built, it should be thoroughly evaluated to verify its generalisability
and to avoid unintended biases. Once the model has been thoroughly tested, it can be implemented in the clinic. The model should be continuously
monitored and tested while in production and as the circumstances required are updated.
Figure 2.
Subﬁelds deﬁned by artiﬁcial intelligence.
Machine learning is the most relevant ﬁeld for the current develop-
ment of artiﬁcial intelligence system for the clinic. Machine learning
can further be split into traditional machine learning methods and
deep learning. Note that the subﬁelds are not mutually exclusive;
most of them rely heavily on machine learning, like computer vision
and language processing.
Artificial intelligence in the fertility clinic
2431
 .............................................................................................................................................................................................................................
Table I Overview of studies using AI-methods in embryo assessment and selection, and for prediction before treatment.
Year
Study
Aim of the study
Outcome
Dataset
AI methods
Summary answer
2017 Milewski et al.
Investigating the poten-
tial of using data on em-
bryo implantation and
morphokinetic parame-
ters in predictive AI
models.
Probability of implanta-
tion, clinical pregnancy.
A dataset of time-lapse
recordings of 610 em-
bryos from 514 treat-
ment cycles,
morphokinetic parame-
ters, data on implanta-
tion, women’s age. It is
unclear if the dataset
was prospectively
collected.
Traditional ML (Principal
Component Analysis)
and Deep Learning
(Multilayer Perceptron)
Morphokinetic parame-
ters from the time-lapse
videos used to discrimi-
nate between implanted
and nonimplanted
achieved an AUC of
0.71.
2018 Rad et al.
Automatic segmentation
of the Zona Pellucida.
Segmentation of Zona
Pellucida.
A retrospective dataset
consisting of images of
blastocyst.
Deep Learning
The AI model was able
to segment the Zona
Pellucida with an IoU
score of 0.78.
2019 Tran et al.
Predict the probability of
pregnancy with foetal
heart from time-lapse
videos.
Foetal heart pregnancy
or not.
A retrospective dataset
containing time-lapse
videos of 10,638 em-
bryos cultured to blasto-
cyst stage from 1,648
patients across 8 IVF
clinics. No manual as-
sessment of videos.
Deep Learning (CNN)
AI model (IVY) was able
to predict the probability
of fetal heart pregnancy
based on timelapse vid-
eos with a mean AUC of
0.93.
2019 Dirvanauskas et al.
Predict embryo develop-
ment stage from time-
lapse videos.
Embryo development
stage (1-cell, 2-cell,
4-cell, 8-cell,
no embryo).
A retrospective dataset
containing 7,002 time-
lapse images from 10
embryos.
Deep learning (CNN)
and traditional ML (K
Nearest Neighbour,
Cecoc, Decision
Trees, Naive Bayes
Classiﬁer)
The AI model for em-
bryo classiﬁcation
achieved an accuracy of
97.62%.
2019 Kanakasabapathy et al.
Develop inexpensive
platforms for use in a
stand-alone optical sys-
tem and a smartphone-
based optical system for
automated grading of
embryos based on
images.
Classiﬁcation of embryos
based on cell
morphology.
A retrospective dataset
containing 160 embryo
images from a stand-
alone optical system and
385 embryo images
from a smartphone-
based optical system.
Models were pretrained
on other high-quality
embryo data.
Deep Learning (CNN)
Two systems were de-
veloped for grading em-
bryos (stand-alone
imaging system and
smartphone optical sys-
tem). Both systems
achieve an accuracy
above 90%.
2019 Khosravi et al.
Develop an AI model for
accurate prediction of
blastocyst quality and se-
lection for single embryo
for transfer.
Classiﬁcation of embryos
into poor-quality and
good-quality.
A retrospective dataset
containing 12,001 time-
lapse images at 110 hr
post-insemination from
10,148 embryos. Manual
classiﬁcation by embryol-
ogists. Age of patient
was included in the
model for 2,182 em-
bryos. Two external
datasets were used for
validation.
Deep Learning (CNN)
AI model (STORK) pre-
dicted blastocyst quality
with an AUC above
0.98. The model
achieved an AUC of
0.90 and 0.76 respec-
tively on two datasets
from other clinics.
2019 Kragh et al.
Develop AI method for
automatic grading of
blastocyst morphological
appearance based on
time-lapse images.
Inner cell mass and tro-
phectoderm grading, im-
plantation rate.
A dataset containing
time-lapse videos of
4,483 embryos (both
IVF and ICSI treatment).
All images were graded
by embryologists.
Implantation information
for 287 embryos. It is
unclear if the dataset
was prospectively
collected.
Deep Learning (CNN,
Recurrent Neural
Network)
AI model achieved an
accuracy of 65% for in-
ner cell mass grading and
70% for trophectoderm
grading. Prediction of im-
plantation achieved an
AUC of 0.66.
(continued)
2432
Riegler et al.
 .............................................................................................................................................................................................................................
Table I Continued
Year
Study
Aim of the study
Outcome
Dataset
AI methods
Summary answer
2019 Raudonis et al.
Automatically detect hu-
man embryo develop-
ment stages during
incubation.
Detect embryo in an im-
age and classify the em-
bryo development stage
(1-cell, 2-cell, 3-cell,
4-cell, > 4-cell).
A dataset containing
images of early-stage
embryo development
from an ESCO Miri TL
incubator system. It is
unclear if the dataset
was prospectively
collected.
Deep Learning (CNN)
Two AI models were
considered, both
achieved a stage classiﬁ-
cation accuracy above
92%. The most difﬁcult
stage to classify was
3-cell.
2019 Qiu et al.
Prediction of a clinical
model for estimating the
cumulative live birth
chance of the ﬁrst com-
plete IVF cycle using pre-
treatment variables in-
cluding BMI and AMH.
Cumulative live birth
chance before IVF.
A retrospective dataset
containing age, AMH,
BMI, duration of infertil-
ity, previous live birth,
previous miscarriage,
previous abortion, and
type of infertility.
Traditional ML (Logistic
Regression, Random
Forest, XGBoost,
Support Vector
Machine)
Four machine learning
models were tested, of
which XGBoost
achieved the best score
with an AUC of 0.73.
The results indicate that
BMI and AMH have a
signiﬁcant impact on live
birth.
2019 Vogiatzi et al.
Predict live birth from
embryo variables by in-
cluding parameters that
exert a meaningful effect
on live birth following as-
sisted reproduction.
Live birth or not.
12 input features: Age
(female), Age at menar-
che, Difﬁculty during ET,
Endometrium thickness
prior to OR, ET/2PN,
TQE D3, TQE D3/2PN,
Total gonadotropins,
Age group, Dyspareunia,
Fresh or frozen cycle,
Menarche > 12 years.
The dataset was col-
lected retrospectively.
Deep Learning
(Multilayer Perceptron)
A multilayer perceptron
using the 12 input fea-
tures achieved a sensitiv-
ity of 0.71 and a
speciﬁcity of 0.70 for
predicting live birth.
2020 Bori et al.
Describe novel embryo
features for implantation
potential prediction that
may be used as input
data in AI models.
Prediction of implanta-
tion potential.
A retrospective dataset
containing time-lapse
images from 637 em-
bryos (ICSI-cycles with-
out PGT, single fresh
embryo transfer),
Implantation rate based
on foetal heartbeat ultra-
sound after eight weeks.
Oocyte donation
programme.
Deep Learning
(Multilayer Perceptron)
Two novel embryo fea-
tures with signiﬁcantly
different values in
implanted and nonim-
planted embryos were
identiﬁed. Novel embryo
features, in addition to
conventional morphoki-
netic parameters, can
improve predictive AI
models.
2020 Bormann et al. (a)
Evaluation of AI models
for embryo selection
based on images.
Embryo quality and im-
plantation potential.
A retrospective dataset
containing single time-
point images at 113 h
post-insemination for
742 embryos from 97
patients.
Deep Learning (CNN)
Two AI models were
evaluated. One selected
the highest quality em-
bryo with 90% accuracy,
and the other was able
to assess implantation
potential better than
trained embryologists
from different fertility
centres.
2020 Bormann et al. (b)
Evaluate AI models for
embryo quality scoring
and assessment of bi-
opsy or cryopreserva-
tion of blastocysts,
compared to decisions
by trained
embryologists.
Morphological quality on
a 1–5 scale.
For embryo scoring,
images from 3469 em-
bryos. 748 at 70 h post-
insemination and 742
images at 113 h post-in-
semination. For biopsy
and cryopreservation as-
sessment, 56 blastocysts
images at 113 h post-in-
semination. All images
were evaluated by
Deep Learning (CNN)
The AI models showed
less variability in embryo
grading than embryolo-
gists and outperformed
the embryologists in
selecting blastocyst bi-
opsy and
cryopreservation.
(continued)
Artificial intelligence in the fertility clinic
2433
 .............................................................................................................................................................................................................................
Table I Continued
Year
Study
Aim of the study
Outcome
Dataset
AI methods
Summary answer
trained embryologists.
Both datasets were ret-
rospectively collected.
2020 Chavez-Badiola et al. (a) Evaluate AI model per-
formance for prediction
of ploidy and implanta-
tion compared to
trained embryologists.
Embryo ranking, embryo
ploidy.
A retrospective dataset
containing single time-
point images from 840
embryos at day 5 or 6
after fertilization by ICSI.
Ploidy, hCG results, or
both were known.
Deep Learning
(Multilayer Perceptron)
An AI model (ERICA)
was able to identify and
rank blastocysts with the
best potential from one
image with higher accu-
racy than embryologists.
2020 Chavez-Badiola et al. (b) Predict pregnancy test
results after embryo
transfer.
Successful pregnancy or
not.
A retrospective dataset
containing embryo
images and patient age.
Traditional ML
(Probabilistic Bayesian,
Support Vector
Machine, Decision
Trees, Random Forest)
and Deep Learning
(Multilayer Perceptron)
Several AI models were
tested, of which the sup-
port vector machine
achieved the best result
across three datasets.
2020 Fukunaga et al.
Automatic pronuclei
counting using deep
learning.
Number of pronuclei.
A dataset containing 900
time-lapse images of 300
embryos up to 20 h
post-insemination. 70
images of each embryo.
Manual assessment and
annotation of pronuclei.
It is unclear if the dataset
was prospectively
collected.
Deep Learning (CNN)
The AI model was able
to count pronuclei with
a sensitivity of 99% for
0PN, 82% for 1PN, and
99% for 2PN. The sys-
tem performed similarly
to that of trained human
experts.
2020 Rad et al.
Automatic trophecto-
derm segmentation in
human embryo using
deep learning.
Trophectoderm
segmentation.
A retrospective dataset
containing images of
day-5 human embryo.
Deep Learning (CNN,
Generative Adversarial
Networks)
An AI model was used
to segment human em-
bryos. The model
achieved an IoU score of
76.71.
2020 Raef et al.
Predict implantation out-
come after embryo
transfer cycle.
Implantation rate.
Positive or negative
beta-HCG.
A dataset containing 82
features (patient-related
data, female and male
pathology, semen analy-
sis, lab tests, oocyte and
embryo data and PRP)
Attributes related to im-
plantation arranged in
two groups (N ¼ 82): 1)
patient-related features
(N ¼ 59) and 2) ART cy-
cle features (N ¼ 23). It
is unclear if the dataset
was prospectively
collected.
Traditional ML (Naive
Bayes Classiﬁer, Support
Vector Machine,
Random Forest, K
Nearest Neighbour,
Decision Trees) and
Deep Learning
(Multilayer Perceptron)
Six AI models were
tested, where the ran-
dom forest algorithm
achieved the best result
with an accuracy of
90.4% and an AUC of
93.7%.
2020 Ver Milyea et al.
Predict embryo viability
using images captured by
optical light microscopy.
Implantation rate—foe-
tal heartbeat.
A retrospective dataset
containing light micros-
copy images of blasto-
cysts, clinical outcome.
Deep Learning
(Convolutional Neural
Network)
An AI model (Life
Whisperer) was tested
on three independent
testing datasets, where it
achieved a 70.1% sensi-
tivity for viable embryos
and a speciﬁcity of
60.5% for non-viable
embryos.
2020 Goyal et al.
Predict live birth before
IVF treatment.
Live birth or not.
A retrospective dataset
containing 141,160 pa-
tient records,
Deep Learning
(Multilayer Perceptron)
Several machine learning
models were evaluated,
of which the multilayer
(continued)
2434
Riegler et al.
 ..................................................
multicentre nature of the above study supported its applicability at dif-
ferent clinics, standardising the interpretation of embryo development.
Embryo assessment, ranking, and selection are procedures nor-
mally based on evaluations at different time points during embryo
development and in several focal planes to get a view of the whole
embryo. There are numerous studies where only static images, usu-
ally in one single focal plane, are used for the AI analysis, which do
not mirror the clinical practice (Rad et al., 2018; Kanakasabapathy
et al., 2019; Khosravi et al., 2019; Bormann et al., 2020a, 2020b;
Chavez-Badiola et al., 2020a; Chavez-Badiola et al., 2020b; Bori
et al., 2021). In these models, well-curated, high-quality data is cru-
cial. For example, non-selection of a large number of images repre-
sentative of the diversity, inconsistent image treatment or inaccurate
labelling of images can lead to poor performing models (Tsipras
et al., 2020). Models involving time-lapse videos might also raise
problems since the definition of the important morphokinetic
markers may vary between different laboratories and still requires
an
automated
and
unbiased
process
(Milewski
et
al.,
2017;
Dirvanauskas et al., 2019; Tran et al., 2019; Bori et al., 2020; Alegre
et al., 2021).
AI methods should incorporate patient data that may impact the
outcome, such as maternal age. A framework (STORK) based on a
large collection of human embryo time-lapse images used a CNN to
automatically predict blastocyst quality depending on patient age
(Khosravi et al., 2019). Milewski et al. (2017) extracted several time
points and specific relative cleavage times together with fragmentation
levels, presence of multinucleation, evenness of blastomeres and
woman’s age. An ANN was trained to predict embryo implantation
from the extracted features. Another study that included 82 features
of patient data found that follicle stimulating hormone/human meno-
pausal gonadotropin dosage was the strongest predictor of embryo
implantation (Raef et al., 2020).
.............................................................................................................................................................................................................................
Table I Continued
Year
Study
Aim of the study
Outcome
Dataset
AI methods
Summary answer
anonymized register
data collected from the
year 2010–2016
obtained from the
Human Fertilisation &
Embryology Authority.
perceptron performed
best with an F1-Score of
72.94%.
2021 Alegre et al.
Evaluate and test an au-
tomatic software for em-
bryo evaluation and
selection (Dana).
Embryo implantation
potential.
A retrospective dataset
containing time-lapse
images and patient char-
acteristics from oocyte
donation program.
Phase 1: 1,676 embryos
from 955 couples. Phase
2: 996 embryos from
249 cycles (multiple
centres). Phase 3 147
embryos from 108
patients.
Deep Learning (CNN)
Increased success of IVF
treatment was found
with the assistance of au-
tomated embryo ranking
by Dana. The creation of
a data cloud can improve
the system further.
2021 Bori et al.
Develop an AI model for
prediction of live birth
based on blastocyst
morphology and proteo-
mic proﬁle of culture
media.
Prediction of live birth.
A retrospective dataset
containing single time
point images at 111 hr
þ/- 1.5 hr from 212
patients. 186 embryos
after exclusions (131
non PGT from oocyte
donation programme, 55
PDG with proteomic
proﬁle.
Deep Learning
(Multilayer Perceptron)
Three AI models using
both morphological and
proteomic variables. The
best model predicted
live birth with an AUC of
1.0.
2021 Zhao et al.
Automatic segmentation
of day one embryos in
zona pellucida (ZP), cy-
toplasm, and pronucleus
(PN).
Cytoplasm, ZP and PN
segments.
A dataset containing
images of day-one em-
bryos (zygotes). It is
unclear if the dataset
was prospectively
collected.
Deep Learning (CNN,
Generative Adversarial
Networks)
The AI model achieved a
precision of 97% when
segmenting the cyto-
plasm, 80% for the zona
pellucida, and 84% for
the pronucleus.
AI, Artiﬁcial intelligence; CNN, Convolutional neural network; AUC, Area under the curve; IVF, In vitro fertilization; ICSI, Intracytoplasmic sperm injection; ZP, Zona pellucida; PN,
Pronucleus, PGT, Preimplantation genetic testing; AMH, Anti-Mullerian hormone; BMI, body mass index.
Artificial intelligence in the fertility clinic
2435
 ............................................................................................................................................................................................................................
Table II Overview of studies using AI-methods in semen analysis and selection of sperm for ICSI.
Year
Study
Aim of study
Outcome
Dataset
AI Methods
Summary answer
2014
Chang et al.
Improve AI models
for detection of hu-
man sperm head
characteristics in-
cluding, acrosome
and nucleus.
Sperm morphology
A prospective data-
set containing 20
images with a total
of 210 stained sperm
cells. Sperm cell
details were manu-
ally classiﬁed and an-
notated in the
dataset.
Traditional ML
(Clustering)
Models showed 80%
overlap with manual
classiﬁcation and
more precise sperm
head detection and
segmentation than
previously described
models.
2017
Chang et al.
Explore AI modes to
classify sperm head
morphology into ﬁve
classes (normal, ta-
pered, pyriform,
small, amorphous)
and introduce a new
dataset.
Sperm morphology
A retrospective
dataset containing
images of 1,854
stained sperm heads
from six semen
smears (SCIAN
MorphoSpermGS).
Sperm head shape
was manually classi-
ﬁed and annotated in
the dataset.
432
The best model was
able to obtain 49%
correct classiﬁcation
of head shape into
the ﬁve classes.
2017
Shaker et al.
Explore Dictionary
Learning technique
for classiﬁcation of
sperm head shapes
into four classes
(normal, tapered
pyriform and amor-
phous), and intro-
duce a new dataset.
Sperm morphology
Two retrospective
datasets. 216 images
of stained sperm
heads (HuSHeM
dataset). Sperm
head shape was
manually classiﬁed
and annotated in the
dataset. 1133 images
from the SCIAN-
MorphoSpermGS
dataset.
Traditional ML
(Dictionary Learning)
Use of Dictionary
Learning was more
effective for sperm
head classiﬁcation
than previously pub-
lished shape-based
features.
2017
Goodson et al.
Development of AI
model for classiﬁca-
tion of sperm motil-
ity patterns during
invitro capacitation.
Sperm motility
CASA tracks of
2,817 washed sperm
cells from 18 sub-
jects. All tacks were
manually classiﬁed as
progressive, interme-
diate, hyperacti-
vated, slow, weakly
motile. It is unclear if
the dataset was pro-
spectively collected.
Traditional ML
(Support Vector
Machine, Decision
Tree)
A web-based pro-
gram, CASAnova,
was developed. This
program classiﬁes
sperm motility pat-
terns into one of ﬁve
classes with an over-
all accuracy of
89.9%.
2019
Agarwal et al.
Evaluate the perfor-
mance of an auto-
mated AI system
(LensHook) to mea-
sure sperm concen-
tration and sperm
motility.
Sperm concentration
and sperm motility
A prospective data-
set containing images
and video from 135
semen samples.
No information
available
Concentration and
motility analysed by
LensHook were
comparable to man-
ual assessment.
2019
Hicks et al.
Predict sperm motil-
ity from videos and
introduce a new
dataset.
Sperm motility
A retrospective
dataset containing
videos of live sperm
in untreated samples
from 85 subjects
(VISEM). Semen
analysis was manually
evaluated according
to WHO 2010.
Deep Learning
(CNN)
Deep learning
showed potential for
rapid and consistent
prediction of sperm
motility categories
(WHO 2010) based
on videos of live,
untreated sperm
samples.
(continued)
2436
Riegler et al.
 ............................................................................................................................................................................................................................
Table II Continued
Year
Study
Aim of study
Outcome
Dataset
AI Methods
Summary answer
2019
Riordon et al.
Automatic assess-
ment for classiﬁcation
of sperm head mor-
phology into ﬁve clas-
ses (normal, tapered,
pyriform, small, and
amorphous).
Sperm morphology
Retrospective images
from HuSHeM data-
set and 1,132 images
from SCIAN dataset.
Deep learning
(CNN)
Deep learning can
classify sperm head
morphology with
higher accuracy than
previously published
AI methods used for
the same datasets.
2019
Javadi and
Mirroshandel
Automatic assess-
ment of sperm mor-
phology in unﬁxed
cells and introduce a
new dataset.
Sperm morphology
1,540 retrospective
grey scale images of
unﬁxed sperm cells
from 235 subjects
(MHSMA dataset).
Sperm cells were
manually classiﬁed as
normal or abnormal,
and acrosome, head,
vacuole, tail, and
neck were
annotated.
Deep learning
(CNN)
The method is able
to classify sperm in
real-time, but accu-
racy needs to be
improved.
2019
McCallum et al.
Automatic method
for ranking sperm
cells based on DNA
quality enabling
sperm selection for
ICSI.
Sperm DNA
integrity
1,064 images of
stained sperm cells
with known DNA in-
tegrity from 6 sub-
jects. It is unclear if
the dataset was pro-
spectively collected.
Deep learning
(CNN)
Correlation between
cell image and DNA
integrity was found,
and the model was
able to predict the
DNA integrity of
sperm cells in a rapid
manner.
2019
Movahed et al.
Automatic segmen-
tation of external
(head, mid piece,
and tail) and internal
parts (acrosome and
nucleus) of the
sperm.
Sperm morphology
A retrospective
dataset containing 20
images of stained
sperm cells. Sperm
parts were manually
annotated.
Deep learning
(CNN) and tradi-
tional ML (Support
Vector Machine, K-
nearest neighbour,
Ensemble Method)
The methods were
better at segmenting
the head, acrosome,
and nucleus than
previously described
models. Provides the
ﬁrst method for eval-
uation of tail and mid
piece.
2020
Ilhan et al.
Fully automated
analyses of sperm
morphology by a
smartphone-based
system and intro-
duce a new dataset.
Sperm morphology
200 retrospective
images of stained
sperm cells from 17
subjects (SMIDS
dataset). Sperm cells
were manually classi-
ﬁed as normal or
abnormal.
Deep learning
(CNN) and tradi-
tional ML (Support
Vector Machine,
Decision Trees, K-
Nearest
Neighbours)
The most precise
model was able to
predict normal or
abnormal sperm
with an accuracy of
87%.
2021
Abbasi et al.
Improve AI models
for classiﬁcation of
the sperm head,
vacuoles, and acro-
some as normal or
abnormal.
Sperm morphology
1,540 retrospective
images from the
MHSMA dataset.
Deep learning
(CNN)
Both AI models
were able to predict
sperm head charac-
teristics more accu-
rately than models
previously described
in other studies.
2021
Valiuskaite et al.
Propose an AI
method that can pre-
dict if a semen sam-
ple is suitable for
artiﬁcial insemination
procedure based on
videos of semen
samples.
Sperm motility
85 retrospective
videos from the
VISEM dataset.
Deep learning
(CNN)
The AI model
detected sperm
heads in the videos
with an accuracy of
91.8%, and the
Pearson correlation
between manually
assessed motility and
predicted sperm head
motility was 0.969.
AI, Artiﬁcial intelligence; CNN, Convolutional neural network; CASA, Computer-assisted semen analysis.
Artificial intelligence in the fertility clinic
2437
 .............................................................................................................................................................................
AI in prediction of outcome
before treatment
In several publications, AI was used to build models that predict the
possibility of a successful treatment based on a patient’s medical re-
cord. The result may be of value for patient counselling about the po-
tential results of the treatment. Goyal et al. (2020) used the dataset
provided by Human Fertilisation and Embryology Authority (HFEA)
which included 30 different features such as age, number of previous
ART cycles, number of previous pregnancies, number of inseminated
oocytes, number of embryos transferred, and diagnosis for a total of
140 000 patients. Several ML techniques were evaluated to predict
live-birth occurrence. They concluded that both male and female traits
and living conditions were factors that influenced the outcome of
the treatment. A well-known ML technique called extreme gradient
boosting (XGBoost) has been used to predict live birth from fea-
tures such as age, anti-Mullerian hormone, BMI and patient anam-
nesis (Qiu et al., 2019). Similarly, an ANN was trained to predict
live birth using a collection of features such as the age of the fe-
male, total dose of gonadotrophins administered, endometrial thick-
ness, and the number of top-quality embryos (Vogiatzi et al., 2019).
AI in analysis of sperm
Most studies using an AI approach for semen analyses have been per-
formed for morphology assessments. The morphological classification
is usually performed on stained spermatozoa and implies both distin-
guishing abnormal from normal spermatozoa as well as identifying vari-
ous defects of the sperm cell (WHO, 2010). Some of the developed
AI models have been trained only to predict the morphology of sperm
heads (Chang et al., 2014; Chang et al.; 2017; Shaker et al., 2017;
Riordon et al., 2019), whereas other studies describe the recognition
of various parts of the whole sperm (Movahed et al., 2019; Ilhan et al.,
2020). These differences in the approaches make it difficult to com-
pare results and possible implications for clinical practice even if the
overall goal is similar. This is also fortified by the fact that the data
used is usually very limited, with only a small number of spermatozoa
or patients. Training and evaluating complex methods, for example,
DL, with a small-sized dataset most probably leads to an overfitted
model. An overfitted model is a model that does not generalise well
to unseen real-world cases although it works well on the training data.
For example, suppose that a model is trained on a dataset of embryo
images to predict pregnancy or not. If the model achieves far higher
prediction performance on the embryo images used for training than
on new and unseen images, the model is overfitted to the training
data.
Annotation of the dataset/sperm images must be done manually
and with high accuracy to obtain well-performing models. For recog-
nising and interpreting images of spermatozoa at the pixel level, seg-
mentation is the common approach, in which the spermatozoon is
divided into parts, each consisting of a set of pixels. Some studies
demonstrate high classification accuracy for morphological characteris-
tics, and most of the studies have both trained and validated the mod-
els on freely available datasets, which makes them easier to compare
(HuSHeM in Shaker et al. (2017), SCIAN in Chang et al. (2017), and a
smaller dataset of 264 spermatozoa in Chang et al. (2014)).
Furthermore, the model performance is compared with existing AI
models, and even though this is common practice in the field of AI, it
reveals little knowledge about the clinical usability of the model.
Regarding sperm morphology, as far as we know, there are no studies
comparing the performance of the models with manual assessment
according to the WHO guidelines or in relation to fertility outcomes.
For prediction of sperm motility, only one study compared AI-based
sperm motility classification against sperm motility that was manually
assessed following WHO guidelines (Hicks et al., 2019), while others
were mainly focused on comparing various models or exploring the
sperm kinematics (Goodson et al., 2017; Valiuskait_e et al., 2020).
Studies related to motility and/or morphology also come with the
challenge of small datasets, and for both of them, the evaluation pro-
cedures are often not clear. Cross validation is sometimes used to
compensate for small datasets (Goodson et al., 2017; Shaker et al.,
2017). However, even though cross validation is acceptable for testing
model performance and comparing it to other models on the same
dataset, it does not test the generalisability of the results. In a clinical
setting, an independent test set evaluation should be performed, opti-
mally across different clinics (Abbasi et al., 2021).
Automatic systems for diagnostic purposes have been developed.
One such system based on an automatic segmentation step and a clas-
sification of normal/abnormal spermatozoa has recently been de-
scribed (Ilhan et al., 2020). The authors reported an accuracy of 87%.
However, the method was just compared with other ML methods and
not evaluated for its clinical value. In addition, accuracy alone is not a
sufficient metric to determine the possible clinical performance of a
method, especially if only a small dataset is used. Another automatic
system for analysis of sperm concentration, morphology and motility
used AI optical microscopic technology, for which the performance
was compared with manual assessment (Agarwal et al., 2019, 2021).
Nonetheless, the morphology values did not correlate with the manual
morphology results, and unfortunately, there are no details provided
on the construction and annotation of the dataset.
Parameters that are not part of standard semen analysis have also
been used in AI models. For example, sperm intracellular pH was
shown to be a stable marker for fertilisation outcome (Gunderson
et al., 2021), and sperm DNA integrity could be predicted from bright-
field sperm images at a single cell level through supervised training
(McCallum et al., 2019). These studies show how AI can be used to
automate sperm sorting and selection tasks. However, big datasets
from multicentre cohorts are needed to evaluate whether the results
are generalisable before these AI models can be used in the clinic as
well as for research related purposes. In addition to the conventional
semen variables, image features may detect sperm characteristics that
are too complex to be recognised by humans, for example, motility
patterns or morphological shapes. Nonetheless, from a diagnostic per-
spective, the clinical value of novel traits must be investigated in epide-
miological studies.
The selection of spermatozoa for ICSI is based on a cursory assess-
ment of motility and morphology in real-time, which is especially a
challenge for morphology evaluation. The procedure has a potential
for improvement using AI to obtain a more objective selection based
on the simultaneous monitoring of morphology and motility patterns.
Attempts have been made to develop DL models for morphological
assessment based on images of unstained spermatozoa (Javadi and
Mirroshandel, 2019; Abbasi et al., 2021). Both algorithms can analyse
2438
Riegler et al.
 .............................................................................................................................................................................
fresh human sperm in real-time with a magnification between 400
and 600.
The AI methods used in sperm related studies are mostly based on
simple algorithms that are standard implementation in most ML frame-
works (Table II). The development of more domain-specific methods
and models related to ART will in the long run lead to better results
compared to using out-of-the-box methods from existing generic
frameworks.
Pitfalls
The AI algorithms are only as good as the data they are based on.
There may also be limitations regarding generalisability due to difficul-
ties with the standardisation of the ML methods. Variation in patient
demographics, clinical and laboratory practices may cause data bias.
When an AI model is based on training in one clinic, the AI model
should be validated in independent cohorts (Tran et al., 2019;
Bormann et al., 2020b). Furthermore, the models should not be lim-
ited to strict inclusion criteria, and optimally the datasets should con-
tain data from different clinics where testing data should be from a
different site than the training and validation data (Alegre et al., 2021;
Bori et al., 2020).
Another important issue is that patient data and treatment informa-
tion are not easily obtained for research due to data privacy and ethi-
cal considerations. This naturally limits the amount of patient related
data to be used for training the AI model. DL methods, which are es-
pecially suited for image and video classification, require a large
amount of diverse data to be generalisable. Another weakness for
some studies is that the data used for training are not connected to
any treatment outcome, leading to overly complex models that might
only
detect
irrelevant
correlations
(Dirvanauskas
et
al.,
2019;
Kanakasabapathy et al., 2019; Khosravi et al., 2019; Raudonis et al.,
2019; Bormann et al., 2020a; Bormann et al., 2020b; Fukunaga et al.,
2020; Rad et al., 2020; Zhao et al., 2021; Alegre et al., 2021). This can
raise concerns like, for example, whether the prediction is related to
the embryo implantation potential. Moreover, most articles resort to a
positive heartbeat at ultrasound control or even a positive hCG test
as their outcome, but the most important outcome in ART is the birth
of a living, healthy child (Vogiatzi et al., 2019; Bori et al., 2021).
AI models are usually evaluated using different metrics such as accu-
racy, precision and sensitivity. Often only a small subset or even just a
single metric is used to decide if the model performs well. This is not
sufficient, and to make a proper estimation about the performance, a
set of metrics needs to be considered. It might even be necessary to
develop task specific performance measurements.
The future symbiosis between
AI and ART
AI methods may be a supporting tool in predicting the patient’s
individual chance of achieving a healthy child based on available patient
data. Adjustments of treatment and prediction of risk and possibilities
for complications during pregnancy may be other tasks guided by AI.
In ART, AI models may assist in selecting methods, selecting the em-
bryo for transfer, and selecting the spermatozoon for ICSI.
As far as we know, no published studies have performed AI-guided
sperm selection for ICSI. Detailed real-time assessment of both motil-
ity and morphology simultaneously is a challenge in the present rou-
tine. By analysing video recordings of sperm selections by ML methods
that consider both the spatial and temporal domains, it may be possi-
ble to detect patterns or unknown characteristics that can be related
to ICSI outcomes. Similarly, until-now unrecognised features of impor-
tance for embryo quality might also be detected by analysing images
and videos of embryos.
At present, most of the publications are of a retrospective nature
and there is a lack of prospective studies. However, there are some
studies that are using retrospective data to perform a prospective
study (Bormann et al., 2020b; Huang et al., 2021). The latter should
preferably be performed as randomised controlled trials, in which the
performance of the AI model included in one arm is compared to
decisions routinely performed at a fertility clinic in the other arm, and
the outcome is defined as live births. The studies should optimally be
designed to include just single embryo transfers to exclude the uncer-
tainty arising when two (or more) embryos are transferred and only
one child is born. Most studies using AI for embryo assessment or se-
lection rely on manually extracted features from embryo images or
videos. However, over the last couple of years, there has been a rapid
increase in the use of DL techniques where features are automatically
learned. There are also a few studies using image segmentation techni-
ques to improve automatic embryo assessment (Rad et al., 2020) or
to streamline manual assessment (Zhao et al., 2021). The impact of
these methods in clinical practice is however limited and standardisa-
tion, explainable methods and transparency are keys to improve it.
Standardisation is essential for the development of an applicable and
reliable AI model. It requires close interdisciplinary collaboration from
the planning of the initial study to the clinical evaluation. In particular,
for the successful implementation of AI in the field of ART, a close col-
laboration between computer science, clinical experience and biologi-
cal knowledge, which also agree on a common standard, is crucial.
Most algorithms used in all the aforementioned articles, especially
DL-based, are black boxes. Ongoing research tries to increase the un-
derstanding of these black boxes (Holzinger et al., 2019; Arrieta et al.,
2020). In ART, methods for better understanding of black boxes are
still in their infancy, focusing on simple visualisation methods (Liu et al.,
2020; Abbasi et al., 2021). However, the whole pipeline of an AI sys-
tem should be transparent (Saito and Rehmsmeier, 2015), including
the evaluation method and metrics that need to be described clearly
(as in: Javadi and Mirroshandel, 2019; Bori et al., 2020). Increased
transparency of AI in ART will also be beneficial for discussions of legal
and ethical implications across countries, which often have different
regulations.
Furthermore, we need a common way of benchmarking and com-
paring different systems. In computer science, this is often done using
open benchmarking datasets collected and curated by the scientific
community. If the hardware changes, like data collected at higher reso-
lutions, the systems will have to be evaluated on the data collected
from these new devices. This means we need these community-wide
benchmarking datasets to be continuously tested before, during and af-
ter clinical trials to verify the performance of AI models. This is not
just important for research but also for commercial companies in the
Artificial intelligence in the fertility clinic
2439
 .............................................................................................................................................................................
field. Systems such as iDASCORE, KIDScore, Eeva and LensHooke
should follow the same requirements and be transparent and open
about data, methods and evaluation.
The datasets also need to be continuously updated following tech-
nological advances and new findings. There are a few open datasets
for sperm and embryo (Shaker et al., 2017; Saeedi et al., 2017;
Haugen et al., 2019; Javadi and Mirroshandel, 2019; Ilhan et al., 2020).
For sperm, datasets such as VISEM (Haugen et al., 2019) and
HuSHeM (Shaker et al., 2017) are commonly used for the evaluation
of sperm characteristics. For embryos, even fewer public datasets ex-
ist, and the data published by Saeedi et al. (2017) has been used for
blastocyst evaluation. Ideally, one publicly available dataset should be
used for developing algorithms and a hidden test dataset can be tested
on hardware provided by, for example, the European Society of
Human Reproduction and Embryology or the American Society for
Reproductive Medicine. This would ensure a common standard for
training and testing to provide reproducible and comparable results
necessary to make AI in ART clinically relevant.
Conclusion
Several studies have applied ML in ART, some of them focusing on
clinical relevance, while others concern AI methodological aspects.
The limitations are often small datasets and the use of AI algorithms
not specifically designed for the fertility clinic. Large open datasets and
methods specifically developed and tailored for use in context with
ART could lead to better results and understanding.
For AI to significantly impact ART, the model must be developed in
the context of clinical practice. Critical steps are proper evaluation and
testing of AI systems in relation to outcomes and regulations, a better
understanding of the technical aspects, and determination of the per-
formance of AI models regarding practical value in the clinic. In addi-
tion, it is important to standardise the use of AI in ART to enable
more transparent, comparable, and reproducible results.
To succeed with implementing AI as a valuable tool in the fertility
clinic, a strong interdisciplinary collaboration is required between
researchers in ART and AI as well as the clinical staff. In addition,
there is a need for large-scale randomised controlled trials where sev-
eral clinics are involved in testing the external validity of the algorithms
before defining AI systems that are sufficiently robust for safe clinical
implementation.
Data availability
The data generated during and/or analysed during the current study
(information extracted from the reviewed articles) are available from
the corresponding author on reasonable request.
Authors’ roles
M.A.R.: Lead for AI, literature review, writing and revising of text and
tables. M.H.S.: Lead for embryo section, literature review, writing and
revising. O.W.: Literature search and review, writing and revising.
J.M.A.: Tables, figures, literature review, writing. S.A.H.: Tables, figures,
literature review, writing and revising of text and tables. H.L.H.:
Literature review, writing and revising. E.D.: Literature review, writing.
P.H.: Literature review, writing. A.Y.: Literature review, writing. N.H.:
Literature review, writing. T.B.H.: Lead for sperm section, literature
review, writing and revising.
Funding
The work on this article was partially funded by the Frimedbio project
ReproAI granted by the Norwegian Research Council with Project
number 288727.
Conflicts of interest
Nothing to disclose.
References
Abbasi A, Miahi E, Mirroshandel SA. Effect of deep transfer and
multi-task learning on sperm abnormality detection. Comput Biol
Med 2021;128:104121.
Agarwal A, Henkel R, Huang CC, Lee MS. Automation of human se-
men analysis using a novel artificial intelligence optical microscopic
technology. Andrologia 2019;51:e13440.
Agarwal A, Panner Selvam MK, Ambar RF. Validation of LensHookeV
R
X1 PRO and computer-assisted semen analyzer compared with
laboratory-based manual semen analysis. World J Mens Health
2021;39:e7.
Alegre L, Del Gallego R, Bori L, Loewke K, Maddah M, Aparicio-Ruiz
B, Palma-Govea AP, Marcos J, Meseguer M. Assessment of em-
bryo implantation potential with a cloud-based automatic software.
Reprod Biomed Online 2021;42:66–74.
Armstrong S, Bhide P, Jordan V, Pacey A, Marjoribanks J, Farquhar
C. Time-lapse systems for embryo incubation and assessment in
assisted reproduction. Cochrane Database Syst Rev 2019; 5:
CD011320. doi: 10.1002/14651858.CD011320.pub4.
Arrieta AB, Diaz-Rodriguez N, Del Ser J, Bennetot A, Tabik S,
Barbado A, Garcia S, Gil-Lopez S, Molina D, Benjamins R. et al.
Explainable Artificial Intelligence (XAI): concepts, taxonomies, op-
portunities and challenges toward responsible AI. Inform Fusion
2020;58:82–115.
Bori L, Dominguez F, Fernandez EI, Del Gallego R, Alegre L,
Hickman C, Quinonero A, Nogueira MFG, Rocha JC, Meseguer M.
An artificial intelligence model based on the proteomic profile of
euploid embryos and blastocyst morphology: a preliminary study.
Reprod Biomed Online 2021;42:340–350.
Bori L, Paya E, Alegre L, Viloria TA, Remohi JA, Naranjo V,
Meseguer M. Novel and conventional embryo parameters as input
data for artificial neural networks: an artificial intelligence model
applied for prediction of the implantation potential. Fertil Steril
2020;114:1232–1241.
Bormann CL, Kanakasabapathy MK, Thirumalaraju P, Gupta R,
Pooniwala R, Kandula H, Hariton E, Souter I, Dimitriadis I,
Ramirez LB. et al. Performance of a deep learning based neural
2440
Riegler et al.
 ..............................................................................................................................................................................
network in the selection of human blastocysts for implantation.
eLife 2020a;9:1–14.
Bormann CL, Thirumalaraju P, Kanakasabapathy MK, Kandula H,
Souter I, Dimitriadis I, Gupta R, Pooniwala R, Shafiee H.
Consistency and objectivity of automated embryo assessments us-
ing deep neural networks. Fertil Steril 2020b;113:781–787.
Boulet SL, Mehta A, Kissin DM, Warner L, Kawwass JF, Jamieson DJ.
Trends in use of and reproductive outcomes associated with intra-
cytoplasmic sperm injection. JAMA 2015;313:255–263.
Chang V, Garcia A, Hitschfeld N, Hartel S. Gold-standard for
computer-assisted morphological sperm analysis. Comput Biol Med
2017;83:143–150.
Chang V, Saavedra JM, Castaneda V, Sarabia L, Hitschfeld N, Hartel
S. Gold-standard and improved framework for sperm head seg-
mentation. Comput Methods Programs Biomed 2014;117:225–237.
Chavez-Badiola
A,
Flores-Saiffe-Farias
A,
Mendizabal-Ruiz
G,
Drakeley AJ, Cohen J. Embryo Ranking Intelligent Classification
Algorithm (ERICA): artificial intelligence clinical assistant predicting
embryo ploidy and implantation. Reprod Biomed Online 2020a;41:
585–593.
Chavez-Badiola A, Flores-Saiffe Farias A, Mendizabal-Ruiz G, Garcia-
Sanchez R, Drakeley AJ, Garcia-Sandoval JP. Predicting pregnancy
test results after embryo transfer by image feature extraction and
analysis using machine learning. Sci Rep 2020b;10:4394.
Dang VQ, Vuong LN, Luu TM, Pham TD, Ho TM, Ha AN, Truong
BT, Phan AK, Nguyen DP, Pham TN. et al. Intracytoplasmic sperm
injection versus conventional in-vitro fertilisation in couples with in-
fertility in whom the male partner has normal total sperm count
and motility: an open-label, randomised controlled trial. Lancet
2021;397:1554–1563.
Dirvanauskas D, Maskeliunas R, Raudonis V, Damasevicius R.
Embryo development stage prediction algorithm for automated
time lapse incubators. Comput Methods Programs Biomed 2019;
177:161–174.
Fukunaga N, Sanami S, Kitasaka H, Tsuzuki Y, Watanabe H, Kida Y,
Takeda S, Asada Y. Development of an automated two pronuclei
detection system on time-lapse embryo images using deep learning
techniques. Reprod Med Biol 2020;19:286–294.
Goodson SG, White S, Stevans AM, Bhat S, Kao C-Y, Jaworski S,
Marlowe TR, Kohlmeier
M, McMillan
L,
Zeisel SH.
et al.
CASAnova: a multiclass support vector machine model for the
classification of human sperm motility patterns. Biol Reprod 2017;
97:698–708.
Goyal A, Kuchana M, Ayyagari KPR. Machine learning predicts
live-birth occurrence before in-vitro fertilization treatment. Sci
Rep 2020;10:20925.
Gunderson SJ, Puga Molina LC, Spies N, Balestrini PA, Buffone MG,
Jungheim ES, Riley J, Santi CM. Machine-learning algorithm incorpo-
rating capacitated sperm intracellular pH predicts conventional
in vitro fertilization success in normospermic patients. Fertil Steril
2021;115:930–939.
Haugen TB, Hicks SA, Andersen JM, Witczak O, Hammer HL, Borgli
R, Halvorsen P, Riegler M. Visem: a multimodal video dataset of
human spermatozoa. In: Proceedings of the 10th ACM Multimedia
Systems Conference, 2019, 261–266.
Hicks SA, Andersen JM, Witczak O, Thambawita V, Halvorsen P,
Hammer HL, Haugen TB, Riegler MA. Machine learning-based
analysis of sperm videos and participant data for male fertility pre-
diction. Sci Rep 2019;9:16770.
Holzinger A, Langs G, Denk H, Zatloukal K, Muller H. Causability
and
explainability
of
artificial
intelligence
in
medicine.
Wiley
Interdiscip Rev Data Min Knowl Discov 2019;9:e1312.
Hosny A, Parmar C, Quackenbush J, Schwartz LH, Aerts H. Artificial
intelligence in radiology. Nat Rev Cancer 2018;18:500–510.
Huang TTF, Kosasa T, Walker B, Arnett C, Huang CTF, Yin C,
Harun Y, Ahn HJ, Ohta A. Deep learning neural network
analysis of human blastocyst expansion from time-lapse image
files. Reprod Biomed Online 2021; 42:1075–1085. doi:10.1016/
j.rbmo.2021.02.015.
Høst E, Ernst E, Lindenberg S, Smidt-Jensen S. Morphology of sper-
matozoa used in IVF and ICSI from oligozoospermic men. Reprod
Biomed Online 2001;3:212–215.
Ilhan HO, Sigirci IO, Serbes G, Aydin N. A fully automated hybrid hu-
man sperm detection and classification system based on mobile-net
and the performance comparison with conventional methods. Med
Biol Eng Comput 2020;58:1047–1068.
Javadi S, Mirroshandel SA. A novel deep learning method for auto-
matic assessment of human sperm images. Comput Biol Med 2019;
109:182–194.
Kanakasabapathy MK, Thirumalaraju P, Bormann CL, Kandula H,
Dimitriadis I, Souter I, Yogesh V, Kota Sai Pavan S, Yarravarapu D,
Gupta R. et al. Development and evaluation of inexpensive auto-
mated deep learning-based imaging systems for embryology. Lab
Chip 2019;19:4139–4145.
Khosravi P, Kazemi E, Zhan Q, Malmsten JE, Toschi M, Zisimopoulos
P, Sigaras A, Lavery S, Cooper LAD, Hickman C. et al. Deep
learning enables robust assessment and selection of human blasto-
cysts after in vitro fertilization. Npj Digit Med 2019;2:21. doi:
10.1038/s41746-019-0096-y.
Kragh MF, Rimestad J, Berntsen J, Karstoft H. Automatic grading of
human blastocysts from time-lapse imaging. Comput Biol Med 2019;
115:103494.
Lemmen JG, Rodriguez NM, Andreasen LD, Loft A, Ziebe S. The to-
tal pregnancy potential
per oocyte
aspiration
after assisted
reproduction-in how many cycles are biologically competent
oocytes available? J Assist Reprod Genet 2016;33:849–854.
Liu L, Jiao Y, Li X, Ouyang Y, Shi D. Machine learning algorithms to
predict early pregnancy loss after in vitro fertilization-embryo
transfer with fetal heart rate as a strong predictor. Comput
Methods Programs Biomed 2020;196:105624.
McCallum C, Riordon J, Wang Y, Kong T, You JB, Sanner S, Lagunov
A, Hannam TG, Jarvi K, Sinton D. Deep learning-based selection
of human sperm with high DNA integrity. Commun Biol 2019;2:
250. doi:10.1038/s42003-019-0491-6.
Milewski R, Kuczynska A, Stankiewicz B, Kuczynski W. How much in-
formation about embryo implantation potential is included in morpho-
kinetic data? A prediction model based on artificial neural networks
and principal component analysis. Adv Med Sci 2017;62:202–206.
Mortimer ST, van der Horst G, Mortimer D. The future of
computer-aided sperm analysis. Asian J Androl 2015;17:545–553.
Movahed RA, Mohammadi E, Orooji M. Automatic segmentation of
Sperm’s parts in microscopic images of human semen smears using
concatenated learning approaches. Comput Biol Med 2019;109:
242–253.
Artificial intelligence in the fertility clinic
2441
 ........................................................................................................................
Paternot G, Devroe J, Debrock S, D’Hooghe TM, Spiessens C. Intra-
and inter-observer analysis in the morphological assessment of
early-stage
embryos.
Reprod
Biol
Endocrinol
2009;7:105.doi:
10.1186/1477-7827-7-105.
Qiu J, Li P, Dong M, Xin X, Tan J. Personalized prediction of live
birth prior to the first in vitro fertilization treatment: a machine
learning method. J Transl Med 2019;17:317. doi:10.1186/s12967-
019-2062-5.
Rad RM, Saeedi P, Au J, Havelock J. Human Blastocyst’s Zona
Pellucida segmentation via boosting ensemble of complementary
learning. Inform Med Unlocked 2018;13:112–121.
Rad RM, Saeedi P, Au J, Havelock J. Trophectoderm segmentation in
human embryo images via inceptioned U-Net. Med Image Anal
2020;62:101612.
Raef B, Maleki M, Ferdousi R. Computational prediction of implanta-
tion outcome after embryo transfer. Health Informatics J 2020;26:
1810–1826.
Raudonis V, Paulauskaite-Taraseviciene A, Sutiene K, Jonaitis D.
Towards the automation of early-stage human embryo develop-
ment
detection.
BioMed
Eng
OnLine
2019;18:120.
doi:
10.1186/s12938-019-0738-y.
Riordon J, McCallum C, Sinton D. Deep learning for the classification
of human sperm. Comput Biol Med 2019;111:103342.
Saeedi P, Yee D, Au J, Havelock J. Automatic identification of human
blastocyst components via texture. IEEE Trans Biomed Eng 2017;
64:2968–2978.
Saito T, Rehmsmeier M. The precision-recall plot is more informative
than the ROC plot when evaluating binary classifiers on imbal-
anced datasets. PLoS One 2015;10:e0118432.
Santos Filho E, Noble JA, Poli M, Griffiths T, Emerson G, Wells D. A
method for semi-automatic grading of human blastocyst micro-
scope images. Hum Reprod 2012;27:2641–2648.
Shaker F, Monadjemi SA, Alirezaie J, Naghsh-Nilchi AR. A dictionary
learning approach for human sperm heads classification. Comput
Biol Med 2017;91:181–190.
Storr A, Venetis CA, Cooke S, Kilani S, Ledger W. Inter-observer
and intra-observer agreement between embryologists during selec-
tion of a single Day 5 embryo for transfer: a multicenter study.
Hum Reprod 2017;32:307–314.
Sundvall L, Ingerslev HJ, Breth Knudsen U, Kirkegaard K. Inter- and
intra-observer variability of time-lapse annotations. Hum Reprod
2013;28:3215–3221.
Tomlinson MJ. Uncertainty of measurement and clinical value of se-
men analysis: has standardisation through professional guidelines
helped or hindered progress? Andrology 2016;4:763–770.
Tran D, Cooke S, Illingworth PJ, Gardner DK. Deep learning as a
predictive tool for fetal heart pregnancy following time-lapse
incubation
and
blastocyst
transfer.
Hum
Reprod
2019;34:
1011–1018.
Tsipras D, Santurkar S, Engstrom L, Ilyas A, Madry A. From imagenet
to image classification: contextualizing progress on benchmarks. Int
Conference on Machine Learning, Vol. 119 2020, 9625–9635.
Valiuskait_e V, Raudonis V, Maskeliunas R, Damasevicius R, Krilavicius
T. Deep learning based evaluation of spermatozoid motility for ar-
tificial insemination. Sensors 2021;21:72.
Vander Borght M, Wyns C. Fertility and infertility: definition and epi-
demiology. Clin Biochem 2018;62:2–10.
Ver Milyea M, Hall JMM, Diakiw SM, Johnston A, Nguyen T, Perugini
D, Miller A, Picou A, Murphy AP, Perugini M. Development of an
artificial intelligence-based assessment model for prediction of em-
bryo viability using static images captured by optical light micros-
copy during IVF. Hum Reprod 2020;35:770–784.
Vogiatzi P, Pouliakis A, Siristatidis C. An artificial neural network for
the prediction of assisted reproduction outcome. J Assist Reprod
Genet 2019;36:1441–1448.
WHO Laboratory Manual for the Examination and Processing of Human
Semen, 5th edn. Genova, Switzerland: WHO Press, 2010. World
Health Organization.
Wyns C, Bergh C, Calhaz-Jorge C, De Geyter C, Kupka M, Motrenko
T, Rugescu I, Smeenk JA. ART in Europe, 2020: results generated
from European registries by ESHRE. Hum Reprod Open 2020:
hoaa032. doi: 10.1093/hropen/hoaa032.
Yang YJ, Bang CS. Application of artificial intelligence in gastroenter-
ology. World J Gastroenterol 2019;25:1666–1683.
Zhao M, Xu M, Li H, Alqawasmeh O, Chung JPW, Li TC, Lee TL,
Tang PMK, Chan DYL. Application of convolutional neural net-
work on early human embryo segmentation during in vitro fertiliza-
tion. J Cell Mol Med 2021;25:2633–2644.
2442
Riegler et al.
",10.1093/humrep/deab168,doc14,"................................................................... Artificial intelligence in the fertility clinic: status, pitfalls and possibilities M.A. Riegler 1,*, M.H. Stensen2, O. Witczak3, J.M. Andersen3, S.A. Hicks1,4, H.L. Hammer1,4, E. Delbarre 3, P. Halvorsen1,4, A. Yazidi4, N. Holst2, and T.B. Haugen3 1Department of Holistic Systems, Simula Metropolitan Center for Digital Engineering, Oslo, Norway 2Fertilitetssenteret, Oslo, Norway 3Department of Life Sciences and Health, Faculty of Health Sciences, OsloMet—Oslo Metropolitan University, Oslo, Norway 4Department of Computer Science, Faculty of Technology, Art and Design, OsloMet—Oslo Metropolitan University, Oslo, Norway *Correspondence address. Department of Holistic Systems, Simula Metropolitan Center for Digital Engineering, Oslo 0167, Norway. E-mail: michael@simula.no Submitted on May 19, 2021; resubmitted on June 21, 2021; editorial decision on June 23, 2021 ABSTRACT: In recent years, the amount of data produced in the ﬁeld of ART has increased exponentially. The diversity of data is large, ranging from videos to tabular data. At the same time, artiﬁcial intelligence (AI) is progressively used in medical practice and may become a promising tool to improve success rates with ART. AI models may compensate for the lack of objectivity in several critical procedures in fertility clinics, especially embryo and sperm assessments. Various models have been developed, and even though several of them show promising performance, there are still many challenges to overcome. In this review, we present recent research on AI in the context of ART. We discuss the strengths and weaknesses of the presented methods, especially regarding clinical relevance. We also address the pit- falls hampering successful use of AI in the clinic and discuss future possibilities and important aspects to make AI truly useful for ART. Key words: artiﬁcial intelligence / machine learning / ART / embryology / semen analysis / embryo / spermatozoa / fertility / infertility / algorithm Introduction The number of treatments with ART is steadily increasing in Europe, and in 2016, over 900 000 treatment cycles were performed (Wyns et al., 2020). Even though there have been gradual improvements in the success rate, only one-third of the ART cycles result in a live birth, and only 5% of the aspirated oocytes have the competence to develop into a child (Lemmen et al., 2016; Wyns et al., 2020). This implies that there is potential for improvement in the crucial steps in ART treat- ments, such as the selection of embryos for transfer and the selection of spermatozoa for ICSI. Improving the ability to select a single em- bryo with the highest implantation potential could increase live birth rates and time to pregnancy, as well as minimise the chance of multi- ple pregnancies due to the transfer of multiple embryos. Likewise, a more reliable method for sperm selection may increase the success rates of the ICSI procedure. Furthermore, the disputable clinical value of semen analysis in male fertility investigation and for ART justifies a need for improving the methods of sperm evaluation both for diagnos- tic purposes and for decisions regarding the fertilisation method of the ART treatment. Video and image analysis constitutes a major part of ART, and artificial intelligence (AI) methods are especially suited for image classification. In addition to videos and images, AI can be used to ana- lyse other types of data, like text or tabular data. As in other parts of medicine, AI methods have been introduced in the field of ART. They have the advantage of objectivity and have the potential to improve ART, which in some parts are based on subjective assessments. In this review, we provide an overview of studies found in Embase (Ovid), where AI methods have been applied in human reproductive medicine with an emphasis on ART. Furthermore, we discuss how to avoid the pitfalls and describe the potential use of AI in clinical practice in the future. Current challenges in ART Highly trained personnel in fertility clinics are faced with important and difficult decisions every day, such as deciding which fertilisation method to use, which spermatozoon to select for ICSI, and which embryo to transfer to the uterus. One of the major challenges in the subjective assessments of embryos is the high intra- and inter-operator variability which exists in the evaluation of morphology and morphokinetics (Paternot et al., 2009; Sundvall et al., 2013; Storr et al., 2017). With time-lapse technology, embryos can be monitored continuously, and V C The Author(s) 2021. Published by Oxford University Press on behalf of European Society of Human Reproduction and Embryology. All rights reserved. For permissions, please email: journals.permissions@oup.com Human Reproduction, Vol.36, No.9, pp. 2429–2442, 2021 Advance Access Publication on July 29, 2021 doi:10.1093/humrep/deab168 MINI REVIEW ............................................................................................................................................................................. the complete process of embryo development is more precisely assessed. However, there is no evidence that the use of time-lapse technology has improved live birth rates after ART (Armstrong et al., 2019). Whilst sperm morphology has no definite impact on the outcome after ART, sperm concentration and sperm motility are normally assessed for deciding whether IVF or ICSI should be used as the fertil- isation method (Høst et al., 2001). Strikingly, ICSI is increasingly used irrespective of a male factor infertility diagnosis (Boulet et al., 2015; Vander Borght and Wyns, 2018). Among the cycles reported in Europe in 2016, 28% were IVF and 72% ICSI (Wyns et al., 2020), al- though the male factor accounts for only 20–30% of the diagnoses of the infertile couples. This is of increasing concern since performing ICSI instead of IVF in couples where the male partner has a defined normal semen sample does not increase the live birth rate (Dang et al., 2021). Early in the fertility investigation, a standard semen analysis accord- ing to WHO guidelines (WHO, 2010) is usually performed. This analy- sis might reveal information essential for deciding whether ART should be recommended as a treatment. The method is time-consuming and prone to limited reproducibility and high inter-personnel variation (Tomlinson, 2016). Several computer-aided sperm analyses (CASA) systems are available, but they are still most suitable for assessing sper- matozoa separated from seminal plasma, and their reliability is debat- able (Mortimer et al., 2015). When selecting spermatozoa to inject for ICSI, the procedure is performed by visually evaluating the morphology and motility of sper- matozoa with an ICSI microscope. This selection process is subjective, based on a qualitative evaluation of the operator, and not on objective sperm characteristics. The potential of AI in ART New technologies, such as better cameras and data capturing systems, are rapidly becoming an integrated part of the fertility clinic and result in a vast amount of stored data, including patient data, embryo time- lapse videos and sperm videos. In recent years, AI has proved to be a valuable tool in medicine by analysing large amounts of data (Hosny et al., 2018; Yang and Bang, 2019). A typical approach for using AI models in ART can be seen in Fig. 1. In particular, machine learning (ML), a subfield within AI, refers to algorithms that automatically learn from data without being explicitly programmed. An overview of common AI methods used in ART is given in Fig. 2. Supervised and unsupervised learning are subgroups of ML. Supervised learning refers to methods that learn from datasets where the answer (the label) is given for each observation. An ob- servation within a dataset could be data from an ART cycle, like an embryo image, and the label regarding whether the embryo resulted in a pregnancy or not. The algorithm will learn from the dataset, and the resulting ML model can be used to predict preg- nancy or not for data from another ART cycle with unknown labels. Unsupervised learning refers to methods that search for patterns in unlabelled data, for example, automatically grouping blastocyst images based on visual features automatically deter- mined by the algorithm that may correlate with morphological characteristics. Such visual features can be completely different from what human observers are able to recognise or may see as relevant. Artificial neural networks (ANNs) are a class of super- vised learning, and deep neural networks (DNNs), or deep learn- ing (DL), refers to especially large and complex ANNs. DL methods have the ability to learn from unstructured data such as images or text. Details of studies discussed in this review can be found in Table I for embryo related articles and in Table II for sperm related articles. AI in embryo assessment Most articles about embryo assessment and selection for transfer address the prediction of embryo quality, grading and ranking, and compare the performance of the AI model with an evaluation done by embryologists (Dirvanauskas et al., 2019; Kanakasabapathy et al., 2019; Khosravi et al., 2019; Raudonis et al., 2019; Fukunaga et al., 2020; Bormann et al., 2020a, 2020b; Rad et al., 2020; Zhao et al., 2021). To make an automatic grading system, the model must learn to locate the embryo in the dish, segment important features, and then assess and grade the embryo from manually annotated data. Manual annotations provided by embryologists are time-consuming to create, leading to small and sparsely annotated datasets. Therefore, most studies of AI methods and resulting models in ART can be considered preliminary. With the development of time-lapse technology, access to image and video data has become more available, making it possible to utilise this data to build new AI models. Dirvanauskas et al. (2019) predicted em- bryo development stages by time-lapse videos using features extracted from a Convolutional Neural Network (CNN). In one study, an auto- mated system was established to detect pronuclei in time-lapse images with the precision almost equivalent to highly skilled embryologists (Fukunaga et al., 2020). In another study, the zona pellucida (ZP) and the cytoplasm and pronucleus in zygotes were detected by developing an algorithm using DL image segmentation technology (Zhao et al., 2021). One group reported the possibility of identifying human em- bryo development stages (Raudonis et al., 2019). First, the location of an embryo in the image was detected by employing a visual image feature-based classifier. Then, a multi-class prediction model was de- veloped to predict the cell stage of the embryo using DL. Others reported a system to detect and assess blastocyst quality by using DL to detect the ZP area (Rad et al., 2018). Data augmentation techniques, like cropping and resizing which are usually used to increase dataset size or variation, were applied to em- bryo assessment to compensate for the lack of data for training the DL models (Rad et al., 2020). Augmented images were proven to be effective in filling the generalisation gap when available data is limited. Experimental results confirmed that the proposed models were capa- ble of segmenting trophectoderm (TE) regions. Inner cell mass (ICM) has been assessed by a computer-based and semi-automatic grading of human blastocysts (Santos Filho et al., 2012). A CNN was able to predict ICM and TE grades from a single frame (a frame is an image extracted from a video), and a recurrent neural network was applied on top to incorporate temporal informa- tion of the expanding blastocysts from multiple frames. Additionally, when evaluating implantation rates for embryos grouped by morphol- ogy grades, a CNN provided a slightly higher correlation between pre- dicted embryo quality and implantation ability than did human 2430 Riegler et al. ....................................................................... embryologists (Kragh et al., 2019). The use of a CNN trained to as- sess an embryo’s implantation potential directly, when using euploid embryos capable of implantation, outperformed 15 trained embryolo- gists (Bormann et al., 2020a). In a retrospective analysis of time-lapse videos and clinical outcomes of 10 000 embryos from eight different IVF clinics across four different countries, a DL model was built with a high level of predictability re- garding the embryo implantation likelihood (Tran et al., 2019). A pro- spective double-blinded study using retrospective data addressed the variability between embryologists to select embryos for biopsy and cryopreservation (Bormann et al., 2020b). It was found that the appli- cation of a DNN could improve the reliability and perform with high consistency during the process of embryo selection, thereby potentially improving outcomes. A DL-based system called Life Whisperer showed a sensitivity of 70% for viable embryos while maintaining a specificity of 61% for non-viable embryos across three independent blind test sets from different clinics (Ver Milyea et al., 2020). The model demonstrated a 25% increase over embryologists for accuracy, and the ranking comparison demonstrated an improvement of 42% over embryolo- gists. One embryo ranking model increased the success of ART treat- ments in oocyte donation programs (Alegre et al., 2021). The Figure 1. Development of a machine learning model. To implement a machine learning model at the clinic, at ﬁrst a clinically relevant aim should be deﬁned, and data must be collected in line with this aim. The collected data should then be stored in an appropriate format so that the ma- chine learning algorithm can process it. The stored data should be split into a training, validation and testing partitions to ensure a robust and thor- ough evaluation. In the optimal case the testing dataset is provided from an independent source (different clinic, new patients). These parts are then be used to build a model that is in line with the medical goal. After the model is built, it should be thoroughly evaluated to verify its generalisability and to avoid unintended biases. Once the model has been thoroughly tested, it can be implemented in the clinic. The model should be continuously monitored and tested while in production and as the circumstances required are updated. Figure 2. Subﬁelds deﬁned by artiﬁcial intelligence. Machine learning is the most relevant ﬁeld for the current develop- ment of artiﬁcial intelligence system for the clinic. Machine learning can further be split into traditional machine learning methods and deep learning. Note that the subﬁelds are not mutually exclusive; most of them rely heavily on machine learning, like computer vision and language processing. Artificial intelligence in the fertility clinic 2431 ............................................................................................................................................................................................................................. Table I Overview of studies using AI-methods in embryo assessment and selection, and for prediction before treatment. Year Study Aim of the study Outcome Dataset AI methods Summary answer 2017 Milewski et al. Investigating the poten- tial of using data on em- bryo implantation and morphokinetic parame- ters in predictive AI models. Probability of implanta- tion, clinical pregnancy. A dataset of time-lapse recordings of 610 em- bryos from 514 treat- ment cycles, morphokinetic parame- ters, data on implanta- tion, women’s age. It is unclear if the dataset was prospectively collected. Traditional ML (Principal Component Analysis) and Deep Learning (Multilayer Perceptron) Morphokinetic parame- ters from the time-lapse videos used to discrimi- nate between implanted and nonimplanted achieved an AUC of 0.71. 2018 Rad et al. Automatic segmentation of the Zona Pellucida. Segmentation of Zona Pellucida. A retrospective dataset consisting of images of blastocyst. Deep Learning The AI model was able to segment the Zona Pellucida with an IoU score of 0.78. 2019 Tran et al. Predict the probability of pregnancy with foetal heart from time-lapse videos. Foetal heart pregnancy or not. A retrospective dataset containing time-lapse videos of 10,638 em- bryos cultured to blasto- cyst stage from 1,648 patients across 8 IVF clinics. No manual as- sessment of videos. Deep Learning (CNN) AI model (IVY) was able to predict the probability of fetal heart pregnancy based on timelapse vid- eos with a mean AUC of 0.93. 2019 Dirvanauskas et al. Predict embryo develop- ment stage from time- lapse videos. Embryo development stage (1-cell, 2-cell, 4-cell, 8-cell, no embryo). A retrospective dataset containing 7,002 time- lapse images from 10 embryos. Deep learning (CNN) and traditional ML (K Nearest Neighbour, Cecoc, Decision Trees, Naive Bayes Classiﬁer) The AI model for em- bryo classiﬁcation achieved an accuracy of 97.62%. 2019 Kanakasabapathy et al. Develop inexpensive platforms for use in a stand-alone optical sys- tem and a smartphone- based optical system for automated grading of embryos based on images. Classiﬁcation of embryos based on cell morphology. A retrospective dataset containing 160 embryo images from a stand- alone optical system and 385 embryo images from a smartphone- based optical system. Models were pretrained on other high-quality embryo data. Deep Learning (CNN) Two systems were de- veloped for grading em- bryos (stand-alone imaging system and smartphone optical sys- tem). Both systems achieve an accuracy above 90%. 2019 Khosravi et al. Develop an AI model for accurate prediction of blastocyst quality and se- lection for single embryo for transfer. Classiﬁcation of embryos into poor-quality and good-quality. A retrospective dataset containing 12,001 time- lapse images at 110 hr post-insemination from 10,148 embryos. Manual classiﬁcation by embryol- ogists. Age of patient was included in the model for 2,182 em- bryos. Two external datasets were used for validation. Deep Learning (CNN) AI model (STORK) pre- dicted blastocyst quality with an AUC above 0.98. The model achieved an AUC of 0.90 and 0.76 respec- tively on two datasets from other clinics. 2019 Kragh et al. Develop AI method for automatic grading of blastocyst morphological appearance based on time-lapse images. Inner cell mass and tro- phectoderm grading, im- plantation rate. A dataset containing time-lapse videos of 4,483 embryos (both IVF and ICSI treatment). All images were graded by embryologists. Implantation information for 287 embryos. It is unclear if the dataset was prospectively collected. Deep Learning (CNN, Recurrent Neural Network) AI model achieved an accuracy of 65% for in- ner cell mass grading and 70% for trophectoderm grading. Prediction of im- plantation achieved an AUC of 0.66. (continued) 2432 Riegler et al. ............................................................................................................................................................................................................................. Table I Continued Year Study Aim of the study Outcome Dataset AI methods Summary answer 2019 Raudonis et al. Automatically detect hu- man embryo develop- ment stages during incubation. Detect embryo in an im- age and classify the em- bryo development stage (1-cell, 2-cell, 3-cell, 4-cell, > 4-cell). A dataset containing images of early-stage embryo development from an ESCO Miri TL incubator system. It is unclear if the dataset was prospectively collected. Deep Learning (CNN) Two AI models were considered, both achieved a stage classiﬁ- cation accuracy above 92%. The most difﬁcult stage to classify was 3-cell. 2019 Qiu et al. Prediction of a clinical model for estimating the cumulative live birth chance of the ﬁrst com- plete IVF cycle using pre- treatment variables in- cluding BMI and AMH. Cumulative live birth chance before IVF. A retrospective dataset containing age, AMH, BMI, duration of infertil- ity, previous live birth, previous miscarriage, previous abortion, and type of infertility. Traditional ML (Logistic Regression, Random Forest, XGBoost, Support Vector Machine) Four machine learning models were tested, of which XGBoost achieved the best score with an AUC of 0.73. The results indicate that BMI and AMH have a signiﬁcant impact on live birth. 2019 Vogiatzi et al. Predict live birth from embryo variables by in- cluding parameters that exert a meaningful effect on live birth following as- sisted reproduction. Live birth or not. 12 input features: Age (female), Age at menar- che, Difﬁculty during ET, Endometrium thickness prior to OR, ET/2PN, TQE D3, TQE D3/2PN, Total gonadotropins, Age group, Dyspareunia, Fresh or frozen cycle, Menarche > 12 years. The dataset was col- lected retrospectively. Deep Learning (Multilayer Perceptron) A multilayer perceptron using the 12 input fea- tures achieved a sensitiv- ity of 0.71 and a speciﬁcity of 0.70 for predicting live birth. 2020 Bori et al. Describe novel embryo features for implantation potential prediction that may be used as input data in AI models. Prediction of implanta- tion potential. A retrospective dataset containing time-lapse images from 637 em- bryos (ICSI-cycles with- out PGT, single fresh embryo transfer), Implantation rate based on foetal heartbeat ultra- sound after eight weeks. Oocyte donation programme. Deep Learning (Multilayer Perceptron) Two novel embryo fea- tures with signiﬁcantly different values in implanted and nonim- planted embryos were identiﬁed. Novel embryo features, in addition to conventional morphoki- netic parameters, can improve predictive AI models. 2020 Bormann et al. (a) Evaluation of AI models for embryo selection based on images. Embryo quality and im- plantation potential. A retrospective dataset containing single time- point images at 113 h post-insemination for 742 embryos from 97 patients. Deep Learning (CNN) Two AI models were evaluated. One selected the highest quality em- bryo with 90% accuracy, and the other was able to assess implantation potential better than trained embryologists from different fertility centres. 2020 Bormann et al. (b) Evaluate AI models for embryo quality scoring and assessment of bi- opsy or cryopreserva- tion of blastocysts, compared to decisions by trained embryologists. Morphological quality on a 1–5 scale. For embryo scoring, images from 3469 em- bryos. 748 at 70 h post- insemination and 742 images at 113 h post-in- semination. For biopsy and cryopreservation as- sessment, 56 blastocysts images at 113 h post-in- semination. All images were evaluated by Deep Learning (CNN) The AI models showed less variability in embryo grading than embryolo- gists and outperformed the embryologists in selecting blastocyst bi- opsy and cryopreservation. (continued) Artificial intelligence in the fertility clinic 2433 ............................................................................................................................................................................................................................. Table I Continued Year Study Aim of the study Outcome Dataset AI methods Summary answer trained embryologists. Both datasets were ret- rospectively collected. 2020 Chavez-Badiola et al. (a) Evaluate AI model per- formance for prediction of ploidy and implanta- tion compared to trained embryologists. Embryo ranking, embryo ploidy. A retrospective dataset containing single time- point images from 840 embryos at day 5 or 6 after fertilization by ICSI. Ploidy, hCG results, or both were known. Deep Learning (Multilayer Perceptron) An AI model (ERICA) was able to identify and rank blastocysts with the best potential from one image with higher accu- racy than embryologists. 2020 Chavez-Badiola et al. (b) Predict pregnancy test results after embryo transfer. Successful pregnancy or not. A retrospective dataset containing embryo images and patient age. Traditional ML (Probabilistic Bayesian, Support Vector Machine, Decision Trees, Random Forest) and Deep Learning (Multilayer Perceptron) Several AI models were tested, of which the sup- port vector machine achieved the best result across three datasets. 2020 Fukunaga et al. Automatic pronuclei counting using deep learning. Number of pronuclei. A dataset containing 900 time-lapse images of 300 embryos up to 20 h post-insemination. 70 images of each embryo. Manual assessment and annotation of pronuclei. It is unclear if the dataset was prospectively collected. Deep Learning (CNN) The AI model was able to count pronuclei with a sensitivity of 99% for 0PN, 82% for 1PN, and 99% for 2PN. The sys- tem performed similarly to that of trained human experts. 2020 Rad et al. Automatic trophecto- derm segmentation in human embryo using deep learning. Trophectoderm segmentation. A retrospective dataset containing images of day-5 human embryo. Deep Learning (CNN, Generative Adversarial Networks) An AI model was used to segment human em- bryos. The model achieved an IoU score of 76.71. 2020 Raef et al. Predict implantation out- come after embryo transfer cycle. Implantation rate. Positive or negative beta-HCG. A dataset containing 82 features (patient-related data, female and male pathology, semen analy- sis, lab tests, oocyte and embryo data and PRP) Attributes related to im- plantation arranged in two groups (N ¼ 82): 1) patient-related features (N ¼ 59) and 2) ART cy- cle features (N ¼ 23). It is unclear if the dataset was prospectively collected. Traditional ML (Naive Bayes Classiﬁer, Support Vector Machine, Random Forest, K Nearest Neighbour, Decision Trees) and Deep Learning (Multilayer Perceptron) Six AI models were tested, where the ran- dom forest algorithm achieved the best result with an accuracy of 90.4% and an AUC of 93.7%. 2020 Ver Milyea et al. Predict embryo viability using images captured by optical light microscopy. Implantation rate—foe- tal heartbeat. A retrospective dataset containing light micros- copy images of blasto- cysts, clinical outcome. Deep Learning (Convolutional Neural Network) An AI model (Life Whisperer) was tested on three independent testing datasets, where it achieved a 70.1% sensi- tivity for viable embryos and a speciﬁcity of 60.5% for non-viable embryos. 2020 Goyal et al. Predict live birth before IVF treatment. Live birth or not. A retrospective dataset containing 141,160 pa- tient records, Deep Learning (Multilayer Perceptron) Several machine learning models were evaluated, of which the multilayer (continued) 2434 Riegler et al. .................................................. multicentre nature of the above study supported its applicability at dif- ferent clinics, standardising the interpretation of embryo development. Embryo assessment, ranking, and selection are procedures nor- mally based on evaluations at different time points during embryo development and in several focal planes to get a view of the whole embryo. There are numerous studies where only static images, usu- ally in one single focal plane, are used for the AI analysis, which do not mirror the clinical practice (Rad et al., 2018; Kanakasabapathy et al., 2019; Khosravi et al., 2019; Bormann et al., 2020a, 2020b; Chavez-Badiola et al., 2020a; Chavez-Badiola et al., 2020b; Bori et al., 2021). In these models, well-curated, high-quality data is cru- cial. For example, non-selection of a large number of images repre- sentative of the diversity, inconsistent image treatment or inaccurate labelling of images can lead to poor performing models (Tsipras et al., 2020). Models involving time-lapse videos might also raise problems since the definition of the important morphokinetic markers may vary between different laboratories and still requires an automated and unbiased process (Milewski et al., 2017; Dirvanauskas et al., 2019; Tran et al., 2019; Bori et al., 2020; Alegre et al., 2021). AI methods should incorporate patient data that may impact the outcome, such as maternal age. A framework (STORK) based on a large collection of human embryo time-lapse images used a CNN to automatically predict blastocyst quality depending on patient age (Khosravi et al., 2019). Milewski et al. (2017) extracted several time points and specific relative cleavage times together with fragmentation levels, presence of multinucleation, evenness of blastomeres and woman’s age. An ANN was trained to predict embryo implantation from the extracted features. Another study that included 82 features of patient data found that follicle stimulating hormone/human meno- pausal gonadotropin dosage was the strongest predictor of embryo implantation (Raef et al., 2020). ............................................................................................................................................................................................................................. Table I Continued Year Study Aim of the study Outcome Dataset AI methods Summary answer anonymized register data collected from the year 2010–2016 obtained from the Human Fertilisation & Embryology Authority. perceptron performed best with an F1-Score of 72.94%. 2021 Alegre et al. Evaluate and test an au- tomatic software for em- bryo evaluation and selection (Dana). Embryo implantation potential. A retrospective dataset containing time-lapse images and patient char- acteristics from oocyte donation program. Phase 1: 1,676 embryos from 955 couples. Phase 2: 996 embryos from 249 cycles (multiple centres). Phase 3 147 embryos from 108 patients. Deep Learning (CNN) Increased success of IVF treatment was found with the assistance of au- tomated embryo ranking by Dana. The creation of a data cloud can improve the system further. 2021 Bori et al. Develop an AI model for prediction of live birth based on blastocyst morphology and proteo- mic proﬁle of culture media. Prediction of live birth. A retrospective dataset containing single time point images at 111 hr þ/- 1.5 hr from 212 patients. 186 embryos after exclusions (131 non PGT from oocyte donation programme, 55 PDG with proteomic proﬁle. Deep Learning (Multilayer Perceptron) Three AI models using both morphological and proteomic variables. The best model predicted live birth with an AUC of 1.0. 2021 Zhao et al. Automatic segmentation of day one embryos in zona pellucida (ZP), cy- toplasm, and pronucleus (PN). Cytoplasm, ZP and PN segments. A dataset containing images of day-one em- bryos (zygotes). It is unclear if the dataset was prospectively collected. Deep Learning (CNN, Generative Adversarial Networks) The AI model achieved a precision of 97% when segmenting the cyto- plasm, 80% for the zona pellucida, and 84% for the pronucleus. AI, Artiﬁcial intelligence; CNN, Convolutional neural network; AUC, Area under the curve; IVF, In vitro fertilization; ICSI, Intracytoplasmic sperm injection; ZP, Zona pellucida; PN, Pronucleus, PGT, Preimplantation genetic testing; AMH, Anti-Mullerian hormone; BMI, body mass index. Artificial intelligence in the fertility clinic 2435 ............................................................................................................................................................................................................................ Table II Overview of studies using AI-methods in semen analysis and selection of sperm for ICSI. Year Study Aim of study Outcome Dataset AI Methods Summary answer 2014 Chang et al. Improve AI models for detection of hu- man sperm head characteristics in- cluding, acrosome and nucleus. Sperm morphology A prospective data- set containing 20 images with a total of 210 stained sperm cells. Sperm cell details were manu- ally classiﬁed and an- notated in the dataset. Traditional ML (Clustering) Models showed 80% overlap with manual classiﬁcation and more precise sperm head detection and segmentation than previously described models. 2017 Chang et al. Explore AI modes to classify sperm head morphology into ﬁve classes (normal, ta- pered, pyriform, small, amorphous) and introduce a new dataset. Sperm morphology A retrospective dataset containing images of 1,854 stained sperm heads from six semen smears (SCIAN MorphoSpermGS). Sperm head shape was manually classi- ﬁed and annotated in the dataset. 432 The best model was able to obtain 49% correct classiﬁcation of head shape into the ﬁve classes. 2017 Shaker et al. Explore Dictionary Learning technique for classiﬁcation of sperm head shapes into four classes (normal, tapered pyriform and amor- phous), and intro- duce a new dataset. Sperm morphology Two retrospective datasets. 216 images of stained sperm heads (HuSHeM dataset). Sperm head shape was manually classiﬁed and annotated in the dataset. 1133 images from the SCIAN- MorphoSpermGS dataset. Traditional ML (Dictionary Learning) Use of Dictionary Learning was more effective for sperm head classiﬁcation than previously pub- lished shape-based features. 2017 Goodson et al. Development of AI model for classiﬁca- tion of sperm motil- ity patterns during invitro capacitation. Sperm motility CASA tracks of 2,817 washed sperm cells from 18 sub- jects. All tacks were manually classiﬁed as progressive, interme- diate, hyperacti- vated, slow, weakly motile. It is unclear if the dataset was pro- spectively collected. Traditional ML (Support Vector Machine, Decision Tree) A web-based pro- gram, CASAnova, was developed. This program classiﬁes sperm motility pat- terns into one of ﬁve classes with an over- all accuracy of 89.9%. 2019 Agarwal et al. Evaluate the perfor- mance of an auto- mated AI system (LensHook) to mea- sure sperm concen- tration and sperm motility. Sperm concentration and sperm motility A prospective data- set containing images and video from 135 semen samples. No information available Concentration and motility analysed by LensHook were comparable to man- ual assessment. 2019 Hicks et al. Predict sperm motil- ity from videos and introduce a new dataset. Sperm motility A retrospective dataset containing videos of live sperm in untreated samples from 85 subjects (VISEM). Semen analysis was manually evaluated according to WHO 2010. Deep Learning (CNN) Deep learning showed potential for rapid and consistent prediction of sperm motility categories (WHO 2010) based on videos of live, untreated sperm samples. (continued) 2436 Riegler et al. ............................................................................................................................................................................................................................ Table II Continued Year Study Aim of study Outcome Dataset AI Methods Summary answer 2019 Riordon et al. Automatic assess- ment for classiﬁcation of sperm head mor- phology into ﬁve clas- ses (normal, tapered, pyriform, small, and amorphous). Sperm morphology Retrospective images from HuSHeM data- set and 1,132 images from SCIAN dataset. Deep learning (CNN) Deep learning can classify sperm head morphology with higher accuracy than previously published AI methods used for the same datasets. 2019 Javadi and Mirroshandel Automatic assess- ment of sperm mor- phology in unﬁxed cells and introduce a new dataset. Sperm morphology 1,540 retrospective grey scale images of unﬁxed sperm cells from 235 subjects (MHSMA dataset). Sperm cells were manually classiﬁed as normal or abnormal, and acrosome, head, vacuole, tail, and neck were annotated. Deep learning (CNN) The method is able to classify sperm in real-time, but accu- racy needs to be improved. 2019 McCallum et al. Automatic method for ranking sperm cells based on DNA quality enabling sperm selection for ICSI. Sperm DNA integrity 1,064 images of stained sperm cells with known DNA in- tegrity from 6 sub- jects. It is unclear if the dataset was pro- spectively collected. Deep learning (CNN) Correlation between cell image and DNA integrity was found, and the model was able to predict the DNA integrity of sperm cells in a rapid manner. 2019 Movahed et al. Automatic segmen- tation of external (head, mid piece, and tail) and internal parts (acrosome and nucleus) of the sperm. Sperm morphology A retrospective dataset containing 20 images of stained sperm cells. Sperm parts were manually annotated. Deep learning (CNN) and tradi- tional ML (Support Vector Machine, K- nearest neighbour, Ensemble Method) The methods were better at segmenting the head, acrosome, and nucleus than previously described models. Provides the ﬁrst method for eval- uation of tail and mid piece. 2020 Ilhan et al. Fully automated analyses of sperm morphology by a smartphone-based system and intro- duce a new dataset. Sperm morphology 200 retrospective images of stained sperm cells from 17 subjects (SMIDS dataset). Sperm cells were manually classi- ﬁed as normal or abnormal. Deep learning (CNN) and tradi- tional ML (Support Vector Machine, Decision Trees, K- Nearest Neighbours) The most precise model was able to predict normal or abnormal sperm with an accuracy of 87%. 2021 Abbasi et al. Improve AI models for classiﬁcation of the sperm head, vacuoles, and acro- some as normal or abnormal. Sperm morphology 1,540 retrospective images from the MHSMA dataset. Deep learning (CNN) Both AI models were able to predict sperm head charac- teristics more accu- rately than models previously described in other studies. 2021 Valiuskaite et al. Propose an AI method that can pre- dict if a semen sam- ple is suitable for artiﬁcial insemination procedure based on videos of semen samples. Sperm motility 85 retrospective videos from the VISEM dataset. Deep learning (CNN) The AI model detected sperm heads in the videos with an accuracy of 91.8%, and the Pearson correlation between manually assessed motility and predicted sperm head motility was 0.969. AI, Artiﬁcial intelligence; CNN, Convolutional neural network; CASA, Computer-assisted semen analysis. Artificial intelligence in the fertility clinic 2437 ............................................................................................................................................................................. AI in prediction of outcome before treatment In several publications, AI was used to build models that predict the possibility of a successful treatment based on a patient’s medical re- cord. The result may be of value for patient counselling about the po- tential results of the treatment. Goyal et al. (2020) used the dataset provided by Human Fertilisation and Embryology Authority (HFEA) which included 30 different features such as age, number of previous ART cycles, number of previous pregnancies, number of inseminated oocytes, number of embryos transferred, and diagnosis for a total of 140 000 patients. Several ML techniques were evaluated to predict live-birth occurrence. They concluded that both male and female traits and living conditions were factors that influenced the outcome of the treatment. A well-known ML technique called extreme gradient boosting (XGBoost) has been used to predict live birth from fea- tures such as age, anti-Mullerian hormone, BMI and patient anam- nesis (Qiu et al., 2019). Similarly, an ANN was trained to predict live birth using a collection of features such as the age of the fe- male, total dose of gonadotrophins administered, endometrial thick- ness, and the number of top-quality embryos (Vogiatzi et al., 2019). AI in analysis of sperm Most studies using an AI approach for semen analyses have been per- formed for morphology assessments. The morphological classification is usually performed on stained spermatozoa and implies both distin- guishing abnormal from normal spermatozoa as well as identifying vari- ous defects of the sperm cell (WHO, 2010). Some of the developed AI models have been trained only to predict the morphology of sperm heads (Chang et al., 2014; Chang et al.; 2017; Shaker et al., 2017; Riordon et al., 2019), whereas other studies describe the recognition of various parts of the whole sperm (Movahed et al., 2019; Ilhan et al., 2020). These differences in the approaches make it difficult to com- pare results and possible implications for clinical practice even if the overall goal is similar. This is also fortified by the fact that the data used is usually very limited, with only a small number of spermatozoa or patients. Training and evaluating complex methods, for example, DL, with a small-sized dataset most probably leads to an overfitted model. An overfitted model is a model that does not generalise well to unseen real-world cases although it works well on the training data. For example, suppose that a model is trained on a dataset of embryo images to predict pregnancy or not. If the model achieves far higher prediction performance on the embryo images used for training than on new and unseen images, the model is overfitted to the training data. Annotation of the dataset/sperm images must be done manually and with high accuracy to obtain well-performing models. For recog- nising and interpreting images of spermatozoa at the pixel level, seg- mentation is the common approach, in which the spermatozoon is divided into parts, each consisting of a set of pixels. Some studies demonstrate high classification accuracy for morphological characteris- tics, and most of the studies have both trained and validated the mod- els on freely available datasets, which makes them easier to compare (HuSHeM in Shaker et al. (2017), SCIAN in Chang et al. (2017), and a smaller dataset of 264 spermatozoa in Chang et al. (2014)). Furthermore, the model performance is compared with existing AI models, and even though this is common practice in the field of AI, it reveals little knowledge about the clinical usability of the model. Regarding sperm morphology, as far as we know, there are no studies comparing the performance of the models with manual assessment according to the WHO guidelines or in relation to fertility outcomes. For prediction of sperm motility, only one study compared AI-based sperm motility classification against sperm motility that was manually assessed following WHO guidelines (Hicks et al., 2019), while others were mainly focused on comparing various models or exploring the sperm kinematics (Goodson et al., 2017; Valiuskait_e et al., 2020). Studies related to motility and/or morphology also come with the challenge of small datasets, and for both of them, the evaluation pro- cedures are often not clear. Cross validation is sometimes used to compensate for small datasets (Goodson et al., 2017; Shaker et al., 2017). However, even though cross validation is acceptable for testing model performance and comparing it to other models on the same dataset, it does not test the generalisability of the results. In a clinical setting, an independent test set evaluation should be performed, opti- mally across different clinics (Abbasi et al., 2021). Automatic systems for diagnostic purposes have been developed. One such system based on an automatic segmentation step and a clas- sification of normal/abnormal spermatozoa has recently been de- scribed (Ilhan et al., 2020). The authors reported an accuracy of 87%. However, the method was just compared with other ML methods and not evaluated for its clinical value. In addition, accuracy alone is not a sufficient metric to determine the possible clinical performance of a method, especially if only a small dataset is used. Another automatic system for analysis of sperm concentration, morphology and motility used AI optical microscopic technology, for which the performance was compared with manual assessment (Agarwal et al., 2019, 2021). Nonetheless, the morphology values did not correlate with the manual morphology results, and unfortunately, there are no details provided on the construction and annotation of the dataset. Parameters that are not part of standard semen analysis have also been used in AI models. For example, sperm intracellular pH was shown to be a stable marker for fertilisation outcome (Gunderson et al., 2021), and sperm DNA integrity could be predicted from bright- field sperm images at a single cell level through supervised training (McCallum et al., 2019). These studies show how AI can be used to automate sperm sorting and selection tasks. However, big datasets from multicentre cohorts are needed to evaluate whether the results are generalisable before these AI models can be used in the clinic as well as for research related purposes. In addition to the conventional semen variables, image features may detect sperm characteristics that are too complex to be recognised by humans, for example, motility patterns or morphological shapes. Nonetheless, from a diagnostic per- spective, the clinical value of novel traits must be investigated in epide- miological studies. The selection of spermatozoa for ICSI is based on a cursory assess- ment of motility and morphology in real-time, which is especially a challenge for morphology evaluation. The procedure has a potential for improvement using AI to obtain a more objective selection based on the simultaneous monitoring of morphology and motility patterns. Attempts have been made to develop DL models for morphological assessment based on images of unstained spermatozoa (Javadi and Mirroshandel, 2019; Abbasi et al., 2021). Both algorithms can analyse 2438 Riegler et al. ............................................................................................................................................................................. fresh human sperm in real-time with a magnification between 400 and 600. The AI methods used in sperm related studies are mostly based on simple algorithms that are standard implementation in most ML frame- works (Table II). The development of more domain-specific methods and models related to ART will in the long run lead to better results compared to using out-of-the-box methods from existing generic frameworks. Pitfalls The AI algorithms are only as good as the data they are based on. There may also be limitations regarding generalisability due to difficul- ties with the standardisation of the ML methods. Variation in patient demographics, clinical and laboratory practices may cause data bias. When an AI model is based on training in one clinic, the AI model should be validated in independent cohorts (Tran et al., 2019; Bormann et al., 2020b). Furthermore, the models should not be lim- ited to strict inclusion criteria, and optimally the datasets should con- tain data from different clinics where testing data should be from a different site than the training and validation data (Alegre et al., 2021; Bori et al., 2020). Another important issue is that patient data and treatment informa- tion are not easily obtained for research due to data privacy and ethi- cal considerations. This naturally limits the amount of patient related data to be used for training the AI model. DL methods, which are es- pecially suited for image and video classification, require a large amount of diverse data to be generalisable. Another weakness for some studies is that the data used for training are not connected to any treatment outcome, leading to overly complex models that might only detect irrelevant correlations (Dirvanauskas et al., 2019; Kanakasabapathy et al., 2019; Khosravi et al., 2019; Raudonis et al., 2019; Bormann et al., 2020a; Bormann et al., 2020b; Fukunaga et al., 2020; Rad et al., 2020; Zhao et al., 2021; Alegre et al., 2021). This can raise concerns like, for example, whether the prediction is related to the embryo implantation potential. Moreover, most articles resort to a positive heartbeat at ultrasound control or even a positive hCG test as their outcome, but the most important outcome in ART is the birth of a living, healthy child (Vogiatzi et al., 2019; Bori et al., 2021). AI models are usually evaluated using different metrics such as accu- racy, precision and sensitivity. Often only a small subset or even just a single metric is used to decide if the model performs well. This is not sufficient, and to make a proper estimation about the performance, a set of metrics needs to be considered. It might even be necessary to develop task specific performance measurements. The future symbiosis between AI and ART AI methods may be a supporting tool in predicting the patient’s individual chance of achieving a healthy child based on available patient data. Adjustments of treatment and prediction of risk and possibilities for complications during pregnancy may be other tasks guided by AI. In ART, AI models may assist in selecting methods, selecting the em- bryo for transfer, and selecting the spermatozoon for ICSI. As far as we know, no published studies have performed AI-guided sperm selection for ICSI. Detailed real-time assessment of both motil- ity and morphology simultaneously is a challenge in the present rou- tine. By analysing video recordings of sperm selections by ML methods that consider both the spatial and temporal domains, it may be possi- ble to detect patterns or unknown characteristics that can be related to ICSI outcomes. Similarly, until-now unrecognised features of impor- tance for embryo quality might also be detected by analysing images and videos of embryos. At present, most of the publications are of a retrospective nature and there is a lack of prospective studies. However, there are some studies that are using retrospective data to perform a prospective study (Bormann et al., 2020b; Huang et al., 2021). The latter should preferably be performed as randomised controlled trials, in which the performance of the AI model included in one arm is compared to decisions routinely performed at a fertility clinic in the other arm, and the outcome is defined as live births. The studies should optimally be designed to include just single embryo transfers to exclude the uncer- tainty arising when two (or more) embryos are transferred and only one child is born. Most studies using AI for embryo assessment or se- lection rely on manually extracted features from embryo images or videos. However, over the last couple of years, there has been a rapid increase in the use of DL techniques where features are automatically learned. There are also a few studies using image segmentation techni- ques to improve automatic embryo assessment (Rad et al., 2020) or to streamline manual assessment (Zhao et al., 2021). The impact of these methods in clinical practice is however limited and standardisa- tion, explainable methods and transparency are keys to improve it. Standardisation is essential for the development of an applicable and reliable AI model. It requires close interdisciplinary collaboration from the planning of the initial study to the clinical evaluation. In particular, for the successful implementation of AI in the field of ART, a close col- laboration between computer science, clinical experience and biologi- cal knowledge, which also agree on a common standard, is crucial. Most algorithms used in all the aforementioned articles, especially DL-based, are black boxes. Ongoing research tries to increase the un- derstanding of these black boxes (Holzinger et al., 2019; Arrieta et al., 2020). In ART, methods for better understanding of black boxes are still in their infancy, focusing on simple visualisation methods (Liu et al., 2020; Abbasi et al., 2021). However, the whole pipeline of an AI sys- tem should be transparent (Saito and Rehmsmeier, 2015), including the evaluation method and metrics that need to be described clearly (as in: Javadi and Mirroshandel, 2019; Bori et al., 2020). Increased transparency of AI in ART will also be beneficial for discussions of legal and ethical implications across countries, which often have different regulations. Furthermore, we need a common way of benchmarking and com- paring different systems. In computer science, this is often done using open benchmarking datasets collected and curated by the scientific community. If the hardware changes, like data collected at higher reso- lutions, the systems will have to be evaluated on the data collected from these new devices. This means we need these community-wide benchmarking datasets to be continuously tested before, during and af- ter clinical trials to verify the performance of AI models. This is not just important for research but also for commercial companies in the Artificial intelligence in the fertility clinic 2439 ............................................................................................................................................................................. field. Systems such as iDASCORE, KIDScore, Eeva and LensHooke should follow the same requirements and be transparent and open about data, methods and evaluation. The datasets also need to be continuously updated following tech- nological advances and new findings. There are a few open datasets for sperm and embryo (Shaker et al., 2017; Saeedi et al., 2017; Haugen et al., 2019; Javadi and Mirroshandel, 2019; Ilhan et al., 2020). For sperm, datasets such as VISEM (Haugen et al., 2019) and HuSHeM (Shaker et al., 2017) are commonly used for the evaluation of sperm characteristics. For embryos, even fewer public datasets ex- ist, and the data published by Saeedi et al. (2017) has been used for blastocyst evaluation. Ideally, one publicly available dataset should be used for developing algorithms and a hidden test dataset can be tested on hardware provided by, for example, the European Society of Human Reproduction and Embryology or the American Society for Reproductive Medicine. This would ensure a common standard for training and testing to provide reproducible and comparable results necessary to make AI in ART clinically relevant. Conclusion Several studies have applied ML in ART, some of them focusing on clinical relevance, while others concern AI methodological aspects. The limitations are often small datasets and the use of AI algorithms not specifically designed for the fertility clinic. Large open datasets and methods specifically developed and tailored for use in context with ART could lead to better results and understanding. For AI to significantly impact ART, the model must be developed in the context of clinical practice. Critical steps are proper evaluation and testing of AI systems in relation to outcomes and regulations, a better understanding of the technical aspects, and determination of the per- formance of AI models regarding practical value in the clinic. In addi- tion, it is important to standardise the use of AI in ART to enable more transparent, comparable, and reproducible results. To succeed with implementing AI as a valuable tool in the fertility clinic, a strong interdisciplinary collaboration is required between researchers in ART and AI as well as the clinical staff. In addition, there is a need for large-scale randomised controlled trials where sev- eral clinics are involved in testing the external validity of the algorithms before defining AI systems that are sufficiently robust for safe clinical implementation. Data availability The data generated during and/or analysed during the current study (information extracted from the reviewed articles) are available from the corresponding author on reasonable request. Authors’ roles M.A.R.: Lead for AI, literature review, writing and revising of text and tables. M.H.S.: Lead for embryo section, literature review, writing and revising. O.W.: Literature search and review, writing and revising. J.M.A.: Tables, figures, literature review, writing. S.A.H.: Tables, figures, literature review, writing and revising of text and tables. H.L.H.: Literature review, writing and revising. E.D.: Literature review, writing. P.H.: Literature review, writing. A.Y.: Literature review, writing. N.H.: Literature review, writing. T.B.H.: Lead for sperm section, literature review, writing and revising. Funding The work on this article was partially funded by the Frimedbio project ReproAI granted by the Norwegian Research Council with Project number 288727. Conflicts of interest Nothing to disclose. References Abbasi A, Miahi E, Mirroshandel SA. Effect of deep transfer and multi-task learning on sperm abnormality detection. Comput Biol Med 2021;128:104121. Agarwal A, Henkel R, Huang CC, Lee MS. Automation of human se- men analysis using a novel artificial intelligence optical microscopic technology. Andrologia 2019;51:e13440. Agarwal A, Panner Selvam MK, Ambar RF. Validation of LensHookeV R X1 PRO and computer-assisted semen analyzer compared with laboratory-based manual semen analysis. World J Mens Health 2021;39:e7. Alegre L, Del Gallego R, Bori L, Loewke K, Maddah M, Aparicio-Ruiz B, Palma-Govea AP, Marcos J, Meseguer M. Assessment of em- bryo implantation potential with a cloud-based automatic software. Reprod Biomed Online 2021;42:66–74. Armstrong S, Bhide P, Jordan V, Pacey A, Marjoribanks J, Farquhar C. Time-lapse systems for embryo incubation and assessment in assisted reproduction. Cochrane Database Syst Rev 2019; 5: CD011320. doi: 10.1002/14651858.CD011320.pub4. Arrieta AB, Diaz-Rodriguez N, Del Ser J, Bennetot A, Tabik S, Barbado A, Garcia S, Gil-Lopez S, Molina D, Benjamins R. et al. Explainable Artificial Intelligence (XAI): concepts, taxonomies, op- portunities and challenges toward responsible AI. Inform Fusion 2020;58:82–115. Bori L, Dominguez F, Fernandez EI, Del Gallego R, Alegre L, Hickman C, Quinonero A, Nogueira MFG, Rocha JC, Meseguer M. An artificial intelligence model based on the proteomic profile of euploid embryos and blastocyst morphology: a preliminary study. Reprod Biomed Online 2021;42:340–350. Bori L, Paya E, Alegre L, Viloria TA, Remohi JA, Naranjo V, Meseguer M. Novel and conventional embryo parameters as input data for artificial neural networks: an artificial intelligence model applied for prediction of the implantation potential. Fertil Steril 2020;114:1232–1241. Bormann CL, Kanakasabapathy MK, Thirumalaraju P, Gupta R, Pooniwala R, Kandula H, Hariton E, Souter I, Dimitriadis I, Ramirez LB. et al. Performance of a deep learning based neural 2440 Riegler et al. .............................................................................................................................................................................. network in the selection of human blastocysts for implantation. eLife 2020a;9:1–14. Bormann CL, Thirumalaraju P, Kanakasabapathy MK, Kandula H, Souter I, Dimitriadis I, Gupta R, Pooniwala R, Shafiee H. Consistency and objectivity of automated embryo assessments us- ing deep neural networks. Fertil Steril 2020b;113:781–787. Boulet SL, Mehta A, Kissin DM, Warner L, Kawwass JF, Jamieson DJ. Trends in use of and reproductive outcomes associated with intra- cytoplasmic sperm injection. JAMA 2015;313:255–263. Chang V, Garcia A, Hitschfeld N, Hartel S. Gold-standard for computer-assisted morphological sperm analysis. Comput Biol Med 2017;83:143–150. Chang V, Saavedra JM, Castaneda V, Sarabia L, Hitschfeld N, Hartel S. Gold-standard and improved framework for sperm head seg- mentation. Comput Methods Programs Biomed 2014;117:225–237. Chavez-Badiola A, Flores-Saiffe-Farias A, Mendizabal-Ruiz G, Drakeley AJ, Cohen J. Embryo Ranking Intelligent Classification Algorithm (ERICA): artificial intelligence clinical assistant predicting embryo ploidy and implantation. Reprod Biomed Online 2020a;41: 585–593. Chavez-Badiola A, Flores-Saiffe Farias A, Mendizabal-Ruiz G, Garcia- Sanchez R, Drakeley AJ, Garcia-Sandoval JP. Predicting pregnancy test results after embryo transfer by image feature extraction and analysis using machine learning. Sci Rep 2020b;10:4394. Dang VQ, Vuong LN, Luu TM, Pham TD, Ho TM, Ha AN, Truong BT, Phan AK, Nguyen DP, Pham TN. et al. Intracytoplasmic sperm injection versus conventional in-vitro fertilisation in couples with in- fertility in whom the male partner has normal total sperm count and motility: an open-label, randomised controlled trial. Lancet 2021;397:1554–1563. Dirvanauskas D, Maskeliunas R, Raudonis V, Damasevicius R. Embryo development stage prediction algorithm for automated time lapse incubators. Comput Methods Programs Biomed 2019; 177:161–174. Fukunaga N, Sanami S, Kitasaka H, Tsuzuki Y, Watanabe H, Kida Y, Takeda S, Asada Y. Development of an automated two pronuclei detection system on time-lapse embryo images using deep learning techniques. Reprod Med Biol 2020;19:286–294. Goodson SG, White S, Stevans AM, Bhat S, Kao C-Y, Jaworski S, Marlowe TR, Kohlmeier M, McMillan L, Zeisel SH. et al. CASAnova: a multiclass support vector machine model for the classification of human sperm motility patterns. Biol Reprod 2017; 97:698–708. Goyal A, Kuchana M, Ayyagari KPR. Machine learning predicts live-birth occurrence before in-vitro fertilization treatment. Sci Rep 2020;10:20925. Gunderson SJ, Puga Molina LC, Spies N, Balestrini PA, Buffone MG, Jungheim ES, Riley J, Santi CM. Machine-learning algorithm incorpo- rating capacitated sperm intracellular pH predicts conventional in vitro fertilization success in normospermic patients. Fertil Steril 2021;115:930–939. Haugen TB, Hicks SA, Andersen JM, Witczak O, Hammer HL, Borgli R, Halvorsen P, Riegler M. Visem: a multimodal video dataset of human spermatozoa. In: Proceedings of the 10th ACM Multimedia Systems Conference, 2019, 261–266. Hicks SA, Andersen JM, Witczak O, Thambawita V, Halvorsen P, Hammer HL, Haugen TB, Riegler MA. Machine learning-based analysis of sperm videos and participant data for male fertility pre- diction. Sci Rep 2019;9:16770. Holzinger A, Langs G, Denk H, Zatloukal K, Muller H. Causability and explainability of artificial intelligence in medicine. Wiley Interdiscip Rev Data Min Knowl Discov 2019;9:e1312. Hosny A, Parmar C, Quackenbush J, Schwartz LH, Aerts H. Artificial intelligence in radiology. Nat Rev Cancer 2018;18:500–510. Huang TTF, Kosasa T, Walker B, Arnett C, Huang CTF, Yin C, Harun Y, Ahn HJ, Ohta A. Deep learning neural network analysis of human blastocyst expansion from time-lapse image files. Reprod Biomed Online 2021; 42:1075–1085. doi:10.1016/ j.rbmo.2021.02.015. Høst E, Ernst E, Lindenberg S, Smidt-Jensen S. Morphology of sper- matozoa used in IVF and ICSI from oligozoospermic men. Reprod Biomed Online 2001;3:212–215. Ilhan HO, Sigirci IO, Serbes G, Aydin N. A fully automated hybrid hu- man sperm detection and classification system based on mobile-net and the performance comparison with conventional methods. Med Biol Eng Comput 2020;58:1047–1068. Javadi S, Mirroshandel SA. A novel deep learning method for auto- matic assessment of human sperm images. Comput Biol Med 2019; 109:182–194. Kanakasabapathy MK, Thirumalaraju P, Bormann CL, Kandula H, Dimitriadis I, Souter I, Yogesh V, Kota Sai Pavan S, Yarravarapu D, Gupta R. et al. Development and evaluation of inexpensive auto- mated deep learning-based imaging systems for embryology. Lab Chip 2019;19:4139–4145. Khosravi P, Kazemi E, Zhan Q, Malmsten JE, Toschi M, Zisimopoulos P, Sigaras A, Lavery S, Cooper LAD, Hickman C. et al. Deep learning enables robust assessment and selection of human blasto- cysts after in vitro fertilization. Npj Digit Med 2019;2:21. doi: 10.1038/s41746-019-0096-y. Kragh MF, Rimestad J, Berntsen J, Karstoft H. Automatic grading of human blastocysts from time-lapse imaging. Comput Biol Med 2019; 115:103494. Lemmen JG, Rodriguez NM, Andreasen LD, Loft A, Ziebe S. The to- tal pregnancy potential per oocyte aspiration after assisted reproduction-in how many cycles are biologically competent oocytes available? J Assist Reprod Genet 2016;33:849–854. Liu L, Jiao Y, Li X, Ouyang Y, Shi D. Machine learning algorithms to predict early pregnancy loss after in vitro fertilization-embryo transfer with fetal heart rate as a strong predictor. Comput Methods Programs Biomed 2020;196:105624. McCallum C, Riordon J, Wang Y, Kong T, You JB, Sanner S, Lagunov A, Hannam TG, Jarvi K, Sinton D. Deep learning-based selection of human sperm with high DNA integrity. Commun Biol 2019;2: 250. doi:10.1038/s42003-019-0491-6. Milewski R, Kuczynska A, Stankiewicz B, Kuczynski W. How much in- formation about embryo implantation potential is included in morpho- kinetic data? A prediction model based on artificial neural networks and principal component analysis. Adv Med Sci 2017;62:202–206. Mortimer ST, van der Horst G, Mortimer D. The future of computer-aided sperm analysis. Asian J Androl 2015;17:545–553. Movahed RA, Mohammadi E, Orooji M. Automatic segmentation of Sperm’s parts in microscopic images of human semen smears using concatenated learning approaches. Comput Biol Med 2019;109: 242–253. Artificial intelligence in the fertility clinic 2441 ........................................................................................................................ Paternot G, Devroe J, Debrock S, D’Hooghe TM, Spiessens C. Intra- and inter-observer analysis in the morphological assessment of early-stage embryos. Reprod Biol Endocrinol 2009;7:105.doi: 10.1186/1477-7827-7-105. Qiu J, Li P, Dong M, Xin X, Tan J. Personalized prediction of live birth prior to the first in vitro fertilization treatment: a machine learning method. J Transl Med 2019;17:317. doi:10.1186/s12967- 019-2062-5. Rad RM, Saeedi P, Au J, Havelock J. Human Blastocyst’s Zona Pellucida segmentation via boosting ensemble of complementary learning. Inform Med Unlocked 2018;13:112–121. Rad RM, Saeedi P, Au J, Havelock J. Trophectoderm segmentation in human embryo images via inceptioned U-Net. Med Image Anal 2020;62:101612. Raef B, Maleki M, Ferdousi R. Computational prediction of implanta- tion outcome after embryo transfer. Health Informatics J 2020;26: 1810–1826. Raudonis V, Paulauskaite-Taraseviciene A, Sutiene K, Jonaitis D. Towards the automation of early-stage human embryo develop- ment detection. BioMed Eng OnLine 2019;18:120. doi: 10.1186/s12938-019-0738-y. Riordon J, McCallum C, Sinton D. Deep learning for the classification of human sperm. Comput Biol Med 2019;111:103342. Saeedi P, Yee D, Au J, Havelock J. Automatic identification of human blastocyst components via texture. IEEE Trans Biomed Eng 2017; 64:2968–2978. Saito T, Rehmsmeier M. The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbal- anced datasets. PLoS One 2015;10:e0118432. Santos Filho E, Noble JA, Poli M, Griffiths T, Emerson G, Wells D. A method for semi-automatic grading of human blastocyst micro- scope images. Hum Reprod 2012;27:2641–2648. Shaker F, Monadjemi SA, Alirezaie J, Naghsh-Nilchi AR. A dictionary learning approach for human sperm heads classification. Comput Biol Med 2017;91:181–190. Storr A, Venetis CA, Cooke S, Kilani S, Ledger W. Inter-observer and intra-observer agreement between embryologists during selec- tion of a single Day 5 embryo for transfer: a multicenter study. Hum Reprod 2017;32:307–314. Sundvall L, Ingerslev HJ, Breth Knudsen U, Kirkegaard K. Inter- and intra-observer variability of time-lapse annotations. Hum Reprod 2013;28:3215–3221. Tomlinson MJ. Uncertainty of measurement and clinical value of se- men analysis: has standardisation through professional guidelines helped or hindered progress? Andrology 2016;4:763–770. Tran D, Cooke S, Illingworth PJ, Gardner DK. Deep learning as a predictive tool for fetal heart pregnancy following time-lapse incubation and blastocyst transfer. Hum Reprod 2019;34: 1011–1018. Tsipras D, Santurkar S, Engstrom L, Ilyas A, Madry A. From imagenet to image classification: contextualizing progress on benchmarks. Int Conference on Machine Learning, Vol. 119 2020, 9625–9635. Valiuskait_e V, Raudonis V, Maskeliunas R, Damasevicius R, Krilavicius T. Deep learning based evaluation of spermatozoid motility for ar- tificial insemination. Sensors 2021;21:72. Vander Borght M, Wyns C. Fertility and infertility: definition and epi- demiology. Clin Biochem 2018;62:2–10. Ver Milyea M, Hall JMM, Diakiw SM, Johnston A, Nguyen T, Perugini D, Miller A, Picou A, Murphy AP, Perugini M. Development of an artificial intelligence-based assessment model for prediction of em- bryo viability using static images captured by optical light micros- copy during IVF. Hum Reprod 2020;35:770–784. Vogiatzi P, Pouliakis A, Siristatidis C. An artificial neural network for the prediction of assisted reproduction outcome. J Assist Reprod Genet 2019;36:1441–1448. WHO Laboratory Manual for the Examination and Processing of Human Semen, 5th edn. Genova, Switzerland: WHO Press, 2010. World Health Organization. Wyns C, Bergh C, Calhaz-Jorge C, De Geyter C, Kupka M, Motrenko T, Rugescu I, Smeenk JA. ART in Europe, 2020: results generated from European registries by ESHRE. Hum Reprod Open 2020: hoaa032. doi: 10.1093/hropen/hoaa032. Yang YJ, Bang CS. Application of artificial intelligence in gastroenter- ology. World J Gastroenterol 2019;25:1666–1683. Zhao M, Xu M, Li H, Alqawasmeh O, Chung JPW, Li TC, Lee TL, Tang PMK, Chan DYL. Application of convolutional neural net- work on early human embryo segmentation during in vitro fertiliza- tion. J Cell Mol Med 2021;25:2633–2644. 2442 Riegler et al."
EvoDynamic: A Framework for the Evolution of Generally Represented Dynamical Systems and Its Application to Criticality,"Pontes-Filho, Sidney
and Lind, Pedro
and Yazidi, Anis
and Zhang, Jianhua
and Hammer, Hugo
and Mello, Gustavo B. M.
and Sandvig, Ioanna
and Tufte, Gunnar
and Nichele, Stefano",2020,,,,inproceedings,"EvoDynamic: a framework for the evolution of
generally represented dynamical systems and its
application to criticality
Sidney Pontes-Filho1,2[0000−0002−0489−5652], Pedro Lind1, Anis Yazidi1,
Jianhua Zhang1, Hugo Hammer1, Gustavo B. M. Mello1, Ioanna Sandvig3,
Gunnar Tufte2, and Stefano Nichele1,4
1 Department of Computer Science, Oslo Metropolitan University, Oslo, Norway
2 Department of Computer Science, Norwegian University of Science and Technology,
Trondheim, Norway
3 Department of Neuromedicine and Movement Science, Norwegian University of
Science and Technology, Trondheim, Norway
4 Holistic Systems, SimulaMet, Oslo, Norway
Email: sidneyp@oslomet.no
Abstract. Dynamical systems possess a computational capacity that
may be exploited in a reservoir computing paradigm. This paper presents
a general representation of dynamical systems which is based on matrix
multiplication. That is similar to how an artiﬁcial neural network (ANN)
would be represented in a deep learning library and its computation
would be faster because of the optimized matrix operations that such
type of libraries have. Initially, we implement the simplest dynamical
system, a cellular automaton. The mathematical fundamentals behind
an ANN are maintained, but the weights of the connections and the ac-
tivation function are adjusted to work as an update rule in the context
of cellular automata. The advantages of such implementation are its us-
age on specialized and optimized deep learning libraries, the capabilities
to generalize it to other types of networks and the possibility to evolve
cellular automata and other dynamical systems in terms of connectivity,
update and learning rules. Our implementation of cellular automata con-
stitutes an initial step towards a more general framework for dynamical
systems. Our objective is to evolve such systems to optimize their usage
in reservoir computing and to model physical computing substrates. Fur-
thermore, we present promising preliminary results toward the evolution
of complex behavior and criticality using genetic algorithm in stochastic
elementary cellular automata.
Keywords: Cellular automata · Dynamical systems · Implementation ·
Reservoir computing · Evolution · Criticality
1
Introduction
A cellular automaton (CA) is the simplest computing system where the emer-
gence of complex dynamics from local interactions might take place. It consists
This is a post-peer-review, pre-copyedit version of a conference proceeding published in Applications of Evolutionary Computation 23rd European Conference, 
EvoApplications 2020, Held as Part of EvoStar 2020, Proceedings, that is part of the Lecture Notes in Computer Science book series (volume 12104). 
The final authenticated version is available online at: https://doi.org/10.1007/978-3-030-43722-0_9
 2
S. Pontes-Filho et al.
of a grid of cells with a ﬁnite number of states that change according to sim-
ple rules depending on the neighborhood and own state in discrete time-steps.
Some notable examples are the elementary CA [30], which is unidimensional
with three neighbors and eight update cases, and Conway’s Game of Life [24],
which is two-dimensional with nine neighbors and three update cases.
Table 1 presents some computing systems that are capable of giving rise to
the emergence of complex dynamics. Those systems can be exploited by reservoir
computing, which is a paradigm that resorts to dynamical systems to simplify
complex data. Such simpliﬁcation means that reservoir computing utilizes the
non-linear dynamical system to perform a non-linear transformation from non-
linear data to higher dimensional linear data. Such linearized data can be applied
in linear machine learning methods which are faster for training and computing
because has less trainable variables and operations. Hence, reservoir computing
is more energy eﬃcient than deep learning methods and it can even yield compet-
itive results, especially for temporal data [25,27]. Basically, reservoir computing
exploits a dynamical system that possesses the echo state property and fading
memory, where the internals of the reservoir are untrained and the only training
happens at the linear readout stage [16].
Reservoir computers are most useful when the substrate’s dynamics are at
the “edge of chaos” [17], meaning a range of dynamical behaviors that is between
order and disorder. Cellular automata with such dynamical behavior are capable
of being exploited as reservoirs [21,22]. Other systems can also exhibit similar
dynamics. The coupled map lattice [15] is very similar to CA, the only exception
is that the coupled map lattice has continuous states which are updated by a
recurrence equation involving the neighborhood. Random Boolean network [10]
is a generalization of CA where random connectivity exists. Echo state network
[13] is an artiﬁcial neural network (ANN) with random topology while liquid
state machine [18] is similar to echo state network with the diﬀerence that it is a
spiking neural network that communicates through discrete-events (spikes) over
continuous time.
One important aspect of the computation performed in a dynamical system
is the trajectory of system states traversed during the computation [19]. Such
trajectory may be guided by system parameters [23]. Another characteristic of
a dynamical system, which is crucial for computation, is to be in a critical state,
Table 1: Examples of dynamical systems.
Dynamical system
State
Time
Connectivity
Cellular automata
Discrete
Discrete
Regular
Coupled map lattice
Continuous Discrete
Regular
Random Boolean network Discrete
Discrete
Random
Echo state network
Continuous Discrete
Random
Liquid state machine
Discrete
Continuous Random
 EvoDynamic: a framework for the evolution of dynamical systems
3
as indicated by Langton [17]. If the attractors of the system are in the critical
state, this characteristic is called self-organized criticality [7].
Besides, computation in dynamical systems may be carried out in physical
substrates [27], such as networks of biological neurons [3] or in nanoscale ma-
terials [8]. Finding the correct abstraction for the computation in a dynamical
system, e.g. CA, is an open problem [20].
All the systems described in Table 1 are sparsely connected and can be
represented by a weighted adjacency matrix, such as a graph. The connectivity
from a layer to another in a fully connected feedforward ANN is represented
with a weighted adjacency matrix that contains the weights of each connection.
Our CA implementation is similar to this, but the connectivity goes from the
“layer” of cells to itself.
The goal of representing CA with a weighted adjacency matrix is to imple-
ment a framework which facilitates the development of all types of CAs, from
unidimensional to multidimensional, with all kinds of lattices and without any
boundary conditions during execution; and also allowing the inclusion of other
major dynamical systems, independent of the type of the state, time and connec-
tivity. Such initial implementation is the ﬁrst component of a Python framework
under development, based on TensorFlow deep neural network library [4]. There-
fore, it beneﬁts from powerful and parallel computing systems with multi-CPU
and multi-GPU. One of the framework’s goals is to have a balance between
performance and generalization of computing dynamical systems, since general
methods are slower than specialized ones. Nevertheless, this framework, called
EvoDynamic, aims at evolving (i.e., using evolutionary algorithms) the connec-
tivity, update and learning rules of sparsely connected networks to improve their
usage for reservoir computing guided by the echo state property, fading memory,
state trajectory, and other quality measurements. Such improvement of reser-
voirs is applied similarly in [26], where the internal connectivity of a reservoir
is trained to increase its performance to several tasks. Moreover, evolution will
model the dynamics and behavior of physical reservoirs, such as in-vitro biolog-
ical neural networks interfaced with microelectrode arrays, and nanomagnetic
ensembles. Those two substrates have real applicability as reservoirs. For exam-
ple, the former substrate is applied to control a robot, in fact making it into a
cyborg, a closed-loop biological-artiﬁcial neuro-system [3], and the latter pos-
sesses computation capability as shown by a square lattice of nanomagnets [14].
Those substrates are the main interest of the SOCRATES project [1] which aims
to explore a dynamic, robust and energy eﬃcient hardware for data analysis.
There exist some implementations of CA similar to the one of EvoDynamic
framework. They typically implement Conway’s Game of Life by applying 2D
convolution with a kernel that is used to count the “alive” neighbors, then the
resulting matrix consists of the number of “alive” neighboring cells and is used to
update the CA. One such implementation, also based on TensorFlow, is available
open-source in [2].
This paper is organized as follows. Section 2 describes our method according
to which we use weighted adjacency matrix to compute CA. Section 3 presents
 4
S. Pontes-Filho et al.
the results obtained from the method. Section 4 discusses the initial advances
and future plan of EvoDynamic framework and Section 5 concludes this paper.
2
Method
In our proposed method, the equation to calculate the next states of the cells in
a cellular automaton is
ct+1 = f(A · ct).
(1)
It is similar to the equation of the forward pass of an artiﬁcial neural network,
but without the bias. The layer is connected to itself, and the activation function
f deﬁnes the update rules of the CA. The next states of the CA ct+1 is calculated
from the result of the activation function f which receives as argument the dot
product between the weighted adjacency matrix A and the current states of the
CA ct. c is always a column vector of size len(c) × 1, that does not depend on
how many dimensions the CA has, and A is a matrix of size len(c) × len(c).
Hence the result of A · c is also a column vector of size len(c) × 1 as c.
The implementation of cellular automata as an artiﬁcial neural network re-
quires the procedural generation of the weighted adjacency matrix of the grid.
In this way, any lattice type or multidimensional CAs can be implemented us-
ing the same approach. The adjacency matrix of a sparsely connected network
contains many zeros because of the small number of connections. Since we im-
plement it on TensorFlow, the data type of the adjacency matrix is preferably
a SparseTensor. A dot product with this data type can be up to 9 times faster
than the dense counterpart. However, it depends on the conﬁguration of the
tensors (or, in our case, the adjacency matrices) [28]. The update rule of the CA
alters the weights of the connections in the adjacency matrix. In a CA whose
cells have two states meaning “dead” (zero) or “alive” (one), the weights in the
adjacency matrix are one for connection and zero for no connection, such as an
ordinary adjacency matrix. Such matrix facilitates the description of the update
rule for counting the number of “alive” neighbors because the result of the dot
product between the adjacency matrix and the cell state vector is the vector
that contains the number of “alive” neighbors for each cell. If the pattern of the
neighborhood matters in the update rule, each cell has its neighbors encoded as
a n-ary string where n means the number of states that a cell can have. In this
case, the weights of the connections with the neighbors are n-base identiﬁers and
are calculated by
neighbori = ni, ∀i ∈{0..len(neighbors) −1}
(2)
where neighbors is a vector of the cell’s neighbors. In the adjacency matrix,
each neighbor receives a weight according to (2). The result of the dot product
with such weighted adjacency matrix is a vector that consists of unique integers
per neighborhood pattern. Thus, the activation function is a lookup table from
integer (i.e., pattern) to next state.
Algorithm 1 generates the weighted adjacency matrix for one-dimensional
CA, such as the elementary CA, where widthCA is the width or number of
 EvoDynamic: a framework for the evolution of dynamical systems
5
Algorithm 1 Generation of weighted adjacency matrix for 1D cellular automa-
ton
1: procedure generateCA1D
2:
numberOfCells ←widthCA
3:
A ←0numberOfCells×numberOfCells
▷Adjacency matrix initialization
4:
for i ←{0..(numberOfCells −1)} do
5:
for
j
←
{−indexNeighborCenter..(len(neighborhood)
−
indexNeighborCenter −1)} do
6:
currentNeighbor ←neighborhoodj+indexNeighborCenter
7:
if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧(0 ≤
(i + j) < widthCA)) then
8:
Ai,((i+j) mod widthCA) ←currentNeighbor
9:
return A
cells of a unidimensional CA and neighborhood is a vector which describes
the region around the center cell. The connection weights depend on the type
of update rule as previously explained. For example, in case of an elementary
CA neighborhood = [4 2 1]. indexNeighborCenter is the index of the center
cell in the neighborhood whose starting index is zero. isWrappedGrid is a
Boolean value that works as a ﬂag for adding a wrapped grid or not. A wrapped
grid for one-dimensional CA means that the initial and ﬁnal cells are neighbors.
With all these parameters, Algorithm 1 creates an adjacency matrix by looping
over the indices of the cells (from zero to numberOfCells −1) with an inner
loop for the indices of the neighbors. If the selected currentNeighbor is a non-
zero value and its indices do not aﬀect the boundary condition, then the value
of currentNeighbor is assigned to the adjacency matrix A in the indices that
correspond to the connection between the current cell in the outer loop and the
actual index of currentNeighbor. Finally, this procedure returns the adjacency
matrix A.
To procedurally generate an adjacency matrix for 2D CA instead of 1D CA,
the algorithm needs to have small adjustments. Algorithm 2 shows that for two-
dimensional CA, such as Conway’s Game of Life. In this case, the height of
the CA is an argument passed as heightCA. Neighborhood is a 2D matrix
and indexNeighborCenter is a vector of two components meaning the in-
dices of the center of Neighborhood. This procedure is similar to the one in
Algorithm 1, but it contains one more loop for the additional dimension.
The activation function for CA is diﬀerent from the ones used for ANN.
For CA, it contains the update rules that verify the vector returned by the
dot product between the weighted adjacency matrix and the vector of states.
Normally, the update rules of the CA are implemented as a lookup table from
neighborhood to next state. In our implementation, the lookup table maps the
resulting vector of the dot product to the next state of the central cell.
 6
S. Pontes-Filho et al.
Algorithm 2 Generation of adjacency matrix of 2D cellular automaton
1: procedure generateCA2D
2:
numberOfCells ←widthCA ∗heightCA
3:
A ←0numberOfCells×numberOfCells
▷Adjacency matrix initialization
4:
widthNB, heightNB ←shape(Neighborhood)
5:
for i ←{0..(numberOfCells −1)} do
6:
for
j
←
{−indexNeighborCenter0..(widthNB
−
indexNeighborCenter0 −1)} do
7:
for
k
←
{−indexNeighborCenter1..(heightNB
−
indexNeighborCenter1 −1)} do
8:
currentNeighbor ←Neighborhoodj+indexNeighborCenter
9:
if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧
(0 ≤((i mod heightCA)+j) < widthCA)∧(0 ≤(⌊i/widthCA⌋+k) < heightCA))
then
10:
Ai,(((i+k) mod widthCA)+((⌊i/widthCA⌋+j) mod heightCA)∗widthCA) ←
currentNeighbor
11:
return A
3
Results
This section presents the results of the proposed method and it also stands for
the preliminary results of the EvoDynamic framework.
Fig. 1 illustrates a wrapped elementary CA described in the procedure of
Algorithm 1 and its generated weighted adjacency matrix. Fig. 1a shows the
appearance of the desired elementary CA with 16 cells (i.e., widthCA = 16).
Fig. 1b describes its pattern 3-neighborhood and the indices of the cells. Fig 1c
shows the result of the Algorithm 1 with the neighborhood calculated by (2) for
pattern matching in the activation function. In Fig. 1c, we can verify that the
left neighbor has weight equal to 4 (or 22 for the most signiﬁcant bit), central cell
weight is 2 (or 21) and right neighbor weight is 1 (or 20 for the least signiﬁcant
bit) as deﬁned by (2). Since the CA is wrapped, we can notice in row index 0
of the adjacency matrix in Fig. 1c that the left neighbor of cell 0 is the cell 15,
and in row index 15 that the right neighbor of cell 15 is the cell 0.
Fig. 2 describes a wrapped 2D CA (similar to Game of Life but with less
number of neighbors) for Algorithm 2 and shows the resulting adjacency matrix.
Fig. 2a illustrates the desired two-dimensional CA with 16 cells (i.e., widthCA =
4 and heightCA = 4). Fig. 2b presents the von Neumann neighborhood [29]
which is used for counting the number of “alive” neighbors (the connection
weights are only zero and one, and Neighborhood argument of Algorithm 2
deﬁnes it). It also shows the index distribution of the CA whose order is preserved
after ﬂatting it to a column vector. Fig 2c contains the generated adjacency
matrix of Algorithm 2 for the described 2D CA. Fig. 2b shows an example of
a central cell with its neighbors, the index of this central cell is 5 and the row
index 5 in the adjacency matrix of Fig. 2c presents the same neighbor indices,
i.e., 1, 4, 6 and 9. Since this is a symmetric matrix, the columns have the same
connectivity of the rows. That means the neighborhood of a cell considers this cell
 EvoDynamic: a framework for the evolution of dynamical systems
7
as a neighbor too. Therefore, the connections are bidirectional and the adjacency
matrix represents an undirected graph. The wrapping eﬀect is also observable.
For example, the neighbors of the cell index 0 are 1, 3, 4 and 12. So the neighbors
3 and 12 are the ones that the wrapped grid allowed to exist for cell index 0.
(a)
(b)
(c)
Fig. 1: Elementary cellular automaton with 16 cells and wrapped grid. (a) Exam-
ple of the grid of cells with states. (b) Indices of the cells and standard pattern
neighborhood of elementary CA where thick border means the central cell and
thin border means the neighbors. (c) Generated weighted adjacency matrix for
the described elementary CA.
4
On-going and future applications with EvoDynamic
The method of implementing a CA as an artiﬁcial neural network is beneﬁcial for
the further development of EvoDynamic framework. Since the implementation of
 8
S. Pontes-Filho et al.
(a)
(b)
(c)
Fig. 2: 2D cellular automaton with 16 cells (4×4) and wrapped grid. (a) Example
of the grid of cells with states. (b) Indices of the cells and von Neumann counting
neighborhood of 2D CA where thick border means the current cell and thin
border means the neighbors. (c) Generated adjacency matrix for the described
2D CA.
 EvoDynamic: a framework for the evolution of dynamical systems
9
all sparsely connected networks in Table 1 is already planned in forthcoming re-
leases of the Python framework, EvoDynamic shall have a general representation
to all of them. Therefore, CAs are treated as ANNs and then can be extended to
random Boolean network by shuﬄing the connections, and to the models that
are already ANNs, such as echo state networks and liquid state machines. More-
over, EvoDynamic framework will evolve the connectivity, update and learning
rules of the dynamical systems for reservoir computing improvement and physi-
cal substrate modeling. This common representation facilitates the evolution of
such systems and models which will be guided by several methods that measure
the quality of a reservoir or the similarity to a dataset. The following subsections
explain two on-going applications with CA that use the EvoDynamic framework.
4.1
State trajectory
An example of methods to guide the evolution of dynamical system is the state
trajectory. This method can be used to cluster similar states for model abstrac-
tion and to measure the quality of the reservoir. Therefore, a graph can be
formed and analysis can be made by searching for attractors and cycles. For
visualization of the state trajectory, we use principal component analysis (PCA)
to reduce the dimensionality of the states and present them as a state transi-
tion diagram as shown in Fig. 3. The depicted dynamical system is Conway’s
Game of Life with 7x7 cells and wrapped boundaries. A glider is its initial state
(Fig. 3a) and this system cycles over 28 unique states as illustrated in the state
transition diagram of Fig. 3l.
4.2
Towards the evolution for criticality
Evolution of dynamical systems is a feature currently under development of
EvoDynamic framework. The ﬁrst on-going evolution task of our framework is
to ﬁnd systems with criticality [7] using genetic algorithm, in order to allow for
better computational capacity [17]. The ﬁrst dynamical system for this task is a
modiﬁed version of stochastic elementary cellular automata (SECA) introduced
by Baetens et al. [6]. Our stochastic elementary cellular automaton works as a
1D three neighbors elementary CA, but the next state in time t+1 of the central
cell ci is deﬁned by a probability p to be 1 and a probability 1−p to be 0 for each
of the eight diﬀerent neighborhood patterns this CA has. Formally, probability
p is represented by
p = P(ci,t+1 = 1|N(ci,t))
(3)
where the neighborhood pattern N(ci,t) is denoted as
N(ci,t) = (ci−1,t, ci,t, ci+1,t).
(4)
The genetic algorithm for criticality is guided by a ﬁtness function which
mainly veriﬁes if the probability distributions of avalanche size (i.e., cluster size5
5 Cluster size stands for the number of repetitions of a state that happened consecu-
tively without any interruption of another state.
 10
S. Pontes-Filho et al.
−1
0
1
−1
0
1
(a) Step 1
−1
0
1
−1
0
1
(b) Step 2
−1
0
1
−1
0
1
(c) Step 3
−1
0
1
−1
0
1
(d) Step 4
−1
0
1
−1
0
1
(e) Step 11
−1
0
1
−1
0
1
(f) Step 12
−1
0
1
−1
0
1
(g) Step 13
−1
0
1
−1
0
1
(h) Step 14
−1
0
1
−1
0
1
(i) Step 26
−1
0
1
−1
0
1
(j) Step 27
−1
0
1
−1
0
1
(k) Step 28
−1
0
1
−1
0
1
(l) Step 29
Fig. 3: States of Conway’s Game of Life in a 7x7 wrapped lattice alongside their
PCA-transformed state transition diagrams of the two ﬁrst principal compo-
nents. (a) Initial state is a glider. (a)-(d) Four ﬁrst steps in this CA. (e)-(h) Four
intermediate steps in this CA while reaching the wrapped border. (i)-(l) Four
last steps in this CA before repeating the initial state and closing a cycle.
in space) and duration (i.e., cluster size in time) follow a power-law distribu-
tion. Such veriﬁcation can be done by checking how linear is the probability
distribution in a log-log plot, by performing goodness-of-ﬁt tests based on the
Kolmogorov-Smirnov (KS) statistic and by comparing the power-law model with
the exponential model using log-likelihood ratio [9]. For our ﬁtness function, we
estimate the candidate distributions with the linear ﬁtting of the ﬁrst 10 points
of the log-log plot using least squares regression, which was veriﬁed to be not
biased and gives a fast and acceptable estimation of the slope of the power-law
distribution [12]. After the linear 10-points ﬁtting, the model is tested using KS
statistic. One beneﬁt of using such estimation method is that when the model
is not a power-law, the KS statistic reports a large error, i.e., an error greater
than one. Another objective in the ﬁtness function is the coeﬃcient of determi-
nation [31], but for a complete linear ﬁt of the log-log plot. The ﬁtness function
also considers the number of unique states of the stochastic elementary CA, the
number of bins in the raw histogram and the value of the estimated power-law
exponent. All these ﬁtness function objectives are calculated using a randomly
initialized CA of 1,000 cells with wrapped boundaries during 1,000 time-steps.
The avalanche size and duration are computed for the cell values 0 and 1, thus
producing four diﬀerent distributions (see Fig. 4) for extracting vectors of their
 EvoDynamic: a framework for the evolution of dynamical systems
11
normalized number of histogram bins6 bin; coeﬃcient of determination R2 of
complete linear ﬁtting; KS statistic D and estimated power-law exponent ˆα
from the 10-points linear estimation. The ﬁtness score s for each objective is
then calculated by the following equations:
bins = tanh(5 ∗(0.9 ∗max(bin) + 0.1 ∗mean(bin))),
(5)
R2
s = mean(R2),
(6)
Ds = exp(−(0.9 ∗min(D) + 0.1 ∗mean(D))),
(7)
ˆαs = mean(ˆα),
(8)
uniques = #uniqueStates
#timesteps
.
(9)
The (5)-(9) are all objective values for calculating the ﬁtness score s. Those
values are real numbers between zero and one, except the score for the estimated
power-law exponent ˆαs, and they have weights attributed to them regarding their
level of importance and for compensating small and large values. The following
equation denotes how the ﬁtness score s is calculated:
s = 10 ∗bins + 10 ∗R2
s + 10 ∗Ds + 0.1 ∗ˆαs + 10 ∗uniques.
(10)
The genetic algorithm has 40 individuals that evolve through 100 generations.
The optimization performed by GA is to maximize the ﬁtness score. The genome
of the individuals has eight real number genes with a value range between zero
and one. Each gene represents the probability of the next state becoming one
(i.e., p in (3)) for its respective neighborhood pattern. The selection of two par-
ents is done by deterministic tournament selection [11]. After that, the crossover
between the genomes of the parents can happen with probability 0.8, then each
gene can be exchanged with probability 0.5. Afterward, a mutation occurs to a
gene with probability 0.1. This mutation adds a random value from a normal
distribution with mean and standard deviation equals to, respectively, 0 and 0.2.
The mating process of the two parents produces an oﬀspring of two new individ-
uals who replace the parents in the next generation. An example of an evolved
genome for the best resulting individual is presented in Table 2. The ﬁtness score
s and all objective scores with their respective weights for calculating s are in
Table 3.
With the genome or probabilities of the eight diﬀerent neighborhood patterns
of the best evolved individual, we can produce the log-log plots of the probability
distribution of avalanche size and duration for the states zero and one. Such plots
6 The actual number of histogram bins is normalized or divided by the possible total
number of bins.
 12
S. Pontes-Filho et al.
Table 2: Best individual
Neighborhood N(ci,t) Probability p
(0,0,0)
0.103009
(0,0,1)
0.536786
(0,1,0)
0.216794
(0,1,1)
0.393468
(1,0,0)
0.679836
(1,0,1)
0.175458
(1,1,0)
0.724778
(1,1,1)
1.000000
Table 3: Fitness score of the best individual
Objective
Score
10 ∗bins
9.780749590096136
10 ∗R2
s
8.832520186440096
10 ∗Ds
9.655719560019996
0.1 ∗ˆαs
0.18022617747972156
10 ∗uniques 10.0
s
38.44921551403595
are depicted in Fig. 4. The p-value of goodness-of-ﬁt test is calculated using 1,000
randomly generated data with 10,000 samples applying the power-law exponent
ˆα estimated by maximum likelihood estimation method with minimum x of
the distribution ﬁxed to 1. The Fig. 4a and Fig. 4b show the avalanche size and
duration for the state 0 or black. They present distributions that are not a power-
law because they do not ﬁt the power-law estimation (the black dashed line).
Moreover, the p-value is equal to 0.0 which proves that those two distributions are
not a power-law. The Fig. 4c and Fig. 4d present the avalanche size and duration
for the state 1 or white. Those distributions follow a power-law because, visually,
the estimated power-law distribution ﬁts the empirical probability distribution
and, quantitatively, the p-value is equal to 1.0 which means that 100% of the KS
statistic of the generated data is greater than the KS statistic of the empirical
distribution of avalanche size and duration of state 1. The number of samples in
those distributions (62,731 for avalanche size and 52,902 for avalanche duration)
conﬁrms that the p-value is trustworthy. Such power-law analysis is performed
by utilizing the powerlaw Python library [5]. It is important to warn that high
ﬁtness scores do not mean p-values closer to 1.0 and the goodness-of-ﬁt test is
not part of the ﬁtness score because it is a slow process.
A sample of the resulting stochastic elementary cellular automaton of the best
individual is illustrated in Fig. 5. This CA, as seen, has no static nor periodic
states, and no random evolution of its states. Therefore, this dynamical system
 EvoDynamic: a framework for the evolution of dynamical systems
13
is between a strongly and weakly coupled substrate. Therefore, the CA presents
patterns or structures that mean the cells are interdependent in this system.
5
Conclusion
In this paper, we present an alternative method to implement a cellular au-
tomaton. This allows any CA to be computed as an artiﬁcial neural network.
That means, any lookup table can be an activation function, and any neigh-
borhood and dimensionality can be represented as a weight matrix. Therefore,
this will help to extend the CA implementation to more complex dynamical sys-
tems, such as random Boolean networks, echo state networks and liquid state
machines. Furthermore, the EvoDynamic framework is built on a deep learning
library, TensorFlow, which permits the acceleration and parallelization of ma-
trix operations when applied on computational platforms with fast CPUs and
(a) Avalanche size of state 0
(b) Avalanche duration of state 0
(c) Avalanche size of state 1
(d) Avalanche duration of state 1
Fig. 4: Avalanche size and duration of the two states 0 and 1 of the evolved
stochastic elementary CA.
 14
S. Pontes-Filho et al.
Fig. 5: Sample of the best evolved stochastic elementary CA of 200 cells (horizon-
tal axis) randomly initialized with wrapped boundaries through 400 time-steps
(vertical axis).
GPUs. The planned future implementations of EvoDynamic are presented and
discussed. The state trajectory is an important feature for the targeted future
tasks. The evolution with genetic algorithm towards criticality of stochastic CA
is showing promising results and our next goal can be for self-organized criti-
cality. The future work for the CA implementation is to develop algorithms to
procedurally generate weighted adjacency matrices for 3D and multidimensional
cellular automata with diﬀerent types of cells, such as the cells with hexagonal
shape in a 2D CA.
 EvoDynamic: a framework for the evolution of dynamical systems
15
Acknowledgments
We thank Kristine Heiney for thoughtful discussions about self-organized criti-
cality.
References
1. SOCRATES – Self-Organizing Computational substRATES, https://www.ntnu.
edu/socrates
2. Conway’s game of life implemented using tensorﬂow 2d convolution function
(2016), https://github.com/conceptacid/conv2d life
3. Aaser, P., Knudsen, M., Ramstad, O.H., van de Wijdeven, R., Nichele, S., Sandvig,
I., Tufte, G., Stefan Bauer, U., Halaas, Ø., Hendseth, S., Sandvig, A., Valderhaug,
V.: Towards making a cyborg: A closed-loop reservoir-neuro system. The 2018
Conference on Artiﬁcial Life: A Hybrid of the European Conference on Artiﬁcial
Life (ECAL) and the International Conference on the Synthesis and Simulation of
Living Systems (ALIFE) (29), 430–437 (2017). https://doi.org/10.1162/isal a 072
4. Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghe-
mawat, S., Irving, G., Isard, M., Kudlur, M., Levenberg, J., Monga, R., Moore,
S., Murray, D.G., Steiner, B., Tucker, P., Vasudevan, V., Warden, P., Wicke, M.,
Yu, Y., Zheng, X.: Tensorﬂow: A system for large-scale machine learning. In: 12th
USENIX Symposium on Operating Systems Design and Implementation (OSDI
16). pp. 265–283. USENIX Association, Savannah, GA (2016)
5. Alstott,
J.,
Bullmore,
E.,
Plenz,
D.:
powerlaw:
A
python
package
for
analysis
of
heavy-tailed
distributions.
PLOS
ONE
9(1),
1–11
(01
2014).
https://doi.org/10.1371/journal.pone.0085777
6. Baetens, J.M., Van der Meeren, W., De Baets, B.: On the dynamics of stochastic
elementary cellular automata. Journal of Cellular Automata 12 (2016)
7. Bak,
P.,
Tang,
C.,
Wiesenfeld,
K.:
Self-organized
criticality:
An
expla-
nation
of
the
1/f
noise.
Phys.
Rev.
Lett.
59,
381–384
(Jul
1987).
https://doi.org/10.1103/PhysRevLett.59.381
8. Broersma, H., Miller, J.F., Nichele, S.: Computational Matter: Evolving Com-
putational Functions in Nanoscale Materials, pp. 397–428. Springer International
Publishing, Cham (2017). https://doi.org/10.1007/978-3-319-33921-4 16
9. Clauset, A., Shalizi, C.R., Newman, M.E.: Power-law distributions in empirical
data. SIAM review 51(4), 661–703 (2009)
10. Gershenson, C.: Introduction to random boolean networks. arXiv preprint
nlin/0408006 (2004)
11. Goldberg, D.E., Deb, K.: A comparative analysis of selection schemes used in
genetic algorithms. In: Foundations of genetic algorithms, vol. 1, pp. 69–93. Elsevier
(1991)
12. Goldstein, M.L., Morris, S.A., Yen, G.G.: Problems with ﬁtting to the power-law
distribution. The European Physical Journal B-Condensed Matter and Complex
Systems 41(2), 255–258 (2004)
13. Jaeger, H., Haas, H.: Harnessing nonlinearity: Predicting chaotic systems and
saving energy in wireless communication. Science 304(5667), 78–80 (2004).
https://doi.org/10.1126/science.1091277
 16
S. Pontes-Filho et al.
14. Jensen, J.H., Folven, E., Tufte, G.: Computation in artiﬁcial spin ice. The 2018
Conference on Artiﬁcial Life: A Hybrid of the European Conference on Artiﬁcial
Life (ECAL) and the International Conference on the Synthesis and Simulation of
Living Systems (ALIFE) (30), 15–22 (2018). https://doi.org/10.1162/isal a 00011
15. Kaneko, K.: Overview of coupled map lattices. Chaos: An Interdisciplinary Journal
of Nonlinear Science 2(3), 279–282 (1992)
16. Konkoli, Z., Nichele, S., Dale, M., Stepney, S.: Reservoir Computing with Com-
putational Matter, pp. 269–293. Springer International Publishing, Cham (2018).
https://doi.org/10.1007/978-3-319-65826-1 14
17. Langton, C.G.: Computation at the edge of chaos: Phase transitions and emer-
gent computation. Physica D: Nonlinear Phenomena 42(1), 12 – 37 (1990).
https://doi.org/https://doi.org/10.1016/0167-2789(90)90064-V
18. Maass, W., Markram, H.: On the computational power of circuits of spiking
neurons. Journal of Computer and System Sciences 69(4), 593 – 616 (2004).
https://doi.org/https://doi.org/10.1016/j.jcss.2004.04.001
19. Nichele, S., Tufte, G.: Trajectories and attractors as speciﬁcation for the evolution
of behaviour in cellular automata. In: IEEE Congress on Evolutionary Computa-
tion. pp. 1–8 (July 2010). https://doi.org/10.1109/CEC.2010.5586115
20. Nichele, S., Farstad, S.S., Tufte, G.: Universality of evolved cellular automata in-
materio. International Journal of Unconventional Computing 13(1) (2017)
21. Nichele,
S.,
Gundersen,
M.S.:
Reservoir
computing
using
nonuniform
bi-
nary
cellular
automata.
Complex
Systems
26(3),
225–245
(Sep
2017).
https://doi.org/10.25088/complexsystems.26.3.225
22. Nichele,
S.,
Molund,
A.:
Deep
learning
with
cellular
automaton-based
reservoir
computing.
Complex
Systems
26(4),
319–339
(Dec
2017).
https://doi.org/10.25088/complexsystems.26.4.319
23. Nichele, S., Tufte, G.: Genome parameters as information to forecast emergent
developmental behaviors. In: Durand-Lose, J., Jonoska, N. (eds.) Unconventional
Computation and Natural Computation. pp. 186–197. Springer Berlin Heidelberg,
Berlin, Heidelberg (2012)
24. Rendell, P.: Turing Universality of the Game of Life, pp. 513–539. Springer London,
London (2002). https://doi.org/10.1007/978-1-4471-0129-1 18
25. Schrauwen, B., Verstraeten, D., Van Campenhout, J.: An overview of reservoir
computing: theory, applications and implementations. In: Proceedings of the 15th
European Symposium on Artiﬁcial Neural Networks. p. 471-482 2007. pp. 471–482
(2007)
26. Subramoney, A., Scherr, F., Maass, W.: Reservoirs learn to learn. arXiv preprint
arXiv:1909.07486 (2019)
27. Tanaka, G., Yamane, T., H´eroux, J.B., Nakane, R., Kanazawa, N., Takeda,
S.,
Numata,
H.,
Nakano,
D.,
Hirose,
A.:
Recent
advances
in
physical
reservoir computing: A review. Neural Networks 115, 100 – 123 (2019).
https://doi.org/https://doi.org/10.1016/j.neunet.2019.03.005
28. TensorFlow: tf.sparse.sparse dense matmul — tensorﬂow core r1.14 — tensorﬂow,
https://www.tensorﬂow.org/api docs/python/tf/sparse/sparse dense matmul
29. Toﬀoli, T., Margolus, N.: Cellular automata machines: a new environment for mod-
eling. MIT press (1987)
30. Wolfram, S.: A new kind of science, vol. 5. Wolfram media Champaign, IL (2002)
31. Wright, S.: Correlation and causation. Journal of Agricultural Research 20, 557–
580 (1921)
",,doc10,"EvoDynamic: a framework for the evolution of generally represented dynamical systems and its application to criticality Sidney Pontes-Filho1,2[0000−0002−0489−5652], Pedro Lind1, Anis Yazidi1, Jianhua Zhang1, Hugo Hammer1, Gustavo B. M. Mello1, Ioanna Sandvig3, Gunnar Tufte2, and Stefano Nichele1,4 1 Department of Computer Science, Oslo Metropolitan University, Oslo, Norway 2 Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway 3 Department of Neuromedicine and Movement Science, Norwegian University of Science and Technology, Trondheim, Norway 4 Holistic Systems, SimulaMet, Oslo, Norway Email: sidneyp@oslomet.no Abstract. Dynamical systems possess a computational capacity that may be exploited in a reservoir computing paradigm. This paper presents a general representation of dynamical systems which is based on matrix multiplication. That is similar to how an artiﬁcial neural network (ANN) would be represented in a deep learning library and its computation would be faster because of the optimized matrix operations that such type of libraries have. Initially, we implement the simplest dynamical system, a cellular automaton. The mathematical fundamentals behind an ANN are maintained, but the weights of the connections and the ac- tivation function are adjusted to work as an update rule in the context of cellular automata. The advantages of such implementation are its us- age on specialized and optimized deep learning libraries, the capabilities to generalize it to other types of networks and the possibility to evolve cellular automata and other dynamical systems in terms of connectivity, update and learning rules. Our implementation of cellular automata con- stitutes an initial step towards a more general framework for dynamical systems. Our objective is to evolve such systems to optimize their usage in reservoir computing and to model physical computing substrates. Fur- thermore, we present promising preliminary results toward the evolution of complex behavior and criticality using genetic algorithm in stochastic elementary cellular automata. Keywords: Cellular automata · Dynamical systems · Implementation · Reservoir computing · Evolution · Criticality 1 Introduction A cellular automaton (CA) is the simplest computing system where the emer- gence of complex dynamics from local interactions might take place. It consists This is a post-peer-review, pre-copyedit version of a conference proceeding published in Applications of Evolutionary Computation 23rd European Conference, EvoApplications 2020, Held as Part of EvoStar 2020, Proceedings, that is part of the Lecture Notes in Computer Science book series (volume 12104). The final authenticated version is available online at: 2 S. Pontes-Filho et al. of a grid of cells with a ﬁnite number of states that change according to sim- ple rules depending on the neighborhood and own state in discrete time-steps. Some notable examples are the elementary CA [30], which is unidimensional with three neighbors and eight update cases, and Conway’s Game of Life [24], which is two-dimensional with nine neighbors and three update cases. Table 1 presents some computing systems that are capable of giving rise to the emergence of complex dynamics. Those systems can be exploited by reservoir computing, which is a paradigm that resorts to dynamical systems to simplify complex data. Such simpliﬁcation means that reservoir computing utilizes the non-linear dynamical system to perform a non-linear transformation from non- linear data to higher dimensional linear data. Such linearized data can be applied in linear machine learning methods which are faster for training and computing because has less trainable variables and operations. Hence, reservoir computing is more energy eﬃcient than deep learning methods and it can even yield compet- itive results, especially for temporal data [25,27]. Basically, reservoir computing exploits a dynamical system that possesses the echo state property and fading memory, where the internals of the reservoir are untrained and the only training happens at the linear readout stage [16]. Reservoir computers are most useful when the substrate’s dynamics are at the “edge of chaos” [17], meaning a range of dynamical behaviors that is between order and disorder. Cellular automata with such dynamical behavior are capable of being exploited as reservoirs [21,22]. Other systems can also exhibit similar dynamics. The coupled map lattice [15] is very similar to CA, the only exception is that the coupled map lattice has continuous states which are updated by a recurrence equation involving the neighborhood. Random Boolean network [10] is a generalization of CA where random connectivity exists. Echo state network [13] is an artiﬁcial neural network (ANN) with random topology while liquid state machine [18] is similar to echo state network with the diﬀerence that it is a spiking neural network that communicates through discrete-events (spikes) over continuous time. One important aspect of the computation performed in a dynamical system is the trajectory of system states traversed during the computation [19]. Such trajectory may be guided by system parameters [23]. Another characteristic of a dynamical system, which is crucial for computation, is to be in a critical state, Table 1: Examples of dynamical systems. Dynamical system State Time Connectivity Cellular automata Discrete Discrete Regular Coupled map lattice Continuous Discrete Regular Random Boolean network Discrete Discrete Random Echo state network Continuous Discrete Random Liquid state machine Discrete Continuous Random EvoDynamic: a framework for the evolution of dynamical systems 3 as indicated by Langton [17]. If the attractors of the system are in the critical state, this characteristic is called self-organized criticality [7]. Besides, computation in dynamical systems may be carried out in physical substrates [27], such as networks of biological neurons [3] or in nanoscale ma- terials [8]. Finding the correct abstraction for the computation in a dynamical system, e.g. CA, is an open problem [20]. All the systems described in Table 1 are sparsely connected and can be represented by a weighted adjacency matrix, such as a graph. The connectivity from a layer to another in a fully connected feedforward ANN is represented with a weighted adjacency matrix that contains the weights of each connection. Our CA implementation is similar to this, but the connectivity goes from the “layer” of cells to itself. The goal of representing CA with a weighted adjacency matrix is to imple- ment a framework which facilitates the development of all types of CAs, from unidimensional to multidimensional, with all kinds of lattices and without any boundary conditions during execution; and also allowing the inclusion of other major dynamical systems, independent of the type of the state, time and connec- tivity. Such initial implementation is the ﬁrst component of a Python framework under development, based on TensorFlow deep neural network library [4]. There- fore, it beneﬁts from powerful and parallel computing systems with multi-CPU and multi-GPU. One of the framework’s goals is to have a balance between performance and generalization of computing dynamical systems, since general methods are slower than specialized ones. Nevertheless, this framework, called EvoDynamic, aims at evolving (i.e., using evolutionary algorithms) the connec- tivity, update and learning rules of sparsely connected networks to improve their usage for reservoir computing guided by the echo state property, fading memory, state trajectory, and other quality measurements. Such improvement of reser- voirs is applied similarly in [26], where the internal connectivity of a reservoir is trained to increase its performance to several tasks. Moreover, evolution will model the dynamics and behavior of physical reservoirs, such as in-vitro biolog- ical neural networks interfaced with microelectrode arrays, and nanomagnetic ensembles. Those two substrates have real applicability as reservoirs. For exam- ple, the former substrate is applied to control a robot, in fact making it into a cyborg, a closed-loop biological-artiﬁcial neuro-system [3], and the latter pos- sesses computation capability as shown by a square lattice of nanomagnets [14]. Those substrates are the main interest of the SOCRATES project [1] which aims to explore a dynamic, robust and energy eﬃcient hardware for data analysis. There exist some implementations of CA similar to the one of EvoDynamic framework. They typically implement Conway’s Game of Life by applying 2D convolution with a kernel that is used to count the “alive” neighbors, then the resulting matrix consists of the number of “alive” neighboring cells and is used to update the CA. One such implementation, also based on TensorFlow, is available open-source in [2]. This paper is organized as follows. Section 2 describes our method according to which we use weighted adjacency matrix to compute CA. Section 3 presents 4 S. Pontes-Filho et al. the results obtained from the method. Section 4 discusses the initial advances and future plan of EvoDynamic framework and Section 5 concludes this paper. 2 Method In our proposed method, the equation to calculate the next states of the cells in a cellular automaton is ct+1 = f(A · ct). (1) It is similar to the equation of the forward pass of an artiﬁcial neural network, but without the bias. The layer is connected to itself, and the activation function f deﬁnes the update rules of the CA. The next states of the CA ct+1 is calculated from the result of the activation function f which receives as argument the dot product between the weighted adjacency matrix A and the current states of the CA ct. c is always a column vector of size len(c) × 1, that does not depend on how many dimensions the CA has, and A is a matrix of size len(c) × len(c). Hence the result of A · c is also a column vector of size len(c) × 1 as c. The implementation of cellular automata as an artiﬁcial neural network re- quires the procedural generation of the weighted adjacency matrix of the grid. In this way, any lattice type or multidimensional CAs can be implemented us- ing the same approach. The adjacency matrix of a sparsely connected network contains many zeros because of the small number of connections. Since we im- plement it on TensorFlow, the data type of the adjacency matrix is preferably a SparseTensor. A dot product with this data type can be up to 9 times faster than the dense counterpart. However, it depends on the conﬁguration of the tensors (or, in our case, the adjacency matrices) [28]. The update rule of the CA alters the weights of the connections in the adjacency matrix. In a CA whose cells have two states meaning “dead” (zero) or “alive” (one), the weights in the adjacency matrix are one for connection and zero for no connection, such as an ordinary adjacency matrix. Such matrix facilitates the description of the update rule for counting the number of “alive” neighbors because the result of the dot product between the adjacency matrix and the cell state vector is the vector that contains the number of “alive” neighbors for each cell. If the pattern of the neighborhood matters in the update rule, each cell has its neighbors encoded as a n-ary string where n means the number of states that a cell can have. In this case, the weights of the connections with the neighbors are n-base identiﬁers and are calculated by neighbori = ni, ∀i ∈{0..len(neighbors) −1} (2) where neighbors is a vector of the cell’s neighbors. In the adjacency matrix, each neighbor receives a weight according to (2). The result of the dot product with such weighted adjacency matrix is a vector that consists of unique integers per neighborhood pattern. Thus, the activation function is a lookup table from integer (i.e., pattern) to next state. Algorithm 1 generates the weighted adjacency matrix for one-dimensional CA, such as the elementary CA, where widthCA is the width or number of EvoDynamic: a framework for the evolution of dynamical systems 5 Algorithm 1 Generation of weighted adjacency matrix for 1D cellular automa- ton 1: procedure generateCA1D 2: numberOfCells ←widthCA 3: A ←0numberOfCells×numberOfCells ▷Adjacency matrix initialization 4: for i ←{0..(numberOfCells −1)} do 5: for j ← {−indexNeighborCenter..(len(neighborhood) − indexNeighborCenter −1)} do 6: currentNeighbor ←neighborhoodj+indexNeighborCenter 7: if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧(0 ≤ (i + j) < widthCA)) then 8: Ai,((i+j) mod widthCA) ←currentNeighbor 9: return A cells of a unidimensional CA and neighborhood is a vector which describes the region around the center cell. The connection weights depend on the type of update rule as previously explained. For example, in case of an elementary CA neighborhood = [4 2 1]. indexNeighborCenter is the index of the center cell in the neighborhood whose starting index is zero. isWrappedGrid is a Boolean value that works as a ﬂag for adding a wrapped grid or not. A wrapped grid for one-dimensional CA means that the initial and ﬁnal cells are neighbors. With all these parameters, Algorithm 1 creates an adjacency matrix by looping over the indices of the cells (from zero to numberOfCells −1) with an inner loop for the indices of the neighbors. If the selected currentNeighbor is a non- zero value and its indices do not aﬀect the boundary condition, then the value of currentNeighbor is assigned to the adjacency matrix A in the indices that correspond to the connection between the current cell in the outer loop and the actual index of currentNeighbor. Finally, this procedure returns the adjacency matrix A. To procedurally generate an adjacency matrix for 2D CA instead of 1D CA, the algorithm needs to have small adjustments. Algorithm 2 shows that for two- dimensional CA, such as Conway’s Game of Life. In this case, the height of the CA is an argument passed as heightCA. Neighborhood is a 2D matrix and indexNeighborCenter is a vector of two components meaning the in- dices of the center of Neighborhood. This procedure is similar to the one in Algorithm 1, but it contains one more loop for the additional dimension. The activation function for CA is diﬀerent from the ones used for ANN. For CA, it contains the update rules that verify the vector returned by the dot product between the weighted adjacency matrix and the vector of states. Normally, the update rules of the CA are implemented as a lookup table from neighborhood to next state. In our implementation, the lookup table maps the resulting vector of the dot product to the next state of the central cell. 6 S. Pontes-Filho et al. Algorithm 2 Generation of adjacency matrix of 2D cellular automaton 1: procedure generateCA2D 2: numberOfCells ←widthCA ∗heightCA 3: A ←0numberOfCells×numberOfCells ▷Adjacency matrix initialization 4: widthNB, heightNB ←shape(Neighborhood) 5: for i ←{0..(numberOfCells −1)} do 6: for j ← {−indexNeighborCenter0..(widthNB − indexNeighborCenter0 −1)} do 7: for k ← {−indexNeighborCenter1..(heightNB − indexNeighborCenter1 −1)} do 8: currentNeighbor ←Neighborhoodj+indexNeighborCenter 9: if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧ (0 ≤((i mod heightCA)+j) < widthCA)∧(0 ≤(⌊i/widthCA⌋+k) < heightCA)) then 10: Ai,(((i+k) mod widthCA)+((⌊i/widthCA⌋+j) mod heightCA)∗widthCA) ← currentNeighbor 11: return A 3 Results This section presents the results of the proposed method and it also stands for the preliminary results of the EvoDynamic framework. Fig. 1 illustrates a wrapped elementary CA described in the procedure of Algorithm 1 and its generated weighted adjacency matrix. Fig. 1a shows the appearance of the desired elementary CA with 16 cells (i.e., widthCA = 16). Fig. 1b describes its pattern 3-neighborhood and the indices of the cells. Fig 1c shows the result of the Algorithm 1 with the neighborhood calculated by (2) for pattern matching in the activation function. In Fig. 1c, we can verify that the left neighbor has weight equal to 4 (or 22 for the most signiﬁcant bit), central cell weight is 2 (or 21) and right neighbor weight is 1 (or 20 for the least signiﬁcant bit) as deﬁned by (2). Since the CA is wrapped, we can notice in row index 0 of the adjacency matrix in Fig. 1c that the left neighbor of cell 0 is the cell 15, and in row index 15 that the right neighbor of cell 15 is the cell 0. Fig. 2 describes a wrapped 2D CA (similar to Game of Life but with less number of neighbors) for Algorithm 2 and shows the resulting adjacency matrix. Fig. 2a illustrates the desired two-dimensional CA with 16 cells (i.e., widthCA = 4 and heightCA = 4). Fig. 2b presents the von Neumann neighborhood [29] which is used for counting the number of “alive” neighbors (the connection weights are only zero and one, and Neighborhood argument of Algorithm 2 deﬁnes it). It also shows the index distribution of the CA whose order is preserved after ﬂatting it to a column vector. Fig 2c contains the generated adjacency matrix of Algorithm 2 for the described 2D CA. Fig. 2b shows an example of a central cell with its neighbors, the index of this central cell is 5 and the row index 5 in the adjacency matrix of Fig. 2c presents the same neighbor indices, i.e., 1, 4, 6 and 9. Since this is a symmetric matrix, the columns have the same connectivity of the rows. That means the neighborhood of a cell considers this cell EvoDynamic: a framework for the evolution of dynamical systems 7 as a neighbor too. Therefore, the connections are bidirectional and the adjacency matrix represents an undirected graph. The wrapping eﬀect is also observable. For example, the neighbors of the cell index 0 are 1, 3, 4 and 12. So the neighbors 3 and 12 are the ones that the wrapped grid allowed to exist for cell index 0. (a) (b) (c) Fig. 1: Elementary cellular automaton with 16 cells and wrapped grid. (a) Exam- ple of the grid of cells with states. (b) Indices of the cells and standard pattern neighborhood of elementary CA where thick border means the central cell and thin border means the neighbors. (c) Generated weighted adjacency matrix for the described elementary CA. 4 On-going and future applications with EvoDynamic The method of implementing a CA as an artiﬁcial neural network is beneﬁcial for the further development of EvoDynamic framework. Since the implementation of 8 S. Pontes-Filho et al. (a) (b) (c) Fig. 2: 2D cellular automaton with 16 cells (4×4) and wrapped grid. (a) Example of the grid of cells with states. (b) Indices of the cells and von Neumann counting neighborhood of 2D CA where thick border means the current cell and thin border means the neighbors. (c) Generated adjacency matrix for the described 2D CA. EvoDynamic: a framework for the evolution of dynamical systems 9 all sparsely connected networks in Table 1 is already planned in forthcoming re- leases of the Python framework, EvoDynamic shall have a general representation to all of them. Therefore, CAs are treated as ANNs and then can be extended to random Boolean network by shuﬄing the connections, and to the models that are already ANNs, such as echo state networks and liquid state machines. More- over, EvoDynamic framework will evolve the connectivity, update and learning rules of the dynamical systems for reservoir computing improvement and physi- cal substrate modeling. This common representation facilitates the evolution of such systems and models which will be guided by several methods that measure the quality of a reservoir or the similarity to a dataset. The following subsections explain two on-going applications with CA that use the EvoDynamic framework. 4.1 State trajectory An example of methods to guide the evolution of dynamical system is the state trajectory. This method can be used to cluster similar states for model abstrac- tion and to measure the quality of the reservoir. Therefore, a graph can be formed and analysis can be made by searching for attractors and cycles. For visualization of the state trajectory, we use principal component analysis (PCA) to reduce the dimensionality of the states and present them as a state transi- tion diagram as shown in Fig. 3. The depicted dynamical system is Conway’s Game of Life with 7x7 cells and wrapped boundaries. A glider is its initial state (Fig. 3a) and this system cycles over 28 unique states as illustrated in the state transition diagram of Fig. 3l. 4.2 Towards the evolution for criticality Evolution of dynamical systems is a feature currently under development of EvoDynamic framework. The ﬁrst on-going evolution task of our framework is to ﬁnd systems with criticality [7] using genetic algorithm, in order to allow for better computational capacity [17]. The ﬁrst dynamical system for this task is a modiﬁed version of stochastic elementary cellular automata (SECA) introduced by Baetens et al. [6]. Our stochastic elementary cellular automaton works as a 1D three neighbors elementary CA, but the next state in time t+1 of the central cell ci is deﬁned by a probability p to be 1 and a probability 1−p to be 0 for each of the eight diﬀerent neighborhood patterns this CA has. Formally, probability p is represented by p = P(ci,t+1 = 1|N(ci,t)) (3) where the neighborhood pattern N(ci,t) is denoted as N(ci,t) = (ci−1,t, ci,t, ci+1,t). (4) The genetic algorithm for criticality is guided by a ﬁtness function which mainly veriﬁes if the probability distributions of avalanche size (i.e., cluster size5 5 Cluster size stands for the number of repetitions of a state that happened consecu- tively without any interruption of another state. 10 S. Pontes-Filho et al. −1 0 1 −1 0 1 (a) Step 1 −1 0 1 −1 0 1 (b) Step 2 −1 0 1 −1 0 1 (c) Step 3 −1 0 1 −1 0 1 (d) Step 4 −1 0 1 −1 0 1 (e) Step 11 −1 0 1 −1 0 1 (f) Step 12 −1 0 1 −1 0 1 (g) Step 13 −1 0 1 −1 0 1 (h) Step 14 −1 0 1 −1 0 1 (i) Step 26 −1 0 1 −1 0 1 (j) Step 27 −1 0 1 −1 0 1 (k) Step 28 −1 0 1 −1 0 1 (l) Step 29 Fig. 3: States of Conway’s Game of Life in a 7x7 wrapped lattice alongside their PCA-transformed state transition diagrams of the two ﬁrst principal compo- nents. (a) Initial state is a glider. (a)-(d) Four ﬁrst steps in this CA. (e)-(h) Four intermediate steps in this CA while reaching the wrapped border. (i)-(l) Four last steps in this CA before repeating the initial state and closing a cycle. in space) and duration (i.e., cluster size in time) follow a power-law distribu- tion. Such veriﬁcation can be done by checking how linear is the probability distribution in a log-log plot, by performing goodness-of-ﬁt tests based on the Kolmogorov-Smirnov (KS) statistic and by comparing the power-law model with the exponential model using log-likelihood ratio [9]. For our ﬁtness function, we estimate the candidate distributions with the linear ﬁtting of the ﬁrst 10 points of the log-log plot using least squares regression, which was veriﬁed to be not biased and gives a fast and acceptable estimation of the slope of the power-law distribution [12]. After the linear 10-points ﬁtting, the model is tested using KS statistic. One beneﬁt of using such estimation method is that when the model is not a power-law, the KS statistic reports a large error, i.e., an error greater than one. Another objective in the ﬁtness function is the coeﬃcient of determi- nation [31], but for a complete linear ﬁt of the log-log plot. The ﬁtness function also considers the number of unique states of the stochastic elementary CA, the number of bins in the raw histogram and the value of the estimated power-law exponent. All these ﬁtness function objectives are calculated using a randomly initialized CA of 1,000 cells with wrapped boundaries during 1,000 time-steps. The avalanche size and duration are computed for the cell values 0 and 1, thus producing four diﬀerent distributions (see Fig. 4) for extracting vectors of their EvoDynamic: a framework for the evolution of dynamical systems 11 normalized number of histogram bins6 bin; coeﬃcient of determination R2 of complete linear ﬁtting; KS statistic D and estimated power-law exponent ˆα from the 10-points linear estimation. The ﬁtness score s for each objective is then calculated by the following equations: bins = tanh(5 ∗(0.9 ∗max(bin) + 0.1 ∗mean(bin))), (5) R2 s = mean(R2), (6) Ds = exp(−(0.9 ∗min(D) + 0.1 ∗mean(D))), (7) ˆαs = mean(ˆα), (8) uniques = #uniqueStates #timesteps . (9) The (5)-(9) are all objective values for calculating the ﬁtness score s. Those values are real numbers between zero and one, except the score for the estimated power-law exponent ˆαs, and they have weights attributed to them regarding their level of importance and for compensating small and large values. The following equation denotes how the ﬁtness score s is calculated: s = 10 ∗bins + 10 ∗R2 s + 10 ∗Ds + 0.1 ∗ˆαs + 10 ∗uniques. (10) The genetic algorithm has 40 individuals that evolve through 100 generations. The optimization performed by GA is to maximize the ﬁtness score. The genome of the individuals has eight real number genes with a value range between zero and one. Each gene represents the probability of the next state becoming one (i.e., p in (3)) for its respective neighborhood pattern. The selection of two par- ents is done by deterministic tournament selection [11]. After that, the crossover between the genomes of the parents can happen with probability 0.8, then each gene can be exchanged with probability 0.5. Afterward, a mutation occurs to a gene with probability 0.1. This mutation adds a random value from a normal distribution with mean and standard deviation equals to, respectively, 0 and 0.2. The mating process of the two parents produces an oﬀspring of two new individ- uals who replace the parents in the next generation. An example of an evolved genome for the best resulting individual is presented in Table 2. The ﬁtness score s and all objective scores with their respective weights for calculating s are in Table 3. With the genome or probabilities of the eight diﬀerent neighborhood patterns of the best evolved individual, we can produce the log-log plots of the probability distribution of avalanche size and duration for the states zero and one. Such plots 6 The actual number of histogram bins is normalized or divided by the possible total number of bins. 12 S. Pontes-Filho et al. Table 2: Best individual Neighborhood N(ci,t) Probability p (0,0,0) 0.103009 (0,0,1) 0.536786 (0,1,0) 0.216794 (0,1,1) 0.393468 (1,0,0) 0.679836 (1,0,1) 0.175458 (1,1,0) 0.724778 (1,1,1) 1.000000 Table 3: Fitness score of the best individual Objective Score 10 ∗bins 9.780749590096136 10 ∗R2 s 8.832520186440096 10 ∗Ds 9.655719560019996 0.1 ∗ˆαs 0.18022617747972156 10 ∗uniques 10.0 s 38.44921551403595 are depicted in Fig. 4. The p-value of goodness-of-ﬁt test is calculated using 1,000 randomly generated data with 10,000 samples applying the power-law exponent ˆα estimated by maximum likelihood estimation method with minimum x of the distribution ﬁxed to 1. The Fig. 4a and Fig. 4b show the avalanche size and duration for the state 0 or black. They present distributions that are not a power- law because they do not ﬁt the power-law estimation (the black dashed line). Moreover, the p-value is equal to 0.0 which proves that those two distributions are not a power-law. The Fig. 4c and Fig. 4d present the avalanche size and duration for the state 1 or white. Those distributions follow a power-law because, visually, the estimated power-law distribution ﬁts the empirical probability distribution and, quantitatively, the p-value is equal to 1.0 which means that 100% of the KS statistic of the generated data is greater than the KS statistic of the empirical distribution of avalanche size and duration of state 1. The number of samples in those distributions (62,731 for avalanche size and 52,902 for avalanche duration) conﬁrms that the p-value is trustworthy. Such power-law analysis is performed by utilizing the powerlaw Python library [5]. It is important to warn that high ﬁtness scores do not mean p-values closer to 1.0 and the goodness-of-ﬁt test is not part of the ﬁtness score because it is a slow process. A sample of the resulting stochastic elementary cellular automaton of the best individual is illustrated in Fig. 5. This CA, as seen, has no static nor periodic states, and no random evolution of its states. Therefore, this dynamical system EvoDynamic: a framework for the evolution of dynamical systems 13 is between a strongly and weakly coupled substrate. Therefore, the CA presents patterns or structures that mean the cells are interdependent in this system. 5 Conclusion In this paper, we present an alternative method to implement a cellular au- tomaton. This allows any CA to be computed as an artiﬁcial neural network. That means, any lookup table can be an activation function, and any neigh- borhood and dimensionality can be represented as a weight matrix. Therefore, this will help to extend the CA implementation to more complex dynamical sys- tems, such as random Boolean networks, echo state networks and liquid state machines. Furthermore, the EvoDynamic framework is built on a deep learning library, TensorFlow, which permits the acceleration and parallelization of ma- trix operations when applied on computational platforms with fast CPUs and (a) Avalanche size of state 0 (b) Avalanche duration of state 0 (c) Avalanche size of state 1 (d) Avalanche duration of state 1 Fig. 4: Avalanche size and duration of the two states 0 and 1 of the evolved stochastic elementary CA. 14 S. Pontes-Filho et al. Fig. 5: Sample of the best evolved stochastic elementary CA of 200 cells (horizon- tal axis) randomly initialized with wrapped boundaries through 400 time-steps (vertical axis). GPUs. The planned future implementations of EvoDynamic are presented and discussed. The state trajectory is an important feature for the targeted future tasks. The evolution with genetic algorithm towards criticality of stochastic CA is showing promising results and our next goal can be for self-organized criti- cality. The future work for the CA implementation is to develop algorithms to procedurally generate weighted adjacency matrices for 3D and multidimensional cellular automata with diﬀerent types of cells, such as the cells with hexagonal shape in a 2D CA. EvoDynamic: a framework for the evolution of dynamical systems 15 Acknowledgments We thank Kristine Heiney for thoughtful discussions about self-organized criti- cality. References 1. SOCRATES – Self-Organizing Computational substRATES, edu/socrates 2. Conway’s game of life implemented using tensorﬂow 2d convolution function (2016), life 3. Aaser, P., Knudsen, M., Ramstad, O.H., van de Wijdeven, R., Nichele, S., Sandvig, I., Tufte, G., Stefan Bauer, U., Halaas, Ø., Hendseth, S., Sandvig, A., Valderhaug, V.: Towards making a cyborg: A closed-loop reservoir-neuro system. The 2018 Conference on Artiﬁcial Life: A Hybrid of the European Conference on Artiﬁcial Life (ECAL) and the International Conference on the Synthesis and Simulation of Living Systems (ALIFE) (29), 430–437 (2017). a 072 4. Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghe- mawat, S., Irving, G., Isard, M., Kudlur, M., Levenberg, J., Monga, R., Moore, S., Murray, D.G., Steiner, B., Tucker, P., Vasudevan, V., Warden, P., Wicke, M., Yu, Y., Zheng, X.: Tensorﬂow: A system for large-scale machine learning. In: 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16). pp. 265–283. USENIX Association, Savannah, GA (2016) 5. Alstott, J., Bullmore, E., Plenz, D.: powerlaw: A python package for analysis of heavy-tailed distributions. PLOS ONE 9(1), 1–11 (01 2014). 6. Baetens, J.M., Van der Meeren, W., De Baets, B.: On the dynamics of stochastic elementary cellular automata. Journal of Cellular Automata 12 (2016) 7. Bak, P., Tang, C., Wiesenfeld, K.: Self-organized criticality: An expla- nation of the 1/f noise. Phys. Rev. Lett. 59, 381–384 (Jul 1987). 8. Broersma, H., Miller, J.F., Nichele, S.: Computational Matter: Evolving Com- putational Functions in Nanoscale Materials, pp. 397–428. Springer International Publishing, Cham (2017). 16 9. Clauset, A., Shalizi, C.R., Newman, M.E.: Power-law distributions in empirical data. SIAM review 51(4), 661–703 (2009) 10. Gershenson, C.: Introduction to random boolean networks. arXiv preprint nlin/0408006 (2004) 11. Goldberg, D.E., Deb, K.: A comparative analysis of selection schemes used in genetic algorithms. In: Foundations of genetic algorithms, vol. 1, pp. 69–93. Elsevier (1991) 12. Goldstein, M.L., Morris, S.A., Yen, G.G.: Problems with ﬁtting to the power-law distribution. The European Physical Journal B-Condensed Matter and Complex Systems 41(2), 255–258 (2004) 13. Jaeger, H., Haas, H.: Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication. Science 304(5667), 78–80 (2004). 16 S. Pontes-Filho et al. 14. Jensen, J.H., Folven, E., Tufte, G.: Computation in artiﬁcial spin ice. The 2018 Conference on Artiﬁcial Life: A Hybrid of the European Conference on Artiﬁcial Life (ECAL) and the International Conference on the Synthesis and Simulation of Living Systems (ALIFE) (30), 15–22 (2018). a 00011 15. Kaneko, K.: Overview of coupled map lattices. Chaos: An Interdisciplinary Journal of Nonlinear Science 2(3), 279–282 (1992) 16. Konkoli, Z., Nichele, S., Dale, M., Stepney, S.: Reservoir Computing with Com- putational Matter, pp. 269–293. Springer International Publishing, Cham (2018). 14 17. Langton, C.G.: Computation at the edge of chaos: Phase transitions and emer- gent computation. Physica D: Nonlinear Phenomena 42(1), 12 – 37 (1990). 18. Maass, W., Markram, H.: On the computational power of circuits of spiking neurons. Journal of Computer and System Sciences 69(4), 593 – 616 (2004). 19. Nichele, S., Tufte, G.: Trajectories and attractors as speciﬁcation for the evolution of behaviour in cellular automata. In: IEEE Congress on Evolutionary Computa- tion. pp. 1–8 (July 2010). 20. Nichele, S., Farstad, S.S., Tufte, G.: Universality of evolved cellular automata in- materio. International Journal of Unconventional Computing 13(1) (2017) 21. Nichele, S., Gundersen, M.S.: Reservoir computing using nonuniform bi- nary cellular automata. Complex Systems 26(3), 225–245 (Sep 2017). 22. Nichele, S., Molund, A.: Deep learning with cellular automaton-based reservoir computing. Complex Systems 26(4), 319–339 (Dec 2017). 23. Nichele, S., Tufte, G.: Genome parameters as information to forecast emergent developmental behaviors. In: Durand-Lose, J., Jonoska, N. (eds.) Unconventional Computation and Natural Computation. pp. 186–197. Springer Berlin Heidelberg, Berlin, Heidelberg (2012) 24. Rendell, P.: Turing Universality of the Game of Life, pp. 513–539. Springer London, London (2002). 18 25. Schrauwen, B., Verstraeten, D., Van Campenhout, J.: An overview of reservoir computing: theory, applications and implementations. In: Proceedings of the 15th European Symposium on Artiﬁcial Neural Networks. p. 471-482 2007. pp. 471–482 (2007) 26. Subramoney, A., Scherr, F., Maass, W.: Reservoirs learn to learn. arXiv preprint arXiv:1909.07486 (2019) 27. Tanaka, G., Yamane, T., H´eroux, J.B., Nakane, R., Kanazawa, N., Takeda, S., Numata, H., Nakano, D., Hirose, A.: Recent advances in physical reservoir computing: A review. Neural Networks 115, 100 – 123 (2019). 28. TensorFlow: tf.sparse.sparse dense matmul — tensorﬂow core r1.14 — tensorﬂow, docs/python/tf/sparse/sparse dense matmul 29. Toﬀoli, T., Margolus, N.: Cellular automata machines: a new environment for mod- eling. MIT press (1987) 30. Wolfram, S.: A new kind of science, vol. 5. Wolfram media Champaign, IL (2002) 31. Wright, S.: Correlation and causation. Journal of Agricultural Research 20, 557– 580 (1921)"
A general representation of dynamical systems for reservoir computing,"Sidney Pontes{-}Filho and
Anis Yazidi and
Jianhua Zhang and
Hugo Hammer and
Gustavo B. M. Mello and
Ioanna Sandvig and
Gunnar Tufte and
Stefano Nichele",2019,,abs/1907.01856,CoRR,article,"A general representation of dynamical systems for
reservoir computing
Sidney Pontes-Filho∗,†,§, Anis Yazidi∗, Jianhua Zhang∗, Hugo Hammer∗,
Gustavo B. M. Mello∗, Ioanna Sandvig‡, Gunnar Tufte† and Stefano Nichele∗
∗Department of Computer Science, Oslo Metropolitan University, Oslo, Norway
†Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway
‡Department of Neuromedicine and Movement Science, Norwegian University of Science and Technology, Trondheim, Norway
Email: §sidneyp@oslomet.no
Abstract—Dynamical systems are capable of performing com-
putation in a reservoir computing paradigm. This paper presents
a general representation of these systems as an artiﬁcial neural
network (ANN). Initially, we implement the simplest dynamical
system, a cellular automaton. The mathematical fundamentals be-
hind an ANN are maintained, but the weights of the connections
and the activation function are adjusted to work as an update
rule in the context of cellular automata. The advantages of such
implementation are its usage on specialized and optimized deep
learning libraries, the capabilities to generalize it to other types of
networks and the possibility to evolve cellular automata and other
dynamical systems in terms of connectivity, update and learning
rules. Our implementation of cellular automata constitutes an
initial step towards a general framework for dynamical systems.
It aims to evolve such systems to optimize their usage in reservoir
computing and to model physical computing substrates.
I. INTRODUCTION
A cellular automaton (CA) is the simplest computing sys-
tem where the emergence of complex dynamics from local
interactions might take place. It consists of a grid of cells
with a ﬁnite number of states that change according to simple
rules depending on the neighborhood and own state in discrete
time-steps. Some notable examples are the elementary CA
[1], which is unidimensional with three neighbors and eight
update rules, and Conway’s Game of Life [2], which is two-
dimensional with nine neighbors and three update rules.
Table I presents some computing systems that are capable
of giving rise to the emergence of complex dynamics. Those
systems can be exploited by reservoir computing which is a
paradigm that resorts to dynamical systems to simplify com-
plex data. Hence, simpler and faster machine learning methods
can be applied with such simpliﬁed data. Reservoir computing
is more energy efﬁcient than deep learning methods and it can
even yield competitive results, especially for temporal data [3].
In short, reservoir computing exploits a dynamical system that
possesses the echo state property and fading memory, where
the internals of the reservoir are untrained and the only training
happens at the linear readout stage [4]. Reservoir computers
are most useful when the substrate’s dynamics are at the
“edge of chaos”, meaning a range of dynamical behaviors
that is between order and disorder [5]. Cellular automata with
such dynamical behavior are capable of being exploited as
TABLE I
EXAMPLES OF DYNAMICAL SYSTEMS.
Dynamical system
State
Time
Connectivity
Cellular automata
Discrete
Discrete
Regular
Coupled map lattice
Continuous
Discrete
Regular
Random Boolean network
Discrete
Discrete
Random
Echo state network
Continuous
Discrete
Random
Liquid state machine
Discrete
Continuous
Random
reservoirs [6], [7]. Other systems can also exhibit the same
dynamics. The coupled map lattice [8] is very similar to
CA, the only exception is that the coupled map lattice has
continuous states which are updated by a recurrence equation
involving the neighborhood. Random Boolean network [9] is a
generalization of CA where random connectivity exists. Echo
state network [10] is an artiﬁcial neural network (ANN) with
random topology while liquid state machine [11] is similar to
echo state network with the difference that it is a spiking neural
network that communicates through discrete-events (spikes)
over continuous time. One important aspect of the computation
performed in a dynamical system is the trajectory of system’s
states traversed during the computation [12]. Such trajectory
may be guided by system parameters [13]. Computation in
dynamical systems may be carried out in physical substrates
[14], such as networks of biological neurons [15] or in other
nanoscale materials [16]. Finding the correct abstraction for
the computation in a dynamical system, e.g. CA, is an open
problem [17]. All the systems described in Table I are sparsely
connected and can be represented by an adjacency matrix, such
as a graph. A fully connected feedforward ANN represents
its connectivity from a layer to another with an adjacency
matrix that contains the weights of each connection. Our CA
implementation is similar to this, but the connectivity is from
the ”layer” of cells to itself.
The goal of representing CA with an adjacency matrix is to
implement a framework which facilitates the development of
all types of CAs, from unidimensional to multidimensional,
with all kinds of lattices and without any boundary checks
during execution; and also the inclusion of the major dynam-
ical systems, independent of the type of the state, time and
arXiv:1907.01856v1  [cs.NE]  3 Jul 2019
 connectivity. Such initial implementation is the ﬁrst part of a
Python framework under development, based on TensorFlow
deep neural network library [18]. Therefore, it beneﬁts from
powerful and parallel computing systems with multi-CPU and
multi-GPU. This framework, called EvoDynamic1, aims at
evolving the connectivity, update and learning rules of sparsely
connected networks to improve their usage for reservoir com-
puting guided by the echo state property, fading memory, state
trajectory and other quality measurements, and to model the
dynamics and behavior of physical reservoirs, such as in-
vitro biological neural networks interfaced with microelectrode
arrays and nanomagnetic ensembles. Those two substrates
have real applicability as reservoirs. For example, the former
substrate is applied to control a robot, in fact making it into a
cyborg, a closed-loop biological-artiﬁcial neuro-system [15],
and the latter possesses computation capability as shown by
a square lattice of nanomagnets [19]. Those substrates are the
main interest of the SOCRATES project [20] which aims to
explore a dynamic, robust and energy efﬁcient hardware for
data analysis.
There are some implementations of CA similar to the one of
EvoDynamic framework. They normally implement Conway’s
Game of Life by applying 2D convolution with a kernel that is
used to count the neighbors, then the resulting matrix consists
of the number of neighboring cells and is used to update the
CA. One such implementation, also based on TensorFlow, is
available open-source in [21].
This paper is organized as follows. Section II describes
our method according to which we use adjacency matrix to
compute CA. Section III presents the results obtained from the
method. Section IV discusses the future plan of EvoDynamic
framework and Section V concludes this paper.
II. METHOD
In our proposed method, the equation to calculate the next
states of the cells in a cellular automaton is
cat+1 = f(A · cat).
(1)
It is similar to the equation of the forward pass of an
artiﬁcial neural network, but without the bias. The layer is
connected to itself, and the activation function f deﬁnes the
update rules of the CA. The next states of the CA cat+1 is
calculated from the result of the activation function f which
receives as argument the dot product between the adjacency
matrix A and the current states of the CA cat. ca is always
a column vector of size len(ca) × 1, that does not depend on
how many dimensions the CA has, and A is a matrix of size
len(ca)×len(ca). Hence the result of A·ca is also a column
vector of size len(ca) × 1 as ca.
The implementation of cellular automata as an artiﬁcial neu-
ral network requires the procedural generation of the adjacency
matrix of the grid. In this way, any lattice type or multidi-
mensional CAs can be implemented using the same approach.
1EvoDynamic
v0.1
available
at
https://github.com/SocratesNFR/
EvoDynamic.
The adjacency matrix of a sparsely connected network contains
many zeros because of the small number of connections. Since
we implement it on TensorFlow, the data type of the adjacency
matrix is preferably a SparseTensor. A dot product with
this data type can be up to 9 times faster depending on the
conﬁguration of the tensors [22]. The update rule of the CA
alters the weights of the connections in the adjacency matrix.
In a CA whose cells have two states meaning “dead” (zero) or
“alive” (one), the weights in the adjacency matrix are one for
connection and zero for no connection, such as an ordinary
adjacency matrix. Such matrix facilitates the description of
the update rule for counting the number of “alive” neighbors
because the result of the dot product between the adjacency
matrix and the cell state vector is the vector that contains the
number of “alive” neighbors for each cell. If the pattern of
the neighborhood matters in the update rule, each cell has
its neighbors encoded as a n-ary string where n means the
number of states that a cell can have. In this case the weights
of the connections with the neighbors are n-base identiﬁers
and are calculated by
neighbori = ni, ∀i ∈{0..len(neighbors) −1}.
(2)
Where neighbors is a vector of the cell’s neighbors. In the
adjacency matrix, each neighbor receives a weight according
to (2). The result of the dot product with such adjacency matrix
is a vector that consists of unique integers per neighborhood
pattern. Thus, the activation function is a lookup table from
integer (i.e., pattern) to next state.
Algorithm 1 generates the adjacency matrix for one-
dimensional CA, such as the elementary CA. Where widthCA
is the width or number of cells of a unidimensional CA
and neighborhood is a vector which describes the region
around the center cell. The connection weights depend on
the type of update rule as previously explained. For ex-
ample, in case of an elementary CA neighborhood =
[4 2 1]. indexNeighborCenter is the index of the center
cell in the neighborhood whose starting index is zero.
isWrappedGrid is a Boolean value that works as a ﬂag
for adding wrapped grid or not. A wrapped grid for one-
dimensional CA means that the initial and ﬁnal cells are
neighbors. With all these parameters, Algorithm 1 creates an
adjacency matrix by looping over the indices of the cells (from
zero to numberOfCells −1) with an inner loop for the
indices of the neighbors. If the selected currentNeighbor is
a non-zero value and its indices do not affect the boundary
condition, then the value of currentNeighbor is assigned
to the adjacency matrix A in the indices that correspond to
the connection between the current cell in the outer loop and
the actual index of currentNeighbor. Finally, this procedure
returns the adjacency matrix A.
To procedurally generate an adjacency matrix for 2D CA
instead of 1D CA, the algorithm needs to have small adjust-
ments. Algorithm 2 shows that for two-dimensional CA, such
as Conway’s Game of Life. In this case, the height of the
CA is an argument passed as heightCA. Neighborhood
 Algorithm 1 Generation of adjacency matrix for 1D cellular automaton
1: procedure GENERATECA1D(widthCA, neighborhood, indexNeighborCenter, isWrappedGrid)
2:
numberOfCells ←widthCA
3:
A ←0numberOfCells×numberOfCells
▷Adjacency matrix initialization
4:
for i ←{0..numberOfCells −1} do
5:
for j ←{−indexNeighborCenter..len(neighborhood) −indexNeighborCenter −1} do
6:
currentNeighbor ←neighborhoodj+indexNeighborCenter
7:
if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧(0 ≤(i + j) < widthCA)) then
8:
Ai,((i+j) mod widthCA) ←currentNeighbor
9:
return A
is a 2D matrix and indexNeighborCenter is a vector
of two components meaning the indices of the center of
Neighborhood. This procedure is similar to the one in
Algorithm 1, but it contains one more loop for the additional
dimension.
The activation function for CA is different from the ones
used for ANN. For CA, it contains the update rules that verify
the vector returned by the dot product between the adjacency
matrix and the vector of states. Normally, the update rules of
the CA are implemented as a lookup table from neighborhood
to next state. In our implementation, the lookup table maps
the resulting vector of the dot product to the next state of the
central cell.
III. RESULTS
This section presents the results of the proposed method and
it also stands for the preliminary results of the EvoDynamic
framework.
Fig. 1 illustrates a wrapped elementary CA described in the
procedure of Algorithm 1 and its generated adjacency matrix.
Fig. 1a shows the appearance of the desired elementary CA
with 16 cells (i.e., widthCA = 16). Fig. 1b describes its
pattern 3-neighborhood and the indices of the cells. Fig 1c
shows the result of the Algorithm 1 with the neighborhood
calculated by (2) for pattern matching in the activation func-
tion. In Fig. 1c, we can verify that the left neighbor has weight
equals to 4 (or 22 for the most signiﬁcant bit), central cell
weight is 2 (or 21) and right neighbor weight is 1 (or 20
for the least signiﬁcant bit) as deﬁned by (2). Since the CA
is wrapped, we can notice in row index 0 of the adjacency
matrix in Fig. 1c that the left neighbor of cell 0 is the cell 15,
and in row index 15 that the right neighbor of cell 15 is the
cell 0.
Fig. 2 describes a wrapped 2D CA for Algorithm 2 and
shows the resulting adjacency matrix. Fig. 2a illustrates the
desired two-dimensional CA with 16 cells (i.e., widthCA = 4
and heightCA = 4). Fig. 2b presents the von Neumann
neighborhood [23] which is used for counting the number of
”alive” neighbors (the connection weights are only zero and
one, and Neighborhood argument of Algorithm 2 deﬁnes
it). It also shows the index distribution of the CA whose
order is preserved after ﬂatting it to a column vector. Fig 2c
contains the generated adjacency matrix of Algorithm 2 for
the described 2D CA. Fig. 2b shows an example of a central
(a)
(b)
(c)
Fig. 1.
Elementary cellular automaton with 16 cells and wrapped grid. (a)
Example of the grid of cells with states. (b) Indices of the cells and standard
pattern neighborhood of elementary CA where thick border means the central
cell and thin border means the neighbors. (c) Generated adjacency matrix for
this elementary CA.
cell with its neighbors, the index of this central cell is 5 and
the row index 5 in the adjacency matrix of Fig. 2c presents
the same neighbor indices, i.e., 1, 4, 6 and 9. Since this is
a symmetric matrix, the columns have the same connectivity
of the rows. Therefore, this adjacency matrix represents an
undirected graph. The wrapping effect is also observable. For
example, the neighbors of the cell index 0 are 1, 3, 4 and 12.
So the neighbors 3 and 12 are the ones that the wrapped grid
allowed to exist for cell index 0.
IV. EVODYNAMIC FUTURE
The method of implementing a CA as an artiﬁcial neural
network will be beneﬁcial for the future of EvoDynamic
framework. Since the implementation of all sparsely connected
networks in Table I are already planned in future releases
 Algorithm 2 Generation of adjacency matrix of 2D cellular automaton
1: procedure GENERATECA2D(widthCA, heightCA, Neighborhood, indexNeighborCenter, isWrappedGrid)
2:
numberOfCells ←widthCA ∗heightCA
3:
A ←0numberOfCells×numberOfCells
▷Adjacency matrix initialization
4:
widthNB, heightNB ←shape(Neighborhood)
5:
for i ←{0..numberOfCells −1} do
6:
for j ←{−indexNeighborCenter0..widthNB −indexNeighborCenter0 −1} do
7:
for k ←{−indexNeighborCenter1..heightNB −indexNeighborCenter1 −1} do
8:
currentNeighbor ←Neighborhoodj+indexNeighborCenter
9:
if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧(0 ≤((i mod heightCA) + j) <
widthCA) ∧(0 ≤(⌊i/widthCA⌋+ k) < heightCA)) then
10:
Ai,(((i+k) mod widthCA)+((⌊i/widthCA⌋+j) mod heightCA)∗widthCA) ←currentNeighbor
11:
return A
(a)
(b)
(c)
Fig. 2. 2D cellular automaton with 16 cells (4 × 4) and wrapped grid. (a)
Example of the grid of cells with states. (b) Indices of the cells and von
Neumann counting neighborhood of 2D CA where thick border means the
current cell and thin border means the neighbors. (c) Generated adjacency
matrix for this 2D CA.
of the Python framework, EvoDynamic must have a general
representation to all of them. Therefore we are treating CA
as an ANN. Moreover, EvoDynamic framework will evolve
the connectivity, update and learning rules of the dynamical
systems for reservoir computing improvement and physical
substrate modeling. This common representation facilitates the
evolution of such systems and models which will be guided by
several methods that measure the quality of a reservoir or the
similarity to a dataset. One example of these methods is the
state trajectory. For visualization, we use principal component
analysis (PCA) to reduce the dimensionality of the states and
present them as a state transition diagram as shown in Fig. 3.
V. CONCLUSION
In this paper, we present an alternative method to implement
a cellular automaton. This allows any CA to be computed as an
artiﬁcial neural network. Therefore, this will help to extend the
CA implementation to more complex dynamical systems, such
as echo state networks and liquid state machines. Furthermore,
the EvoDynamic framework is built on a deep learning library,
TensorFlow, which permits the acceleration of the execution
when applied on parallel computational platforms with fast
CPUs and GPUs. The future work for this CA implementation
is to develop algorithms to procedurally generate adjacency
matrices for 3D and multidimensional cellular automata with
different types of cells, such as the cells with hexagonal shape.
ACKNOWLEDGMENTS
This work was supported by Norwegian Research Council
SOCRATES project (grant number 270961).
REFERENCES
[1] S. Wolfram, A new kind of science.
Wolfram media Champaign, IL,
2002, vol. 5.
[2] P. Rendell, Turing Universality of the Game of Life.
London:
Springer London, 2002, pp. 513–539. [Online]. Available: https:
//doi.org/10.1007/978-1-4471-0129-1 18
[3] B. Schrauwen, D. Verstraeten, and J. Van Campenhout, “An overview
of reservoir computing: theory, applications and implementations,” in
Proceedings of the 15th European Symposium on Artiﬁcial Neural
Networks. p. 471-482 2007, 2007, pp. 471–482.
[4] Z.
Konkoli,
S.
Nichele,
M.
Dale,
and
S.
Stepney,
Reservoir
Computing with Computational Matter.
Cham: Springer International
Publishing, 2018, pp. 269–293. [Online]. Available: https://doi.org/10.
1007/978-3-319-65826-1 14
[5] C. G. Langton, “Computation at the edge of chaos: Phase transitions
and
emergent
computation,”
Physica
D:
Nonlinear
Phenomena,
vol. 42, no. 1, pp. 12 – 37, 1990. [Online]. Available: http:
//www.sciencedirect.com/science/article/pii/016727899090064V
[6] S.
Nichele
and
M.
S.
Gundersen,
“Reservoir
computing
using
nonuniform binary cellular automata,” Complex Systems, vol. 26, no. 3,
pp. 225–245, Sep. 2017. [Online]. Available: https://doi.org/10.25088/
complexsystems.26.3.225
[7] S. Nichele and A. Molund, “Deep learning with cellular automaton-
based reservoir computing,” Complex Systems, vol. 26, no. 4, pp.
319–339, Dec. 2017. [Online]. Available: https://doi.org/10.25088/
complexsystems.26.4.319
[8] K. Kaneko, “Overview of coupled map lattices,” Chaos: An Interdisci-
plinary Journal of Nonlinear Science, vol. 2, no. 3, pp. 279–282, 1992.
 (a) Step 1
(b) Step 2
(c) Step 3
(d) Step 4
(e) Step 11
(f) Step 12
(g) Step 13
(h) Step 14
(i) Step 26
(j) Step 27
(k) Step 28
(l) Step 29
Fig. 3.
States of Conway’s Game of Life in a 7x7 wrapped lattice alongside their PCA-transformed state transition diagrams of the two ﬁrst principal
components. (a) Initial state is a glider. (a)-(d) Four ﬁrst steps in this CA. (e)-(h) Four intermediate steps in this CA while reaching the wrapped border. (i)-(l)
Four last steps in this CA before repeating the initial state and closing a cycle.
[9] C. Gershenson, “Introduction to random boolean networks,” arXiv
preprint nlin/0408006, 2004.
[10] H. Jaeger and H. Haas, “Harnessing nonlinearity: Predicting chaotic
systems and saving energy in wireless communication,” Science,
vol. 304, no. 5667, pp. 78–80, 2004. [Online]. Available: https:
//science.sciencemag.org/content/304/5667/78
[11] W.
Maass
and
H.
Markram,
“On
the
computational
power
of
circuits
of
spiking
neurons,”
Journal
of
Computer
and
System
Sciences, vol. 69, no. 4, pp. 593 – 616, 2004. [Online]. Available:
http://www.sciencedirect.com/science/article/pii/S0022000004000406
[12] S. Nichele and G. Tufte, “Trajectories and attractors as speciﬁcation for
the evolution of behaviour in cellular automata,” in IEEE Congress on
Evolutionary Computation, July 2010, pp. 1–8.
[13] S. Nichele and G. Tufte, “Genome parameters as information to forecast
emergent developmental behaviors,” in Unconventional Computation
and Natural Computation, J. Durand-Lose and N. Jonoska, Eds. Berlin,
Heidelberg: Springer Berlin Heidelberg, 2012, pp. 186–197.
[14] G. Tanaka, T. Yamane, J. B. Hroux, R. Nakane, N. Kanazawa,
S.
Takeda,
H.
Numata,
D.
Nakano,
and
A.
Hirose,
“Recent
advances
in
physical
reservoir
computing:
A
review,”
Neural
Networks, vol. 115, pp. 100 – 123, 2019. [Online]. Available:
http://www.sciencedirect.com/science/article/pii/S0893608019300784
[15] P. Aaser, M. Knudsen, O. H. Ramstad, R. van de Wijdeven, S. Nichele,
I. Sandvig, G. Tufte, U. Stefan Bauer, . Halaas, S. Hendseth,
A. Sandvig, and V. Valderhaug, “Towards making a cyborg: A
closed-loop reservoir-neuro system,” The 2018 Conference on Artiﬁcial
Life: A Hybrid of the European Conference on Artiﬁcial Life (ECAL)
and the International Conference on the Synthesis and Simulation
of Living Systems (ALIFE), no. 29, pp. 430–437, 2017. [Online].
Available: https://www.mitpressjournals.org/doi/abs/10.1162/isal a 072
[16] H. Broersma, J. F. Miller, and S. Nichele, Computational Matter:
Evolving Computational Functions in Nanoscale Materials.
Cham:
Springer
International
Publishing,
2017,
pp.
397–428.
[Online].
Available: https://doi.org/10.1007/978-3-319-33921-4 16
[17] S. Nichele, S. S. Farstad, and G. Tufte, “Universality of evolved
cellular automata in-materio.” International Journal of Unconventional
Computing, vol. 13, no. 1, 2017.
[18] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin,
S. Ghemawat, G. Irving, M. Isard, M. Kudlur, J. Levenberg, R. Monga,
S. Moore, D. G. Murray, B. Steiner, P. Tucker, V. Vasudevan, P. Warden,
M. Wicke, Y. Yu, and X. Zheng, “Tensorﬂow: A system for large-scale
machine learning,” in 12th USENIX Symposium on Operating Systems
Design and Implementation (OSDI 16).
Savannah, GA: USENIX
Association, 2016, pp. 265–283. [Online]. Available: https://www.
usenix.org/conference/osdi16/technical-sessions/presentation/abadi
[19] J. H. Jensen, E. Folven, and G. Tufte, “Computation in artiﬁcial
spin
ice,”
The
2018
Conference
on
Artiﬁcial
Life:
A
Hybrid
of the European Conference on Artiﬁcial Life (ECAL) and the
International Conference on the Synthesis and Simulation of Living
Systems (ALIFE), no. 30, pp. 15–22, 2018. [Online]. Available:
https://www.mitpressjournals.org/doi/abs/10.1162/isal a 00011
[20] SOCRATES
Self-Organizing Computational substRATES. [Online].
Available: https://www.ntnu.edu/socrates
[21] “Conway’s game of life implemented using tensorﬂow 2d convolution
function,” 2016. [Online]. Available: https://github.com/conceptacid/
conv2d life
[22] TensorFlow, “tf.sparse.sparse dense matmul — tensorﬂow core r1.14
— tensorﬂow.” [Online]. Available: https://www.tensorﬂow.org/api
docs/python/tf/sparse/sparse dense matmul
[23] T. Toffoli and N. Margolus, Cellular automata machines: a new envi-
ronment for modeling.
MIT press, 1987.
",,doc11,"A general representation of dynamical systems for reservoir computing Sidney Pontes-Filho∗,†,§, Anis Yazidi∗, Jianhua Zhang∗, Hugo Hammer∗, Gustavo B. M. Mello∗, Ioanna Sandvig‡, Gunnar Tufte† and Stefano Nichele∗ ∗Department of Computer Science, Oslo Metropolitan University, Oslo, Norway †Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway ‡Department of Neuromedicine and Movement Science, Norwegian University of Science and Technology, Trondheim, Norway Email: §sidneyp@oslomet.no Abstract—Dynamical systems are capable of performing com- putation in a reservoir computing paradigm. This paper presents a general representation of these systems as an artiﬁcial neural network (ANN). Initially, we implement the simplest dynamical system, a cellular automaton. The mathematical fundamentals be- hind an ANN are maintained, but the weights of the connections and the activation function are adjusted to work as an update rule in the context of cellular automata. The advantages of such implementation are its usage on specialized and optimized deep learning libraries, the capabilities to generalize it to other types of networks and the possibility to evolve cellular automata and other dynamical systems in terms of connectivity, update and learning rules. Our implementation of cellular automata constitutes an initial step towards a general framework for dynamical systems. It aims to evolve such systems to optimize their usage in reservoir computing and to model physical computing substrates. I. INTRODUCTION A cellular automaton (CA) is the simplest computing sys- tem where the emergence of complex dynamics from local interactions might take place. It consists of a grid of cells with a ﬁnite number of states that change according to simple rules depending on the neighborhood and own state in discrete time-steps. Some notable examples are the elementary CA [1], which is unidimensional with three neighbors and eight update rules, and Conway’s Game of Life [2], which is two- dimensional with nine neighbors and three update rules. Table I presents some computing systems that are capable of giving rise to the emergence of complex dynamics. Those systems can be exploited by reservoir computing which is a paradigm that resorts to dynamical systems to simplify com- plex data. Hence, simpler and faster machine learning methods can be applied with such simpliﬁed data. Reservoir computing is more energy efﬁcient than deep learning methods and it can even yield competitive results, especially for temporal data [3]. In short, reservoir computing exploits a dynamical system that possesses the echo state property and fading memory, where the internals of the reservoir are untrained and the only training happens at the linear readout stage [4]. Reservoir computers are most useful when the substrate’s dynamics are at the “edge of chaos”, meaning a range of dynamical behaviors that is between order and disorder [5]. Cellular automata with such dynamical behavior are capable of being exploited as TABLE I EXAMPLES OF DYNAMICAL SYSTEMS. Dynamical system State Time Connectivity Cellular automata Discrete Discrete Regular Coupled map lattice Continuous Discrete Regular Random Boolean network Discrete Discrete Random Echo state network Continuous Discrete Random Liquid state machine Discrete Continuous Random reservoirs [6], [7]. Other systems can also exhibit the same dynamics. The coupled map lattice [8] is very similar to CA, the only exception is that the coupled map lattice has continuous states which are updated by a recurrence equation involving the neighborhood. Random Boolean network [9] is a generalization of CA where random connectivity exists. Echo state network [10] is an artiﬁcial neural network (ANN) with random topology while liquid state machine [11] is similar to echo state network with the difference that it is a spiking neural network that communicates through discrete-events (spikes) over continuous time. One important aspect of the computation performed in a dynamical system is the trajectory of system’s states traversed during the computation [12]. Such trajectory may be guided by system parameters [13]. Computation in dynamical systems may be carried out in physical substrates [14], such as networks of biological neurons [15] or in other nanoscale materials [16]. Finding the correct abstraction for the computation in a dynamical system, e.g. CA, is an open problem [17]. All the systems described in Table I are sparsely connected and can be represented by an adjacency matrix, such as a graph. A fully connected feedforward ANN represents its connectivity from a layer to another with an adjacency matrix that contains the weights of each connection. Our CA implementation is similar to this, but the connectivity is from the ”layer” of cells to itself. The goal of representing CA with an adjacency matrix is to implement a framework which facilitates the development of all types of CAs, from unidimensional to multidimensional, with all kinds of lattices and without any boundary checks during execution; and also the inclusion of the major dynam- ical systems, independent of the type of the state, time and arXiv:1907.01856v1 [cs.NE] 3 Jul 2019 connectivity. Such initial implementation is the ﬁrst part of a Python framework under development, based on TensorFlow deep neural network library [18]. Therefore, it beneﬁts from powerful and parallel computing systems with multi-CPU and multi-GPU. This framework, called EvoDynamic1, aims at evolving the connectivity, update and learning rules of sparsely connected networks to improve their usage for reservoir com- puting guided by the echo state property, fading memory, state trajectory and other quality measurements, and to model the dynamics and behavior of physical reservoirs, such as in- vitro biological neural networks interfaced with microelectrode arrays and nanomagnetic ensembles. Those two substrates have real applicability as reservoirs. For example, the former substrate is applied to control a robot, in fact making it into a cyborg, a closed-loop biological-artiﬁcial neuro-system [15], and the latter possesses computation capability as shown by a square lattice of nanomagnets [19]. Those substrates are the main interest of the SOCRATES project [20] which aims to explore a dynamic, robust and energy efﬁcient hardware for data analysis. There are some implementations of CA similar to the one of EvoDynamic framework. They normally implement Conway’s Game of Life by applying 2D convolution with a kernel that is used to count the neighbors, then the resulting matrix consists of the number of neighboring cells and is used to update the CA. One such implementation, also based on TensorFlow, is available open-source in [21]. This paper is organized as follows. Section II describes our method according to which we use adjacency matrix to compute CA. Section III presents the results obtained from the method. Section IV discusses the future plan of EvoDynamic framework and Section V concludes this paper. II. METHOD In our proposed method, the equation to calculate the next states of the cells in a cellular automaton is cat+1 = f(A · cat). (1) It is similar to the equation of the forward pass of an artiﬁcial neural network, but without the bias. The layer is connected to itself, and the activation function f deﬁnes the update rules of the CA. The next states of the CA cat+1 is calculated from the result of the activation function f which receives as argument the dot product between the adjacency matrix A and the current states of the CA cat. ca is always a column vector of size len(ca) × 1, that does not depend on how many dimensions the CA has, and A is a matrix of size len(ca)×len(ca). Hence the result of A·ca is also a column vector of size len(ca) × 1 as ca. The implementation of cellular automata as an artiﬁcial neu- ral network requires the procedural generation of the adjacency matrix of the grid. In this way, any lattice type or multidi- mensional CAs can be implemented using the same approach. 1EvoDynamic v0.1 available at EvoDynamic. The adjacency matrix of a sparsely connected network contains many zeros because of the small number of connections. Since we implement it on TensorFlow, the data type of the adjacency matrix is preferably a SparseTensor. A dot product with this data type can be up to 9 times faster depending on the conﬁguration of the tensors [22]. The update rule of the CA alters the weights of the connections in the adjacency matrix. In a CA whose cells have two states meaning “dead” (zero) or “alive” (one), the weights in the adjacency matrix are one for connection and zero for no connection, such as an ordinary adjacency matrix. Such matrix facilitates the description of the update rule for counting the number of “alive” neighbors because the result of the dot product between the adjacency matrix and the cell state vector is the vector that contains the number of “alive” neighbors for each cell. If the pattern of the neighborhood matters in the update rule, each cell has its neighbors encoded as a n-ary string where n means the number of states that a cell can have. In this case the weights of the connections with the neighbors are n-base identiﬁers and are calculated by neighbori = ni, ∀i ∈{0..len(neighbors) −1}. (2) Where neighbors is a vector of the cell’s neighbors. In the adjacency matrix, each neighbor receives a weight according to (2). The result of the dot product with such adjacency matrix is a vector that consists of unique integers per neighborhood pattern. Thus, the activation function is a lookup table from integer (i.e., pattern) to next state. Algorithm 1 generates the adjacency matrix for one- dimensional CA, such as the elementary CA. Where widthCA is the width or number of cells of a unidimensional CA and neighborhood is a vector which describes the region around the center cell. The connection weights depend on the type of update rule as previously explained. For ex- ample, in case of an elementary CA neighborhood = [4 2 1]. indexNeighborCenter is the index of the center cell in the neighborhood whose starting index is zero. isWrappedGrid is a Boolean value that works as a ﬂag for adding wrapped grid or not. A wrapped grid for one- dimensional CA means that the initial and ﬁnal cells are neighbors. With all these parameters, Algorithm 1 creates an adjacency matrix by looping over the indices of the cells (from zero to numberOfCells −1) with an inner loop for the indices of the neighbors. If the selected currentNeighbor is a non-zero value and its indices do not affect the boundary condition, then the value of currentNeighbor is assigned to the adjacency matrix A in the indices that correspond to the connection between the current cell in the outer loop and the actual index of currentNeighbor. Finally, this procedure returns the adjacency matrix A. To procedurally generate an adjacency matrix for 2D CA instead of 1D CA, the algorithm needs to have small adjust- ments. Algorithm 2 shows that for two-dimensional CA, such as Conway’s Game of Life. In this case, the height of the CA is an argument passed as heightCA. Neighborhood Algorithm 1 Generation of adjacency matrix for 1D cellular automaton 1: procedure GENERATECA1D(widthCA, neighborhood, indexNeighborCenter, isWrappedGrid) 2: numberOfCells ←widthCA 3: A ←0numberOfCells×numberOfCells ▷Adjacency matrix initialization 4: for i ←{0..numberOfCells −1} do 5: for j ←{−indexNeighborCenter..len(neighborhood) −indexNeighborCenter −1} do 6: currentNeighbor ←neighborhoodj+indexNeighborCenter 7: if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧(0 ≤(i + j) < widthCA)) then 8: Ai,((i+j) mod widthCA) ←currentNeighbor 9: return A is a 2D matrix and indexNeighborCenter is a vector of two components meaning the indices of the center of Neighborhood. This procedure is similar to the one in Algorithm 1, but it contains one more loop for the additional dimension. The activation function for CA is different from the ones used for ANN. For CA, it contains the update rules that verify the vector returned by the dot product between the adjacency matrix and the vector of states. Normally, the update rules of the CA are implemented as a lookup table from neighborhood to next state. In our implementation, the lookup table maps the resulting vector of the dot product to the next state of the central cell. III. RESULTS This section presents the results of the proposed method and it also stands for the preliminary results of the EvoDynamic framework. Fig. 1 illustrates a wrapped elementary CA described in the procedure of Algorithm 1 and its generated adjacency matrix. Fig. 1a shows the appearance of the desired elementary CA with 16 cells (i.e., widthCA = 16). Fig. 1b describes its pattern 3-neighborhood and the indices of the cells. Fig 1c shows the result of the Algorithm 1 with the neighborhood calculated by (2) for pattern matching in the activation func- tion. In Fig. 1c, we can verify that the left neighbor has weight equals to 4 (or 22 for the most signiﬁcant bit), central cell weight is 2 (or 21) and right neighbor weight is 1 (or 20 for the least signiﬁcant bit) as deﬁned by (2). Since the CA is wrapped, we can notice in row index 0 of the adjacency matrix in Fig. 1c that the left neighbor of cell 0 is the cell 15, and in row index 15 that the right neighbor of cell 15 is the cell 0. Fig. 2 describes a wrapped 2D CA for Algorithm 2 and shows the resulting adjacency matrix. Fig. 2a illustrates the desired two-dimensional CA with 16 cells (i.e., widthCA = 4 and heightCA = 4). Fig. 2b presents the von Neumann neighborhood [23] which is used for counting the number of ”alive” neighbors (the connection weights are only zero and one, and Neighborhood argument of Algorithm 2 deﬁnes it). It also shows the index distribution of the CA whose order is preserved after ﬂatting it to a column vector. Fig 2c contains the generated adjacency matrix of Algorithm 2 for the described 2D CA. Fig. 2b shows an example of a central (a) (b) (c) Fig. 1. Elementary cellular automaton with 16 cells and wrapped grid. (a) Example of the grid of cells with states. (b) Indices of the cells and standard pattern neighborhood of elementary CA where thick border means the central cell and thin border means the neighbors. (c) Generated adjacency matrix for this elementary CA. cell with its neighbors, the index of this central cell is 5 and the row index 5 in the adjacency matrix of Fig. 2c presents the same neighbor indices, i.e., 1, 4, 6 and 9. Since this is a symmetric matrix, the columns have the same connectivity of the rows. Therefore, this adjacency matrix represents an undirected graph. The wrapping effect is also observable. For example, the neighbors of the cell index 0 are 1, 3, 4 and 12. So the neighbors 3 and 12 are the ones that the wrapped grid allowed to exist for cell index 0. IV. EVODYNAMIC FUTURE The method of implementing a CA as an artiﬁcial neural network will be beneﬁcial for the future of EvoDynamic framework. Since the implementation of all sparsely connected networks in Table I are already planned in future releases Algorithm 2 Generation of adjacency matrix of 2D cellular automaton 1: procedure GENERATECA2D(widthCA, heightCA, Neighborhood, indexNeighborCenter, isWrappedGrid) 2: numberOfCells ←widthCA ∗heightCA 3: A ←0numberOfCells×numberOfCells ▷Adjacency matrix initialization 4: widthNB, heightNB ←shape(Neighborhood) 5: for i ←{0..numberOfCells −1} do 6: for j ←{−indexNeighborCenter0..widthNB −indexNeighborCenter0 −1} do 7: for k ←{−indexNeighborCenter1..heightNB −indexNeighborCenter1 −1} do 8: currentNeighbor ←Neighborhoodj+indexNeighborCenter 9: if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧(0 ≤((i mod heightCA) + j) < widthCA) ∧(0 ≤(⌊i/widthCA⌋+ k) < heightCA)) then 10: Ai,(((i+k) mod widthCA)+((⌊i/widthCA⌋+j) mod heightCA)∗widthCA) ←currentNeighbor 11: return A (a) (b) (c) Fig. 2. 2D cellular automaton with 16 cells (4 × 4) and wrapped grid. (a) Example of the grid of cells with states. (b) Indices of the cells and von Neumann counting neighborhood of 2D CA where thick border means the current cell and thin border means the neighbors. (c) Generated adjacency matrix for this 2D CA. of the Python framework, EvoDynamic must have a general representation to all of them. Therefore we are treating CA as an ANN. Moreover, EvoDynamic framework will evolve the connectivity, update and learning rules of the dynamical systems for reservoir computing improvement and physical substrate modeling. This common representation facilitates the evolution of such systems and models which will be guided by several methods that measure the quality of a reservoir or the similarity to a dataset. One example of these methods is the state trajectory. For visualization, we use principal component analysis (PCA) to reduce the dimensionality of the states and present them as a state transition diagram as shown in Fig. 3. V. CONCLUSION In this paper, we present an alternative method to implement a cellular automaton. This allows any CA to be computed as an artiﬁcial neural network. Therefore, this will help to extend the CA implementation to more complex dynamical systems, such as echo state networks and liquid state machines. Furthermore, the EvoDynamic framework is built on a deep learning library, TensorFlow, which permits the acceleration of the execution when applied on parallel computational platforms with fast CPUs and GPUs. The future work for this CA implementation is to develop algorithms to procedurally generate adjacency matrices for 3D and multidimensional cellular automata with different types of cells, such as the cells with hexagonal shape. ACKNOWLEDGMENTS This work was supported by Norwegian Research Council SOCRATES project (grant number 270961). REFERENCES [1] S. Wolfram, A new kind of science. Wolfram media Champaign, IL, 2002, vol. 5. [2] P. Rendell, Turing Universality of the Game of Life. London: Springer London, 2002, pp. 513–539. [Online]. Available: https: //doi.org/10.1007/978-1-4471-0129-1 18 [3] B. Schrauwen, D. Verstraeten, and J. Van Campenhout, “An overview of reservoir computing: theory, applications and implementations,” in Proceedings of the 15th European Symposium on Artiﬁcial Neural Networks. p. 471-482 2007, 2007, pp. 471–482. [4] Z. Konkoli, S. Nichele, M. Dale, and S. Stepney, Reservoir Computing with Computational Matter. Cham: Springer International Publishing, 2018, pp. 269–293. [Online]. Available: 1007/978-3-319-65826-1 14 [5] C. G. Langton, “Computation at the edge of chaos: Phase transitions and emergent computation,” Physica D: Nonlinear Phenomena, vol. 42, no. 1, pp. 12 – 37, 1990. [Online]. Available: http: //www.sciencedirect.com/science/article/pii/016727899090064V [6] S. Nichele and M. S. Gundersen, “Reservoir computing using nonuniform binary cellular automata,” Complex Systems, vol. 26, no. 3, pp. 225–245, Sep. 2017. [Online]. Available: complexsystems.26.3.225 [7] S. Nichele and A. Molund, “Deep learning with cellular automaton- based reservoir computing,” Complex Systems, vol. 26, no. 4, pp. 319–339, Dec. 2017. [Online]. Available: complexsystems.26.4.319 [8] K. Kaneko, “Overview of coupled map lattices,” Chaos: An Interdisci- plinary Journal of Nonlinear Science, vol. 2, no. 3, pp. 279–282, 1992. (a) Step 1 (b) Step 2 (c) Step 3 (d) Step 4 (e) Step 11 (f) Step 12 (g) Step 13 (h) Step 14 (i) Step 26 (j) Step 27 (k) Step 28 (l) Step 29 Fig. 3. States of Conway’s Game of Life in a 7x7 wrapped lattice alongside their PCA-transformed state transition diagrams of the two ﬁrst principal components. (a) Initial state is a glider. (a)-(d) Four ﬁrst steps in this CA. (e)-(h) Four intermediate steps in this CA while reaching the wrapped border. (i)-(l) Four last steps in this CA before repeating the initial state and closing a cycle. [9] C. Gershenson, “Introduction to random boolean networks,” arXiv preprint nlin/0408006, 2004. [10] H. Jaeger and H. Haas, “Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication,” Science, vol. 304, no. 5667, pp. 78–80, 2004. [Online]. Available: https: //science.sciencemag.org/content/304/5667/78 [11] W. Maass and H. Markram, “On the computational power of circuits of spiking neurons,” Journal of Computer and System Sciences, vol. 69, no. 4, pp. 593 – 616, 2004. [Online]. Available: [12] S. Nichele and G. Tufte, “Trajectories and attractors as speciﬁcation for the evolution of behaviour in cellular automata,” in IEEE Congress on Evolutionary Computation, July 2010, pp. 1–8. [13] S. Nichele and G. Tufte, “Genome parameters as information to forecast emergent developmental behaviors,” in Unconventional Computation and Natural Computation, J. Durand-Lose and N. Jonoska, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2012, pp. 186–197. [14] G. Tanaka, T. Yamane, J. B. Hroux, R. Nakane, N. Kanazawa, S. Takeda, H. Numata, D. Nakano, and A. Hirose, “Recent advances in physical reservoir computing: A review,” Neural Networks, vol. 115, pp. 100 – 123, 2019. [Online]. Available: [15] P. Aaser, M. Knudsen, O. H. Ramstad, R. van de Wijdeven, S. Nichele, I. Sandvig, G. Tufte, U. Stefan Bauer, . Halaas, S. Hendseth, A. Sandvig, and V. Valderhaug, “Towards making a cyborg: A closed-loop reservoir-neuro system,” The 2018 Conference on Artiﬁcial Life: A Hybrid of the European Conference on Artiﬁcial Life (ECAL) and the International Conference on the Synthesis and Simulation of Living Systems (ALIFE), no. 29, pp. 430–437, 2017. [Online]. Available: a 072 [16] H. Broersma, J. F. Miller, and S. Nichele, Computational Matter: Evolving Computational Functions in Nanoscale Materials. Cham: Springer International Publishing, 2017, pp. 397–428. [Online]. Available: 16 [17] S. Nichele, S. S. Farstad, and G. Tufte, “Universality of evolved cellular automata in-materio.” International Journal of Unconventional Computing, vol. 13, no. 1, 2017. [18] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat, G. Irving, M. Isard, M. Kudlur, J. Levenberg, R. Monga, S. Moore, D. G. Murray, B. Steiner, P. Tucker, V. Vasudevan, P. Warden, M. Wicke, Y. Yu, and X. Zheng, “Tensorﬂow: A system for large-scale machine learning,” in 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16). Savannah, GA: USENIX Association, 2016, pp. 265–283. [Online]. Available: usenix.org/conference/osdi16/technical-sessions/presentation/abadi [19] J. H. Jensen, E. Folven, and G. Tufte, “Computation in artiﬁcial spin ice,” The 2018 Conference on Artiﬁcial Life: A Hybrid of the European Conference on Artiﬁcial Life (ECAL) and the International Conference on the Synthesis and Simulation of Living Systems (ALIFE), no. 30, pp. 15–22, 2018. [Online]. Available: a 00011 [20] SOCRATES Self-Organizing Computational substRATES. [Online]. Available: [21] “Conway’s game of life implemented using tensorﬂow 2d convolution function,” 2016. [Online]. Available: conv2d life [22] TensorFlow, “tf.sparse.sparse dense matmul — tensorﬂow core r1.14 — tensorﬂow.” [Online]. Available: docs/python/tf/sparse/sparse dense matmul [23] T. Toffoli and N. Margolus, Cellular automata machines: a new envi- ronment for modeling. MIT press, 1987."
A deep CNN model for anomaly detection and localization in wireless capsule endoscopy images,Samir Jain and Ayan Seal and Aparajita Ojha and Anis Yazidi and Jan Bures and Ilja Tacheci and Ondrej Krejcar,2021,,137,Computers in Biology and Medicine,article,"Computers in Biology and Medicine 137 (2021) 104789
Available online 25 August 2021
0010-4825/© 2021 Elsevier Ltd. All rights reserved.
A deep CNN model for anomaly detection and localization in wireless 
capsule endoscopy images 
Samir Jain a, Ayan Seal a,*, Aparajita Ojha a, Anis Yazidi b,d,c, Jan Bures e, Ilja Tacheci e, 
Ondrej Krejcar f,g 
a PDPM Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, 482005, India 
b Department of Computer Science, OsloMet – Oslo Metropolitan University, Oslo, Norway 
c Department of Plastic and Reconstructive Surgery, Oslo University Hospital, Oslo, Norway 
d Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway 
e Second Department of Internal Medicine-Gastroenterology, Charles University, Faculty of Medicine in Hradec Kralove and University Hospital Hradec Kralove, Sokolska 
581, Hradec Kralove, 50005, Czech Republic 
f Center for Basic and Applied Research, Faculty of Informatics and Management, University of Hradec Kralove, Hradecka 1249, Hradec Kralove, 50003, Czech Republic 
g Malaysia Japan International Institute of Technology, Universiti Teknologi Malaysia, Jalan Sultan Yahya Petra, 54100, Kuala Lumpur, Malaysia   
A R T I C L E  I N F O   
Keywords: 
Deep convolutional neural network 
Attention mechanism 
Wireless capsule endoscopy 
Anomaly detection 
Localization 
A B S T R A C T   
Wireless capsule endoscopy (WCE) is one of the most efficient methods for the examination of gastrointestinal 
tracts. Computer-aided intelligent diagnostic tools alleviate the challenges faced during manual inspection of 
long WCE videos. Several approaches have been proposed in the literature for the automatic detection and 
localization of anomalies in WCE images. Some of them focus on specific anomalies such as bleeding, polyp, 
lesion, etc. However, relatively fewer generic methods have been proposed to detect all those common anomalies 
simultaneously. In this paper, a deep convolutional neural network (CNN) based model ‘WCENet’ is proposed for 
anomaly detection and localization in WCE images. The model works in two phases. In the first phase, a simple 
and efficient attention-based CNN classifies an image into one of the four categories: polyp, vascular, inflam­
matory, or normal. If the image is classified in one of the abnormal categories, it is processed in the second phase 
for the anomaly localization. Fusion of Grad-CAM++ and a custom SegNet is used for anomalous region seg­
mentation in the abnormal image. WCENet classifier attains accuracy and area under receiver operating char­
acteristic of 98% and 99%. The WCENet segmentation model obtains a frequency weighted intersection over 
union of 81%, and an average dice score of 56% on the KID dataset. WCENet outperforms nine different state-of- 
the-art conventional machine learning and deep learning models on the KID dataset. The proposed model 
demonstrates potential for clinical applications.   
1. Introduction 
Computer-aided diagnostic (CAD) systems have seen tremendous 
growth in recent years. With the evolution of cyber-physical healthcare 
systems, the emphasis is on process automation in every field of di­
agnostics. Modern artificial intelligence techniques enriched with deep 
learning algorithms are major catalysts in these developments. Com­
puter Vision-based diagnostic tools have shown remarkable improve­
ments over the years in tasks like tumor detection in brain MRI [1], 
identification of gastro-intestinal malignancy [2], ulcers [3], polyps [4], 
tumors [5], bleeding [6] etc. WCE is a promising non-invasive painless 
method for the inspection of the digestive tract through captured videos 
[7]. In WCE, a tiny capsule equipped with a micro-sized camera (10 ×
25 mm) is swallowed by the patient under examination. The video 
captured on the fly by the capsule is sent to a small receiver tied around 
the waist of the patient. WCE is a primary tool for the detection and 
diagnosis of anomalies like ulcers [8], bleeding regions [9], and polyps 
[10]. It enables examining those areas which conventional endoscopic 
procedures cannot reach. However, the downside of the WCE is the 
length of videos that may last from 8 to 10 h and may contain more than 
eighty thousand frames, with a frequency rate of 2 frames per second 
[11]. This makes the manual investigation of the entire tract a tedious 
and cognitively demanding task. The complete analysis of the video 
requires continuous concentration for very long hours which might 
* Corresponding author. 
E-mail address: ayan@iiitdmj.ac.in (A. Seal).  
Contents lists available at ScienceDirect 
Computers in Biology and Medicine 
journal homepage: www.elsevier.com/locate/compbiomed 
https://doi.org/10.1016/j.compbiomed.2021.104789 
Received 11 April 2021; Received in revised form 18 August 2021; Accepted 18 August 2021   
 Computers in Biology and Medicine 137 (2021) 104789
2
overwhelm human attention. Due to this reason, the call for automation 
of the identification of abnormalities in video frames is of high demand. 
Recently, some product manufacturers have launched WCE systems with 
embedded software for identifying bleeding regions in video frames 
[12]. However, such systems struggle in identifying other types of 
anomalies. It is mainly because different types of anomalies pose chal­
lenges in identifying them using traditional image processing techniques 
due to the differences in color, texture, size and, shape. 
Many Machine Learning (ML) techniques have been devised in the 
last decade for the detection of abnormal frames in WCE videos. The k- 
nearest neighbors (KNN), principal component analysis (PCA), support 
vector machines (SVM), random forest (RF), and artificial neural net­
works (ANN) are some of the most widely deployed classifiers for the 
identification of different types of anomalies. These ML algorithms are 
usually trained using manually extracted features such as color histo­
gram [13], wavelet transform [14], local binary pattern (LBP) [15], 
Haralick texture features [16], scale-invariant feature transform (SIFT) 
[16], speed up robust features [17], and fractal dimensions (FD) [18] for 
the identification of WCE anomalies. 
In recent years, deep learning has emerged as a promising tool for the 
detection of anomalous WCE images and localization of abnormal re­
gions [4,11,19–21]. Notably, CNNs along with conventional feature 
extraction techniques have been used for anomaly detection such as 
lesion, hookworm, and bleeding [22,23]. Although deep learning tech­
niques have shown improved performance in many cases, the problem 
we are tackling in this paper remains challenging due to the diversity of 
patterns and the complexity of textures of the abnormalities. The scar­
city of labeled data and the computational requirements are also matters 
of concern when it comes to the applicability of these algorithms in WCE 
videos [24–26]. Until recently, most of the methods were developed to 
identify only a single type of anomaly. For automatic classification and 
localization of abnormal regions, a single method that can cover most of 
the anomalies in one shot is highly useful. Some of the recent approaches 
that address this problem include [11,27,28]. Iakovidis et al. [11] have 
suggested a CNN-based three-phase method that captures the features of 
a large number of anomalies in the WCE images. They have also esti­
mated salient points in abnormal images which serve as guiding factors 
for the localization of abnormal regions. Gao et al. [29] have suggested a 
deep learning tool for the detection of outliers in the WCE image. They 
integrated a long short-term memory network with a CNN for learning 
the graphical patterns of ulcers, erythema, protruding lesions, polyp, 
and vascular malformation. 
In this paper, a CAD model ‘WCENet’ is proposed to automatically 
identify and localize three different types of abnormalities in WCE im­
ages. The model works in two phases. In the first phase, a CNN model 
with an attention mechanism is trained to classify WCE images into 4 
classes namely, inflammatory, polyp, vascular and normal. Images 
classified into abnormal classes are processed in the second phase for 
estimation of regions using a combination of a custom SegNet [30] and 
Grad-CAM++ [31]. The main contributions of the proposed work are 
summarized as follows:  
• An attention-based CNN model is developed for the classification of 
WCE images into four categories namely, inflammatory, polyp, 
vascular (bleeding), and normal.  
• A hybrid approach is used for the localization of anomalies in an 
image using both a custom SegNet [30] and Grad-CAM++ [31]. The 
hybrid approach provides higher precision than the individual 
methods.  
• The proposed model demonstrates superior performance in terms of 
classification and localization performance in comparison with other 
state-of-the-art methods. 
The rest of the paper is organized as follows. Section II gives a brief 
overview of related work. Section III is devoted to the presentation of the 
proposed model for anomaly detection and localization in WCE images. 
In Section IV, experimental results are presented and compared with 
some state-of-the-art techniques. Section V concludes the paper and 
delineates some future work. 
2. Related work 
Existing research in the field of WCE covers detection of anomalies 
like bleeding [22,32], polyps [33–35], hook-worms [19], ulcers [8], 
tumors [36] etc. Pixel-based approaches have been found effective for 
bleeding detection since color plays an essential role in this type of 
anomaly (see e.g. Refs. [12,32,37,38]). Some of the researchers have 
used the conversion of RGB images to a different color space to improve 
classification accuracy. Shah et al. in Ref. [39] have opted for HSI color 
space over RGB for the classification of bleeding and non-bleeding im­
ages using a color threshold (see also [6,12]). Shape and texture analysis 
proves to be very useful in the characterization of polyps, ulcers, in­
flammatory or vascular disorders, and tumors. Bag of visual words [32], 
color histogram [38], LBP [40], wavelet transform [36], FD [18] are 
some of the approaches relying on these types of features. Most of the 
image 
classification 
techniques 
mentioned 
above 
are 
either 
threshold-based where the count and the intensity of pixels are used 
[12] or use ML algorithms like KNN [32,37], SVM [13,17], and ANN 
[14,41]. Cong et al. [42]. have suggested a new variant of SVM termed 
as Deep Sparse SVM (DSSVM) for the identification of abnormal frames. 
DSSVM is trained on color and texture features that were extracted from 
image super-pixels. A group sparsity criterion is defined for the removal 
of irrelevant features by assigning a higher weight to important features. 
This model is found to be quite useful when the computed features 
exhibit redundancies. 
Deep learning methods have recently emerged as powerful solutions 
in a variety of applications including WCE video analytics (see, for 
example [9,25,31,39,43]). Sekuboyina et al. [27]. have used the CIE-Lab 
color space representation of WCE images to train a CNN classifier on the 
patches falling in the normal and abnormal regions of WCE images. Once 
the CNN is trained, it locates the abnormal regions in an image by 
identifying and combining abnormal patches. Other methods that utilize 
CNN include [4,11,22,28]. CNN-based autoencoders have also been 
popular alternatives for the extraction of features from WCE images 
[10]. A stacked sparse autoencoder (SSAE) has been presented by Yuan 
et al. [10] for polyp detection. The accuracy of the model is enhanced 
using an image manifold constraint (SSAEIM) with the idea that the 
images belonging to the same class share common features whereas the 
images from different classes exhibit high variances in the learned fea­
tures. Banik et al. [4] have suggested an integrated method for the 
segmentation of polyps by deploying a CNN and a level set method. A 
modified level set method termed as Local Gradient Weighting 
embedded Level Set Method (LGWe-LSM) is introduced for surface and 
shape analysis which suppresses high-intensity regions that may pro­
create false positives. A 16-layer deep CNN for the detection of polyps in 
colonoscopy images has been projected by Rahim et al. [33]. They have 
introduced generalized intersection over union to deal with scale 
invariance issues. 
Deep neural networks are data-hungry and unfortunately, most of 
the publicly available WCE datasets are of a relatively small size as 
compared to the general category datasets on which deep learning 
models have shown remarkable performance. To overcome the problem 
of small datasets, the transfer learning approach has been used by many 
authors. Li et al. [44] have exploited the effectiveness of transfer 
learning for gastrointestinal bleeding detection on a small-size imbal­
anced endoscopy image dataset. Riberio et al. in Ref. [45] have 
considered pre-trained models AlexNet, VGGNet, and GoogLeNet on 
ImageNet and Pascal VOC datasets for the classification of colonic 
polyps. Shin et al. [46] have also utilized the transfer learning approach 
for the localization of polyps using Faster RCNN with Inception-Resnet 
(InceptionV4) [47]. In the method devised by Sadasivan et al. [28], a 
patch-based CNN is suggested where patches from normal and abnormal 
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 137 (2021) 104789
3
regions of WCE images are extracted and used for the localization of 
anomaly. The CNN is trained to classify the patches as normal or 
abnormal. Ghosh et al. [43] presented a two-stage system for bleeding 
detection and localization in WCE images. In the first stage, a CNN with 
AlexNet architecture is used to classify bleeding and non-bleeding 
(normal) frames. In the next stage, bleeding regions are segmented 
using VGG16 based SegNet [30]. AlexNet is an old architecture and 
several efficient CNN models have been tendered over the years that 
show significant improvement over AlexNet [48]. Further, in recent 
years, some CNN models with attention mechanisms have also been 
explored in different domains which were shown to help improve the 
prediction performance of the models. 
A review of the existing literature indicates that a handful number of 
generic methods have been presented to deal with multiple types of 
anomalies simultaneously. Further, deep CNN models used in the clas­
sification of anomalies have large memory footprints and demand high 
computational resources. In this paper, an attention-based CNN is pro­
posed which detects four different types of anomalies in WCE images. To 
locate the abnormal regions in identified images, a hybrid of two stan­
dard approaches is applied, namely, Grad-CAM++ [31] and SegNet 
[30]. The proposed method provides improved classification accuracy 
and localization results with higher precision levels compared to legacy 
methods. 
3. WCENet: an anomaly detection and localization model 
In this section, an automatic anomaly detection and localization 
model ‘WCENet’ is proposed for WCE images. Fig. 1 presents the sche­
matic diagram of the model that consists of (i) a base CNN model using 
an attention-based mechanism that classifies the images into four cate­
gories (ii) a custom SegNet [30] model for semantic segmentation of 
abnormal regions in images (iii) a supporting mechanism to the seg­
mentation model using Grad-CAM++ [31] applied on the trained clas­
sification model. 
The 11-layer attention-based CNN model is trained on a WCE image 
dataset to classify images into four categories namely, inflammatory, 
polyp, vascular, and normal. The attention mechanism focuses on 
dominant features and suppresses the insignificant ones. All images that 
are classified as abnormal by the CNN model are then passed onto the 
localization framework which consists of two parallel mechanisms (i) a 
SegNet based [30] CNN model that is trained to segment the pixels 
falling in the abnormal region of an image, and (ii) analysis of the class 
activation maps of the images using Grad-CAM++ [31] applied on the 
trained WCENet. The set of pixels that are identified by both methods as 
abnormal are finally selected for the localization of the anomaly in the 
image. Details of SegNet and Grad-CAM++ are given in Section 3.2. 
3.1. The classification network 
The classification model of WCENet is a CNN with an attention 
mechanism having 7 convolution (Conv) blocks and 4 fully connected 
(FC) blocks as shown in Fig. 2. A Conv block consists of a Conv layer 
followed by a batch normalization + ReLU layer that fends off the model 
from overfitting. The Conv blocks are grouped into 4 modules. The first 
module consists of two Conv blocks, with 32 filters, each of size 3 × 3 in 
both the Conv layers. Max-pooling is applied at the output of the second 
Conv block and then an attention block is added. The second and the 
third modules have an identical structure except for the number of fil­
ters. There are 64 filters in each of the Conv layers in the second module 
and 128 filters in the Conv layers of the third module. The fourth module 
has only one Conv block followed by max-pooling. Since the anomalies 
in the WCE images can be present at the boundaries also, the role of 
boundary pixels is crucial. Therefore, ‘SAME’ padding is used in the 
convolution operation throughout the Conv layers. As depicted in Fig. 2, 
an attention block is added after each of the first three Conv modules. 
The attention mechanism is induced from the concept of a convolution 
block attention module (CBAM) [49] which is briefly discussed in Sec­
tion 3.1.1, the output of the fourth module goes to the global average 
pooling (GAP) layer. GAP layer contributes to limit the computation of 
Fig. 1. Schematic block diagram of proposed WCENet.  
Fig. 2. Schematic block diagram of WCENet classifier.  
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 137 (2021) 104789
4
parameters as compared to the flatten layer to make the network learn 
faster. Then four FC layers are added to the tail of the network with 128, 
64, 32, and 4 units, the last layer is the (output) classification layer. The 
first three FC layers are coupled with batch normalization and ReLU 
activation whereas the output layer uses softmax activation. Input to the 
WCENet is a 3-channel, 24-bit RGB image of size 320 × 320. 
3.1.1. Convolution block attention module 
The CBAM [49] is a lightweight and generalized attention module 
that can be integrated easily with any CNN. CBAM derives attention 
maps from channels and spatial dimensions of intermediate feature 
maps. To understand how the attention mechanism works, consider an 
intermediate feature map M ∈RC×I×J, where C denotes the number of 
channels in M and I × J is the feature dimension. CBAM extracts 1-D 
channel attention map Ac ∈RC×1×1 and a 2-D attention map As ∈
R1×I×J as shown in Fig. 3. The final feature map with attention is 
computed with the following series of operations: 
M
′ = Ac(M) ⊗M,
(1)  
M′′ = As(M
′) ⊗M
′,
(2) 
where the symbol ⊗denotes the element-wise multiplication of two 
matrices. Here, M′′ is the final feature map with the attention that can be 
considered as the refined output. The channel attention module targets 
‘which’ information inside the image is meaningful whereas the spatial 
attention module focuses on ‘where’ the meaningful information is 
located in the image. To compute the channel attention, the spatial di­
mensions are squeezed by aggregating the spatial information using 
max-pooling and average-pooling. These two spatial context feature 
descriptors Mc
avg and Mc
max are then forwarded to a single hidden layer 
fully connected NN (FC-NN) to produce Ac ∈RC×1×1. The hidden acti­
vation can be fixed to a size of RC/n×1×1 where the size can be reduced by 
n. Each descriptor is passed through the shared FC-NN and the outputs of 
both the descriptors are added element-wise to get Ac which is then 
multiplied to each element of M along the channel axis to get M′ as given 
in Eq. (1). Next, the spatial attention is computed on M′ by max-pooling 
and average-pooling feature maps at each pixel location across all the 
channels producing Ms
avg and Ms
max ∈R1×I×J. Convolution operation 
with filters of size f is then performed on the two-channel feature 
descriptor formed after concatenation of Ms
avg and Ms
max to produce 
As ∈R1×I×J. Finally, element-wise multiplication of As is performed on 
each channel C of M
′ ∈RC×I×J to produce a refined feature map M′′ as 
given in Eq. (2). In this way, a CBAM can be easily applied to the output 
of any intermediate layer of a CNN. 
3.2. Anomaly localization framework 
In the second stage of WCENet, an abnormal image (labeled as 
abnormal after classification) is analyzed further for the localization of 
anomalies. The localization is achieved through a hybrid approach using 
two standard localization methods namely SegNet [30] and 
Grad-CAM++ [31]. SegNet is a deep encoder-decoder architecture that 
provides pixel-wise segmentation of an image. In the present paper, a 
custom CNN is used in the encoder and the decoder parts of SegNet. The 
second method is Grad-CAM++ which uses the trained WCENet classi­
fier network and generates the class activation maps that highlight the 
salient region in an input image. The outputs of both the methods are 
then fused to get the segmented region in the WCE image for the 
Fig. 3. Schematic block diagram of CBAM attention sub-modules.  
Fig. 4. A flow diagram of localization framework in WCENet.  
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 137 (2021) 104789
5
localization of the anomaly in an image. The localization framework is 
presented in Fig. 4. 
3.2.1. SegNet architecture 
Gastrointestinal (GI) anomalies differ in their visual appearances. 
They exhibit irregular shapes, different colors, and textures which make 
them difficult to locate in an image by computer vision techniques. Pixel 
level segmentation can be useful for identifying such anomalous regions. 
In this paper, a customized CNN-based segmentation model inspired by 
the idea of SegNet [30] is proposed. The segmentation model trained on 
a WCE dataset can differentiate the pixels belonging to an abnormal or a 
normal region in an image. As mentioned earlier, the SegNet architec­
ture consists of an encoder and decoder network which can be a CNN or 
FC-NN followed by a final pixel-wise classification layer. 
SegNet model developed in the proposed work is shown in Fig. 5. In 
this network, depthwise separable convolutions (DSC) are used for the 
extraction of features. DSC makes the model lightweight by drastically 
reducing computations and model size. Both the encoder and the 
decoder are composed of 8 depthwise separable convolutions (DSC) 
layers. Each DSC layer is followed by the batch normalization layer and 
a ReLU activation layer. The DSC layer is configured with 3 × 3 filters 
and a stride = 1. Further, a 2 × 2 max-pooling layer with stride = 2 is 
used in the network. All the DSC layers are followed by batch normali­
zation and ReLU layers. The decoder is a mirror network configured with 
upsampling layers in place of max-pooling layers. Here, the upsampling 
is performed as in the original SegNet. Since the max-pooling operation 
in the encoder leads to the loss of the spatial resolution, SegNet stores 
the location of the maximum value for each feature map during the max- 
pooling operation as shown in Fig. 6. The green lines connecting the 
encoder-decoder layers in Fig. 5 show max-pooling indices shared by the 
encoder and decoder which are used during the upsampling operation. 
The decoder generates sparse-feature maps which are then convolved 
with the filter banks to densify them. The decoded output is passed 
through the softmax layer that generates a K−
channel image of the 
probability values at pixel locations where K is the number of classes. 
Finally, a segmented image is obtained where each segment corresponds 
to an anomaly class giving the maximum probability at each pixel. 
3.2.2. Grad-CAM++
In contrast to SegNet, which is trained explicitly on the datasets with 
ground-truths for pixel segmentation in an input image, Grad-CAM++
[31] works on a trained classifier, and builds a heatmap to identify the 
region of interest in an input image. Grad-CAM++ performs an analysis 
of the class activation maps (CAMs). Zhou et al. [50] suggested that 
various layers of a CNN can be exploited as object detectors using CAM if 
the GAP layer is utilized with the combination of weighted feature maps 
produced just before the softmax classification layer (penultimate 
Fig. 5. SegNet architecture for localization of anomaly in WCE images.  
Fig. 6. A SegNet decoder employing max-pooling indices during unpooling.  
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 137 (2021) 104789
6
layer). This method allows generating a heatmap that highlights the 
pixels in the image that have participated in assigning a particular class 
to the image. 
Let the penultimate layer produce L feature maps, Ml ∈Ru×v of size u 
× v. To apply the spatial GAP on these feature maps, the linear combi­
nation given in Eq. (3) is used to compute a score Sc for each class c. 
Sc =
∑
l
wc
l
⏞⏟⏟⏞class ​ weights 1
Q
∑
i
∑
j
⏟̅̅̅̅̅⏞⏞̅̅̅̅̅⏟
GAP
Ml
ij
⏞⏟⏟⏞feature ​ map
,
(3)  
where Q is the number of pixels in the activation map M. The class- 
specific localization map Lc at each location (i, j) is calculated using 
Eq. (4). 
Fig. 7. Some samples of images categorized in four classes where anomalies present in the abnormal class are located with the white circle.  
Table 1 
Description of the KID dataset (KID-I and KID-II combined).  
Class 
# Images in the dataset 
# Images after augmentation 
Inflammatory 
241 
1266 
Polyps 
50 
1293 
Vascular 
350 
1243 
Normal 
728 
1300  
Table 2 
Performance of WCENet with and without attention mechanism.  
WCENet 
Accuracy 
Precision 
Recall 
F1-score 
Without attention 
0.97 
0.96 
0.97 
0.97 
With attention 
0.98 
0.98 
0.98 
0.98  
Table 3 
Parametric configuration of six state-of-the-art CNN classification models and the proposed WCENet classifier.  
Author 
# CNN 
# Pooling 
# FC 
Hyperparameters 
# Trainable  
Layers 
Layers 
Layers 
(opt, lr, bs, ep) 
Parameters 
Sekuboyina et al. [27] 
3 
2 
3 
Adam, 0.01, 100, 100 
7,032 
Georgakopolous et al. [55] 
5 
2 
3 
SGD, 0.001, 100, 100 
115,486 
Sadasivan et al. [28] 
3 
2 
3 
Adam, 0.001, 64, 200 
7,032 
Jia et al. [9] 
3 
3 
2 
SGD, 0.01, 100, 200 
10,697,060 
Iakovidis et al. [11] 
5 
4 
3 
SGD, 0.001, 50, 200 
286,344 
Ghosh et al. [43] 
5 
3 
3 
SGD, 0.01, 16, 200 
528,078,924 
Proposed WCENet 
7 
4 
4 
SGD, 0.001, 16, 200 
656,010  
Table 4 
Parametric configuration of the ML classification methods compared with 
WCENet classifier.  
Author 
Method 
Feature 
Length 
ML 
classifier 
Hyperparameters 
Yuan et al. 
[40] 
SIFT +
CLBP 
120 
SVM 
Cubic SVM kernel 
Ghosh et al. 
[38] 
CHOBS 
4096 
KNN 
K = 1 
Jain et al. 
[18] 
DBC (FD) 
2025 
RF 
# Estimators =
500  
Table 5 
Classification performance of nine state-of-the-art techniques and WCENet with 
5-fold cross validation.  
Method 
Accuracy 
Precision 
Recall 
f1- 
score 
AUC 
Sekuboyina et al. [27] 
0.53 
0.51 
0.98 
0.67 
0.52 
Georgakopoulos et al.(patch 
CNN) [55] 
0.58 
0.55 
0.96 
0.70 
0.57 
Sadasivan et al. [28] 
0.57 
0.54 
0.99 
0.71 
0.59 
Jia et al. [9] 
0.90 
0.92 
0.85 
0.87 
0.85 
Iakovidis et al. [11]. 
0.92 
0.95 
0.91 
0.93 
0.94 
Ghosh et al. [38] 
0.72 
0.70 
0.73 
0.72 
0.74 
Yuan et al. [40] 
0.82 
0.79 
0.85 
0.82 
0.83 
Jain et al. [18] 
0.83 
0.85 
0.84 
0.84 
0.84 
Ghosh et al. [43] 
0.94 
0.96 
0.94 
0.94 
0.95 
WCENet 
0.98 
0.98 
0.98 
0.98 
0.99  
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 137 (2021) 104789
7
Lc
i,j =
∑
l
wc
l ⋅Ml
ij
(4) 
Note that the CAMs help visualizing the outputs of the last convo­
lution layer only, which is a limitation. Also, the process involves 
training the linear classifier for each class. These issues were addressed 
in a method known as Grad-CAM introduced by Selvaraju et al. [51]. 
Instead of training multiple classifiers for the class-specific weight 
computation, the weights wc
l for a specific activation map Ml and the 
class c are computed using Eq. (5). 
wc
l = Q⋅∂Sc
∂Ml
ij
⏟̅̅̅⏞⏞̅̅̅⏟
gradients
∀i, j
(5) 
The above formulation computes the weights wc
l independent of the 
spatial locations (i, j) of a specific activation map Ml. The limitation of 
CAM is overcome by taking the GAP of the partial derivatives ∂Ml
ij. 
Therefore, the weights wc
l are computed using Eq. (6). 
wc
l = 1
Q
∑
i
∑
j
∂Sc
∂Ml
ij
(6) 
Grad-CAM’s performance deteriorates when there are multiple in­
stances of the same object in an image. This is quite common in WCE 
images where anomalies can be present at different locations in the same 
image. Further, the localization through Grad-CAM is observed to miss 
some portion of the region of interest, probably due to the unweighted 
average of partial derivatives. Grad-CAM++ introduced by Chatto­
padhyay et al. [31] overcomes this issue by modifying Eq. (6) as follows. 
wc
l =
∑
i
∑
j
βlc
ij
⏟⏞⏞⏟
gradient ​ weights
ReLU
(
∂Sc
∂Ml
ij
)
(7) 
The main idea behind the above formula is that wc
l apprehends the 
significance of a particular activation map Ml. For a given activation 
map Ml, the positive gradient at location (i, j) makes the class score S 
stronger with increasing pixel values. Therefore, the linear combination 
of partial derivatives over each pixel in an activation map Ml will show 
the relevance of that map for class C. The formulation in Eq. (6), com­
putes the weighted average of gradients wc
l in contrast to the GAP per­
formed using Eq. (7). The class score Sc is computed using Eq. (8) which 
Fig. 8. ROC curves of WCENet.  
Table 6 
Performance comparison of segmentation models with different base 
architectures.  
Method 
Encoder Architecture 
FwIoU 
MIou 
Dc 
SegNet 
VGG16 
0.79 
0.60 
0.48 
SegNet 
ResNet50 
0.80 
0.60 
0.51 
SegNet 
MobileNetV1 
0.81 
0.61 
0.55 
SegNet 
Custom CNN 
0.81 
0.60 
0.55 
UNet 
VGG16 
0.77 
0.50 
0.45 
UNet 
ResNet50 
0.78 
0.53 
0.46 
UNet 
MobileNetv1 
0.79 
0.56 
0.48 
UNet 
Custom CNN 
0.79 
0.56 
0.48 
PSPNet 
VGG16 
0.74 
0.44 
0.39 
PSPNet 
ResNet50 
0.77 
0.51 
0.45 
PSPNet 
MobileNetv1 
0.79 
0.49 
0.47 
PSPNet 
Custom CNN 
0.78 
0.49 
0.48  
Fig. 9. (a,d) Original WCE image with anomalies. (b,e) Corresponding ground truths of WCE images. (c,f) Segmentation results produced by SegNet model.  
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 137 (2021) 104789
8
is derived by combining Eqs. (3) and (7). 
Sc =
∑
l
[∑
i
∑
j
{∑
a
∑
b
βlc
abReLU
( ∂Sc
∂Ml
ab
) }
Ml
ij
]
(8) 
In Eq. (8), the iterators (i, j) and (a, b) are identical and iterate over 
entire activation map Ml. Since ReLU is a threshold function that allows 
the gradients to flow-back, we can drop it. Therefore, by taking partial 
derivative on both the sides of Eq. (8), for a specific class c, an activation 
map l, and the class score Sc, the gradient weights βlc
ij are computed using 
Eq. (9). 
Fig. 10. (a,d) Original WCE image with anomalies. (b,e) Corresponding ground truths of WCE images. (c,f) Heatmaps through GradCAM++ applied on trained 
WCENet classifier. 
Fig. 11. Some sample segmentation results of Grad-CAM++ using different threshold values.  
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 137 (2021) 104789
9
βlc
ij =
∂2Sc
(∂Ml
i,j)
2
2⋅
∂2Sc
(∂Ml
i,j)
2 + ∑
a
∑
b
Ml
ab
⎧
⎪
⎨
⎪
⎩
∂3Sc
(∂Ml
i,j)
3
⎫
⎪
⎬
⎪
⎭
(9) 
The class-wise saliency maps for a given image I are calculated as the 
linear combinations of forward activation maps. Each spatial element in 
the saliency map Lc is then computed using Eq. (10). 
Lc
ij = ReLU
(∑
l
wc
l ⋅Ml
ij
)
(10) 
The localization result obtained using Grad-CAM++ is combined 
with the result of SegNet to get the final segmented image. Pixelwise 
AND operation is performed to compute the final segmented region of an 
anomaly in a given input image. 
4. Experimental results and discussion 
In the present section, the performance of the WCENet anomaly 
detection and localization model is evaluated on the publicly available 
KID [52] dataset. The model’s performance is also compared with some 
state-of-the-art methods that are relevant to the present work. All the 
experiments are performed on an Intel Xeon processor with 64 GB RAM 
and 8 GB Nvidia Quadro P4000 GPU. Keras API 2.1.3 is used with 
Tensorflow 2.2 as the backend to code the proposed model and all the 
ML and DL algorithms used in the comparison. 
4.1. Dataset 
Experiments are performed on the KID dataset [52] which consists of 
two subsets KID-I [17] and KID-II [11]. The KID-I contains 77 images of 
various classes of anomalies like angiectasia (27), lymphangiectasia (9), 
polyps (6), ulcers (9), bleeding (5), stenoses (6), aphthae (5), chylous 
cysts (8). The KID dataset-II contains images with anomalies of three 
classes that are polyp (44), vascular (303) and, inflammatory lesion 
(227), and normal images from different parts of the GI tract like 
esophagus (282), stomach (599), small bowel (728) and colon (169). 
The anomaly classes in the KID-I can also be broadly categorized into 
one of the classes in the KID-II. The abnormal images belonging to 
angiectasia, lymphangiectasia, bleeding, and stenoses are mapped to the 
vascular class whereas aphthae and ulcer images are grouped into the 
inflammatory class. After the categorization of images in the KID-I, they 
are merged with the KID-II. Images of the size 360 × 360 × 3 are 
captured using a MicroCam capsule endoscope (IntroMedic Co, Seoul, 
Korea). 
The anomalies belonging to different classes have variations in 
texture and color as depicted in Fig. 7. The inflammatory class 
commonly referred to as inflammatory bowel disease (IBD) can be 
characterized by chronic inflammation in the intestinal walls. It can be a 
wound-like structure swollen up, sometimes turning red in color. Ulcers 
are common in IBDs, which appear like a wound with pale yellow or red 
color. A polyp is another kind of GI disease that is formed on the lining of 
the colon that looks like a blob of cells. It is formed due to its unregulated 
growth. In most cases, polyps have a color similar to the intestinal walls 
but their structure differentiates them from the normal regions. In the GI 
tract, there can be syndromes with abnormalities in mucosal and sub­
mucosal vessels. These vessels may cause bleeding and can be referred to 
as a vascular anomaly. 
The proposed model is trained and tested on the merged KID dataset. 
The original images in the dataset are of the size 360 × 360 with black 
borders. In pre-processing steps, the borders are removed and the final 
images are of size 320 × 320. Sometimes the light source of the capsule 
gets obstructed by some clinical events [53] resulting in poor quality of 
frames. To deal with this problem, the contrast limited adaptive histo­
gram equalization (CLAHE) method is used for image contrast 
enhancement [54]. Since the dataset is imbalanced with the majority of 
normal images, augmentation is also performed by applying random 
geometric transformations like rotation between −20 to + 20◦, zooming 
with a factor of 0.2, horizontal and vertical flips. In addition, random 
Gaussian noise is used for data augmentation. The number of images in 
each class before and after augmentations is listed in Table 1. A ratio of 
4: 1 is taken for splitting the dataset into training and testing sets. 
4.2. Performance of WCENet 
The proposed WCENet is trained to classify the WCE images into one 
of the four classes that are inflammatory, polyp, vascular, and normal as 
discussed in the previous section. The WCENet classifier is trained using 
the categorical cross-entropy loss with a learning rate of 0.001, the 
number of epochs = 200, and Adam optimizer with momentum = 0.9. 
The performance of the model is tested with and without an attention 
mechanism and it is found that the attention mechanism provides 
slightly better results (Table 2). 
4.3. Comparative analysis of WCENet 
This section provides the experimental results to analyze and 
compare the performance of WCENet with nine different schemes 
introduced in Refs. [9,11,18,27,28,38,40,43] and, [55]. Methods 
involving handcrafted features for the classification of WCE images as 
well as deep learning techniques are considered for comparative 
analysis.  
1) Deep learning-based methods: WCENet is compared with six 
different CNN-based classifiers introduced in Refs. [9,11,27,28,43] 
and [55] (Table 5). These include patch-based CNN models intro­
duced in Refs. [27,28,55] and CNN models that work on full images 
[9,11,43]. In the patch-based schemes, an image patch is defined to 
be abnormal if most of its pixels fall in the abnormal region and 
normal otherwise. For a fair comparison of the performance of 
WCENet with the patch-based methods, even if the single patch in 
the image is identified as abnormal then the whole image is 
Table 7 
Grad-CAM++ segmentation performance with different threshold values.  
Threshold 
FwIoU 
MIou 
Dc 
0.1 
0.73 
0.47 
0.41 
0.2 
0.73 
0.48 
0.43 
0.3 
0.75 
0.53 
0.45 
0.4 
0.75 
0.54 
0.46 
0.5 
0.76 
0.55 
0.47 
0.6 
0.74 
0.54 
0.46 
0.7 
0.74 
0.54 
0.46 
0.8 
0.72 
0.54 
0.45 
0.9 
0.72 
0.54 
0.44  
Table 8 
Localization performance comparison by taking union and intersection of seg­
mentation masks produced by Grad-CAM++ (M1) and SegNet (M2).   
M1⋃M2 
M1 ∩M2 
Threshold 
FwIoU 
MIou 
Dc 
FwIoU 
MIou 
Dc 
0.1 
0.70 
0.48 
0.41 
0.83 
0.59 
0.56 
0.2 
0.72 
0.48 
0.44 
0.81 
0.59 
0.55 
0.3 
0.72 
0.49 
0.46 
0.79 
0.57 
0.55 
0.4 
0.73 
0.49 
0.48 
0.78 
0.55 
0.54 
0.5 
0.74 
0.50 
0.50 
0.77 
0.55 
0.54 
0.6 
0.74 
0.50 
0.50 
0.76 
0.55 
0.53 
0.7 
0.74 
0.52 
0.51 
0.76 
0.55 
0.52 
0.8 
0.75 
0.55 
0.51 
0.74 
0.52 
0.50 
0.9 
0.75 
0.55 
0.52 
0.69 
0.47 
0.40  
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 137 (2021) 104789
10
considered as abnormal. The CNN model in Ref. [55] is trained on 
RGB color image patches, whereas a−channel of CIE-Lab color space 
is used to train the models in Refs. [27,28]. Since the number of 
abnormal patches is less as compared to the normal patches, a 
balanced set is prepared for experiments with 5518 patches in each 
class (c.f [27,28,55]) and the patch size of 32 × 32 is taken for the 
experiment. Other than the patch-based models, the CNN architec­
tures in Refs. [9,11,43] work on the full image. The parametric 
configurations of the above six architectures and the proposed model 
are given in Table 3. 
2)Conventional ML methods: Three conventional ML methods are 
also compared with WCENet. The first method is by Yuan et al. [40] 
according to which a bag-of-features is computed making use of SIFT 
and LBP. Another method is the Color Histogram of Block Statistics 
(CHOBS) proposed by Ghosh et al. [38] in which some statistical 
values are calculated over the blocks extracted from the image and 
on which the color histograms are computed. The third method is by 
Jain et al. [18] that uses fractal features based on the differential 
box-counting method which are fed to the random forest classier. 
The parametric configurations of the above three ML techniques are 
listed in Table 4. 
All the experiments were performed on the merged KID dataset with 
augmentation mentioned in Section 4.1. Since the number of training 
and testing samples is quite limited, a 5-fold cross-validation is applied 
on WCENet as well as on all the methods used in the comparative 
analysis. Results in Table 5 demonstrate that WCENet yields 98% ac­
curacy. Ghosh et al. [43] have employed transfer learning on AlexNet 
CNN architecture and the classification accuracy of their model is 96%. 
In patch-based methods, since an image is divided into patches, it may 
happen the normal region in a patch dominates the abnormal region, 
and hence the patch might be categorized as normal. This might be a 
reason for the lower performance of patch-based CNNs given in Refs. 
[27,55]. Moreover, the CNN proposed by Jia et al. [22] has fewer 
convolution layers with a small number of filters that might be the 
reason for its lower performance with 82% accuracy. We anticipate that 
the features used in Refs. [18,38,40], have their limitations in identifi­
cation of a wide range of anomalies in the dataset with different colors, 
textures, shapes. This could be the reason for the relatively lower per­
formance of these methods. Along with the accuracy and F1-score, the 
area under the receiver operating characteristic curve abbreviated as 
AUC is also analyzed. It can be drawn from Table 5 that WCENet per­
forms better than the other state-of-the-art methods with the highest 
Fig. 12. Localization results produced by taking the union and intersection of segmentation masks produced by GradCAM++(M1) and SegNet(M2).  
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 137 (2021) 104789
11
accuracy and AUC score as 98% and 99% respectively. The plots of the 
ROC curves are shown in Fig. 8. 
4.4. Experimental results on anomaly localization 
The anomaly localization framework explained in Section 3.2 is a 
hybrid of two methods: a custom SegNet model with an 8−layer CNN 
encoder-decoder structure and GradCAM++ using the trained WCENet 
classifier. The selection of the CNN architecture in SegNet [30] is based 
on the experimental analysis with two popular segmentation models 
UNet [56] and PSPNet [57]. All these models use a base CNN archi­
tecture. To analyze the performance of segmentation models with 
respect to the base architecture, three popular CNN models are taken to 
constitute the base model in UNet, PSPNet, and SegNet. These base 
models are ResNet50 [58], VGG16 [59], and MobileNetV1 [60]. Apart 
from this, an 8-layer custom encoder-decoder model is also used for 
performance evaluation represented in Fig. 5. Three popular metrics are 
used for comparison namely mean IoU (MIoU), frequency weighted 
intersection over union (FWIoU), and Dice coefficient (Dc). MIoU and 
FWIoU can be calculated with the help of Eqs. (11) and (12). 
MIoU = 1
N⋅
∑
jnjj
Lj + ∑
knkj −njj
,
(11)  
FwIoU =
1
∑
sLs
⋅
∑
j
Lj ∗njj
Lj + ∑
k
nkj −njj
,
(12)  
where N is the total number of classes, and nkj is the total number of 
pixels in the class j identified by the method, but originally belonging to 
the class k. Further, Lj is the total number of pixels belonging to class j in 
the ground truth. The dice coefficient is somewhat similar to the F1 score 
used in the classification. It is computed as the ratio of two times the area 
of intersection between the ground truth and the predicted segmentation 
to the union of the ground truth and predicted segmentation areas. Let G 
Fig. 13. Segmentation performance of the proposed method and some state-of-the-art bleeding segmentation methods.  
Table 9 
Performance of WCENet localization on CVC-CLINIC dataset.  
WCENet Model 
IoU 
FwIoU 
Dc 
Trained with KID dataset 
0.48 
0.78 
0.32 
Exclusively trained with CVC-CLINIC 
0.90 
0.96 
0.89  
Fig. 14. Segmentation results of SegNet trained on CVC-CLINIC dataset. (a,d). Polyp images in CVC-CLINIC dataset. (b,e) Corresponding ground truths. (c,f) Seg­
mentation results by SegNet. 
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 137 (2021) 104789
12
be the area of the ground truth and S be the segmented area, then Dc is 
calculated using Eq. (13). 
Dc = 2 ×
G ∩S
|G| + |S|
(13) 
The segmentation models considered in this study are trained on the 
same augmented KID dataset, used in the classification stage. All the 
models are trained for 200 epochs with a categorical cross-entropy loss 
function. Stochastic gradient descent (SGD) with momentum is used for 
optimization with the momentum = 0.9 and the learning rate of 0.01. 
To find out the best combination of the segmentation model with the 
appropriate encoder architecture, an empirical study is performed. All 
the models are trained and evaluated on the augmented KID dataset. The 
results are recorded in Table 6, which show that the SegNet model with 
the custom CNN produces better results as compared to other base ar­
chitectures with the highest FwIoU of 0.81 as compared to the other 
encoding architectures. Some of the sample WCE images, their corre­
sponding ground truths, and the segmented regions by the proposed 
SegNet model are shown in Fig. 9. Although the performance of SegNet 
with MobileNetV1 is close to SegNet with the custom CNN, we have 
adopted to use custom CNN due to its lightweight architecture with 8 
layers as compared to MobileNetV1 which consists of 13 layers. 
The automatic segmentation of WCE images is also performed using 
GradCAM++ as described in Section 3.2.2. The trained WCENet is uti­
lized for the generation of heatmaps. Some heatmap visualizations are 
plotted in Fig. 10. The heatmaps are also evaluated on segmentation of 
anomalies and the qualitative results are shown in Fig. 11. The quanti­
tative results are also reported in Table 7. The colors in the heatmap 
represent different confidence scores calculated by GradCAM++
through the computation of gradients which can be determined using 
Eq. (10). The red color signifies the highest confidence of an anomalous 
region whereas the blue region indicates the normal region. The class C 
of an image I is identified by referring to the result of the WCENet 
classifier on the image. 
It can be deduced from the individual segmentation results produced 
by both the techniques discussed above individually that the SegNet 
Fig. 15. Quantitative segmentation results of WCENet localization method on 
both KID and CVC-CLINIC datasets. 
Fig. 16. Failed segmentation results (M1 ∩M2) and alternative results by computing union (M1 ∪M2) of segmentation masks produced by Grad-CAM++ (M1) and 
SegNet (M2). 
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 137 (2021) 104789
13
(M2) technique performs better with a Dc score of 0.55 as compared to 
Grad-CAM++ (M1) with a Dc score of 0.47. The segmentation results are 
also computed through the fusion of segmentation masks produced by 
both the methods. Intersection and union of segmentation masks of both 
the methods are analyzed as shown in Table 8. It can be seen that the 
intersection of M1 and M2 produces a Dc score of 0.56 which is slightly 
better than individual Dc scores of both M1 and M2. Few examples of the 
localization results are shown in Fig. 12 for a qualitative comparison. 
The localization performance of the proposed model is compared 
with some state-of-the-art methods. Ghosh et al. [43] have recently re­
ported bleeding segmentation using SegNet [30]. Yuan et al. [32] have 
suggested a saliency map extraction method in two stages for high­
lighting bleeding regions, where different color channels are blended in 
the first stage and a saliency map is obtained in the second stage from 
the visual contrast by using CIE-Lab and HSV color spaces. Kundu et al. 
[61] have suggested extracting the bleeding region using inter-plane 
intensity variation on R–B and R-G planes in the normalized RGB 
color space. Patch-based CNN is exploited in Ref. [28] where the CNN is 
trained on normal and abnormal patches. Jia et al. [62] have highlighted 
bleeding regions by training a fully connected neural network. The re­
sults are reported in Fig. 13. Since all these methods are focused on 
detecting bleeding regions, for a fair comparison of the proposed seg­
mentation method with these methods, only those images are consid­
ered that belong to a vascular class of anomaly. It is found that the 
results obtained by the proposed method are better than other 
state-of-the-art methods with the highest FwIoU of 0.87. 
To validate the performance of the proposed model trained on the 
KID dataset [52], it is also tested on another publicly available colo­
noscopy dataset known as CVC-CLINIC [63]. CVC-CLINIC dataset con­
sists of only polyp frames extracted from the colonoscopy videos. These 
frames cover a wide variety of polyps. Along with the frames, the dataset 
also provides ground truths. The dataset contains 612 images taken from 
29 different video sequences. Since CVC-CLINIC contains only polyp 
images, the WCENet classifier could not be trained on the dataset. 
Therefore, we have tested the performance of the trained WCENet 
classifier on CVC-CLINIC. It is observed that the WCENet classifier 
correctly labels 484 frames out of 612 frames as a polyp. The localization 
capability of the trained WCENet is also tested on the CVC-CLINIC 
dataset. Further, the custom SegNet model is separately trained on the 
CVC-CLINIC dataset, and the quantitative results are listed in Table 9. 
The qualitative results are also shown in Fig. 14. The performance of 
WCENet on both the datasets augmented KID and CVC-CLINIC is visu­
alized in Fig. 15. 
The proposed WCENet performs better in comparison to other 
methods, but there are situations where the proposed method fails to 
localize the anomaly. As mentioned earlier, the intersection of the out­
puts by Grad-CAM++ (M1) and SegNet (M2) is taken as the final output 
mask for producing the segmented output. The localization results are 
quite close to the results produced by SegNet independently. Therefore, 
SegNet individually can be adopted for localization. But there are cases 
when SegNet fails to generate the mask. In those cases, we can use the 
localization mask generated through Grad-CAM++. Also, there can be 
situations where both the methods generate non-overlapping masks. In 
such situations, the union of the masks produced by M1 and M2 may 
probably help a physician in approximating the probable anomaly re­
gions. In this way, system failure can be minimized. In Fig. 16 some of 
these cases are demonstrated. 
5. Conclusion 
In the present paper, a deep CNN model WCENet is proposed for the 
identification and localization of GI anomalies in WCE images. The 
model operates in two phases. In the first phase, an input image is passed 
through an attention-based CNN classifier with 11-layers which clas­
sifies the image into one of the four categories namely, inflammatory, 
polyp, vascular, or normal. If the image is tagged as abnormal, it is 
passed to the second phase for estimating the anomalous region. 
Localization network SegNet is supplemented with Grad-CAM++ to 
produce the localization results. Combining the outcomes of two 
different localization techniques adds to the reliability of the model. 
Anomaly localization is the prime requirement for CAD systems in the 
current scenario of emerging digital healthcare. The proposed model can 
be applied for the identification and localization of a wide range of 
anomalies in WCE images. Due to the scarcity of publicly available 
labeled datasets, experiments are performed only on two datasets, KID 
[52] and CVC-CLINIC [63]. Comprehensive comparison results with 
existing approaches demonstrate that the proposed method outperforms 
other state-of-the-art methods. Although our proposed approach WCE­
Net performs better than legacy methods, there is a room to improve the 
localization performance in terms of dice score. As future work, more 
datasets will be considered to yield generalizable results. 
Declaration of competing interest 
The authors declare no conflict of interest. 
Acknowledgment 
This work is partially supported by the project “Prediction of diseases 
through computer assisted diagnosis system using images captured by 
minimally-invasive and non-invasive modalities”, Computer Science 
and Engineering, PDPM Indian Institute of Information Technology, 
Design and Manufacturing, Jabalpur India (under ID: SPARC-MHRD- 
231). This work is also partially supported by the project IT4Neuro 
(degeneration), reg. nr. CZ.02.1.01/0.0/0.0/18 069/0010054 and by 
the project “Smart Solutions in Ubiquitous Computing Environments”, 
Grant Agency of Excellence, University of Hradec Kralove, Faculty of 
Informatics and Management, Czech Republic (under ID: UHK-FIM-GE- 
2021). 
References 
[1] J. Dolz, N. Betrouni, M. Quidet, D. Kharroubi, H.A. Leroy, N. Reyns, L. Massoptier, 
M. Vermandel, Stacking denoising auto-encoders in a deep network to segment the 
brainstem on mri in brain cancer patients: a clinical study, Comput. Med. Imag. 
Graph. 52 (2016) 8–18. 
[2] M. Habibzadeh, M. Jannesari, Z. Rezaei, H. Baharvand, M. Totonchi, Automatic 
white blood cell classification using pre-trained deep learning models: resnet and 
inception, in: Tenth International Conference on Machine Vision (ICMV 2017), vol. 
10696, International Society for Optics and Photonics, 2018, 1069612. 
[3] T. Rahim, M.A. Usman, S.Y. Shin, A survey on contemporary computer-aided 
tumor, polyp, and ulcer detection methods in wireless capsule endoscopy imaging, 
Comput. Med. Imag. Graph. 85 (2020), 101767. 
[4] D. Banik, K. Roy, D. Bhattacharjee, M. Nasipuri, O. Krejcar, Polyp-net: a 
multimodel fusion network for polyp segmentation, IEEE Transactions on 
Instrumentation and Measurement 70 (2021) 1–12. 
[5] B. Li, M.Q.-H. Meng, J.Y. Lau, Computer-aided small bowel tumor detection for 
capsule endoscopy, Artif. Intell. Med. 52 (1) (2011) 11–16. 
[6] A. Karargyris, N. Bourbakis, Wireless capsule endoscopy and endoscopic imaging: a 
survey on various methodologies presented, IEEE Eng. Med. Biol. Mag. 29 (1) 
(2010) 72–83. 
[7] G. Iddan, G. Meron, A. Glukhovsky, P. Swain, Wireless capsule endoscopy, Nature 
405 (6785) (2000), 417–417. 
[8] Y. Yuan, J. Wang, B. Li, M.Q.-H. Meng, Saliency based ulcer detection for wireless 
capsule endoscopy diagnosis, IEEE Trans. Med. Imag. 34 (10) (2015) 2046–2057. 
[9] X. Jia, M.Q.-H. Meng, A deep convolutional neural network for bleeding detection 
in wireless capsule endoscopy images, in: 2016 38th Annual International 
Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), IEEE, 
2016, pp. 639–642. 
[10] Y. Yuan, M.Q.-H. Meng, Deep learning for polyp recognition in wireless capsule 
endoscopy images, Med. Phys. 44 (4) (2017) 1379–1389. 
[11] D.K. Iakovidis, S.V. Georgakopoulos, M. Vasilakakis, A. Koulaouzidis, V. 
P. Plagianakos, Detecting and locating gastrointestinal anomalies using deep 
learning and iterative cluster unification, IEEE Trans. Med. Imag. 37 (10) (2018) 
2196–2210. 
[12] A. Novoz´amskỳ, J. Flusser, I. Tachecí, L. Sulík, J. Bureˇs, O. Krejcar, Automatic 
blood detection in capsule endoscopy video, J. Biomed. Opt. 21 (12) (2016), 
126007. 
[13] G. Lv, G. Yan, Z. Wang, Bleeding detection in wireless capsule endoscopy images 
based on color invariants and spatial pyramids using support vector machines, in: 
S. Jain et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 137 (2021) 104789
14
2011 Annual International Conference of the IEEE Engineering in Medicine and 
Biology Society, IEEE, 2011, pp. 6643–6646. 
[14] S.A. Karkanis, D.K. Iakovidis, D. Karras, D. Maroulis, Detection of lesions in 
endoscopic video using textural descriptors on wavelet domain supported by 
artificial neural network architectures, in: Proceedings 2001 International 
Conference on Image Processing (Cat. No. 01CH37205) vol. 2, IEEE, 2001, 
pp. 833–836. 
[15] D. Bhattacharjee, A. Seal, S. Ganguly, M. Nasipuri, D.K. Basu, A comparative study 
of human thermal face recognition based on haar wavelet transform and local 
binary pattern, Comput. Intell. Neurosci. 2012 (2012), https://doi.org/10.1155/ 
2012/261089. Article ID 261089. 
[16] C. Sindhu, V. Valsan, A novel method for automatic detection of inflammatory 
bowel diseases in wireless capsule endoscopy images, in: 2017 Fourth International 
Conference on Signal Processing, Communication and Networking (ICSCN), IEEE, 
2017, pp. 1–6. 
[17] D.K. Iakovidis, A. Koulaouzidis, Automatic lesion detection in wireless capsule 
endoscopy—a simple solution for a complex problem, in: 2014 IEEE International 
Conference on Image Processing (ICIP), IEEE, 2014, pp. 2236–2240. 
[18] S. Jain, A. Seal, A. Ojha, O. Krejcar, J. Bureˇs, I. Tachecí, A. Yazidi, Detection of 
abnormality in wireless capsule endoscopy images using fractal features, Comput. 
Biol. Med. 127 (2020), 104094. 
[19] J.-Y. He, X. Wu, Y.-G. Jiang, Q. Peng, R. Jain, Hookworm detection in wireless 
capsule endoscopy images with deep learning, IEEE Trans. Image Process. 27 (5) 
(2018) 2379–2392. 
[20] X. Xing, Y. Yuan, M.Q.-H. Meng, Zoom in lesions for better diagnosis: attention 
guided deformation network for wce image classification, IEEE Trans. Med. Imag. 
39 (2020) 4047–4059. 
[21] S. Jain, A. Seal, A. Ojha, Deep learning models for anomaly detection in wireless 
capsule endoscopy video frames: the transfer learning approach, in: Smart 
Computing: Proceedings of the 1st International Conference on Smart Machine 
Intelligence and Real-Time Computing (SmartCom 2020), 26-27 June 2020, Pauri, 
Garhwal, Uttarakhand, India,, CRC Press, 2021, p. 423. 
[22] X. Jia, M.Q.-H. Meng, Gastrointestinal bleeding detection in wireless capsule 
endoscopy images using handcrafted and cnn features, in: 2017 39th Annual 
International Conference of the IEEE Engineering in Medicine and Biology Society 
(EMBC), IEEE, 2017, pp. 3154–3157. 
[23] M.A. Khan, S. Kadry, M. Alhaisoni, Y. Nam, Y. Zhang, V. Rajinikanth, M.S. Sarfraz, 
Computer-aided gastrointestinal diseases analysis from wireless capsule 
endoscopy: a framework of best features selection, IEEE Access 8 (2020) 
132850–132859. 
[24] G. Litjens, T. Kooi, B.E. Bejnordi, A.A.A. Setio, F. Ciompi, M. Ghafoorian, J.A. Van 
Der Laak, B. Van Ginneken, C.I. S´anchez, A survey on deep learning in medical 
image analysis, Med. Image Anal. 42 (2017) 60–88. 
[25] M.I. Razzak, S. Naz, A. Zaib, Deep learning for medical image processing: 
overview, challenges and the future, in: Classification in BioApps, Springer, 2018, 
pp. 323–350. 
[26] H.-C. Shin, H.R. Roth, M. Gao, L. Lu, Z. Xu, I. Nogues, J. Yao, D. Mollura, R. 
M. Summers, Deep convolutional neural networks for computer-aided detection: 
cnn architectures, dataset characteristics and transfer learning, IEEE Trans. Med. 
Imag. 35 (5) (2016) 1285–1298. 
[27] A.K. Sekuboyina, S.T. Devarakonda, C.S. Seelamantula, A convolutional neural 
network approach for abnormality detection in wireless capsule endoscopy, in: 
2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017), 
IEEE, 2017, pp. 1057–1060. 
[28] V.S. Sadasivan, C.S. Seelamantula, High accuracy patch-level classification of 
wireless capsule endoscopy images using a convolutional neural network, in: 2019 
IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), IEEE, 
2019, pp. 96–99. 
[29] Y. Gao, W. Lu, X. Si, Y. Lan, Deep model-based semi-supervised learning way for 
outlier detection in wireless capsule endoscopy images, IEEE Access 8 (2020) 
81621–81632. 
[30] V. Badrinarayanan, A. Kendall, R. Cipolla, Segnet: a deep convolutional encoder- 
decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. 
Intell. 39 (12) (2017) 2481–2495. 
[31] A. Chattopadhay, A. Sarkar, P. Howlader, V.N. Balasubramanian, Grad-cam++: 
generalized gradient-based visual explanations for deep convolutional networks, 
in: 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), 
IEEE, 2018, pp. 839–847. 
[32] Y. Yuan, B. Li, M.Q.-H. Meng, Bleeding frame and region detection in the wireless 
capsule endoscopy video, IEEE.J. Biomed. Health Inf. 20 (2) (2015) 624–630. 
[33] T. Rahim, S.A. Hassan, S.Y. Shin, A deep convolutional neural network for the 
detection of polyps in colonoscopy images, Biomed. Signal Process Contr. 68 
(2021), 102654. 
[34] B. Li, M.Q.-H. Meng, Automatic polyp detection for wireless capsule endoscopy 
images, Expert Syst. Appl. 39 (12) (2012) 10952–10958. 
[35] D.K. Iakovidis, D.E. Maroulis, S.A. Karkanis, A. Brokos, A comparative study of 
texture features for the discrimination of gastric polyps in endoscopic video, in: 
18th IEEE Symposium on Computer-Based Medical Systems (CBMS’05), IEEE, 
2005, pp. 575–580. 
[36] D.J. Barbosa, J. Ramos, C.S. Lima, Detection of small bowel tumors in capsule 
endoscopy frames using texture analysis based on the discrete wavelet transform, 
in: 2008 30th Annual International Conference of the IEEE Engineering in 
Medicine and Biology Society, IEEE, 2008, pp. 3012–3015. 
[37] H. Chen, S. Wang, Y. Ding, D. Qian, Saliency-based bleeding localization for 
wireless capsule endoscopy diagnosis, Int. J. Biomed. Imag. 2017 (2017), https:// 
doi.org/10.1155/2017/8147632. Article ID 8147632. 
[38] T. Ghosh, S.A. Fattah, K.A. Wahid, Chobs: color histogram of block statistics for 
automatic bleeding detection in wireless capsule endoscopy video, IEEE.J. Transl. 
Eng. Health Med. 6 (2018) 1–12. 
[39] S.K. Shah, P.P. Rajauria, J. Lee, M.E. Celebi, Classification of bleeding images in 
wireless capsule endoscopy using hsi color domain and region segmentation, in: 
URI-NE ASEE 2007 Conference, 2007. 
[40] Y. Yuan, B. Li, M.Q.-H. Meng, Improved bag of feature for automatic polyp 
detection in wireless capsule endoscopy images, IEEE Trans. Autom. Sci. Eng. 13 
(2) (2015) 529–535. 
[41] S. Sainju, F.M. Bui, K. Wahid, Bleeding detection in wireless capsule endoscopy 
based on color features from histogram probability, in: 2013 26th IEEE Canadian 
Conference on Electrical and Computer Engineering (CCECE), IEEE, 2013, pp. 1–4. 
[42] Y. Cong, S. Wang, J. Liu, J. Cao, Y. Yang, J. Luo, Deep sparse feature selection for 
computer aided endoscopy diagnosis, Pattern Recogn. 48 (3) (2015) 907–917. 
[43] T. Ghosh, J. Chakareski, Deep transfer learning for automated intestinal bleeding 
detection in capsule endoscopy imaging, J. Digit. Imag. (2021) 1–14. 
[44] X. Li, H. Zhang, X. Zhang, H. Liu, G. Xie, Exploring transfer learning for 
gastrointestinal bleeding detection on small-size imbalanced endoscopy images, in: 
2017 39th Annual International Conference of the IEEE Engineering in Medicine 
and Biology Society (EMBC), IEEE, 2017, pp. 1994–1997. 
[45] E. Ribeiro, A. Uhl, G. Wimmer, M. H¨afner, Exploring deep learning and transfer 
learning for colonic polyp classification, Computational and Mathematical 
Methods in Medicine 2016 (2016), https://doi.org/10.1155/2016/6584725. 
[46] Y. Shin, H.A. Qadir, L. Aabakken, J. Bergsland, I. Balasingham, Automatic colon 
polyp detection using region based deep cnn and post learning approaches, IEEE 
Access 6 (2018) 40950–40962. 
[47] C. Szegedy, S. Ioffe, V. Vanhoucke, A. Alemi, Inception-v4, Inception-Resnet and 
the Impact of Residual Connections on Learning, ArXiv Preprint arXiv:1602.07261. 
[48] S. Bianco, R. Cadene, L. Celona, P. Napoletano, Benchmark analysis of 
representative deep neural network architectures, IEEE Access 6 (2018) 
64270–64277. 
[49] S. Woo, J. Park, J.-Y. Lee, I.S. Kweon, Cbam: convolutional block attention module, 
in: Proceedings of the European Conference on Computer Vision (ECCV), 2018, 
pp. 3–19. 
[50] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, A. Torralba, Learning deep features for 
discriminative localization, in: Proceedings of the IEEE Conference on Computer 
Vision and Pattern Recognition, 2016, pp. 2921–2929. 
[51] R.R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, D. Batra, Grad-cam: 
visual explanations from deep networks via gradient-based localization, in: 
Proceedings of the IEEE International Conference on Computer Vision, 2017, 
pp. 618–626. 
[52] A. Koulaouzidis, D.K. Iakovidis, D.E. Yung, E. Rondonotti, U. Kopylov, J.N. Plevris, 
E. Toth, A. Eliakim, G. Wurm Johansson, W. Marlicz, G. Mavrogenis, A. Nemeth, 
H. Thorlacius, G.E. Tontini, KID Project: an internet-based digital video atlas of 
capsule endoscopy for research purposes, Endosc. Int. Open 5 (6) (2017) 
E477–E483. 
[53] S. Seguí, M. Drozdzal, G. Pascual, P. Radeva, C. Malagelada, F. Azpiroz, J. Vitri`a, 
Generic feature learning for wireless capsule endoscopy analysis, Comput. Biol. 
Med. 79 (2016) 163–172. 
[54] V. Vani, K.M. Prashanth, Color image enhancement techniques in wireless capsule 
endoscopy, in: 2015 International Conference on Trends in Automation, 
Communications and Computing Technology (I-TACT-15), IEEE, 2015, pp. 1–6. 
[55] S.V. Georgakopoulos, D.K. Iakovidis, M. Vasilakakis, V.P. Plagianakos, 
A. Koulaouzidis, Weakly-supervised convolutional learning for detection of 
inflammatory gastrointestinal lesions, in: 2016 IEEE International Conference on 
Imaging Systems and Techniques (IST), IEEE, 2016, pp. 510–514. 
[56] O. Ronneberger, P. Fischer, T. Brox, U-net, Convolutional networks for biomedical 
image segmentation, in: International Conference on Medical Image Computing 
and Computer-Assisted Intervention, Springer, 2015, pp. 234–241. 
[57] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: 
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 
2017, pp. 2881–2890. 
[58] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in: 
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 
2016, pp. 770–778. 
[59] K. Simonyan, A. Zisserman, Very Deep Convolutional Networks for Large-Scale 
Image Recognition, ArXiv Preprint arXiv:1409.1556. 
[60] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. 
Andreetto, H. Adam, Mobilenets: Efficient Convolutional Neural Networks for 
Mobile Vision Applications, ArXiv Preprint arXiv:1704.04861. 
[61] A.K. Kundu, S.A. Fattah, M.N. Rizve, An automatic bleeding frame and region 
detection scheme for wireless capsule endoscopy videos based on interplane 
intensity variation profile in normalized rgb color space, J. Healthc. Eng. 2018 
(2018), https://doi.org/10.1155/2018/9423062. Article ID 9423062. 
[62] X. Jia, M.Q.-H. Meng, A study on automated segmentation of blood regions in 
wireless capsule endoscopy images using fully convolutional networks, in: 2017 
IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017), IEEE, 
2017, pp. 179–182. 
[63] J. Bernal, F.J. S´anchez, G. Fern´andez-Esparrach, D. Gil, C. Rodríguez, F. Vilari˜no, 
Wm-dova maps for accurate polyp highlighting in colonoscopy: validation vs. 
saliency maps from physicians, Comput. Med. Imag. Graph. 43 (2015) 99–111. 
S. Jain et al.                                                                                                                                                                                                                                     
",https://doi.org/10.1016/j.compbiomed.2021.104789,doc13,"Computers in Biology and Medicine 137 (2021) 104789 Available online 25 August 2021 0010-4825/© 2021 Elsevier Ltd. All rights reserved. A deep CNN model for anomaly detection and localization in wireless capsule endoscopy images Samir Jain a, Ayan Seal a,*, Aparajita Ojha a, Anis Yazidi b,d,c, Jan Bures e, Ilja Tacheci e, Ondrej Krejcar f,g a PDPM Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, 482005, India b Department of Computer Science, OsloMet – Oslo Metropolitan University, Oslo, Norway c Department of Plastic and Reconstructive Surgery, Oslo University Hospital, Oslo, Norway d Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway e Second Department of Internal Medicine-Gastroenterology, Charles University, Faculty of Medicine in Hradec Kralove and University Hospital Hradec Kralove, Sokolska 581, Hradec Kralove, 50005, Czech Republic f Center for Basic and Applied Research, Faculty of Informatics and Management, University of Hradec Kralove, Hradecka 1249, Hradec Kralove, 50003, Czech Republic g Malaysia Japan International Institute of Technology, Universiti Teknologi Malaysia, Jalan Sultan Yahya Petra, 54100, Kuala Lumpur, Malaysia A R T I C L E I N F O Keywords: Deep convolutional neural network Attention mechanism Wireless capsule endoscopy Anomaly detection Localization A B S T R A C T Wireless capsule endoscopy (WCE) is one of the most efficient methods for the examination of gastrointestinal tracts. Computer-aided intelligent diagnostic tools alleviate the challenges faced during manual inspection of long WCE videos. Several approaches have been proposed in the literature for the automatic detection and localization of anomalies in WCE images. Some of them focus on specific anomalies such as bleeding, polyp, lesion, etc. However, relatively fewer generic methods have been proposed to detect all those common anomalies simultaneously. In this paper, a deep convolutional neural network (CNN) based model ‘WCENet’ is proposed for anomaly detection and localization in WCE images. The model works in two phases. In the first phase, a simple and efficient attention-based CNN classifies an image into one of the four categories: polyp, vascular, inflam­ matory, or normal. If the image is classified in one of the abnormal categories, it is processed in the second phase for the anomaly localization. Fusion of Grad-CAM++ and a custom SegNet is used for anomalous region seg­ mentation in the abnormal image. WCENet classifier attains accuracy and area under receiver operating char­ acteristic of 98% and 99%. The WCENet segmentation model obtains a frequency weighted intersection over union of 81%, and an average dice score of 56% on the KID dataset. WCENet outperforms nine different state-of- the-art conventional machine learning and deep learning models on the KID dataset. The proposed model demonstrates potential for clinical applications. 1. Introduction Computer-aided diagnostic (CAD) systems have seen tremendous growth in recent years. With the evolution of cyber-physical healthcare systems, the emphasis is on process automation in every field of di­ agnostics. Modern artificial intelligence techniques enriched with deep learning algorithms are major catalysts in these developments. Com­ puter Vision-based diagnostic tools have shown remarkable improve­ ments over the years in tasks like tumor detection in brain MRI [1], identification of gastro-intestinal malignancy [2], ulcers [3], polyps [4], tumors [5], bleeding [6] etc. WCE is a promising non-invasive painless method for the inspection of the digestive tract through captured videos [7]. In WCE, a tiny capsule equipped with a micro-sized camera (10 × 25 mm) is swallowed by the patient under examination. The video captured on the fly by the capsule is sent to a small receiver tied around the waist of the patient. WCE is a primary tool for the detection and diagnosis of anomalies like ulcers [8], bleeding regions [9], and polyps [10]. It enables examining those areas which conventional endoscopic procedures cannot reach. However, the downside of the WCE is the length of videos that may last from 8 to 10 h and may contain more than eighty thousand frames, with a frequency rate of 2 frames per second [11]. This makes the manual investigation of the entire tract a tedious and cognitively demanding task. The complete analysis of the video requires continuous concentration for very long hours which might * Corresponding author. E-mail address: ayan@iiitdmj.ac.in (A. Seal). Contents lists available at ScienceDirect Computers in Biology and Medicine journal homepage: www.elsevier.com/locate/compbiomed Received 11 April 2021; Received in revised form 18 August 2021; Accepted 18 August 2021 Computers in Biology and Medicine 137 (2021) 104789 2 overwhelm human attention. Due to this reason, the call for automation of the identification of abnormalities in video frames is of high demand. Recently, some product manufacturers have launched WCE systems with embedded software for identifying bleeding regions in video frames [12]. However, such systems struggle in identifying other types of anomalies. It is mainly because different types of anomalies pose chal­ lenges in identifying them using traditional image processing techniques due to the differences in color, texture, size and, shape. Many Machine Learning (ML) techniques have been devised in the last decade for the detection of abnormal frames in WCE videos. The k- nearest neighbors (KNN), principal component analysis (PCA), support vector machines (SVM), random forest (RF), and artificial neural net­ works (ANN) are some of the most widely deployed classifiers for the identification of different types of anomalies. These ML algorithms are usually trained using manually extracted features such as color histo­ gram [13], wavelet transform [14], local binary pattern (LBP) [15], Haralick texture features [16], scale-invariant feature transform (SIFT) [16], speed up robust features [17], and fractal dimensions (FD) [18] for the identification of WCE anomalies. In recent years, deep learning has emerged as a promising tool for the detection of anomalous WCE images and localization of abnormal re­ gions [4,11,19–21]. Notably, CNNs along with conventional feature extraction techniques have been used for anomaly detection such as lesion, hookworm, and bleeding [22,23]. Although deep learning tech­ niques have shown improved performance in many cases, the problem we are tackling in this paper remains challenging due to the diversity of patterns and the complexity of textures of the abnormalities. The scar­ city of labeled data and the computational requirements are also matters of concern when it comes to the applicability of these algorithms in WCE videos [24–26]. Until recently, most of the methods were developed to identify only a single type of anomaly. For automatic classification and localization of abnormal regions, a single method that can cover most of the anomalies in one shot is highly useful. Some of the recent approaches that address this problem include [11,27,28]. Iakovidis et al. [11] have suggested a CNN-based three-phase method that captures the features of a large number of anomalies in the WCE images. They have also esti­ mated salient points in abnormal images which serve as guiding factors for the localization of abnormal regions. Gao et al. [29] have suggested a deep learning tool for the detection of outliers in the WCE image. They integrated a long short-term memory network with a CNN for learning the graphical patterns of ulcers, erythema, protruding lesions, polyp, and vascular malformation. In this paper, a CAD model ‘WCENet’ is proposed to automatically identify and localize three different types of abnormalities in WCE im­ ages. The model works in two phases. In the first phase, a CNN model with an attention mechanism is trained to classify WCE images into 4 classes namely, inflammatory, polyp, vascular and normal. Images classified into abnormal classes are processed in the second phase for estimation of regions using a combination of a custom SegNet [30] and Grad-CAM++ [31]. The main contributions of the proposed work are summarized as follows: • An attention-based CNN model is developed for the classification of WCE images into four categories namely, inflammatory, polyp, vascular (bleeding), and normal. • A hybrid approach is used for the localization of anomalies in an image using both a custom SegNet [30] and Grad-CAM++ [31]. The hybrid approach provides higher precision than the individual methods. • The proposed model demonstrates superior performance in terms of classification and localization performance in comparison with other state-of-the-art methods. The rest of the paper is organized as follows. Section II gives a brief overview of related work. Section III is devoted to the presentation of the proposed model for anomaly detection and localization in WCE images. In Section IV, experimental results are presented and compared with some state-of-the-art techniques. Section V concludes the paper and delineates some future work. 2. Related work Existing research in the field of WCE covers detection of anomalies like bleeding [22,32], polyps [33–35], hook-worms [19], ulcers [8], tumors [36] etc. Pixel-based approaches have been found effective for bleeding detection since color plays an essential role in this type of anomaly (see e.g. Refs. [12,32,37,38]). Some of the researchers have used the conversion of RGB images to a different color space to improve classification accuracy. Shah et al. in Ref. [39] have opted for HSI color space over RGB for the classification of bleeding and non-bleeding im­ ages using a color threshold (see also [6,12]). Shape and texture analysis proves to be very useful in the characterization of polyps, ulcers, in­ flammatory or vascular disorders, and tumors. Bag of visual words [32], color histogram [38], LBP [40], wavelet transform [36], FD [18] are some of the approaches relying on these types of features. Most of the image classification techniques mentioned above are either threshold-based where the count and the intensity of pixels are used [12] or use ML algorithms like KNN [32,37], SVM [13,17], and ANN [14,41]. Cong et al. [42]. have suggested a new variant of SVM termed as Deep Sparse SVM (DSSVM) for the identification of abnormal frames. DSSVM is trained on color and texture features that were extracted from image super-pixels. A group sparsity criterion is defined for the removal of irrelevant features by assigning a higher weight to important features. This model is found to be quite useful when the computed features exhibit redundancies. Deep learning methods have recently emerged as powerful solutions in a variety of applications including WCE video analytics (see, for example [9,25,31,39,43]). Sekuboyina et al. [27]. have used the CIE-Lab color space representation of WCE images to train a CNN classifier on the patches falling in the normal and abnormal regions of WCE images. Once the CNN is trained, it locates the abnormal regions in an image by identifying and combining abnormal patches. Other methods that utilize CNN include [4,11,22,28]. CNN-based autoencoders have also been popular alternatives for the extraction of features from WCE images [10]. A stacked sparse autoencoder (SSAE) has been presented by Yuan et al. [10] for polyp detection. The accuracy of the model is enhanced using an image manifold constraint (SSAEIM) with the idea that the images belonging to the same class share common features whereas the images from different classes exhibit high variances in the learned fea­ tures. Banik et al. [4] have suggested an integrated method for the segmentation of polyps by deploying a CNN and a level set method. A modified level set method termed as Local Gradient Weighting embedded Level Set Method (LGWe-LSM) is introduced for surface and shape analysis which suppresses high-intensity regions that may pro­ create false positives. A 16-layer deep CNN for the detection of polyps in colonoscopy images has been projected by Rahim et al. [33]. They have introduced generalized intersection over union to deal with scale invariance issues. Deep neural networks are data-hungry and unfortunately, most of the publicly available WCE datasets are of a relatively small size as compared to the general category datasets on which deep learning models have shown remarkable performance. To overcome the problem of small datasets, the transfer learning approach has been used by many authors. Li et al. [44] have exploited the effectiveness of transfer learning for gastrointestinal bleeding detection on a small-size imbal­ anced endoscopy image dataset. Riberio et al. in Ref. [45] have considered pre-trained models AlexNet, VGGNet, and GoogLeNet on ImageNet and Pascal VOC datasets for the classification of colonic polyps. Shin et al. [46] have also utilized the transfer learning approach for the localization of polyps using Faster RCNN with Inception-Resnet (InceptionV4) [47]. In the method devised by Sadasivan et al. [28], a patch-based CNN is suggested where patches from normal and abnormal S. Jain et al. Computers in Biology and Medicine 137 (2021) 104789 3 regions of WCE images are extracted and used for the localization of anomaly. The CNN is trained to classify the patches as normal or abnormal. Ghosh et al. [43] presented a two-stage system for bleeding detection and localization in WCE images. In the first stage, a CNN with AlexNet architecture is used to classify bleeding and non-bleeding (normal) frames. In the next stage, bleeding regions are segmented using VGG16 based SegNet [30]. AlexNet is an old architecture and several efficient CNN models have been tendered over the years that show significant improvement over AlexNet [48]. Further, in recent years, some CNN models with attention mechanisms have also been explored in different domains which were shown to help improve the prediction performance of the models. A review of the existing literature indicates that a handful number of generic methods have been presented to deal with multiple types of anomalies simultaneously. Further, deep CNN models used in the clas­ sification of anomalies have large memory footprints and demand high computational resources. In this paper, an attention-based CNN is pro­ posed which detects four different types of anomalies in WCE images. To locate the abnormal regions in identified images, a hybrid of two stan­ dard approaches is applied, namely, Grad-CAM++ [31] and SegNet [30]. The proposed method provides improved classification accuracy and localization results with higher precision levels compared to legacy methods. 3. WCENet: an anomaly detection and localization model In this section, an automatic anomaly detection and localization model ‘WCENet’ is proposed for WCE images. Fig. 1 presents the sche­ matic diagram of the model that consists of (i) a base CNN model using an attention-based mechanism that classifies the images into four cate­ gories (ii) a custom SegNet [30] model for semantic segmentation of abnormal regions in images (iii) a supporting mechanism to the seg­ mentation model using Grad-CAM++ [31] applied on the trained clas­ sification model. The 11-layer attention-based CNN model is trained on a WCE image dataset to classify images into four categories namely, inflammatory, polyp, vascular, and normal. The attention mechanism focuses on dominant features and suppresses the insignificant ones. All images that are classified as abnormal by the CNN model are then passed onto the localization framework which consists of two parallel mechanisms (i) a SegNet based [30] CNN model that is trained to segment the pixels falling in the abnormal region of an image, and (ii) analysis of the class activation maps of the images using Grad-CAM++ [31] applied on the trained WCENet. The set of pixels that are identified by both methods as abnormal are finally selected for the localization of the anomaly in the image. Details of SegNet and Grad-CAM++ are given in Section 3.2. 3.1. The classification network The classification model of WCENet is a CNN with an attention mechanism having 7 convolution (Conv) blocks and 4 fully connected (FC) blocks as shown in Fig. 2. A Conv block consists of a Conv layer followed by a batch normalization + ReLU layer that fends off the model from overfitting. The Conv blocks are grouped into 4 modules. The first module consists of two Conv blocks, with 32 filters, each of size 3 × 3 in both the Conv layers. Max-pooling is applied at the output of the second Conv block and then an attention block is added. The second and the third modules have an identical structure except for the number of fil­ ters. There are 64 filters in each of the Conv layers in the second module and 128 filters in the Conv layers of the third module. The fourth module has only one Conv block followed by max-pooling. Since the anomalies in the WCE images can be present at the boundaries also, the role of boundary pixels is crucial. Therefore, ‘SAME’ padding is used in the convolution operation throughout the Conv layers. As depicted in Fig. 2, an attention block is added after each of the first three Conv modules. The attention mechanism is induced from the concept of a convolution block attention module (CBAM) [49] which is briefly discussed in Sec­ tion 3.1.1, the output of the fourth module goes to the global average pooling (GAP) layer. GAP layer contributes to limit the computation of Fig. 1. Schematic block diagram of proposed WCENet. Fig. 2. Schematic block diagram of WCENet classifier. S. Jain et al. Computers in Biology and Medicine 137 (2021) 104789 4 parameters as compared to the flatten layer to make the network learn faster. Then four FC layers are added to the tail of the network with 128, 64, 32, and 4 units, the last layer is the (output) classification layer. The first three FC layers are coupled with batch normalization and ReLU activation whereas the output layer uses softmax activation. Input to the WCENet is a 3-channel, 24-bit RGB image of size 320 × 320. 3.1.1. Convolution block attention module The CBAM [49] is a lightweight and generalized attention module that can be integrated easily with any CNN. CBAM derives attention maps from channels and spatial dimensions of intermediate feature maps. To understand how the attention mechanism works, consider an intermediate feature map M ∈RC×I×J, where C denotes the number of channels in M and I × J is the feature dimension. CBAM extracts 1-D channel attention map Ac ∈RC×1×1 and a 2-D attention map As ∈ R1×I×J as shown in Fig. 3. The final feature map with attention is computed with the following series of operations: M ′ = Ac(M) ⊗M, (1) M′′ = As(M ′) ⊗M ′, (2) where the symbol ⊗denotes the element-wise multiplication of two matrices. Here, M′′ is the final feature map with the attention that can be considered as the refined output. The channel attention module targets ‘which’ information inside the image is meaningful whereas the spatial attention module focuses on ‘where’ the meaningful information is located in the image. To compute the channel attention, the spatial di­ mensions are squeezed by aggregating the spatial information using max-pooling and average-pooling. These two spatial context feature descriptors Mc avg and Mc max are then forwarded to a single hidden layer fully connected NN (FC-NN) to produce Ac ∈RC×1×1. The hidden acti­ vation can be fixed to a size of RC/n×1×1 where the size can be reduced by n. Each descriptor is passed through the shared FC-NN and the outputs of both the descriptors are added element-wise to get Ac which is then multiplied to each element of M along the channel axis to get M′ as given in Eq. (1). Next, the spatial attention is computed on M′ by max-pooling and average-pooling feature maps at each pixel location across all the channels producing Ms avg and Ms max ∈R1×I×J. Convolution operation with filters of size f is then performed on the two-channel feature descriptor formed after concatenation of Ms avg and Ms max to produce As ∈R1×I×J. Finally, element-wise multiplication of As is performed on each channel C of M ′ ∈RC×I×J to produce a refined feature map M′′ as given in Eq. (2). In this way, a CBAM can be easily applied to the output of any intermediate layer of a CNN. 3.2. Anomaly localization framework In the second stage of WCENet, an abnormal image (labeled as abnormal after classification) is analyzed further for the localization of anomalies. The localization is achieved through a hybrid approach using two standard localization methods namely SegNet [30] and Grad-CAM++ [31]. SegNet is a deep encoder-decoder architecture that provides pixel-wise segmentation of an image. In the present paper, a custom CNN is used in the encoder and the decoder parts of SegNet. The second method is Grad-CAM++ which uses the trained WCENet classi­ fier network and generates the class activation maps that highlight the salient region in an input image. The outputs of both the methods are then fused to get the segmented region in the WCE image for the Fig. 3. Schematic block diagram of CBAM attention sub-modules. Fig. 4. A flow diagram of localization framework in WCENet. S. Jain et al. Computers in Biology and Medicine 137 (2021) 104789 5 localization of the anomaly in an image. The localization framework is presented in Fig. 4. 3.2.1. SegNet architecture Gastrointestinal (GI) anomalies differ in their visual appearances. They exhibit irregular shapes, different colors, and textures which make them difficult to locate in an image by computer vision techniques. Pixel level segmentation can be useful for identifying such anomalous regions. In this paper, a customized CNN-based segmentation model inspired by the idea of SegNet [30] is proposed. The segmentation model trained on a WCE dataset can differentiate the pixels belonging to an abnormal or a normal region in an image. As mentioned earlier, the SegNet architec­ ture consists of an encoder and decoder network which can be a CNN or FC-NN followed by a final pixel-wise classification layer. SegNet model developed in the proposed work is shown in Fig. 5. In this network, depthwise separable convolutions (DSC) are used for the extraction of features. DSC makes the model lightweight by drastically reducing computations and model size. Both the encoder and the decoder are composed of 8 depthwise separable convolutions (DSC) layers. Each DSC layer is followed by the batch normalization layer and a ReLU activation layer. The DSC layer is configured with 3 × 3 filters and a stride = 1. Further, a 2 × 2 max-pooling layer with stride = 2 is used in the network. All the DSC layers are followed by batch normali­ zation and ReLU layers. The decoder is a mirror network configured with upsampling layers in place of max-pooling layers. Here, the upsampling is performed as in the original SegNet. Since the max-pooling operation in the encoder leads to the loss of the spatial resolution, SegNet stores the location of the maximum value for each feature map during the max- pooling operation as shown in Fig. 6. The green lines connecting the encoder-decoder layers in Fig. 5 show max-pooling indices shared by the encoder and decoder which are used during the upsampling operation. The decoder generates sparse-feature maps which are then convolved with the filter banks to densify them. The decoded output is passed through the softmax layer that generates a K− channel image of the probability values at pixel locations where K is the number of classes. Finally, a segmented image is obtained where each segment corresponds to an anomaly class giving the maximum probability at each pixel. 3.2.2. Grad-CAM++ In contrast to SegNet, which is trained explicitly on the datasets with ground-truths for pixel segmentation in an input image, Grad-CAM++ [31] works on a trained classifier, and builds a heatmap to identify the region of interest in an input image. Grad-CAM++ performs an analysis of the class activation maps (CAMs). Zhou et al. [50] suggested that various layers of a CNN can be exploited as object detectors using CAM if the GAP layer is utilized with the combination of weighted feature maps produced just before the softmax classification layer (penultimate Fig. 5. SegNet architecture for localization of anomaly in WCE images. Fig. 6. A SegNet decoder employing max-pooling indices during unpooling. S. Jain et al. Computers in Biology and Medicine 137 (2021) 104789 6 layer). This method allows generating a heatmap that highlights the pixels in the image that have participated in assigning a particular class to the image. Let the penultimate layer produce L feature maps, Ml ∈Ru×v of size u × v. To apply the spatial GAP on these feature maps, the linear combi­ nation given in Eq. (3) is used to compute a score Sc for each class c. Sc = ∑ l wc l ⏞⏟⏟⏞class ​ weights 1 Q ∑ i ∑ j ⏟̅̅̅̅̅⏞⏞̅̅̅̅̅⏟ GAP Ml ij ⏞⏟⏟⏞feature ​ map , (3) where Q is the number of pixels in the activation map M. The class- specific localization map Lc at each location (i, j) is calculated using Eq. (4). Fig. 7. Some samples of images categorized in four classes where anomalies present in the abnormal class are located with the white circle. Table 1 Description of the KID dataset (KID-I and KID-II combined). Class # Images in the dataset # Images after augmentation Inflammatory 241 1266 Polyps 50 1293 Vascular 350 1243 Normal 728 1300 Table 2 Performance of WCENet with and without attention mechanism. WCENet Accuracy Precision Recall F1-score Without attention 0.97 0.96 0.97 0.97 With attention 0.98 0.98 0.98 0.98 Table 3 Parametric configuration of six state-of-the-art CNN classification models and the proposed WCENet classifier. Author # CNN # Pooling # FC Hyperparameters # Trainable Layers Layers Layers (opt, lr, bs, ep) Parameters Sekuboyina et al. [27] 3 2 3 Adam, 0.01, 100, 100 7,032 Georgakopolous et al. [55] 5 2 3 SGD, 0.001, 100, 100 115,486 Sadasivan et al. [28] 3 2 3 Adam, 0.001, 64, 200 7,032 Jia et al. [9] 3 3 2 SGD, 0.01, 100, 200 10,697,060 Iakovidis et al. [11] 5 4 3 SGD, 0.001, 50, 200 286,344 Ghosh et al. [43] 5 3 3 SGD, 0.01, 16, 200 528,078,924 Proposed WCENet 7 4 4 SGD, 0.001, 16, 200 656,010 Table 4 Parametric configuration of the ML classification methods compared with WCENet classifier. Author Method Feature Length ML classifier Hyperparameters Yuan et al. [40] SIFT + CLBP 120 SVM Cubic SVM kernel Ghosh et al. [38] CHOBS 4096 KNN K = 1 Jain et al. [18] DBC (FD) 2025 RF # Estimators = 500 Table 5 Classification performance of nine state-of-the-art techniques and WCENet with 5-fold cross validation. Method Accuracy Precision Recall f1- score AUC Sekuboyina et al. [27] 0.53 0.51 0.98 0.67 0.52 Georgakopoulos et al.(patch CNN) [55] 0.58 0.55 0.96 0.70 0.57 Sadasivan et al. [28] 0.57 0.54 0.99 0.71 0.59 Jia et al. [9] 0.90 0.92 0.85 0.87 0.85 Iakovidis et al. [11]. 0.92 0.95 0.91 0.93 0.94 Ghosh et al. [38] 0.72 0.70 0.73 0.72 0.74 Yuan et al. [40] 0.82 0.79 0.85 0.82 0.83 Jain et al. [18] 0.83 0.85 0.84 0.84 0.84 Ghosh et al. [43] 0.94 0.96 0.94 0.94 0.95 WCENet 0.98 0.98 0.98 0.98 0.99 S. Jain et al. Computers in Biology and Medicine 137 (2021) 104789 7 Lc i,j = ∑ l wc l ⋅Ml ij (4) Note that the CAMs help visualizing the outputs of the last convo­ lution layer only, which is a limitation. Also, the process involves training the linear classifier for each class. These issues were addressed in a method known as Grad-CAM introduced by Selvaraju et al. [51]. Instead of training multiple classifiers for the class-specific weight computation, the weights wc l for a specific activation map Ml and the class c are computed using Eq. (5). wc l = Q⋅∂Sc ∂Ml ij ⏟̅̅̅⏞⏞̅̅̅⏟ gradients ∀i, j (5) The above formulation computes the weights wc l independent of the spatial locations (i, j) of a specific activation map Ml. The limitation of CAM is overcome by taking the GAP of the partial derivatives ∂Ml ij. Therefore, the weights wc l are computed using Eq. (6). wc l = 1 Q ∑ i ∑ j ∂Sc ∂Ml ij (6) Grad-CAM’s performance deteriorates when there are multiple in­ stances of the same object in an image. This is quite common in WCE images where anomalies can be present at different locations in the same image. Further, the localization through Grad-CAM is observed to miss some portion of the region of interest, probably due to the unweighted average of partial derivatives. Grad-CAM++ introduced by Chatto­ padhyay et al. [31] overcomes this issue by modifying Eq. (6) as follows. wc l = ∑ i ∑ j βlc ij ⏟⏞⏞⏟ gradient ​ weights ReLU ( ∂Sc ∂Ml ij ) (7) The main idea behind the above formula is that wc l apprehends the significance of a particular activation map Ml. For a given activation map Ml, the positive gradient at location (i, j) makes the class score S stronger with increasing pixel values. Therefore, the linear combination of partial derivatives over each pixel in an activation map Ml will show the relevance of that map for class C. The formulation in Eq. (6), com­ putes the weighted average of gradients wc l in contrast to the GAP per­ formed using Eq. (7). The class score Sc is computed using Eq. (8) which Fig. 8. ROC curves of WCENet. Table 6 Performance comparison of segmentation models with different base architectures. Method Encoder Architecture FwIoU MIou Dc SegNet VGG16 0.79 0.60 0.48 SegNet ResNet50 0.80 0.60 0.51 SegNet MobileNetV1 0.81 0.61 0.55 SegNet Custom CNN 0.81 0.60 0.55 UNet VGG16 0.77 0.50 0.45 UNet ResNet50 0.78 0.53 0.46 UNet MobileNetv1 0.79 0.56 0.48 UNet Custom CNN 0.79 0.56 0.48 PSPNet VGG16 0.74 0.44 0.39 PSPNet ResNet50 0.77 0.51 0.45 PSPNet MobileNetv1 0.79 0.49 0.47 PSPNet Custom CNN 0.78 0.49 0.48 Fig. 9. (a,d) Original WCE image with anomalies. (b,e) Corresponding ground truths of WCE images. (c,f) Segmentation results produced by SegNet model. S. Jain et al. Computers in Biology and Medicine 137 (2021) 104789 8 is derived by combining Eqs. (3) and (7). Sc = ∑ l [∑ i ∑ j {∑ a ∑ b βlc abReLU ( ∂Sc ∂Ml ab ) } Ml ij ] (8) In Eq. (8), the iterators (i, j) and (a, b) are identical and iterate over entire activation map Ml. Since ReLU is a threshold function that allows the gradients to flow-back, we can drop it. Therefore, by taking partial derivative on both the sides of Eq. (8), for a specific class c, an activation map l, and the class score Sc, the gradient weights βlc ij are computed using Eq. (9). Fig. 10. (a,d) Original WCE image with anomalies. (b,e) Corresponding ground truths of WCE images. (c,f) Heatmaps through GradCAM++ applied on trained WCENet classifier. Fig. 11. Some sample segmentation results of Grad-CAM++ using different threshold values. S. Jain et al. Computers in Biology and Medicine 137 (2021) 104789 9 βlc ij = ∂2Sc (∂Ml i,j) 2 2⋅ ∂2Sc (∂Ml i,j) 2 + ∑ a ∑ b Ml ab ⎧ ⎪ ⎨ ⎪ ⎩ ∂3Sc (∂Ml i,j) 3 ⎫ ⎪ ⎬ ⎪ ⎭ (9) The class-wise saliency maps for a given image I are calculated as the linear combinations of forward activation maps. Each spatial element in the saliency map Lc is then computed using Eq. (10). Lc ij = ReLU (∑ l wc l ⋅Ml ij ) (10) The localization result obtained using Grad-CAM++ is combined with the result of SegNet to get the final segmented image. Pixelwise AND operation is performed to compute the final segmented region of an anomaly in a given input image. 4. Experimental results and discussion In the present section, the performance of the WCENet anomaly detection and localization model is evaluated on the publicly available KID [52] dataset. The model’s performance is also compared with some state-of-the-art methods that are relevant to the present work. All the experiments are performed on an Intel Xeon processor with 64 GB RAM and 8 GB Nvidia Quadro P4000 GPU. Keras API 2.1.3 is used with Tensorflow 2.2 as the backend to code the proposed model and all the ML and DL algorithms used in the comparison. 4.1. Dataset Experiments are performed on the KID dataset [52] which consists of two subsets KID-I [17] and KID-II [11]. The KID-I contains 77 images of various classes of anomalies like angiectasia (27), lymphangiectasia (9), polyps (6), ulcers (9), bleeding (5), stenoses (6), aphthae (5), chylous cysts (8). The KID dataset-II contains images with anomalies of three classes that are polyp (44), vascular (303) and, inflammatory lesion (227), and normal images from different parts of the GI tract like esophagus (282), stomach (599), small bowel (728) and colon (169). The anomaly classes in the KID-I can also be broadly categorized into one of the classes in the KID-II. The abnormal images belonging to angiectasia, lymphangiectasia, bleeding, and stenoses are mapped to the vascular class whereas aphthae and ulcer images are grouped into the inflammatory class. After the categorization of images in the KID-I, they are merged with the KID-II. Images of the size 360 × 360 × 3 are captured using a MicroCam capsule endoscope (IntroMedic Co, Seoul, Korea). The anomalies belonging to different classes have variations in texture and color as depicted in Fig. 7. The inflammatory class commonly referred to as inflammatory bowel disease (IBD) can be characterized by chronic inflammation in the intestinal walls. It can be a wound-like structure swollen up, sometimes turning red in color. Ulcers are common in IBDs, which appear like a wound with pale yellow or red color. A polyp is another kind of GI disease that is formed on the lining of the colon that looks like a blob of cells. It is formed due to its unregulated growth. In most cases, polyps have a color similar to the intestinal walls but their structure differentiates them from the normal regions. In the GI tract, there can be syndromes with abnormalities in mucosal and sub­ mucosal vessels. These vessels may cause bleeding and can be referred to as a vascular anomaly. The proposed model is trained and tested on the merged KID dataset. The original images in the dataset are of the size 360 × 360 with black borders. In pre-processing steps, the borders are removed and the final images are of size 320 × 320. Sometimes the light source of the capsule gets obstructed by some clinical events [53] resulting in poor quality of frames. To deal with this problem, the contrast limited adaptive histo­ gram equalization (CLAHE) method is used for image contrast enhancement [54]. Since the dataset is imbalanced with the majority of normal images, augmentation is also performed by applying random geometric transformations like rotation between −20 to + 20◦, zooming with a factor of 0.2, horizontal and vertical flips. In addition, random Gaussian noise is used for data augmentation. The number of images in each class before and after augmentations is listed in Table 1. A ratio of 4: 1 is taken for splitting the dataset into training and testing sets. 4.2. Performance of WCENet The proposed WCENet is trained to classify the WCE images into one of the four classes that are inflammatory, polyp, vascular, and normal as discussed in the previous section. The WCENet classifier is trained using the categorical cross-entropy loss with a learning rate of 0.001, the number of epochs = 200, and Adam optimizer with momentum = 0.9. The performance of the model is tested with and without an attention mechanism and it is found that the attention mechanism provides slightly better results (Table 2). 4.3. Comparative analysis of WCENet This section provides the experimental results to analyze and compare the performance of WCENet with nine different schemes introduced in Refs. [9,11,18,27,28,38,40,43] and, [55]. Methods involving handcrafted features for the classification of WCE images as well as deep learning techniques are considered for comparative analysis. 1) Deep learning-based methods: WCENet is compared with six different CNN-based classifiers introduced in Refs. [9,11,27,28,43] and [55] (Table 5). These include patch-based CNN models intro­ duced in Refs. [27,28,55] and CNN models that work on full images [9,11,43]. In the patch-based schemes, an image patch is defined to be abnormal if most of its pixels fall in the abnormal region and normal otherwise. For a fair comparison of the performance of WCENet with the patch-based methods, even if the single patch in the image is identified as abnormal then the whole image is Table 7 Grad-CAM++ segmentation performance with different threshold values. Threshold FwIoU MIou Dc 0.1 0.73 0.47 0.41 0.2 0.73 0.48 0.43 0.3 0.75 0.53 0.45 0.4 0.75 0.54 0.46 0.5 0.76 0.55 0.47 0.6 0.74 0.54 0.46 0.7 0.74 0.54 0.46 0.8 0.72 0.54 0.45 0.9 0.72 0.54 0.44 Table 8 Localization performance comparison by taking union and intersection of seg­ mentation masks produced by Grad-CAM++ (M1) and SegNet (M2). M1⋃M2 M1 ∩M2 Threshold FwIoU MIou Dc FwIoU MIou Dc 0.1 0.70 0.48 0.41 0.83 0.59 0.56 0.2 0.72 0.48 0.44 0.81 0.59 0.55 0.3 0.72 0.49 0.46 0.79 0.57 0.55 0.4 0.73 0.49 0.48 0.78 0.55 0.54 0.5 0.74 0.50 0.50 0.77 0.55 0.54 0.6 0.74 0.50 0.50 0.76 0.55 0.53 0.7 0.74 0.52 0.51 0.76 0.55 0.52 0.8 0.75 0.55 0.51 0.74 0.52 0.50 0.9 0.75 0.55 0.52 0.69 0.47 0.40 S. Jain et al. Computers in Biology and Medicine 137 (2021) 104789 10 considered as abnormal. The CNN model in Ref. [55] is trained on RGB color image patches, whereas a−channel of CIE-Lab color space is used to train the models in Refs. [27,28]. Since the number of abnormal patches is less as compared to the normal patches, a balanced set is prepared for experiments with 5518 patches in each class (c.f [27,28,55]) and the patch size of 32 × 32 is taken for the experiment. Other than the patch-based models, the CNN architec­ tures in Refs. [9,11,43] work on the full image. The parametric configurations of the above six architectures and the proposed model are given in Table 3. 2)Conventional ML methods: Three conventional ML methods are also compared with WCENet. The first method is by Yuan et al. [40] according to which a bag-of-features is computed making use of SIFT and LBP. Another method is the Color Histogram of Block Statistics (CHOBS) proposed by Ghosh et al. [38] in which some statistical values are calculated over the blocks extracted from the image and on which the color histograms are computed. The third method is by Jain et al. [18] that uses fractal features based on the differential box-counting method which are fed to the random forest classier. The parametric configurations of the above three ML techniques are listed in Table 4. All the experiments were performed on the merged KID dataset with augmentation mentioned in Section 4.1. Since the number of training and testing samples is quite limited, a 5-fold cross-validation is applied on WCENet as well as on all the methods used in the comparative analysis. Results in Table 5 demonstrate that WCENet yields 98% ac­ curacy. Ghosh et al. [43] have employed transfer learning on AlexNet CNN architecture and the classification accuracy of their model is 96%. In patch-based methods, since an image is divided into patches, it may happen the normal region in a patch dominates the abnormal region, and hence the patch might be categorized as normal. This might be a reason for the lower performance of patch-based CNNs given in Refs. [27,55]. Moreover, the CNN proposed by Jia et al. [22] has fewer convolution layers with a small number of filters that might be the reason for its lower performance with 82% accuracy. We anticipate that the features used in Refs. [18,38,40], have their limitations in identifi­ cation of a wide range of anomalies in the dataset with different colors, textures, shapes. This could be the reason for the relatively lower per­ formance of these methods. Along with the accuracy and F1-score, the area under the receiver operating characteristic curve abbreviated as AUC is also analyzed. It can be drawn from Table 5 that WCENet per­ forms better than the other state-of-the-art methods with the highest Fig. 12. Localization results produced by taking the union and intersection of segmentation masks produced by GradCAM++(M1) and SegNet(M2). S. Jain et al. Computers in Biology and Medicine 137 (2021) 104789 11 accuracy and AUC score as 98% and 99% respectively. The plots of the ROC curves are shown in Fig. 8. 4.4. Experimental results on anomaly localization The anomaly localization framework explained in Section 3.2 is a hybrid of two methods: a custom SegNet model with an 8−layer CNN encoder-decoder structure and GradCAM++ using the trained WCENet classifier. The selection of the CNN architecture in SegNet [30] is based on the experimental analysis with two popular segmentation models UNet [56] and PSPNet [57]. All these models use a base CNN archi­ tecture. To analyze the performance of segmentation models with respect to the base architecture, three popular CNN models are taken to constitute the base model in UNet, PSPNet, and SegNet. These base models are ResNet50 [58], VGG16 [59], and MobileNetV1 [60]. Apart from this, an 8-layer custom encoder-decoder model is also used for performance evaluation represented in Fig. 5. Three popular metrics are used for comparison namely mean IoU (MIoU), frequency weighted intersection over union (FWIoU), and Dice coefficient (Dc). MIoU and FWIoU can be calculated with the help of Eqs. (11) and (12). MIoU = 1 N⋅ ∑ jnjj Lj + ∑ knkj −njj , (11) FwIoU = 1 ∑ sLs ⋅ ∑ j Lj ∗njj Lj + ∑ k nkj −njj , (12) where N is the total number of classes, and nkj is the total number of pixels in the class j identified by the method, but originally belonging to the class k. Further, Lj is the total number of pixels belonging to class j in the ground truth. The dice coefficient is somewhat similar to the F1 score used in the classification. It is computed as the ratio of two times the area of intersection between the ground truth and the predicted segmentation to the union of the ground truth and predicted segmentation areas. Let G Fig. 13. Segmentation performance of the proposed method and some state-of-the-art bleeding segmentation methods. Table 9 Performance of WCENet localization on CVC-CLINIC dataset. WCENet Model IoU FwIoU Dc Trained with KID dataset 0.48 0.78 0.32 Exclusively trained with CVC-CLINIC 0.90 0.96 0.89 Fig. 14. Segmentation results of SegNet trained on CVC-CLINIC dataset. (a,d). Polyp images in CVC-CLINIC dataset. (b,e) Corresponding ground truths. (c,f) Seg­ mentation results by SegNet. S. Jain et al. Computers in Biology and Medicine 137 (2021) 104789 12 be the area of the ground truth and S be the segmented area, then Dc is calculated using Eq. (13). Dc = 2 × G ∩S |G| + |S| (13) The segmentation models considered in this study are trained on the same augmented KID dataset, used in the classification stage. All the models are trained for 200 epochs with a categorical cross-entropy loss function. Stochastic gradient descent (SGD) with momentum is used for optimization with the momentum = 0.9 and the learning rate of 0.01. To find out the best combination of the segmentation model with the appropriate encoder architecture, an empirical study is performed. All the models are trained and evaluated on the augmented KID dataset. The results are recorded in Table 6, which show that the SegNet model with the custom CNN produces better results as compared to other base ar­ chitectures with the highest FwIoU of 0.81 as compared to the other encoding architectures. Some of the sample WCE images, their corre­ sponding ground truths, and the segmented regions by the proposed SegNet model are shown in Fig. 9. Although the performance of SegNet with MobileNetV1 is close to SegNet with the custom CNN, we have adopted to use custom CNN due to its lightweight architecture with 8 layers as compared to MobileNetV1 which consists of 13 layers. The automatic segmentation of WCE images is also performed using GradCAM++ as described in Section 3.2.2. The trained WCENet is uti­ lized for the generation of heatmaps. Some heatmap visualizations are plotted in Fig. 10. The heatmaps are also evaluated on segmentation of anomalies and the qualitative results are shown in Fig. 11. The quanti­ tative results are also reported in Table 7. The colors in the heatmap represent different confidence scores calculated by GradCAM++ through the computation of gradients which can be determined using Eq. (10). The red color signifies the highest confidence of an anomalous region whereas the blue region indicates the normal region. The class C of an image I is identified by referring to the result of the WCENet classifier on the image. It can be deduced from the individual segmentation results produced by both the techniques discussed above individually that the SegNet Fig. 15. Quantitative segmentation results of WCENet localization method on both KID and CVC-CLINIC datasets. Fig. 16. Failed segmentation results (M1 ∩M2) and alternative results by computing union (M1 ∪M2) of segmentation masks produced by Grad-CAM++ (M1) and SegNet (M2). S. Jain et al. Computers in Biology and Medicine 137 (2021) 104789 13 (M2) technique performs better with a Dc score of 0.55 as compared to Grad-CAM++ (M1) with a Dc score of 0.47. The segmentation results are also computed through the fusion of segmentation masks produced by both the methods. Intersection and union of segmentation masks of both the methods are analyzed as shown in Table 8. It can be seen that the intersection of M1 and M2 produces a Dc score of 0.56 which is slightly better than individual Dc scores of both M1 and M2. Few examples of the localization results are shown in Fig. 12 for a qualitative comparison. The localization performance of the proposed model is compared with some state-of-the-art methods. Ghosh et al. [43] have recently re­ ported bleeding segmentation using SegNet [30]. Yuan et al. [32] have suggested a saliency map extraction method in two stages for high­ lighting bleeding regions, where different color channels are blended in the first stage and a saliency map is obtained in the second stage from the visual contrast by using CIE-Lab and HSV color spaces. Kundu et al. [61] have suggested extracting the bleeding region using inter-plane intensity variation on R–B and R-G planes in the normalized RGB color space. Patch-based CNN is exploited in Ref. [28] where the CNN is trained on normal and abnormal patches. Jia et al. [62] have highlighted bleeding regions by training a fully connected neural network. The re­ sults are reported in Fig. 13. Since all these methods are focused on detecting bleeding regions, for a fair comparison of the proposed seg­ mentation method with these methods, only those images are consid­ ered that belong to a vascular class of anomaly. It is found that the results obtained by the proposed method are better than other state-of-the-art methods with the highest FwIoU of 0.87. To validate the performance of the proposed model trained on the KID dataset [52], it is also tested on another publicly available colo­ noscopy dataset known as CVC-CLINIC [63]. CVC-CLINIC dataset con­ sists of only polyp frames extracted from the colonoscopy videos. These frames cover a wide variety of polyps. Along with the frames, the dataset also provides ground truths. The dataset contains 612 images taken from 29 different video sequences. Since CVC-CLINIC contains only polyp images, the WCENet classifier could not be trained on the dataset. Therefore, we have tested the performance of the trained WCENet classifier on CVC-CLINIC. It is observed that the WCENet classifier correctly labels 484 frames out of 612 frames as a polyp. The localization capability of the trained WCENet is also tested on the CVC-CLINIC dataset. Further, the custom SegNet model is separately trained on the CVC-CLINIC dataset, and the quantitative results are listed in Table 9. The qualitative results are also shown in Fig. 14. The performance of WCENet on both the datasets augmented KID and CVC-CLINIC is visu­ alized in Fig. 15. The proposed WCENet performs better in comparison to other methods, but there are situations where the proposed method fails to localize the anomaly. As mentioned earlier, the intersection of the out­ puts by Grad-CAM++ (M1) and SegNet (M2) is taken as the final output mask for producing the segmented output. The localization results are quite close to the results produced by SegNet independently. Therefore, SegNet individually can be adopted for localization. But there are cases when SegNet fails to generate the mask. In those cases, we can use the localization mask generated through Grad-CAM++. Also, there can be situations where both the methods generate non-overlapping masks. In such situations, the union of the masks produced by M1 and M2 may probably help a physician in approximating the probable anomaly re­ gions. In this way, system failure can be minimized. In Fig. 16 some of these cases are demonstrated. 5. Conclusion In the present paper, a deep CNN model WCENet is proposed for the identification and localization of GI anomalies in WCE images. The model operates in two phases. In the first phase, an input image is passed through an attention-based CNN classifier with 11-layers which clas­ sifies the image into one of the four categories namely, inflammatory, polyp, vascular, or normal. If the image is tagged as abnormal, it is passed to the second phase for estimating the anomalous region. Localization network SegNet is supplemented with Grad-CAM++ to produce the localization results. Combining the outcomes of two different localization techniques adds to the reliability of the model. Anomaly localization is the prime requirement for CAD systems in the current scenario of emerging digital healthcare. The proposed model can be applied for the identification and localization of a wide range of anomalies in WCE images. Due to the scarcity of publicly available labeled datasets, experiments are performed only on two datasets, KID [52] and CVC-CLINIC [63]. Comprehensive comparison results with existing approaches demonstrate that the proposed method outperforms other state-of-the-art methods. Although our proposed approach WCE­ Net performs better than legacy methods, there is a room to improve the localization performance in terms of dice score. As future work, more datasets will be considered to yield generalizable results. Declaration of competing interest The authors declare no conflict of interest. Acknowledgment This work is partially supported by the project “Prediction of diseases through computer assisted diagnosis system using images captured by minimally-invasive and non-invasive modalities”, Computer Science and Engineering, PDPM Indian Institute of Information Technology, Design and Manufacturing, Jabalpur India (under ID: SPARC-MHRD- 231). This work is also partially supported by the project IT4Neuro (degeneration), reg. nr. CZ.02.1.01/0.0/0.0/18 069/0010054 and by the project “Smart Solutions in Ubiquitous Computing Environments”, Grant Agency of Excellence, University of Hradec Kralove, Faculty of Informatics and Management, Czech Republic (under ID: UHK-FIM-GE- 2021). References [1] J. Dolz, N. Betrouni, M. Quidet, D. Kharroubi, H.A. Leroy, N. Reyns, L. Massoptier, M. Vermandel, Stacking denoising auto-encoders in a deep network to segment the brainstem on mri in brain cancer patients: a clinical study, Comput. Med. Imag. Graph. 52 (2016) 8–18. [2] M. Habibzadeh, M. Jannesari, Z. Rezaei, H. Baharvand, M. Totonchi, Automatic white blood cell classification using pre-trained deep learning models: resnet and inception, in: Tenth International Conference on Machine Vision (ICMV 2017), vol. 10696, International Society for Optics and Photonics, 2018, 1069612. [3] T. Rahim, M.A. Usman, S.Y. Shin, A survey on contemporary computer-aided tumor, polyp, and ulcer detection methods in wireless capsule endoscopy imaging, Comput. Med. Imag. Graph. 85 (2020), 101767. [4] D. Banik, K. Roy, D. Bhattacharjee, M. Nasipuri, O. Krejcar, Polyp-net: a multimodel fusion network for polyp segmentation, IEEE Transactions on Instrumentation and Measurement 70 (2021) 1–12. [5] B. Li, M.Q.-H. Meng, J.Y. Lau, Computer-aided small bowel tumor detection for capsule endoscopy, Artif. Intell. Med. 52 (1) (2011) 11–16. [6] A. Karargyris, N. Bourbakis, Wireless capsule endoscopy and endoscopic imaging: a survey on various methodologies presented, IEEE Eng. Med. Biol. Mag. 29 (1) (2010) 72–83. [7] G. Iddan, G. Meron, A. Glukhovsky, P. Swain, Wireless capsule endoscopy, Nature 405 (6785) (2000), 417–417. [8] Y. Yuan, J. Wang, B. Li, M.Q.-H. Meng, Saliency based ulcer detection for wireless capsule endoscopy diagnosis, IEEE Trans. Med. Imag. 34 (10) (2015) 2046–2057. [9] X. Jia, M.Q.-H. Meng, A deep convolutional neural network for bleeding detection in wireless capsule endoscopy images, in: 2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), IEEE, 2016, pp. 639–642. [10] Y. Yuan, M.Q.-H. Meng, Deep learning for polyp recognition in wireless capsule endoscopy images, Med. Phys. 44 (4) (2017) 1379–1389. [11] D.K. Iakovidis, S.V. Georgakopoulos, M. Vasilakakis, A. Koulaouzidis, V. P. Plagianakos, Detecting and locating gastrointestinal anomalies using deep learning and iterative cluster unification, IEEE Trans. Med. Imag. 37 (10) (2018) 2196–2210. [12] A. Novoz´amskỳ, J. Flusser, I. Tachecí, L. Sulík, J. Bureˇs, O. Krejcar, Automatic blood detection in capsule endoscopy video, J. Biomed. Opt. 21 (12) (2016), 126007. [13] G. Lv, G. Yan, Z. Wang, Bleeding detection in wireless capsule endoscopy images based on color invariants and spatial pyramids using support vector machines, in: S. Jain et al. Computers in Biology and Medicine 137 (2021) 104789 14 2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, IEEE, 2011, pp. 6643–6646. [14] S.A. Karkanis, D.K. Iakovidis, D. Karras, D. Maroulis, Detection of lesions in endoscopic video using textural descriptors on wavelet domain supported by artificial neural network architectures, in: Proceedings 2001 International Conference on Image Processing (Cat. No. 01CH37205) vol. 2, IEEE, 2001, pp. 833–836. [15] D. Bhattacharjee, A. Seal, S. Ganguly, M. Nasipuri, D.K. Basu, A comparative study of human thermal face recognition based on haar wavelet transform and local binary pattern, Comput. Intell. Neurosci. 2012 (2012), 2012/261089. Article ID 261089. [16] C. Sindhu, V. Valsan, A novel method for automatic detection of inflammatory bowel diseases in wireless capsule endoscopy images, in: 2017 Fourth International Conference on Signal Processing, Communication and Networking (ICSCN), IEEE, 2017, pp. 1–6. [17] D.K. Iakovidis, A. Koulaouzidis, Automatic lesion detection in wireless capsule endoscopy—a simple solution for a complex problem, in: 2014 IEEE International Conference on Image Processing (ICIP), IEEE, 2014, pp. 2236–2240. [18] S. Jain, A. Seal, A. Ojha, O. Krejcar, J. Bureˇs, I. Tachecí, A. Yazidi, Detection of abnormality in wireless capsule endoscopy images using fractal features, Comput. Biol. Med. 127 (2020), 104094. [19] J.-Y. He, X. Wu, Y.-G. Jiang, Q. Peng, R. Jain, Hookworm detection in wireless capsule endoscopy images with deep learning, IEEE Trans. Image Process. 27 (5) (2018) 2379–2392. [20] X. Xing, Y. Yuan, M.Q.-H. Meng, Zoom in lesions for better diagnosis: attention guided deformation network for wce image classification, IEEE Trans. Med. Imag. 39 (2020) 4047–4059. [21] S. Jain, A. Seal, A. Ojha, Deep learning models for anomaly detection in wireless capsule endoscopy video frames: the transfer learning approach, in: Smart Computing: Proceedings of the 1st International Conference on Smart Machine Intelligence and Real-Time Computing (SmartCom 2020), 26-27 June 2020, Pauri, Garhwal, Uttarakhand, India,, CRC Press, 2021, p. 423. [22] X. Jia, M.Q.-H. Meng, Gastrointestinal bleeding detection in wireless capsule endoscopy images using handcrafted and cnn features, in: 2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), IEEE, 2017, pp. 3154–3157. [23] M.A. Khan, S. Kadry, M. Alhaisoni, Y. Nam, Y. Zhang, V. Rajinikanth, M.S. Sarfraz, Computer-aided gastrointestinal diseases analysis from wireless capsule endoscopy: a framework of best features selection, IEEE Access 8 (2020) 132850–132859. [24] G. Litjens, T. Kooi, B.E. Bejnordi, A.A.A. Setio, F. Ciompi, M. Ghafoorian, J.A. Van Der Laak, B. Van Ginneken, C.I. S´anchez, A survey on deep learning in medical image analysis, Med. Image Anal. 42 (2017) 60–88. [25] M.I. Razzak, S. Naz, A. Zaib, Deep learning for medical image processing: overview, challenges and the future, in: Classification in BioApps, Springer, 2018, pp. 323–350. [26] H.-C. Shin, H.R. Roth, M. Gao, L. Lu, Z. Xu, I. Nogues, J. Yao, D. Mollura, R. M. Summers, Deep convolutional neural networks for computer-aided detection: cnn architectures, dataset characteristics and transfer learning, IEEE Trans. Med. Imag. 35 (5) (2016) 1285–1298. [27] A.K. Sekuboyina, S.T. Devarakonda, C.S. Seelamantula, A convolutional neural network approach for abnormality detection in wireless capsule endoscopy, in: 2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017), IEEE, 2017, pp. 1057–1060. [28] V.S. Sadasivan, C.S. Seelamantula, High accuracy patch-level classification of wireless capsule endoscopy images using a convolutional neural network, in: 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), IEEE, 2019, pp. 96–99. [29] Y. Gao, W. Lu, X. Si, Y. Lan, Deep model-based semi-supervised learning way for outlier detection in wireless capsule endoscopy images, IEEE Access 8 (2020) 81621–81632. [30] V. Badrinarayanan, A. Kendall, R. Cipolla, Segnet: a deep convolutional encoder- decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell. 39 (12) (2017) 2481–2495. [31] A. Chattopadhay, A. Sarkar, P. Howlader, V.N. Balasubramanian, Grad-cam++: generalized gradient-based visual explanations for deep convolutional networks, in: 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), IEEE, 2018, pp. 839–847. [32] Y. Yuan, B. Li, M.Q.-H. Meng, Bleeding frame and region detection in the wireless capsule endoscopy video, IEEE.J. Biomed. Health Inf. 20 (2) (2015) 624–630. [33] T. Rahim, S.A. Hassan, S.Y. Shin, A deep convolutional neural network for the detection of polyps in colonoscopy images, Biomed. Signal Process Contr. 68 (2021), 102654. [34] B. Li, M.Q.-H. Meng, Automatic polyp detection for wireless capsule endoscopy images, Expert Syst. Appl. 39 (12) (2012) 10952–10958. [35] D.K. Iakovidis, D.E. Maroulis, S.A. Karkanis, A. Brokos, A comparative study of texture features for the discrimination of gastric polyps in endoscopic video, in: 18th IEEE Symposium on Computer-Based Medical Systems (CBMS’05), IEEE, 2005, pp. 575–580. [36] D.J. Barbosa, J. Ramos, C.S. Lima, Detection of small bowel tumors in capsule endoscopy frames using texture analysis based on the discrete wavelet transform, in: 2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, IEEE, 2008, pp. 3012–3015. [37] H. Chen, S. Wang, Y. Ding, D. Qian, Saliency-based bleeding localization for wireless capsule endoscopy diagnosis, Int. J. Biomed. Imag. 2017 (2017), https:// doi.org/10.1155/2017/8147632. Article ID 8147632. [38] T. Ghosh, S.A. Fattah, K.A. Wahid, Chobs: color histogram of block statistics for automatic bleeding detection in wireless capsule endoscopy video, IEEE.J. Transl. Eng. Health Med. 6 (2018) 1–12. [39] S.K. Shah, P.P. Rajauria, J. Lee, M.E. Celebi, Classification of bleeding images in wireless capsule endoscopy using hsi color domain and region segmentation, in: URI-NE ASEE 2007 Conference, 2007. [40] Y. Yuan, B. Li, M.Q.-H. Meng, Improved bag of feature for automatic polyp detection in wireless capsule endoscopy images, IEEE Trans. Autom. Sci. Eng. 13 (2) (2015) 529–535. [41] S. Sainju, F.M. Bui, K. Wahid, Bleeding detection in wireless capsule endoscopy based on color features from histogram probability, in: 2013 26th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE), IEEE, 2013, pp. 1–4. [42] Y. Cong, S. Wang, J. Liu, J. Cao, Y. Yang, J. Luo, Deep sparse feature selection for computer aided endoscopy diagnosis, Pattern Recogn. 48 (3) (2015) 907–917. [43] T. Ghosh, J. Chakareski, Deep transfer learning for automated intestinal bleeding detection in capsule endoscopy imaging, J. Digit. Imag. (2021) 1–14. [44] X. Li, H. Zhang, X. Zhang, H. Liu, G. Xie, Exploring transfer learning for gastrointestinal bleeding detection on small-size imbalanced endoscopy images, in: 2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), IEEE, 2017, pp. 1994–1997. [45] E. Ribeiro, A. Uhl, G. Wimmer, M. H¨afner, Exploring deep learning and transfer learning for colonic polyp classification, Computational and Mathematical Methods in Medicine 2016 (2016), [46] Y. Shin, H.A. Qadir, L. Aabakken, J. Bergsland, I. Balasingham, Automatic colon polyp detection using region based deep cnn and post learning approaches, IEEE Access 6 (2018) 40950–40962. [47] C. Szegedy, S. Ioffe, V. Vanhoucke, A. Alemi, Inception-v4, Inception-Resnet and the Impact of Residual Connections on Learning, ArXiv Preprint arXiv:1602.07261. [48] S. Bianco, R. Cadene, L. Celona, P. Napoletano, Benchmark analysis of representative deep neural network architectures, IEEE Access 6 (2018) 64270–64277. [49] S. Woo, J. Park, J.-Y. Lee, I.S. Kweon, Cbam: convolutional block attention module, in: Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 3–19. [50] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, A. Torralba, Learning deep features for discriminative localization, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 2921–2929. [51] R.R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, D. Batra, Grad-cam: visual explanations from deep networks via gradient-based localization, in: Proceedings of the IEEE International Conference on Computer Vision, 2017, pp. 618–626. [52] A. Koulaouzidis, D.K. Iakovidis, D.E. Yung, E. Rondonotti, U. Kopylov, J.N. Plevris, E. Toth, A. Eliakim, G. Wurm Johansson, W. Marlicz, G. Mavrogenis, A. Nemeth, H. Thorlacius, G.E. Tontini, KID Project: an internet-based digital video atlas of capsule endoscopy for research purposes, Endosc. Int. Open 5 (6) (2017) E477–E483. [53] S. Seguí, M. Drozdzal, G. Pascual, P. Radeva, C. Malagelada, F. Azpiroz, J. Vitri`a, Generic feature learning for wireless capsule endoscopy analysis, Comput. Biol. Med. 79 (2016) 163–172. [54] V. Vani, K.M. Prashanth, Color image enhancement techniques in wireless capsule endoscopy, in: 2015 International Conference on Trends in Automation, Communications and Computing Technology (I-TACT-15), IEEE, 2015, pp. 1–6. [55] S.V. Georgakopoulos, D.K. Iakovidis, M. Vasilakakis, V.P. Plagianakos, A. Koulaouzidis, Weakly-supervised convolutional learning for detection of inflammatory gastrointestinal lesions, in: 2016 IEEE International Conference on Imaging Systems and Techniques (IST), IEEE, 2016, pp. 510–514. [56] O. Ronneberger, P. Fischer, T. Brox, U-net, Convolutional networks for biomedical image segmentation, in: International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer, 2015, pp. 234–241. [57] H. Zhao, J. Shi, X. Qi, X. Wang, J. Jia, Pyramid scene parsing network, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 2881–2890. [58] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 770–778. [59] K. Simonyan, A. Zisserman, Very Deep Convolutional Networks for Large-Scale Image Recognition, ArXiv Preprint arXiv:1409.1556. [60] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. Andreetto, H. Adam, Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications, ArXiv Preprint arXiv:1704.04861. [61] A.K. Kundu, S.A. Fattah, M.N. Rizve, An automatic bleeding frame and region detection scheme for wireless capsule endoscopy videos based on interplane intensity variation profile in normalized rgb color space, J. Healthc. Eng. 2018 (2018), Article ID 9423062. [62] X. Jia, M.Q.-H. Meng, A study on automated segmentation of blood regions in wireless capsule endoscopy images using fully convolutional networks, in: 2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017), IEEE, 2017, pp. 179–182. [63] J. Bernal, F.J. S´anchez, G. Fern´andez-Esparrach, D. Gil, C. Rodríguez, F. Vilari˜no, Wm-dova maps for accurate polyp highlighting in colonoscopy: validation vs. saliency maps from physicians, Comput. Med. Imag. Graph. 43 (2015) 99–111. S. Jain et al."
Exploring Multilingual Word Embedding Alignments in BERT Models: A Case Study of English and Norwegian,"Aaby, Pernille
and Biermann, Daniel
and Yazidi, Anis
and Mello, Gustavo Borges Moreno e.
and Palumbo, Fabrizio",2023,,,,inproceedings," 
 
 
 
Accepted manuscript 
Aaby, P., Biermann, D., Yazidi, A., Borges Moreno e Mello, G. & Palumbo, F. (2023). Exploring 
Multilingual Word Embedding Alignments in BERT Models: A Case Study of English and 
Norwegian. Lecture Notes in Computer Science (LNCS), 14381, 47-58. 
https://doi.org/10.1007/978-3-031-47994-6_4 
 
 
Published in: 
Lecture Notes in Computer Science (LNCS) 
 
DOI:   
 
https://doi.org/10.1007/978-3-031-47994-6_4 
 
AURA:  
 
https://hdl.handle.net/11250/3122000 
 
Copyright:  
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2023 
 
Available: 
 
08. Nov. 2024 
 Exploring Multilingual Word Embedding Alignments in
BERT Models: A Case Study of English and Norwegian
Pernille Aaby1, Daniel Biermann2, Anis Yazidi1, Gustavo Borges Moreno e Mello1,
and Fabrizio Palumbo1
1 Artificial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi,
Oslo Metropolitan University, Oslo, Norway
2 Centre for Artificial Intelligence Research (CAIR)
Department of ICT, University of Agder, Grimstad, Norway
fabrizio.palumbo@oslomet.no
Abstract. Contextual language models, such as transformers, can solve a wide
range of language tasks ranging from text classification to question answering and
machine translation. Like many deep learning models, the performance heavily
depends on the quality and amount of data available for training. This poses a
problem for low-resource languages, such as Norwegian, that can not provide the
necessary amount of training data. In this article, we investigate the use of mul-
tilingual models as a step toward overcoming the data sparsity problem for mi-
nority languages. In detail, we study how words are represented by multilingual
BERT models across two languages of our interest: English and Norwegian. Our
analysis shows that multilingual models similarly encode English-Norwegian
word pairs. The multilingual model automatically aligns semantics across lan-
guages without supervision. Additionally, our analysis also shows that embed-
ding a word encodes information about the language to which it belongs. We,
therefore, believe that in pre-trained multilingual modelsâ ˘A´Z knowledge from
one language can be transferred to another without direct supervision and help
solve the data sparsity problem for minor languages.
Keywords: Natural Language Processing · Multilingual Bert · Word Alignment
· Data Sparsity.
1
Introduction
Over recent years, the field of AI has made impressive progress regarding the perfor-
mance of natural language processing tasks such as text classification, question answer-
ing, machine translation, or language generation. This progress is mainly driven by
purely data-driven models such as transformers. To encode how words relate to their
context, transformers are pre-trained on vast, unlabeled and mostly monolingual train-
ing corpora. This approach is powerful for languages such as English or Spanish, with
an abundance of language resources consisting in raw text, labeled datasets, and bench-
marks. However, when it comes to low-resource languages, such as Norwegian, the
available language datasets are often limited. Unfortunately, the performance in such
data-driven models and approaches heavily depends on the quality and amount of train-
ing data available. That is, good performance depends on high-quality datasets. At the
This is a post-peer-review, pre-copyedit version of the following conference proceeding: Aaby, P., Biermann, D., Yazidi, A., Mello, G.B.M.e., Palumbo, F. (2023).
Exploring Multilingual Word Embedding Alignments in BERT Models: A Case Study of English and Norwegian. In: Bramer, M., Stahl, F. (eds) Artificial Intelligence XL. SGAI 2023.
Lecture Notes in Computer Science(), vol 14381. Springer, Cham. DOI: https://doi.org/10.1007/978-3-031-47994-6_4 
 written time, there are 2181 matches for English datasets and only 67 for Norwegian
datasets on huggingface.co3. More training data tend to improve the performance of
language models [17,3]. Consequently, monolingual Norwegian language models will
likely not achieve the same performance as monolingual English language models.
Most existing language models today have been trained on monolingual corpora
[7,14], which do not benefit languages with sparse data availability. Isbister et al.[11]
proposed an approach that translates the text from a low-resource language to a high-
resource language. Then, it uses a state-of-the-art performing model trained on high-
resource language to alleviate the data sparsity problem. However, recent work shows
that specific multilingual language models manage to align words from different lan-
guages without learning from parallel data, which machine translation requires [4,15].
Therefore, we pose the questions:
– Can multilingual models relieve the need for monolingual models?
– Can knowledge from one language be transferred to another without parallel data?
In this article, we explore the similarities and dissimilarities between the word represen-
tations in English and Norwegian, using two multilingual language models. To this end,
we use different methods from recent literature and combine them in a comprehensive
study of the case of the English-Norwegian language pair.
To find similarities we evaluate word retrieval performance, from an English source
vocabulary to a Norwegian target vocabulary. To find dissimilarities, we quantify the
accuracy of retrieving the original language from the word representation. All methods
are non-parametric and rely purely on vector proximity. The model architecture we have
used is BERT (Bidirectional Encoder from Transformer) [7] since previous work has
shown its capability to align words automatically [4,16].
We believe that this exploration can provide the research community with a better
understanding of how the information of different languages manifests inside the word
representations of multilingual models and ultimately help improve existing models and
applications that suffer from data sparsity.
2
Related Work
2.1
Multilingual Word Retrieval
Mikolov et al. [22] noticed that the distribution of word embeddings in latent space
showed similar characteristics across different languages. Motivated by the similarity
of distributions, they hypothesized that they could align two distributions with word
embeddings from two different languages to create a bilingual dictionary with word
retrieval. Their technique relied on bilingual parallel corpora. Conneau et al. [6] showed
that it was possible to align two-word embedding distributions from different languages
without any supervision (parallel corpora). They utilized adversarial training to learn a
linear mapping from the source to the target language, alleviating the need for parallel
corpora.
3 !https://huggingface.co/datasets Visited: 19.01.2023
2
 2.2
Multilingual BERT
BERT is a transformer-based [30] model which improved state-of-the-art results on sev-
eral NLP tasks at the time of release [7]. It improved on question-answering tasks like
SQuAD v1.1 [25] and SQuAD v2.0 [24], and language understanding tasks like GLUE
[31] and MutliNLI [33]. The model is trained on vast amounts of text corpora, the orig-
inal English BERT used the English part of Wikipedia [7], but today it is being trained
on bigger collections, even book collections from a whole library [13]. The model has
been trained for several languages like French, Swedish, and Norwegian [20,19,14].
BERT can also be trained in several languages simultaneously to obtain multilingual
understanding. mBERT is one of these models, and it is trained on Wikipedia corpus
for 104 different languages, including English and Norwegian4.
Notram, Norwegian Transformer Model, is a BERT model initialized from mBERT
and further trained on mostly Norwegian book-corpus data [13]. Although the model
is mainly trained on Norwegian corpus, after initialization, the authors estimate that a
portion of 4% is English. The model scores high on Named Entity Recognition both for
the Norwegian language and the English language.
Previous work [4,15] also shows that the semantics of two (and more) languages
align automatically in BERT. So the model does not only represent two languages sep-
arately, but it is also able to encode connections between two languages through shared
semantics of the words, without being trained on parallel data.
2.3
From Contextual to Static Embeddings
In order to benefit from previous benchmarks like SimLex999 [10], WordSim353 [1]
and SimVerb3500 [9] that evaluate semantics, Bommasani et al. [2] distilled a set of
static word embeddings from contextual word embeddings. This way the results could
be compared to traditional word embeddings [21,23,12]. To create the static word em-
beddings from BERT they tried different aggregation and pooling strategies. The best-
performing aggregation method was to take the average over several contexts, also re-
ferred to as AOC (Average Over Context). They also used mean pooling, taking the
mean of all token representations over subtokens of a word in case a word consists of
more than one token.
2.4
Probing BERT
Probing BERT has become a popular area of research to better justify its success and
understand the model better so it is easier to improve the architecture [27]. It entails
creating a simple classifier and using the features from the pre-trained model. If the
simple classifier manages to solve the task, then we can assume that the necessary
information is already within the features we extract.
From previous work, we know that BERT represents words with information about
syntax and semantics [27]. Tenney et al. [28] discovered that BERT hierarchically learns
information that corresponds to the traditional NLP (Natural Language Processing)
4 !https://huggingface.co/bert-base-multilingual-cased
3
 pipeline. Starting with local syntax structure such as POS tagging and parsing in the
lower layers, while finding named entity recognition, semantic roles, and co-reference
are information encoded later in the model in the respective order. Similar discoveries
can be found in other works as well [16,29].
Naturally, since BERT is a contextual model representing a word based on not only
itself but also the surrounding words, the question of whether one could distinguish
different meanings of an ambiguous through the representation arose. In previous work
[32,18] they find that ambiguous words divide different meanings into clusters from the
contextual representation, although it is not always the same clusters as we would have
defined from a human perspective.
3
Methods
Our analysis examines similarities and differences between word representations in two
languages. Similarities are found through static word retrieval and differences through
language detection. Our non-parametric method only relies on finding the most similar
embedding(s) from a source word to a target collection. We used KNN (K- Nearest
Neighbours) with cosine similarity to find the most similar vectors.
3.1
Static Word Retrieval
Following the work by Bommasani et al. [2] we created a static set of word embeddings
by taking the AOC of several contextual embeddings for a term t. The contextual em-
bedding for word t is obtained from a context ct ∈Ct, where each ct is two sentences
from the relevant language corpus.
st = 1
Nt
N
X
n=1
wtn
(1)
wtn is the nth contextual embedding for the number of contexts Nt = |Ct|. For words
that consist of more than one workpiece, we used mean pooling, taking the mean of all
subtokens, to aggregate all token embeddings.
wtn = 1
It
I
X
i=1
pti
(2)
pti is the ith token in the word. We created static embeddings for all 13 intermediate
representations from BERT, one after all the 12 stacked layers and the input layer. We
aimed to retrieve a Norwegian target word from an English source word. The objective
becomes, for each of the English word representations si−en, evaluate the cosine simi-
larity to all the Norwegian word representations sj−no, rank the similarities, and return
the top(@) match(s). If a translation of the English word is one of the returned words,
we achieved a correct word retrieval.
k-neighbours(i) = argmax
j
sim(si−en, sj−no)
(3)
4
 yi =
(
1,
if k-neighbours(i) ∈translation(sno)
0,
otherwise
(4)
accuracy static word retrieval = 1
T
T
X
i=1
yi
(5)
T is the number of terms in the English vocabulary.
Liu et al. [15] test if word retrieval performance increases by doing a mean shift.
Mean shift entails shifting from an English source word to be closer to a Norwegian
target word by first subtracting the mean of all the English word embeddings and then
adding the mean of all the Norwegian word embeddings. We define a language vector
as the mean of all the static word embeddings in one vocabulary.
Ll = 1
T
T
X
t=1
wt
(6)
l ∈{English, Norwegian} and T is the number of words in each vocabulary. Mean
shift:
st,en−>no = st,en −Len + Lno
(7)
Len and Lno are language vectors for English and Norwegian respectively.
yi−l =





1,
if
sim(si−l, Len) > sim(si−l, Lno)
and
l = en
1,
elif
sim(si−l, Len) < sim(si−l, Lno)
and
l = no
0,
otherwise
(8)
accuracy language detection = 1
2T
T
X
i=1
yi−en + 1
2T
T
X
i=1
yi−no
(9)
3.2
Language Detection
Motivated by the fact that words from the same language could be aggregated to a lan-
guage vector, we asked the question:
Can we detect the language of a word based on the similarity to the language embed-
dings?
We detected the language by evaluating which language vector a word representation is
most similar to.
3.3
Data
The Norwegian News Corpus5 is used as the raw text corpora for the Norwegian part.
We only used the part in Norwegian bokmÃˇel (not nynorsk). The articles in the dataset
5 !https://www.nb.no/sprakbanken/ressurskatalog/oai-nb-no-sbr-4/
5
 are from multiple different newspapers, such as “VG”, “Aftenposten” and “Dagens
nÃ˛eringsliv” etc., collected from the years 1998 to 2019. We chose a set of contexts
from the corpus for each word in our Norwegian vocabulary between 100 and 500. A
context is defined as two sentences.
The vocabulary is restricted to only include the 50,000 most common words from
the Norwegian News Corpus. In addition, we checked that the word is present in a
Norwegian wordlist for BokmÃˇel 6.
To evaluate the word retrieval from English to Norwegian, we have used the English-
Norwegian word benchmark from MUSE 7 [6]. We only used the word pairs, where the
Norwegian word is in our top 50,000 vocabularies, and the English word is present
in the Brown corpus 8 [8]. Some English words have more than one Norwegian word
translation. We define a correct word retrieval as at least one match.
The Brown corpus gives the context sentences for the English word embedding vo-
cabulary. The number of contexts for a word is the number of times a word stands in the
Brown corpus but a maximum of 500 times. We only obtained static word embeddings
for the words in the MUSE benchmark. The MUSE-filtered vocabulary ended up with
approximately 12,000 English source words.
4
Results
4.1
Static Word Retrieval
In Figure 1 we report the results of the English to Norwegian word retrieval using
KNN and cosine similarity. We compare the performance of both mBERT (Figure 1a)
and Notram (Figure 1c) for different numbers of top matches (@1,@3,@10). Notram
achieved better accuracy than mBERT in general. The middle layers seem to perform
best for both models, with Notram achieving around 50% at @1 match and more than
70% accuracy when using the @10 matches at layer 7. In addition, for the Notram
model. we notice a dip in performance for layer 11. Overall, we argue that BERT models
are capable of aligning semantics across English and Norwegian without using any
supervised datasets with parallel sentences.
4.2
Static Word Retrieval with Mean Shift
Figure 1b and Figure 1d show the static word retrieval performances when adjusted
with the mean shift. To illustrate the impact of the mean shift on the word retrieval per-
formance better, the performance increase between the shifted and non-shifted model
is depicted by the dashed lines. We can see that the overall influence of the mean shift
on performance is relatively low across all layers. When mean shifting, the model re-
tains word retrieval accuracy better from the middle layers to the subsequent layers than
without the mean shift. The maximum word retrieval performance increase is reached
in layer 11 for the Notram model, improving by 8% for K at @1, @3, and @10. Thus,
6 !https://www.nb.no/sprakbanken/en/resource-catalogue/oai-nb-no-sbr-23/
7 !https://github.com/facebookresearch/MUSE
8 !https://www.nltk.org/nltk_data/
6
 (a) mBERT
(b) mBERT, shifted
//
(c) Notram
(d) Notram, shifted
Fig. 1: Static word retrieval performance from English to Norwegian with layer-wise
performance accuracy with and without mean shift. The lower dashed lines depict the
performance increase when using the mean shift. The star marker shows at which layer
the performance peaked. Both models experience the highest performance increase in
layer 11 for all chosen @matches.
the mean shift seems to alleviate the cause of the performance dip seen before in later
layers.
4.3
Language Detection
Figure 2 reports the results from the language detection experiment. The non-parametric
method clearly shows that it is possible to find the language of a word using this method
as the performance reaches almost 100% in the top-performing layer. The language
detection accuracy reaches values above 95% for both models as soon as layer 1. This
strongly indicates that the closest language vector can serve as a strong predictor for the
language of the embedding.
4.4
Both Semantics and Language Properties can Cluster
For a more qualitative inspection of the word representations, Figure 3 illustrates both
semantic alignment and language properties between English and Norwegian. The top
7
 (a) mBERT: Language Belonging.
(b) Notram
Fig. 2: Layer wise language detection performance. The lighter line (circle) describes
the prediction accuracy for the English vocabulary, the darkest line (square) describes
the prediction accuracy for the Norwegian language and the line of intermediate shade
(triangle) describes the combined prediction accuracy of language detection. The stars
mark in which layer the performance peaks.
graph Figure 3a, inspired by previous work on semantic alignment in BERT [4], shows a
plot comparing a set of 5 words in each English and Norwegian, respectively. The words
were taken from the parallel corpus with sentences from riksrevisjonen9[26]. We can
observe that all word pairs are clustering together, indicating the semantic alignment of
the word embeddings between the languages.
In the bottom graph Figure 3b we see two sets of 500 static word embeddings from
each language. We can notice a clear clustering of the two languages. In both graphs,
we reduce the embedding dimension to two dimensions with the t-SNE method. This
further solidifies that BERT models are able to align semantics across English and Nor-
wegian without using any supervised data
5
Discussion
Our analysis shows that layers 5-9 (middle layers) have the highest accuracy on static
word retrieval. This result is in line with previous work on semantic similarity [5].
We argue that the best-performing layers in semantic similarity will also be the best-
performing layers in semantic alignment between two languages. Although we observe
a clear separation between languages in the word representation space, the mean shift
method did not significantly impact the word retrieval accuracy. In layer 11, the accu-
racy does increase by around 8% in the Notram model. However, in the best performing
layer of the same model, layer 7 (or 5), the increase is only around 1%. We consider
this a slight change since the accuracy at @1 is around 50%. Overall, the word retrieval
9 !https://www.elrc-share.eu/repository/browse/bilingual-english-norwegian-parallel-corpus-f
rom-the-office-of-the-auditor-general-riksrevisjonen-website/a5d2470201e311e9b7d400155
d0267060fffdc9258a741659ce9e52ef15a7c26/
8
 (a) Visualizing contextual word embeddings for word pairs in English and
Norwegian. Contextual embeddings taken from layer 8 of the Notram model
and the English contextual embeddings have experienced a mean shift. The
word embeddings are reduced to 2D with t-SNE. The darker colored markers
show contextual word embeddings for Norwegian while the lighter color show
contextual embedding for English. Each word pair has its own marker.
(b) 500 random words from Norwegian and English vocabulary respectively.
The static word embeddings are from Notram layer 12. The word embeddings
are reduced to 2D with t-SNE. Lighter points correspond to English embed-
dings and darkest points correspond to Norwegian embeddings.
Fig. 3: Visualizing static and contextual word embeddings from BERT
9
 results suggest that the hypothesis that translating one language to another in the word
representation space by looking at the closest matched embedding of the other lan-
guage is a promising approach. Though, the low impact of the mean shift indicates that
the translation from one language to another is not as simple as shifting the embedding
by a simple mean language vector. This warrants further investigation into better meth-
ods to create language vector representations that might improve the impact of such a
language vector shift. Nevertheless, the language vectors from the mean shift analysis
remain strong predictors for identifying the language of an embedding as can be seen
by the strong performance results of our language detection analysis.
It is noteworthy that static word retrieval does not deal with ambiguous words. Both
language vocabularies most likely contain words with multiple meanings, leading to a
conflation of meaning in the embedding. Conflated meanings most likely affected word
retrieval since the English and Norwegian corpus do not provide the same contexts, and
a word representation can be conflated with different meanings depending on the text
corpus. In addition, words within each language can have different meanings. There-
fore, an ambiguous word can often be detected because it will translate to different
words in another language depending on the context. To deal with this downside, one
would have to include a more nuanced analysis of either sense or a word pair from the
same context. We believe that ambiguous words have a negative impact on accuracy
as we could observe significantly better results when considering @3 and @10 nearest
neighbours, with an increase of more than a 20% going from @1 to @10.
Norwegian is a language that borrows many words and phrases from English. It
can be single words like ""skateboard"" or whole phrases like movie titles. Even though
we filtered out sentences detected as English from the Norwegian text corpus, single
words and smaller phrases may have been hard to remove. The effect could be English
noise in the Norwegian part of the corpus and hence an effect in language detection.
mBERT outperforms Notram in the subsequent layers of the model in detecting the
correct language, and it achieves close to 100% accuracy. However, we question if the
accuracy is this high because there might exist English noise in the Norwegian corpus,
which would mean that the accuracy should not be 100%. A better evaluation dataset
could be used to inspect this effect further.
6
Conclusion
In this exploratory analysis, we have shown that BERT’s word representations automat-
ically align semantics across English and Norwegian. We showed this with an accuracy
of 50% for @1 nearest neighbor and an accuracy of more than 70 % for @10 nearest
neighbor on the word retrieval task. In addition, we found that language is encoded in
the word representation: We could detect the correct language of a word, with close to
100% accuracy, only by looking at its proximity to the two language vectors for English
and Norwegian, respectively. We demonstrate that the model can align semantics and
learn language properties by training on only raw text data (no parallel sentences).
We believe that the combination of automatic language detection and word re-
trieval between language embeddings allows for knowledge to be transferred between
languages, ultimately helping alleviate the data sparsity problem in low-resource lan-
10
 guages, such as Norwegian. While our results show promising tendencies, further in-
vestigations into reaching higher word retrieval accuracies and better aligning language
vectors are warranted to make this approach reliable. We hope that our findings moti-
vate new ways of using multilingual models and inspire more research in training and
investigating multilingual models for low-resource languages.
References
1. Agirre, E., Alfonseca, E., Hall, K., Kravalova, J., Pasca, M., Soroa, A.: A study on similarity
and relatedness using distributional and wordnet-based approaches (2009)
2. Bommasani, R., Davis, K., Cardie, C.: Interpreting Pretrained Contextualized Representa-
tions via Reductions to Static Embeddings. In: Proceedings of the 58th Annual Meeting of
the Association for Computational Linguistics. pp. 4758–4781 (2020)
3. Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A.,
Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan,
T., Child, R., Ramesh, A., Ziegler, D.M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E.,
Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever,
I., Amodei, D.: Language Models are Few-Shot Learners. arXiv preprint arXiv:2005.14165
(2020)
4. Cao, S., Kitaev, N., Klein, D.: Multilingual alignment of contextual word representations.
arXiv preprint arXiv:2002.03518 (2020)
5. Chronis, G., Erk, K.: When is a bishop not like a rook? When itâ ˘A´Zs like a rabbi! Multi-
prototype BERT embeddings for estimating semantic relationships. In: Proceedings of the
24th Conference on Computational Natural Language Learning. pp. 227–244 (2020)
6. Conneau, A., Lample, G., Ranzato, M., Denoyer, L., Jégou, H.: Word translation without
parallel data. arXiv preprint arXiv:1710.04087 (2017)
7. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of deep bidirectional
transformers for language understanding. NAACL HLT 2019 - 2019 Conference of the
North American Chapter of the Association for Computational Linguistics: Human Lan-
guage Technologies - Proceedings of the Conference 1(Mlm), 4171–4186 (2019)
8. Francis, W.N., Kucera, H.: Brown corpus manual. Letters to the Editor 5(2), 7 (1979)
9. Gerz, D., Vuli´c, I., Hill, F., Reichart, R., Korhonen, A.: Simverb-3500: A large-scale evalua-
tion set of verb similarity. arXiv preprint arXiv:1608.00869 (2016)
10. Hill, F., Reichart, R., Korhonen, A.: Simlex-999: Evaluating semantic models with (genuine)
similarity estimation. Computational Linguistics 41(4), 665–695 (2015)
11. Isbister, T., Carlsson, F., Sahlgren, M.: Should we Stop Training More Monolingual Models,
and Simply Use Machine Translation Instead? arXiv preprint arXiv:2104.10441 (2021)
12. Joulin, A., Grave, E., Bojanowski, P., Mikolov, T.: Bag of tricks for efficient text classifi-
cation. In: 15th Conference of the European Chapter of the Association for Computational
Linguistics, EACL 2017 - Proceedings of Conference. vol. 2 (2017). https://doi.org/10.186
53/v1/e17-2068
13. Kummervold, P.E., la Rosa, J., Wetjen, F., Brygfjeld, S.A.: Operationalizing a national dig-
ital library: The case for a norwegian transformer model. arXiv preprint arXiv:2104.09617
(2021)
14. Kutuzov, A., Barnes, J., Velldal, E., Øvrelid, L., Oepen, S.: Large-scale contextualised lan-
guage modelling for norwegian. arXiv preprint arXiv:2104.06546 (2021)
15. Liu, C.L., Hsu, T.Y., Chuang, Y.S., Lee, H.Y.: A study of cross-lingual ability and language-
specific information in multilingual BERT. arXiv preprint arXiv:2004.09205 (2020)
11
 16. Liu, N.F., Gardner, M., Belinkov, Y., Peters, M.E., Smith, N.A.: Linguistic knowledge and
transferability of contextual representations. arXiv preprint arXiv:1903.08855 (2019)
17. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer,
L., Stoyanov, V.: RoBERTa: A Robustly Optimized BERT Pretraining Approach. CoRR
abs/1907.1 (2019), http://arxiv.org/abs/1907.11692
18. Loureiro, D., Rezaee, K., Pilehvar, M.T., Camacho-Collados, J.: Analysis and Evaluation
of Language Models for Word Sense Disambiguation. Computational Linguistics pp. 1–55
(2021)
19. Malmsten, M., Börjeson, L., Haffenden, C.: Playing with Words at the National Library of
Sweden–Making a Swedish BERT. arXiv preprint arXiv:2007.01658 (2020)
20. Martin, L., Muller, B., Suárez, P.J.O., Dupont, Y., Romary, L., de La Clergerie, Ã.V.,
Seddah, D., Sagot, B.: CamemBERT: a tasty French language model. arXiv preprint
arXiv:1911.03894 (2019)
21. Mikolov, T., Chen, K., Corrado, G., Dean, J.: Efficient estimation of word representations
in vector space. 1st International Conference on Learning Representations, ICLR 2013 -
Workshop Track Proceedings ICLR 2013, 1–12 (2013), https://arxiv.org/abs/1301.3781
22. Mikolov, T., Le, Q.V., Sutskever, I.: Exploiting similarities among languages for machine
translation. arXiv preprint arXiv:1309.4168 (2013)
23. Pennington, J., Socher, R., Manning, C.D.: GloVe: Global vectors for word representation.
In: EMNLP 2014 - 2014 Conference on Empirical Methods in Natural Language Processing,
Proceedings of the Conference (2014). https://doi.org/10.3115/v1/d14-1162
24. Rajpurkar, P., Jia, R., Liang, P.: Know what you don’t know: Unanswerable questions for
SQuAD. arXiv preprint arXiv:1806.03822 (2018)
25. Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P.: SQuad: 100,000+ questions for machine
comprehension of text. EMNLP 2016 - Conference on Empirical Methods in Natural Lan-
guage Processing, Proceedings (ii), 2383–2392 (2016). https://doi.org/10.18653/v1/d16-126
4
26. Riksrevisjonen: Bilingual English-Norwegian parallel corpus from the Office of the Auditor
General (Riksrevisjonen) website â ˘A¸S ELRC-SHARE (2018), https://www.elrc-share.eu/re
pository/browse/bilingual-english-norwegian-parallel-corpus-from-the-office-of-the-audit
or-general-riksrevisjonen-website/a5d2470201e311e9b7d400155d0267060fffdc9258a741
659ce9e52ef15a7c26/
27. Rogers, A., Kovaleva, O., Rumshisky, A.: A primer in bertology: What we know about how
bert works. Transactions of the Association for Computational Linguistics 8, 842–866 (2020)
28. Tenney, I., Das, D., Pavlick, E.: BERT rediscovers the classical NLP pipeline. arXiv preprint
arXiv:1905.05950 (2019)
29. Tenney, I., Xia, P., Chen, B., Wang, A., Poliak, A., McCoy, R.T., Kim, N., Van Durme,
B., Bowman, S.R., Das, D., others: What do you learn from context? probing for sentence
structure in contextualized word representations. arXiv preprint arXiv:1905.06316 (2019)
30. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Å.,
Polosukhin, I.: Attention is all you need. Advances in Neural Information Processing Sys-
tems 2017-Decem(Nips), 5999–6009 (2017)
31. Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., Bowman, S.R.: GLUE: A multi-
task benchmark and analysis platform for natural language understanding. arXiv preprint
arXiv:1804.07461 (2018)
32. Wiedemann, G., Remus, S., Chawla, A., Biemann, C.: Does BERT make any sense? In-
terpretable word sense disambiguation with contextualized embeddings. arXiv preprint
arXiv:1909.10430 (2019)
33. Williams, A., Nangia, N., Bowman, S.R.: A broad-coverage challenge corpus for sentence
understanding through inference. arXiv preprint arXiv:1704.05426 (2017)
12
",,doc12,"Accepted manuscript Aaby, P., Biermann, D., Yazidi, A., Borges Moreno e Mello, G. & Palumbo, F. (2023). Exploring Multilingual Word Embedding Alignments in BERT Models: A Case Study of English and Norwegian. Lecture Notes in Computer Science (LNCS), 14381, 47-58. Published in: Lecture Notes in Computer Science (LNCS) DOI: AURA: Copyright: © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023 Available: 08. Nov. 2024 Exploring Multilingual Word Embedding Alignments in BERT Models: A Case Study of English and Norwegian Pernille Aaby1, Daniel Biermann2, Anis Yazidi1, Gustavo Borges Moreno e Mello1, and Fabrizio Palumbo1 1 Artificial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi, Oslo Metropolitan University, Oslo, Norway 2 Centre for Artificial Intelligence Research (CAIR) Department of ICT, University of Agder, Grimstad, Norway fabrizio.palumbo@oslomet.no Abstract. Contextual language models, such as transformers, can solve a wide range of language tasks ranging from text classification to question answering and machine translation. Like many deep learning models, the performance heavily depends on the quality and amount of data available for training. This poses a problem for low-resource languages, such as Norwegian, that can not provide the necessary amount of training data. In this article, we investigate the use of mul- tilingual models as a step toward overcoming the data sparsity problem for mi- nority languages. In detail, we study how words are represented by multilingual BERT models across two languages of our interest: English and Norwegian. Our analysis shows that multilingual models similarly encode English-Norwegian word pairs. The multilingual model automatically aligns semantics across lan- guages without supervision. Additionally, our analysis also shows that embed- ding a word encodes information about the language to which it belongs. We, therefore, believe that in pre-trained multilingual modelsâ ˘A´Z knowledge from one language can be transferred to another without direct supervision and help solve the data sparsity problem for minor languages. Keywords: Natural Language Processing · Multilingual Bert · Word Alignment · Data Sparsity. 1 Introduction Over recent years, the field of AI has made impressive progress regarding the perfor- mance of natural language processing tasks such as text classification, question answer- ing, machine translation, or language generation. This progress is mainly driven by purely data-driven models such as transformers. To encode how words relate to their context, transformers are pre-trained on vast, unlabeled and mostly monolingual train- ing corpora. This approach is powerful for languages such as English or Spanish, with an abundance of language resources consisting in raw text, labeled datasets, and bench- marks. However, when it comes to low-resource languages, such as Norwegian, the available language datasets are often limited. Unfortunately, the performance in such data-driven models and approaches heavily depends on the quality and amount of train- ing data available. That is, good performance depends on high-quality datasets. At the This is a post-peer-review, pre-copyedit version of the following conference proceeding: Aaby, P., Biermann, D., Yazidi, A., Mello, G.B.M.e., Palumbo, F. (2023). Exploring Multilingual Word Embedding Alignments in BERT Models: A Case Study of English and Norwegian. In: Bramer, M., Stahl, F. (eds) Artificial Intelligence XL. SGAI 2023. Lecture Notes in Computer Science(), vol 14381. Springer, Cham. DOI: written time, there are 2181 matches for English datasets and only 67 for Norwegian datasets on huggingface.co3. More training data tend to improve the performance of language models [17,3]. Consequently, monolingual Norwegian language models will likely not achieve the same performance as monolingual English language models. Most existing language models today have been trained on monolingual corpora [7,14], which do not benefit languages with sparse data availability. Isbister et al.[11] proposed an approach that translates the text from a low-resource language to a high- resource language. Then, it uses a state-of-the-art performing model trained on high- resource language to alleviate the data sparsity problem. However, recent work shows that specific multilingual language models manage to align words from different lan- guages without learning from parallel data, which machine translation requires [4,15]. Therefore, we pose the questions: – Can multilingual models relieve the need for monolingual models? – Can knowledge from one language be transferred to another without parallel data? In this article, we explore the similarities and dissimilarities between the word represen- tations in English and Norwegian, using two multilingual language models. To this end, we use different methods from recent literature and combine them in a comprehensive study of the case of the English-Norwegian language pair. To find similarities we evaluate word retrieval performance, from an English source vocabulary to a Norwegian target vocabulary. To find dissimilarities, we quantify the accuracy of retrieving the original language from the word representation. All methods are non-parametric and rely purely on vector proximity. The model architecture we have used is BERT (Bidirectional Encoder from Transformer) [7] since previous work has shown its capability to align words automatically [4,16]. We believe that this exploration can provide the research community with a better understanding of how the information of different languages manifests inside the word representations of multilingual models and ultimately help improve existing models and applications that suffer from data sparsity. 2 Related Work 2.1 Multilingual Word Retrieval Mikolov et al. [22] noticed that the distribution of word embeddings in latent space showed similar characteristics across different languages. Motivated by the similarity of distributions, they hypothesized that they could align two distributions with word embeddings from two different languages to create a bilingual dictionary with word retrieval. Their technique relied on bilingual parallel corpora. Conneau et al. [6] showed that it was possible to align two-word embedding distributions from different languages without any supervision (parallel corpora). They utilized adversarial training to learn a linear mapping from the source to the target language, alleviating the need for parallel corpora. 3 ! Visited: 19.01.2023 2 2.2 Multilingual BERT BERT is a transformer-based [30] model which improved state-of-the-art results on sev- eral NLP tasks at the time of release [7]. It improved on question-answering tasks like SQuAD v1.1 [25] and SQuAD v2.0 [24], and language understanding tasks like GLUE [31] and MutliNLI [33]. The model is trained on vast amounts of text corpora, the orig- inal English BERT used the English part of Wikipedia [7], but today it is being trained on bigger collections, even book collections from a whole library [13]. The model has been trained for several languages like French, Swedish, and Norwegian [20,19,14]. BERT can also be trained in several languages simultaneously to obtain multilingual understanding. mBERT is one of these models, and it is trained on Wikipedia corpus for 104 different languages, including English and Norwegian4. Notram, Norwegian Transformer Model, is a BERT model initialized from mBERT and further trained on mostly Norwegian book-corpus data [13]. Although the model is mainly trained on Norwegian corpus, after initialization, the authors estimate that a portion of 4% is English. The model scores high on Named Entity Recognition both for the Norwegian language and the English language. Previous work [4,15] also shows that the semantics of two (and more) languages align automatically in BERT. So the model does not only represent two languages sep- arately, but it is also able to encode connections between two languages through shared semantics of the words, without being trained on parallel data. 2.3 From Contextual to Static Embeddings In order to benefit from previous benchmarks like SimLex999 [10], WordSim353 [1] and SimVerb3500 [9] that evaluate semantics, Bommasani et al. [2] distilled a set of static word embeddings from contextual word embeddings. This way the results could be compared to traditional word embeddings [21,23,12]. To create the static word em- beddings from BERT they tried different aggregation and pooling strategies. The best- performing aggregation method was to take the average over several contexts, also re- ferred to as AOC (Average Over Context). They also used mean pooling, taking the mean of all token representations over subtokens of a word in case a word consists of more than one token. 2.4 Probing BERT Probing BERT has become a popular area of research to better justify its success and understand the model better so it is easier to improve the architecture [27]. It entails creating a simple classifier and using the features from the pre-trained model. If the simple classifier manages to solve the task, then we can assume that the necessary information is already within the features we extract. From previous work, we know that BERT represents words with information about syntax and semantics [27]. Tenney et al. [28] discovered that BERT hierarchically learns information that corresponds to the traditional NLP (Natural Language Processing) 4 ! 3 pipeline. Starting with local syntax structure such as POS tagging and parsing in the lower layers, while finding named entity recognition, semantic roles, and co-reference are information encoded later in the model in the respective order. Similar discoveries can be found in other works as well [16,29]. Naturally, since BERT is a contextual model representing a word based on not only itself but also the surrounding words, the question of whether one could distinguish different meanings of an ambiguous through the representation arose. In previous work [32,18] they find that ambiguous words divide different meanings into clusters from the contextual representation, although it is not always the same clusters as we would have defined from a human perspective. 3 Methods Our analysis examines similarities and differences between word representations in two languages. Similarities are found through static word retrieval and differences through language detection. Our non-parametric method only relies on finding the most similar embedding(s) from a source word to a target collection. We used KNN (K- Nearest Neighbours) with cosine similarity to find the most similar vectors. 3.1 Static Word Retrieval Following the work by Bommasani et al. [2] we created a static set of word embeddings by taking the AOC of several contextual embeddings for a term t. The contextual em- bedding for word t is obtained from a context ct ∈Ct, where each ct is two sentences from the relevant language corpus. st = 1 Nt N X n=1 wtn (1) wtn is the nth contextual embedding for the number of contexts Nt = |Ct|. For words that consist of more than one workpiece, we used mean pooling, taking the mean of all subtokens, to aggregate all token embeddings. wtn = 1 It I X i=1 pti (2) pti is the ith token in the word. We created static embeddings for all 13 intermediate representations from BERT, one after all the 12 stacked layers and the input layer. We aimed to retrieve a Norwegian target word from an English source word. The objective becomes, for each of the English word representations si−en, evaluate the cosine simi- larity to all the Norwegian word representations sj−no, rank the similarities, and return the top(@) match(s). If a translation of the English word is one of the returned words, we achieved a correct word retrieval. k-neighbours(i) = argmax j sim(si−en, sj−no) (3) 4 yi = ( 1, if k-neighbours(i) ∈translation(sno) 0, otherwise (4) accuracy static word retrieval = 1 T T X i=1 yi (5) T is the number of terms in the English vocabulary. Liu et al. [15] test if word retrieval performance increases by doing a mean shift. Mean shift entails shifting from an English source word to be closer to a Norwegian target word by first subtracting the mean of all the English word embeddings and then adding the mean of all the Norwegian word embeddings. We define a language vector as the mean of all the static word embeddings in one vocabulary. Ll = 1 T T X t=1 wt (6) l ∈{English, Norwegian} and T is the number of words in each vocabulary. Mean shift: st,en−>no = st,en −Len + Lno (7) Len and Lno are language vectors for English and Norwegian respectively. yi−l =      1, if sim(si−l, Len) > sim(si−l, Lno) and l = en 1, elif sim(si−l, Len) < sim(si−l, Lno) and l = no 0, otherwise (8) accuracy language detection = 1 2T T X i=1 yi−en + 1 2T T X i=1 yi−no (9) 3.2 Language Detection Motivated by the fact that words from the same language could be aggregated to a lan- guage vector, we asked the question: Can we detect the language of a word based on the similarity to the language embed- dings? We detected the language by evaluating which language vector a word representation is most similar to. 3.3 Data The Norwegian News Corpus5 is used as the raw text corpora for the Norwegian part. We only used the part in Norwegian bokmÃˇel (not nynorsk). The articles in the dataset 5 ! 5 are from multiple different newspapers, such as “VG”, “Aftenposten” and “Dagens nÃ˛eringsliv” etc., collected from the years 1998 to 2019. We chose a set of contexts from the corpus for each word in our Norwegian vocabulary between 100 and 500. A context is defined as two sentences. The vocabulary is restricted to only include the 50,000 most common words from the Norwegian News Corpus. In addition, we checked that the word is present in a Norwegian wordlist for BokmÃˇel 6. To evaluate the word retrieval from English to Norwegian, we have used the English- Norwegian word benchmark from MUSE 7 [6]. We only used the word pairs, where the Norwegian word is in our top 50,000 vocabularies, and the English word is present in the Brown corpus 8 [8]. Some English words have more than one Norwegian word translation. We define a correct word retrieval as at least one match. The Brown corpus gives the context sentences for the English word embedding vo- cabulary. The number of contexts for a word is the number of times a word stands in the Brown corpus but a maximum of 500 times. We only obtained static word embeddings for the words in the MUSE benchmark. The MUSE-filtered vocabulary ended up with approximately 12,000 English source words. 4 Results 4.1 Static Word Retrieval In Figure 1 we report the results of the English to Norwegian word retrieval using KNN and cosine similarity. We compare the performance of both mBERT (Figure 1a) and Notram (Figure 1c) for different numbers of top matches (@1,@3,@10). Notram achieved better accuracy than mBERT in general. The middle layers seem to perform best for both models, with Notram achieving around 50% at @1 match and more than 70% accuracy when using the @10 matches at layer 7. In addition, for the Notram model. we notice a dip in performance for layer 11. Overall, we argue that BERT models are capable of aligning semantics across English and Norwegian without using any supervised datasets with parallel sentences. 4.2 Static Word Retrieval with Mean Shift Figure 1b and Figure 1d show the static word retrieval performances when adjusted with the mean shift. To illustrate the impact of the mean shift on the word retrieval per- formance better, the performance increase between the shifted and non-shifted model is depicted by the dashed lines. We can see that the overall influence of the mean shift on performance is relatively low across all layers. When mean shifting, the model re- tains word retrieval accuracy better from the middle layers to the subsequent layers than without the mean shift. The maximum word retrieval performance increase is reached in layer 11 for the Notram model, improving by 8% for K at @1, @3, and @10. Thus, 6 ! 7 ! 8 ! 6 (a) mBERT (b) mBERT, shifted // (c) Notram (d) Notram, shifted Fig. 1: Static word retrieval performance from English to Norwegian with layer-wise performance accuracy with and without mean shift. The lower dashed lines depict the performance increase when using the mean shift. The star marker shows at which layer the performance peaked. Both models experience the highest performance increase in layer 11 for all chosen @matches. the mean shift seems to alleviate the cause of the performance dip seen before in later layers. 4.3 Language Detection Figure 2 reports the results from the language detection experiment. The non-parametric method clearly shows that it is possible to find the language of a word using this method as the performance reaches almost 100% in the top-performing layer. The language detection accuracy reaches values above 95% for both models as soon as layer 1. This strongly indicates that the closest language vector can serve as a strong predictor for the language of the embedding. 4.4 Both Semantics and Language Properties can Cluster For a more qualitative inspection of the word representations, Figure 3 illustrates both semantic alignment and language properties between English and Norwegian. The top 7 (a) mBERT: Language Belonging. (b) Notram Fig. 2: Layer wise language detection performance. The lighter line (circle) describes the prediction accuracy for the English vocabulary, the darkest line (square) describes the prediction accuracy for the Norwegian language and the line of intermediate shade (triangle) describes the combined prediction accuracy of language detection. The stars mark in which layer the performance peaks. graph Figure 3a, inspired by previous work on semantic alignment in BERT [4], shows a plot comparing a set of 5 words in each English and Norwegian, respectively. The words were taken from the parallel corpus with sentences from riksrevisjonen9[26]. We can observe that all word pairs are clustering together, indicating the semantic alignment of the word embeddings between the languages. In the bottom graph Figure 3b we see two sets of 500 static word embeddings from each language. We can notice a clear clustering of the two languages. In both graphs, we reduce the embedding dimension to two dimensions with the t-SNE method. This further solidifies that BERT models are able to align semantics across English and Nor- wegian without using any supervised data 5 Discussion Our analysis shows that layers 5-9 (middle layers) have the highest accuracy on static word retrieval. This result is in line with previous work on semantic similarity [5]. We argue that the best-performing layers in semantic similarity will also be the best- performing layers in semantic alignment between two languages. Although we observe a clear separation between languages in the word representation space, the mean shift method did not significantly impact the word retrieval accuracy. In layer 11, the accu- racy does increase by around 8% in the Notram model. However, in the best performing layer of the same model, layer 7 (or 5), the increase is only around 1%. We consider this a slight change since the accuracy at @1 is around 50%. Overall, the word retrieval 9 ! rom-the-office-of-the-auditor-general-riksrevisjonen-website/a5d2470201e311e9b7d400155 d0267060fffdc9258a741659ce9e52ef15a7c26/ 8 (a) Visualizing contextual word embeddings for word pairs in English and Norwegian. Contextual embeddings taken from layer 8 of the Notram model and the English contextual embeddings have experienced a mean shift. The word embeddings are reduced to 2D with t-SNE. The darker colored markers show contextual word embeddings for Norwegian while the lighter color show contextual embedding for English. Each word pair has its own marker. (b) 500 random words from Norwegian and English vocabulary respectively. The static word embeddings are from Notram layer 12. The word embeddings are reduced to 2D with t-SNE. Lighter points correspond to English embed- dings and darkest points correspond to Norwegian embeddings. Fig. 3: Visualizing static and contextual word embeddings from BERT 9 results suggest that the hypothesis that translating one language to another in the word representation space by looking at the closest matched embedding of the other lan- guage is a promising approach. Though, the low impact of the mean shift indicates that the translation from one language to another is not as simple as shifting the embedding by a simple mean language vector. This warrants further investigation into better meth- ods to create language vector representations that might improve the impact of such a language vector shift. Nevertheless, the language vectors from the mean shift analysis remain strong predictors for identifying the language of an embedding as can be seen by the strong performance results of our language detection analysis. It is noteworthy that static word retrieval does not deal with ambiguous words. Both language vocabularies most likely contain words with multiple meanings, leading to a conflation of meaning in the embedding. Conflated meanings most likely affected word retrieval since the English and Norwegian corpus do not provide the same contexts, and a word representation can be conflated with different meanings depending on the text corpus. In addition, words within each language can have different meanings. There- fore, an ambiguous word can often be detected because it will translate to different words in another language depending on the context. To deal with this downside, one would have to include a more nuanced analysis of either sense or a word pair from the same context. We believe that ambiguous words have a negative impact on accuracy as we could observe significantly better results when considering @3 and @10 nearest neighbours, with an increase of more than a 20% going from @1 to @10. Norwegian is a language that borrows many words and phrases from English. It can be single words like ""skateboard"" or whole phrases like movie titles. Even though we filtered out sentences detected as English from the Norwegian text corpus, single words and smaller phrases may have been hard to remove. The effect could be English noise in the Norwegian part of the corpus and hence an effect in language detection. mBERT outperforms Notram in the subsequent layers of the model in detecting the correct language, and it achieves close to 100% accuracy. However, we question if the accuracy is this high because there might exist English noise in the Norwegian corpus, which would mean that the accuracy should not be 100%. A better evaluation dataset could be used to inspect this effect further. 6 Conclusion In this exploratory analysis, we have shown that BERT’s word representations automat- ically align semantics across English and Norwegian. We showed this with an accuracy of 50% for @1 nearest neighbor and an accuracy of more than 70 % for @10 nearest neighbor on the word retrieval task. In addition, we found that language is encoded in the word representation: We could detect the correct language of a word, with close to 100% accuracy, only by looking at its proximity to the two language vectors for English and Norwegian, respectively. We demonstrate that the model can align semantics and learn language properties by training on only raw text data (no parallel sentences). We believe that the combination of automatic language detection and word re- trieval between language embeddings allows for knowledge to be transferred between languages, ultimately helping alleviate the data sparsity problem in low-resource lan- 10 guages, such as Norwegian. While our results show promising tendencies, further in- vestigations into reaching higher word retrieval accuracies and better aligning language vectors are warranted to make this approach reliable. We hope that our findings moti- vate new ways of using multilingual models and inspire more research in training and investigating multilingual models for low-resource languages. References 1. Agirre, E., Alfonseca, E., Hall, K., Kravalova, J., Pasca, M., Soroa, A.: A study on similarity and relatedness using distributional and wordnet-based approaches (2009) 2. Bommasani, R., Davis, K., Cardie, C.: Interpreting Pretrained Contextualized Representa- tions via Reductions to Static Embeddings. In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. pp. 4758–4781 (2020) 3. Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D.M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., Amodei, D.: Language Models are Few-Shot Learners. arXiv preprint arXiv:2005.14165 (2020) 4. Cao, S., Kitaev, N., Klein, D.: Multilingual alignment of contextual word representations. arXiv preprint arXiv:2002.03518 (2020) 5. Chronis, G., Erk, K.: When is a bishop not like a rook? When itâ ˘A´Zs like a rabbi! Multi- prototype BERT embeddings for estimating semantic relationships. In: Proceedings of the 24th Conference on Computational Natural Language Learning. pp. 227–244 (2020) 6. Conneau, A., Lample, G., Ranzato, M., Denoyer, L., Jégou, H.: Word translation without parallel data. arXiv preprint arXiv:1710.04087 (2017) 7. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of deep bidirectional transformers for language understanding. NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan- guage Technologies - Proceedings of the Conference 1(Mlm), 4171–4186 (2019) 8. Francis, W.N., Kucera, H.: Brown corpus manual. Letters to the Editor 5(2), 7 (1979) 9. Gerz, D., Vuli´c, I., Hill, F., Reichart, R., Korhonen, A.: Simverb-3500: A large-scale evalua- tion set of verb similarity. arXiv preprint arXiv:1608.00869 (2016) 10. Hill, F., Reichart, R., Korhonen, A.: Simlex-999: Evaluating semantic models with (genuine) similarity estimation. Computational Linguistics 41(4), 665–695 (2015) 11. Isbister, T., Carlsson, F., Sahlgren, M.: Should we Stop Training More Monolingual Models, and Simply Use Machine Translation Instead? arXiv preprint arXiv:2104.10441 (2021) 12. Joulin, A., Grave, E., Bojanowski, P., Mikolov, T.: Bag of tricks for efficient text classifi- cation. In: 15th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2017 - Proceedings of Conference. vol. 2 (2017). 53/v1/e17-2068 13. Kummervold, P.E., la Rosa, J., Wetjen, F., Brygfjeld, S.A.: Operationalizing a national dig- ital library: The case for a norwegian transformer model. arXiv preprint arXiv:2104.09617 (2021) 14. Kutuzov, A., Barnes, J., Velldal, E., Øvrelid, L., Oepen, S.: Large-scale contextualised lan- guage modelling for norwegian. arXiv preprint arXiv:2104.06546 (2021) 15. Liu, C.L., Hsu, T.Y., Chuang, Y.S., Lee, H.Y.: A study of cross-lingual ability and language- specific information in multilingual BERT. arXiv preprint arXiv:2004.09205 (2020) 11 16. Liu, N.F., Gardner, M., Belinkov, Y., Peters, M.E., Smith, N.A.: Linguistic knowledge and transferability of contextual representations. arXiv preprint arXiv:1903.08855 (2019) 17. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., Stoyanov, V.: RoBERTa: A Robustly Optimized BERT Pretraining Approach. CoRR abs/1907.1 (2019), 18. Loureiro, D., Rezaee, K., Pilehvar, M.T., Camacho-Collados, J.: Analysis and Evaluation of Language Models for Word Sense Disambiguation. Computational Linguistics pp. 1–55 (2021) 19. Malmsten, M., Börjeson, L., Haffenden, C.: Playing with Words at the National Library of Sweden–Making a Swedish BERT. arXiv preprint arXiv:2007.01658 (2020) 20. Martin, L., Muller, B., Suárez, P.J.O., Dupont, Y., Romary, L., de La Clergerie, Ã.V., Seddah, D., Sagot, B.: CamemBERT: a tasty French language model. arXiv preprint arXiv:1911.03894 (2019) 21. Mikolov, T., Chen, K., Corrado, G., Dean, J.: Efficient estimation of word representations in vector space. 1st International Conference on Learning Representations, ICLR 2013 - Workshop Track Proceedings ICLR 2013, 1–12 (2013), 22. Mikolov, T., Le, Q.V., Sutskever, I.: Exploiting similarities among languages for machine translation. arXiv preprint arXiv:1309.4168 (2013) 23. Pennington, J., Socher, R., Manning, C.D.: GloVe: Global vectors for word representation. In: EMNLP 2014 - 2014 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference (2014). 24. Rajpurkar, P., Jia, R., Liang, P.: Know what you don’t know: Unanswerable questions for SQuAD. arXiv preprint arXiv:1806.03822 (2018) 25. Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P.: SQuad: 100,000+ questions for machine comprehension of text. EMNLP 2016 - Conference on Empirical Methods in Natural Lan- guage Processing, Proceedings (ii), 2383–2392 (2016). 4 26. Riksrevisjonen: Bilingual English-Norwegian parallel corpus from the Office of the Auditor General (Riksrevisjonen) website â ˘A¸S ELRC-SHARE (2018), pository/browse/bilingual-english-norwegian-parallel-corpus-from-the-office-of-the-audit or-general-riksrevisjonen-website/a5d2470201e311e9b7d400155d0267060fffdc9258a741 659ce9e52ef15a7c26/ 27. Rogers, A., Kovaleva, O., Rumshisky, A.: A primer in bertology: What we know about how bert works. Transactions of the Association for Computational Linguistics 8, 842–866 (2020) 28. Tenney, I., Das, D., Pavlick, E.: BERT rediscovers the classical NLP pipeline. arXiv preprint arXiv:1905.05950 (2019) 29. Tenney, I., Xia, P., Chen, B., Wang, A., Poliak, A., McCoy, R.T., Kim, N., Van Durme, B., Bowman, S.R., Das, D., others: What do you learn from context? probing for sentence structure in contextualized word representations. arXiv preprint arXiv:1905.06316 (2019) 30. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Å., Polosukhin, I.: Attention is all you need. Advances in Neural Information Processing Sys- tems 2017-Decem(Nips), 5999–6009 (2017) 31. Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., Bowman, S.R.: GLUE: A multi- task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461 (2018) 32. Wiedemann, G., Remus, S., Chawla, A., Biemann, C.: Does BERT make any sense? In- terpretable word sense disambiguation with contextualized embeddings. arXiv preprint arXiv:1909.10430 (2019) 33. Williams, A., Nangia, N., Bowman, S.R.: A broad-coverage challenge corpus for sentence understanding through inference. arXiv preprint arXiv:1704.05426 (2017) 12"
A Deep Learning-Based Tool for Automatic Brain Extraction from Functional Magnetic Resonance Images of Rodents,"Pontes-Filho, Sidney
and Dahl, Annelene Gulden
and Nichele, Stefano
and Mello, Gustavo Borges Moreno e.",2022,,,,inproceedings,"A deep learning based tool for automatic brain
extraction from functional magnetic resonance
images in rodents
Sidney Pontes-Filho∗,†, Annelene Gulden Dahl‡, Stefano Nichele∗and Gustavo Borges Moreno e Mello∗,§
∗Department of Computer Science, Oslo Metropolitan University, Oslo, Norway
†Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway
‡Kavli Institute for Systems Neuroscience, Norwegian University of Science and Technology, Trondheim, Norway
§Department of Mech., Elec. and Chem. Engineering, Oslo Metropolitan University, Oslo, Norway
Email: gustavom@oslomet.no
Abstract—Removing skull artifacts from functional magnetic
images (fMRI) is a well understood and frequently encountered
problem. Because the fMRI ﬁeld has grown mostly due to human
studies, many new tools were developed to handle human data.
Nonetheless, these tools are not equally useful to handle the
data derived from animal studies, especially from rodents. This
represents a major problem to the ﬁeld because rodent studies
generate larger datasets from larger populations, which implies
that preprocessing these images manually to remove the skull
becomes a bottleneck in the data analysis pipeline. In this study,
we address this problem by implementing a neural network based
method that uses a U-Net architecture to segment the brain
area into a mask and removing the skull and other tissues from
the image. We demonstrate several strategies to speed up the
process of generating the training dataset using watershedding
and several strategies for data augmentation that allowed to
train faster the U-Net to perform the segmentation. Finally, we
deployed the trained network freely available.
Index Terms—neural network, deep learning, fMRI, rodent,
brain extraction, skull stripping, MRI, U-Net
I. INTRODUCTION
Functional magnetic imaging (fMRI) has emerged as a
powerful tool to investigate functional networks in the brain.
Because fMRI is a non-invasive technology, the ﬁeld has
primarily been driven by its application to the study of the
human brain. Consequently, great advances in automating
analysis of fMRI data through tools that improve its speed and
efﬁciency have been achieved to process human data, saving
both time and costs associated with fMRI studies. However,
efforts to either modify preexisting tools, or develop similar
tools for use on rodent datasets are lagging.
Currently, one of the most time consuming steps in the
processing of rodent fMRI data is the process of brain ex-
traction or skull stripping. This step consists of segmenting
the whole brain, which is equivalent to removing all non-
cerebral tissue, including the skull, nose, mouth, ears, and
muscles [1]. Accurate extraction of the brain is essential to
ensure that fMRI data of all the subjects in the study are
anatomically aligned, which is necessary to allow for reliable
statistical comparison across large cohorts of animals [2]–[6].
Because skull stripping is a well understood problem [7] and
a necessity in every fMRI analysis, the development of tools
to automatise and increase the speed and reliability of results
might have a great positive impact into fMRI research.
Rodent’s brain extraction poses additional challenges when
compared to segmenting the human brains from fMRI data.
Rodents have a smaller gap between the brain and the skull,
resulting in a less clear edge demarcation than in humans.
Additionally, the rodent brain differs in shape, texture, size
and proportion from the human brain. This means that the
automated tools developed to handle human data such as
Brain Extraction Toolkit (BET) [8] and BrainSuites Brain
Surface Extractor (BSE) [9] usually fail to process images of
rodent brains. Therefore, brain extraction of rodent anatomical
and functional data is predominantly carried out manually.
This process involves researchers going slice-by-slice through
the acquired (anatomical and functional) images in all three
dimensions and manually drawing masks for the brain using
a mouse or a tablet.
A tool to efﬁciently extract the brain from rodent anatomical
images was recently published [10]. This tool takes as input
one representative brain from the study and its manually
created brain mask, and uses this information to carry out the
brain extraction of the remaining subjects in the study. While
this is a great tool for extracting the brains in the anatomical
images, it is not intended for use in functional datasets, and
there is, to the best of our knowledge, no equivalent tool
available for extracting the brain from the functional dataset.
In order to observe the changing activity of the brain over time,
the functional datasets have to be acquired at a much greater
speed than the anatomical images, resulting in a much lower
spatial resolution than the anatomical images. To preserve
the sensitivity to blood-oxygenation-level-dependent (BOLD)
contrast the images are also frequently subject to severe
susceptibility-induced distortions, in particular, in the back of
the brain near ear canals and sinuses. Due to these confounds,
skull extraction of functional rodent images commonly fails,
and the current state-of-the-art in the ﬁeld of rodent imaging
is to manually draw the masks. This process is both time-
consuming and often inaccurate, contributing to a less-than-
arXiv:1912.01359v2  [eess.IV]  6 Dec 2019
 perfect alignment of the functional data to the template brain.
To overcome this obstacle, we have developed a deep
learning-based tool in Python that quickly and successfully
extracts the brain from the functional datasets, thus improving
the speed and accuracy of the preprocessing pipeline. The tool,
furthermore, does not require any study-speciﬁc input from the
researcher in order to successfully separate brain from non-
brain tissue. The tool is freely available online.
II. RELATED WORKS
In the last three decades, many methods for skull stripping
have been proposed [11]–[13], ranging from simple luminance
thresholding to 3D-convolutional deep learning techniques
[14]. Among them, the most promising are the water-shedding
based segmentation [1], the Brain Extraction Tool (BET) [8]
and the most recent 3D-U-Net [14]. Watershed based methods
are image processing pipelines originally described in [15]
that are advantageous for being unsupervised, fast, and easy
to tune; they leverage luminance gradients to deﬁne regions of
interest that can be deﬁned either as brain or non-brain. BET,
on the other hand, uses a malleable model, where a spherical
mesh is initialized at the center of mass and then expanded
towards the surface of the brain; locally adaptive model forces
based on local intensity values guide this process, allowing
BET to quickly segment the brain. The caveat is that BET
has a spherical (human) brain assumption, and has irregular
performance with oblong elliptical shaped brains, such as
rodent brains. Finally, 3D-U-Net is a promising robust method-
ology that uses convolutional neural networks to perform
semantic binary segmentation. This method has the advantage
of being able to learn from experts by mapping spacial features
of the raw fMRI image to ground-truth data generated by
manual segmentation. Because of the need for coregistration
and alignment in the z-axis, this method cannot beneﬁt from
several of the data augmentation methods available, such as
elastic transformations [16], [17], thus requiring much more
data than the standard U-Net [17]. All of these methods were
developed to handle human fMRI data, and regardless of
the great levels of performance achieved by the previously
cited methods, a solution to reliably perform skull stripping in
rodent data is still missing.
The solutions to particularly handle rodent fMRI data
use more modest technologies. More often than not, skull
stripping is still done by creating hand-drawn masks and
only occasionally helped by semi-automation tools such as
BrainSuite’s Brain Surface Extractor (BSE) [9] which pro-
duces an initial mask that subsequently needs to be reﬁned
and corrected by hand. Beyond BSE other two automation
method categories are available, warping to brain atlas based
methods, and surface template based methods [10]. Both
methods are built extending the NiftyReg software package
[18]; and both dependent on the warping of the image to
a template coordinate map, or on warping a mask to the
raw image through a series of afﬁne and non-linear transfor-
mations. These methods produce excellent results on high-
resolution anatomical images, but due to the lower spatial
resolution and image distortions in the functional datasets the
automated skull stripping methods currently available fail to
perform correctly on rodent functional images. Hence, the
brain extraction problem in functional images from rodent data
has yet to be solved satisfactorily in a generic and robust way.
III. METHODS
A. Image acquisition
62 fMRI datasets from 31 McGill-R-thy-App rats were
acquired on a 7T Biospec 70/30 (Bruker BioSpin) preclin-
ical scanner, equipped with an actively shielded 660 mT/m
BGA12S HP gradient set (Bruker) in combination with a
quadrature surface coil (Bruker BioSpin). Aspin-echo EPI
sequence was used with the following parameters: 600 repeti-
tions (total scan time of 30 min each) with 2 segments, TE=
20ms, repetition time (TR) = 1.5s for a full-volume acquisition
of 3s., ﬁeld-of-view (FOV) of 20x20mm, matrix size 80x80,
55 dummy scans, ﬂip angle of 90 degrees. Seventeen slices
were acquired in rostro-caudal direction for a ﬁnal resolution
of 250 x 250 x 1000um. All procedures were approved by
the Norwegian Food Safety Authority as well as the local
Animal Welfare Committee of the Norwegian University of
Science and Technology (NTNU). All animals were housed
and handled according to the Norwegian laws and regulations
concerning animal welfare and animal research. Experimental
protocols were approved by the Norwegian Animal Research
Authority (FOTS application number 11932) and were in
accordance with the European Convention for the Protection of
Vertebrate Animals used for Experimental and Other Scientiﬁc
Purposes.
B. Training dataset and Watershedding-based brain segmen-
tation
Due to the success of the watershedding algorithm to
segment the brain in human fMRI dataset [19], we used it
as a semi-automated approach to generate a dataset of masks
that were used to train the neural network to segment the
brain from the skull. Watershedding is a region-based approach
that considers the target structure as a homogeneous region
which is determined by a search process guided by appropriate
criteria for homogeneity. We implemented the watershedding
segmentation by using functions in OpenCV [20] to preprocess
the images by gray-scaling, mean-shifting and normalizing
them. Once the images were considered suitable for seg-
mentation, we thresholded the gray-scaled image into masks,
calculated their basin gradients, ﬁltered these gradients, and
identiﬁed the segmented areas as connected components. As
result, the watershed method provides per each image a series
of masks for each structure in each image. The gradient of
an image function f is the vector constituted by the partial
derivatives in each image dimension. The gradient’s direction
is the direction of steepest descent and a magnitude (mag) is
the length of the gradient vector. For an image function in R2,
f(x, y) the magnitude of the gradient is calculated as
mag(▽f) =
s
(δf
δx)2 + (δf
δy )2.
(1)
 To choose the mask that represented the brain structure,
we leveraged the regularities in the data. Because in this
dataset the brain was always very close to the center, this
meant that the average polar radial distance between each
point of the brain structure mask and the center of the image
was shorter than any other structure. Thus, we used this as
the criterion to exclude other structures. The parameters for
this process were chosen manually and the results followed
by close supervised eye-inspection. Nonetheless, this semi-
supervised approach proved to be substantially faster than the
manual alternative, because the same parameters could be used
for different datasets acquired in similar conditions.
C. Deep-Learning-based segmentation
In this article, we use a standard U-Net [17] architecture to
perform skull stripping from fMRI images of rodents. U-Nets
are most often used for semantic segmentation tasks. Beyond
performing well on the task, they allow for efﬁcient use of
GPU memory, which is an asset for processing big image
datasets with many features. This is heavily dependent on the
fully convolutional architecture of the U-Net, which enables
the extraction of image features at multiple image scales. In the
U-Net, different layers capture coarse feature-maps that reﬂect
this contextual information about the category and location of
objects at multiple scales. These feature-maps are later merged
through skip connections to combine coarse- and ﬁne-level
dense predictions [17].
The goal of the U-Net neural network architecture is to
predict which pixels in the image matrix are to be classiﬁed
as brain and which ones are to be classiﬁed otherwise. Thus,
the output of the ﬁnal decoder layer is a soft mask (see Fig.
1) that when multiplied to the input image produces the ﬁnal
segmented brain region.
D. Data Augmentation and Training
One major advantage of using the U-Net is that it is possible
and simple to use several methods for data augmentation such
as resizing, ﬂipping, rotating, and minor translations. These
data augmentation strategies increase the performance of the
model by increasing the size and variety of the dataset [21].
Additionally, fMRI images often do have distortions and
movement artifacts. To improve U-Net’s robustness in face
of such artifacts, elastic afﬁne transformations were applied
equally to the input image and the target masks. In total, the
training and validation datasets were increased by 50% with
these slightly deformed images [21].
To speed up training we utilized a U-Net pre-trained to
segment pathological structures in human MRI images. In-
stead of stochastic gradient descent, we modiﬁed the original
optimizer of U-Net to Adam [22] with the learning rate of
0.001. Additionally, the training used batches of 25 images
during 1,000 epochs.
IV. RESULTS
This section presents the quantitative and qualitative results
of the deep learning neural network for our task of segmenting
Fig. 1.
Soft masks examples: The left column represents the input image.
The right column illustrates the mask prediction for three different coronal
slices of a rodent’s .
rodents’ brains. Table I contains the quantitative results of
binary cross-entropy (BCE) loss, accuracy, F1 score, precision
and recall on the validation dataset of 49 images (5 % of our
dataset). All these values show that our model segments almost
all pixels that contain the brain (98.3 % recall) with precision
of 98.5 %. The F1 score is a metric that combines recall and
precision. The accuracy represents the percentage of correct
answers for the pixels predicted as part of the brain or not.
Such value is high and it is 99.35 %. Those measurements
suggest that the model performance is excellent.
TABLE I
VALIDATION RESULTS OF THE BEST (LOWEST) LOSS.
Measurement
Value
BCE loss
0.01562267541885376
Accuracy
0.9935703277587891
F1 Score
0.9843953251838684
Precision
0.9854521751403809
Recall
0.9833407998085022
 (a)
(b)
(c)
(d)
(e)
(f)
Fig. 2. Validation results. Green line represents the ground truth and red line is the predicted region.
The same model that obtained the best BCE loss on vali-
dation dataset has 6 out of its 49 results depicted in Fig. 2.
In general, the model performs well to segment the rodent’s
brain in an fMRI. There is one validation result which has a
small mistake in the segmentation. That is depicted in Fig 2e
and it has a small predicted region on the right side of the
image which means that the model predicted a “second” tiny
brain. Despite that, the qualitative and qualitative results are
impressive.
V. DISCUSSION
Much of what is known in neuroscience is derived from
studies using rodent models, due to its versatility and the
large selection of methods (e.g., invasive methods) available
to study them. On the other hand, much of what is known
about the human brain is derived from MRI and fMRI studies.
Thus, fMRI holds the promise of bridging the gap between
what we know about the mammalian brain. It may provide
evidence to generalize results from rodent-derived studies
using electrophysiology, optical, and pharmacological methods
to the human model. In this context, it is important to create
powerful tools that can increase the speed and the reliability
of the analysis performed on data derived from rodent models
and can equally be applied to human data. In this article we
made a step towards democratizing deep learning tools to the
neuroscience community by successfully applying a U-Net to
perform skull stripping of low resolution functional magnetic
resonance images from rodents. The method was quick to
train, required little data due to the usage of data augmentation
techniques, and qualitatively performed reasonably well. In
contrast to other approaches that depend on images with
high-resolution images or deformations of initial masks, U-
Nets work well with low resolution images and can segment
distorted images, even with motion artifacts. Additionally, by
using a network that operates on images as inputs instead
of a 3D tensor with all the image slices at once, we could
use data augmentation strategies without major problems with
respect to alignment issues. However, we recognize that U-
Net may not be the best nor the fastest architecture to perform
semantic segmentation. Other topologies such as Albunet, or
Ternausnet [23] might deploy better segmentation at higher
speeds. Additionally, because fMRI has a temporal component,
recursive layers could be added to take the dynamic nature
of the signal in the brain as a feature to better segment and
remove the skull, perhaps even in a non-supervised manner.
Consequently, a logical step is to explore how more modern
 architectures could perform in this task. We hope this tool
helps neuroscientists to reduce time in preprocessing steps of
their analysis of fMRI data in non-human models.
ACKNOWLEDGMENT
The two authors, Annelene Gulden Dahl and Sidney Pontes-
Filho contributed equally to the work. We also thank Stefano
Nichele for the comments on the manuscript. This work
was supported by Norwegian Research Council SOCRATES
project (grant number 270961) and received internal support
as a lighthouse project in Computer Vision from the Faculty
of Technology, Art and Design (TKD) at Oslo Metropolitan
University, Norway.
REPOSITORY
Code and example data can be found in the following
repository: https://github.com/sidneyp/skull-stripper
REFERENCES
[1] H. K. Hahn and H.-O. Peitgen, “The skull stripping problem in mri
solved by a single 3d watershed transform,” in International Conference
on Medical Image Computing and Computer-Assisted Intervention.
Springer, 2000, pp. 134–143.
[2] S. Spring, J. P. Lerch, and R. M. Henkelman, “Sexual dimorphism
revealed in the structure of the mouse brain using three-dimensional
magnetic resonance imaging,” Neuroimage, vol. 35, no. 4, pp. 1424–
1433, 2007.
[3] E. L. Bearer, X. Zhang, D. Janvelyan, B. Boulat, and R. E. Jacobs, “Re-
ward circuitry is perturbed in the absence of the serotonin transporter,”
Neuroimage, vol. 46, no. 4, pp. 1091–1104, 2009.
[4] D. A. Vousden, J. Epp, H. Okuno, B. J. Nieman, M. van Eede, J. Dazai,
T. Ragan, H. Bito, P. W. Frankland, J. P. Lerch et al., “Whole-brain
mapping of behaviourally induced neural activation in mice,” Brain
Structure and Function, vol. 220, no. 4, pp. 2043–2057, 2015.
[5] X. Zhang, E. L. Bearer, B. Boulat, F. S. Hall, G. R. Uhl, and R. E.
Jacobs, “Altered neurocircuitry in the dopamine transporter knockout
mouse brain,” PloS one, vol. 5, no. 7, p. e11506, 2010.
[6] M. C. van Eede, J. Scholz, M. M. Chakravarty, R. M. Henkelman, and
J. P. Lerch, “Mapping registration sensitivity in mr mouse brain images,”
Neuroimage, vol. 82, pp. 226–236, 2013.
[7] T. Kapur, W. E. L. Grimson, W. M. Wells III, and R. Kikinis, “Segmen-
tation of brain tissue from magnetic resonance images,” Medical image
analysis, vol. 1, no. 2, pp. 109–127, 1996.
[8] S. M. Smith, “Fast robust automated brain extraction,” Human brain
mapping, vol. 17, no. 3, pp. 143–155, 2002.
[9] D. W. Shattuck and R. M. Leahy, “Brainsuite: an automated cortical
surface identiﬁcation tool,” Medical image analysis, vol. 6, no. 2, pp.
129–142, 2002.
[10] A. Delora, A. Gonzales, C. S. Medina, A. Mitchell, A. F. Mohed, R. E.
Jacobs, and E. L. Bearer, “A simple rapid process for semi-automated
brain extraction from magnetic resonance images of the whole mouse
head,” Journal of neuroscience methods, vol. 257, pp. 185–193, 2016.
[11] S. F. Eskildsen, P. Coup´e, V. Fonov, J. V. Manj´on, K. K. Leung,
N. Guizard, S. N. Wassef, L. R. Østergaard, D. L. Collins, A. D. N.
Initiative et al., “Beast: brain extraction based on nonlocal segmentation
technique,” NeuroImage, vol. 59, no. 3, pp. 2362–2373, 2012.
[12] F. J. Galdames, F. Jaillet, and C. A. Perez, “An accurate skull stripping
method based on simplex meshes and histogram analysis for magnetic
resonance images,” Journal of neuroscience methods, vol. 206, no. 2,
pp. 103–119, 2012.
[13] W. Speier, J. E. Iglesias, L. El-Kara, Z. Tu, and C. Arnold, “Robust
skull stripping of clinical glioblastoma multiforme data,” in Interna-
tional Conference on Medical Image Computing and Computer-Assisted
Intervention.
Springer, 2011, pp. 659–666.
[14] H. Hwang, H. Z. U. Rehman, and S. Lee, “3d u-net for skull stripping
in brain mri,” Applied Sciences, vol. 9, no. 3, p. 569, 2019.
[15] S. Hahn, S. Oberbauer, R. Gebauer, N. Grulke, O. Lange, and J. Ten-
hunen, “Vegetation structure and aboveground carbon and nutrient pools
in the imnavait creek watershed,” in Landscape function and disturbance
in Arctic tundra.
Springer, 1996, pp. 109–128.
[16] M. Moshfeghi, “Elastic matching of multimodality medical images,”
CVGIP: Graphical Models and Image Processing, vol. 53, no. 3, pp.
271–282, 1991.
[17] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks
for biomedical image segmentation,” in International Conference on
Medical image computing and computer-assisted intervention. Springer,
2015, pp. 234–241.
[18] M. Modat, J. McClelland, and S. Ourselin, “Lung registration using
the niftyreg package,” Medical image analysis for the clinic-a grand
Challenge, vol. 2010, pp. 33–42, 2010.
[19] N. Malpica, C. O. De Sol´orzano, J. J. Vaquero, A. Santos, I. Vallcorba,
J. M. Garc´ıa-Sagredo, and F. Del Pozo, “Applying watershed algorithms
to the segmentation of clustered nuclei,” Cytometry: The Journal of the
International Society for Analytical Cytology, vol. 28, no. 4, pp. 289–
297, 1997.
[20] G. Bradski, “The OpenCV Library,” Dr. Dobb’s Journal of Software
Tools, 2000.
[21] P. Y. Simard, D. Steinkraus, J. C. Platt et al., “Best practices for
convolutional neural networks applied to visual document analysis.” in
Icdar, vol. 3, no. 2003, 2003.
[22] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
arXiv preprint arXiv:1412.6980, 2014.
[23] S. Wang, Y. Hua, Y. Cao, T. Song, Z. Xue, X. Gong, G. Wang,
R. Ma, and H. Guan, “Deep learning based fetal middle cerebral
artery segmentation in large-scale ultrasound images,” in 2018 IEEE
International Conference on Bioinformatics and Biomedicine (BIBM).
IEEE, 2018, pp. 532–539.
",,doc9,"A deep learning based tool for automatic brain extraction from functional magnetic resonance images in rodents Sidney Pontes-Filho∗,†, Annelene Gulden Dahl‡, Stefano Nichele∗and Gustavo Borges Moreno e Mello∗,§ ∗Department of Computer Science, Oslo Metropolitan University, Oslo, Norway †Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway ‡Kavli Institute for Systems Neuroscience, Norwegian University of Science and Technology, Trondheim, Norway §Department of Mech., Elec. and Chem. Engineering, Oslo Metropolitan University, Oslo, Norway Email: gustavom@oslomet.no Abstract—Removing skull artifacts from functional magnetic images (fMRI) is a well understood and frequently encountered problem. Because the fMRI ﬁeld has grown mostly due to human studies, many new tools were developed to handle human data. Nonetheless, these tools are not equally useful to handle the data derived from animal studies, especially from rodents. This represents a major problem to the ﬁeld because rodent studies generate larger datasets from larger populations, which implies that preprocessing these images manually to remove the skull becomes a bottleneck in the data analysis pipeline. In this study, we address this problem by implementing a neural network based method that uses a U-Net architecture to segment the brain area into a mask and removing the skull and other tissues from the image. We demonstrate several strategies to speed up the process of generating the training dataset using watershedding and several strategies for data augmentation that allowed to train faster the U-Net to perform the segmentation. Finally, we deployed the trained network freely available. Index Terms—neural network, deep learning, fMRI, rodent, brain extraction, skull stripping, MRI, U-Net I. INTRODUCTION Functional magnetic imaging (fMRI) has emerged as a powerful tool to investigate functional networks in the brain. Because fMRI is a non-invasive technology, the ﬁeld has primarily been driven by its application to the study of the human brain. Consequently, great advances in automating analysis of fMRI data through tools that improve its speed and efﬁciency have been achieved to process human data, saving both time and costs associated with fMRI studies. However, efforts to either modify preexisting tools, or develop similar tools for use on rodent datasets are lagging. Currently, one of the most time consuming steps in the processing of rodent fMRI data is the process of brain ex- traction or skull stripping. This step consists of segmenting the whole brain, which is equivalent to removing all non- cerebral tissue, including the skull, nose, mouth, ears, and muscles [1]. Accurate extraction of the brain is essential to ensure that fMRI data of all the subjects in the study are anatomically aligned, which is necessary to allow for reliable statistical comparison across large cohorts of animals [2]–[6]. Because skull stripping is a well understood problem [7] and a necessity in every fMRI analysis, the development of tools to automatise and increase the speed and reliability of results might have a great positive impact into fMRI research. Rodent’s brain extraction poses additional challenges when compared to segmenting the human brains from fMRI data. Rodents have a smaller gap between the brain and the skull, resulting in a less clear edge demarcation than in humans. Additionally, the rodent brain differs in shape, texture, size and proportion from the human brain. This means that the automated tools developed to handle human data such as Brain Extraction Toolkit (BET) [8] and BrainSuites Brain Surface Extractor (BSE) [9] usually fail to process images of rodent brains. Therefore, brain extraction of rodent anatomical and functional data is predominantly carried out manually. This process involves researchers going slice-by-slice through the acquired (anatomical and functional) images in all three dimensions and manually drawing masks for the brain using a mouse or a tablet. A tool to efﬁciently extract the brain from rodent anatomical images was recently published [10]. This tool takes as input one representative brain from the study and its manually created brain mask, and uses this information to carry out the brain extraction of the remaining subjects in the study. While this is a great tool for extracting the brains in the anatomical images, it is not intended for use in functional datasets, and there is, to the best of our knowledge, no equivalent tool available for extracting the brain from the functional dataset. In order to observe the changing activity of the brain over time, the functional datasets have to be acquired at a much greater speed than the anatomical images, resulting in a much lower spatial resolution than the anatomical images. To preserve the sensitivity to blood-oxygenation-level-dependent (BOLD) contrast the images are also frequently subject to severe susceptibility-induced distortions, in particular, in the back of the brain near ear canals and sinuses. Due to these confounds, skull extraction of functional rodent images commonly fails, and the current state-of-the-art in the ﬁeld of rodent imaging is to manually draw the masks. This process is both time- consuming and often inaccurate, contributing to a less-than- arXiv:1912.01359v2 [eess.IV] 6 Dec 2019 perfect alignment of the functional data to the template brain. To overcome this obstacle, we have developed a deep learning-based tool in Python that quickly and successfully extracts the brain from the functional datasets, thus improving the speed and accuracy of the preprocessing pipeline. The tool, furthermore, does not require any study-speciﬁc input from the researcher in order to successfully separate brain from non- brain tissue. The tool is freely available online. II. RELATED WORKS In the last three decades, many methods for skull stripping have been proposed [11]–[13], ranging from simple luminance thresholding to 3D-convolutional deep learning techniques [14]. Among them, the most promising are the water-shedding based segmentation [1], the Brain Extraction Tool (BET) [8] and the most recent 3D-U-Net [14]. Watershed based methods are image processing pipelines originally described in [15] that are advantageous for being unsupervised, fast, and easy to tune; they leverage luminance gradients to deﬁne regions of interest that can be deﬁned either as brain or non-brain. BET, on the other hand, uses a malleable model, where a spherical mesh is initialized at the center of mass and then expanded towards the surface of the brain; locally adaptive model forces based on local intensity values guide this process, allowing BET to quickly segment the brain. The caveat is that BET has a spherical (human) brain assumption, and has irregular performance with oblong elliptical shaped brains, such as rodent brains. Finally, 3D-U-Net is a promising robust method- ology that uses convolutional neural networks to perform semantic binary segmentation. This method has the advantage of being able to learn from experts by mapping spacial features of the raw fMRI image to ground-truth data generated by manual segmentation. Because of the need for coregistration and alignment in the z-axis, this method cannot beneﬁt from several of the data augmentation methods available, such as elastic transformations [16], [17], thus requiring much more data than the standard U-Net [17]. All of these methods were developed to handle human fMRI data, and regardless of the great levels of performance achieved by the previously cited methods, a solution to reliably perform skull stripping in rodent data is still missing. The solutions to particularly handle rodent fMRI data use more modest technologies. More often than not, skull stripping is still done by creating hand-drawn masks and only occasionally helped by semi-automation tools such as BrainSuite’s Brain Surface Extractor (BSE) [9] which pro- duces an initial mask that subsequently needs to be reﬁned and corrected by hand. Beyond BSE other two automation method categories are available, warping to brain atlas based methods, and surface template based methods [10]. Both methods are built extending the NiftyReg software package [18]; and both dependent on the warping of the image to a template coordinate map, or on warping a mask to the raw image through a series of afﬁne and non-linear transfor- mations. These methods produce excellent results on high- resolution anatomical images, but due to the lower spatial resolution and image distortions in the functional datasets the automated skull stripping methods currently available fail to perform correctly on rodent functional images. Hence, the brain extraction problem in functional images from rodent data has yet to be solved satisfactorily in a generic and robust way. III. METHODS A. Image acquisition 62 fMRI datasets from 31 McGill-R-thy-App rats were acquired on a 7T Biospec 70/30 (Bruker BioSpin) preclin- ical scanner, equipped with an actively shielded 660 mT/m BGA12S HP gradient set (Bruker) in combination with a quadrature surface coil (Bruker BioSpin). Aspin-echo EPI sequence was used with the following parameters: 600 repeti- tions (total scan time of 30 min each) with 2 segments, TE= 20ms, repetition time (TR) = 1.5s for a full-volume acquisition of 3s., ﬁeld-of-view (FOV) of 20x20mm, matrix size 80x80, 55 dummy scans, ﬂip angle of 90 degrees. Seventeen slices were acquired in rostro-caudal direction for a ﬁnal resolution of 250 x 250 x 1000um. All procedures were approved by the Norwegian Food Safety Authority as well as the local Animal Welfare Committee of the Norwegian University of Science and Technology (NTNU). All animals were housed and handled according to the Norwegian laws and regulations concerning animal welfare and animal research. Experimental protocols were approved by the Norwegian Animal Research Authority (FOTS application number 11932) and were in accordance with the European Convention for the Protection of Vertebrate Animals used for Experimental and Other Scientiﬁc Purposes. B. Training dataset and Watershedding-based brain segmen- tation Due to the success of the watershedding algorithm to segment the brain in human fMRI dataset [19], we used it as a semi-automated approach to generate a dataset of masks that were used to train the neural network to segment the brain from the skull. Watershedding is a region-based approach that considers the target structure as a homogeneous region which is determined by a search process guided by appropriate criteria for homogeneity. We implemented the watershedding segmentation by using functions in OpenCV [20] to preprocess the images by gray-scaling, mean-shifting and normalizing them. Once the images were considered suitable for seg- mentation, we thresholded the gray-scaled image into masks, calculated their basin gradients, ﬁltered these gradients, and identiﬁed the segmented areas as connected components. As result, the watershed method provides per each image a series of masks for each structure in each image. The gradient of an image function f is the vector constituted by the partial derivatives in each image dimension. The gradient’s direction is the direction of steepest descent and a magnitude (mag) is the length of the gradient vector. For an image function in R2, f(x, y) the magnitude of the gradient is calculated as mag(▽f) = s (δf δx)2 + (δf δy )2. (1) To choose the mask that represented the brain structure, we leveraged the regularities in the data. Because in this dataset the brain was always very close to the center, this meant that the average polar radial distance between each point of the brain structure mask and the center of the image was shorter than any other structure. Thus, we used this as the criterion to exclude other structures. The parameters for this process were chosen manually and the results followed by close supervised eye-inspection. Nonetheless, this semi- supervised approach proved to be substantially faster than the manual alternative, because the same parameters could be used for different datasets acquired in similar conditions. C. Deep-Learning-based segmentation In this article, we use a standard U-Net [17] architecture to perform skull stripping from fMRI images of rodents. U-Nets are most often used for semantic segmentation tasks. Beyond performing well on the task, they allow for efﬁcient use of GPU memory, which is an asset for processing big image datasets with many features. This is heavily dependent on the fully convolutional architecture of the U-Net, which enables the extraction of image features at multiple image scales. In the U-Net, different layers capture coarse feature-maps that reﬂect this contextual information about the category and location of objects at multiple scales. These feature-maps are later merged through skip connections to combine coarse- and ﬁne-level dense predictions [17]. The goal of the U-Net neural network architecture is to predict which pixels in the image matrix are to be classiﬁed as brain and which ones are to be classiﬁed otherwise. Thus, the output of the ﬁnal decoder layer is a soft mask (see Fig. 1) that when multiplied to the input image produces the ﬁnal segmented brain region. D. Data Augmentation and Training One major advantage of using the U-Net is that it is possible and simple to use several methods for data augmentation such as resizing, ﬂipping, rotating, and minor translations. These data augmentation strategies increase the performance of the model by increasing the size and variety of the dataset [21]. Additionally, fMRI images often do have distortions and movement artifacts. To improve U-Net’s robustness in face of such artifacts, elastic afﬁne transformations were applied equally to the input image and the target masks. In total, the training and validation datasets were increased by 50% with these slightly deformed images [21]. To speed up training we utilized a U-Net pre-trained to segment pathological structures in human MRI images. In- stead of stochastic gradient descent, we modiﬁed the original optimizer of U-Net to Adam [22] with the learning rate of 0.001. Additionally, the training used batches of 25 images during 1,000 epochs. IV. RESULTS This section presents the quantitative and qualitative results of the deep learning neural network for our task of segmenting Fig. 1. Soft masks examples: The left column represents the input image. The right column illustrates the mask prediction for three different coronal slices of a rodent’s . rodents’ brains. Table I contains the quantitative results of binary cross-entropy (BCE) loss, accuracy, F1 score, precision and recall on the validation dataset of 49 images (5 % of our dataset). All these values show that our model segments almost all pixels that contain the brain (98.3 % recall) with precision of 98.5 %. The F1 score is a metric that combines recall and precision. The accuracy represents the percentage of correct answers for the pixels predicted as part of the brain or not. Such value is high and it is 99.35 %. Those measurements suggest that the model performance is excellent. TABLE I VALIDATION RESULTS OF THE BEST (LOWEST) LOSS. Measurement Value BCE loss 0.01562267541885376 Accuracy 0.9935703277587891 F1 Score 0.9843953251838684 Precision 0.9854521751403809 Recall 0.9833407998085022 (a) (b) (c) (d) (e) (f) Fig. 2. Validation results. Green line represents the ground truth and red line is the predicted region. The same model that obtained the best BCE loss on vali- dation dataset has 6 out of its 49 results depicted in Fig. 2. In general, the model performs well to segment the rodent’s brain in an fMRI. There is one validation result which has a small mistake in the segmentation. That is depicted in Fig 2e and it has a small predicted region on the right side of the image which means that the model predicted a “second” tiny brain. Despite that, the qualitative and qualitative results are impressive. V. DISCUSSION Much of what is known in neuroscience is derived from studies using rodent models, due to its versatility and the large selection of methods (e.g., invasive methods) available to study them. On the other hand, much of what is known about the human brain is derived from MRI and fMRI studies. Thus, fMRI holds the promise of bridging the gap between what we know about the mammalian brain. It may provide evidence to generalize results from rodent-derived studies using electrophysiology, optical, and pharmacological methods to the human model. In this context, it is important to create powerful tools that can increase the speed and the reliability of the analysis performed on data derived from rodent models and can equally be applied to human data. In this article we made a step towards democratizing deep learning tools to the neuroscience community by successfully applying a U-Net to perform skull stripping of low resolution functional magnetic resonance images from rodents. The method was quick to train, required little data due to the usage of data augmentation techniques, and qualitatively performed reasonably well. In contrast to other approaches that depend on images with high-resolution images or deformations of initial masks, U- Nets work well with low resolution images and can segment distorted images, even with motion artifacts. Additionally, by using a network that operates on images as inputs instead of a 3D tensor with all the image slices at once, we could use data augmentation strategies without major problems with respect to alignment issues. However, we recognize that U- Net may not be the best nor the fastest architecture to perform semantic segmentation. Other topologies such as Albunet, or Ternausnet [23] might deploy better segmentation at higher speeds. Additionally, because fMRI has a temporal component, recursive layers could be added to take the dynamic nature of the signal in the brain as a feature to better segment and remove the skull, perhaps even in a non-supervised manner. Consequently, a logical step is to explore how more modern architectures could perform in this task. We hope this tool helps neuroscientists to reduce time in preprocessing steps of their analysis of fMRI data in non-human models. ACKNOWLEDGMENT The two authors, Annelene Gulden Dahl and Sidney Pontes- Filho contributed equally to the work. We also thank Stefano Nichele for the comments on the manuscript. This work was supported by Norwegian Research Council SOCRATES project (grant number 270961) and received internal support as a lighthouse project in Computer Vision from the Faculty of Technology, Art and Design (TKD) at Oslo Metropolitan University, Norway. REPOSITORY Code and example data can be found in the following repository: REFERENCES [1] H. K. Hahn and H.-O. Peitgen, “The skull stripping problem in mri solved by a single 3d watershed transform,” in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2000, pp. 134–143. [2] S. Spring, J. P. Lerch, and R. M. Henkelman, “Sexual dimorphism revealed in the structure of the mouse brain using three-dimensional magnetic resonance imaging,” Neuroimage, vol. 35, no. 4, pp. 1424– 1433, 2007. [3] E. L. Bearer, X. Zhang, D. Janvelyan, B. Boulat, and R. E. Jacobs, “Re- ward circuitry is perturbed in the absence of the serotonin transporter,” Neuroimage, vol. 46, no. 4, pp. 1091–1104, 2009. [4] D. A. Vousden, J. Epp, H. Okuno, B. J. Nieman, M. van Eede, J. Dazai, T. Ragan, H. Bito, P. W. Frankland, J. P. Lerch et al., “Whole-brain mapping of behaviourally induced neural activation in mice,” Brain Structure and Function, vol. 220, no. 4, pp. 2043–2057, 2015. [5] X. Zhang, E. L. Bearer, B. Boulat, F. S. Hall, G. R. Uhl, and R. E. Jacobs, “Altered neurocircuitry in the dopamine transporter knockout mouse brain,” PloS one, vol. 5, no. 7, p. e11506, 2010. [6] M. C. van Eede, J. Scholz, M. M. Chakravarty, R. M. Henkelman, and J. P. Lerch, “Mapping registration sensitivity in mr mouse brain images,” Neuroimage, vol. 82, pp. 226–236, 2013. [7] T. Kapur, W. E. L. Grimson, W. M. Wells III, and R. Kikinis, “Segmen- tation of brain tissue from magnetic resonance images,” Medical image analysis, vol. 1, no. 2, pp. 109–127, 1996. [8] S. M. Smith, “Fast robust automated brain extraction,” Human brain mapping, vol. 17, no. 3, pp. 143–155, 2002. [9] D. W. Shattuck and R. M. Leahy, “Brainsuite: an automated cortical surface identiﬁcation tool,” Medical image analysis, vol. 6, no. 2, pp. 129–142, 2002. [10] A. Delora, A. Gonzales, C. S. Medina, A. Mitchell, A. F. Mohed, R. E. Jacobs, and E. L. Bearer, “A simple rapid process for semi-automated brain extraction from magnetic resonance images of the whole mouse head,” Journal of neuroscience methods, vol. 257, pp. 185–193, 2016. [11] S. F. Eskildsen, P. Coup´e, V. Fonov, J. V. Manj´on, K. K. Leung, N. Guizard, S. N. Wassef, L. R. Østergaard, D. L. Collins, A. D. N. Initiative et al., “Beast: brain extraction based on nonlocal segmentation technique,” NeuroImage, vol. 59, no. 3, pp. 2362–2373, 2012. [12] F. J. Galdames, F. Jaillet, and C. A. Perez, “An accurate skull stripping method based on simplex meshes and histogram analysis for magnetic resonance images,” Journal of neuroscience methods, vol. 206, no. 2, pp. 103–119, 2012. [13] W. Speier, J. E. Iglesias, L. El-Kara, Z. Tu, and C. Arnold, “Robust skull stripping of clinical glioblastoma multiforme data,” in Interna- tional Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2011, pp. 659–666. [14] H. Hwang, H. Z. U. Rehman, and S. Lee, “3d u-net for skull stripping in brain mri,” Applied Sciences, vol. 9, no. 3, p. 569, 2019. [15] S. Hahn, S. Oberbauer, R. Gebauer, N. Grulke, O. Lange, and J. Ten- hunen, “Vegetation structure and aboveground carbon and nutrient pools in the imnavait creek watershed,” in Landscape function and disturbance in Arctic tundra. Springer, 1996, pp. 109–128. [16] M. Moshfeghi, “Elastic matching of multimodality medical images,” CVGIP: Graphical Models and Image Processing, vol. 53, no. 3, pp. 271–282, 1991. [17] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for biomedical image segmentation,” in International Conference on Medical image computing and computer-assisted intervention. Springer, 2015, pp. 234–241. [18] M. Modat, J. McClelland, and S. Ourselin, “Lung registration using the niftyreg package,” Medical image analysis for the clinic-a grand Challenge, vol. 2010, pp. 33–42, 2010. [19] N. Malpica, C. O. De Sol´orzano, J. J. Vaquero, A. Santos, I. Vallcorba, J. M. Garc´ıa-Sagredo, and F. Del Pozo, “Applying watershed algorithms to the segmentation of clustered nuclei,” Cytometry: The Journal of the International Society for Analytical Cytology, vol. 28, no. 4, pp. 289– 297, 1997. [20] G. Bradski, “The OpenCV Library,” Dr. Dobb’s Journal of Software Tools, 2000. [21] P. Y. Simard, D. Steinkraus, J. C. Platt et al., “Best practices for convolutional neural networks applied to visual document analysis.” in Icdar, vol. 3, no. 2003, 2003. [22] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” arXiv preprint arXiv:1412.6980, 2014. [23] S. Wang, Y. Hua, Y. Cao, T. Song, Z. Xue, X. Gong, G. Wang, R. Ma, and H. Guan, “Deep learning based fetal middle cerebral artery segmentation in large-scale ultrasound images,” in 2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE, 2018, pp. 532–539."
A Scalable Population Code for Time in the Striatum,Gustavo B.M. Mello and Sofia Soares and Joseph J. Paton,2015,9.0,25,Current Biology,article,"Article
A Scalable Population Code for Time in the Striatum
Highlights
d Striatal neurons ﬁre at different times over tens of seconds
during timing behavior
d Response times of striatal neurons rescaled with the interval
being timed
d Time coding by the population predicted timing behavior
from trial to trial
d Striatal neurons multiplexed information about action and
time
Authors
Gustavo B.M. Mello, Soﬁa Soares,
Joseph J. Paton
Correspondence
joe.paton@neuro.fchampalimaud.org
In Brief
Time is fundamental for all behavior, yet
how the brain encodes time is unknown.
Mello, Soares, and Paton found that ﬁring
dynamics in populations of neurons in the
rodent striatum robustly and ﬂexibly
encoded time over tens of seconds.
These results supply new insight into how
the basal ganglia might function during
learning and action selection.
Mello et al., 2015, Current Biology 25, 1113–1122
May 4, 2015 ª2015 Elsevier Ltd All rights reserved
http://dx.doi.org/10.1016/j.cub.2015.02.036
 Current Biology
Article
A Scalable Population Code for Time
in the Striatum
Gustavo B.M. Mello,1,2,3 Soﬁa Soares,1,2,3 and Joseph J. Paton1,2,*
1Champalimaud Neuroscience Programme, Champalimaud Centre for the Unknown, Lisbon 1400-038, Portugal
2Instituto Gulbenkian de Cieˆ ncia, Oeiras 2780-156, Portugal
3Co-ﬁrst author
*Correspondence: joe.paton@neuro.fchampalimaud.org
http://dx.doi.org/10.1016/j.cub.2015.02.036
SUMMARY
To guide behavior and learn from its consequences,
the brain must represent time over many scales. Yet,
the neural signals used to encode time in the sec-
onds-to-minute range are not known. The striatum
is a major input area of the basal ganglia associated
with learning and motor function. Previous studies
have also shown that the striatum is necessary for
normal timing behavior. To address how striatal sig-
nals might be involved in timing, we recorded from
striatal neurons in rats performing an interval timing
task. We found that neurons ﬁred at delays spanning
tens of seconds and that this pattern of responding
reﬂected the interaction between time and the ani-
mals’ ongoing sensorimotor state. Surprisingly, cells
rescaled responses in time when intervals changed,
indicating that striatal populations encoded relative
time. Moreover, time estimates decoded from activ-
ity predicted timing behavior as animals adjusted to
new intervals, and disrupting striatal function led to
a decrease in timing performance. These results sug-
gest that striatal activity forms a scalable population
code for time, providing timing signals that animals
use to guide their actions.
INTRODUCTION
To behave adaptively in complex, ever-changing environments,
animals must learn which actions to take in a particular context
based on their past experience. However, to learn about the
sometimes-delayed consequences of actions and to guide
future behavior, it is absolutely necessary that the brain repre-
sent not only actions and consequences but also temporal infor-
mation about when those actions and consequences occur [1].
Multiple lines of evidence implicate the basal ganglia (BG) as a
locus for the representation of such temporal information. Le-
sions of the striatum in rats [2], disease states that affect the
BG such as Parkinson’s [3] and Huntington’s disease [4], drugs
that affect dopamine (DA) signaling [5], and genetic manipula-
tions that affect the DA system in the BG [6] all result in interval
timing dysfunction. Furthermore, human fMRI studies have
found that the striatum, a main input area of the BG, is activated
by tasks that involve the processing of interval information [7, 8].
In addition, many theoretical models have been proposed
to explain timing behavior. These models can be grouped
into at least three categories. Pacemaker-accumulator models
integrate pulses emitted from a central pacemaker to measure
elapsed time [9, 10]. Beat frequency models detect patterns
of activation across resettable oscillatory processes at dif-
ferent frequencies to encode time delays from a resetting
event [11]. Sequential state models contain orderly transitions
between different activity states that can be used to encode
time [12–14]. These theories reproduce various aspects of
timing
behavior in
many interval
timing
tasks.
However,
neural data in conﬂict or in support of the various theories are
lacking.
To understand how time is encoded in neural circuits, we re-
corded the spiking activity of neurons as rats performed an inter-
val timing task. Speciﬁcally, given the apparent localization of
timing function in striatal tissue, we asked whether striatal neural
activity could encode elapsed time over durations of tens of sec-
onds to 1 min while we measured behavior that reﬂected ani-
mals’ estimates of time.
We found that different striatal neurons ﬁred maximally at
different delays from reward receipt and that information about
animals’ time estimates could be extracted from striatal popula-
tions by simply treating neurons as tuned for time. Importantly,
this tuning for time, while affected by sensorimotor event-related
neural responses, could not be fully explained by ongoing
behavior, as even cells that displayed responses locked to a spe-
ciﬁc behavior varied their responses depending on when that
behavior was executed within a given interval. Strikingly, we
found that temporal tuning stretched or contracted, rescaling
with the interval being timed. Thus, striatal populations encoded
relative time, ﬂexibly adapting to the immediate demands of the
environment. Finally, we ran a simple simulation of the task and
show that neural responses resembling those we observe in the
striatum are suitable as a basis for timing behavior. These results
provide important biological insight into how a major brain sys-
tem encodes time during behavior.
RESULTS
Lever Pressing Start Time under Fixed Interval
Reinforcement Schedules Is a Behavioral Measure of
Rats’ Expectation of Time until Reward
To elicit robust time-dependent behavior over a broad range of
timescales, we employed operant conditioning procedures un-
der ﬁxed interval (FI) schedules of reinforcement (Figure 1A).
Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved
1113
 Brieﬂy, rats were placed in a behavioral box containing a lever
positioned over a liquid delivery port and were trained to press
the lever to receive water reward. Reward delivery triggered a
timer, and reward became available again only after the timer ex-
ceeded a FI ranging from 12 s to 60 s in multiples of 12 s. Lever
presses occurring after reward delivery but before the FI had
elapsed were not reinforced. A FI was maintained for between
18 and 40 rewards before changing to another FI, randomly cho-
sen from the interval set.
In single sessions, rats tended to distribute lever pressing
toward the latter portion of the FI, shifting when they responded
as FI changes occurred (Figures 1B and S1A). This pattern of re-
sponding produced ramps in block-wise averaged pressing as a
function of time that varied in slope in relation to FI (Figures 1C
and S1B). However, this did not reﬂect the pattern of responding
in single trials. We asked how pressing evolved after pressing
onset (pressing start times, PSTs) in each trial by aligning on
the PST and averaging lever press rates across trials and within
blocks of the same FI (Figure 1D). Rats pressed at a relatively
constant rate after the ﬁrst press in each trial, with a rate deter-
mined by the experienced reward rate (Figure S1C). The ramps
in the reward-aligned pressing as a function of time largely result
from changing distributions of PSTs (Figure 1E), as these vary
systematically with FI, and averaging a group of step functions
with onset times drawn from these distributions will produce
ramps of varying slope.
This serial ﬁxed interval (SFI) lever pressing task produced
systematic variation in the distributions of PSTs of bouts of antic-
ipatory pressing, consistent with previous timing studies em-
ploying FI schedules of reinforcement [9]. These bouts were of
a relatively constant rate that varied with reward rate over time
(Figures 1D and S1C). The PST thus provided a behavioral metric
that covaried with the animals’ changing expectation about time
until the next available reward, which we compared to the activity
of neurons recorded in the striatum during performance of the
task as described below.
Striatal Neurons Display Temporal Tuning
In the SFI task, reward delivery is both the timing cue and the
reinforcer. Since animals reported knowledge of time between
reward availability by when they began to press a lever, we
asked whether neuronal responses in the striatum aligned on
reward might reveal a signal that animals could use to guide
the decision of when to begin pressing. We recorded broadly
in the dorsal striatum so as to sample neurons from regions pre-
viously shown to be important for interval timing behavior [2]
(inset in Figure S1D), and the vast majority of units we recorded
exhibited average ﬁring rates of less than ﬁve spikes per second,
consistent with a population made up of mostly medium spiny
projection neurons [15] (Figure S1D).
Aligned on reward delivery, the population of recorded cells
exhibited a broad distribution of activity patterns, as reﬂected
12s 24s 36s 48s or 60s
reward
lick
lever press
reward 
available
FI = 
time from reward (s)
trial number
time
0
30
20
10
40
50
0
120
20
40
60
100
80
60
180
160
140
200
lever press
pressing start time (s)
10 20 30 40 50 60
10
20
30
40
50
60
time from reward (s)
pressing rate (Hz)
10
20
30
40
50
60
0.4
0.3
0.2
0.1
0.0
0
0.5
0.6
pressing rate (Hz)
10
20
30
0
-4
0.5
0.0
0.4
0.3
0.2
0.1
0.6
40
50
0
0
PST density
JP 27 2010_06_23
A
B
C
D
E
60
Figure 1. The SFI Task Produces Systematic Changes in Lever PST
(A) Task structure. The following color code will be commonly used: blue represents short FIs, and green represents longer FIs.
(B) Example of lever pressing behavior in a single session of the SFI task. Gray markers indicate a lever press; red markers indicate the PST.
(C) Average lever pressing rate in each of the ﬁve FIs, aligned on preceding reward. Dashed lines represent SEM.
(D) Average rate of lever pressing in each block, aligned on PST. Traces are plotted on a solid line for the period for which more than half of the trials contribute data
and on a dotted line after that point. Shaded patches along the horizontal axis represent SEM. 1 s bins are indicated in (C) and (D).
(E) Median and interquartile range of PST for each of the ﬁve FIs. Smoothed density functions depicting the full distributions of PST are shown on the right.
See also Figure S1.
1114
Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved
 in the normalized spike density functions (SDFs; see Supple-
mental Experimental Procedures for details) shown in Figure 2A.
Some cells ﬁred just after reward delivery, others ﬁred in the
middle of the delay, and others ﬁred leading up to the next
reward (Figures 2A, S2, and S3). This produced a slow-moving
‘‘bump’’ of activity that traversed the population during each
FI. In theory, reading out the location of this bump in the popula-
tion could provide an estimate of time within the FI. However, a
core feature of interval timing behavior is that timing accuracy
decreases with the magnitude of the interval being timed [9].
Two features of the neural data could potentially contribute to
this phenomenon: an increased spread of each neuron’s re-
sponses as a function of their peak latency and a decreasing
density of neurons displaying peak ﬁring rates as time pro-
gresses. We found that the widths of responses were indeed
correlated with their latencies to peak ﬁring within each FI (Fig-
ure 2B, linear regression, FI 12 s, R = 0.4443, p < 0.001; FI
24 s, R = 0.7563, p < 0.001; FI 36 s R = 0.7188, p < 0.001; FI
48 s, R = 0.5910, p < 0.001; FI 60 s R = 0.4733, p < 0.001; see
Supplemental Experimental Procedures for details). In addition,
the density of peak ﬁring rate latencies in our population
decreased over time within the FI (Figure 2C). Thus, the bump
in activity within the striatum population moved progressively
slower as the FI wore on. Strikingly, the overall time taken by
this bump to traverse the population appeared to scale with
the FI (Figures 2A and S4A). To begin to assess apparent scaling
of response times, we ﬁrst selected cells that we had recorded in
all ﬁve FIs and that maintained their ordinal position within the
population when responses within each FI were ordered by ﬁring
dynamics [16]. Of the 112 neurons recorded in all FIs, we found
that 76 neurons (68%) maintained their ordinal position in time
across the population (see Supplemental Experimental Proce-
dures for details). The responses of these neurons can be
observed in Figure 2A, wherein the position of cells along the
y axis is the same across the panels displaying average re-
sponses in each of the FIs (for all recorded cells, see Figure S4A).
To quantify to what degree responses rescaled, we computed
a scale factor for each neuron as the ratio of the center of mass
(COM) of the SDF in the 12-s FI over the COM of the SDF in each
of the other four FIs (Figure 3A). The distributions of these scale
factors were sharper than and signiﬁcantly different from null dis-
tributions generated by shufﬂing cell identity across FIs and
recomputing the scale factors (red distributions in Figure 3A, Kol-
mogorov-Smirnov test, p < 0.001 for all pairwise comparisons).
The medians of these distributions, were the population to
have rescaled its responses in direct proportion to the FI, should
lie at 1/2, 1/3, 1/4, and 1/5 for the scale factors corresponding to
12/24 s, 12/36 s, 12/48 s, and 12/60 s FIs, respectively. We
observed median values of 0.59, 0.39, 0.30, 0.24 for the corre-
sponding distributions, indicating near-proportional rescaling
of response times across the recorded striatal population. A
more-complete description of the relative scale of responses
can be seen in Figures 3B–3E, where the COM of each cell’s
SDF in the 12-s FI against each of the other FIs are displayed.
These data demonstrate a strong tendency for rescaling of neu-
ral responses across the population, suggesting that the state of
striatal populations may convey relative elapsed time informa-
tion scaled to the animal’s estimate of the current behaviorally
relevant timescale in the environment. We explore this hypothe-
sis in greater detail below.
Striatal Populations Encode Information about Timing
Behavior
The above analyses of striatal neural responses indicate a gross
correspondence between striatal activity and timing behavior
across blocks of trials, suggesting that striatal activity patterns
response latency (s)
response width (s)
10
20
30
0
0
20
15
10
5
40
B
time relative to reward (s)
cell #
FI = 12
FI = 24
FI = 36
FI = 48
FI = 60
A
ring rate (z)
response latency
(time/FI)
0.2
0.4
0.6
0
0.8
0
8
6
4
2
10
18
16
14
12
count
C
20
40
60
0
-12
12
#
""#
$#
%#
""#
$#
%#
""#
$#
%#
""#
$#
%#
#
$
#
""##
""
$#
$#
%#
%#
%#
%#
""#
$#
%#
#
""##
""
$#
$#
$#
%#
%#
%#
%#
""#
$#
%#
""##
""
$#
$#
$#
%#
%#
%#
%#
""#
$#
%#
#
""##
""
$#
$#
$#
%#
%#
%#
%#
20
40
60
0
-24
24
20
40
60
0
-36
36
20
40
60
0
-48
48
20
40
60
0
-60
60
10
5
0
Figure 2. Striatal Neurons Display Variable Responses that Tile Tens of Seconds to 1 Min
(A) SDFs of neurons that maintained their relative ordinal position in time within the population across all ﬁve FIs, aligned on reward.
(B) Width of each cell’s response within each FI as a function of latency to peak ﬁring. Colored lines represent the best linear ﬁt to the data.
(C) Histogram of relative peak latencies pooled over all FIs, using data shown in (B).
See also Figure S2.
Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved
1115
 might guide decisions about when to begin pressing the lever
during each FI. To test this hypothesis, we applied a decoding
approach to data collected from single trials near block transi-
tions, wherein animals systematically changed the time that
they began to press the lever. Speciﬁcally, we asked three ques-
tions. First, we asked whether decoded time estimates covaried
with true time. Second, we asked whether systematic errors in
estimated time as compared to true time occurred at these block
transitions. Lastly, we asked whether any observed errors in time
encoding correlated with timing behavior.
We ﬁrst built a probabilistic decoder to derive an estimate of
elapsed time from reward in single trials given the observed
spiking response of the population. We focused on the ﬁrst trials
of the 12-s and 60-s FI blocks because these blocks were the
shortest and longest FIs employed, respectively. Thus, animals
consistently overestimated and underestimated the amount of
time remaining until reward as they entered 12-s and 60-s
blocks. Brieﬂy, our decoder was constructed as follows. In
each of the ﬁrst seven trials of a block, we counted spikes within
deﬁned time bins and asked how likely we were to have
observed that number of spikes at each time given the observed
distributions of spike counts in trials 8 onward of the correspond-
ing block. This generated a likelihood function for current time,
given an observed spike count in each bin, for each individual
cell. To derive a measure of the population’s estimate of the like-
lihood for current time, we multiplied together the individual cells’
likelihood functions. We then took the mean of this likelihood
function as our estimate for current time [17].
In Figures 4A and 4C, we display decoded estimates as a func-
tion of time for the ﬁrst seven trials of 12-s and 60-s FI blocks. We
found that decoded estimates tracked true time but that system-
atic errors between estimates and true time were present in the
ﬁrst few trials of the 12-s and 60-s FI blocks. This feature can be
observed more readily when estimates derived from multiple tri-
als are plotted on the same axes (Figures 4B and 4D, quadratic
ﬁts). Initial estimates were relatively slow and fast in the ﬁrst trials
of the 12-s and 60-s FI blocks, respectively, and became more
accurate after the ﬁrst few trials.
Next we asked whether such timing signals may be used by
animals to guide timing behavior. We ﬁrst asked whether errors
in decoded time estimates over the ﬁrst trials of blocks were
correlated with timing behavior. We found that the mean PST
was signiﬁcantly correlated with the errors in time estimates
derived from the population over the ﬁrst seven trials of 12-s
and 60-s FI blocks (Figure 5; FI = 12, R2 = 0.63, p = 0.03; FI =
60, R2 = 0.64, p = 0.03). In the initial trials of the 12-s FI block,
rats began pressing late relative to subsequent trials, and like-
wise, the decoded estimate of time relative to reward ran slow
(Figures 4B and 5). The ﬁrst trials of the 60-s FI block showed
a similar relationship, yet opposite in direction: the decoded
estimate ran quickly in early trials, and rats were early to press
(Figures 4D and 5). We then tested in two control animals
whether manipulating striatal circuitry via bilateral infusions of
the GABAa agonist muscimol produced deﬁcits in timing
behavior (Figure S5). Indeed, at a dose that rendered rats able
to perform the task, muscimol reversibly and signiﬁcantly dimin-
ished the relationship between PST and FI (linear regression,
likelihood ratio test, signiﬁcant effect of treatment, p < 0.001),
showing that a normally functioning striatum is critical for normal
timing behavior. The consistency between time estimates de-
coded from striatal populations and trial-by-trial variations in
timing behavior at block transitions, together with observed
dependence of a normally functioning striatum for normal timing
behavior, suggests that the brain uses a population code for time
that samples broadly from striatal neurons to guide decisions
about when to act.
Striatal Neurons Multiplexed Information about Action
and Time
Based on previous studies [18–20], we expected that striatal
neurons would display signiﬁcant modulation by behaviors dur-
ing the FI. Could behaviors that accompany task performance
fully explain the sequential neural responses we observed?
Several features of the data argue against this possibility. Rats
consistently licked at the reward port from 0.5 s to 5.5 s after
reward delivery (Figure S4B), and yet, our ability to decode
time was unaffected by the animal being engaged in a ﬁxed
behavior over this time (see initial 5 s of decoded time esti-
mates in Figures 4A and 4C). After departing from the reward
port, however, it is possible that observed dynamics in neural re-
sponses are accounted for by ongoing behaviors. Were this the
case, responses related to a particular behavior should not vary
A
C
0
12
24
36
48
60
0
6
12
0
12
24
36
48
60
0
6
12
0
12
24
36
48
60
0
6
12
0
12
24
36
48
60
0
6
12
B
E
D
center of mass 24s FI
center of mass 36s FI
center of mass 48s FI
center of mass 60s FI
center of mass 12s FI
center of mass 12s FI
center of mass 12s FI
center of mass 12s FI
cell count
com 12sFI / com XsFI
0
0.5
1.0
1.5
2.0
0
20
20
20
20
0
0
0
X = 24
X = 36
X = 48
X = 60
Figure 3. Striatal Neurons Rescale Their Response Time with FI
(A) Distributions of scale factors obtained by calculating the ratio of the center of mass (COM) of the SDF between the 12-s FI and X-s FI (24 s, 36 s, 48 s, and 60 s,
respectively, from blue to green) for each cell. For each distribution of scale factors, a null distribution was generated by shufﬂing cell identity across FIs and
recomputing the scale factors (red).
(B–E) COM of each cell’s SDF in the 12-s FI against each of the other FIs. The black dotted line signiﬁes no change in COM from block to block. The colored dotted
line signiﬁes a change in COM that is proportional to the change in FI relative to the 12-s FI.
See also Figure S3.
1116
Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved
 depending on when in a trial the rat engaged in that behavior.
To identify neurons that were signiﬁcantly modulated by a
measured behavior in our task, we focused on a 2.5-s epoch
centered on the PST in each trial. We found that of the 76 neu-
rons displayed in Figure 2A, 31 exhibited signiﬁcant modulations
around the onset of lever pressing. Next, we asked whether
spiking observed in time bins aligned on the PST was addition-
ally correlated with the time, relative to the FI, that pressing onset
occurred. More than half of pressing onset-modulated neurons
(16/31, 52%) displayed a signiﬁcant correlation between spiking
around each press initiation and the relative time that press onset
occurred within the FI (Pearson’s linear regression, p < 0.01). Fig-
ures 6A–6D show examples of four such neurons from three
different animals, all of which vary in their responses around
the PST, from none at all to robust ﬁring.
The regression approach described above is only expected to
identify neurons that display a monotonic relationship between
pressing onset response and the relative time of pressing onset.
Other cells may have displayed signiﬁcant time-dependent mod-
ulations in pressing onset response that were not monotonic (for
example, see Figures S2B and S3A). To identify such cells, we
asked whether the median of distributions of spikes counts,
collected around pressing onsets and falling into each of ﬁve
quintiles of relative PSTs, differed from each other. We found
that 53 out of 76 neurons (70%) displayed in Figure 2A exhibited
signiﬁcantly different median spike counts across relative time
0
2
4
6
8 10
10
8
6
4
2
0
0
2
4
6
8 10
10
8
6
4
2
0
0
2
4
6
8 10
10
8
6
4
2
0
0
2
4
6
8 10
10
8
6
4
2
0
10
8
6
4
2
0
10
8
6
4
2
0
10
8
6
4
2
0
10
8
6
4
2
0
7 trial average
trial #: 1
2
3
4
5
6
7
decoded time (s)
A
B
trial number
1
7
time relative to reward (s)
time relative to reward (s)
0 10 20 30 40 50
50
40
30
20
10
0
0 10 20 30 40 50
50
40
30
20
10
0
0 10 20 30 40 50
50
40
30
20
10
0
0 10 20 30 40 50
50
40
30
20
10
0
0 10 20 30 40 50
50
40
30
20
10
0
0 10 20 30 40 50
50
40
30
20
10
0
0 10 20 30 40 50
50
40
30
20
10
0
0 10 20 30 40 50
50
40
30
20
10
0
7 trial average
trial #: 1
2
3
4
5
6
7
decoded time (s)
time relative to reward (s)
trial number
1
7
time relative to reward (s)
C
D
decoded time (s)
decoded time (s)
10
0
8
6
4
2
2
4
6
0
8 10
10
0
8
6
4
2
2
4
6
0
8 10
10
0
8
6
4
2
2
4
6
0
8 10
10
0
8
6
4
2
2
4
6
0
8 10
10
0
8
6
4
2
2
4
6
0
8 10
10
0
8
6
4
2
2
4
6
0
8 10
50
0
40
30
20
10
10 20 30
0
40 50
50
0
40
30
20
10
10 20 30
0
40 50
50
0
40
30
20
10
10 20 30
0
40 50
50
0
40
30
20
10
10 20 30
0
40 50
50
0
40
30
20
10
10 20 30
0
40 50
50
0
40
30
20
10
10 20 30
0
40 50
10
0
8
6
4
2
2
4
6
0
8 10
10
0
8
6
4
2
2
4
6
0
8 10
50
0
40
30
20
10
10 20 30
0
40 50
50
0
40
30
20
10
10 20 30
0
40 50
10
0
8
6
4
2
2
4
6
0
8
10
50
0
40
30
20
10
10
20
30
0
40
50
Figure 4. Single-Trial Estimates of Elapsed Time Decoded from the Population Response Correlate with True Time during Initial Trials of 12-s
and 60-s FI Blocks
(A) Decoded population estimates of elapsed time from reward in single trials, for the ﬁrst seven trials of the 12-s FI block plotted against true time. Red traces
indicate the mean of the population likelihood function, and the underlying heatmap indicates the population likelihood function. The last panel shows a seven-trial
average likelihood function using the ﬁrst seven trials of the 12-s block.
(B) Decoded estimates of elapsed time for the ﬁrst seven trials of the 12-s FI block plotted on the same axis. Curves are quadratic ﬁts to the mean likelihood
function of each individual trial (red lines in ﬁrst seven panels). Red curves represent early trials, and black curves represent later trials.
(C) Same description as in (A), but for the 60-s FI.
(D) Same description as in (B), but for the 60-s FI.
See also Figure S4.
Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved
1117
 within the FI (p < 0.01, Kruskal-Wallis). Of these, nine cells were
signiﬁcantly modulated by the onset of lever pressing and were
not identiﬁed in the linear regression analysis. Overall, only six
cells that displayed response modulation around PST did not
exhibit additional modulation by relative time in the FI as
assessed by linear regression and/or nonparametric testing for
median difference in spike count. These results suggest that
striatal neurons multiplex information about time and immediate
sensorimotor state of the animal and argue strongly against the
possibility that the striatal population responses we observed
can be explained by purely non-time-related responses to spe-
ciﬁc sensory or motor components of ongoing behavior.
A Simple Simulation of Timing Behavior
In order to understand the relationship between the recorded
striatal signals and rats’ behavior, we ran a simple simulation
that performed the SFI task (Figure 7A). The core of this simula-
tion is comprised of a set of temporal basis functions that were
inspired by the diverse single-neuron responses observed in
our striatal dataset as well as existing timing and learning models
[21–24]. We used the method described in [23] to generate tem-
poral bases. Each function was used as a rate function for gener-
ating inhomogeneous Poisson spike trains from which time was
read out during task performance. Whenever this time readout
passed a threshold, presses were produced at a ﬁxed rate. In
order to adapt to the changing FIs, we implemented a simple
learning rule to update a temporal scale factor for the basis func-
tions depending on the difference between expected time of
reward and encoded time at the time of reward delivery. Lastly,
to account for our observation that many striatal neurons multi-
plexed information about action and time, each press produced
a response in the temporal bases that was proportional to the
product of the original time-dependent rate function at the time
of the press and a rate function generated by the press itself.
With these elements, we ran the simulation under the conditions
contained in the SFI task.
The simulation produced qualitatively similar behavior to that
of rats (Figures 7B and S6) and reproduced the three main fea-
tures that we observed in striatal neurons: temporal tuning,
rescaling of neural responses (Figure 7C), and multiplexing of in-
formation about action and time (Figure 7D). Although simple,
the simulation serves as proof of principle that neural activity
with the properties that we observe in this study can serve as a
basis for timing behavior and suggests candidate computational
elements such as a scale factor and temporal error signal for
which there might exist functional analogs in the brain.
DISCUSSION
Time is a fundamental dimension of animals’ experience in the
world. As such, it plays an integral role in many brain processes,
from perception to motor control to learning and memory forma-
tion. What is the role of temporal representation within the BG? A
dominant view supported by a wide range of neurobiological
data posits that the BG implements aspects of reinforcement
learning (RL) [1, 20, 25–28], learning how an organism ought to
act in order to maximize reward. However, to learn about the
sometimes-delayed consequences of actions and to guide
future behavior toward rewarding outcomes, it is absolutely
necessary that the brain represent situations and actions
through time [1, 29]. Indeed, temporal relations among actions
and events contain the causal information that learning systems
have evolved to detect through a process sometimes referred to
as credit assignment [30]. Once credit for the occurrence of pre-
dictable events has been assigned, this information must be
used to proﬁtably guide the course and timing of action as situ-
ations arise. This continuous learning-behaving cycle is what RL
algorithms naturally account for [29]. Yet, it is not known how the
BG, the brain system most often associated with RL, represents
temporal relationships over the durations necessary to explain
its purported role in animal learning and behavior.
The sequential neural states that we describe in the striatum
during timing behavior can provide a unifying view of the BG’s
role in timing and RL. These signals are strikingly similar to tem-
poral basis functions proposed in existing learning models as
more neurally plausible and efﬁcient representations of time
[21–23], which we show can be used to generate timing behavior
similar to what we observed experimentally. Such models
operate by learning a set of weights used in a weighted sum
of the temporal bases to construct a moment-by-moment
prediction about future events such as expected reward. In
theory, a weighted combination of activity patterns in the cortical
or thalamic inputs to the striatum could act as such temporal
bases and modulate the responses of striatal neurons that we
observed.
An important question for future studies concerns the mecha-
nism that generated the striatal dynamics we observed. We
ﬁnd it unlikely, given the duration of the intervals we examined,
that striatal dynamics were purely locally generated, although
several modeling studies suggest mechanisms for generat-
ing sequential activity states using striatum-like circuitry over
10
15
20
25
0.20
0.15
0.10
0.05
0.0
0.05
0.10
0.15
mean error,
 true time - readout
 (fraction of FI)
R2: 0.63, p=0.03
R2: 0.64, p=0.03
pressing start time (s)
Figure 5. Errors in Decoded Time Predicted Timing Behavior
Mean error between true time and the decoded population estimate in the ﬁrst
seven trials of the 12-s (blue) and 60-s (green) FI blocks. Contiguous trials are
connected by solid lines to display the trajectory of the data over trials, and the
ﬁrst trial on each block is indicated by the black arrow. Dashed horizontal gray
line represents zero error average decoding as compared to true time. See
also Figure S5.
1118
Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved
 shorter timescales [31, 32]. Indeed, the signals we use to decode
time were affected, but not fully explained by, the ongoing
sensorimotor state of the animal. Thus, our decoding approach
implicitly endorses a number of prominent interval timing
theories, positing that animals may use behavioral [12, 14] or
sensory state [33] transitions to learn to time events in the envi-
ronment and their own behavior.
Our data appear most consistent with theoretical models that
suggest distributed representations of time encoded by the joint
activity of populations of neurons [13]. Indeed, the decoder used
in the current study assumes that time information may be pre-
sent in many different neurons. However, we cannot rule out
that upstream of the population we recorded in the striatum,
other forms of temporal representations may exist. For instance,
an accumulating process such as that contained within pace-
maker accumulator models [9] might act to trigger neurons to
become active at different delays as the accumulator passes a
series of thresholds.
We show that sequential neural activation in the striatum can
be used to encode time on a scale of tens of seconds up to
1 min. These results add to a growing list of studies that demon-
strate sequential activation of neurons over multi-second time-
scales in other brain areas, such as the hippocampus [34, 35],
the cerebellum [36], the parietal cortex [37], and the prefrontal
cortex [38–40]. Unlike previous studies, we found that many indi-
vidual striatal neurons exhibited responses that dynamically re-
scaled with the timing of events in the environment and that
this scaling of responses produced changes in time encoding
by the population that correlated with timing behavior. Com-
bined with previous studies highlighting the importance of a nor-
mally functioning striatum for timing behavior [2–4, 6], the effect
of striatal inactivation in the current study, and other work that
demonstrated time encoding by striatal populations over shorter
timescales [41], our results suggest that information about where
in time a subject ﬁnds itself relative to anticipated events in the
environment is present in populations of striatal neurons and is
used to guide behavior.
Similar timing signals observed in areas other than the striatum
are viewed within the larger context of the functional role of
those areas where they were recorded. Timing signals in the
!
!""#
$
%!
&!
'!
#!
!
!""#
$
!
#
!
!""#
$
!
$!
%!
&!
0
0.5
1
0
5
10
15
20
−!
""
!
""
!""
#""
$""
!""""
!$""
−!
""
!
""
!""
#""
$""
%""
!""""
!%""
−!
""
!
!""
#""
$""
%""
&""
&""
!""""
!&""
−!
""
!
""
#
$
%
&
'""
!""""
!'""
A
B
C
D
trials ordered by PST/FI
JP41_11_06_23nr23
JP41_11_06_23nr25_02
JP27_10_06_12nr27_02
JP28_10_06_25nr13
R2: 0.24, p<10-12
R2: 0.13, p<10-6
R2: 0.16 p<10-7
R2: 0.17 p<10-8
50
100
150
50
100
150
50
100
150
50
100
150
10
20
40
30
50
0
2
6
4
8
0
10
20
30
0
10
20
20
30
40
50
0
5
0
10
20
30
0
10
15
20
5
0
-1
1
0
-1
1
0
-1
1
0
-1
1
0
-1
1
0
-1
1
0
-1
1
0
-1
1
0.5
0
1
0.5
0
1
0.5
0
1
0.5
0
1
Figure 6. Pressing Onset Responsive Neurons Display Sensitivity to the Time Relative to the FIs
(A–D) Four single-neuron peri-stimulus time histograms (top) and raster plots (middle) of 2.5-s epochs aligned on pressing onset event (from three animals; the
two ﬁrst columns display data from two neurons recorded in the same animal and same session). Trials were sorted in ascendant fashion from bottom to top on
the vertical axis by the pressing onset time relative to the FI (middle) and grouped into quintiles. Here, the colors from gray to red represent the ﬁrst to the ﬁfth
quintile, respectively (middle and top panels). Bottom panels: correlation between the ﬁring rate of the respective neuron and the time of the pressing onset
relative to FI. Each data point is color coded from gray to red for the ﬁrst to the tenth decile of the relative pressing onset time. Firing rates were extracted from the
most modulated 500 ms bin of the four bins surrounding the pressing onset event.
Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved
1119
 hippocampus might endow explicit memories with accurate in-
formation about the order and temporal context of events [24],
and timing signals in the cerebellum might coordinate learned
actions at a ﬁne timescale [36], while timing signals in premotor
cortex might enable accurate timing of movement in general [42].
The striatal neurons we observed appear to multiplex temporal
information with other, non-temporal types of information, such
as signals related to the ongoing sensorimotor state of the animal
and likely other previously identiﬁed striatal signals related to
actions, motor sequences, or reinforcement [19, 26–28]. Such
multiplexing of temporal and other information in populations
of striatal neurons as observed in the current study is likely to
be critical to the previously ascribed and often-studied function
of the BG in learning and action selection.
A
C
D
B
Figure 7. A Simple Simulation of Timing Behavior
(A) Firing of striatal neurons was modeled based on receptive ﬁelds for the height of a decaying trace that is reset in each trial by reward delivery (top left). This
trace can decay faster (solid line) or slower (dotted line) by adjusting the parameter g. The Gaussian functions (top right) represent receptive ﬁelds evenly spaced
along the height of the trace function. The trace function was multiplied by the receptive ﬁelds to generate rate functions, the levels of which vary across time as
the memory trace decays. Spike counts observed within deﬁned time bins were then multiplied by the logarithm of their respective rate functions and summed to
compute the population log likelihood function for current time given the population response, from t = 0 to t = FI. The maximum of this likelihood function was
used to derive our estimate for current time relative to reward, for each time bin. Decoded time estimates can run faster or slower depending on whether the trace
function decays quickly or slowly. For each trial, when the decoded time estimate reached a given threshold (red dotted line), we simulated a probabilistic
pressing process. If the decoded estimate runs too slowly, it fails to reach the threshold value for expected reward (blue dotted line) before the current FI elapses,
and the reward happens before it was expected (dotted black box), generating a large prediction error that drives appropriate updating of g in the next trial. If the
decoded estimate runs more accurately (solid black box), a small prediction error is generated, and g is minimally adjusted in the next trial.
(B) Example of simulated lever pressing behavior on the SFI task. Gray markers indicate a lever press; red markers indicate the PST.
(C) SDFs of simulated units ordered by response proﬁle. Each panel corresponds to one FI.
(D) Four single-unit peri-stimulus time histograms of 2.5-s epochs aligned on pressing onset event (top). Trials were grouped in quintiles of the relative PST. The
colors from gray to red represent the average ﬁring in the ﬁrst to the ﬁfth quintile, respectively. The bottom panel shows the correlation between the ﬁring rate of
the correspondent unit on the top panel and the PST relative to FI. Each data point is color coded from gray to red for the ﬁrst to the tenth decile of the relative PST.
See also Figure S6.
1120
Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved
 EXPERIMENTAL PROCEDURES
All experiments were in accordance with the European Union Directive 86/609/
EEC and approved by the Portuguese Veterinary General Board (Direcc¸ a˜ o-
Geral de Veterina´ ria, project approval 014303 - 0420/000/000/2011). Five
male Long-Evans hooded rats were used in the neurophysiological experi-
ments, and two male Long-Evans rats were used for the muscimol experi-
ments. All isolated units (179 total from 5 rats, 25 R1, 9 R2, 21 R3, 28 R4, 96
R5) recorded for at least three blocks in sessions in which PSTs correlated
signiﬁcantly with FI (p < 0.05) were included in subsequent analyses. All ana-
lyses and simulations were performed using custom software in MATLAB
(MathWorks). See Supplemental Experimental Procedures for a detailed
description of methods and procedures.
SUPPLEMENTAL INFORMATION
Supplemental Information includes Supplemental Experimental Procedures
and six ﬁgures and can be found with this article online at http://dx.doi.org/
10.1016/j.cub.2015.02.036.
AUTHOR CONTRIBUTIONS
G.B.M.M. and J.J.P. designed the experiments. G.B.M.M. and S.S. carried out
the experiments. G.B.M.M., S.S., and J.J.P. analyzed the data and wrote the
manuscript.
ACKNOWLEDGMENTS
We thank Bassam Atallah, Brian Lau, Kenway Louie, Christian Machens, Zach-
ary Mainen, Thiago Gouveˆ a, Eric DeWitt, Alfonso Renart, and Masayoshi Mur-
akami for critical comments on versions of the manuscript and discussions.
We thank the histopathology and vivarium staff from the Champalimaud Scien-
tiﬁc and Technological Platforms for support. This work was supported by
Champalimaud and Gulbenkian Foundations and fellowships to G.B.M.M.
and S.S from the Portuguese Foundation for Science and Technology.
Received: December 15, 2014
Revised: January 23, 2015
Accepted: February 11, 2015
Published: April 23, 2015
REFERENCES
1. Schultz, W., Dayan, P., and Montague, P.R. (1997). A neural substrate of
prediction and reward. Science 275, 1593–1599.
2. Meck, W.H. (2006). Neuroanatomical localization of an internal clock: a
functional link between mesolimbic, nigrostriatal, and mesocortical dopa-
minergic systems. Brain Res. 1109, 93–107.
3. Malapani, C., Rakitin, B., Levy, R., Meck, W.H., Deweer, B., Dubois, B.,
and Gibbon, J. (1998). Coupled temporal memories in Parkinson’s dis-
ease: a dopamine-related dysfunction. J. Cogn. Neurosci. 10, 316–331.
4. Rowe, K.C., Paulsen, J.S., Langbehn, D.R., Duff, K., Beglinger, L.J., Wang,
C., O’Rourke, J.J., Stout, J.C., and Moser, D.J. (2010). Self-paced
timing detects and tracks change in prodromal Huntington disease.
Neuropsychology 24, 435–442.
5. Maricq, A.V., and Church, R.M. (1983). The differential effects of
haloperidol and methamphetamine on time estimation in the rat.
Psychopharmacology (Berl.) 79, 10–15.
6. Ward, R.D., Kellendonk, C., Simpson, E.H., Lipatova, O., Drew, M.R.,
Fairhurst, S., Kandel, E.R., and Balsam, P.D. (2009). Impaired timing pre-
cision produced by striatal D2 receptor overexpression is mediated by
cognitive and motivational deﬁcits. Behav. Neurosci. 123, 720–730.
7. Hinton, S.C., and Meck, W.H. (2004). Frontal-striatal circuitry activated by
human peak-interval timing in the supra-seconds range. Brain Res. Cogn.
Brain Res. 21, 171–182.
8. Tanaka, S.C., Doya, K., Okada, G., Ueda, K., Okamoto, Y., and Yamawaki,
S. (2004). Prediction of immediate and future rewards differentially recruits
cortico-basal ganglia loops. Nat. Neurosci. 7, 887–893.
9. Gibbon, J. (1977). Scalar expectancy theory and Weber’s law in animal
timing. Psychol. Rev. 84, 279–325.
10. Simen, P., Balci, F., de Souza, L., Cohen, J.D., and Holmes, P. (2011). A
model of interval timing by neural integration. J. Neurosci. 31, 9238–9253.
11. Meck, W.H., Penney, T.B., and Pouthas, V. (2008). Cortico-striatal repre-
sentation of time in animals and humans. Curr. Opin. Neurobiol. 18,
145–152.
12. Killeen, P.R., and Fetterman, J.G. (1988). A behavioral theory of timing.
Psychol. Rev. 95, 274–295.
13. Buonomano, D.V., and Merzenich, M.M. (1995). Temporal information
transformed into a spatial code by a neural network with realistic proper-
ties. Science 267, 1028–1030.
14. Machado, A., Malheiro, M.T., and Erlhagen, W. (2009). Learning to time: a
perspective. J. Exp. Anal. Behav. 92, 423–458.
15. Gage, G.J., Stoetzner, C.R., Wiltschko, A.B., and Berke, J.D. (2010).
Selective activation of striatal fast-spiking interneurons during choice
execution. Neuron 67, 466–479.
16. Geffen, M.N., Broome, B.M., Laurent, G., and Meister, M. (2009). Neural
encoding of rapidly ﬂuctuating odors. Neuron 61, 570–586.
17. Dayan, P., and Abbott, L.F. (2005). Theoretical Neuroscience, Second
Edition. (Cambridge: MIT Press).
18. Mink, J.W. (1996). The basal ganglia: focused selection and inhibition of
competing motor programs. Prog. Neurobiol. 50, 381–425.
19. Jin, X., and Costa, R.M. (2010). Start/stop signals emerge in nigrostriatal
circuits during sequence learning. Nature 466, 457–462.
20. Kim, H., Sul, J.H., Huh, N., Lee, D., and Jung, M.W. (2009). Role of striatum
in updating values of chosen actions. J. Neurosci. 29, 14701–14712.
21. Grossberg, S., and Schmajuk, N.A. (1989). Neural dynamics of adaptive
timing and temporal discrimination during associative learning. Neural
Netw. 2, 79–102.
22. Suri, R.E., and Schultz, W. (1999). A neural network model with dopamine-
like reinforcement signal that learns a spatial delayed response task.
Neuroscience 91, 871–890.
23. Ludvig, E.A., Sutton, R.S., and Kehoe, E.J. (2008). Stimulus representation
and the timing of reward-prediction errors in models of the dopamine sys-
tem. Neural Comput. 20, 3034–3054.
24. Howard, M.W., MacDonald, C.J., Tiganj, Z., Shankar, K.H., Du, Q.,
Hasselmo, M.E., and Eichenbaum, H. (2014). A uniﬁed mathematical
framework for coding time, space, and sequences in the hippocampal re-
gion. J. Neurosci. 34, 4692–4707.
25. Doya, K. (1999). What are the computations of the cerebellum, the basal
ganglia and the cerebral cortex? Neural Netw. 12, 961–974.
26. Lauwereyns, J., Watanabe, K., Coe, B., and Hikosaka, O. (2002). A neural
correlate of response bias in monkey caudate nucleus. Nature 418,
413–417.
27. Samejima, K., Ueda, Y., Doya, K., and Kimura, M. (2005). Representation
of action-speciﬁc reward values in the striatum. Science 310, 1337–1340.
28. Lau, B., and Glimcher, P.W. (2008). Value representations in the primate
striatum during matching behavior. Neuron 58, 451–463.
29. Sutton,
R.S.,
and
Barto,
A.G.
(1998).
Reinforcement
Learning.
(Cambridge: MIT Press).
30. Balsam, P.D., and Gallistel, C.R. (2009). Temporal maps and informative-
ness in associative learning. Trends Neurosci. 32, 73–78.
31. Ponzi, A., and Wickens, J. (2010). Sequentially switching cell assemblies in
random inhibitory networks of spiking neurons in the striatum. J. Neurosci.
30, 5894–5911.
32. Berns, G.S., and Sejnowski, T.J. (1998). A computational model of how the
basal ganglia produce sequences. J. Cogn. Neurosci. 10, 108–121.
Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved
1121
 33. Ahrens, M.B., and Sahani, M. (2011). Observers exploit stochastic models
of sensory change to help judge the passage of time. Curr. Biol. 21,
200–206.
34. Pastalkova, E., Itskov, V., Amarasingham, A., and Buzsa´ ki, G. (2008).
Internally generated cell assembly sequences in the rat hippocampus.
Science 321, 1322–1327.
35. MacDonald, C.J., Lepage, K.Q., Eden, U.T., and Eichenbaum, H. (2011).
Hippocampal ‘‘time cells’’ bridge the gap in memory for discontiguous
events. Neuron 71, 737–749.
36. Buonomano, D.V., and Mauk, M.D. (1994). Neural network model of the
cerebellum: temporal discrimination and the timing of motor responses.
Neural Comput. 6, 38–55.
37. Harvey, C.D., Coen, P., and Tank, D.W. (2012). Choice-speciﬁc sequences
in parietal cortex during a virtual-navigation decision task. Nature 484,
62–68.
38. Machens, C.K., Romo, R., and Brody, C.D. (2010). Functional, but
not anatomical, separation of ‘‘what’’ and ‘‘when’’ in prefrontal cortex.
J. Neurosci. 30, 350–360.
39. Shinomoto, S., Omi, T., Mita, A., Mushiake, H., Shima, K., Matsuzaka, Y.,
and Tanji, J. (2011). Deciphering elapsed time and predicting action timing
from neuronal population signals. Front. Comput. Neurosci. 5, 29.
40. Kim, J., Ghim, J.W., Lee, J.H., and Jung, M.W. (2013). Neural correlates of
interval timing in rodent prefrontal cortex. J. Neurosci. 33, 13834–13847.
41. Jin, D.Z., Fujii, N., and Graybiel, A.M. (2009). Neural representation of time
in cortico-basal ganglia circuits. Proc. Natl. Acad. Sci. USA 106, 19156–
19161.
42. Merchant, H., Pe´ rez, O., Zarco, W., and Ga´ mez, J. (2013). Interval tuning in
the primate medial premotor cortex as a general timing mechanism.
J. Neurosci. 33, 9082–9096.
1122
Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved
",https://doi.org/10.1016/j.cub.2015.02.036,doc8,"Article A Scalable Population Code for Time in the Striatum Highlights d Striatal neurons ﬁre at different times over tens of seconds during timing behavior d Response times of striatal neurons rescaled with the interval being timed d Time coding by the population predicted timing behavior from trial to trial d Striatal neurons multiplexed information about action and time Authors Gustavo B.M. Mello, Soﬁa Soares, Joseph J. Paton Correspondence joe.paton@neuro.fchampalimaud.org In Brief Time is fundamental for all behavior, yet how the brain encodes time is unknown. Mello, Soares, and Paton found that ﬁring dynamics in populations of neurons in the rodent striatum robustly and ﬂexibly encoded time over tens of seconds. These results supply new insight into how the basal ganglia might function during learning and action selection. Mello et al., 2015, Current Biology 25, 1113–1122 May 4, 2015 ª2015 Elsevier Ltd All rights reserved Current Biology Article A Scalable Population Code for Time in the Striatum Gustavo B.M. Mello,1,2,3 Soﬁa Soares,1,2,3 and Joseph J. Paton1,2,* 1Champalimaud Neuroscience Programme, Champalimaud Centre for the Unknown, Lisbon 1400-038, Portugal 2Instituto Gulbenkian de Cieˆ ncia, Oeiras 2780-156, Portugal 3Co-ﬁrst author *Correspondence: joe.paton@neuro.fchampalimaud.org SUMMARY To guide behavior and learn from its consequences, the brain must represent time over many scales. Yet, the neural signals used to encode time in the sec- onds-to-minute range are not known. The striatum is a major input area of the basal ganglia associated with learning and motor function. Previous studies have also shown that the striatum is necessary for normal timing behavior. To address how striatal sig- nals might be involved in timing, we recorded from striatal neurons in rats performing an interval timing task. We found that neurons ﬁred at delays spanning tens of seconds and that this pattern of responding reﬂected the interaction between time and the ani- mals’ ongoing sensorimotor state. Surprisingly, cells rescaled responses in time when intervals changed, indicating that striatal populations encoded relative time. Moreover, time estimates decoded from activ- ity predicted timing behavior as animals adjusted to new intervals, and disrupting striatal function led to a decrease in timing performance. These results sug- gest that striatal activity forms a scalable population code for time, providing timing signals that animals use to guide their actions. INTRODUCTION To behave adaptively in complex, ever-changing environments, animals must learn which actions to take in a particular context based on their past experience. However, to learn about the sometimes-delayed consequences of actions and to guide future behavior, it is absolutely necessary that the brain repre- sent not only actions and consequences but also temporal infor- mation about when those actions and consequences occur [1]. Multiple lines of evidence implicate the basal ganglia (BG) as a locus for the representation of such temporal information. Le- sions of the striatum in rats [2], disease states that affect the BG such as Parkinson’s [3] and Huntington’s disease [4], drugs that affect dopamine (DA) signaling [5], and genetic manipula- tions that affect the DA system in the BG [6] all result in interval timing dysfunction. Furthermore, human fMRI studies have found that the striatum, a main input area of the BG, is activated by tasks that involve the processing of interval information [7, 8]. In addition, many theoretical models have been proposed to explain timing behavior. These models can be grouped into at least three categories. Pacemaker-accumulator models integrate pulses emitted from a central pacemaker to measure elapsed time [9, 10]. Beat frequency models detect patterns of activation across resettable oscillatory processes at dif- ferent frequencies to encode time delays from a resetting event [11]. Sequential state models contain orderly transitions between different activity states that can be used to encode time [12–14]. These theories reproduce various aspects of timing behavior in many interval timing tasks. However, neural data in conﬂict or in support of the various theories are lacking. To understand how time is encoded in neural circuits, we re- corded the spiking activity of neurons as rats performed an inter- val timing task. Speciﬁcally, given the apparent localization of timing function in striatal tissue, we asked whether striatal neural activity could encode elapsed time over durations of tens of sec- onds to 1 min while we measured behavior that reﬂected ani- mals’ estimates of time. We found that different striatal neurons ﬁred maximally at different delays from reward receipt and that information about animals’ time estimates could be extracted from striatal popula- tions by simply treating neurons as tuned for time. Importantly, this tuning for time, while affected by sensorimotor event-related neural responses, could not be fully explained by ongoing behavior, as even cells that displayed responses locked to a spe- ciﬁc behavior varied their responses depending on when that behavior was executed within a given interval. Strikingly, we found that temporal tuning stretched or contracted, rescaling with the interval being timed. Thus, striatal populations encoded relative time, ﬂexibly adapting to the immediate demands of the environment. Finally, we ran a simple simulation of the task and show that neural responses resembling those we observe in the striatum are suitable as a basis for timing behavior. These results provide important biological insight into how a major brain sys- tem encodes time during behavior. RESULTS Lever Pressing Start Time under Fixed Interval Reinforcement Schedules Is a Behavioral Measure of Rats’ Expectation of Time until Reward To elicit robust time-dependent behavior over a broad range of timescales, we employed operant conditioning procedures un- der ﬁxed interval (FI) schedules of reinforcement (Figure 1A). Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved 1113 Brieﬂy, rats were placed in a behavioral box containing a lever positioned over a liquid delivery port and were trained to press the lever to receive water reward. Reward delivery triggered a timer, and reward became available again only after the timer ex- ceeded a FI ranging from 12 s to 60 s in multiples of 12 s. Lever presses occurring after reward delivery but before the FI had elapsed were not reinforced. A FI was maintained for between 18 and 40 rewards before changing to another FI, randomly cho- sen from the interval set. In single sessions, rats tended to distribute lever pressing toward the latter portion of the FI, shifting when they responded as FI changes occurred (Figures 1B and S1A). This pattern of re- sponding produced ramps in block-wise averaged pressing as a function of time that varied in slope in relation to FI (Figures 1C and S1B). However, this did not reﬂect the pattern of responding in single trials. We asked how pressing evolved after pressing onset (pressing start times, PSTs) in each trial by aligning on the PST and averaging lever press rates across trials and within blocks of the same FI (Figure 1D). Rats pressed at a relatively constant rate after the ﬁrst press in each trial, with a rate deter- mined by the experienced reward rate (Figure S1C). The ramps in the reward-aligned pressing as a function of time largely result from changing distributions of PSTs (Figure 1E), as these vary systematically with FI, and averaging a group of step functions with onset times drawn from these distributions will produce ramps of varying slope. This serial ﬁxed interval (SFI) lever pressing task produced systematic variation in the distributions of PSTs of bouts of antic- ipatory pressing, consistent with previous timing studies em- ploying FI schedules of reinforcement [9]. These bouts were of a relatively constant rate that varied with reward rate over time (Figures 1D and S1C). The PST thus provided a behavioral metric that covaried with the animals’ changing expectation about time until the next available reward, which we compared to the activity of neurons recorded in the striatum during performance of the task as described below. Striatal Neurons Display Temporal Tuning In the SFI task, reward delivery is both the timing cue and the reinforcer. Since animals reported knowledge of time between reward availability by when they began to press a lever, we asked whether neuronal responses in the striatum aligned on reward might reveal a signal that animals could use to guide the decision of when to begin pressing. We recorded broadly in the dorsal striatum so as to sample neurons from regions pre- viously shown to be important for interval timing behavior [2] (inset in Figure S1D), and the vast majority of units we recorded exhibited average ﬁring rates of less than ﬁve spikes per second, consistent with a population made up of mostly medium spiny projection neurons [15] (Figure S1D). Aligned on reward delivery, the population of recorded cells exhibited a broad distribution of activity patterns, as reﬂected 12s 24s 36s 48s or 60s reward lick lever press reward available FI = time from reward (s) trial number time 0 30 20 10 40 50 0 120 20 40 60 100 80 60 180 160 140 200 lever press pressing start time (s) 10 20 30 40 50 60 10 20 30 40 50 60 time from reward (s) pressing rate (Hz) 10 20 30 40 50 60 0.4 0.3 0.2 0.1 0.0 0 0.5 0.6 pressing rate (Hz) 10 20 30 0 -4 0.5 0.0 0.4 0.3 0.2 0.1 0.6 40 50 0 0 PST density JP 27 2010_06_23 A B C D E 60 Figure 1. The SFI Task Produces Systematic Changes in Lever PST (A) Task structure. The following color code will be commonly used: blue represents short FIs, and green represents longer FIs. (B) Example of lever pressing behavior in a single session of the SFI task. Gray markers indicate a lever press; red markers indicate the PST. (C) Average lever pressing rate in each of the ﬁve FIs, aligned on preceding reward. Dashed lines represent SEM. (D) Average rate of lever pressing in each block, aligned on PST. Traces are plotted on a solid line for the period for which more than half of the trials contribute data and on a dotted line after that point. Shaded patches along the horizontal axis represent SEM. 1 s bins are indicated in (C) and (D). (E) Median and interquartile range of PST for each of the ﬁve FIs. Smoothed density functions depicting the full distributions of PST are shown on the right. See also Figure S1. 1114 Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved in the normalized spike density functions (SDFs; see Supple- mental Experimental Procedures for details) shown in Figure 2A. Some cells ﬁred just after reward delivery, others ﬁred in the middle of the delay, and others ﬁred leading up to the next reward (Figures 2A, S2, and S3). This produced a slow-moving ‘‘bump’’ of activity that traversed the population during each FI. In theory, reading out the location of this bump in the popula- tion could provide an estimate of time within the FI. However, a core feature of interval timing behavior is that timing accuracy decreases with the magnitude of the interval being timed [9]. Two features of the neural data could potentially contribute to this phenomenon: an increased spread of each neuron’s re- sponses as a function of their peak latency and a decreasing density of neurons displaying peak ﬁring rates as time pro- gresses. We found that the widths of responses were indeed correlated with their latencies to peak ﬁring within each FI (Fig- ure 2B, linear regression, FI 12 s, R = 0.4443, p < 0.001; FI 24 s, R = 0.7563, p < 0.001; FI 36 s R = 0.7188, p < 0.001; FI 48 s, R = 0.5910, p < 0.001; FI 60 s R = 0.4733, p < 0.001; see Supplemental Experimental Procedures for details). In addition, the density of peak ﬁring rate latencies in our population decreased over time within the FI (Figure 2C). Thus, the bump in activity within the striatum population moved progressively slower as the FI wore on. Strikingly, the overall time taken by this bump to traverse the population appeared to scale with the FI (Figures 2A and S4A). To begin to assess apparent scaling of response times, we ﬁrst selected cells that we had recorded in all ﬁve FIs and that maintained their ordinal position within the population when responses within each FI were ordered by ﬁring dynamics [16]. Of the 112 neurons recorded in all FIs, we found that 76 neurons (68%) maintained their ordinal position in time across the population (see Supplemental Experimental Proce- dures for details). The responses of these neurons can be observed in Figure 2A, wherein the position of cells along the y axis is the same across the panels displaying average re- sponses in each of the FIs (for all recorded cells, see Figure S4A). To quantify to what degree responses rescaled, we computed a scale factor for each neuron as the ratio of the center of mass (COM) of the SDF in the 12-s FI over the COM of the SDF in each of the other four FIs (Figure 3A). The distributions of these scale factors were sharper than and signiﬁcantly different from null dis- tributions generated by shufﬂing cell identity across FIs and recomputing the scale factors (red distributions in Figure 3A, Kol- mogorov-Smirnov test, p < 0.001 for all pairwise comparisons). The medians of these distributions, were the population to have rescaled its responses in direct proportion to the FI, should lie at 1/2, 1/3, 1/4, and 1/5 for the scale factors corresponding to 12/24 s, 12/36 s, 12/48 s, and 12/60 s FIs, respectively. We observed median values of 0.59, 0.39, 0.30, 0.24 for the corre- sponding distributions, indicating near-proportional rescaling of response times across the recorded striatal population. A more-complete description of the relative scale of responses can be seen in Figures 3B–3E, where the COM of each cell’s SDF in the 12-s FI against each of the other FIs are displayed. These data demonstrate a strong tendency for rescaling of neu- ral responses across the population, suggesting that the state of striatal populations may convey relative elapsed time informa- tion scaled to the animal’s estimate of the current behaviorally relevant timescale in the environment. We explore this hypothe- sis in greater detail below. Striatal Populations Encode Information about Timing Behavior The above analyses of striatal neural responses indicate a gross correspondence between striatal activity and timing behavior across blocks of trials, suggesting that striatal activity patterns response latency (s) response width (s) 10 20 30 0 0 20 15 10 5 40 B time relative to reward (s) cell # FI = 12 FI = 24 FI = 36 FI = 48 FI = 60 A ring rate (z) response latency (time/FI) 0.2 0.4 0.6 0 0.8 0 8 6 4 2 10 18 16 14 12 count C 20 40 60 0 -12 12 # ""# $# %# ""# $# %# ""# $# %# ""# $# %# # $ # ""## "" $# $# %# %# %# %# ""# $# %# # ""## "" $# $# $# %# %# %# %# ""# $# %# ""## "" $# $# $# %# %# %# %# ""# $# %# # ""## "" $# $# $# %# %# %# %# 20 40 60 0 -24 24 20 40 60 0 -36 36 20 40 60 0 -48 48 20 40 60 0 -60 60 10 5 0 Figure 2. Striatal Neurons Display Variable Responses that Tile Tens of Seconds to 1 Min (A) SDFs of neurons that maintained their relative ordinal position in time within the population across all ﬁve FIs, aligned on reward. (B) Width of each cell’s response within each FI as a function of latency to peak ﬁring. Colored lines represent the best linear ﬁt to the data. (C) Histogram of relative peak latencies pooled over all FIs, using data shown in (B). See also Figure S2. Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved 1115 might guide decisions about when to begin pressing the lever during each FI. To test this hypothesis, we applied a decoding approach to data collected from single trials near block transi- tions, wherein animals systematically changed the time that they began to press the lever. Speciﬁcally, we asked three ques- tions. First, we asked whether decoded time estimates covaried with true time. Second, we asked whether systematic errors in estimated time as compared to true time occurred at these block transitions. Lastly, we asked whether any observed errors in time encoding correlated with timing behavior. We ﬁrst built a probabilistic decoder to derive an estimate of elapsed time from reward in single trials given the observed spiking response of the population. We focused on the ﬁrst trials of the 12-s and 60-s FI blocks because these blocks were the shortest and longest FIs employed, respectively. Thus, animals consistently overestimated and underestimated the amount of time remaining until reward as they entered 12-s and 60-s blocks. Brieﬂy, our decoder was constructed as follows. In each of the ﬁrst seven trials of a block, we counted spikes within deﬁned time bins and asked how likely we were to have observed that number of spikes at each time given the observed distributions of spike counts in trials 8 onward of the correspond- ing block. This generated a likelihood function for current time, given an observed spike count in each bin, for each individual cell. To derive a measure of the population’s estimate of the like- lihood for current time, we multiplied together the individual cells’ likelihood functions. We then took the mean of this likelihood function as our estimate for current time [17]. In Figures 4A and 4C, we display decoded estimates as a func- tion of time for the ﬁrst seven trials of 12-s and 60-s FI blocks. We found that decoded estimates tracked true time but that system- atic errors between estimates and true time were present in the ﬁrst few trials of the 12-s and 60-s FI blocks. This feature can be observed more readily when estimates derived from multiple tri- als are plotted on the same axes (Figures 4B and 4D, quadratic ﬁts). Initial estimates were relatively slow and fast in the ﬁrst trials of the 12-s and 60-s FI blocks, respectively, and became more accurate after the ﬁrst few trials. Next we asked whether such timing signals may be used by animals to guide timing behavior. We ﬁrst asked whether errors in decoded time estimates over the ﬁrst trials of blocks were correlated with timing behavior. We found that the mean PST was signiﬁcantly correlated with the errors in time estimates derived from the population over the ﬁrst seven trials of 12-s and 60-s FI blocks (Figure 5; FI = 12, R2 = 0.63, p = 0.03; FI = 60, R2 = 0.64, p = 0.03). In the initial trials of the 12-s FI block, rats began pressing late relative to subsequent trials, and like- wise, the decoded estimate of time relative to reward ran slow (Figures 4B and 5). The ﬁrst trials of the 60-s FI block showed a similar relationship, yet opposite in direction: the decoded estimate ran quickly in early trials, and rats were early to press (Figures 4D and 5). We then tested in two control animals whether manipulating striatal circuitry via bilateral infusions of the GABAa agonist muscimol produced deﬁcits in timing behavior (Figure S5). Indeed, at a dose that rendered rats able to perform the task, muscimol reversibly and signiﬁcantly dimin- ished the relationship between PST and FI (linear regression, likelihood ratio test, signiﬁcant effect of treatment, p < 0.001), showing that a normally functioning striatum is critical for normal timing behavior. The consistency between time estimates de- coded from striatal populations and trial-by-trial variations in timing behavior at block transitions, together with observed dependence of a normally functioning striatum for normal timing behavior, suggests that the brain uses a population code for time that samples broadly from striatal neurons to guide decisions about when to act. Striatal Neurons Multiplexed Information about Action and Time Based on previous studies [18–20], we expected that striatal neurons would display signiﬁcant modulation by behaviors dur- ing the FI. Could behaviors that accompany task performance fully explain the sequential neural responses we observed? Several features of the data argue against this possibility. Rats consistently licked at the reward port from 0.5 s to 5.5 s after reward delivery (Figure S4B), and yet, our ability to decode time was unaffected by the animal being engaged in a ﬁxed behavior over this time (see initial 5 s of decoded time esti- mates in Figures 4A and 4C). After departing from the reward port, however, it is possible that observed dynamics in neural re- sponses are accounted for by ongoing behaviors. Were this the case, responses related to a particular behavior should not vary A C 0 12 24 36 48 60 0 6 12 0 12 24 36 48 60 0 6 12 0 12 24 36 48 60 0 6 12 0 12 24 36 48 60 0 6 12 B E D center of mass 24s FI center of mass 36s FI center of mass 48s FI center of mass 60s FI center of mass 12s FI center of mass 12s FI center of mass 12s FI center of mass 12s FI cell count com 12sFI / com XsFI 0 0.5 1.0 1.5 2.0 0 20 20 20 20 0 0 0 X = 24 X = 36 X = 48 X = 60 Figure 3. Striatal Neurons Rescale Their Response Time with FI (A) Distributions of scale factors obtained by calculating the ratio of the center of mass (COM) of the SDF between the 12-s FI and X-s FI (24 s, 36 s, 48 s, and 60 s, respectively, from blue to green) for each cell. For each distribution of scale factors, a null distribution was generated by shufﬂing cell identity across FIs and recomputing the scale factors (red). (B–E) COM of each cell’s SDF in the 12-s FI against each of the other FIs. The black dotted line signiﬁes no change in COM from block to block. The colored dotted line signiﬁes a change in COM that is proportional to the change in FI relative to the 12-s FI. See also Figure S3. 1116 Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved depending on when in a trial the rat engaged in that behavior. To identify neurons that were signiﬁcantly modulated by a measured behavior in our task, we focused on a 2.5-s epoch centered on the PST in each trial. We found that of the 76 neu- rons displayed in Figure 2A, 31 exhibited signiﬁcant modulations around the onset of lever pressing. Next, we asked whether spiking observed in time bins aligned on the PST was addition- ally correlated with the time, relative to the FI, that pressing onset occurred. More than half of pressing onset-modulated neurons (16/31, 52%) displayed a signiﬁcant correlation between spiking around each press initiation and the relative time that press onset occurred within the FI (Pearson’s linear regression, p < 0.01). Fig- ures 6A–6D show examples of four such neurons from three different animals, all of which vary in their responses around the PST, from none at all to robust ﬁring. The regression approach described above is only expected to identify neurons that display a monotonic relationship between pressing onset response and the relative time of pressing onset. Other cells may have displayed signiﬁcant time-dependent mod- ulations in pressing onset response that were not monotonic (for example, see Figures S2B and S3A). To identify such cells, we asked whether the median of distributions of spikes counts, collected around pressing onsets and falling into each of ﬁve quintiles of relative PSTs, differed from each other. We found that 53 out of 76 neurons (70%) displayed in Figure 2A exhibited signiﬁcantly different median spike counts across relative time 0 2 4 6 8 10 10 8 6 4 2 0 0 2 4 6 8 10 10 8 6 4 2 0 0 2 4 6 8 10 10 8 6 4 2 0 0 2 4 6 8 10 10 8 6 4 2 0 10 8 6 4 2 0 10 8 6 4 2 0 10 8 6 4 2 0 10 8 6 4 2 0 7 trial average trial #: 1 2 3 4 5 6 7 decoded time (s) A B trial number 1 7 time relative to reward (s) time relative to reward (s) 0 10 20 30 40 50 50 40 30 20 10 0 0 10 20 30 40 50 50 40 30 20 10 0 0 10 20 30 40 50 50 40 30 20 10 0 0 10 20 30 40 50 50 40 30 20 10 0 0 10 20 30 40 50 50 40 30 20 10 0 0 10 20 30 40 50 50 40 30 20 10 0 0 10 20 30 40 50 50 40 30 20 10 0 0 10 20 30 40 50 50 40 30 20 10 0 7 trial average trial #: 1 2 3 4 5 6 7 decoded time (s) time relative to reward (s) trial number 1 7 time relative to reward (s) C D decoded time (s) decoded time (s) 10 0 8 6 4 2 2 4 6 0 8 10 10 0 8 6 4 2 2 4 6 0 8 10 10 0 8 6 4 2 2 4 6 0 8 10 10 0 8 6 4 2 2 4 6 0 8 10 10 0 8 6 4 2 2 4 6 0 8 10 10 0 8 6 4 2 2 4 6 0 8 10 50 0 40 30 20 10 10 20 30 0 40 50 50 0 40 30 20 10 10 20 30 0 40 50 50 0 40 30 20 10 10 20 30 0 40 50 50 0 40 30 20 10 10 20 30 0 40 50 50 0 40 30 20 10 10 20 30 0 40 50 50 0 40 30 20 10 10 20 30 0 40 50 10 0 8 6 4 2 2 4 6 0 8 10 10 0 8 6 4 2 2 4 6 0 8 10 50 0 40 30 20 10 10 20 30 0 40 50 50 0 40 30 20 10 10 20 30 0 40 50 10 0 8 6 4 2 2 4 6 0 8 10 50 0 40 30 20 10 10 20 30 0 40 50 Figure 4. Single-Trial Estimates of Elapsed Time Decoded from the Population Response Correlate with True Time during Initial Trials of 12-s and 60-s FI Blocks (A) Decoded population estimates of elapsed time from reward in single trials, for the ﬁrst seven trials of the 12-s FI block plotted against true time. Red traces indicate the mean of the population likelihood function, and the underlying heatmap indicates the population likelihood function. The last panel shows a seven-trial average likelihood function using the ﬁrst seven trials of the 12-s block. (B) Decoded estimates of elapsed time for the ﬁrst seven trials of the 12-s FI block plotted on the same axis. Curves are quadratic ﬁts to the mean likelihood function of each individual trial (red lines in ﬁrst seven panels). Red curves represent early trials, and black curves represent later trials. (C) Same description as in (A), but for the 60-s FI. (D) Same description as in (B), but for the 60-s FI. See also Figure S4. Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved 1117 within the FI (p < 0.01, Kruskal-Wallis). Of these, nine cells were signiﬁcantly modulated by the onset of lever pressing and were not identiﬁed in the linear regression analysis. Overall, only six cells that displayed response modulation around PST did not exhibit additional modulation by relative time in the FI as assessed by linear regression and/or nonparametric testing for median difference in spike count. These results suggest that striatal neurons multiplex information about time and immediate sensorimotor state of the animal and argue strongly against the possibility that the striatal population responses we observed can be explained by purely non-time-related responses to spe- ciﬁc sensory or motor components of ongoing behavior. A Simple Simulation of Timing Behavior In order to understand the relationship between the recorded striatal signals and rats’ behavior, we ran a simple simulation that performed the SFI task (Figure 7A). The core of this simula- tion is comprised of a set of temporal basis functions that were inspired by the diverse single-neuron responses observed in our striatal dataset as well as existing timing and learning models [21–24]. We used the method described in [23] to generate tem- poral bases. Each function was used as a rate function for gener- ating inhomogeneous Poisson spike trains from which time was read out during task performance. Whenever this time readout passed a threshold, presses were produced at a ﬁxed rate. In order to adapt to the changing FIs, we implemented a simple learning rule to update a temporal scale factor for the basis func- tions depending on the difference between expected time of reward and encoded time at the time of reward delivery. Lastly, to account for our observation that many striatal neurons multi- plexed information about action and time, each press produced a response in the temporal bases that was proportional to the product of the original time-dependent rate function at the time of the press and a rate function generated by the press itself. With these elements, we ran the simulation under the conditions contained in the SFI task. The simulation produced qualitatively similar behavior to that of rats (Figures 7B and S6) and reproduced the three main fea- tures that we observed in striatal neurons: temporal tuning, rescaling of neural responses (Figure 7C), and multiplexing of in- formation about action and time (Figure 7D). Although simple, the simulation serves as proof of principle that neural activity with the properties that we observe in this study can serve as a basis for timing behavior and suggests candidate computational elements such as a scale factor and temporal error signal for which there might exist functional analogs in the brain. DISCUSSION Time is a fundamental dimension of animals’ experience in the world. As such, it plays an integral role in many brain processes, from perception to motor control to learning and memory forma- tion. What is the role of temporal representation within the BG? A dominant view supported by a wide range of neurobiological data posits that the BG implements aspects of reinforcement learning (RL) [1, 20, 25–28], learning how an organism ought to act in order to maximize reward. However, to learn about the sometimes-delayed consequences of actions and to guide future behavior toward rewarding outcomes, it is absolutely necessary that the brain represent situations and actions through time [1, 29]. Indeed, temporal relations among actions and events contain the causal information that learning systems have evolved to detect through a process sometimes referred to as credit assignment [30]. Once credit for the occurrence of pre- dictable events has been assigned, this information must be used to proﬁtably guide the course and timing of action as situ- ations arise. This continuous learning-behaving cycle is what RL algorithms naturally account for [29]. Yet, it is not known how the BG, the brain system most often associated with RL, represents temporal relationships over the durations necessary to explain its purported role in animal learning and behavior. The sequential neural states that we describe in the striatum during timing behavior can provide a unifying view of the BG’s role in timing and RL. These signals are strikingly similar to tem- poral basis functions proposed in existing learning models as more neurally plausible and efﬁcient representations of time [21–23], which we show can be used to generate timing behavior similar to what we observed experimentally. Such models operate by learning a set of weights used in a weighted sum of the temporal bases to construct a moment-by-moment prediction about future events such as expected reward. In theory, a weighted combination of activity patterns in the cortical or thalamic inputs to the striatum could act as such temporal bases and modulate the responses of striatal neurons that we observed. An important question for future studies concerns the mecha- nism that generated the striatal dynamics we observed. We ﬁnd it unlikely, given the duration of the intervals we examined, that striatal dynamics were purely locally generated, although several modeling studies suggest mechanisms for generat- ing sequential activity states using striatum-like circuitry over 10 15 20 25 0.20 0.15 0.10 0.05 0.0 0.05 0.10 0.15 mean error, true time - readout (fraction of FI) R2: 0.63, p=0.03 R2: 0.64, p=0.03 pressing start time (s) Figure 5. Errors in Decoded Time Predicted Timing Behavior Mean error between true time and the decoded population estimate in the ﬁrst seven trials of the 12-s (blue) and 60-s (green) FI blocks. Contiguous trials are connected by solid lines to display the trajectory of the data over trials, and the ﬁrst trial on each block is indicated by the black arrow. Dashed horizontal gray line represents zero error average decoding as compared to true time. See also Figure S5. 1118 Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved shorter timescales [31, 32]. Indeed, the signals we use to decode time were affected, but not fully explained by, the ongoing sensorimotor state of the animal. Thus, our decoding approach implicitly endorses a number of prominent interval timing theories, positing that animals may use behavioral [12, 14] or sensory state [33] transitions to learn to time events in the envi- ronment and their own behavior. Our data appear most consistent with theoretical models that suggest distributed representations of time encoded by the joint activity of populations of neurons [13]. Indeed, the decoder used in the current study assumes that time information may be pre- sent in many different neurons. However, we cannot rule out that upstream of the population we recorded in the striatum, other forms of temporal representations may exist. For instance, an accumulating process such as that contained within pace- maker accumulator models [9] might act to trigger neurons to become active at different delays as the accumulator passes a series of thresholds. We show that sequential neural activation in the striatum can be used to encode time on a scale of tens of seconds up to 1 min. These results add to a growing list of studies that demon- strate sequential activation of neurons over multi-second time- scales in other brain areas, such as the hippocampus [34, 35], the cerebellum [36], the parietal cortex [37], and the prefrontal cortex [38–40]. Unlike previous studies, we found that many indi- vidual striatal neurons exhibited responses that dynamically re- scaled with the timing of events in the environment and that this scaling of responses produced changes in time encoding by the population that correlated with timing behavior. Com- bined with previous studies highlighting the importance of a nor- mally functioning striatum for timing behavior [2–4, 6], the effect of striatal inactivation in the current study, and other work that demonstrated time encoding by striatal populations over shorter timescales [41], our results suggest that information about where in time a subject ﬁnds itself relative to anticipated events in the environment is present in populations of striatal neurons and is used to guide behavior. Similar timing signals observed in areas other than the striatum are viewed within the larger context of the functional role of those areas where they were recorded. Timing signals in the ! !""# $ %! &! '! #! ! !""# $ ! # ! !""# $ ! $! %! &! 0 0.5 1 0 5 10 15 20 −! "" ! "" !"" #"" $"" !"""" !$"" −! "" ! "" !"" #"" $"" %"" !"""" !%"" −! "" ! !"" #"" $"" %"" &"" &"" !"""" !&"" −! "" ! "" # $ % & '"" !"""" !'"" A B C D trials ordered by PST/FI JP41_11_06_23nr23 JP41_11_06_23nr25_02 JP27_10_06_12nr27_02 JP28_10_06_25nr13 R2: 0.24, p<10-12 R2: 0.13, p<10-6 R2: 0.16 p<10-7 R2: 0.17 p<10-8 50 100 150 50 100 150 50 100 150 50 100 150 10 20 40 30 50 0 2 6 4 8 0 10 20 30 0 10 20 20 30 40 50 0 5 0 10 20 30 0 10 15 20 5 0 -1 1 0 -1 1 0 -1 1 0 -1 1 0 -1 1 0 -1 1 0 -1 1 0 -1 1 0.5 0 1 0.5 0 1 0.5 0 1 0.5 0 1 Figure 6. Pressing Onset Responsive Neurons Display Sensitivity to the Time Relative to the FIs (A–D) Four single-neuron peri-stimulus time histograms (top) and raster plots (middle) of 2.5-s epochs aligned on pressing onset event (from three animals; the two ﬁrst columns display data from two neurons recorded in the same animal and same session). Trials were sorted in ascendant fashion from bottom to top on the vertical axis by the pressing onset time relative to the FI (middle) and grouped into quintiles. Here, the colors from gray to red represent the ﬁrst to the ﬁfth quintile, respectively (middle and top panels). Bottom panels: correlation between the ﬁring rate of the respective neuron and the time of the pressing onset relative to FI. Each data point is color coded from gray to red for the ﬁrst to the tenth decile of the relative pressing onset time. Firing rates were extracted from the most modulated 500 ms bin of the four bins surrounding the pressing onset event. Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved 1119 hippocampus might endow explicit memories with accurate in- formation about the order and temporal context of events [24], and timing signals in the cerebellum might coordinate learned actions at a ﬁne timescale [36], while timing signals in premotor cortex might enable accurate timing of movement in general [42]. The striatal neurons we observed appear to multiplex temporal information with other, non-temporal types of information, such as signals related to the ongoing sensorimotor state of the animal and likely other previously identiﬁed striatal signals related to actions, motor sequences, or reinforcement [19, 26–28]. Such multiplexing of temporal and other information in populations of striatal neurons as observed in the current study is likely to be critical to the previously ascribed and often-studied function of the BG in learning and action selection. A C D B Figure 7. A Simple Simulation of Timing Behavior (A) Firing of striatal neurons was modeled based on receptive ﬁelds for the height of a decaying trace that is reset in each trial by reward delivery (top left). This trace can decay faster (solid line) or slower (dotted line) by adjusting the parameter g. The Gaussian functions (top right) represent receptive ﬁelds evenly spaced along the height of the trace function. The trace function was multiplied by the receptive ﬁelds to generate rate functions, the levels of which vary across time as the memory trace decays. Spike counts observed within deﬁned time bins were then multiplied by the logarithm of their respective rate functions and summed to compute the population log likelihood function for current time given the population response, from t = 0 to t = FI. The maximum of this likelihood function was used to derive our estimate for current time relative to reward, for each time bin. Decoded time estimates can run faster or slower depending on whether the trace function decays quickly or slowly. For each trial, when the decoded time estimate reached a given threshold (red dotted line), we simulated a probabilistic pressing process. If the decoded estimate runs too slowly, it fails to reach the threshold value for expected reward (blue dotted line) before the current FI elapses, and the reward happens before it was expected (dotted black box), generating a large prediction error that drives appropriate updating of g in the next trial. If the decoded estimate runs more accurately (solid black box), a small prediction error is generated, and g is minimally adjusted in the next trial. (B) Example of simulated lever pressing behavior on the SFI task. Gray markers indicate a lever press; red markers indicate the PST. (C) SDFs of simulated units ordered by response proﬁle. Each panel corresponds to one FI. (D) Four single-unit peri-stimulus time histograms of 2.5-s epochs aligned on pressing onset event (top). Trials were grouped in quintiles of the relative PST. The colors from gray to red represent the average ﬁring in the ﬁrst to the ﬁfth quintile, respectively. The bottom panel shows the correlation between the ﬁring rate of the correspondent unit on the top panel and the PST relative to FI. Each data point is color coded from gray to red for the ﬁrst to the tenth decile of the relative PST. See also Figure S6. 1120 Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved EXPERIMENTAL PROCEDURES All experiments were in accordance with the European Union Directive 86/609/ EEC and approved by the Portuguese Veterinary General Board (Direcc¸ a˜ o- Geral de Veterina´ ria, project approval 014303 - 0420/000/000/2011). Five male Long-Evans hooded rats were used in the neurophysiological experi- ments, and two male Long-Evans rats were used for the muscimol experi- ments. All isolated units (179 total from 5 rats, 25 R1, 9 R2, 21 R3, 28 R4, 96 R5) recorded for at least three blocks in sessions in which PSTs correlated signiﬁcantly with FI (p < 0.05) were included in subsequent analyses. All ana- lyses and simulations were performed using custom software in MATLAB (MathWorks). See Supplemental Experimental Procedures for a detailed description of methods and procedures. SUPPLEMENTAL INFORMATION Supplemental Information includes Supplemental Experimental Procedures and six ﬁgures and can be found with this article online at 10.1016/j.cub.2015.02.036. AUTHOR CONTRIBUTIONS G.B.M.M. and J.J.P. designed the experiments. G.B.M.M. and S.S. carried out the experiments. G.B.M.M., S.S., and J.J.P. analyzed the data and wrote the manuscript. ACKNOWLEDGMENTS We thank Bassam Atallah, Brian Lau, Kenway Louie, Christian Machens, Zach- ary Mainen, Thiago Gouveˆ a, Eric DeWitt, Alfonso Renart, and Masayoshi Mur- akami for critical comments on versions of the manuscript and discussions. We thank the histopathology and vivarium staff from the Champalimaud Scien- tiﬁc and Technological Platforms for support. This work was supported by Champalimaud and Gulbenkian Foundations and fellowships to G.B.M.M. and S.S from the Portuguese Foundation for Science and Technology. Received: December 15, 2014 Revised: January 23, 2015 Accepted: February 11, 2015 Published: April 23, 2015 REFERENCES 1. Schultz, W., Dayan, P., and Montague, P.R. (1997). A neural substrate of prediction and reward. Science 275, 1593–1599. 2. Meck, W.H. (2006). Neuroanatomical localization of an internal clock: a functional link between mesolimbic, nigrostriatal, and mesocortical dopa- minergic systems. Brain Res. 1109, 93–107. 3. Malapani, C., Rakitin, B., Levy, R., Meck, W.H., Deweer, B., Dubois, B., and Gibbon, J. (1998). Coupled temporal memories in Parkinson’s dis- ease: a dopamine-related dysfunction. J. Cogn. Neurosci. 10, 316–331. 4. Rowe, K.C., Paulsen, J.S., Langbehn, D.R., Duff, K., Beglinger, L.J., Wang, C., O’Rourke, J.J., Stout, J.C., and Moser, D.J. (2010). Self-paced timing detects and tracks change in prodromal Huntington disease. Neuropsychology 24, 435–442. 5. Maricq, A.V., and Church, R.M. (1983). The differential effects of haloperidol and methamphetamine on time estimation in the rat. Psychopharmacology (Berl.) 79, 10–15. 6. Ward, R.D., Kellendonk, C., Simpson, E.H., Lipatova, O., Drew, M.R., Fairhurst, S., Kandel, E.R., and Balsam, P.D. (2009). Impaired timing pre- cision produced by striatal D2 receptor overexpression is mediated by cognitive and motivational deﬁcits. Behav. Neurosci. 123, 720–730. 7. Hinton, S.C., and Meck, W.H. (2004). Frontal-striatal circuitry activated by human peak-interval timing in the supra-seconds range. Brain Res. Cogn. Brain Res. 21, 171–182. 8. Tanaka, S.C., Doya, K., Okada, G., Ueda, K., Okamoto, Y., and Yamawaki, S. (2004). Prediction of immediate and future rewards differentially recruits cortico-basal ganglia loops. Nat. Neurosci. 7, 887–893. 9. Gibbon, J. (1977). Scalar expectancy theory and Weber’s law in animal timing. Psychol. Rev. 84, 279–325. 10. Simen, P., Balci, F., de Souza, L., Cohen, J.D., and Holmes, P. (2011). A model of interval timing by neural integration. J. Neurosci. 31, 9238–9253. 11. Meck, W.H., Penney, T.B., and Pouthas, V. (2008). Cortico-striatal repre- sentation of time in animals and humans. Curr. Opin. Neurobiol. 18, 145–152. 12. Killeen, P.R., and Fetterman, J.G. (1988). A behavioral theory of timing. Psychol. Rev. 95, 274–295. 13. Buonomano, D.V., and Merzenich, M.M. (1995). Temporal information transformed into a spatial code by a neural network with realistic proper- ties. Science 267, 1028–1030. 14. Machado, A., Malheiro, M.T., and Erlhagen, W. (2009). Learning to time: a perspective. J. Exp. Anal. Behav. 92, 423–458. 15. Gage, G.J., Stoetzner, C.R., Wiltschko, A.B., and Berke, J.D. (2010). Selective activation of striatal fast-spiking interneurons during choice execution. Neuron 67, 466–479. 16. Geffen, M.N., Broome, B.M., Laurent, G., and Meister, M. (2009). Neural encoding of rapidly ﬂuctuating odors. Neuron 61, 570–586. 17. Dayan, P., and Abbott, L.F. (2005). Theoretical Neuroscience, Second Edition. (Cambridge: MIT Press). 18. Mink, J.W. (1996). The basal ganglia: focused selection and inhibition of competing motor programs. Prog. Neurobiol. 50, 381–425. 19. Jin, X., and Costa, R.M. (2010). Start/stop signals emerge in nigrostriatal circuits during sequence learning. Nature 466, 457–462. 20. Kim, H., Sul, J.H., Huh, N., Lee, D., and Jung, M.W. (2009). Role of striatum in updating values of chosen actions. J. Neurosci. 29, 14701–14712. 21. Grossberg, S., and Schmajuk, N.A. (1989). Neural dynamics of adaptive timing and temporal discrimination during associative learning. Neural Netw. 2, 79–102. 22. Suri, R.E., and Schultz, W. (1999). A neural network model with dopamine- like reinforcement signal that learns a spatial delayed response task. Neuroscience 91, 871–890. 23. Ludvig, E.A., Sutton, R.S., and Kehoe, E.J. (2008). Stimulus representation and the timing of reward-prediction errors in models of the dopamine sys- tem. Neural Comput. 20, 3034–3054. 24. Howard, M.W., MacDonald, C.J., Tiganj, Z., Shankar, K.H., Du, Q., Hasselmo, M.E., and Eichenbaum, H. (2014). A uniﬁed mathematical framework for coding time, space, and sequences in the hippocampal re- gion. J. Neurosci. 34, 4692–4707. 25. Doya, K. (1999). What are the computations of the cerebellum, the basal ganglia and the cerebral cortex? Neural Netw. 12, 961–974. 26. Lauwereyns, J., Watanabe, K., Coe, B., and Hikosaka, O. (2002). A neural correlate of response bias in monkey caudate nucleus. Nature 418, 413–417. 27. Samejima, K., Ueda, Y., Doya, K., and Kimura, M. (2005). Representation of action-speciﬁc reward values in the striatum. Science 310, 1337–1340. 28. Lau, B., and Glimcher, P.W. (2008). Value representations in the primate striatum during matching behavior. Neuron 58, 451–463. 29. Sutton, R.S., and Barto, A.G. (1998). Reinforcement Learning. (Cambridge: MIT Press). 30. Balsam, P.D., and Gallistel, C.R. (2009). Temporal maps and informative- ness in associative learning. Trends Neurosci. 32, 73–78. 31. Ponzi, A., and Wickens, J. (2010). Sequentially switching cell assemblies in random inhibitory networks of spiking neurons in the striatum. J. Neurosci. 30, 5894–5911. 32. Berns, G.S., and Sejnowski, T.J. (1998). A computational model of how the basal ganglia produce sequences. J. Cogn. Neurosci. 10, 108–121. Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved 1121 33. Ahrens, M.B., and Sahani, M. (2011). Observers exploit stochastic models of sensory change to help judge the passage of time. Curr. Biol. 21, 200–206. 34. Pastalkova, E., Itskov, V., Amarasingham, A., and Buzsa´ ki, G. (2008). Internally generated cell assembly sequences in the rat hippocampus. Science 321, 1322–1327. 35. MacDonald, C.J., Lepage, K.Q., Eden, U.T., and Eichenbaum, H. (2011). Hippocampal ‘‘time cells’’ bridge the gap in memory for discontiguous events. Neuron 71, 737–749. 36. Buonomano, D.V., and Mauk, M.D. (1994). Neural network model of the cerebellum: temporal discrimination and the timing of motor responses. Neural Comput. 6, 38–55. 37. Harvey, C.D., Coen, P., and Tank, D.W. (2012). Choice-speciﬁc sequences in parietal cortex during a virtual-navigation decision task. Nature 484, 62–68. 38. Machens, C.K., Romo, R., and Brody, C.D. (2010). Functional, but not anatomical, separation of ‘‘what’’ and ‘‘when’’ in prefrontal cortex. J. Neurosci. 30, 350–360. 39. Shinomoto, S., Omi, T., Mita, A., Mushiake, H., Shima, K., Matsuzaka, Y., and Tanji, J. (2011). Deciphering elapsed time and predicting action timing from neuronal population signals. Front. Comput. Neurosci. 5, 29. 40. Kim, J., Ghim, J.W., Lee, J.H., and Jung, M.W. (2013). Neural correlates of interval timing in rodent prefrontal cortex. J. Neurosci. 33, 13834–13847. 41. Jin, D.Z., Fujii, N., and Graybiel, A.M. (2009). Neural representation of time in cortico-basal ganglia circuits. Proc. Natl. Acad. Sci. USA 106, 19156– 19161. 42. Merchant, H., Pe´ rez, O., Zarco, W., and Ga´ mez, J. (2013). Interval tuning in the primate medial premotor cortex as a general timing mechanism. J. Neurosci. 33, 9082–9096. 1122 Current Biology 25, 1113–1122, May 4, 2015 ª2015 Elsevier Ltd All rights reserved"
Introduction: Understanding Roots and Betweenness Defining Safety of Journalists as a Sub-field of Research. Reading between the Lines,"Roy Krøvel, Fabrizio Palumbo and Kristin Skare Orgeret",2023,7.0,24,Journalism Studies,article,"Journalism Studies
ISSN: (Print) (Online) Journal homepage: www.tandfonline.com/journals/rjos20
Introduction: Underﬆanding Roots and Betweenness
Deﬁning Safety of Journaliﬆs as a Sub-ﬁeld of Research.
Reading between the Lines
Roy Krøvel, Fabrizio Palumbo & Kristin Skare Orgeret
To cite this article: Roy Krøvel, Fabrizio Palumbo & Kristin Skare Orgeret (2023) Introduction:
Understanding Roots and Betweenness Deﬁning Safety of Journalists as a Sub-ﬁeld
of Research. Reading between the Lines, Journalism Studies, 24:7, 825-837, DOI:
10.1080/1461670X.2023.2206494
To link to this article:  https://doi.org/10.1080/1461670X.2023.2206494
Published online: 18 Jul 2023.
Submit your article to this journal 
Article views: 868
View related articles 
View Crossmark data
Citing articles: 2 View citing articles 
Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=rjos20
 EDITORIAL
Introduction: Understanding Roots and Betweenness
Deﬁning Safety of Journalists as a Sub-ﬁeld of Research.
Reading between the Lines
Introduction
The topic of the safety of journalists has emerged as an increasingly important one in public
discourse in tandem with the advancement of the study of journalists’ safety over the last few
years. As more attention is given to the fact that a journalist is killed every seventh day for
work-related reasons, the awareness of the safety of journalists as one of the most daunting
challenges for press freedom and democracy around the world has grown. The Nobel peace
prize award of 2021 to brave journalists Maria Ressa and Dmitiri Muratov also drew inter-
national public opinion’s attention to how the safety of journalists can serve as a pointer
towards democratic development and media freedom in general.
In the more than ten years since the UN Plan of Action on the Safety of Journalists was
launched in 2012, the topic of the safety of journalists has emerged signiﬁcantly in academic
and public spheres. In 2014 UNESCO developed a research agenda in line with the Plan of
Action and promoted it through a call for research cooperation with academic scholars to
inspire new research in an area that previously had received little attention. The increase in
publications on journalism safety and the issue of impunity over the last decade is manifest.
However, can we talk about the appearance of a new academic ﬁeld?
Pierre Bourdieu’s ﬁeld theory would see an academic ﬁeld as a space characterized by a dis-
tinct set of rules, values, and norms that shape the actions and decisions of individuals within it
(Bourdieu and Johnson 1993). According to such an approach, ﬁelds are separated from one
another by their own speciﬁc forms of economic, cultural, and social capital, and habitus (dispo-
sitions, ways of thinking, and acting), which deﬁnes the boundaries of each ﬁeld. Using Bour-
dieu’s approach, the research on the safety of journalists would probably rather be a sub-
ﬁeld: distinct areas of specialization within a larger ﬁeld that has their own forms of capital
and habitus (Di Salvo 2022; Garnham and Williams 1980; Hesmondhalgh 2006; Prior 2013).
A reason for considering “Safety of Journalists” as a ﬁeld on its own premises, is the fact that
the UN, UNESCO, University Centres, and Research Groups have jointly worked to increase the
amount and quality of research into safety issues for journalists. One example is the research
agenda for safety of journalists developed by UNESCO in cooperation with researchers. We con-
sequently ﬁnd the topic of safety of journalists to be a remarkably interesting case to investigate
to better understand how a sub-ﬁeld might emerge and develop, and how roots are taken.
Our Question Here would be If the Safety of Journalists is to be
Considered an Academic Field – Where does It Find Its Roots?
To answer this question, we will approach the eleven selected articles of this Special Issue and
map their origins with the help of computational methods, in an attempt to unlock where their
ﬁnds their “roots” in terms of methods used, theoretical frameworks and citation networks,
© 2023 Informa UK Limited, trading as Taylor & Francis Group
JOURNALISM STUDIES
2023, VOL. 24, NO. 7, 825–837
https://doi.org/10.1080/1461670X.2023.2206494
 which with the help of centrality metrics enable us to say something about the article’s assumed
importance in its network and unpack how the networks relate to each other as topical clusters.
Building on these exercises, we will continue the discussion about the Safety of Journalists as an
academic subﬁeld and discover how knowledge is shared and developed within and among
clusters. Who stands out as important mediators of information in this emerging ﬁeld? And
what characterizes the geographies of the various researchers and research topics?
More than “Just” Ten1 Articles?
The ten articles of this Special Issue were collected from some of the best paper presentations
at the 7th Annual International Conference on the Safety of Journalists at OsloMet University, as
well as through an additional call for papers. To better understand the selected articles, we ﬁrst
systematized the methods used in each of them. We found that all articles utilized in-depth or
semi-structured interviews in some form as their main data collection method. The articles’
authors argue that interviews have the ability to provide a thorough understanding of partici-
pants’ experiences, perceptions, attitudes, and motivations.
Some authors employed mixed methods, combining interviews with surveys (two articles)
and document analysis (three articles), to achieve a more comprehensive understanding of
their research question. According to these authors, this approach allowed them to triangulate
data and enhance the validity and reliability of their results. There are clearly many similarities
between the investigations represented here although the topics and locations of the studies
are quite diverse.
Reading the 11 articles, we realized that the articles speak to each other in terms of theoretical
frameworks and how theoretical perspectives are reﬂected in the methodologies developed for
each investigation. “Resilience” is the most used theoretical framework. It is employed by authors
here to formulate research questions, develop methods, in addition to interpreting and explain-
ing ﬁndings. In general, resilience is seen as the capacity to bounce back from adversity and
maintain functioning in challenging conditions. In the context of journalism, resilience is
being used to refer to the ability of journalists to continue carrying out their work safely in
the face of threats, or to “bounce back” after a critical event. Typically, the authors represented
here also include other theoretical perspectives to understand the safety issues, for example
resistance. This perspective focuses on the means by which journalists withstand threats and per-
severe. Post-traumatic growth is another perspective used to examine how journalists can experi-
ence positive outcomes after exposure to traumatic events, such as increased self-awareness and
personal strength. Emotional labour, meanwhile, highlights the emotional toll that journalism
can take on journalists, including feelings of stress, anxiety, and burnout. The postcolonial fem-
inist approach considers the impact of colonialism and patriarchal structures on the experiences
of journalists, particularly those from marginalized communities. Mediated social capital encom-
passes the role that social networks and relationships play in promoting journalist safety. Discur-
sive structural inequalities highlight the ways in which dominant narratives and power structures
shape the experiences of journalists and impact their safety. Routine activity theory examines
how individuals’ characteristics and routines, contact with motivated oﬀenders, and lack of guar-
dianship dispose them to victimization. Media capture considers the ways in which media organ-
izations and industries can be inﬂuenced by political and economic interests, which can lead to
biased reporting and threats to journalist safety. The social-ecological perspective explores the
interplay between the social and natural environments in shaping journalist safety. Boundary
work is used to analyse the evolution of journalism and its institutions over time. As digital tech-
nology and cultural and political changes raise questions about the deﬁnition and purpose of
journalism, boundary work helps to understand the ongoing development of the ﬁeld.
826
EDITORIAL
 As guest editors of the special issue, we ﬁnd all these perspectives and lenses help the
authors gain new insights and build knowledge about the safety of journalists. At the same
time, we see that these perspectives are interconnected and belong to similar traditions
related to each other. This kinship is one of the reasons why we want to know more and under-
stand better where the emergent research ﬁeld of safety of journalism is coming from.
Building a Citation Network
At the ﬁrst level of analysis, we reviewed the 11 articles and their references, which in total
added up to 277. We then went on to a second level of analysis, where we developed a citation
network to be able to say something more about where the eleven articles ﬁnd their theoreti-
cal and methodological roots. A citation network is a graph that represents the relationships
between published works based on citations. It is a directed graph with works as nodes and
citations as edges. This network is used in bibliometrics and scientometrics to gain insight
into the structure of scientiﬁc literature and knowledge diﬀusion. By analysing citation net-
works, researchers can study various aspects of the scientiﬁc landscape, such as the
inﬂuence of works, the popularity of topics, the evolution of subject areas, and the emergence
of new subﬁelds. They can also assess the inﬂuence of researchers, institutions, journals,
funding agencies, and other stakeholders. In summary, citation networks are useful for study-
ing the relationships between published works and their inﬂuence on science.
In our analysis of the “safety of journalists” studies, we sought to uncover the roots of this
emerging ﬁeld. Our approach involved tracing the citations of the 11 articles in the special
issue. We started by analysing the citations of these 11 articles and found approximately
270 relevant papers. By taking advantage of a “snowballing” algorithm combined with a bib-
liography API (Crossref n.d.; Pallath n.d.; Pallath and Zhang 2022), we then expanded our
search by following the citations in these papers for two extra level, resulting in the collection
of information on over 44,000 published works. We collected data such as author details,
aﬃliations, article titles, journal names, and publication years to gain a deeper understanding
of who, what, where, and when have had an impact on the development of the ﬁeld over time.
The goal of this analysis was to shed light on the key players, works, and historical events that
have shaped the “safety of journalists” studies.
Our analysis yielded a number of intriguing ﬁndings. We identiﬁed clusters of literature,
using the Louvain algorithm (Blondel et al. 2008), that had a substantial impact on the articles
of the special issue and observed the ﬂow of citations and knowledge between these clusters.
Additionally, several articles emerged as signiﬁcant “bridges,” connecting the clusters and
facilitating the transfer of knowledge. These insights allow us to gain a better understanding
of the disciplines and ﬁelds that are shaping the emergence of “safety of journalists” studies.
The ﬁndings also highlight the importance of interdisciplinary exchange in shaping this ﬁeld.
Lastly, we aim to make possible a further examination of the speciﬁc articles that serve as facil-
itators in bridging knowledge between diﬀerent disciplines and clusters of articles.
Three clusters stand out in terms of the number of articles and citations.
First, the cluster “Cyberbullying and Adolescent Victimization” focuses on the examination of
diﬀerent forms of bullying, victimization, and its impact on the mental and emotional health of
adolescents. The most frequent words and bi-grams include “sexual harassment,” “mental
health,” “fear crime,” and “routine activities,” among others, pointing to a broader concern
for the eﬀects of victimization on individuals, particularly school-aged youth. The trigrams
reinforce this emphasis by highlighting terms such as “high school students,” “middle
school students,” “among college students,” and “among African American,” indicating a par-
ticular interest in the study of bullying among diﬀerent demographics of young people.
JOURNALISM STUDIES
827
 Additionally, terms such as “General theory of crime,” “social learning theory,” and “structural
equation modelling” suggest a focus on understanding the underlying theories and modeling
approaches used to study these topics.
The second cluster can be summarized as “Media and Political Communication” with a focus on
the impact of news media, social media, and other forms of communication on public opinion,
political participation, and human rights. It is of course no surprise that a cluster of media and
communication related articles is by far the largest of the clusters. The cluster includes studies
examining the eﬀects of media on attitudes, job satisfaction, and social support, as well as the
role of media in shaping political communication, public sphere, and social movements. The
research also investigates the impact of media coverage on social and political issues such as
sexual harassment, foreign policy, and elections. The analysis includes both content analysis
and comparative studies, and the use of various methodologies such as structural equation mod-
eling, critical discourse analysis, and interpretive phenomenological analysis.
The third cluster appears to focus on the theme of “Mental Health”. The bi-grams and tri-
grams are related to topics such as posttraumatic stress disorder, stress disorder, health
care, asylum seekers, systematic reviews, social support, labor market, mental disorders,
health literacy, quality of life, political violence, primary care, psychological distress, qualitative
research, risk factors, health status, mental health services, and more. The trigrams, speciﬁcally,
delve into topics such as posttraumatic stress disorder among asylum seekers and refugees,
mental health services for displaced persons, symptoms of stress disorder and depression,
mental health problems among Syrian refugees, and randomized controlled trials for treating
posttraumatic stress. Overall, this cluster highlights the importance of addressing mental
health concerns in various populations and the role of various factors such as access to
health care, social support, and political violence in aﬀecting mental health.
In addition to the three dominant clusters, we identiﬁed a further six subclusters of articles.
These subclusters have been given descriptive titles and are summarized below to provide an
idea of the content contained within each. As will be clear from the descriptions below, some
of the clusters are heavily inﬂuenced by the geographies of the studies selected for the special
issue.
Cluster 4: International Law and Human Rights. This cluster of sources revolves around topics
regarding global legislation, human privileges, and legality in armed conﬂicts. It features col-
locations of two or three words and references to journals, reports, and communiques, as well
as terms such as “combating lawlessness,” “humanitarian law,” “minimum humanitarian stan-
dards,” “legal framework,” and “war on terror.
Cluster 5: Suicide Prevention. The focus of this cluster is suicide risk assessment and avoid-
ance. Main areas of concern are suicide risk, suicide prevention, risk factors, suicidal behavior,
suicide attempts, systematic review, and suicidal ideation. Cluster also underscores the signiﬁ-
cance of mental health, personality disorder, and primary care in suicide prevention. Studies
on suicide risk and prevention are typically conducted in the US and emphasize the require-
ment for public health promotion and risk assessment. Cluster mentions randomized con-
trolled trials and cohort studies in understanding suicide risk factors, especially in men.
Dialectical behavior therapy, health behavior change, and suicide prevention programs are
highlighted as important interventions. Cluster discusses the prevalence of suicide risk
factors, depression and primary care relationship, interpersonal and psychological theories
of suicide, and the role of deliberate self-harm in suicide prevention. Systematic reviews of
adolescent suicidal behavior are also emphasized as necessary.
Cluster 6: Turkish Cities and Globalization. This cluster of papers seems to be examining the
theme of urban renewal and political struggles in the context of Turkish cities and globaliza-
tion. The papers delve into the various aspects of urban transformation, citizenship,
828
EDITORIAL
 environmentalism, and politics of space in an urban context, focusing on the struggles of the
poor, refugees, and social movements. Cluster 7: Childcare Policies in Post-Communist Europe.
This cluster focuses on analysing childcare policies in post-communist Central European
countries, particularly their impact on gender equality and the role of women in society.
The papers examine the historical background and current state of welfare policies in countries
such as Poland, Hungary, and Germany and how they have shifted towards a more liberal and
business-oriented approach.
Cluster 8: Family Policies and Gender Relations in Post-Communist Europe. The papers in this
cluster examine family policies and childcare arrangements in post-communist Central Euro-
pean countries and their impact on gender relations and work-life balance. The articles
seem to be utilizing qualitative and comparative methods to gauge the generosity of policies
and evaluate changes in care services.
Cluster 9: Technology and Mental Health. The articles in this cluster examine the intersection
of technology, mental health, and resilience. Topics explored include secondary traumatic
stress among police oﬃcers, resilience training, randomized controlled trials, and the impact
of virtual reality on mental health. The ﬁndings suggest the signiﬁcance of peer support, posi-
tive psychological capital, and judicious design in technology aimed at promoting emotional
well-being and resilience. Based on the articles of this special issue, the emergent ﬁeld of
“Safety of Journalists” appears to be a multidisciplinary ﬁeld that involves the study of numer-
ous issues related to journalists and the media. The most inﬂuential clusters of papers focus on
three main themes: Media and Political Communication; Mental Health and Cyberbullying and
Adolescent Victimization. These themes highlight the importance of addressing certain chal-
lenges that journalists face as well as the impact that media can have on society, including
mental health concerns, bullying and victimization, and political communication. The
studies also suggest that there is a focus on understanding the underlying theories and
methods used to study these topics (Figure 1).
Figure 1. Visual representation of the Citation Network in which diﬀerent communities are high-
lighted. The percentage of articles in each community is reported within brackets. Graph generated
using Gephi [https://gephi.org/].
JOURNALISM STUDIES
829
 Betweenness - What makes Knowledge Flow between Clusters?
Once we successfully built a Citation Network, we had the opportunity to extract, for each
article, centrality metrics describing its importance in the network. Two of the most used
metrics in the ﬁeld are “degree”, reﬂecting how many connections each nodes holds, and
“betweenness”, representing the importance of a node in connecting the network together
(Barrat et al. 2004; Borassi and Natale 2016; Jia et al. 2012). Of particular interest for our analysis
is the “betweenness” since it holds a distinct connotation in comparison to other centrality
metrics. Rather than merely reﬂecting the importance of a node in the network, betweenness
characterizes a node’s signiﬁcance as a mediator of information or citation ﬂow between sep-
arate clusters or communities of articles.
This is quantiﬁed by counting the frequency with which the node appears in the shortest
paths linking distinct groups of nodes. Nodes exhibiting a high betweenness score serve as
critical conduits, allowing for the exchange of information between otherwise disparate com-
munities (Barrat et al. 2004; Leydesdorﬀ2007).
The analysis of betweenness in a citation network can provide a nuanced understanding of
the network’s structure and dynamics, illuminating the relationships between disparate com-
munities and the intermediating role of speciﬁc articles.
While centrality gauges a node’s overall prominence, reﬂecting its many connections
and the frequency of its citation by other nodes, betweenness is a metric which
assesses a node’s function as a bridge or connector between disparate communities
of articles.
In our analysis, we elected to concentrate on betweenness rather than centrality because
we wanted to understand the function of particular references in bridging the ﬂow of infor-
mation or citations between diﬀerent research areas. By analysing betweenness, we sought
to discern the nodes which played a crucial role in linking diﬀerent parts of the network
and fostering the exchange of knowledge between these disparate communities.
Top Articles on the Betweenness-list
We found “Comparing Media Systems” to be the most important study in terms of between-
ness-score (Hallin and Mancini 2004). This comes as no surprise, given the signiﬁcant impact
the book has had on the ﬁeld of media and communication studies. Its contributions to
research on media systems, media policy, and comparative media analysis are evident in
the frequency with which it is referenced in these areas. Furthermore, the book’s theoretical
framework has had a profound impact on shaping research in the ﬁeld and has facilitated a
greater understanding of the complex relationship between media, politics, and society
across diﬀerent countries. It is worth noting that the impact of “Comparing Media Systems”
extends beyond media and communication studies. The ﬁndings of this investigation shows
that the book has also played a pivotal role in disseminating theories and knowledge from
media studies to other disciplines.
The book “Comparing Media Systems” belongs to the largest cluster of references which we
named “Media and Political Communication” above. Interestingly, the articles and books in the
Media and Political Communication cluster with the highest betweenness-score must be
divided into at least four diﬀerent groups. Three of the most important references (in terms
of betweenness-score), are more general Media Analysis and Media Theory type of articles
and books such as “Comparing Media Systems”, “An Emotional Turn in Journalism Studies?”
and “The role of self-reports in the study of news production” (Hallin and Mancini 2004;
Ryfe 2020; Wahl-Jorgensen 2020). However, a topically narrower group of references seems
to be playing an even more important role in the ﬂow of knowledge between cluster in this
830
EDITORIAL
 system of references. This group includes titles such as “Not Funny? The Eﬀects of Factual
Versus Sarcastic Journalistic Responses to Uncivil User Comments” (Ziegele and Jost 2020),
“Engagement Moderation: What Journalists Should Say to Improve Online Discussions”
(Masullo, Riedl, and Huang 2022), “Online Harassment and Its Implications for the Journal-
ist–Audience Relationship” (Lewis, Zamith, and Coddington 2020), Mob Censorship: Online
Harassment of US Journalists in Times of Digital Hate and Populism (Waisbord 2020) and
“Roots of Incivility: How Personality, Media Use, and Online Experiences Shape Uncivil Partici-
pation” (Frischlich et al. 2021). Keywords are journalism, incivility, and online harassment. It is
not diﬃcult to understand why these two groups of references belong to the Media and Pol-
itical Communication cluster. Perhaps more surprisingly, an article from Statistics examining
how well certain criteria work when evaluating how well statistical models ﬁt observed
data, is found to be among the top articles when it comes to betweenness-score in this
cluster (Hu and Bentler 1999). The fact that this article is so much cited indicates the impor-
tance of statistical methods for the development of the Media and Political Communication
cluster. The inclusion of “Using thematic analysis in psychology in this cluster, despite its
apparent divergence from the other articles, highlights the signiﬁcance of thematic analysis
as a methodology that transcends disciplinary boundaries, and underscores its potential use-
fulness in both psychological and media and communication studies research (Braun and
Clarke 2006).
The clustering and betweenness score analysis indicate that many general articles on media
and communication studies are being cited in other ﬁelds and disciplines, suggesting a ﬂow of
knowledge beyond the Media and Political Communication cluster. However, it is noteworthy
that statistics and thematic analysis play a crucial role in this cluster. The emphasis on statistics
and thematic analysis suggests the importance of both quantitative and qualitative
approaches in media and communication research, and the need for interdisciplinary collab-
orations to better understand the complex relationship between media, politics, and society.
We also found a few references with hight betweenness-score in the other clusters. The
second most important references (in terms of betweenness-score) in the whole reference
network, is a proposal of a “social-ecological framework of theory, assessment, and prevention
of suicide” (Cramer and Kapusta 2017). The article provides a comprehensive and integrated
framework for understanding and addressing suicide risk that has been widely cited and
used in research and practice, also among researchers of journalism. In this citation
network, the article is part of the cluster we have earlier named “Cluster 5: Suicide Prevention”
with suicide risk, suicide prevention, risk factors, suicidal behavior, suicide attempts, systematic
review, and suicidal ideation as principal areas of concern. The social-ecological framework for
understanding suicide risk takes a comprehensive and integrated approach, recognizing that
suicide prevention eﬀorts should go beyond individual-level risk factors to also address com-
munity and societal factors that contribute to suicide risk.
The last article we will mention here, calls for an integrated, multi-system approach to
address the unique needs of refugee women (Hawkins et al. 2021). It highlights the need
for comprehensive synthesis regarding how individual, interpersonal, community, and organ-
izational factors interact to inﬂuence the health of refugee women. This article plays a vital role
in building knowledge in cluster 3 “Mental Health”.
Our analysis found that articles on suicide prevention and refugee women’s mental health
have high betweenness-score and play important roles in building knowledge in their respect-
ive clusters. Such articles emphasize the need for a comprehensive and integrated approach
that addresses individual, interpersonal, community, and societal factors in for example pre-
venting suicide and improving mental health outcomes for refugee women.
JOURNALISM STUDIES
831
 Geographies of Researchers & Research Topics
In this ﬁgure, we have plotted the results for the countries mentioned either in author
aﬃliations or in titles. We are particularly interested in the countries represented by the
dark red circles. This is the group of countries deemed by Reporters Without Borders to be
in a very serious (dark red) condition when it comes to safety of journalists (Methodology
Used for Compiling the World Press Freedom Index | RSF n.d.).
In this study, we have utilized the safety index of Reporters Without Borders to rank
countries according to the safety of journalists. Along with that, we have estimated the
number of references that deal with issues related to speciﬁc countries by counting references
that contain the country’s name in the title. Lastly, we have estimated the number of published
authors from diﬀerent countries based on the university aﬃliations mentioned in the author
aﬃliation ﬁelds of the references.
Reporters Without Borders has been monitoring the safety of journalists globally since
2002, providing a safety index that ranks countries according to the safety and protection pro-
vided to journalists (Index | RSF n.d.). The safety index considers a range of factors such as vio-
lence against journalists, legal restrictions, and censorship, among others. This safety index
serves as a useful tool to understand the safety of journalists in diﬀerent countries.
Our analysis has revealed some noteworthy patterns that can be utilized to inform discus-
sions on the safety of journalists. Our ﬁndings indicate that countries with a low ranking in the
safety index of Reporters Without Borders have fewer published authors and references
dealing with issues related to them. On the other hand, many countries that rank high in
the safety index have a higher number of published authors and references. For instance,
countries such as Norway, Sweden, Finland, and Denmark, which rank high in the safety
index, have a relatively larger number of published authors and references dealing with
832
EDITORIAL
 issues related to them. In contrast, countries like Pakistan, Afghanistan, and Iraq, which rank
low in the safety index, have fewer published authors and references.
As we see, many of these countries are concentrated in the bottom left quadrant of the
ﬁgure. Amongst the countries scoring low on the RSF safety index, China and Mexico stand
out by the number of titles referring speciﬁcally to China or Mexico and the number of
authors aﬃliated to Chinese or Mexican universities. We believe this is an indication of the rela-
tive strength of the university system and research in general in these two countries. Afghani-
stan, meanwhile, stands out as a country that have received signiﬁcant interest from
researchers but with very few local authors cited in the network. Palestine, Vietnam, and
Morocco are examples of countries that seem to have been little researched while at the
same time very seldom are mentioned in the aﬃliations of the authors.
This ﬁnding is signiﬁcant as it highlights the pressing need for increased attention to the
safety of journalists and the protection of freedom of expression in countries where journalists
face signiﬁcant challenges. However, the study has some limitations. Firstly, the safety index of
Reporters Without Borders is not a comprehensive measure of the safety of journalists, and it
does not account for all factors that can impact the safety of journalists. Secondly, our esti-
mation of the number of published authors and references is based on a simpliﬁed approach,
which may not accurately reﬂect the true number of authors or references.
It is important to note that a large number of countries ranked by Reporters Without
Borders for the safety of journalists are not included in the graph presented in this study.
This is primarily because the graph is based on references that contain a country’s name in
the title and authors’ aﬃliations that mention the country. As a result, countries that are
not mentioned in the titles or do not have any author aﬃliations related to the country are
not represented in the graph.
This limitation is particularly concerning for some of the most dangerous countries for jour-
nalists since they may not have enough published authors or references that meet the criteria
for inclusion in the graph. The top 18 country ranked by safety score which are not represented
in the graph above are reported in the table below.
Country name
CODE
Safety Score
Mentions in titles
Mentions in aﬃliations
Myanmar
MMR
95,37
1
Not present
Eritrea
ERI
88,64
1
Not present
Yemen
YEM
88,46
1
Not present
North Korea
PRK
87,62
Not present
Not present
Syria
SYR
86,61
Not present
Not present
Iran
IRN
86,39
10
Not present
Iraq
IRQ
81,73
88
Not present
Somalia
SOM
81,73
8
Not present
Belarus
BLR
81,15
Not present
Not present
Dem. Rep. Congo
COD
75,66
Not present
Not present
Nicaragua
NIC
72,32
2
Not present
Azerbaijan
AZE
71,52
Not present
Not present
Bahrain
BHR
70,35
5
Not present
Venezuela
VEN
68,78
Not present
1
Guatemala
GTM
67,88
6
Not present
Turkmenistan
TKM
64,31
Not present
Not present
Libya
LBY
63,42
3
Not present
Rwanda
RWA
61,24
19
Not present
It is worth noting that the exclusion of a large number of countries from then graph is a
reﬂection of the fact that the citation network was built upon a narrow group of articles
dealing with speciﬁc topics and geographies. These topics and geographies often did not
require the inclusion of references from the excluded countries. Consequently, the exclusion
JOURNALISM STUDIES
833
 of these countries may not necessarily indicate a lack of published authors or references
dealing with issues related to them. Rather, it may be a result of the speciﬁc focus of the articles
included in the citation network. It is important to consider this context when interpreting the
ﬁndings presented in this study and to avoid generalizing the results to countries that we
excluded from the graph. It is also worth noting that while the country Syria has no mentions
in the titles, a number of articles in the network deals with issues related to “Syrian Refugees.”
Knowledge Transfer?
While this exploratory study has limitations, it provides insights into the relationship between
the safety of journalists in individual countries and the number of aﬃliated authors and refer-
ences dealing with that country. Our analysis indicates that there is a linear relationship
between aﬃliations and the number of articles, as seen on a log to log scale. However, the
line for relatively safe countries, those with a score below 60, appears to run parallel to but
signiﬁcantly below the line for more unsafe countries, those with a score above 59.
The ﬁndings suggest that studies focused on unsafe countries are more likely to be con-
ducted by scholars based at universities in relatively safe countries, rather than the other
way around. It indicates that much research about unsafe environments for journalists build
on theories and methodologies developed in relatively safe localities and found useful for
studies of journalists in those localities. While this may seem like an obvious observation,
we believe that it is crucial to understand how knowledge ﬂows between distinct locations
in order to improve the quality and impact of research in this area. By recognizing the asym-
metrical distribution of research on the safety of journalists, we can identify potential biases
834
EDITORIAL
 and gaps in knowledge production. This understanding can help to inform eﬀorts to improve
the quality and relevance of research, as well as to ensure that the perspectives and experi-
ences of scholars from diverse locations are considered. Overall, the study highlights the
importance of considering the geographic and institutional factors that shape knowledge pro-
duction in the ﬁeld of journalism and related areas. By doing so, we can foster a more inclusive
and robust research community that is better equipped to address the complex challenges
facing journalists and freedom of expression globally.
We believe this to be particularly important in relation to the topics and geographies
coming out of this study as this universe of references draw extensively on studies dealing
with Mental Health and Cyberbullying and Adolescent Victimization. We need to ask to what
extent are theories and ﬁndings related to mental health issues stemming from studies in rela-
tively safe locations such as the US or Northers Europe useful when trying to understand safety
related issues in Afghanistan, Syria, Nicaragua or Iraq?
Koch and Weingart suggest that the idea of knowledge transfer is a delusion because it
assumes that knowledge is a tangible and transferable commodity that can be easily trans-
mitted from one location to another (Koch and Weingart 2016). According to their perspective,
this assumption overlooks the complex social, cultural, and institutional factors that shape the
production and dissemination of knowledge in diﬀerent contexts.
Instead, we propose that researchers of the safety of journalists should focus on the idea of
knowledge co-construction, which recognizes that knowledge is a dynamic and socially con-
structed process that involves the interaction and collaboration of diverse actors across
diﬀerent locations and contexts. This perspective highlights the importance of recognizing
and valuing the diverse perspectives, experiences, and knowledge systems that shape
research and innovation in diﬀerent ﬁelds.
Caveat
It is vital to note that the selection of ﬁrst-level articles in a citation network analysis can sig-
niﬁcantly aﬀect the results. In the present study, the ﬁrst articles were those published in this
particular special issue. A diﬀerent set of articles would have resulted in a diﬀerent citation
network. For a more comprehensive understanding of the emerging subﬁeld of journalist
safety, a broader selection of articles should be considered in future projects. However, the
present experiment provides a way to study the development of a ﬁeld or subﬁeld and to
analyse its formation at an early stage. In this way, steps can be taken to ensure a diverse rep-
resentation of topics, geographies, theories, and methodologies in the ﬁeld, thus promoting
inclusiveness and progress.
We recognize that the articles in this special issue may not be fully representative of the
sub-ﬁeld of safety of journalists. Other relevant articles exist that address important topics
and are not included here. Additionally, other scholars employ diﬀering methodologies and
theories from those represented in this issue.
Consequently, we are not claiming that the citation network presented is fully represen-
tative of the sub-ﬁeld. However, this approach serves as a valuable tool for comprehending
the theoretical and methodological foundations and historical origins of this special issue.
Despite its experimental nature, we contend that this approach has the potential to
provide insight into how ﬁelds emerge, and research develops. If nothing else, this
method has allowed us to introduce the articles of this special issue in a productive and
informative manner.
Little has so far been written about the community of scholars studying and contributing to
the increased knowledge base of the safety of journalists. Approaching the growing line of
JOURNALISM STUDIES
835
 academics and critical practitioners interested in the topic and their work as an emerging new
academic ﬁeld, allows us as this article has illustrated, to consider both its prospects and chal-
lenges in more thorough and analytical way.
Note
1. (Henrichsen and Shelton 2022) was originally planned to be part of the special issue and has
consequently been included in the reference network referred to in this introduction.
References
Barrat, A., M. Barthélemy, R. Pastor-Satorras, and A. Vespignani. 2004. “The Architecture of Complex Weighted
Networks.” Proceedings of the National Academy of Sciences 101 (11): 3747–3752. doi:10.1073/pnas.
0400087101.
Blondel, V. D., J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. 2008. “Fast Unfolding of Communities in Large
Networks.” Journal of Statistical Mechanics: Theory and Experiment 2008 (10): 10008. doi:10.1088/1742-
5468/2008/10/P10008.
Borassi, M., and E. Natale. 2016. KADABRA is an ADaptive Algorithm for Betweenness via Random Approximation
[Application/pdf]. 18 pages. doi:10.4230/LIPICS.ESA.2016.20.
Bourdieu, P., and R. Johnson. 1993. The Field of Cultural Production: Essays on Art and Literature. New York:
Columbia University Press.
Braun, V., and V. Clarke. 2006. “Using Thematic Analysis in Psychology.” Qualitative Research in Psychology 3 (2):
77–101. doi:10.1191/1478088706qp063oa.
Cramer, R. J., and N. D. Kapusta. 2017. “A Social-Ecological Framework of Theory, Assessment, and Prevention of
Suicide.” Frontiers in Psychology 8: 1756. doi:10.3389/fpsyg.2017.01756.
Crossref. n.d. Crossref-commons: Crossref Commons (0.0.7) [Python; OS Independent]. Accessed March 3, 2023.
https://gitlab.com/crossref/crossref_commons_py.
Di Salvo, P. 2022. “Information Security and Journalism: Mapping a Nascent Research Field.” Sociology Compass
16: 3. doi:10.1111/soc4.12961.
Frischlich, L., T. Schatto-Eckrodt, S. Boberg, and F. Wintterlin. 2021. “Roots of Incivility: How Personality, Media
Use, and Online Experiences Shape Uncivil Participation.” Media and Communication 9 (1): 195–208. doi:10.
17645/mac.v9i1.3360.
Garnham, N., and R. Williams. 1980. “Pierre Bourdieu and the Sociology of Culture: An Introduction.” Media,
Culture & Society 2 (3): 209–233
Hallin, D. C., and P. Mancini. 2004. Comparing Media Systems: Three Models of Media and Politics. 1st ed.
Cambridge University Press. doi:10.1017/CBO9780511790867.
Hawkins, M. M., M. E. Schmitt, C. T. Adebayo, J. Weitzel, O. Olukotun, A. M. Christensen, A. M. Ruiz, et al. 2021.
“Promoting the Health of Refugee Women: A Scoping Literature Review Incorporating the Social
Ecological Model.” International Journal for Equity in Health 20 (1): 45. doi:10.1186/s12939-021-01387-5.
Henrichsen, J. R., and M. Shelton. 2022. “Boundaries, Barriers, and Champions: Understanding Digital Security
Education in US Journalism Programs.” Journalism Studies, 1–20. doi:10.1080/1461670X.2022.2148267.
Hesmondhalgh, D. 2006. “Bourdieu, the Media and Cultural Production.” Media, Culture & Society 28 (2): 211–231.
doi:10.1177/0163443706061682.
Hu, L., and P. M. Bentler. 1999. “CutoﬀCriteria for Fit Indexes in Covariance Structure Analysis: Conventional
Criteria Versus New Alternatives.” Structural Equation Modeling: A Multidisciplinary Journal 6 (1): 1–55.
doi:10.1080/10705519909540118.
Index | RSF. n.d. Accessed March 23, 2023. https://rsf.org/en/index
Jia, Y., V. Lu, J. Hoberock, M. Garland, and J. C. Hart. 2012. “Edge v. Node Parallelism for Graph Centrality Metrics.”
In GPU Computing Gems Jade Edition, 15–28. Elsevier. doi:10.1016/B978-0-12-385963-1.00002-2.
Koch, S., and P. Weingart. 2016. The Delusion of Knowledge Transfer: The Impact of Foreign aid Experts on Policy-
making in South Africa and Tanzania. African Minds.
Lewis, S. C., R. Zamith, and M. Coddington. 2020. “Online Harassment and Its Implications for the Journalist–
Audience Relationship.” Digital Journalism 8 (8): 1047–1067. doi:10.1080/21670811.2020.1811743.
Leydesdorﬀ, L. 2007. “Betweenness Centrality as an Indicator of the Interdisciplinarity of Scientiﬁc Journals.”
Journal of the American Society for Information Science and Technology 58 (9): 1303–1319. doi:10.1002/asi.
20614.
836
EDITORIAL
 Masullo, G. M., M. J. Riedl, and Q. E. Huang. 2022. “Engagement Moderation: What Journalists Should Say to
Improve Online Discussions.” Journalism Practice 16 (4): 738–754. doi:10.1080/17512786.2020.1808858.
Methodology used for compiling the World Press Freedom Index | RSF. n.d. Accessed March 13, 2023. https://rsf.org/
en/index-methodologie-2022.
Pallath, A. n.d. Paperfetcher: Python Package to Mine Papers for Systematic Reviews. (1.2.0). Accessed March 3,
2023. https://github.com/paperfetcher/paperfetcher.
Pallath, A., and Q. Zhang. 2022. “Paperfetcher : A Tool to Automate Handsearching and Citation Searching for
Systematic Reviews.” Research Synthesis Methods, jrsm 1604. doi:10.1002/jrsm.1604.
Prior, N. 2013. “Bourdieu and the Sociology of Music Consumption: A Critical Assessment of Recent
Developments.” Sociology Compass 7 (3): 181–193. doi:10.1111/soc4.12020
Ryfe, D. M. 2020. “The Role of Self-reports in the Study of News Production.” Journalism 21 (3): 349–364. doi:10.
1177/1464884918800076.
Wahl-Jorgensen, K. 2020. “An Emotional Turn in Journalism Studies?” Digital Journalism 8 (2): 175–194. doi:10.
1080/21670811.2019.1697626.
Waisbord, S. 2020. “Mob Censorship: Online Harassment of US Journalists in Times of Digital Hate and Populism.”
Digital Journalism 8 (8): 1030–1046. doi:10.1080/21670811.2020.1818111.
Ziegele, M., and P. B. Jost. 2020. “Not Funny? The Eﬀects of Factual Versus Sarcastic Journalistic Responses to
Uncivil User Comments.” Communication Research 47 (6): 891–920. doi:10.1177/0093650216671854.
Roy Krøvel
Department of Journalism and Media Studies, OsloMet – Oslo Metropolitan University,
Oslo, Norway
royk@oslomet.no
Fabrizio Palumbo
Department of Journalism and Media Studies, OsloMet – Oslo Metropolitan University,
Oslo, Norway
Kristin Skare Orgeret
Department of Journalism and Media Studies, OsloMet – Oslo Metropolitan University,
Oslo, Norway
JOURNALISM STUDIES
837
",10.1080/1461670X.2023.2206494,doc5,"Journalism Studies (Online) Journal homepage: www.tandfonline.com/journals/rjos20 Introduction: Understanding Roots and Betweenness Deﬁning Safety of Journalists as a Sub-ﬁeld of Research. Reading between the Lines Roy Krøvel, Fabrizio Palumbo & Kristin Skare Orgeret To cite this article: Roy Krøvel, Fabrizio Palumbo & Kristin Skare Orgeret (2023) Introduction: Understanding Roots and Betweenness Deﬁning Safety of Journalists as a Sub-ﬁeld of Research. Reading between the Lines, Journalism Studies, 24:7, 825-837, DOI: 10.1080/1461670X.2023.2206494 To link to this article: Published online: 18 Jul 2023. Submit your article to this journal Article views: 868 View related articles View Crossmark data Citing articles: 2 View citing articles Full Terms & Conditions of access and use can be found at EDITORIAL Introduction: Understanding Roots and Betweenness Deﬁning Safety of Journalists as a Sub-ﬁeld of Research. Reading between the Lines Introduction The topic of the safety of journalists has emerged as an increasingly important one in public discourse in tandem with the advancement of the study of journalists’ safety over the last few years. As more attention is given to the fact that a journalist is killed every seventh day for work-related reasons, the awareness of the safety of journalists as one of the most daunting challenges for press freedom and democracy around the world has grown. The Nobel peace prize award of 2021 to brave journalists Maria Ressa and Dmitiri Muratov also drew inter- national public opinion’s attention to how the safety of journalists can serve as a pointer towards democratic development and media freedom in general. In the more than ten years since the UN Plan of Action on the Safety of Journalists was launched in 2012, the topic of the safety of journalists has emerged signiﬁcantly in academic and public spheres. In 2014 UNESCO developed a research agenda in line with the Plan of Action and promoted it through a call for research cooperation with academic scholars to inspire new research in an area that previously had received little attention. The increase in publications on journalism safety and the issue of impunity over the last decade is manifest. However, can we talk about the appearance of a new academic ﬁeld? Pierre Bourdieu’s ﬁeld theory would see an academic ﬁeld as a space characterized by a dis- tinct set of rules, values, and norms that shape the actions and decisions of individuals within it (Bourdieu and Johnson 1993). According to such an approach, ﬁelds are separated from one another by their own speciﬁc forms of economic, cultural, and social capital, and habitus (dispo- sitions, ways of thinking, and acting), which deﬁnes the boundaries of each ﬁeld. Using Bour- dieu’s approach, the research on the safety of journalists would probably rather be a sub- ﬁeld: distinct areas of specialization within a larger ﬁeld that has their own forms of capital and habitus (Di Salvo 2022; Garnham and Williams 1980; Hesmondhalgh 2006; Prior 2013). A reason for considering “Safety of Journalists” as a ﬁeld on its own premises, is the fact that the UN, UNESCO, University Centres, and Research Groups have jointly worked to increase the amount and quality of research into safety issues for journalists. One example is the research agenda for safety of journalists developed by UNESCO in cooperation with researchers. We con- sequently ﬁnd the topic of safety of journalists to be a remarkably interesting case to investigate to better understand how a sub-ﬁeld might emerge and develop, and how roots are taken. Our Question Here would be If the Safety of Journalists is to be Considered an Academic Field – Where does It Find Its Roots? To answer this question, we will approach the eleven selected articles of this Special Issue and map their origins with the help of computational methods, in an attempt to unlock where their ﬁnds their “roots” in terms of methods used, theoretical frameworks and citation networks, © 2023 Informa UK Limited, trading as Taylor & Francis Group JOURNALISM STUDIES 2023, VOL. 24, NO. 7, 825–837 which with the help of centrality metrics enable us to say something about the article’s assumed importance in its network and unpack how the networks relate to each other as topical clusters. Building on these exercises, we will continue the discussion about the Safety of Journalists as an academic subﬁeld and discover how knowledge is shared and developed within and among clusters. Who stands out as important mediators of information in this emerging ﬁeld? And what characterizes the geographies of the various researchers and research topics? More than “Just” Ten1 Articles? The ten articles of this Special Issue were collected from some of the best paper presentations at the 7th Annual International Conference on the Safety of Journalists at OsloMet University, as well as through an additional call for papers. To better understand the selected articles, we ﬁrst systematized the methods used in each of them. We found that all articles utilized in-depth or semi-structured interviews in some form as their main data collection method. The articles’ authors argue that interviews have the ability to provide a thorough understanding of partici- pants’ experiences, perceptions, attitudes, and motivations. Some authors employed mixed methods, combining interviews with surveys (two articles) and document analysis (three articles), to achieve a more comprehensive understanding of their research question. According to these authors, this approach allowed them to triangulate data and enhance the validity and reliability of their results. There are clearly many similarities between the investigations represented here although the topics and locations of the studies are quite diverse. Reading the 11 articles, we realized that the articles speak to each other in terms of theoretical frameworks and how theoretical perspectives are reﬂected in the methodologies developed for each investigation. “Resilience” is the most used theoretical framework. It is employed by authors here to formulate research questions, develop methods, in addition to interpreting and explain- ing ﬁndings. In general, resilience is seen as the capacity to bounce back from adversity and maintain functioning in challenging conditions. In the context of journalism, resilience is being used to refer to the ability of journalists to continue carrying out their work safely in the face of threats, or to “bounce back” after a critical event. Typically, the authors represented here also include other theoretical perspectives to understand the safety issues, for example resistance. This perspective focuses on the means by which journalists withstand threats and per- severe. Post-traumatic growth is another perspective used to examine how journalists can experi- ence positive outcomes after exposure to traumatic events, such as increased self-awareness and personal strength. Emotional labour, meanwhile, highlights the emotional toll that journalism can take on journalists, including feelings of stress, anxiety, and burnout. The postcolonial fem- inist approach considers the impact of colonialism and patriarchal structures on the experiences of journalists, particularly those from marginalized communities. Mediated social capital encom- passes the role that social networks and relationships play in promoting journalist safety. Discur- sive structural inequalities highlight the ways in which dominant narratives and power structures shape the experiences of journalists and impact their safety. Routine activity theory examines how individuals’ characteristics and routines, contact with motivated oﬀenders, and lack of guar- dianship dispose them to victimization. Media capture considers the ways in which media organ- izations and industries can be inﬂuenced by political and economic interests, which can lead to biased reporting and threats to journalist safety. The social-ecological perspective explores the interplay between the social and natural environments in shaping journalist safety. Boundary work is used to analyse the evolution of journalism and its institutions over time. As digital tech- nology and cultural and political changes raise questions about the deﬁnition and purpose of journalism, boundary work helps to understand the ongoing development of the ﬁeld. 826 EDITORIAL As guest editors of the special issue, we ﬁnd all these perspectives and lenses help the authors gain new insights and build knowledge about the safety of journalists. At the same time, we see that these perspectives are interconnected and belong to similar traditions related to each other. This kinship is one of the reasons why we want to know more and under- stand better where the emergent research ﬁeld of safety of journalism is coming from. Building a Citation Network At the ﬁrst level of analysis, we reviewed the 11 articles and their references, which in total added up to 277. We then went on to a second level of analysis, where we developed a citation network to be able to say something more about where the eleven articles ﬁnd their theoreti- cal and methodological roots. A citation network is a graph that represents the relationships between published works based on citations. It is a directed graph with works as nodes and citations as edges. This network is used in bibliometrics and scientometrics to gain insight into the structure of scientiﬁc literature and knowledge diﬀusion. By analysing citation net- works, researchers can study various aspects of the scientiﬁc landscape, such as the inﬂuence of works, the popularity of topics, the evolution of subject areas, and the emergence of new subﬁelds. They can also assess the inﬂuence of researchers, institutions, journals, funding agencies, and other stakeholders. In summary, citation networks are useful for study- ing the relationships between published works and their inﬂuence on science. In our analysis of the “safety of journalists” studies, we sought to uncover the roots of this emerging ﬁeld. Our approach involved tracing the citations of the 11 articles in the special issue. We started by analysing the citations of these 11 articles and found approximately 270 relevant papers. By taking advantage of a “snowballing” algorithm combined with a bib- liography API (Crossref n.d.; Pallath n.d.; Pallath and Zhang 2022), we then expanded our search by following the citations in these papers for two extra level, resulting in the collection of information on over 44,000 published works. We collected data such as author details, aﬃliations, article titles, journal names, and publication years to gain a deeper understanding of who, what, where, and when have had an impact on the development of the ﬁeld over time. The goal of this analysis was to shed light on the key players, works, and historical events that have shaped the “safety of journalists” studies. Our analysis yielded a number of intriguing ﬁndings. We identiﬁed clusters of literature, using the Louvain algorithm (Blondel et al. 2008), that had a substantial impact on the articles of the special issue and observed the ﬂow of citations and knowledge between these clusters. Additionally, several articles emerged as signiﬁcant “bridges,” connecting the clusters and facilitating the transfer of knowledge. These insights allow us to gain a better understanding of the disciplines and ﬁelds that are shaping the emergence of “safety of journalists” studies. The ﬁndings also highlight the importance of interdisciplinary exchange in shaping this ﬁeld. Lastly, we aim to make possible a further examination of the speciﬁc articles that serve as facil- itators in bridging knowledge between diﬀerent disciplines and clusters of articles. Three clusters stand out in terms of the number of articles and citations. First, the cluster “Cyberbullying and Adolescent Victimization” focuses on the examination of diﬀerent forms of bullying, victimization, and its impact on the mental and emotional health of adolescents. The most frequent words and bi-grams include “sexual harassment,” “mental health,” “fear crime,” and “routine activities,” among others, pointing to a broader concern for the eﬀects of victimization on individuals, particularly school-aged youth. The trigrams reinforce this emphasis by highlighting terms such as “high school students,” “middle school students,” “among college students,” and “among African American,” indicating a par- ticular interest in the study of bullying among diﬀerent demographics of young people. JOURNALISM STUDIES 827 Additionally, terms such as “General theory of crime,” “social learning theory,” and “structural equation modelling” suggest a focus on understanding the underlying theories and modeling approaches used to study these topics. The second cluster can be summarized as “Media and Political Communication” with a focus on the impact of news media, social media, and other forms of communication on public opinion, political participation, and human rights. It is of course no surprise that a cluster of media and communication related articles is by far the largest of the clusters. The cluster includes studies examining the eﬀects of media on attitudes, job satisfaction, and social support, as well as the role of media in shaping political communication, public sphere, and social movements. The research also investigates the impact of media coverage on social and political issues such as sexual harassment, foreign policy, and elections. The analysis includes both content analysis and comparative studies, and the use of various methodologies such as structural equation mod- eling, critical discourse analysis, and interpretive phenomenological analysis. The third cluster appears to focus on the theme of “Mental Health”. The bi-grams and tri- grams are related to topics such as posttraumatic stress disorder, stress disorder, health care, asylum seekers, systematic reviews, social support, labor market, mental disorders, health literacy, quality of life, political violence, primary care, psychological distress, qualitative research, risk factors, health status, mental health services, and more. The trigrams, speciﬁcally, delve into topics such as posttraumatic stress disorder among asylum seekers and refugees, mental health services for displaced persons, symptoms of stress disorder and depression, mental health problems among Syrian refugees, and randomized controlled trials for treating posttraumatic stress. Overall, this cluster highlights the importance of addressing mental health concerns in various populations and the role of various factors such as access to health care, social support, and political violence in aﬀecting mental health. In addition to the three dominant clusters, we identiﬁed a further six subclusters of articles. These subclusters have been given descriptive titles and are summarized below to provide an idea of the content contained within each. As will be clear from the descriptions below, some of the clusters are heavily inﬂuenced by the geographies of the studies selected for the special issue. Cluster 4: International Law and Human Rights. This cluster of sources revolves around topics regarding global legislation, human privileges, and legality in armed conﬂicts. It features col- locations of two or three words and references to journals, reports, and communiques, as well as terms such as “combating lawlessness,” “humanitarian law,” “minimum humanitarian stan- dards,” “legal framework,” and “war on terror. Cluster 5: Suicide Prevention. The focus of this cluster is suicide risk assessment and avoid- ance. Main areas of concern are suicide risk, suicide prevention, risk factors, suicidal behavior, suicide attempts, systematic review, and suicidal ideation. Cluster also underscores the signiﬁ- cance of mental health, personality disorder, and primary care in suicide prevention. Studies on suicide risk and prevention are typically conducted in the US and emphasize the require- ment for public health promotion and risk assessment. Cluster mentions randomized con- trolled trials and cohort studies in understanding suicide risk factors, especially in men. Dialectical behavior therapy, health behavior change, and suicide prevention programs are highlighted as important interventions. Cluster discusses the prevalence of suicide risk factors, depression and primary care relationship, interpersonal and psychological theories of suicide, and the role of deliberate self-harm in suicide prevention. Systematic reviews of adolescent suicidal behavior are also emphasized as necessary. Cluster 6: Turkish Cities and Globalization. This cluster of papers seems to be examining the theme of urban renewal and political struggles in the context of Turkish cities and globaliza- tion. The papers delve into the various aspects of urban transformation, citizenship, 828 EDITORIAL environmentalism, and politics of space in an urban context, focusing on the struggles of the poor, refugees, and social movements. Cluster 7: Childcare Policies in Post-Communist Europe. This cluster focuses on analysing childcare policies in post-communist Central European countries, particularly their impact on gender equality and the role of women in society. The papers examine the historical background and current state of welfare policies in countries such as Poland, Hungary, and Germany and how they have shifted towards a more liberal and business-oriented approach. Cluster 8: Family Policies and Gender Relations in Post-Communist Europe. The papers in this cluster examine family policies and childcare arrangements in post-communist Central Euro- pean countries and their impact on gender relations and work-life balance. The articles seem to be utilizing qualitative and comparative methods to gauge the generosity of policies and evaluate changes in care services. Cluster 9: Technology and Mental Health. The articles in this cluster examine the intersection of technology, mental health, and resilience. Topics explored include secondary traumatic stress among police oﬃcers, resilience training, randomized controlled trials, and the impact of virtual reality on mental health. The ﬁndings suggest the signiﬁcance of peer support, posi- tive psychological capital, and judicious design in technology aimed at promoting emotional well-being and resilience. Based on the articles of this special issue, the emergent ﬁeld of “Safety of Journalists” appears to be a multidisciplinary ﬁeld that involves the study of numer- ous issues related to journalists and the media. The most inﬂuential clusters of papers focus on three main themes: Media and Political Communication; Mental Health and Cyberbullying and Adolescent Victimization. These themes highlight the importance of addressing certain chal- lenges that journalists face as well as the impact that media can have on society, including mental health concerns, bullying and victimization, and political communication. The studies also suggest that there is a focus on understanding the underlying theories and methods used to study these topics (Figure 1). Figure 1. Visual representation of the Citation Network in which diﬀerent communities are high- lighted. The percentage of articles in each community is reported within brackets. Graph generated using Gephi [ JOURNALISM STUDIES 829 Betweenness - What makes Knowledge Flow between Clusters? Once we successfully built a Citation Network, we had the opportunity to extract, for each article, centrality metrics describing its importance in the network. Two of the most used metrics in the ﬁeld are “degree”, reﬂecting how many connections each nodes holds, and “betweenness”, representing the importance of a node in connecting the network together (Barrat et al. 2004; Borassi and Natale 2016; Jia et al. 2012). Of particular interest for our analysis is the “betweenness” since it holds a distinct connotation in comparison to other centrality metrics. Rather than merely reﬂecting the importance of a node in the network, betweenness characterizes a node’s signiﬁcance as a mediator of information or citation ﬂow between sep- arate clusters or communities of articles. This is quantiﬁed by counting the frequency with which the node appears in the shortest paths linking distinct groups of nodes. Nodes exhibiting a high betweenness score serve as critical conduits, allowing for the exchange of information between otherwise disparate com- munities (Barrat et al. 2004; Leydesdorﬀ2007). The analysis of betweenness in a citation network can provide a nuanced understanding of the network’s structure and dynamics, illuminating the relationships between disparate com- munities and the intermediating role of speciﬁc articles. While centrality gauges a node’s overall prominence, reﬂecting its many connections and the frequency of its citation by other nodes, betweenness is a metric which assesses a node’s function as a bridge or connector between disparate communities of articles. In our analysis, we elected to concentrate on betweenness rather than centrality because we wanted to understand the function of particular references in bridging the ﬂow of infor- mation or citations between diﬀerent research areas. By analysing betweenness, we sought to discern the nodes which played a crucial role in linking diﬀerent parts of the network and fostering the exchange of knowledge between these disparate communities. Top Articles on the Betweenness-list We found “Comparing Media Systems” to be the most important study in terms of between- ness-score (Hallin and Mancini 2004). This comes as no surprise, given the signiﬁcant impact the book has had on the ﬁeld of media and communication studies. Its contributions to research on media systems, media policy, and comparative media analysis are evident in the frequency with which it is referenced in these areas. Furthermore, the book’s theoretical framework has had a profound impact on shaping research in the ﬁeld and has facilitated a greater understanding of the complex relationship between media, politics, and society across diﬀerent countries. It is worth noting that the impact of “Comparing Media Systems” extends beyond media and communication studies. The ﬁndings of this investigation shows that the book has also played a pivotal role in disseminating theories and knowledge from media studies to other disciplines. The book “Comparing Media Systems” belongs to the largest cluster of references which we named “Media and Political Communication” above. Interestingly, the articles and books in the Media and Political Communication cluster with the highest betweenness-score must be divided into at least four diﬀerent groups. Three of the most important references (in terms of betweenness-score), are more general Media Analysis and Media Theory type of articles and books such as “Comparing Media Systems”, “An Emotional Turn in Journalism Studies?” and “The role of self-reports in the study of news production” (Hallin and Mancini 2004; Ryfe 2020; Wahl-Jorgensen 2020). However, a topically narrower group of references seems to be playing an even more important role in the ﬂow of knowledge between cluster in this 830 EDITORIAL system of references. This group includes titles such as “Not Funny? The Eﬀects of Factual Versus Sarcastic Journalistic Responses to Uncivil User Comments” (Ziegele and Jost 2020), “Engagement Moderation: What Journalists Should Say to Improve Online Discussions” (Masullo, Riedl, and Huang 2022), “Online Harassment and Its Implications for the Journal- ist–Audience Relationship” (Lewis, Zamith, and Coddington 2020), Mob Censorship: Online Harassment of US Journalists in Times of Digital Hate and Populism (Waisbord 2020) and “Roots of Incivility: How Personality, Media Use, and Online Experiences Shape Uncivil Partici- pation” (Frischlich et al. 2021). Keywords are journalism, incivility, and online harassment. It is not diﬃcult to understand why these two groups of references belong to the Media and Pol- itical Communication cluster. Perhaps more surprisingly, an article from Statistics examining how well certain criteria work when evaluating how well statistical models ﬁt observed data, is found to be among the top articles when it comes to betweenness-score in this cluster (Hu and Bentler 1999). The fact that this article is so much cited indicates the impor- tance of statistical methods for the development of the Media and Political Communication cluster. The inclusion of “Using thematic analysis in psychology in this cluster, despite its apparent divergence from the other articles, highlights the signiﬁcance of thematic analysis as a methodology that transcends disciplinary boundaries, and underscores its potential use- fulness in both psychological and media and communication studies research (Braun and Clarke 2006). The clustering and betweenness score analysis indicate that many general articles on media and communication studies are being cited in other ﬁelds and disciplines, suggesting a ﬂow of knowledge beyond the Media and Political Communication cluster. However, it is noteworthy that statistics and thematic analysis play a crucial role in this cluster. The emphasis on statistics and thematic analysis suggests the importance of both quantitative and qualitative approaches in media and communication research, and the need for interdisciplinary collab- orations to better understand the complex relationship between media, politics, and society. We also found a few references with hight betweenness-score in the other clusters. The second most important references (in terms of betweenness-score) in the whole reference network, is a proposal of a “social-ecological framework of theory, assessment, and prevention of suicide” (Cramer and Kapusta 2017). The article provides a comprehensive and integrated framework for understanding and addressing suicide risk that has been widely cited and used in research and practice, also among researchers of journalism. In this citation network, the article is part of the cluster we have earlier named “Cluster 5: Suicide Prevention” with suicide risk, suicide prevention, risk factors, suicidal behavior, suicide attempts, systematic review, and suicidal ideation as principal areas of concern. The social-ecological framework for understanding suicide risk takes a comprehensive and integrated approach, recognizing that suicide prevention eﬀorts should go beyond individual-level risk factors to also address com- munity and societal factors that contribute to suicide risk. The last article we will mention here, calls for an integrated, multi-system approach to address the unique needs of refugee women (Hawkins et al. 2021). It highlights the need for comprehensive synthesis regarding how individual, interpersonal, community, and organ- izational factors interact to inﬂuence the health of refugee women. This article plays a vital role in building knowledge in cluster 3 “Mental Health”. Our analysis found that articles on suicide prevention and refugee women’s mental health have high betweenness-score and play important roles in building knowledge in their respect- ive clusters. Such articles emphasize the need for a comprehensive and integrated approach that addresses individual, interpersonal, community, and societal factors in for example pre- venting suicide and improving mental health outcomes for refugee women. JOURNALISM STUDIES 831 Geographies of Researchers & Research Topics In this ﬁgure, we have plotted the results for the countries mentioned either in author aﬃliations or in titles. We are particularly interested in the countries represented by the dark red circles. This is the group of countries deemed by Reporters Without Borders to be in a very serious (dark red) condition when it comes to safety of journalists (Methodology Used for Compiling the World Press Freedom Index | RSF n.d.). In this study, we have utilized the safety index of Reporters Without Borders to rank countries according to the safety of journalists. Along with that, we have estimated the number of references that deal with issues related to speciﬁc countries by counting references that contain the country’s name in the title. Lastly, we have estimated the number of published authors from diﬀerent countries based on the university aﬃliations mentioned in the author aﬃliation ﬁelds of the references. Reporters Without Borders has been monitoring the safety of journalists globally since 2002, providing a safety index that ranks countries according to the safety and protection pro- vided to journalists (Index | RSF n.d.). The safety index considers a range of factors such as vio- lence against journalists, legal restrictions, and censorship, among others. This safety index serves as a useful tool to understand the safety of journalists in diﬀerent countries. Our analysis has revealed some noteworthy patterns that can be utilized to inform discus- sions on the safety of journalists. Our ﬁndings indicate that countries with a low ranking in the safety index of Reporters Without Borders have fewer published authors and references dealing with issues related to them. On the other hand, many countries that rank high in the safety index have a higher number of published authors and references. For instance, countries such as Norway, Sweden, Finland, and Denmark, which rank high in the safety index, have a relatively larger number of published authors and references dealing with 832 EDITORIAL issues related to them. In contrast, countries like Pakistan, Afghanistan, and Iraq, which rank low in the safety index, have fewer published authors and references. As we see, many of these countries are concentrated in the bottom left quadrant of the ﬁgure. Amongst the countries scoring low on the RSF safety index, China and Mexico stand out by the number of titles referring speciﬁcally to China or Mexico and the number of authors aﬃliated to Chinese or Mexican universities. We believe this is an indication of the rela- tive strength of the university system and research in general in these two countries. Afghani- stan, meanwhile, stands out as a country that have received signiﬁcant interest from researchers but with very few local authors cited in the network. Palestine, Vietnam, and Morocco are examples of countries that seem to have been little researched while at the same time very seldom are mentioned in the aﬃliations of the authors. This ﬁnding is signiﬁcant as it highlights the pressing need for increased attention to the safety of journalists and the protection of freedom of expression in countries where journalists face signiﬁcant challenges. However, the study has some limitations. Firstly, the safety index of Reporters Without Borders is not a comprehensive measure of the safety of journalists, and it does not account for all factors that can impact the safety of journalists. Secondly, our esti- mation of the number of published authors and references is based on a simpliﬁed approach, which may not accurately reﬂect the true number of authors or references. It is important to note that a large number of countries ranked by Reporters Without Borders for the safety of journalists are not included in the graph presented in this study. This is primarily because the graph is based on references that contain a country’s name in the title and authors’ aﬃliations that mention the country. As a result, countries that are not mentioned in the titles or do not have any author aﬃliations related to the country are not represented in the graph. This limitation is particularly concerning for some of the most dangerous countries for jour- nalists since they may not have enough published authors or references that meet the criteria for inclusion in the graph. The top 18 country ranked by safety score which are not represented in the graph above are reported in the table below. Country name CODE Safety Score Mentions in titles Mentions in aﬃliations Myanmar MMR 95,37 1 Not present Eritrea ERI 88,64 1 Not present Yemen YEM 88,46 1 Not present North Korea PRK 87,62 Not present Not present Syria SYR 86,61 Not present Not present Iran IRN 86,39 10 Not present Iraq IRQ 81,73 88 Not present Somalia SOM 81,73 8 Not present Belarus BLR 81,15 Not present Not present Dem. Rep. Congo COD 75,66 Not present Not present Nicaragua NIC 72,32 2 Not present Azerbaijan AZE 71,52 Not present Not present Bahrain BHR 70,35 5 Not present Venezuela VEN 68,78 Not present 1 Guatemala GTM 67,88 6 Not present Turkmenistan TKM 64,31 Not present Not present Libya LBY 63,42 3 Not present Rwanda RWA 61,24 19 Not present It is worth noting that the exclusion of a large number of countries from then graph is a reﬂection of the fact that the citation network was built upon a narrow group of articles dealing with speciﬁc topics and geographies. These topics and geographies often did not require the inclusion of references from the excluded countries. Consequently, the exclusion JOURNALISM STUDIES 833 of these countries may not necessarily indicate a lack of published authors or references dealing with issues related to them. Rather, it may be a result of the speciﬁc focus of the articles included in the citation network. It is important to consider this context when interpreting the ﬁndings presented in this study and to avoid generalizing the results to countries that we excluded from the graph. It is also worth noting that while the country Syria has no mentions in the titles, a number of articles in the network deals with issues related to “Syrian Refugees.” Knowledge Transfer? While this exploratory study has limitations, it provides insights into the relationship between the safety of journalists in individual countries and the number of aﬃliated authors and refer- ences dealing with that country. Our analysis indicates that there is a linear relationship between aﬃliations and the number of articles, as seen on a log to log scale. However, the line for relatively safe countries, those with a score below 60, appears to run parallel to but signiﬁcantly below the line for more unsafe countries, those with a score above 59. The ﬁndings suggest that studies focused on unsafe countries are more likely to be con- ducted by scholars based at universities in relatively safe countries, rather than the other way around. It indicates that much research about unsafe environments for journalists build on theories and methodologies developed in relatively safe localities and found useful for studies of journalists in those localities. While this may seem like an obvious observation, we believe that it is crucial to understand how knowledge ﬂows between distinct locations in order to improve the quality and impact of research in this area. By recognizing the asym- metrical distribution of research on the safety of journalists, we can identify potential biases 834 EDITORIAL and gaps in knowledge production. This understanding can help to inform eﬀorts to improve the quality and relevance of research, as well as to ensure that the perspectives and experi- ences of scholars from diverse locations are considered. Overall, the study highlights the importance of considering the geographic and institutional factors that shape knowledge pro- duction in the ﬁeld of journalism and related areas. By doing so, we can foster a more inclusive and robust research community that is better equipped to address the complex challenges facing journalists and freedom of expression globally. We believe this to be particularly important in relation to the topics and geographies coming out of this study as this universe of references draw extensively on studies dealing with Mental Health and Cyberbullying and Adolescent Victimization. We need to ask to what extent are theories and ﬁndings related to mental health issues stemming from studies in rela- tively safe locations such as the US or Northers Europe useful when trying to understand safety related issues in Afghanistan, Syria, Nicaragua or Iraq? Koch and Weingart suggest that the idea of knowledge transfer is a delusion because it assumes that knowledge is a tangible and transferable commodity that can be easily trans- mitted from one location to another (Koch and Weingart 2016). According to their perspective, this assumption overlooks the complex social, cultural, and institutional factors that shape the production and dissemination of knowledge in diﬀerent contexts. Instead, we propose that researchers of the safety of journalists should focus on the idea of knowledge co-construction, which recognizes that knowledge is a dynamic and socially con- structed process that involves the interaction and collaboration of diverse actors across diﬀerent locations and contexts. This perspective highlights the importance of recognizing and valuing the diverse perspectives, experiences, and knowledge systems that shape research and innovation in diﬀerent ﬁelds. Caveat It is vital to note that the selection of ﬁrst-level articles in a citation network analysis can sig- niﬁcantly aﬀect the results. In the present study, the ﬁrst articles were those published in this particular special issue. A diﬀerent set of articles would have resulted in a diﬀerent citation network. For a more comprehensive understanding of the emerging subﬁeld of journalist safety, a broader selection of articles should be considered in future projects. However, the present experiment provides a way to study the development of a ﬁeld or subﬁeld and to analyse its formation at an early stage. In this way, steps can be taken to ensure a diverse rep- resentation of topics, geographies, theories, and methodologies in the ﬁeld, thus promoting inclusiveness and progress. We recognize that the articles in this special issue may not be fully representative of the sub-ﬁeld of safety of journalists. Other relevant articles exist that address important topics and are not included here. Additionally, other scholars employ diﬀering methodologies and theories from those represented in this issue. Consequently, we are not claiming that the citation network presented is fully represen- tative of the sub-ﬁeld. However, this approach serves as a valuable tool for comprehending the theoretical and methodological foundations and historical origins of this special issue. Despite its experimental nature, we contend that this approach has the potential to provide insight into how ﬁelds emerge, and research develops. If nothing else, this method has allowed us to introduce the articles of this special issue in a productive and informative manner. Little has so far been written about the community of scholars studying and contributing to the increased knowledge base of the safety of journalists. Approaching the growing line of JOURNALISM STUDIES 835 academics and critical practitioners interested in the topic and their work as an emerging new academic ﬁeld, allows us as this article has illustrated, to consider both its prospects and chal- lenges in more thorough and analytical way. Note 1. (Henrichsen and Shelton 2022) was originally planned to be part of the special issue and has consequently been included in the reference network referred to in this introduction. References Barrat, A., M. Barthélemy, R. Pastor-Satorras, and A. Vespignani. 2004. “The Architecture of Complex Weighted Networks.” Proceedings of the National Academy of Sciences 101 (11): 3747–3752. doi:10.1073/pnas. 0400087101. Blondel, V. D., J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. 2008. “Fast Unfolding of Communities in Large Networks.” Journal of Statistical Mechanics: Theory and Experiment 2008 (10): 10008. doi:10.1088/1742- 5468/2008/10/P10008. Borassi, M., and E. Natale. 2016. KADABRA is an ADaptive Algorithm for Betweenness via Random Approximation [Application/pdf]. 18 pages. doi:10.4230/LIPICS.ESA.2016.20. Bourdieu, P., and R. Johnson. 1993. The Field of Cultural Production: Essays on Art and Literature. New York: Columbia University Press. Braun, V., and V. Clarke. 2006. “Using Thematic Analysis in Psychology.” Qualitative Research in Psychology 3 (2): 77–101. doi:10.1191/1478088706qp063oa. Cramer, R. J., and N. D. Kapusta. 2017. “A Social-Ecological Framework of Theory, Assessment, and Prevention of Suicide.” Frontiers in Psychology 8: 1756. doi:10.3389/fpsyg.2017.01756. Crossref. n.d. Crossref-commons: Crossref Commons (0.0.7) [Python; OS Independent]. Accessed March 3, 2023. Di Salvo, P. 2022. “Information Security and Journalism: Mapping a Nascent Research Field.” Sociology Compass 16: 3. doi:10.1111/soc4.12961. Frischlich, L., T. Schatto-Eckrodt, S. Boberg, and F. Wintterlin. 2021. “Roots of Incivility: How Personality, Media Use, and Online Experiences Shape Uncivil Participation.” Media and Communication 9 (1): 195–208. doi:10. 17645/mac.v9i1.3360. Garnham, N., and R. Williams. 1980. “Pierre Bourdieu and the Sociology of Culture: An Introduction.” Media, Culture & Society 2 (3): 209–233 Hallin, D. C., and P. Mancini. 2004. Comparing Media Systems: Three Models of Media and Politics. 1st ed. Cambridge University Press. doi:10.1017/CBO9780511790867. Hawkins, M. M., M. E. Schmitt, C. T. Adebayo, J. Weitzel, O. Olukotun, A. M. Christensen, A. M. Ruiz, et al. 2021. “Promoting the Health of Refugee Women: A Scoping Literature Review Incorporating the Social Ecological Model.” International Journal for Equity in Health 20 (1): 45. doi:10.1186/s12939-021-01387-5. Henrichsen, J. R., and M. Shelton. 2022. “Boundaries, Barriers, and Champions: Understanding Digital Security Education in US Journalism Programs.” Journalism Studies, 1–20. doi:10.1080/1461670X.2022.2148267. Hesmondhalgh, D. 2006. “Bourdieu, the Media and Cultural Production.” Media, Culture & Society 28 (2): 211–231. doi:10.1177/0163443706061682. Hu, L., and P. M. Bentler. 1999. “CutoﬀCriteria for Fit Indexes in Covariance Structure Analysis: Conventional Criteria Versus New Alternatives.” Structural Equation Modeling: A Multidisciplinary Journal 6 (1): 1–55. doi:10.1080/10705519909540118. Index | RSF. n.d. Accessed March 23, 2023. Jia, Y., V. Lu, J. Hoberock, M. Garland, and J. C. Hart. 2012. “Edge v. Node Parallelism for Graph Centrality Metrics.” In GPU Computing Gems Jade Edition, 15–28. Elsevier. doi:10.1016/B978-0-12-385963-1.00002-2. Koch, S., and P. Weingart. 2016. The Delusion of Knowledge Transfer: The Impact of Foreign aid Experts on Policy- making in South Africa and Tanzania. African Minds. Lewis, S. C., R. Zamith, and M. Coddington. 2020. “Online Harassment and Its Implications for the Journalist– Audience Relationship.” Digital Journalism 8 (8): 1047–1067. doi:10.1080/21670811.2020.1811743. Leydesdorﬀ, L. 2007. “Betweenness Centrality as an Indicator of the Interdisciplinarity of Scientiﬁc Journals.” Journal of the American Society for Information Science and Technology 58 (9): 1303–1319. doi:10.1002/asi. 20614. 836 EDITORIAL Masullo, G. M., M. J. Riedl, and Q. E. Huang. 2022. “Engagement Moderation: What Journalists Should Say to Improve Online Discussions.” Journalism Practice 16 (4): 738–754. doi:10.1080/17512786.2020.1808858. Methodology used for compiling the World Press Freedom Index | RSF. n.d. Accessed March 13, 2023. en/index-methodologie-2022. Pallath, A. n.d. Paperfetcher: Python Package to Mine Papers for Systematic Reviews. (1.2.0). Accessed March 3, 2023. Pallath, A., and Q. Zhang. 2022. “Paperfetcher : A Tool to Automate Handsearching and Citation Searching for Systematic Reviews.” Research Synthesis Methods, jrsm 1604. doi:10.1002/jrsm.1604. Prior, N. 2013. “Bourdieu and the Sociology of Music Consumption: A Critical Assessment of Recent Developments.” Sociology Compass 7 (3): 181–193. doi:10.1111/soc4.12020 Ryfe, D. M. 2020. “The Role of Self-reports in the Study of News Production.” Journalism 21 (3): 349–364. doi:10. 1177/1464884918800076. Wahl-Jorgensen, K. 2020. “An Emotional Turn in Journalism Studies?” Digital Journalism 8 (2): 175–194. doi:10. 1080/21670811.2019.1697626. Waisbord, S. 2020. “Mob Censorship: Online Harassment of US Journalists in Times of Digital Hate and Populism.” Digital Journalism 8 (8): 1030–1046. doi:10.1080/21670811.2020.1818111. Ziegele, M., and P. B. Jost. 2020. “Not Funny? The Eﬀects of Factual Versus Sarcastic Journalistic Responses to Uncivil User Comments.” Communication Research 47 (6): 891–920. doi:10.1177/0093650216671854. Roy Krøvel Department of Journalism and Media Studies, OsloMet – Oslo Metropolitan University, Oslo, Norway royk@oslomet.no Fabrizio Palumbo Department of Journalism and Media Studies, OsloMet – Oslo Metropolitan University, Oslo, Norway Kristin Skare Orgeret Department of Journalism and Media Studies, OsloMet – Oslo Metropolitan University, Oslo, Norway JOURNALISM STUDIES 837"
Optimized protocol for conditioned place avoidance learning in juvenile zebrafish,Fabrizio Palumbo and Bram Serneels and Emre Yaksi,2021,2.0,2,STAR Protocols,article,"Protocol
Optimized protocol for conditioned place
avoidance learning in juvenile zebraﬁsh
Conditioned place avoidance assays are broadly used in mammals to study different cognitive
aspects of operant learning. Here, we introduce a series of experimental designs for training
juvenile zebraﬁsh in short-term and long-term conditioned place avoidance assays. Our goal is to
promote standardization of animal handling procedures and setup conditions to improve animal
welfare and reproducibility while studying operant learning behaviors in juvenile zebraﬁsh.
Fabrizio Palumbo,
Bram Serneels, Emre
Yaksi
fabrizio.palumbo@ntnu.
no (F.P.)
emre.yaksi@ntnu.no (E.Y.)
Highlights
We describe juvenile
zebraﬁsh handling
procedures for
operant learning
behavior
We detail
experimental designs
for short- and long-
term learning
We introduce
potential pitfalls for
chemogenetic
ablation of neurons
We highlight the
importance of animal
welfare for successful
learning performance
Palumbo et al., STAR Protocols
2, 100465
June 18, 2021 ª 2021 The
Author(s).
https://doi.org/10.1016/
j.xpro.2021.100465
ll
OPEN ACCESS
 Protocol
Optimized protocol for conditioned place avoidance
learning in juvenile zebraﬁsh
Fabrizio Palumbo,1,2,* Bram Serneels,1,2 and Emre Yaksi1,3,*
1Kavli Institute for Systems Neuroscience and Centre for Neural Computation, Faculty of Medicine and Health Sciences,
Norwegian University of Science and Technology, 7030 Trondheim, Norway
2Technical contact
3Lead contact
*Correspondence: fabrizio.palumbo@ntnu.no (F.P.), emre.yaksi@ntnu.no (E.Y.)
https://doi.org/10.1016/j.xpro.2021.100465
SUMMARY
Conditioned place avoidance assays are broadly used in mammals to study
different cognitive aspects of operant learning. Here, we introduce a series of
experimental designs for training juvenile zebraﬁsh in short-term and long-
term conditioned place avoidance assays. Our goal is to promote standardization
of animal handling procedures and setup conditions to improve animal welfare
and reproducibility while studying operant learning behaviors in juvenile zebra-
ﬁsh.
For complete details on the use and execution of this protocol, please refer to
Palumbo et al. (2020).
BEFORE YOU BEGIN
Before describing all the steps of our behavioral experiments in detail we want to emphasize the
importance of proper and reproducible zebraﬁsh husbandry to ensure reproducibility of most
behavioral assays, including our conditioned place avoidance learning assay (Palumbo et al.,
2020) described in the following section.
Fish maintenance and husbandry
Note: The animal facilities and maintenance of the zebraﬁsh, Danio rerio, were approved by
the Norwegian Food Safety Authority.
1. Keep ﬁsh in 3.5-liter tanks in a Techniplast Zebtech Multilinking system at constant conditions:
a. Temperature=28C
b. pH=7
c. Water conductivity=600 mSiemens
d. Dark/light cycle=14:10 h light/dark cycle
e. Maximum animals per tank= 35; 10 animals per liter of water at adult stage
f.
Diet: dry food two times a day (SDS 100–400, dependent of age) and, after the 5th day of
development, also Artemia nauplii once a day (ZM Brine Shrimp Cysts Premium 250 Grade,
ZM Systems). We notice an increase in animal health and growth since we started feeding
them Artemia nauplii as soon as 5 days post fertilization.
Note: Variations from the above-mentioned parameters in ﬁsh husbandry will affect animal
welfare and stress level, and it might affect the outcome of the experiment.
STAR Protocols 2, 100465, June 18, 2021 ª 2021 The Author(s).
This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
1
ll
OPEN ACCESS
 Note: We recommend standardizing the breeding procedures to minimize experimental vari-
ability. We have optimized the following procedure.
2. Place animals for breeding before the evening feeding in subgroups of 5 to 10 ﬁsh.
3. On the following day, collect the eggs in a petri dish containing egg water, a solution of 0.1%
methylene blue in artiﬁcial ﬁsh water (AFW, 0.2 g/L instant ocean salt in reverse osmosis water
(RO)), and incubate at 28.5C.
4. Clean the Petri dish and exchange the egg water on a daily basis.
5. At the 5th day post fertilization screen the animals for positive expression of the transgenic ﬂuo-
rescent protein of interest.
6. Transfer the larvae zebraﬁsh to the zebraﬁsh facility into 0.7 L nursery nets installed in 3,5 L tanks
(see key resources table) until 3–4 weeks post fertilization. Pay attention to keep the number of
animal larvae around 100 per tank.
7. Keep the water ﬂow outside of the nursery net for the ﬁrst 7–10 days (from day 5 until day 15 post
fertilization). This will limit mechanical stress on the young animals, while ensuring a high rate of
water turnover surrounding the nursery nets.
Note: Putting the animal into nursery nets will provide them with a high exchange of fresh wa-
ter while keeping them in a conﬁned space and protected by the mechanical stress of the wa-
ter ﬂow.
Fish handling
Timing: 20 min
Stress and anxiety can severely impact animal behavior to a point of disrupting its learning capa-
bility. Therefore, caution in handling the animals is essential both before and during behavioral
testing. We therefore optimized a series of good practices to ensure we minimize animal stress
caused by experimenter handling. We recommend observing animal behavior during and after
any procedure is performed.
8.
Collect the zebraﬁsh, once the desired age is reached, from the zebraﬁsh facility in the same
morning of the planned experiments, after the morning feeding. We observed that the morning
feeding is particularly important for better welfare and successful learning performance. This will
prevent the animal from being food deprived over a long period of time since the last feeding
time would have been the previous evening.
9.
Use a 7 mL plastic pipette and cut the ﬁrst 5–8 mm of the pipette’s tip to increase its cross-sec-
tion. This reduces the mechanical stress on the animals while transferring them. Pay attention to
always pipette the animal from its front or its back and never from the side. The animal’s length is
greater than the pipette cross-section therefore, if pipetted from the side, animal body can bend
unnaturally.
10. Place the animals immediately in a 50 mL falcon tube containing AFW at around 28C. Cover the
falcon tube (any opaque material is ﬁne) during transportation and avoid any sudden movement
of the falcon tube to reduce animals’ stress. We recommend avoiding taking the stairs if
possible.
11. Once in the experimental area, transfer the ﬁsh immediately to a petri dish in AFW, at G 28C,
and place it in an incubator (G 28C). We recommend to always store a bottle of AFW in the
incubator to have available pre-warmed AFW and avoid any thermal shock for the animal.
Note: Further ﬁsh handling and monitoring during chemogenetic ablation and the behavior
experiment are described later in the step-by-step methods details.
ll
OPEN ACCESS
2
STAR Protocols 2, 100465, June 18, 2021
Protocol
 CRITICAL: It is crucial that the animals are never exposed to water colder than 25C to
ensure good health (see problem 1).
CRITICAL: Always wash the behavioral chamber before and after an experiment. Use RO
water ﬁrst and AFW later, to remove any olfactory trace.
CRITICAL: 3–4 weeks old zebraﬁsh are transitioning from larval to adult stage. During this
developmental stage ﬁsh size is a highly variable parameter. Hence, we recommend select-
ing animals of a similar size within the same age group (see problem 3). In our study the size
of 4 weeks old zebraﬁsh is in the range of 7G2 mm2 (Palumbo et al., 2020).
CRITICAL: As animals develop expression patterns of transgenic markers may change.
Larval zebraﬁsh usually display a broader unspeciﬁc expression of the Gal4:UAS construct,
which becomes more speciﬁc once the animal reach the juvenile/adult stage. Therefore, it
is a good practice to conﬁrm the transgenic expression patterns for chemogenetic abla-
tion once at larval stage and later at juvenile stage.
Note: Keep in mind that different genetic backgrounds/strains might lead to substantial dif-
ferences in animal behavior. It is important to design a control experiment in which you test for
the effect of the different transgenics strains. In our article we show that pigmentless nacre mu-
tants expressing Gcamp6s (Vladimirov et al., 2014) show no differences in CPA learning per-
formance, when compared to pigmented AB wildtype zebraﬁsh (https://www.ezrc.kit.edu/,
Cat# ZDB-GENO-960809-7).
KEY RESOURCE TABLE
REAGENT or RESOURCE
SOURCE
IDENTIFIER
Chemicals, peptides, and recombinant proteins
Metronidazole (MTZ)
Sigma-Aldrich
Cat#M1547
Dimethyl sulfoxide (DMSO)
Sigma-Aldrich
Cat#276855
Phosphate-buffered saline (PBS)
Thermo Fisher Scientiﬁc
Cat#BR0014G
Formaldehyde
Sigma-Aldrich
Cat#F8775
Bovine Serum Albumin Fraction V
AppliChem/Panreac
Cat#A1391.0100
LMP Agarose
Fisher Scientiﬁc
Cat# 16520100
MS222 (Tricaine methanesulfonate)
Sigma-Aldrich
Cat# E10521
Gibco Trypsin 2.5%
Thermo Fisher Scientiﬁc - Gibco
11538876
DAPI
Thermo Fisher Scientiﬁc
Cat#P36931
Goat serum
Sigma-Aldrich
Cat#G9023
Triton X-100
Merck
Cat#108643
Glycerol
Sigma-Aldrich
Cat# 1.04092
Critical commercial assays
In Situ Cell Death
Detection Kit, Fluorescein
Sigma - Roche
11684795910
Experimental models: organisms/strains
Tg(elavl3 :GCaMP6s)
Vladimirov et al., 2014
ZFIN Cat# ZDB-ALT-141023-1,
RRID:ZFIN_ZDB-ALT-141023-1
Tg(narp:GAL4VP16)
Agetsuma et al., 2010
ZFIN ID: ZDB-ALT-110215-5
Tg(UAS-E1b:NTR-mCherry)
Agetsuma et al., 2010
ZFIN ID: ZDB-ALT-070316-1
Wildtype zebraﬁsh
EZRC (https://www.ezrc.kit.edu/)
ZFIN Cat# ZDB-GENO-960809-7
Software and algorithms
Fiji/ImageJ
Schindelin et al., 2012
https://imagej.net/
Fiji.html#Downloads
MATLAB 2019b
https://se.mathworks.com/
N/A
(Continued on next page)
ll
OPEN ACCESS
STAR Protocols 2, 100465, June 18, 2021
3
Protocol
 STEP-BY-STEP METHOD DETAILS
Behavioral testing setup
Timing: varies, up to 1 week
1. Software. To implement the custom-made real-time tracking software (Kermen et al., 2020, Palumbo
et al., 2020) we use the OpenCV 3.0 library and the QtCreator5.2 developing platform. With this STAR
protocol, we publish the source code to implement the Object class ‘‘Tracker’’, which would allow you
to create instances of ‘‘trackers’’ and allocate each of them in a different thread, if you go for a multi-
threaded approach. The only step you will have to implement is the image collection from a camera of
your choice and send them to the object for processing. Once processed, the object ‘‘tracker’’ will
return the detected position of the animals together with its size. For further details see documenta-
tions for source code, header and instruction on how to implement it in your code: https://github.
com/fabrizio-palumbo/Conditioned-behaviour-in-juvenile-zebraﬁsh.
2. Implementation. We use a class of algorithm called ‘‘Adaptive Background Gaussian Mixture
Model for foreground segmentation’’ (KaewTraKulPong and Bowden, 2002, Lech et al., 2014, Ziv-
kovic, 2004, Power and Schoonees, 2002).
a. The principle behind this algorithm is the following: the intensity value of each pixel in the im-
age is modeled by an adaptive parametric mixture model of N, typically three or ﬁve, Gaussian
Continued
REAGENT or RESOURCE
SOURCE
IDENTIFIER
Open CV3.0
https://opencv.org/
opencv-3-0/
N/A
QtCreator5.2
https://www.qt.io/
https://doc.qt.io/qt-5/
gettingstarted.html#installing-qt
Deposited data
Custom scripts
https://github.com/fabrizio-
palumbo/Conditioned-
behaviour-in-juvenile-zebraﬁsh
N/A
Other
Confocal microscope (203
plan NA 0.8 objective)
Zeiss
Examiner Z1
Confocal microscope (203
plan NA 1.0, Plan-Apochromat)
Zeiss
Examiner Z1
Fish dry food
Sparos
ZEBRAFEED
Artemia nauplii – ZM Brine
Shrimp Cysts Premium 250 Grade
ZM Systems
N/A
Instant Ocean Salt
https://www.webzoo.net/
AS 1010006
Methylene blue
Sigma-Aldrich
M9140-25G
Plastic pipets
VWR
612-1681
ZebTEC nursery nets (bottom
pore size = 300 mm)
Scanbur
80-ZB300BTI
Falcon tubes 50 mL
VWR
525-0158 or 525-0610
Petri dishes
VWR
391-0440
Zebraﬁsh tank 3.5 L
Scanbur –
Tecniplast ZebTech
80ZB30TK
Gosselin Square Petri Dish,
1203120 mm, Corning
VWR
10799-777
GigE Vision camera
Allied Vision
Manta G-235B
Excalibur low-noise high-speed
precision operational ampliﬁers
Texas Instrument
TLE2142
Arduino Due
https://www.arduino.cc/
https://store.arduino.
cc/arduino-due
Tungsten wire
Sigma-Aldrich
267554-9.5G
Vortex
https://www.ika.com/
0003617000
Shaker (PMR-30
Mini Rocker-Shaker)
VWR
444-0341
ll
OPEN ACCESS
4
STAR Protocols 2, 100465, June 18, 2021
Protocol
 distributions (KaewTraKulPong and Bowden, 2002, Power and Schoonees, 2002). Once the
image has been modeled, the posterior probability is estimated, to deﬁne the current state
of the pixel: background or foreground (Power and Schoonees, 2002).
b. The implementation of this algorithm is described more in detail in Figure 1 and in attached
documentation,https://github.com/fabrizio-palumbo/
Conditioned-behaviour-in-juvenile-zebraﬁsh. Once the pixels corresponding to the juvenile
zebraﬁsh are identiﬁed their center of mass deﬁnes the animal’s coordinates in the arena (Fig-
ures 1A–1C). As a quality control of the detected ﬁsh, two criteria must be satisﬁed by the area
detected:
i. The size of the detected zebraﬁsh must be within a physiological range for the develop-
mental stage of the analyzed ﬁsh (1–2 week=2–4 mm2, 3–4 weeks= 4–10 mm2).
ii. The distance between the detected animal position in two consecutive frames must be
smaller than a threshold deﬁned by the physiological maximum velocity for the zebraﬁsh.
We use 3 cm displacement between two frames, corresponding to 66 ms, to avoid noise
detection from the distant borders of the arena.
c. The result of our tracking algorithm has proven to be very stable and reliable even in conditions of
weak contrast between the ﬁsh and the surrounding environment (Figures 1A–1C), compared to a
background subtraction algorithm in our assay. In our CPA training assay, image acquisition fre-
quency of 15 Hz was sufﬁcient to accurately track the ﬁsh without computationally overload the
software. An example two minutes’ pathway for one juvenile is shown in Figure 1D.
Figure 1. Image processing ﬂow chart to detect juvenile zebraﬁsh in low contrast images
(A) Pixels corresponding to the zebraﬁsh are detected by the tracking algorithm.
(B) Dilations and erosion operations are performed to reduce the noise in the background pixels.
(C) Coordinates of the biggest area detected, which match the animal size range deﬁned by the user, are extracted
and processed by the software.
(D) Example of two min raw trace of ﬁsh position superimposed on the raw image detected by the camera. Dashed
white lines shows 2 min of detected ﬁsh position, recorded at 15 frames per second.
ll
OPEN ACCESS
STAR Protocols 2, 100465, June 18, 2021
5
Protocol
 Alternative: The approach we follow to implement our behavioral software is only one of the
possible solutions. It is worth to mention the recent sotfware package, Stytra (https://github.
com/portugueslab/stytra), published by Portugues lab (Stih et al., 2019). This software pack-
age provides a platform which will allow the experimenter to perform many different behav-
ioral protocols, requiring little programming knowledge by the user thanks to a user-friendly
interface and documentation.
3. Hardware. To implement the behavioral setup there are speciﬁc design requirements that are
important to maximize animal welfare and minimize external inﬂuence during the experiment.
We implemented a setup design, shown in Figure 2, which fulﬁlls the following requirements:
a. Prevent light\sound contamination from the surrounding environment as good as possible.
b. Prevent visual contact between the animals in different chambers during the behavioral
testing.
c. The water temperature should be maintained constant and never below 25C/26C. We used
a heater in the room to buffer temperature ﬂuctuations.
d. Prevent any intervention by the experimenter during the entire protocol.
4. Behavioral arena. To construct the behavioral arena using standard components, we recommend
Gosselin square shaped Petri dishes (120 mm 3 120 mm 3 15.8 mm). The walls of each arena
were covered with standard white opaque electric tape to avoid any interaction between the
ﬁsh in neighboring chambers. This is particularly important, since the juvenile zebraﬁsh exhibit
social interactions (Dreosti et al., 2015, Tunbak et al., 2020, Groneberg et al., 2020, Hinz and
de Polavieja, 2017). Using these large petri dishes allows the animal to explore the arena freely
Figure 2. Schematic representation of the behavioral setup that is used for conditioned place avoidance
Six square shaped petri dishes are placed on an LCD screen that display speciﬁc visual patterns from the bottom. A
high-resolution camera, Manta 235B (Allied Vision) with a wide-angle objective, is used to acquire images of the
animals. A custom-made software is used to acquired and process the images in real time. Depending on the protocol
that is performed, the software communicates with an Arduino Due that controls 6 separate non-inverting ampliﬁer
Opamp circuit for delivering the mildly aversive electric stimulation only when animals are detected in the
conditioned zone. Each arena is equipped with two tungsten wires, covering the entire length of it two opposing
sides. Figure adapted with permission from (Palumbo et al., 2020)
ll
OPEN ACCESS
6
STAR Protocols 2, 100465, June 18, 2021
Protocol
 without any restrictions and increase the richness of the behavioral repertoire. These small details
play a crucial role on the resulting behavior since we are not constraining animal movement and
enhance ﬂexibility. Finally, using square shaped petri dishes allows easier implementation of the
electrodes for establishing a uniform electric ﬁeld.
5. Electrodes. We recommend the use of inert tungsten wire electrodes, 12 cm of length and
0.25 mm of diameter, for delivering mild aversive electric stimulation to the ﬁsh. We observed
that tungsten electrodes were better than silver electrodes which showed toxic effects in water.
However, tungsten wires exhibit fast decay in conductivity due to the accumulation of ions over
one of the electrodes, generating a coating layer within few seconds under constant voltage. To
avoid coating and establish constant current, we use 10 milliseconds long 1.2 mA current pulses
at 1.33 Hz repetition rate and alternate the polarity on the electrodes between conditioning ses-
sions. All these additional measures prevent oxidation of tungsten wires throughout 2–3 h long
behavioral training sessions. This allows us to reuse the same electrodes across experiments ex-
tending their lifetime indeﬁnitely (we have used the same electrodes for 4 years now and they still
work well). (See problem 2 for troubleshooting)
6. Electric stimulation circuit. To deliver mildly aversive electric stimuli separately to individual ﬁsh,
we used an Arduino Due based circuit. Arduino board received 3,3 V digital input from the
tracking software, when the zebraﬁsh is detected in the condition zone, during conditioning
period, and delivered 18 V (10 millisecond, 1.2 mA current at 1.33 Hz) to each ﬁsh separately.
For each ﬁsh, a separate integrated circuit was built and used, connecting an Operational-Ampli-
ﬁer (Opamp, TLE2142 EXCALIBUR low-noise high-speed precision, Texas Instrument) in a non-
inverted ampliﬁed conﬁguration. The Voltage at the output is given by the relation (see Figure 2):
Voltage output = Voltage input

1 + Resistance 2
Resistance 1

7. Visual stimuli presentation. Visual stimuli are presented to the ﬁsh form the bottom using a hor-
izontally positioned LCD monitor. The LCD monitor gives the ﬂexibility to change the visual stim-
uli, to control its timing, and to synchronize with other electronic systems.
a. We use a simple visual pattern dividing the arena half in red and half in gray colors. We match the
luminosity of colored illumination, when choosing the red and gray patterns marking different
compartment of the arena. This is important since zebraﬁsh respond differently to different illumi-
nation and ambient light levels (Spence and Smith, 2008, Avdesh et al., 2012, Oliveira et al., 2015,
Guggiana-Nilo and Engert, 2016, Cheng et al., 2017, Cheng et al., 2016).
Note: It is very important to keep the water in the behavioral chambers warm, which is crucial
especially for extended behavioral testing.
To ensure that the water in each behavioral arena never drops below 26C:
b. Measure the water temperature in each arena before and after performing a behavioral exper-
iment.
c. Perform the behavioral experiments in a heated room. We installed a passive heater element
in our behavioral room which helps to keep the room temperature around 26C over time.
8. Experimental design. When designing behavioral experiments, the ﬁrst rule you need to have in
mind is ‘‘minimize animals’ discomfort, while maximizing animal welfare and scientiﬁc rigor of the
experimental output.’’ To do so it is very important that you tune all the parameters of your behav-
ioral protocol with this goal in mind.
a. The stimulus design is a critical step when building a conditioned place avoidance task. We
chose the minimum stimulus intensity that elicits a brief escape response. We therefore
ll
OPEN ACCESS
STAR Protocols 2, 100465, June 18, 2021
7
Protocol
 recommend minimizing the intensity and the duration of the aversive electric stimuli to maxi-
mize animals’ welfare and consequently their performance.
b. The duration of each training and test session of the CPA protocol is another important param-
eter to optimize.
c. Additionally, we recommend verifying the CPA learning results by ﬂipping the color assign-
ment of the conditioned zone from red to gray, in separate CPA experiments.
d. We recommend our CPA protocols below.
Behavioral training
Timing: varies, 5h for steps 9–10, 4 days for step 11
9. Single day CPA training. For single day CPA training, we recommend the experimental design in
Figure 3. Also keep in mind:
a. Establish a long enough baseline session to ensure that the animals are relaxed and habitu-
ated to the environment, evenly exploring the arena without bias. We choose to have a base-
line session of 1 h. This will give you the opportunity to evaluate possible innate preference of
the animal for any of the arena parameters (location, pattern displayed, etc.). If a naı¨ve animal
displays a clear preference for speciﬁc compartment of the arena after a long baseline session,
it might be necessary to adjust the visual patterns to reduce such bias. We suggest to always
maintain a homogeneous luminosity all over the arena (Methods video S1).
b. Minimize the duration of the conditioning sessions, as much as possible. This will reduce the
discomfort of the animal, substantially. We recommend performing multiple short condition-
ing sessions, separated by test sessions.
c. Administrate the negative stimulus to the animal (1.2 mA for 10 ms at 1.33 Hz) every time the
animal enters the conditioned zone.
d. Terminate stimulus administration as soon as the animal exits the conditioned zone.
e. We recommend two 30 min conditioning sessions and two 30 min test sessions. Together with
a 1-h long baseline session, the experiment will last around 3 h, which has no negative impact
on animals’ health and welfare, as we show in our previous publication (Palumbo et al., 2020).
f.
We do not recommend protocols longer than 5 h (the longest duration we have tested). This
might have a negative impact on animals’ health since they will not be fed for a long time and
the water is not changed during the training.
Note: In our study (Palumbo et al., 2020), we do not observe freezing behavior or anxiety-like
phenotype in animal trained in 1 day protocols up to 5 h long. We therefore recommend to
keeping any behavioral protocol shorter than 5 h.
Note: We do recommend collecting the animal from the facility only when the behavioral pro-
tocol is ready to begin. This will allow the experimenter to transport the animal to the
Figure 3. Schematic description of the protocol recommended for one day training in juvenile zebraﬁsh
Baseline is 60 min long; conditioning and test sessions are 30 min long with no delay in between sessions. During the
conditioning session, mildly aversive electric stimuli are delivered at 1.33hz, every time the animal enters the conditioned zone
(red). We recommend verifying the CPA learning results by ﬁlliping the color assignment of the conditioned zone from red to
gray, in separate CPA experiments. Figure adapted with permission from (Palumbo et al., 2020).
ll
OPEN ACCESS
8
STAR Protocols 2, 100465, June 18, 2021
Protocol
 experimental area and to initiate the behavioral training immediately. This will minimize the
total time the animal is handled outside the facility.
10. Sham-training experiments. In our recent study focusing on CPA learning in juvenile zebraﬁsh (Pal-
umbo et al., 2020), we proposed a sham-training protocol to distinguish the effects of animals’ aver-
sive experience due to mildly aversive electric stimulation (US), from the CPA learning related adap-
tations of animal behavior, as described in Figure 4A. This sham training protocol decouples
animals’ spatial position in the arena from animals’ subjective experiences in response to the deliv-
ery of electric stimuli (US). This allows us to compare the behaviors of CPA trained animals with sham-
trained animals with same subjective experience of the US. To do so:
a. Assign, for each animal which undergoes a training session, a sibling animal as a sham-con-
trol. Animals will undergo the training session in couples, one trained and one sham-
trained.
b. The two arenas need to be identical. We also recommend alternating the arena used for
training with the arena used for sham-training, in different sessions. This will control for
any asymmetry in the arena of which the experimenter is not aware of.
Figure 4. Schematic description of the Sham experiment in juvenile zebraﬁsh
(A) Schematic description of the protocol recommended for one day training in juvenile zebraﬁsh. Baseline is 60 min
long; conditioning and test sessions are 30 min long with no delay in between sessions.
(B) Hardware conﬁguration of the behavioral setup to perform sham training. Each trained animal is coupled, via direct
hardwiring, to another animal which will be sham trained. During the conditioning session, mildly aversive electric
stimuli are delivered at 1.33hz to both animals simultaneously, every time the trained animal enters the conditioned
zone (red). We recommend verifying the CPA learning results by ﬁlliping the color assignment of the conditioned zone
from red to gray, in separate CPA experiments. Figure adapted with permission from (Palumbo et al., 2020).
ll
OPEN ACCESS
STAR Protocols 2, 100465, June 18, 2021
9
Protocol
 c. Connect both arenas to the same stimulation cable, the one controlled by the trained ﬁsh
(Figure 4B). Doing so, both animals will be exposed to the same stimulation, controlled
exclusively by the trained ﬁsh.
d. Perform a new series of sham-training experiment any time a new training protocol is imple-
mented.
11. Multi-day CPA training. In our recent study, we showed that long term training of juvenile zebra-
ﬁsh leads to better CPA learning performance and memory recall (Palumbo et al., 2020). Such
long-term training is best achieved by multiple training sessions spread over consecutive
days. This allows the animal to rest, feed and recover between training days. Training juvenile
zebraﬁsh over multiple days requires the experimenter to plan animal husbandry and handling
accordingly. For multi-day CPA training, we recommend the experimental design in Figure 5.
Also, keep in mind:
a. Minimize the amount of time for transferring animals between behavioral chambers and tem-
porary holding between training days. After the ﬁrst training day, we keep individual juvenile
zebraﬁsh in petri-dishes (90 mm radius) in a 28C incubator from the end of the behavioral
training (circa 5:00 pm) until the next day training session (circa 10:00 am) We feed the ﬁsh
before placing them in the incubator. The next morning, we refresh the water and we feed
the animals 30 min before the start of the new training session.
b. We recommend, before performing a 30 min recall session, to begin each additional day of
training with a 30 min habituation session without any visual pattern presented to the animal.
This will allow the animal to habituate to the behavioral arena without eliciting any memory
recall related to the training visual stimuli, since they are not displayed. The arena is illumi-
nated with light gray, of the same luminosity of the pattern used on day1, see Figure 5 for
a graphical representation.
c. We recommend concluding each training day with a conditioning session (but not a test ses-
sion), as it might help promote memory consolidation.
d. Wash each behavioral chamber thoroughly with RO water, before and after each training day.
Figure 5. Schematic description of the protocol recommended for multi-day training in juvenile zebraﬁsh
Baseline and blank sessions are 60 min long, recall, conditioning and test sessions are 30 min long with no delay in
between sessions. During the conditioning session, mildly aversive electric stimuli are delivered at 1.33hz, every time
the animal enters the conditioned zone (red). Each day is concluded with a conditioning session to avoid memory
extinction overnight. From day two, each protocol starts with a blank session during which the animals are habituated
to the arena without any pattern presented. Figure adapted with permission from (Palumbo et al., 2020).
ll
OPEN ACCESS
10
STAR Protocols 2, 100465, June 18, 2021
Protocol
 Behavioral analysis
Timing: varies, up to 15–30 min to adapt and run the codes we provide
For designing the analysis pipeline, we recommend using multiple complementary CPA learning
measures, some of which are also used in previous studies (Palumbo et al., 2020, Valente et al.,
2012, Millot et al., 2014, Yashina et al., 2019, Kermen et al., 2020). This approach allows quantiﬁca-
tion of animal behavior from different perspectives with different strengths and weaknesses.
12. We suggest quantifying the following parameters to assess CPA learning:
a. Average density of zebraﬁsh position in the CPA arena.
b. Relative time spent in the conditioned zone.
c. Relative swimming distance in the conditioned zone.
d. Animals’ distance from the boundary between safe and conditioned zones.
e. Conditioned Place Avoidance learning index (Palumbo et al., 2020).
f.
Swim direction near the boundary between safe and conditioned zone.
g. Avoidance of entry to conditioned zone, near the boundary between safe and conditioned
zones.
13. We suggest quantifying following parameters to assess animals state and health:
a. Swim velocity during the experiment.
b. Percentage of time that the zebraﬁsh exhibit no swimming (freezing), which we deﬁned as
less than 2 mm swimming for 2 s (adapted from (Agetsuma et al., 2010)).
c. Swim velocity, one second before (b) and after (a) the delivery of aversive unconditioned
stimuli (US).
Note: To see the implementation of these measures, please refer to the documentation in
https://github.com/fabrizio-palumbo/Conditioned-behaviour-in-juvenile-zebraﬁsh
and
in
our earlier study (Palumbo et al., 2020).
Note: In order to have a complete and complementary overview of animal health and perfor-
mance, we highlight the importance of using multiple metrics while evaluating animal
behavior.
Chemogenetic ablation of speciﬁc neural populations in zebraﬁsh brain
Timing: 44 h
This protocol describes the use of a transgenic zebraﬁsh line Tg(narp:GAL4VP16; UAS-E1b:NTR-
mCherry) to ablate dorsolateral habenula (dlHb) neurons. This transgenic line expresses Nitroreduc-
tase (NTR) fusion protein tagged by a mCherry speciﬁcally in dlHb (Agetsuma et al., 2010) (Methods
video S2). As shown before in adult zebraﬁsh (Agetsuma et al., 2010), bath application of Metroni-
dazole (MTZ) chemogenetically ablate NTR positive dlHb neurons in juvenile zebraﬁsh (Palumbo
et al., 2020).
14. Prepare MTZ solution
a. Needed: 50 mL tubes, petri dishes (50 mL), aluminum foil, microbalance, vortex, and shaker
(see key resources table), incubator (G 28C).
b. Prepare 50 mL [10 mM] MTZ solution in a 50 mL tube. Fill the 50 mL tube with AFW and add
DMSO, subsequently add the MTZ powder. Proportion is described in Table 1).
c. Given the photodegradable nature of the resulting MTZ solution, wrap the entire 50 mL tube,
once securely locked, into aluminum foil and make sure that no light comes into contact with
the solution. Pay particular attention to this step.
ll
OPEN ACCESS
STAR Protocols 2, 100465, June 18, 2021
11
Protocol
 CRITICAL: MTZ is photodegradable. Prepare a fresh batch of MTZ solution for each abla-
tion protocol. 2 3 50 mL is needed for treating control and experimental groups
simultaneously.
CRITICAL: We recommend leaving the animal for at least 12h (overnight) in ﬁsh water after
removing them from the MTZ bath to allow the MTZ to wash out. During this time,
frequently refresh the water in the petri dish and feed the animal.
CRITICAL: Perform the behavioral experiments as soon as the MTZ washout is completed,
before any neurogenesis that might occur over the course of the next few days.
CRITICAL: As control animals, we recommend using sibling zebraﬁsh that do not express
the UAS-E1b:NTR-mCherry transgene.
d. Shake by hand, vortex thoroughly, and leave the tube on a shaker for at least 30 min, allowing
the metronidazole to dissolve properly.
15. Chemogenetic ablation
a. Before you start treating the animals make sure you have:
i.
23 50 mL [10 mM] MTZ solution
ii. Aluminum foil
iii. Fish already in the experimental area and fed prior to the treatment.
iv. Incubator at G 28C.
v. 1 petri dish must contain at most 3 juvenile zebraﬁsh.
vi. Prepare the ﬁsh ready for the experiment. Make sure that the ﬁsh had access to food
before the start of the ablation protocol. Limit the number of ﬁsh (max 3) per dish, to avoid
mortality due to hypoxia or excessive ammonia. Make sure that the animals to be treated
are size matched.
b. Fill two petri dishes with 50 mL [10 mM] each, and make sure the temperature of the solution
is not lower than 26C
c. Transfer the zebraﬁsh, one at a time in the petri dishes with the MTZ solution, using a 7 mL
pipette. Make sure to cut the tip of the pipette, as described earlier. To prevent reduction
of MTZ concentration in the petri dish, transfer the ﬁsh in a small bubble of water.
CRITICAL: We observed that the lower MTZ concentrations (1 and 5 mM) did not yield
desired effects in juvenile zebraﬁsh. Moreover 10 mM MTZ solution did not elicit any
toxicity or alteration of animal behavior in control animals of nacre or Ab wild-type genetic
background.
d. Label the petri dish with necessary information (ﬁsh line, date, experimental group, experi-
menters initial, etc.)
e. Metronidazole is light-sensitive, therefore wrap the dish in aluminum foil. Exposure to light
can decrease effectiveness of the ablation and will turn the ﬁsh water brown/yellow.
f.
Label the aluminum foil again with the same info as in point 3.
g. Place the petri dishes in the incubator (G 28C).
Table 1. Speciﬁcs of the 10 mM MTZ solution
Component
Volume/Weight
Final concentration
Metronidazole (MTZ)
0.086 g
0.01 M [10 mM]
Dimethyl Sulfoxide (DMSO)
0.250 mL
0.5%
Artiﬁcial ﬁsh water (AFW, 0.2 g/L instant ocean salt in reverse osmosis
water (RO))
49.750 mL
N/A
Speciﬁcation about the chemicals can be found in the key resources table.
ll
OPEN ACCESS
12
STAR Protocols 2, 100465, June 18, 2021
Protocol
 Note: Be extra careful when moving the dish around since even small movements can be very
stressful for the animals.
h. Incubate for 24 h in MTZ.
Note: For these 24 h, the animal will be kept in darkness.
i.
After 24 h, transfer the ﬁsh to a new petri dish containing clean ﬁsh water. Make sure to
refresh the water twice in each petri dish in the ﬁrst few hours after the MTZ treatment.
j.
Incubate again (G 28C) for 12 h in AFW. Make sure to feed the animal before incubating.
k. The next morning make sure to refresh the ﬁsh water in each petri dish and feed the animal at
least 30 min before the start of the behavioral protocol.
l.
The ﬁsh are now ready for the behavior protocol. Ideally start between 9 and 12 am, to keep
consistency for the timing of the experiments, and animals’ circadian rhythm.
16. Validation of chemogenetic ablation (Timing: 16 h)
To verify successful chemogenetic ablation of neurons we recommend TUNEL assay (Agetsuma
et al., 2010). The protocol was adapted from the manufacturer’s protocol (In Situ Cell Death
Detection Kit, Fluorescein, 11684795910 Roche) and optimized for whole mount labeling and
confocal imaging (Methods video S3).
a. Euthanize ﬁsh in ice cold water and ﬁx it in cooled 4% PFA in 0.25% PBTx (0.25% Triton X-100
in 13 PBS) for 12 h at 4C.
b. Permeabilizesamplesin0.050%Trypsin-EDTAonicefor40minandwash3timeswith0.25%PBTx.
c. Incubate the samples in 50mL TUNEL reaction mix for 1 h at 37C humidiﬁed atmosphere, in a
water bath covered by aluminum foil the dark. Subsequently wash it in 0.25% PBTx.
d. Place the samples on microscopy slides after washing steps in increasing glycerol concentra-
tion of 25%, 50%, and 75%. Then, use 75% Glycerol as a medium for mounting the samples
on glass slides for confocal imaging (see problems 4 and 5).
e. The TUNEL assay is based on detection of apoptotic cells. Apoptosis is a form of pro-
grammed cell death and can be affected by numerous factors (e.g., uptake of the drug, pas-
sage through the blood brain barrier, concentration, etc.). To visualize the ablated cells at
different apoptotic stages, we performed TUNEL assay at 16 h (Figure 6A and 6C) and
24 h (Figure 6B) after the start of the MTZ treatment. While apoptotic cells are clearly visible
in 16 h after chemogenetic ablation, 24 h after the ablation apoptotic fragments are less de-
tectible with TUNEL assay (Figure 6B).
Note: Zebraﬁsh brain have exceptional regenerative capacity (Celikkaya et al., 2019; Kizil,
2018; Cosacak et al., 2019; Lange et al., 2020; Kesavan et al., 2020; Schwarzer et al., 2020).
Therefore, we recommend that the behavioral testing is done no longer than 2 days after
the chemogenetic ablation, otherwise neuroregeneration may affect subsequent experi-
ments. We observed addition of new habenular neurons in juvenile zebraﬁsh, already
2 days after chemogenetic ablation (Figure 7; Methods video S4).
Note: Health monitoring. In the rare cases, if we observe that a ﬁsh has abnormal swim or no
movement, we euthanized these animals and did not perform any behavioral study
EXPECTED OUTCOMES
Once the conditioned protocol has been performed, following all the instruction described above,
the behavioral phenotype of the animal will replicate the one we describe in our previous publication
(Palumbo et al., 2020).
Most importantly, the animal will not show any 1) Freezing behavior, 2) Erratic swimming, or 3)
Thigmotaxis.
ll
OPEN ACCESS
STAR Protocols 2, 100465, June 18, 2021
13
Protocol
 The animal will spend most of his time in the safe zone of the arena once the training session is
completed.
For more details, in our publication (Palumbo et al., 2020) we provide several analysis of animal
behavior over the course of the behavioral training.
LIMITATIONS
We only detect the animal’s ‘‘center of mass’’ to obtain its position. We did not detect/analyzed an-
imal posture or animal swim pattern.
In our setup we did not implement a conditioned place learning protocol based on reward. This chal-
lenging task will require development of repeated and robust reward delivery systems that require
further design.
Implementing more computational power and higher spatiotemporal resolution of video monitoring
would lead to better image quality for posture estimation and allow the processing of larger number
of zebraﬁsh in parallel.
Figure 7. Regeneration of new neurons 48 h after chemogenetic ablation with metrodiniazole
Confocal microscopy image of three weeks old Tg(narp:Gal4;UAS-E1b:NTR-mCherry) zebraﬁsh, 48h after Metrodiniazole treatement. The new-born
neurons that are marked with white arrows are already integrating into developing habenula. Scale bar is 50 mm.
Figure 6. TUNEL assay for detecting apoptosis after chemogenetic ablation with metrodiniazole
(A–C)Confocal microscopy images of three weeks old Tg(narp:Gal4;UAS-E1b:NTR-mCherry) zebraﬁsh 16 h (A) and
24 h (B) after the start of Metronidazole (MTZ) treatement. Green ﬂuorescent labels TUNEL signal which is a direct
measure of cell death (apoptosis). Note that green TUNEL signal is not visible in control animals (C). Scale bar is 50 mm.
ll
OPEN ACCESS
14
STAR Protocols 2, 100465, June 18, 2021
Protocol
 TROUBLESHOOTING
Problem 1
During the baseline session, the animal shows reduced swimming behavior, with a high freezing time
(step 9–11).
Potential solution
Control the water temperature in the behavioral arena, it is likely too cold for the animal. Addition-
ally, make sure that the animal is fed before it is transported (always using warm water) to the exper-
imental area. Heating up the room in which you perform the behavioral training can also contribute
to maintain the right water temperature.
See Methods video S1 for an example of animal baseline behavior.
Problem 2
The animal does not respond to the electric stimulation during the conditioned sessions (step 5–11).
Potential solution
As a ﬁrst approach always make sure that all the hardware is properly connected and secured (no
loose wires around). Moreover, be sure of alternating cathode and anode across conditioning ses-
sions to avoid electrode passivation.
If none of the above solves the problem, then it is likely that the stimulus amplitude is the problem:
too low amplitude will not elicit any response from the animal, while a too strong stimulus will elicit at
ﬁrst a strong animal reaction, but it will quickly lead to a helplessness behavior. Therefore, pay close
attention to see in which of these two conditions you ﬁnd yourself and adjust the stimulus amplitude
accordingly.
Problem 3
The animal used for experiments at 3-week post fertilization is small in size compared to previous
experiments (step 9–11).
Potential solution
This is probably due to crowded nursery tank in the ﬁsh facility together with a non-appropriate
feeding routine. We do recommend keeping no more than 25 larvae per liter of water and feeding
them twice a day with dry food (morning and evening) and once with Artemia naplii (around 13:00)
(see key resources table). Keeping the waterﬂow outside the nursery net also improve animal growth
and health.
Problem 4
The ﬂuorescent signal of the whole mount TUNEL staining decreases with the imaging depth (step
16).
Potential solution
When dissecting the brain remove the skin and dura on top of the brain. This allows a better pene-
tration of the antibodies into the brain. Additionally, when imaging, make sure that the cover slip is
right on top of the brain, as close as possible. Pay attention however not to squeeze the brain.
Problem 5
The sample is not stable during the imaging process (step 16).
ll
OPEN ACCESS
STAR Protocols 2, 100465, June 18, 2021
15
Protocol
 Potential solution
We recommend using a 4% gelatin - 65% glycerol solution as mounting medium. It improves the sta-
bility of the sample, since it has better mechanical properties at room temperature (20C G 2C) than
75% glycerol, which remains viscous.
RESOURCE AVAILABILITY
Lead contact
Further information and requests for resources and reagents should be directed to and will be ful-
ﬁlled by the lead contact, Emre Yaksi (emre.yaksi@ntnu.no)
Materials availability
This study did not generate any new unique reagent
Data and code availability
All custom scripts described in this article are available at:
https://github.com/fabrizio-palumbo/Conditioned-behaviour-in-juvenile-zebraﬁsh
SUPPLEMENTAL INFORMATION
Supplemental information can be found online at https://doi.org/10.1016/j.xpro.2021.100465.
ACKNOWLEDGMENTS
We thank Hitoshi Okamoto, Misha Ahrens (for transgenic lines), Siv Eggen, Vy Nguyen, Andreas Ny-
gard (for technical assistance), and all Yaksi lab members (for stimulating discussions). This work was
funded by ERC grant 335561 (F.P. and E.Y.), RCN FRIPRO grant 314212 (E.Y.), Kavli Foundation, and
NTNU.
AUTHOR CONTRIBUTIONS
Conceptualization, F.P. and E.Y.; methodology and data, F.P. and B.S.; codes repository, F.P.; data
analysis, F.P.; investigation, all authors; writing, F.P. and E.Y.; review & editing, all authors; funding
acquisition and supervision, E.Y.
DECLARATION OF INTERESTS
The authors declare no competing interests.
REFERENCES
Agetsuma, M., Aizawa, H., Aoki, T., Nakayama, R.,
Takahoko, M., Goto, M., Sassa, T., Amo, R., Shiraki,
T., Kawakami, K., et al. (2010). The habenula is crucial
for experience-dependent modiﬁcation of fear
responsesinzebraﬁsh.Nat. Neurosci.13, 1354–1356.
Avdesh, A., Martin-Iverson, M.T., Mondal, A., Chen,
M., Askraba, S., Morgan, N., Lardelli, M., Groth,
D.M., Verdile, G., and Martins, R.N. (2012).
Evaluation of color preference in zebraﬁsh for
learning and memory. J. Alzheimer’s Dis. 28,
459–469.
Celikkaya, H., Cosacak, M.I., Papadimitriou, C.,
Popova, S., Bhattarai, P., Biswas, S.N., Siddiqui, T.,
Wistorf, S., Nevado-Alcalde, I., Naumann, L., et al.
(2019). GATA3 promotes the neural progenitor
state but not neurogenesis in 3D traumatic injury
model of primary human cortical astrocytes. Front.
Cell. Neurosci. 13, 23.
Cheng, R.-K., Krishnan, S., Lin, Q., Kibat, C., and
Jesuthasan, S. (2017). Characterization of a
thalamic nucleus mediating habenula responses to
changes in ambient illumination. BMC Biol. 15, 104.
Cheng, R.K., Krishnan, S., and Jesuthasan, S. (2016).
Activation and inhibition of tph2 serotonergic
neurons operate in tandem to inﬂuence larval
zebraﬁsh preference for light over darkness. Sci.
Rep. 6, 20788.
Cosacak, M.I., Bhattarai, P., Reinhardt, S., Petzold,
A., Dahl, A., Zhang, Y., and Kizil, C. (2019). Single-
cell transcriptomics analyses of neural stem cell
heterogeneity and contextual plasticity in a
zebraﬁsh brain model of amyloid toxicity. Cell Rep.
27, 1307–1318.e3.
Dreosti, E., Lopes, G., Kampff, A.R., and Wilson,
S.W. (2015). Development of social behavior in
young zebraﬁsh. Front. Neural Circuits 9, 39.
Groneberg, A.H., Marques, J.C., Martins, A.L., Diez
Del Corral, R., De Polavieja, G.G., and Orger, M.B.
(2020). Early-life social experience shapes social
avoidance reactions in larval zebraﬁsh. Curr. Biol
30, 4009–4021.e4.
Guggiana-Nilo, D.A., and Engert, F. (2016).
Properties of the visible light phototaxis and UV
avoidance behaviors in the larval zebraﬁsh. Front.
Behav. Neurosci. 10, 160.
Hinz, R.C., and De Polavieja, G.G. (2017). Ontogeny
of collective behavior reveals a simple attraction
rule. Proc. Natl. Acad. Sci. U S A 114, 2295–2300.
Kaewtrakulpong, P., and Bowden, R. (2002). An
improved adaptive background mixture model for
real-time tracking with shadow detection. In Video-
Based Surveillance Systems: Computer Vision and
Distributed Processing, P. Remagnino, G.A. Jones,
N. Paragios, and C.S. RegazzonI, eds. (Springer
US).
Kermen, F., Darnet, L., Wiest, C., Palumbo, F.,
Bechert, J., Uslu, O., and Yaksi, E. (2020). Stimulus-
speciﬁc behavioral responses of zebraﬁsh to a large
ll
OPEN ACCESS
16
STAR Protocols 2, 100465, June 18, 2021
Protocol
 range of odors exhibit individual variability. BMC
Biol. 18, 66.
Kesavan, G., Machate, A., Hans, S., and Brand, M.
(2020). Cell-fate plasticity, adhesion and cell sorting
complementarily establish a sharp midbrain-
hindbrain boundary. Development 147,
dev186882.
Kizil, C. (2018). Mechanisms of pathology-induced
neural stem cell plasticity and neural regeneration
in adult zebraﬁsh brain. Curr. Pathobiol. Rep. 6,
71–77.
Lange, C., Rost, F., Machate, A., Reinhardt, S.,
Lesche, M., Weber, A., Kuscha, V., Dahl, A.,
Rulands, S., and Brand, M. (2020). Single cell
sequencing of radial glia progeny reveals the
diversity of newborn neurons in the adult zebraﬁsh
brain. Development 147, dev185595.
Lech, M., Dalka, P., Szwoch, G., and Czy_zewski, A.
(2014). Examining quality of hand segmentation
based on gaussian mixture models. In Multimedia
Communications, Services and Security: 7th
International Conference, MCSS 2014, Krakow,
Poland, June 11-12, 2014. Proceedings, A. Dziech
and A. Czy_zewski, eds. (Springer International
Publishing).
Millot, S., Cerqueira, M., Castanheira, M.F., Øverli,
Ø., Martins, C.I.M., and Oliveira, R.F. (2014). Use of
conditioned place preference/avoidance tests to
assess affective states in ﬁsh. Appl. Anim. Behav.
Sci. 154, 104–111.
Oliveira, J., Silveira, M., Chacon, D., and Luchiari, A.
(2015). The zebraﬁsh world of colors and shapes:
preference and discrimination. Zebraﬁsh 12,
166–173.
Palumbo, F., Serneels, B., Pelgrims, R., and Yaksi, E.
(2020). The zebraﬁsh dorsolateral habenula is
required for updating learned behaviors. Cell Rep.
32, 108054.
Power, P.W., and Schoonees, J.A. (2002).
Understanding background mixture models for
foreground segmentation. In Proceedings of
Image and Vision Computing New Zealand
(IVCNZ), pp. 266–271.
Schindelin, J., Arganda-Carreras, I., Frise, E.,
Kaynig, V., Longair, M., Pietzsch, T., Preibisch, S.,
Rueden, C., Saalfeld, S., Schmid, B., et al. (2012).
Fiji: an open-source platform for biological-image
analysis. Nat. Methods 9, 676–682.
Schwarzer, S., Asokan, N., Bludau, O., Chae, J.,
Kuscha, V., Kaslin, J., and Hans, S. (2020).
Neurogenesis in the inner ear: the zebraﬁsh
statoacoustic ganglion provides new neurons
from a Neurod/Nestin-positive progenitor pool
well into adulthood. Development 147,
dev176750.
Spence, R., and Smith, C. (2008). Innate and learned
colour preference in the Zebraﬁsh, Danio rerio.
Ethology 114, 582–588.
Stih, V., Petrucco, L., Kist, A.M., and Portugues, R.
(2019). Stytra: An open-source, integrated system
for stimulation, tracking and closed-loop
behavioral experiments. PLoS Comput. Biol. 15,
e1006699.
Tunbak, H., Vazquez-Prada, M., Ryan, T.M., Kampff,
A.R., and Dreosti, E. (2020). Whole-brain mapping
of socially isolated zebraﬁsh reveals that lonely ﬁsh
are not loners. Elife 9, e55863.
Valente, A., Huang, K.H., Portugues, R., and Engert,
F. (2012). Ontogeny of classical and operant
learning behaviors in zebraﬁsh. Learn. Mem. 19,
170–177.
Vladimirov, N., Mu, Y., Kawashima, T., Bennett,
D.V., Yang, C.T., Looger, L.L., Keller, P.J., Freeman,
J., and Ahrens, M.B. (2014). Light-sheet functional
imaging in ﬁctively behaving zebraﬁsh. Nat.
Methods 11, 883–884.
Yashina, K., Tejero-Cantero, A´ ., Herz, A., and Baier,
H. (2019). Zebraﬁsh exploit visual cues and
geometric relationships to form a spatial memory.
iScience 19, 119–134.
Zivkovic, Z. (2004). Improved adaptive gaussian
mixture model for background subtraction. In
Proceedings of the Pattern Recognition,
17th International Conference on (ICPR’04)
Volume 2 - Volume 02 (IEEE Computer
Society).
ll
OPEN ACCESS
STAR Protocols 2, 100465, June 18, 2021
17
Protocol
",https://doi.org/10.1016/j.xpro.2021.100465,doc4,"Protocol Optimized protocol for conditioned place avoidance learning in juvenile zebraﬁsh Conditioned place avoidance assays are broadly used in mammals to study different cognitive aspects of operant learning. Here, we introduce a series of experimental designs for training juvenile zebraﬁsh in short-term and long-term conditioned place avoidance assays. Our goal is to promote standardization of animal handling procedures and setup conditions to improve animal welfare and reproducibility while studying operant learning behaviors in juvenile zebraﬁsh. Fabrizio Palumbo, Bram Serneels, Emre Yaksi fabrizio.palumbo@ntnu. no (F.P.) emre.yaksi@ntnu.no (E.Y.) Highlights We describe juvenile zebraﬁsh handling procedures for operant learning behavior We detail experimental designs for short- and long- term learning We introduce potential pitfalls for chemogenetic ablation of neurons We highlight the importance of animal welfare for successful learning performance Palumbo et al., STAR Protocols 2, 100465 June 18, 2021 ª 2021 The Author(s). j.xpro.2021.100465 ll OPEN ACCESS Protocol Optimized protocol for conditioned place avoidance learning in juvenile zebraﬁsh Fabrizio Palumbo,1,2,* Bram Serneels,1,2 and Emre Yaksi1,3,* 1Kavli Institute for Systems Neuroscience and Centre for Neural Computation, Faculty of Medicine and Health Sciences, Norwegian University of Science and Technology, 7030 Trondheim, Norway 2Technical contact 3Lead contact *Correspondence: fabrizio.palumbo@ntnu.no (F.P.), emre.yaksi@ntnu.no (E.Y.) SUMMARY Conditioned place avoidance assays are broadly used in mammals to study different cognitive aspects of operant learning. Here, we introduce a series of experimental designs for training juvenile zebraﬁsh in short-term and long- term conditioned place avoidance assays. Our goal is to promote standardization of animal handling procedures and setup conditions to improve animal welfare and reproducibility while studying operant learning behaviors in juvenile zebra- ﬁsh. For complete details on the use and execution of this protocol, please refer to Palumbo et al. (2020). BEFORE YOU BEGIN Before describing all the steps of our behavioral experiments in detail we want to emphasize the importance of proper and reproducible zebraﬁsh husbandry to ensure reproducibility of most behavioral assays, including our conditioned place avoidance learning assay (Palumbo et al., 2020) described in the following section. Fish maintenance and husbandry Note: The animal facilities and maintenance of the zebraﬁsh, Danio rerio, were approved by the Norwegian Food Safety Authority. 1. Keep ﬁsh in 3.5-liter tanks in a Techniplast Zebtech Multilinking system at constant conditions: a. Temperature=28C b. pH=7 c. Water conductivity=600 mSiemens d. Dark/light cycle=14:10 h light/dark cycle e. Maximum animals per tank= 35; 10 animals per liter of water at adult stage f. Diet: dry food two times a day (SDS 100–400, dependent of age) and, after the 5th day of development, also Artemia nauplii once a day (ZM Brine Shrimp Cysts Premium 250 Grade, ZM Systems). We notice an increase in animal health and growth since we started feeding them Artemia nauplii as soon as 5 days post fertilization. Note: Variations from the above-mentioned parameters in ﬁsh husbandry will affect animal welfare and stress level, and it might affect the outcome of the experiment. STAR Protocols 2, 100465, June 18, 2021 ª 2021 The Author(s). This is an open access article under the CC BY-NC-ND license ( 1 ll OPEN ACCESS Note: We recommend standardizing the breeding procedures to minimize experimental vari- ability. We have optimized the following procedure. 2. Place animals for breeding before the evening feeding in subgroups of 5 to 10 ﬁsh. 3. On the following day, collect the eggs in a petri dish containing egg water, a solution of 0.1% methylene blue in artiﬁcial ﬁsh water (AFW, 0.2 g/L instant ocean salt in reverse osmosis water (RO)), and incubate at 28.5C. 4. Clean the Petri dish and exchange the egg water on a daily basis. 5. At the 5th day post fertilization screen the animals for positive expression of the transgenic ﬂuo- rescent protein of interest. 6. Transfer the larvae zebraﬁsh to the zebraﬁsh facility into 0.7 L nursery nets installed in 3,5 L tanks (see key resources table) until 3–4 weeks post fertilization. Pay attention to keep the number of animal larvae around 100 per tank. 7. Keep the water ﬂow outside of the nursery net for the ﬁrst 7–10 days (from day 5 until day 15 post fertilization). This will limit mechanical stress on the young animals, while ensuring a high rate of water turnover surrounding the nursery nets. Note: Putting the animal into nursery nets will provide them with a high exchange of fresh wa- ter while keeping them in a conﬁned space and protected by the mechanical stress of the wa- ter ﬂow. Fish handling Timing: 20 min Stress and anxiety can severely impact animal behavior to a point of disrupting its learning capa- bility. Therefore, caution in handling the animals is essential both before and during behavioral testing. We therefore optimized a series of good practices to ensure we minimize animal stress caused by experimenter handling. We recommend observing animal behavior during and after any procedure is performed. 8. Collect the zebraﬁsh, once the desired age is reached, from the zebraﬁsh facility in the same morning of the planned experiments, after the morning feeding. We observed that the morning feeding is particularly important for better welfare and successful learning performance. This will prevent the animal from being food deprived over a long period of time since the last feeding time would have been the previous evening. 9. Use a 7 mL plastic pipette and cut the ﬁrst 5–8 mm of the pipette’s tip to increase its cross-sec- tion. This reduces the mechanical stress on the animals while transferring them. Pay attention to always pipette the animal from its front or its back and never from the side. The animal’s length is greater than the pipette cross-section therefore, if pipetted from the side, animal body can bend unnaturally. 10. Place the animals immediately in a 50 mL falcon tube containing AFW at around 28C. Cover the falcon tube (any opaque material is ﬁne) during transportation and avoid any sudden movement of the falcon tube to reduce animals’ stress. We recommend avoiding taking the stairs if possible. 11. Once in the experimental area, transfer the ﬁsh immediately to a petri dish in AFW, at G 28C, and place it in an incubator (G 28C). We recommend to always store a bottle of AFW in the incubator to have available pre-warmed AFW and avoid any thermal shock for the animal. Note: Further ﬁsh handling and monitoring during chemogenetic ablation and the behavior experiment are described later in the step-by-step methods details. ll OPEN ACCESS 2 STAR Protocols 2, 100465, June 18, 2021 Protocol CRITICAL: It is crucial that the animals are never exposed to water colder than 25C to ensure good health (see problem 1). CRITICAL: Always wash the behavioral chamber before and after an experiment. Use RO water ﬁrst and AFW later, to remove any olfactory trace. CRITICAL: 3–4 weeks old zebraﬁsh are transitioning from larval to adult stage. During this developmental stage ﬁsh size is a highly variable parameter. Hence, we recommend select- ing animals of a similar size within the same age group (see problem 3). In our study the size of 4 weeks old zebraﬁsh is in the range of 7G2 mm2 (Palumbo et al., 2020). CRITICAL: As animals develop expression patterns of transgenic markers may change. Larval zebraﬁsh usually display a broader unspeciﬁc expression of the Gal4:UAS construct, which becomes more speciﬁc once the animal reach the juvenile/adult stage. Therefore, it is a good practice to conﬁrm the transgenic expression patterns for chemogenetic abla- tion once at larval stage and later at juvenile stage. Note: Keep in mind that different genetic backgrounds/strains might lead to substantial dif- ferences in animal behavior. It is important to design a control experiment in which you test for the effect of the different transgenics strains. In our article we show that pigmentless nacre mu- tants expressing Gcamp6s (Vladimirov et al., 2014) show no differences in CPA learning per- formance, when compared to pigmented AB wildtype zebraﬁsh ( Cat# ZDB-GENO-960809-7). KEY RESOURCE TABLE REAGENT or RESOURCE SOURCE IDENTIFIER Chemicals, peptides, and recombinant proteins Metronidazole (MTZ) Sigma-Aldrich Cat#M1547 Dimethyl sulfoxide (DMSO) Sigma-Aldrich Cat#276855 Phosphate-buffered saline (PBS) Thermo Fisher Scientiﬁc Cat#BR0014G Formaldehyde Sigma-Aldrich Cat#F8775 Bovine Serum Albumin Fraction V AppliChem/Panreac Cat#A1391.0100 LMP Agarose Fisher Scientiﬁc Cat# 16520100 MS222 (Tricaine methanesulfonate) Sigma-Aldrich Cat# E10521 Gibco Trypsin 2.5% Thermo Fisher Scientiﬁc - Gibco 11538876 DAPI Thermo Fisher Scientiﬁc Cat#P36931 Goat serum Sigma-Aldrich Cat#G9023 Triton X-100 Merck Cat#108643 Glycerol Sigma-Aldrich Cat# 1.04092 Critical commercial assays In Situ Cell Death Detection Kit, Fluorescein Sigma - Roche 11684795910 Experimental models: organisms/strains Tg(elavl3 :GCaMP6s) Vladimirov et al., 2014 ZFIN Cat# ZDB-ALT-141023-1, RRID:ZFIN_ZDB-ALT-141023-1 Tg(narp:GAL4VP16) Agetsuma et al., 2010 ZFIN ID: ZDB-ALT-110215-5 Tg(UAS-E1b:NTR-mCherry) Agetsuma et al., 2010 ZFIN ID: ZDB-ALT-070316-1 Wildtype zebraﬁsh EZRC ( ZFIN Cat# ZDB-GENO-960809-7 Software and algorithms Fiji/ImageJ Schindelin et al., 2012 Fiji.html#Downloads MATLAB 2019b N/A (Continued on next page) ll OPEN ACCESS STAR Protocols 2, 100465, June 18, 2021 3 Protocol STEP-BY-STEP METHOD DETAILS Behavioral testing setup Timing: varies, up to 1 week 1. Software. To implement the custom-made real-time tracking software (Kermen et al., 2020, Palumbo et al., 2020) we use the OpenCV 3.0 library and the QtCreator5.2 developing platform. With this STAR protocol, we publish the source code to implement the Object class ‘‘Tracker’’, which would allow you to create instances of ‘‘trackers’’ and allocate each of them in a different thread, if you go for a multi- threaded approach. The only step you will have to implement is the image collection from a camera of your choice and send them to the object for processing. Once processed, the object ‘‘tracker’’ will return the detected position of the animals together with its size. For further details see documenta- tions for source code, header and instruction on how to implement it in your code: com/fabrizio-palumbo/Conditioned-behaviour-in-juvenile-zebraﬁsh. 2. Implementation. We use a class of algorithm called ‘‘Adaptive Background Gaussian Mixture Model for foreground segmentation’’ (KaewTraKulPong and Bowden, 2002, Lech et al., 2014, Ziv- kovic, 2004, Power and Schoonees, 2002). a. The principle behind this algorithm is the following: the intensity value of each pixel in the im- age is modeled by an adaptive parametric mixture model of N, typically three or ﬁve, Gaussian Continued REAGENT or RESOURCE SOURCE IDENTIFIER Open CV3.0 opencv-3-0/ N/A QtCreator5.2 gettingstarted.html#installing-qt Deposited data Custom scripts palumbo/Conditioned- behaviour-in-juvenile-zebraﬁsh N/A Other Confocal microscope (203 plan NA 0.8 objective) Zeiss Examiner Z1 Confocal microscope (203 plan NA 1.0, Plan-Apochromat) Zeiss Examiner Z1 Fish dry food Sparos ZEBRAFEED Artemia nauplii – ZM Brine Shrimp Cysts Premium 250 Grade ZM Systems N/A Instant Ocean Salt AS 1010006 Methylene blue Sigma-Aldrich M9140-25G Plastic pipets VWR 612-1681 ZebTEC nursery nets (bottom pore size = 300 mm) Scanbur 80-ZB300BTI Falcon tubes 50 mL VWR 525-0158 or 525-0610 Petri dishes VWR 391-0440 Zebraﬁsh tank 3.5 L Scanbur – Tecniplast ZebTech 80ZB30TK Gosselin Square Petri Dish, 1203120 mm, Corning VWR 10799-777 GigE Vision camera Allied Vision Manta G-235B Excalibur low-noise high-speed precision operational ampliﬁers Texas Instrument TLE2142 Arduino Due cc/arduino-due Tungsten wire Sigma-Aldrich 267554-9.5G Vortex 0003617000 Shaker (PMR-30 Mini Rocker-Shaker) VWR 444-0341 ll OPEN ACCESS 4 STAR Protocols 2, 100465, June 18, 2021 Protocol distributions (KaewTraKulPong and Bowden, 2002, Power and Schoonees, 2002). Once the image has been modeled, the posterior probability is estimated, to deﬁne the current state of the pixel: background or foreground (Power and Schoonees, 2002). b. The implementation of this algorithm is described more in detail in Figure 1 and in attached documentation, Conditioned-behaviour-in-juvenile-zebraﬁsh. Once the pixels corresponding to the juvenile zebraﬁsh are identiﬁed their center of mass deﬁnes the animal’s coordinates in the arena (Fig- ures 1A–1C). As a quality control of the detected ﬁsh, two criteria must be satisﬁed by the area detected: i. The size of the detected zebraﬁsh must be within a physiological range for the develop- mental stage of the analyzed ﬁsh (1–2 week=2–4 mm2, 3–4 weeks= 4–10 mm2). ii. The distance between the detected animal position in two consecutive frames must be smaller than a threshold deﬁned by the physiological maximum velocity for the zebraﬁsh. We use 3 cm displacement between two frames, corresponding to 66 ms, to avoid noise detection from the distant borders of the arena. c. The result of our tracking algorithm has proven to be very stable and reliable even in conditions of weak contrast between the ﬁsh and the surrounding environment (Figures 1A–1C), compared to a background subtraction algorithm in our assay. In our CPA training assay, image acquisition fre- quency of 15 Hz was sufﬁcient to accurately track the ﬁsh without computationally overload the software. An example two minutes’ pathway for one juvenile is shown in Figure 1D. Figure 1. Image processing ﬂow chart to detect juvenile zebraﬁsh in low contrast images (A) Pixels corresponding to the zebraﬁsh are detected by the tracking algorithm. (B) Dilations and erosion operations are performed to reduce the noise in the background pixels. (C) Coordinates of the biggest area detected, which match the animal size range deﬁned by the user, are extracted and processed by the software. (D) Example of two min raw trace of ﬁsh position superimposed on the raw image detected by the camera. Dashed white lines shows 2 min of detected ﬁsh position, recorded at 15 frames per second. ll OPEN ACCESS STAR Protocols 2, 100465, June 18, 2021 5 Protocol Alternative: The approach we follow to implement our behavioral software is only one of the possible solutions. It is worth to mention the recent sotfware package, Stytra ( com/portugueslab/stytra), published by Portugues lab (Stih et al., 2019). This software pack- age provides a platform which will allow the experimenter to perform many different behav- ioral protocols, requiring little programming knowledge by the user thanks to a user-friendly interface and documentation. 3. Hardware. To implement the behavioral setup there are speciﬁc design requirements that are important to maximize animal welfare and minimize external inﬂuence during the experiment. We implemented a setup design, shown in Figure 2, which fulﬁlls the following requirements: a. Prevent light\sound contamination from the surrounding environment as good as possible. b. Prevent visual contact between the animals in different chambers during the behavioral testing. c. The water temperature should be maintained constant and never below 25C/26C. We used a heater in the room to buffer temperature ﬂuctuations. d. Prevent any intervention by the experimenter during the entire protocol. 4. Behavioral arena. To construct the behavioral arena using standard components, we recommend Gosselin square shaped Petri dishes (120 mm 3 120 mm 3 15.8 mm). The walls of each arena were covered with standard white opaque electric tape to avoid any interaction between the ﬁsh in neighboring chambers. This is particularly important, since the juvenile zebraﬁsh exhibit social interactions (Dreosti et al., 2015, Tunbak et al., 2020, Groneberg et al., 2020, Hinz and de Polavieja, 2017). Using these large petri dishes allows the animal to explore the arena freely Figure 2. Schematic representation of the behavioral setup that is used for conditioned place avoidance Six square shaped petri dishes are placed on an LCD screen that display speciﬁc visual patterns from the bottom. A high-resolution camera, Manta 235B (Allied Vision) with a wide-angle objective, is used to acquire images of the animals. A custom-made software is used to acquired and process the images in real time. Depending on the protocol that is performed, the software communicates with an Arduino Due that controls 6 separate non-inverting ampliﬁer Opamp circuit for delivering the mildly aversive electric stimulation only when animals are detected in the conditioned zone. Each arena is equipped with two tungsten wires, covering the entire length of it two opposing sides. Figure adapted with permission from (Palumbo et al., 2020) ll OPEN ACCESS 6 STAR Protocols 2, 100465, June 18, 2021 Protocol without any restrictions and increase the richness of the behavioral repertoire. These small details play a crucial role on the resulting behavior since we are not constraining animal movement and enhance ﬂexibility. Finally, using square shaped petri dishes allows easier implementation of the electrodes for establishing a uniform electric ﬁeld. 5. Electrodes. We recommend the use of inert tungsten wire electrodes, 12 cm of length and 0.25 mm of diameter, for delivering mild aversive electric stimulation to the ﬁsh. We observed that tungsten electrodes were better than silver electrodes which showed toxic effects in water. However, tungsten wires exhibit fast decay in conductivity due to the accumulation of ions over one of the electrodes, generating a coating layer within few seconds under constant voltage. To avoid coating and establish constant current, we use 10 milliseconds long 1.2 mA current pulses at 1.33 Hz repetition rate and alternate the polarity on the electrodes between conditioning ses- sions. All these additional measures prevent oxidation of tungsten wires throughout 2–3 h long behavioral training sessions. This allows us to reuse the same electrodes across experiments ex- tending their lifetime indeﬁnitely (we have used the same electrodes for 4 years now and they still work well). (See problem 2 for troubleshooting) 6. Electric stimulation circuit. To deliver mildly aversive electric stimuli separately to individual ﬁsh, we used an Arduino Due based circuit. Arduino board received 3,3 V digital input from the tracking software, when the zebraﬁsh is detected in the condition zone, during conditioning period, and delivered 18 V (10 millisecond, 1.2 mA current at 1.33 Hz) to each ﬁsh separately. For each ﬁsh, a separate integrated circuit was built and used, connecting an Operational-Ampli- ﬁer (Opamp, TLE2142 EXCALIBUR low-noise high-speed precision, Texas Instrument) in a non- inverted ampliﬁed conﬁguration. The Voltage at the output is given by the relation (see Figure 2): Voltage output = Voltage input  1 + Resistance 2 Resistance 1  7. Visual stimuli presentation. Visual stimuli are presented to the ﬁsh form the bottom using a hor- izontally positioned LCD monitor. The LCD monitor gives the ﬂexibility to change the visual stim- uli, to control its timing, and to synchronize with other electronic systems. a. We use a simple visual pattern dividing the arena half in red and half in gray colors. We match the luminosity of colored illumination, when choosing the red and gray patterns marking different compartment of the arena. This is important since zebraﬁsh respond differently to different illumi- nation and ambient light levels (Spence and Smith, 2008, Avdesh et al., 2012, Oliveira et al., 2015, Guggiana-Nilo and Engert, 2016, Cheng et al., 2017, Cheng et al., 2016). Note: It is very important to keep the water in the behavioral chambers warm, which is crucial especially for extended behavioral testing. To ensure that the water in each behavioral arena never drops below 26C: b. Measure the water temperature in each arena before and after performing a behavioral exper- iment. c. Perform the behavioral experiments in a heated room. We installed a passive heater element in our behavioral room which helps to keep the room temperature around 26C over time. 8. Experimental design. When designing behavioral experiments, the ﬁrst rule you need to have in mind is ‘‘minimize animals’ discomfort, while maximizing animal welfare and scientiﬁc rigor of the experimental output.’’ To do so it is very important that you tune all the parameters of your behav- ioral protocol with this goal in mind. a. The stimulus design is a critical step when building a conditioned place avoidance task. We chose the minimum stimulus intensity that elicits a brief escape response. We therefore ll OPEN ACCESS STAR Protocols 2, 100465, June 18, 2021 7 Protocol recommend minimizing the intensity and the duration of the aversive electric stimuli to maxi- mize animals’ welfare and consequently their performance. b. The duration of each training and test session of the CPA protocol is another important param- eter to optimize. c. Additionally, we recommend verifying the CPA learning results by ﬂipping the color assign- ment of the conditioned zone from red to gray, in separate CPA experiments. d. We recommend our CPA protocols below. Behavioral training Timing: varies, 5h for steps 9–10, 4 days for step 11 9. Single day CPA training. For single day CPA training, we recommend the experimental design in Figure 3. Also keep in mind: a. Establish a long enough baseline session to ensure that the animals are relaxed and habitu- ated to the environment, evenly exploring the arena without bias. We choose to have a base- line session of 1 h. This will give you the opportunity to evaluate possible innate preference of the animal for any of the arena parameters (location, pattern displayed, etc.). If a naı¨ve animal displays a clear preference for speciﬁc compartment of the arena after a long baseline session, it might be necessary to adjust the visual patterns to reduce such bias. We suggest to always maintain a homogeneous luminosity all over the arena (Methods video S1). b. Minimize the duration of the conditioning sessions, as much as possible. This will reduce the discomfort of the animal, substantially. We recommend performing multiple short condition- ing sessions, separated by test sessions. c. Administrate the negative stimulus to the animal (1.2 mA for 10 ms at 1.33 Hz) every time the animal enters the conditioned zone. d. Terminate stimulus administration as soon as the animal exits the conditioned zone. e. We recommend two 30 min conditioning sessions and two 30 min test sessions. Together with a 1-h long baseline session, the experiment will last around 3 h, which has no negative impact on animals’ health and welfare, as we show in our previous publication (Palumbo et al., 2020). f. We do not recommend protocols longer than 5 h (the longest duration we have tested). This might have a negative impact on animals’ health since they will not be fed for a long time and the water is not changed during the training. Note: In our study (Palumbo et al., 2020), we do not observe freezing behavior or anxiety-like phenotype in animal trained in 1 day protocols up to 5 h long. We therefore recommend to keeping any behavioral protocol shorter than 5 h. Note: We do recommend collecting the animal from the facility only when the behavioral pro- tocol is ready to begin. This will allow the experimenter to transport the animal to the Figure 3. Schematic description of the protocol recommended for one day training in juvenile zebraﬁsh Baseline is 60 min long; conditioning and test sessions are 30 min long with no delay in between sessions. During the conditioning session, mildly aversive electric stimuli are delivered at 1.33hz, every time the animal enters the conditioned zone (red). We recommend verifying the CPA learning results by ﬁlliping the color assignment of the conditioned zone from red to gray, in separate CPA experiments. Figure adapted with permission from (Palumbo et al., 2020). ll OPEN ACCESS 8 STAR Protocols 2, 100465, June 18, 2021 Protocol experimental area and to initiate the behavioral training immediately. This will minimize the total time the animal is handled outside the facility. 10. Sham-training experiments. In our recent study focusing on CPA learning in juvenile zebraﬁsh (Pal- umbo et al., 2020), we proposed a sham-training protocol to distinguish the effects of animals’ aver- sive experience due to mildly aversive electric stimulation (US), from the CPA learning related adap- tations of animal behavior, as described in Figure 4A. This sham training protocol decouples animals’ spatial position in the arena from animals’ subjective experiences in response to the deliv- ery of electric stimuli (US). This allows us to compare the behaviors of CPA trained animals with sham- trained animals with same subjective experience of the US. To do so: a. Assign, for each animal which undergoes a training session, a sibling animal as a sham-con- trol. Animals will undergo the training session in couples, one trained and one sham- trained. b. The two arenas need to be identical. We also recommend alternating the arena used for training with the arena used for sham-training, in different sessions. This will control for any asymmetry in the arena of which the experimenter is not aware of. Figure 4. Schematic description of the Sham experiment in juvenile zebraﬁsh (A) Schematic description of the protocol recommended for one day training in juvenile zebraﬁsh. Baseline is 60 min long; conditioning and test sessions are 30 min long with no delay in between sessions. (B) Hardware conﬁguration of the behavioral setup to perform sham training. Each trained animal is coupled, via direct hardwiring, to another animal which will be sham trained. During the conditioning session, mildly aversive electric stimuli are delivered at 1.33hz to both animals simultaneously, every time the trained animal enters the conditioned zone (red). We recommend verifying the CPA learning results by ﬁlliping the color assignment of the conditioned zone from red to gray, in separate CPA experiments. Figure adapted with permission from (Palumbo et al., 2020). ll OPEN ACCESS STAR Protocols 2, 100465, June 18, 2021 9 Protocol c. Connect both arenas to the same stimulation cable, the one controlled by the trained ﬁsh (Figure 4B). Doing so, both animals will be exposed to the same stimulation, controlled exclusively by the trained ﬁsh. d. Perform a new series of sham-training experiment any time a new training protocol is imple- mented. 11. Multi-day CPA training. In our recent study, we showed that long term training of juvenile zebra- ﬁsh leads to better CPA learning performance and memory recall (Palumbo et al., 2020). Such long-term training is best achieved by multiple training sessions spread over consecutive days. This allows the animal to rest, feed and recover between training days. Training juvenile zebraﬁsh over multiple days requires the experimenter to plan animal husbandry and handling accordingly. For multi-day CPA training, we recommend the experimental design in Figure 5. Also, keep in mind: a. Minimize the amount of time for transferring animals between behavioral chambers and tem- porary holding between training days. After the ﬁrst training day, we keep individual juvenile zebraﬁsh in petri-dishes (90 mm radius) in a 28C incubator from the end of the behavioral training (circa 5:00 pm) until the next day training session (circa 10:00 am) We feed the ﬁsh before placing them in the incubator. The next morning, we refresh the water and we feed the animals 30 min before the start of the new training session. b. We recommend, before performing a 30 min recall session, to begin each additional day of training with a 30 min habituation session without any visual pattern presented to the animal. This will allow the animal to habituate to the behavioral arena without eliciting any memory recall related to the training visual stimuli, since they are not displayed. The arena is illumi- nated with light gray, of the same luminosity of the pattern used on day1, see Figure 5 for a graphical representation. c. We recommend concluding each training day with a conditioning session (but not a test ses- sion), as it might help promote memory consolidation. d. Wash each behavioral chamber thoroughly with RO water, before and after each training day. Figure 5. Schematic description of the protocol recommended for multi-day training in juvenile zebraﬁsh Baseline and blank sessions are 60 min long, recall, conditioning and test sessions are 30 min long with no delay in between sessions. During the conditioning session, mildly aversive electric stimuli are delivered at 1.33hz, every time the animal enters the conditioned zone (red). Each day is concluded with a conditioning session to avoid memory extinction overnight. From day two, each protocol starts with a blank session during which the animals are habituated to the arena without any pattern presented. Figure adapted with permission from (Palumbo et al., 2020). ll OPEN ACCESS 10 STAR Protocols 2, 100465, June 18, 2021 Protocol Behavioral analysis Timing: varies, up to 15–30 min to adapt and run the codes we provide For designing the analysis pipeline, we recommend using multiple complementary CPA learning measures, some of which are also used in previous studies (Palumbo et al., 2020, Valente et al., 2012, Millot et al., 2014, Yashina et al., 2019, Kermen et al., 2020). This approach allows quantiﬁca- tion of animal behavior from different perspectives with different strengths and weaknesses. 12. We suggest quantifying the following parameters to assess CPA learning: a. Average density of zebraﬁsh position in the CPA arena. b. Relative time spent in the conditioned zone. c. Relative swimming distance in the conditioned zone. d. Animals’ distance from the boundary between safe and conditioned zones. e. Conditioned Place Avoidance learning index (Palumbo et al., 2020). f. Swim direction near the boundary between safe and conditioned zone. g. Avoidance of entry to conditioned zone, near the boundary between safe and conditioned zones. 13. We suggest quantifying following parameters to assess animals state and health: a. Swim velocity during the experiment. b. Percentage of time that the zebraﬁsh exhibit no swimming (freezing), which we deﬁned as less than 2 mm swimming for 2 s (adapted from (Agetsuma et al., 2010)). c. Swim velocity, one second before (b) and after (a) the delivery of aversive unconditioned stimuli (US). Note: To see the implementation of these measures, please refer to the documentation in and in our earlier study (Palumbo et al., 2020). Note: In order to have a complete and complementary overview of animal health and perfor- mance, we highlight the importance of using multiple metrics while evaluating animal behavior. Chemogenetic ablation of speciﬁc neural populations in zebraﬁsh brain Timing: 44 h This protocol describes the use of a transgenic zebraﬁsh line Tg(narp:GAL4VP16; UAS-E1b:NTR- mCherry) to ablate dorsolateral habenula (dlHb) neurons. This transgenic line expresses Nitroreduc- tase (NTR) fusion protein tagged by a mCherry speciﬁcally in dlHb (Agetsuma et al., 2010) (Methods video S2). As shown before in adult zebraﬁsh (Agetsuma et al., 2010), bath application of Metroni- dazole (MTZ) chemogenetically ablate NTR positive dlHb neurons in juvenile zebraﬁsh (Palumbo et al., 2020). 14. Prepare MTZ solution a. Needed: 50 mL tubes, petri dishes (50 mL), aluminum foil, microbalance, vortex, and shaker (see key resources table), incubator (G 28C). b. Prepare 50 mL [10 mM] MTZ solution in a 50 mL tube. Fill the 50 mL tube with AFW and add DMSO, subsequently add the MTZ powder. Proportion is described in Table 1). c. Given the photodegradable nature of the resulting MTZ solution, wrap the entire 50 mL tube, once securely locked, into aluminum foil and make sure that no light comes into contact with the solution. Pay particular attention to this step. ll OPEN ACCESS STAR Protocols 2, 100465, June 18, 2021 11 Protocol CRITICAL: MTZ is photodegradable. Prepare a fresh batch of MTZ solution for each abla- tion protocol. 2 3 50 mL is needed for treating control and experimental groups simultaneously. CRITICAL: We recommend leaving the animal for at least 12h (overnight) in ﬁsh water after removing them from the MTZ bath to allow the MTZ to wash out. During this time, frequently refresh the water in the petri dish and feed the animal. CRITICAL: Perform the behavioral experiments as soon as the MTZ washout is completed, before any neurogenesis that might occur over the course of the next few days. CRITICAL: As control animals, we recommend using sibling zebraﬁsh that do not express the UAS-E1b:NTR-mCherry transgene. d. Shake by hand, vortex thoroughly, and leave the tube on a shaker for at least 30 min, allowing the metronidazole to dissolve properly. 15. Chemogenetic ablation a. Before you start treating the animals make sure you have: i. 23 50 mL [10 mM] MTZ solution ii. Aluminum foil iii. Fish already in the experimental area and fed prior to the treatment. iv. Incubator at G 28C. v. 1 petri dish must contain at most 3 juvenile zebraﬁsh. vi. Prepare the ﬁsh ready for the experiment. Make sure that the ﬁsh had access to food before the start of the ablation protocol. Limit the number of ﬁsh (max 3) per dish, to avoid mortality due to hypoxia or excessive ammonia. Make sure that the animals to be treated are size matched. b. Fill two petri dishes with 50 mL [10 mM] each, and make sure the temperature of the solution is not lower than 26C c. Transfer the zebraﬁsh, one at a time in the petri dishes with the MTZ solution, using a 7 mL pipette. Make sure to cut the tip of the pipette, as described earlier. To prevent reduction of MTZ concentration in the petri dish, transfer the ﬁsh in a small bubble of water. CRITICAL: We observed that the lower MTZ concentrations (1 and 5 mM) did not yield desired effects in juvenile zebraﬁsh. Moreover 10 mM MTZ solution did not elicit any toxicity or alteration of animal behavior in control animals of nacre or Ab wild-type genetic background. d. Label the petri dish with necessary information (ﬁsh line, date, experimental group, experi- menters initial, etc.) e. Metronidazole is light-sensitive, therefore wrap the dish in aluminum foil. Exposure to light can decrease effectiveness of the ablation and will turn the ﬁsh water brown/yellow. f. Label the aluminum foil again with the same info as in point 3. g. Place the petri dishes in the incubator (G 28C). Table 1. Speciﬁcs of the 10 mM MTZ solution Component Volume/Weight Final concentration Metronidazole (MTZ) 0.086 g 0.01 M [10 mM] Dimethyl Sulfoxide (DMSO) 0.250 mL 0.5% Artiﬁcial ﬁsh water (AFW, 0.2 g/L instant ocean salt in reverse osmosis water (RO)) 49.750 mL N/A Speciﬁcation about the chemicals can be found in the key resources table. ll OPEN ACCESS 12 STAR Protocols 2, 100465, June 18, 2021 Protocol Note: Be extra careful when moving the dish around since even small movements can be very stressful for the animals. h. Incubate for 24 h in MTZ. Note: For these 24 h, the animal will be kept in darkness. i. After 24 h, transfer the ﬁsh to a new petri dish containing clean ﬁsh water. Make sure to refresh the water twice in each petri dish in the ﬁrst few hours after the MTZ treatment. j. Incubate again (G 28C) for 12 h in AFW. Make sure to feed the animal before incubating. k. The next morning make sure to refresh the ﬁsh water in each petri dish and feed the animal at least 30 min before the start of the behavioral protocol. l. The ﬁsh are now ready for the behavior protocol. Ideally start between 9 and 12 am, to keep consistency for the timing of the experiments, and animals’ circadian rhythm. 16. Validation of chemogenetic ablation (Timing: 16 h) To verify successful chemogenetic ablation of neurons we recommend TUNEL assay (Agetsuma et al., 2010). The protocol was adapted from the manufacturer’s protocol (In Situ Cell Death Detection Kit, Fluorescein, 11684795910 Roche) and optimized for whole mount labeling and confocal imaging (Methods video S3). a. Euthanize ﬁsh in ice cold water and ﬁx it in cooled 4% PFA in 0.25% PBTx (0.25% Triton X-100 in 13 PBS) for 12 h at 4C. b. Permeabilizesamplesin0.050%Trypsin-EDTAonicefor40minandwash3timeswith0.25%PBTx. c. Incubate the samples in 50mL TUNEL reaction mix for 1 h at 37C humidiﬁed atmosphere, in a water bath covered by aluminum foil the dark. Subsequently wash it in 0.25% PBTx. d. Place the samples on microscopy slides after washing steps in increasing glycerol concentra- tion of 25%, 50%, and 75%. Then, use 75% Glycerol as a medium for mounting the samples on glass slides for confocal imaging (see problems 4 and 5). e. The TUNEL assay is based on detection of apoptotic cells. Apoptosis is a form of pro- grammed cell death and can be affected by numerous factors (e.g., uptake of the drug, pas- sage through the blood brain barrier, concentration, etc.). To visualize the ablated cells at different apoptotic stages, we performed TUNEL assay at 16 h (Figure 6A and 6C) and 24 h (Figure 6B) after the start of the MTZ treatment. While apoptotic cells are clearly visible in 16 h after chemogenetic ablation, 24 h after the ablation apoptotic fragments are less de- tectible with TUNEL assay (Figure 6B). Note: Zebraﬁsh brain have exceptional regenerative capacity (Celikkaya et al., 2019; Kizil, 2018; Cosacak et al., 2019; Lange et al., 2020; Kesavan et al., 2020; Schwarzer et al., 2020). Therefore, we recommend that the behavioral testing is done no longer than 2 days after the chemogenetic ablation, otherwise neuroregeneration may affect subsequent experi- ments. We observed addition of new habenular neurons in juvenile zebraﬁsh, already 2 days after chemogenetic ablation (Figure 7; Methods video S4). Note: Health monitoring. In the rare cases, if we observe that a ﬁsh has abnormal swim or no movement, we euthanized these animals and did not perform any behavioral study EXPECTED OUTCOMES Once the conditioned protocol has been performed, following all the instruction described above, the behavioral phenotype of the animal will replicate the one we describe in our previous publication (Palumbo et al., 2020). Most importantly, the animal will not show any 1) Freezing behavior, 2) Erratic swimming, or 3) Thigmotaxis. ll OPEN ACCESS STAR Protocols 2, 100465, June 18, 2021 13 Protocol The animal will spend most of his time in the safe zone of the arena once the training session is completed. For more details, in our publication (Palumbo et al., 2020) we provide several analysis of animal behavior over the course of the behavioral training. LIMITATIONS We only detect the animal’s ‘‘center of mass’’ to obtain its position. We did not detect/analyzed an- imal posture or animal swim pattern. In our setup we did not implement a conditioned place learning protocol based on reward. This chal- lenging task will require development of repeated and robust reward delivery systems that require further design. Implementing more computational power and higher spatiotemporal resolution of video monitoring would lead to better image quality for posture estimation and allow the processing of larger number of zebraﬁsh in parallel. Figure 7. Regeneration of new neurons 48 h after chemogenetic ablation with metrodiniazole Confocal microscopy image of three weeks old Tg(narp:Gal4;UAS-E1b:NTR-mCherry) zebraﬁsh, 48h after Metrodiniazole treatement. The new-born neurons that are marked with white arrows are already integrating into developing habenula. Scale bar is 50 mm. Figure 6. TUNEL assay for detecting apoptosis after chemogenetic ablation with metrodiniazole (A–C)Confocal microscopy images of three weeks old Tg(narp:Gal4;UAS-E1b:NTR-mCherry) zebraﬁsh 16 h (A) and 24 h (B) after the start of Metronidazole (MTZ) treatement. Green ﬂuorescent labels TUNEL signal which is a direct measure of cell death (apoptosis). Note that green TUNEL signal is not visible in control animals (C). Scale bar is 50 mm. ll OPEN ACCESS 14 STAR Protocols 2, 100465, June 18, 2021 Protocol TROUBLESHOOTING Problem 1 During the baseline session, the animal shows reduced swimming behavior, with a high freezing time (step 9–11). Potential solution Control the water temperature in the behavioral arena, it is likely too cold for the animal. Addition- ally, make sure that the animal is fed before it is transported (always using warm water) to the exper- imental area. Heating up the room in which you perform the behavioral training can also contribute to maintain the right water temperature. See Methods video S1 for an example of animal baseline behavior. Problem 2 The animal does not respond to the electric stimulation during the conditioned sessions (step 5–11). Potential solution As a ﬁrst approach always make sure that all the hardware is properly connected and secured (no loose wires around). Moreover, be sure of alternating cathode and anode across conditioning ses- sions to avoid electrode passivation. If none of the above solves the problem, then it is likely that the stimulus amplitude is the problem: too low amplitude will not elicit any response from the animal, while a too strong stimulus will elicit at ﬁrst a strong animal reaction, but it will quickly lead to a helplessness behavior. Therefore, pay close attention to see in which of these two conditions you ﬁnd yourself and adjust the stimulus amplitude accordingly. Problem 3 The animal used for experiments at 3-week post fertilization is small in size compared to previous experiments (step 9–11). Potential solution This is probably due to crowded nursery tank in the ﬁsh facility together with a non-appropriate feeding routine. We do recommend keeping no more than 25 larvae per liter of water and feeding them twice a day with dry food (morning and evening) and once with Artemia naplii (around 13:00) (see key resources table). Keeping the waterﬂow outside the nursery net also improve animal growth and health. Problem 4 The ﬂuorescent signal of the whole mount TUNEL staining decreases with the imaging depth (step 16). Potential solution When dissecting the brain remove the skin and dura on top of the brain. This allows a better pene- tration of the antibodies into the brain. Additionally, when imaging, make sure that the cover slip is right on top of the brain, as close as possible. Pay attention however not to squeeze the brain. Problem 5 The sample is not stable during the imaging process (step 16). ll OPEN ACCESS STAR Protocols 2, 100465, June 18, 2021 15 Protocol Potential solution We recommend using a 4% gelatin - 65% glycerol solution as mounting medium. It improves the sta- bility of the sample, since it has better mechanical properties at room temperature (20C G 2C) than 75% glycerol, which remains viscous. RESOURCE AVAILABILITY Lead contact Further information and requests for resources and reagents should be directed to and will be ful- ﬁlled by the lead contact, Emre Yaksi (emre.yaksi@ntnu.no) Materials availability This study did not generate any new unique reagent Data and code availability All custom scripts described in this article are available at: SUPPLEMENTAL INFORMATION Supplemental information can be found online at ACKNOWLEDGMENTS We thank Hitoshi Okamoto, Misha Ahrens (for transgenic lines), Siv Eggen, Vy Nguyen, Andreas Ny- gard (for technical assistance), and all Yaksi lab members (for stimulating discussions). This work was funded by ERC grant 335561 (F.P. and E.Y.), RCN FRIPRO grant 314212 (E.Y.), Kavli Foundation, and NTNU. AUTHOR CONTRIBUTIONS Conceptualization, F.P. and E.Y.; methodology and data, F.P. and B.S.; codes repository, F.P.; data analysis, F.P.; investigation, all authors; writing, F.P. and E.Y.; review & editing, all authors; funding acquisition and supervision, E.Y. DECLARATION OF INTERESTS The authors declare no competing interests. REFERENCES Agetsuma, M., Aizawa, H., Aoki, T., Nakayama, R., Takahoko, M., Goto, M., Sassa, T., Amo, R., Shiraki, T., Kawakami, K., et al. (2010). The habenula is crucial for experience-dependent modiﬁcation of fear responsesinzebraﬁsh.Nat. Neurosci.13, 1354–1356. Avdesh, A., Martin-Iverson, M.T., Mondal, A., Chen, M., Askraba, S., Morgan, N., Lardelli, M., Groth, D.M., Verdile, G., and Martins, R.N. (2012). Evaluation of color preference in zebraﬁsh for learning and memory. J. Alzheimer’s Dis. 28, 459–469. Celikkaya, H., Cosacak, M.I., Papadimitriou, C., Popova, S., Bhattarai, P., Biswas, S.N., Siddiqui, T., Wistorf, S., Nevado-Alcalde, I., Naumann, L., et al. (2019). GATA3 promotes the neural progenitor state but not neurogenesis in 3D traumatic injury model of primary human cortical astrocytes. Front. Cell. Neurosci. 13, 23. Cheng, R.-K., Krishnan, S., Lin, Q., Kibat, C., and Jesuthasan, S. (2017). Characterization of a thalamic nucleus mediating habenula responses to changes in ambient illumination. BMC Biol. 15, 104. Cheng, R.K., Krishnan, S., and Jesuthasan, S. (2016). Activation and inhibition of tph2 serotonergic neurons operate in tandem to inﬂuence larval zebraﬁsh preference for light over darkness. Sci. Rep. 6, 20788. Cosacak, M.I., Bhattarai, P., Reinhardt, S., Petzold, A., Dahl, A., Zhang, Y., and Kizil, C. (2019). Single- cell transcriptomics analyses of neural stem cell heterogeneity and contextual plasticity in a zebraﬁsh brain model of amyloid toxicity. Cell Rep. 27, 1307–1318.e3. Dreosti, E., Lopes, G., Kampff, A.R., and Wilson, S.W. (2015). Development of social behavior in young zebraﬁsh. Front. Neural Circuits 9, 39. Groneberg, A.H., Marques, J.C., Martins, A.L., Diez Del Corral, R., De Polavieja, G.G., and Orger, M.B. (2020). Early-life social experience shapes social avoidance reactions in larval zebraﬁsh. Curr. Biol 30, 4009–4021.e4. Guggiana-Nilo, D.A., and Engert, F. (2016). Properties of the visible light phototaxis and UV avoidance behaviors in the larval zebraﬁsh. Front. Behav. Neurosci. 10, 160. Hinz, R.C., and De Polavieja, G.G. (2017). Ontogeny of collective behavior reveals a simple attraction rule. Proc. Natl. Acad. Sci. U S A 114, 2295–2300. Kaewtrakulpong, P., and Bowden, R. (2002). An improved adaptive background mixture model for real-time tracking with shadow detection. In Video- Based Surveillance Systems: Computer Vision and Distributed Processing, P. Remagnino, G.A. Jones, N. Paragios, and C.S. RegazzonI, eds. (Springer US). Kermen, F., Darnet, L., Wiest, C., Palumbo, F., Bechert, J., Uslu, O., and Yaksi, E. (2020). Stimulus- speciﬁc behavioral responses of zebraﬁsh to a large ll OPEN ACCESS 16 STAR Protocols 2, 100465, June 18, 2021 Protocol range of odors exhibit individual variability. BMC Biol. 18, 66. Kesavan, G., Machate, A., Hans, S., and Brand, M. (2020). Cell-fate plasticity, adhesion and cell sorting complementarily establish a sharp midbrain- hindbrain boundary. Development 147, dev186882. Kizil, C. (2018). Mechanisms of pathology-induced neural stem cell plasticity and neural regeneration in adult zebraﬁsh brain. Curr. Pathobiol. Rep. 6, 71–77. Lange, C., Rost, F., Machate, A., Reinhardt, S., Lesche, M., Weber, A., Kuscha, V., Dahl, A., Rulands, S., and Brand, M. (2020). Single cell sequencing of radial glia progeny reveals the diversity of newborn neurons in the adult zebraﬁsh brain. Development 147, dev185595. Lech, M., Dalka, P., Szwoch, G., and Czy_zewski, A. (2014). Examining quality of hand segmentation based on gaussian mixture models. In Multimedia Communications, Services and Security: 7th International Conference, MCSS 2014, Krakow, Poland, June 11-12, 2014. Proceedings, A. Dziech and A. Czy_zewski, eds. (Springer International Publishing). Millot, S., Cerqueira, M., Castanheira, M.F., Øverli, Ø., Martins, C.I.M., and Oliveira, R.F. (2014). Use of conditioned place preference/avoidance tests to assess affective states in ﬁsh. Appl. Anim. Behav. Sci. 154, 104–111. Oliveira, J., Silveira, M., Chacon, D., and Luchiari, A. (2015). The zebraﬁsh world of colors and shapes: preference and discrimination. Zebraﬁsh 12, 166–173. Palumbo, F., Serneels, B., Pelgrims, R., and Yaksi, E. (2020). The zebraﬁsh dorsolateral habenula is required for updating learned behaviors. Cell Rep. 32, 108054. Power, P.W., and Schoonees, J.A. (2002). Understanding background mixture models for foreground segmentation. In Proceedings of Image and Vision Computing New Zealand (IVCNZ), pp. 266–271. Schindelin, J., Arganda-Carreras, I., Frise, E., Kaynig, V., Longair, M., Pietzsch, T., Preibisch, S., Rueden, C., Saalfeld, S., Schmid, B., et al. (2012). Fiji: an open-source platform for biological-image analysis. Nat. Methods 9, 676–682. Schwarzer, S., Asokan, N., Bludau, O., Chae, J., Kuscha, V., Kaslin, J., and Hans, S. (2020). Neurogenesis in the inner ear: the zebraﬁsh statoacoustic ganglion provides new neurons from a Neurod/Nestin-positive progenitor pool well into adulthood. Development 147, dev176750. Spence, R., and Smith, C. (2008). Innate and learned colour preference in the Zebraﬁsh, Danio rerio. Ethology 114, 582–588. Stih, V., Petrucco, L., Kist, A.M., and Portugues, R. (2019). Stytra: An open-source, integrated system for stimulation, tracking and closed-loop behavioral experiments. PLoS Comput. Biol. 15, e1006699. Tunbak, H., Vazquez-Prada, M., Ryan, T.M., Kampff, A.R., and Dreosti, E. (2020). Whole-brain mapping of socially isolated zebraﬁsh reveals that lonely ﬁsh are not loners. Elife 9, e55863. Valente, A., Huang, K.H., Portugues, R., and Engert, F. (2012). Ontogeny of classical and operant learning behaviors in zebraﬁsh. Learn. Mem. 19, 170–177. Vladimirov, N., Mu, Y., Kawashima, T., Bennett, D.V., Yang, C.T., Looger, L.L., Keller, P.J., Freeman, J., and Ahrens, M.B. (2014). Light-sheet functional imaging in ﬁctively behaving zebraﬁsh. Nat. Methods 11, 883–884. Yashina, K., Tejero-Cantero, A´ ., Herz, A., and Baier, H. (2019). Zebraﬁsh exploit visual cues and geometric relationships to form a spatial memory. iScience 19, 119–134. Zivkovic, Z. (2004). Improved adaptive gaussian mixture model for background subtraction. In Proceedings of the Pattern Recognition, 17th International Conference on (ICPR’04) Volume 2 - Volume 02 (IEEE Computer Society). ll OPEN ACCESS STAR Protocols 2, 100465, June 18, 2021 17 Protocol"
COST-WINNERS: COST reduction WIth Neural NEtworks-based augmented Random Search for simultaneous thermal and electrical energy storage control,Sven Myrdahl Opalic and Fabrizio Palumbo and Morten Goodwin and Lei Jiao and Henrik Kofoed Nielsen and Mohan Lal Kolhe,2023,,72,Journal of Energy Storage,article,"Journal of Energy Storage 72 (2023) 108202
Available online 20 July 2023
2352-152X/© 2023 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-
nc-nd/4.0/).
Contents lists available at ScienceDirect
Journal of Energy Storage
journal homepage: www.elsevier.com/locate/est
Research papers
COST-WINNERS: COST reduction WIth Neural NEtworks-based augmented
Random Search for simultaneous thermal and electrical energy storage
control
Sven Myrdahl Opalic a,b,c, Fabrizio Palumbo d, Morten Goodwin a, Lei Jiao a,
Henrik Kofoed Nielsen b, Mohan Lal Kolhe b,∗
a Centre for Artificial Intelligence Research, University of Agder, 4879, Grimstad, Norway
b Faculty of Engineering and Science, University of Agder, 4879, Grimstad, Norway
c Relog AS, Kongens Gate 16, 7011, Trondheim, Norway
d Oslo Metropolitan University, P.O. Box 4 St. Olavs plass, 0130, Oslo, Norway
A R T I C L E
I N F O
Keywords:
Reinforcement learning
COST-WINNERS
Thermal energy storage
Multiple ESS control
Smart warehouse
A B S T R A C T
The combination of local renewable energy production, dynamic loads, and multiple energy storage systems
with different dynamics requires sophisticated control systems to maximize the energy cost efficiency of the
combined energy system. Battery and thermal energy storage systems can be combined to increase the local
use of on-site renewable energy, reduce peak power demand, and exploit time-of-use energy pricing. In this
paper, we focus on how the augmented random search algorithm and artificial neural networks can be used
together to solve an energy cost optimization problem involving the control of a battery energy storage system
and a thermal energy storage system at the same time in a smart warehouse. As part of this work, a simulated
training environment made using the data from the smart warehouse’s operations. In addition to the energy
storage systems, the warehouse energy system has integrated a large roof mounted photovoltaic power plant
and an industrial-scale cooling system.
The developed solution is able to minimize the energy costs by modulating both energy systems, depending
on the situation. Additionally, when it is tested against the state-of-the-art solutions, our developed solution
at worst matches performance when the alternative algorithm is allowed to increase training time by a factor
of nearly three. On average, our presented solution doubles the performance of the benchmark algorithm with
much less computational resource expenditure.
1. Introduction
The current state of global energy supply and demand highlights
the need for controllable energy production and storage [1]. There is
an increasing demand for robust and responsive electrical and thermal
Energy Storage Systems (ESS) [2] as an increasing fraction of the
world’s energy demand is met by wind and solar power at the expense
of fossil-fueled and nuclear power [3]. The building sector represents a
natural candidate to deploy an algorithm controlling renewable energy
production and storage systems, as buildings are responsible for nearly
40% of global CO2 emissions [4].
Energy Storage Systems (ESS) can consist of various technologies
and be applied in a multitude of ways [5]. From the perspective of
the main electrical distribution grid, an important distinction exists
between centralized and decentralized ESS. As opposed to decentralized
∗Corresponding author.
E-mail addresses: sven.opalic@uia.no (S.M. Opalic), fabrizio@oslomet.no (F. Palumbo), morten.goodwin@uia.no (M. Goodwin), lei.jiao@uia.no (L. Jiao),
henrik.kofoed.nielsen@uia.no (H.K. Nielsen), Mohan.L.Kolhe@uia.no (M.L. Kolhe).
ESS, centralized systems can be directly controlled by the grid operator.
However, decentralized ESSs are seen as an important component of
a more environmentally friendly energy system, but they come with a
new set of challenges [6]. The decentralized systems should monitor the
energy market, integrate the control algorithm with market dynamics,
and use it to reduce the peak load of the system while also minimizing
the costs. In the case of multiple ESSs with different dynamics, such as
a combination of a Battery Energy Storage System (BESS) and Thermal
Energy Storage (TES), the complexity of the optimization problem
further increases.
One approach that is recently gaining a lot of interest in the sci-
entific community as a robust and self-improving method to control
building energy systems is Reinforcement Learning (RL) algorithms
[7]. RL algorithms can reduce costs by reducing necessary human
https://doi.org/10.1016/j.est.2023.108202
Received 20 December 2022; Received in revised form 2 June 2023; Accepted 26 June 2023
 Journal of Energy Storage 72 (2023) 108202
2
S.M. Opalic et al.
Nomenclature
ANN
Artificial Neural Network
ARS
Augmented Random Search
BESS
Battery Energy Storage System
BMS
Building Management System
DC
Direct Current
DDPG
Deep Deterministic Policy Gradient
DPC
Data Predictive Control
DPG
Deep Policy Gradient
DQN
Deep Q-Network
ESS
Energy Storage System
GLPK
GNU Linear Programming Kit
IEMS
Intelligent Energy Management System
MILP
Mixed Integer Linear Programming
MPC
Model Predictive Control
RL
Reinforcement Learning
SAC
Soft Actor-Critic
SOC
State Of Charge
TD3
Twin Delayed Deep Deterministic Policy Gradient
TES
Thermal Energy Storage
TRPO
Trust-Region Policy Optimization
resource expenditure, and risks associated with their behavior can be
managed through off-line, data-driven training. Newer RL algorithms
often include training Artificial Neural Networks (ANN) to output
desired actions or action values, showing improved performance [8–
10]. In contrast, Mania et al. [11] showed that the Augmented Random
Search (ARS) algorithm could achieve high performance with very
little computational resource expenditure by training a simple linear
function for action selection with their proposed search algorithm.
In this article we build on the work published in Opalic et al.
[12] where we showed that using ANNs for action selection together
with the ARS search algorithm improved the agent performance on a
BESS control problem. We now propose COST-WINNERS — a novel
approach to control, for the first time, both the BESS and TES of a smart
warehouse.
Specifically, our contributions in this paper are:
• We implement the ARS [11] RL algorithm, modified with ANNs to
encode the agent policy, to simultaneously control TES and BESS
energy storage systems.
• We build a data-driven simulated training environment, also mod-
eling the dynamics of the TES.
• Overall, we introduce a novel approach to control both the BESS
and TES of a smart warehouse simultaneously to reduce total
energy cost. This is important because combining different en-
ergy storage systems can lead to improved performance and cost
savings but also introduces new challenges due to each system’s
different dynamics and control requirements.
2. Related work
It was suggested in Xu and Shen [13] an algorithm for optimal
control of multiple ESSs using individual custom defined boundaries
for energy price. However, the study only features Battery Energy
Storage Systems (BESSs) and does not specify how to determine the
price boundaries for each system. Zhu et al. [14] examines decentral-
ized ESSs in urban railway applications and suggests multiagent deep
Reinforcement Learning (RL) for cooperative control using Q-learning
with recurrent ANNs. ANNs are also at the core of Model Predictive
Control (MPC) of TES developed by Cox et al. [15]. Zhang et al.
[16] propose Soft Actor-Critic (SAC, [17]) to optimize BESS control
with multiple energy production facilities. However, the authors have
not clarified if the experiment is based on more than a single 24-
hour episode and results are only compared with other simpler RL
algorithms. Goldsworthy et al. [18] have implemented a cloud-based
Model Predictive Control (MPC) battery control algorithm for energy
cost reduction at an office building. The system has been operational
for a year and achieved an energy cost reduction of 5.5%. Although
some of the related work show promising results, we were unable to
find any related work that examines advanced control algorithms for
energy cost optimization with multiple ESSs with different dynamics,
such as the BESS and TES in our smart warehouse.
2.1. Energy optimization in buildings
Similar to the Intelligent Energy Management System (IEMS) imple-
mented in the warehouse and described in our previous work Opalic
et al. [12], Sechilariu et al. [19] proposed Mixed Integer Linear Pro-
gramming (MILP) to optimize energy cost and power flow in a Direct
Current (DC) microgrid. Unlike the implemented smart warehouse
IEMS, it also features instant power balancing. A hybrid Model, sug-
gested by Huang et al. [20], uses MPC for energy cost optimization in a
case-study of an airport terminal. The authors suggest ANNs to account
for non-linearity. MPC using hierarchical MPCs to provide thermal
comfort and reduce energy cost was suggested in [21]. Smarra et al.
[22] propose a data-driven MPC, i.e., Data Predictive Control (DPC),
using a random forest algorithm for predictions, claiming that physical
models are impractical when considering the unique character and
complexity of building-related control systems. On the same line, Rätz
et al. [23] also explore data-driven energy system modeling for build-
ings using RL and MPC. For a twin BESS connected to a wind turbine
power plant, Wang et al. [24] suggest MPC. The authors assert greater
production dispatchability and increased battery life. To conclude, a
review study by Mariano-Hernández et al. [25] determined that the
most popular management technique in non-residential buildings is
MPC. They come to the conclusion that enabling intelligent control will
depend on the building modeling methodology.
2.2. Reinforcement learning
According to Sutton and Barto [26], RL is learning through discov-
ering which actions that increase a reward.
The operational concept of RL is often described as shown in Fig. 1.
An agent interacts with an environment, following its internal policy 𝜋,
by taking actions and receiving feedback from it as reward or penalty.
The policy typically gives the agent certain degrees of freedom to
choose actions that deviate from the strictest application of the policy.
This allows the agent to discover new states and actions that generate
higher reward, consequently updating its policy.
Well-known RL algorithms include Q-learning [27] and Deep Q-
Networks (DQN) [28]. The Q-learning algorithm maps each state to
the expected discounted future value of all the possible actions (Q-
value). In Q-learning, the agents’ policy is encoded in the Q-table, and
the deterministic version of it maximizes Q-value. DQN deploys a deep
ANN to compute the Q-values of available discrete actions given an
environment state.
The application of RL has been conducted in many different fields,
ranging from renewable energy to energy storage, and complex energy
systems. An example can be seen in Kuznetsova et al. [29]. The authors
developed a simulated microgrid, including a BESS and a wind turbine.
The methodology is based on Q-learning taking as inputs the BESS State
Of Charge (SOC), energy price, predictions of wind power production,
and energy consumption demand. The discrete action space includes
three possible BESS actions: charging, discharging, or none. Mbuwir
et al. [30] proposed fitted Q-iteration for transfer learning of BESS
control to and from systems with comparable properties. Wen et al.
 Journal of Energy Storage 72 (2023) 108202
3
S.M. Opalic et al.
Fig. 1. Interaction between agent and environment.
[31] suggest adopting Q-learning and end-user device utilization for
controlling load shifting in modest office and apartment buildings.
Additionally, Henze and Schoenmann [32] also used Q-learning for TES
control.
Perera and Kamalaruban [7] found that Q-learning is the most com-
mon use of RL techniques in the energy research area, even if simpler
algorithms are still deployed. Importantly, there are also attempts at
exploring state-of-the-art algorithms in the literature. Mocanu et al.
[33] propose Deep Policy Gradient (DPG), similar to DQN, for on–
off load shifting in the residential sector. Focusing on residential BESS
control, a variant of Deep Deterministic Policy Gradient (DDPG) [8] is
developed by Wan et al. [34]. Moreover, an improved DQN was imple-
mented also by Cao et al. [9] for BESS arbitrage. This algorithm takes
into account a lithium-ion battery degradation model, with discretized
action space for full or 50% capacity dynamics together with the stand-
by state. Shang et al. [10] combines DQN with bootstrapping and a
Monte Carlo tree search for BESS control in a microgrid. However,
in all cases except Wan et al. [34], the algorithms work in a discrete
domain, having limited action space. In addition, the reward functions
are generally complicated and experiment specific. Therefore, most of
the approaches mentioned are not ideal for large-scale implementation
of IEMS in a multitude of sites using RL.
Brandi et al. [35] explored control of a TES using online deep RL,
MPC and offline deep RL. For the online RL controller, energy cost
was increased by 160% for a four week period before it converged
to comparable behavior to the top performing MPC and offline RL
controllers. The study is limited to optimizing electricity cost incurred
by the chiller while disregarding overall building energy cost and
potential peak power cost.
Wang and Hong [36] conducted a survey of RL application to
control technical systems in buildings. The authors argue that estab-
lished techniques such as MPC requires extensive domain knowledge
to properly design and implement, making it less applicable in the
building control domain compared with mass production domains such
as the automobile industry. Furthermore, Wang and Hong [36] state
that RL combined with transfer learning should be further explored for
building control.
The authors in Xu et al. [37] propose a combination of RL with
differential evolution to reduce energy cost for industrial users with
solar power and thermal energy production, as well as BESS and TES,
while satisfying local energy demand and trading energy in an energy
trading platform.
2.3. Augmented random search
ARS is an optimization of what was named basic random search
by Mania et al. [11]. ARS is designed for continuous action space and
works with a strictly linear policy matrix, as opposed to other current
RL approaches. Moreover, exploration with the ARS is done directly in
Table 1
Main components of the smart warehouse energy system.
System
Characteristic value
Unit of measurement
Solar power plant
1000
[kW𝑝]
BESS
460/200
[kWh/kW]
TES
300/300a
[m3/kW𝑡ℎ𝑒𝑟𝑚𝑎𝑙]
Cooling plant
1140
[kW𝑡ℎ𝑒𝑟𝑚𝑎𝑙]
Electric boiler
500
[kW]
aAt 10 ◦K temperature difference.
Table 2
Thermal energy storage system characteristics.
Attribute
Values
Unit of measurement
Measurements
L × W × H - 12 × 10 × 2,5 [m]
Volume
300
[m3]
Average U-value
0.20
[
W
m2K ]
Ambient temperature
7
[◦C]
Storage medium
Water
N/A
Heat exchanger max flow
25
[ m3
h ]
Heat exchanger temperature loss 2
[◦K]
the parameters of the policy function. In comparison, algorithms such
as SAC [17], DDPG [8], TD3 [38], and Trust-Region Policy Optimiza-
tion (TRPO) [39], also operating in continuous action space, promote
action exploration with random noise added to the agents selected
action. In the ARS algorithm, random noise is generated and added
directly to the policy parameters and tested in the environment. The
rewards from 𝑁such tests, or rollouts, are then sorted in descending
order [11]. The top 𝑏directions are used to update the policy according
to
𝜃𝑗+1 = 𝜃𝑗+
𝛼
𝑏𝜎𝑅
𝑏
∑
𝑘=1
[𝑟(𝜋𝑗,(𝑘),+
) −𝑟(𝜋𝑗,(𝑘),−
)] 𝛿(𝑘),
(1)
where 𝜃represents the policy parameters, 𝛼represents the learning
rate, 𝜎𝑅is the reward standard deviation, 𝑟(𝜋𝑗,(𝑘),+) and 𝑟(𝜋𝑗,(𝑘),−) are
the rewards from rollouts and 𝛿(𝑘) is the random noise fitted in size
to 𝜃. Continuously updated mean and standard deviation of input
variables are used to normalize the inputs. Mania et al. [11] managed
to achieve outstanding performance while also drastically using less
computational resources when tested in a variety of well-known RL
benchmark problems.
3. Smart warehouse energy system
The energy system in the smart warehouse has previously been
described in detail in [12,40,41]. Table 1 lists its main components
and a scheme of it is visualized in Fig. 2. In this work we focus
mainly on describing the thermal components of the energy system,
and specifically the TES.
The main thermal components of the energy system are:
• the cooling plant with cooling energy distribution through evap-
orators based on direct expansion of carbon dioxide
• heat recovery from the cooling plant with hydronic heating en-
ergy distribution
• TES in an insulated firewater tank submerged in the ground.
• cooling for ventilation and server rooms with hydronic cooling
energy distribution
The physical characteristics of the tank are listed in Table 2. TES
specifications and model parameters are listed in Table 2. Additionally,
the energy system also features a BESS, described in detail in [12], that
is controlled simultaneously with the TES.
The TES is used to store both heating and cooling energy. Switching
between heating and cooling storage, on the other hand, incurs a
 Journal of Energy Storage 72 (2023) 108202
4
S.M. Opalic et al.
Fig. 2. The smart warehouse energy system with BESS, TES, cooling system and PV power plant. Arrows indicate the direction of energy flow.
significant cost due to the difference in operational temperature levels
of the heating and cooling distribution systems at 50 ◦C and 25 ◦C,
and 9 ◦C and 15 ◦C, respectively. Therefore, the TES is used only for
heat storage in winter and for cooling storage during summer. For the
remainder of this paper, we focus on the TES in heat storage mode.
Since the TES is located underground, the ambient temperature also
remains relatively stable and is modeled as a constant temperature.
Excess heat is recovered from the cooling plant and can either be
directly distributed to cover the warehouse heating demand or stored in
the TES, or both. Available excess heat depends on the cooling demand
of the refrigerated areas in the building and will vary proportionally
to the cooling work done by the cooling plant. If available heat is
not sufficient to cover the heating demand, the remaining demand
can either be met by discharging stored energy from the TES or by
producing heat with an electrical boiler. The boiler can produce heat
at an efficiency of around 0.9, whereas using excess heat from the
cooling plant only incurs a small cost based on various operating con-
ditions such as internal operating pressure, operational temperature,
external cooling demand, and ambient temperature. Recovering and
storing excess heat for later discharge can therefore be defined as a
time-dependent optimization problem for energy cost reduction.
An IEMS currently controls the on-site ESSs by applying machine
learning to predict load and PV solar panel production [42]. Addi-
tionally, an optimization algorithm calculates a two-day plan for the
BESS and a TES deployment. The local Building Management System
(BMS) implements the schedule and updates it hourly. The current
IEMS system does not react to live operational data. Every hour the
system calculates another two-day schedule, implementing the first
hour’s actions. Therefore, the system is very dependent on accurate pre-
dictions for maximum energy storage and cost reduction. Furthermore,
in this scenery, it is challenging to prevent excessive peak power load
costs. The magnitude of the challenge is only amplified if we take into
account the structure used for the monthly peak power tariff, by the
local grid operator: the entire monthly peak power cost is dependent
on the highest hourly peak of that month. It is clear then that combining
long-term planning with short-term reactions is a key strategy to benefit
from the ESS’ capability for peak power shaving.
4. Methodology
In this paper, we examine the applicability of the ARS-ANN RL
algorithm to a complex energy cost reduction problem through direct
control of BESS and TES charging and discharging setpoints in a
simulated case-study smart warehouse. Our main research goal is to
examine if the ARS-ANN algorithm can efficiently control multiple ESSs
with different dynamics and substantially varying degrees of impact
on energy cost. The agent is trained in a simulated environment of
the smart warehouse, which we mainly designed through the use of
data-driven techniques. We have emphasized the use of data-driven
techniques as a way to reduce the need for human expertise to design
the simulated environment and increase the practical utility of our
approach.
4.1. Simulated environment
We have built the simulated environment on operational data us-
ing linear and polynomial regression in order to make the simulated
environment accessible for result analysis. As this potentially decreases
the accuracy of the system model, one could consider building a more
accurate model of the environment using deep learning neural networks
in an operational scenario. The methodology described in [23] or
similar approaches would then be considered. The current version of
the simulated environment features an ensemble of models of energy
system components and dynamics.
We use a model for the thermal energy storage, production and
distribution featuring:
• The heat exchanger temperature loss.
• Temperature loss through heat conduction to surroundings.
• 4 vertical internal temperature levels.
Important components and dynamics of the models for the TES,
production, and distribution are the following:
• Operational data of TES charging and discharging compared to
setpoint.
• TES storage loss and internal temperature levels.
• Cooling plant electrical power consumption and recoverable ex-
cess heat.
A schematic of the TES is included in Fig. 3. The schematic shows
the TES in the bottom visualized as a rectangular prism. Physically,
the TES is a subterranean concrete basin, insulated on all sides with
 Journal of Energy Storage 72 (2023) 108202
5
S.M. Opalic et al.
Fig. 3. Thermal energy storage with valves for reversing direction of water flow.
perforated water pipes (1, 2) placed diagonally along opposite walls
within. This allows for an even distribution of water flowing into and
out of the thermal storage, consistent with a strategy of maintaining
water temperature layering inside the tank. The direction of water
flowing through the tank can be reversed using an arrangement of
four two-way valves (3–6). The TES is physically separated from the
main hydronic energy distribution systems by a heat exchanger (8).
The flow volume on the TES side of the heat exchanger is automatically
balanced with the main hydronic energy distribution system using flow
measurements and a frequency controlled pump (7). Our model of the
TES includes the ability to reverse the direction of the flow of water
such that hotter water is always added to or extracted from the top
of the tank and vice versa for colder water. We have not included a
model of the heat exchanger due to the physical system automatically
balancing volume flow on both sides of the heat exchanger and the
observed temperature loss in the heat exchanger is minimal. Modeling
the heat exchanger could possibly be considered for future work.
On the secondary side of the heat exchanger, the TES is connected to
the hydronic distribution system in two ways (not shown in the figure).
Firstly, the TES is connected in parallel with all the thermal heat loads
with a modulating two-way control valve that controls the charging
according to an external thermal power setpoint. Secondly, the TES
can be discharged by circulating the combined return flow through a
modulating three-way valve that also responds to an external thermal
power setpoint.
However, the dynamics of the hydronic heating system is compli-
cated. We have therefore examined TES operational data in response
to charging and discharging set points. The examination shows a high
degree of variation between the actual delivered and the requested
charge, as well as a non-linear relationship between charging and
discharging dynamics. Therefore, we chose to model charging and
discharging dynamics with two different functions, using more recent
operational data. Charging dynamic is shown in Fig. 4(a), while the dis-
charging dynamic is illustrated in Fig. 4(b). However, we provide a TES
action space balanced around the origin of [−100, +100] to the agent
interacting with the environment. Actions below 0.2 and above −0.2
are regarded as standby, or no-action. The 𝑅2 score for the charging
and discharging functions is 0.83 and 0.53, respectively. A qualitative
analysis of the figures highlight a larger spread in the data point for
the discharge function. Importantly, although the 𝑅2 for the discharge
function is rather low, the goal of this function is to have a simple and
explainable model of the TES while discharging. The variation in TES
discharging, related to the setpoint, is known to depend on a multitude
of other variables when considering a priori and empirical knowledge
of the hydronic heating system and is beyond the scope of this paper. A
more practical way to model the TES dynamic, with a higher degree of
accuracy, is likely through the use of ANN and multiple input variables.
Fig. 4. Requested TES action vs. actual response with polynomial function fit.
However, this would reduce model explainability, and it is not desirable
at the current stage.
In this article we have implemented the warehouse model described
in [40], and configured it to continuously calculate the refrigerant
mass flow in the cooling plants. We have fitted a linear regression
model, using pressure and mass flow of the refrigerant as inputs and
 Journal of Energy Storage 72 (2023) 108202
6
S.M. Opalic et al.
recoverable heat as output. Consequently, this model can be used to
find the recoverable heat upper bound at the maximum pressure of
80 bar and at any given refrigerant mass flow.
Moreover, we also model the electric consumption of the cooling
plant as a second order polynomial, using refrigerant mass flow and
heat recovered as inputs, and the electric consumption as output. The
R2 (R-Squared) score of the electric consumption function is 0.87, while
the RMSE is 11.17.
The cooling work, expressed as the refrigerant mass flow, represents
the limiting factor for the maximum heat that can be recovered. We
model this dynamic with a simple linear function, using as input
the refrigerant mass flow and returning as an output the maximum
recoverable heat.
Finally, there is a minimum amount of electrical energy required
by the cooling plant to keep the storage areas refrigerated. Also in this
case we chose a linear model using as input the refrigerant mass flow
and returning as an output the least required energy.
The following historical data sources were examined and used as
input for the smart warehouse model:
• Total power consumption and local power production.
• Cooling plant power consumption.
• Cooling plant mass flow [40].
• Heating demand.
• TES charging and discharging.
• Energy price for electrical energy bought from and sold to the
grid.
4.2. ARS with ANN
In [12], we implement a modified version of the ARS algorithm [11].
We deploy an ANN for policy parametrization in place of the linear
function proposed by Mania et al. [11], see Algorithm 1. We thereby
modify the processing of inputs to output from a linear to a nonlinear
function. More specifically, the ARS algorithm is used to train an ANN
to output actions for the TES and BESS with the input being the current
state of the environment. We take advantage of the functionality
for neural networks already implemented in the RLLIB programming
library. Refer to [12] for a detailed explanation of the implemented
solution. The algorithm in this article is based on the previously
suggested approach.
We use Pyomo [43,44], an open-source Python tool for optimization
modeling, with a GNU Linear Programming Kit (GNU Linear Pro-
gramming Kit (GLPK)) solver to calculate near-optimal solutions for
performance comparisons and benchmarking. We feed the GLPK solver
with all the information about the training scenario and it attempts
to find an optimal solution. However, due to the complex nature of
our energy system, we did not attempt to implement the TES in the
GLPK solver solution. We examined the operational data and found that
the electrical boiler had contributed very little to satisfying the heating
demand in the selected time period due to the fact that available excess
heat from the cooling system seemed to be sufficient. Reducing energy
consumption on the boiler is the main way that the TES can contribute
to lower electrical energy consumption during winter operation. We
argue that the impact of the TES on the energy cost in the time period
we pulled our operational data from is very limited. Adopting the
performance of the GLPK solver’s control of the BESS as a benchmark
is therefore still valid and useful.
5. Scenarios: Results and discussions
In this section, we investigate the application of the ARS-ANN
algorithm in a case-study smart warehouse, featuring both electrical
(BESS) and thermal (TES) energy storage systems. Therefore, we have
the opportunity of analyzing algorithm performance on a complex tem-
poral energy optimization problem. The objective of the algorithm is to
reduce energy cost by controlling charging and discharging setpoints of
both energy storage systems, BESS and TES.
Algorithm 1 Augmented Random Search with ANN.
1: Set hyperparameters:
• 𝛼- learning rate
• 𝑛- number of directions sampled per iteration
• 𝑣- exploration noise standard deviation
• 𝑏- number of top-performing directions to use
2: Run algorithm 2 to initialize policy parameters 𝜃𝑗, i.e. ANN
weights
3: Initialize:
• Mean - 𝜇0 = 0 ∈R𝑖𝑛𝑝𝑢𝑡𝑠
• Covariance - 𝛴0 = 𝐈𝑛∈R𝑖𝑛𝑝𝑢𝑡𝑠𝑥𝑖𝑛𝑝𝑢𝑡𝑠
4: while ending condition not satisfied do
5:
Sample 𝛿1, 𝛿2, ..., 𝛿𝑁of the same size as 𝜃𝑗, with i.i.d. standard
normal entries.
6:
Normalize input values 𝑥with 𝑥𝑛𝑜𝑟𝑚𝑎𝑙𝑖𝑧𝑒𝑑= 𝑑𝑖𝑎𝑔(𝛴𝑗)−1
2 (𝑥−𝜇𝑗).
Collect 2𝑁rollouts of horizon 𝐻and their corresponding rewards
using noise modified ANN policies 𝜋𝑗,𝑘,+ and 𝜋𝑗,𝑘,−, where the 𝑣𝛿𝑘
exploration noise is added to the weight parameters 𝜃𝑗of the ANN
for 𝜋𝑗,𝑘,+ and subtracted from 𝜃𝑗for 𝜋𝑗,𝑘,−with 𝑘∈{1, 2, ..., 𝑁}.
7:
Sort the directions 𝛿𝑘by max{𝑟(𝜋𝑗,𝑘,+), 𝑟(𝜋𝑗,𝑘,−)}, denote by
𝛿(𝑘) the 𝑘-th largest direction, and by 𝜋𝑗,(𝑘),+ and 𝜋𝑗,(𝑘),−the
corresponding policies.
8:
Make the update step for the ANN weights:
𝜃𝑗+1 = 𝜃𝑗+
𝛼
𝑏𝜎𝑅
∑𝑏
𝑘=1[𝑟(𝜋𝑗,𝑘,+) −𝑟(𝜋𝑗,𝑘,−)]𝛿𝑘, where the standard
deviation of the 2𝑏rewards for the policy update is 𝜎𝑅.
9:
Set the mean and covariance, 𝜇𝑗+1, 𝛴𝑗+1, of the 2𝑁𝐻(𝑗+ 1)
training states encountered.
10:
𝑗←𝑗+ 1.
11: end while
Algorithm 2 ANN for ARS in RLLIB.
1: Set hyperparameters:
• 𝜃ℎ𝑙- ANN hidden layers.
• 𝜃𝑛𝑢- number of neurons in each hidden layer.
• 𝜃𝑎𝑓- list of activation function for each layer.
2: Initialize: 𝑗= 0, policy parameters 𝜃𝑗of shape defined by 𝜃ℎ𝑙and
𝜃𝑛𝑢and random values 𝑋from 𝑁(𝜇𝜃, 𝜎2
𝜃) normal distribution of
mean 𝜇𝜃= 0 and variance 𝜎2
𝜃= 1, multiplied by standard deviation
𝜎= 1.0 for the hidden layers and 𝜎= 0.1 for the output, divided by
the square root of the random value 𝑋ℎ𝑙,𝑛𝑢, 𝜃ℎ𝑙,𝑛𝑢
𝑗
= 𝑋ℎ𝑙,𝑛𝑢
𝜎
√
𝑋.
5.1. Scenario I — proof of concept
In scenario I (i.e. first experiment), we apply the ARS-ANN agent to
control both BESS and TES for a random 48-hour episode. Our results
clearly indicate that the agent is able to find a near-optimal value for
BESS charging such that the peak power cost is reduced to a minimum.
Change in cooling plant electrical consumption due to control of the
TES is shown in Fig. 5, whereas total energy consumption and ESS
actions performed by the ARS-ANN agent are shown in Fig. 6. As we can
observe in Fig. 6 the maximum hourly energy consumption is flattened,
by utilization of the ESS, to around 512 kW, compensating for the
consumption peak at almost 600 kW that would occur in the baseline
consumption and contributing mainly in the reducing peak power tariff
cost.
The agent took advantage of the TES, when heating was required, to
reduce the electrical energy required by the cooling plant. It is relevant
to mention that the heating demand was very low during the random
episode used for experiment one. However, the ARS-ANN agent was
 Journal of Energy Storage 72 (2023) 108202
7
S.M. Opalic et al.
Fig. 5. Change in electrical energy consumption for the cooling system due to
ARS-ANN agent TES control.
Fig. 6. Total energy consumption and ARS-ANN agent ESS utilization in experiment
one.
Table 3
Results for 10 seeded trials for ARS-ANN vs GLPK — battery only.
Trial
GLPK — Battery only
ARS-ANN Result
Percent of GLPK
1
4910
5046
103%
2
7115
7106
100%
3
7540
7498
99%
4
298
361
121%
5
643
639
100%
6
7117
7109
100%
7
5861
5864
100%
8
3771
3780
100%
9
640
641
100%
10
6652
3233
49%
still able to find and store excess heat when there was no cost induced,
and then in turn used this to partially reduce electrical consumption by
discharging when necessary. Doing this, the agent was able to minimize
cooling system energy demand when heat was in demand.
5.2. Scenario II — seeded trials and benchmarking
To better quantify the performance of the ARS-ANN agent, we
compare it with a GLPK optimization solver in multiple seeded trials,
as well as benchmark it with other state-of-the-art RL algorithms. The
GLPK will be controlling solely the BESS, with perfect information, and
the comparison will be done for 10 seeded trials. Opposed to the GLPK,
the ARS-ANN agent will have control of both BESS and TES. We have
Table 4
Results for 10 seeded trials with state-of-the-art RL algorithms, compared as a
percentage to ARS-ANN results from Table 3.
Trial
SAC
TD3
Reward
Percentage ARS-ANN
Reward
Percentage ARS-ANN
1
13
0.3%
346
7%
2
7083
99.7%
290
4%
3
7147
95.3%
43
1%
4
141
39.1%
−62
−17%
5
86
13.4%
76
12%
6
1246
17.5%
305
4%
7
133
2.3%
55
1%
8
3772
99.8%
21
1%
9
728
113.5%
232
36%
10
691
21.4%
−338
−10%
decided that comparing performance to an optimization algorithm,
with perfect information, of simultaneous BESS and TES control is out
of the scope of this paper due to the complexity. Additionally, the
operational data used to pull random seeded trials is from early winter
where the potential cost reduction of optimal TES control is minor
compared with BESS control. There are two main reasons behind this
choice of time period. Firstly, this was the time period with the most
available data requiring minimal amounts of data cleaning. Secondly,
we decided that observing how the algorithm performs in controlling
multiple systems with vastly different impact on the result would be of
interest.
The results of the simulation are displayed in Table 3. We observe
that for the majority of the trials, the energy cost reduction of the
ARS-ANN with both BESS and TES control either meets or exceeds
the cost reduction of the GLPK with BESS control only. For trial 10,
the algorithm seems to get stuck in a local optima where it charges
the battery too aggressively on the first timestep. Additional research
is required to explore why this happens and how it can be avoided
in the future. In the 4th seeded trial we observe that the ARS-ANN
outperforms GLPK by 21%. In this trial, the potential of cost reduction
using the BESS is quite low due to a relatively low baseline peak power
cost. Finally, we compare results for the SAC and TD3 RL algorithms
to the ARS-ANN algorithm solution, shown in Table 4. In Table 4 the
results for SAC and TD3 are compared to the results for ARS-ANN from
Table 3. Here, we can observe that TD3 seems to get stuck around
original while SAC actually performs reasonably well and even exceeds
ARS-ANN in a single trial, finally achieving an average performance of
50% compared with ARS-ANN. However, on a reasonable time frame
of running the algorithms for about a week of training time on 6
GPU’s and 96 CPU’s, both SAC and TD3 achieved similar results. It
was only after increasing SAC training time, by a factor of 3, to a total
of more than 3 weeks that these results could be achieved. Also, the
SAC algorithm results were not stable in the sense that the performance
does not stabilize at a high performance. In fact, it drops off entirely in
most cases. The results in Table 4 include the maximum award achieved
during each training session.
We also ran the seeded trials for the original ARS algorithm to quan-
tify the improvement represented by ARS-ANN. The results showed
that ARS performed at an average of 68% compared to GLPK over
the 10 trials and hence was outperformed by ARS-ANN by almost 30
percentage points.
5.3. Discussion
In this paper, we examine the applicability of the ARS-ANN RL
algorithm to a complex energy cost reduction problem by direct control
of BESS and TES charging and discharging setpoints in a simulated
environment of an operational smart warehouse.
To evaluate our solution, we use a GLPK optimization solver, con-
trolling only a BESS, as a benchmark. We have decided not to include
the TES in the GLPK solver for two main reasons: (i) our initial
 Journal of Energy Storage 72 (2023) 108202
8
S.M. Opalic et al.
data analysis demonstrated a marginal impact of the TES, and (ii) its
complex thermal dynamics. We argue that for this work a GLPK solver
with BESS represents a sufficient approximation to a good solution. We
show that for nine out of ten of our seeded trials, the algorithm meets or
exceeds the performance of a GLPK optimization solver controlling the
BESS only, while given perfect information. For the single trial where
it only performs at around 50% of the GLPK, the algorithm seems to
get stuck in a local optimum which is to be further explored in future
research.
We also compare our solution to state-of-the-art RL algorithms,
showing an average of 100% performance increase compared to the
SAC algorithm. However, the SAC algorithm was able to match or
slightly exceed the performance of ARS-ANN in a few seeded trials
when SAC training time was increased by a factor of 3. Further, the
best results for SAC were not maintained as the training progressed,
meaning that the performance declined after briefly achieving the high-
est performance for each training session. These ‘‘sparks of brilliance’’
could perhaps be leveraged in some way in future research. It would be
of interest, for future work, to investigate possible solutions combining
ARS-ANN and SAC for managing BESS and TES.
It is essential to mention that, due to time constraints and a lack of
additional data, we only tested our approach in scenarios in which the
heating demand was limited. It would be of interest, in future studies, to
explore a broader landscape of scenarios, with higher heating demand,
to evaluate the general efficacy of the method.
6. Conclusions
We demonstrate that we are able to minimize energy cost in the
considered warehouse. We are able to model the dynamics of the TES
and to use it in combination with BESS, controlled simultaneously by
the ARS-ANN agent.
We demonstrate that by combining BESS and TES with the pre-
sented ARS-ANN agent, the agent was able to stabilize maximum
energy consumption and thereby reducing the peak power cost. Ad-
ditionally, the agent was able to exploit the TES when the heat was in
demand to reduce the required electrical energy consumption by the
cooling plant and electrical boiler.
To conclude, we propose a novel approach to control both the
BESS and TES of a smart warehouse simultaneously to reduce total
energy cost. This is important because combining different energy
storage systems can lead to improved performance and cost savings
but also introduces new challenges due to each system’s different
dynamics and control requirements. The results conclusively show that
ARS-ANN outperforms comparable RL algorithms, achieving similar
performance to an optimization algorithm controlling the BESS with
perfect information.
Declaration of competing interest
All authors declare there is no conflict of interest.
Data availability
The data that has been used is confidential.
Acknowledgment
This work is the result of a collaboration between the Relog AS and
University of Agder and it’s Centre for Artificial Intelligence Research
(CAIR). The work is also partially supported by the Norwegian Research
Council.
References
[1] IEA, World energy outlook 2021, 2021, https://www.iea.org/reports/world-
energy-outlook-2021.
[2] A.A. Kebede, T. Kalogiannis, J. Van Mierlo, M. Berecibar, A comprehensive
review of stationary energy storage devices for large scale renewable energy
sources grid integration, Renew. Sustain. Energy Rev. 159 (2022) 112213, http:
//dx.doi.org/10.1016/j.rser.2022.112213, URL https://www.sciencedirect.com/
science/article/pii/S1364032122001368.
[3] J. Buongiorno, J.E. Parsons, D.A. Petti, J. Parsons, The future of nuclear energy
in a carbon-constrained world, Mass. Inst. Technol. Energy Initiative (MITEI)
(2019).
[4] IEA,
Energy
efficiency
2020,
2020,
https://www.iea.org/reports/energy-
efficiency-2020.
[5] O. Palizban, K. Kauhaniemi, Energy storage systems in modern grids—Matrix of
technologies and applications, J. Energy Storage 6 (2016) 248–259, http://dx.
doi.org/10.1016/j.est.2016.02.001, URL https://www.sciencedirect.com/science/
article/pii/S2352152X1630010X.
[6] P.M. Bögel, P. Upham, H. Shahrokni, O. Kordas, What is needed for citizen-
centered urban energy transitions: Insights on attitudes towards decentralized
energy storage, Energy Policy 149 (2021) 112032.
[7] A. Perera, P. Kamalaruban, Applications of reinforcement learning in energy
systems, Renew. Sustain. Energy Rev. 137 (2021) 110618, http://dx.doi.org/10.
1016/j.rser.2020.110618,
URL
https://www.sciencedirect.com/science/article/
pii/S1364032120309023.
[8] T.P. Lillicrap, J.J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa, D. Silver, D.
Wierstra, Continuous control with deep reinforcement learning, 2015, arXiv:
1509.02971.
[9] J. Cao, D. Harrold, Z. Fan, T. Morstyn, D. Healey, K. Li, Deep reinforce-
ment learning-based energy storage arbitrage with accurate lithium-ion battery
degradation model, IEEE Trans. Smart Grid 11 (5) (2020) 4513–4521, http:
//dx.doi.org/10.1109/TSG.2020.2986333.
[10] Y. Shang, W. Wu, J. Guo, Z. Ma, W. Sheng, Z. Lv, C. Fu, Stochastic
dispatch of energy storage in microgrids: An augmented reinforcement learn-
ing approach, Appl. Energy 261 (2020) 114423, http://dx.doi.org/10.1016/j.
apenergy.2019.114423, URL https://www.sciencedirect.com/science/article/pii/
S0306261919321105.
[11] H. Mania, A. Guy, B. Recht, Simple random search provides a competitive
approach to reinforcement learning, 2018, arXiv:1803.07055.
[12] S.M. Opalic, M. Goodwin, L. Jiao, H.K. Nielsen, M.L. Kolhe, Augmented
random search with artificial neural networks for energy cost optimization
with battery control, J. Clean. Prod. (2022) 134676, http://dx.doi.org/10.1016/
j.jclepro.2022.134676, URL https://www.sciencedirect.com/science/article/pii/
S0959652622042482.
[13] Y. Xu, X. Shen, Optimal control based energy management of multiple energy
storage systems in a microgrid, IEEE Access 6 (2018) 32925–32934, http://dx.
doi.org/10.1109/ACCESS.2018.2845408.
[14] F. Zhu, Z. Yang, F. Lin, Y. Xin, Decentralized cooperative control of multiple
energy storage systems in urban railway based on multiagent deep reinforcement
learning, IEEE Trans. Power Electron. 35 (9) (2020) 9368–9379, http://dx.doi.
org/10.1109/TPEL.2020.2971637.
[15] S.J. Cox, D. Kim, H. Cho, P. Mago, Real time optimal control of district cooling
system with thermal energy storage using neural networks, Appl. Energy 238
(2019) 466–480, http://dx.doi.org/10.1016/j.apenergy.2019.01.093, URL https:
//www.sciencedirect.com/science/article/pii/S0306261919300911.
[16] B. Zhang, W. Hu, D. Cao, T. Li, Z. Zhang, Z. Chen, F. Blaabjerg, Soft actor-critic–
based multi-objective optimized energy conversion and management strategy for
integrated energy systems with renewable energy, Energy Convers. Manage. 243
(2021) 114381.
[17] T. Haarnoja, A. Zhou, P. Abbeel, S. Levine, Soft actor-critic: Off-policy maximum
entropy deep reinforcement learning with a stochastic actor, 2018, CoRR
abs/1801.01290 URL http://arxiv.org/abs/1801.01290.
[18] M. Goldsworthy, T. Moore, M. Peristy, M. Grimeland, Cloud-based model-
predictive-control of a battery storage system at a commercial site, Appl.
Energy 327 (2022) 120038, http://dx.doi.org/10.1016/j.apenergy.2022.120038,
URL https://www.sciencedirect.com/science/article/pii/S0306261922012958.
[19] M. Sechilariu, B.C. Wang, F. Locment, Supervision control for optimal energy cost
management in DC microgrid: Design and simulation, Int. J. Electr. Power Energy
Syst. 58 (2014) 140–149, http://dx.doi.org/10.1016/j.ijepes.2014.01.018, URL
https://www.sciencedirect.com/science/article/pii/S0142061514000313.
[20] H. Huang, L. Chen, E. Hu, A new model predictive control scheme for en-
ergy and cost savings in commercial buildings: An airport terminal building
case study, Build. Environ. 89 (2015) 203–216, http://dx.doi.org/10.1016/j.
buildenv.2015.01.037, URL https://www.sciencedirect.com/science/article/pii/
S0360132315000530.
[21] V. Lešić, A. Martinčević, M. Vašak, Modular energy cost optimization for
buildings with integrated microgrid, Appl. Energy 197 (2017) 14–28, http://dx.
doi.org/10.1016/j.apenergy.2017.03.087, URL https://www.sciencedirect.com/
science/article/pii/S0306261917303276.
 Journal of Energy Storage 72 (2023) 108202
9
S.M. Opalic et al.
[22] F. Smarra, A. Jain, T. de Rubeis, D. Ambrosini, A. D’Innocenzo, R. Mangharam,
Data-driven model predictive control using random forests for building energy
optimization and climate control, Appl. Energy 226 (2018) 1252–1272, http:
//dx.doi.org/10.1016/j.apenergy.2018.02.126, URL https://www.sciencedirect.
com/science/article/pii/S0306261918302575.
[23] M. Rätz, A.P. Javadi, M. Baranski, K. Finkbeiner, D. Müller, Automated data-
driven modeling of building energy systems via machine learning algorithms,
Energy Build. 202 (2019) 109384.
[24] B. Wang, G. Cai, D. Yang, Dispatching of a wind farm incorporated with dual-
battery energy storage system using model predictive control, IEEE Access 8
(2020) 144442–144452, http://dx.doi.org/10.1109/ACCESS.2020.3014214.
[25] D. Mariano-Hernández, L. Hernández-Callejo, A. Zorita-Lamadrid, O. Duque-
Pérez, F. Santos García, A review of strategies for building energy management
system: Model predictive control, demand side management, optimization, and
fault detect & diagnosis, J. Build. Eng. 33 (2021) 101692, http://dx.doi.org/10.
1016/j.jobe.2020.101692, URL https://www.sciencedirect.com/science/article/
pii/S2352710220310627.
[26] R.S. Sutton, A.G. Barto, Reinforcement Learning: An Introduction, second ed.,
The MIT Press, 2018, URL http://incompleteideas.net/book/the-book-2nd.html.
[27] C.J.C.H. Watkins, Learning from Delayed Rewards (Ph.D. thesis, Cambridge
University, Cambridge, England), King’s College, Cambridge United Kingdom,
1989.
[28] V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wierstra,
M.A. Riedmiller, Playing atari with deep reinforcement learning, 2013, CoRR
abs/1312.5602 URL http://arxiv.org/abs/1312.5602.
[29] E. Kuznetsova, Y.-F. Li, C. Ruiz, E. Zio, G. Ault, K. Bell, Reinforcement learning
for microgrid energy management, Energy 59 (2013) 133–146, http://dx.doi.
org/10.1016/j.energy.2013.05.060, URL http://www.sciencedirect.com/science/
article/pii/S0360544213004817.
[30] B.V. Mbuwir, F. Ruelens, F. Spiessens, G. Deconinck, Battery energy management
in a microgrid using batch reinforcement learning, Energies 10 (11) (2017) 1846.
[31] Z. Wen, D. O’Neill, H. Maei, Optimal demand response using device-based
reinforcement learning, IEEE Trans. Smart Grid 6 (5) (2015) 2312–2324.
[32] G.P. Henze, J. Schoenmann, Evaluation of reinforcement learning control
for
thermal
energy
storage
systems,
HVAC
R
Res.
9
(3)
(2003)
259–
275, http://dx.doi.org/10.1080/10789669.2003.10391069, arXiv:https://www.
tandfonline.com/doi/pdf/10.1080/10789669.2003.10391069 URL https://www.
tandfonline.com/doi/abs/10.1080/10789669.2003.10391069.
[33] E. Mocanu, D.C. Mocanu, P.H. Nguyen, A. Liotta, M.E. Webber, M. Gibescu,
J.G. Slootweg, On-line building energy optimization using deep reinforcement
learning, IEEE Trans. Smart Grid 10 (4) (2019) 3698–3708, http://dx.doi.org/
10.1109/TSG.2018.2834219.
[34] Z. Wan, H. Li, H. He, Residential energy management with deep reinforcement
learning, in: 2018 International Joint Conference on Neural Networks, IJCNN,
2018, pp. 1–7, http://dx.doi.org/10.1109/IJCNN.2018.8489210.
[35] S. Brandi, M. Fiorentini, A. Capozzoli, Comparison of online and offline
deep reinforcement learning with model predictive control for thermal energy
management, Autom. Constr. 135 (2022) 104128.
[36] Z. Wang, T. Hong, Reinforcement learning for building controls: The oppor-
tunities and challenges, Appl. Energy 269 (2020) 115036, http://dx.doi.org/
10.1016/j.apenergy.2020.115036, URL https://www.sciencedirect.com/science/
article/pii/S0306261920305481.
[37] Z. Xu, G. Han, L. Liu, M. Martínez-García, Z. Wang, Multi-energy scheduling of an
industrial integrated energy system by reinforcement learning-based differential
evolution, IEEE Trans. Green Commun. Netw. 5 (3) (2021) 1077–1090.
[38] S. Fujimoto, H. van Hoof, D. Meger, Addressing function approximation error
in actor-critic methods, 2018, CoRR abs/1802.09477 URL http://arxiv.org/abs/
1802.09477.
[39] J. Schulman, S. Levine, P. Moritz, M.I. Jordan, P. Abbeel, Trust region pol-
icy optimization, 2015, CoRR abs/1502.05477 URL http://arxiv.org/abs/1502.
05477.
[40] S.M. Opalic, M. Goodwin, L. Jiao, H.K. Nielsen, Á.Á. Pardiñas, A. Hafner,
M.L. Kolhe, ANN modelling of CO2 refrigerant cooling system COP in a smart
warehouse, J. Clean. Prod. 260 (2020) 120887, http://dx.doi.org/10.1016/
j.jclepro.2020.120887, URL https://www.sciencedirect.com/science/article/pii/
S0959652620309343.
[41] S.M. Opalic, M. Goodwin, L. Jiao, H.K. Nielsen, M. Lal Kolhe, A deep reinforce-
ment learning scheme for battery energy management, in: 2020 5th International
Conference on Smart and Sustainable Technologies, SpliTech, 2020, pp. 1–6,
http://dx.doi.org/10.23919/SpliTech49282.2020.9243797.
[42] G. Marton, et al., MIP in Demand Side Response (Master thesis), Gergely Marton,
2019.
[43] W.E.
Hart,
J.-P.
Watson,
D.L.
Woodruff,
Pyomo:
modeling
and
solving
mathematical programs in Python, Math. Program. Comput. 3 (3) (2011)
219–260.
[44] M.L. Bynum, G.A. Hackebeil, W.E. Hart, C.D. Laird, B.L. Nicholson, J.D. Siirola,
J.-P. Watson, D.L. Woodruff, Pyomo–Optimization Modeling in Python, Vol. 67,
third ed., Springer Science & Business Media, 2021.
",https://doi.org/10.1016/j.est.2023.108202,doc6,"Journal of Energy Storage 72 (2023) 108202 Available online 20 July 2023 2352-152X/ nc-nd/4.0/). Contents lists available at ScienceDirect Journal of Energy Storage journal homepage: www.elsevier.com/locate/est Research papers COST-WINNERS: COST reduction WIth Neural NEtworks-based augmented Random Search for simultaneous thermal and electrical energy storage control Sven Myrdahl Opalic a,b,c, Fabrizio Palumbo d, Morten Goodwin a, Lei Jiao a, Henrik Kofoed Nielsen b, Mohan Lal Kolhe b,∗ a Centre for Artificial Intelligence Research, University of Agder, 4879, Grimstad, Norway b Faculty of Engineering and Science, University of Agder, 4879, Grimstad, Norway c Relog AS, Kongens Gate 16, 7011, Trondheim, Norway d Oslo Metropolitan University, P.O. Box 4 St. Olavs plass, 0130, Oslo, Norway A R T I C L E I N F O Keywords: Reinforcement learning COST-WINNERS Thermal energy storage Multiple ESS control Smart warehouse A B S T R A C T The combination of local renewable energy production, dynamic loads, and multiple energy storage systems with different dynamics requires sophisticated control systems to maximize the energy cost efficiency of the combined energy system. Battery and thermal energy storage systems can be combined to increase the local use of on-site renewable energy, reduce peak power demand, and exploit time-of-use energy pricing. In this paper, we focus on how the augmented random search algorithm and artificial neural networks can be used together to solve an energy cost optimization problem involving the control of a battery energy storage system and a thermal energy storage system at the same time in a smart warehouse. As part of this work, a simulated training environment made using the data from the smart warehouse’s operations. In addition to the energy storage systems, the warehouse energy system has integrated a large roof mounted photovoltaic power plant and an industrial-scale cooling system. The developed solution is able to minimize the energy costs by modulating both energy systems, depending on the situation. Additionally, when it is tested against the state-of-the-art solutions, our developed solution at worst matches performance when the alternative algorithm is allowed to increase training time by a factor of nearly three. On average, our presented solution doubles the performance of the benchmark algorithm with much less computational resource expenditure. 1. Introduction The current state of global energy supply and demand highlights the need for controllable energy production and storage [1]. There is an increasing demand for robust and responsive electrical and thermal Energy Storage Systems (ESS) [2] as an increasing fraction of the world’s energy demand is met by wind and solar power at the expense of fossil-fueled and nuclear power [3]. The building sector represents a natural candidate to deploy an algorithm controlling renewable energy production and storage systems, as buildings are responsible for nearly 40% of global CO2 emissions [4]. Energy Storage Systems (ESS) can consist of various technologies and be applied in a multitude of ways [5]. From the perspective of the main electrical distribution grid, an important distinction exists between centralized and decentralized ESS. As opposed to decentralized ∗Corresponding author. E-mail addresses: sven.opalic@uia.no (S.M. Opalic), fabrizio@oslomet.no (F. Palumbo), morten.goodwin@uia.no (M. Goodwin), lei.jiao@uia.no (L. Jiao), henrik.kofoed.nielsen@uia.no (H.K. Nielsen), Mohan.L.Kolhe@uia.no (M.L. Kolhe). ESS, centralized systems can be directly controlled by the grid operator. However, decentralized ESSs are seen as an important component of a more environmentally friendly energy system, but they come with a new set of challenges [6]. The decentralized systems should monitor the energy market, integrate the control algorithm with market dynamics, and use it to reduce the peak load of the system while also minimizing the costs. In the case of multiple ESSs with different dynamics, such as a combination of a Battery Energy Storage System (BESS) and Thermal Energy Storage (TES), the complexity of the optimization problem further increases. One approach that is recently gaining a lot of interest in the sci- entific community as a robust and self-improving method to control building energy systems is Reinforcement Learning (RL) algorithms [7]. RL algorithms can reduce costs by reducing necessary human Received 20 December 2022; Received in revised form 2 June 2023; Accepted 26 June 2023 Journal of Energy Storage 72 (2023) 108202 2 S.M. Opalic et al. Nomenclature ANN Artificial Neural Network ARS Augmented Random Search BESS Battery Energy Storage System BMS Building Management System DC Direct Current DDPG Deep Deterministic Policy Gradient DPC Data Predictive Control DPG Deep Policy Gradient DQN Deep Q-Network ESS Energy Storage System GLPK GNU Linear Programming Kit IEMS Intelligent Energy Management System MILP Mixed Integer Linear Programming MPC Model Predictive Control RL Reinforcement Learning SAC Soft Actor-Critic SOC State Of Charge TD3 Twin Delayed Deep Deterministic Policy Gradient TES Thermal Energy Storage TRPO Trust-Region Policy Optimization resource expenditure, and risks associated with their behavior can be managed through off-line, data-driven training. Newer RL algorithms often include training Artificial Neural Networks (ANN) to output desired actions or action values, showing improved performance [8– 10]. In contrast, Mania et al. [11] showed that the Augmented Random Search (ARS) algorithm could achieve high performance with very little computational resource expenditure by training a simple linear function for action selection with their proposed search algorithm. In this article we build on the work published in Opalic et al. [12] where we showed that using ANNs for action selection together with the ARS search algorithm improved the agent performance on a BESS control problem. We now propose COST-WINNERS — a novel approach to control, for the first time, both the BESS and TES of a smart warehouse. Specifically, our contributions in this paper are: • We implement the ARS [11] RL algorithm, modified with ANNs to encode the agent policy, to simultaneously control TES and BESS energy storage systems. • We build a data-driven simulated training environment, also mod- eling the dynamics of the TES. • Overall, we introduce a novel approach to control both the BESS and TES of a smart warehouse simultaneously to reduce total energy cost. This is important because combining different en- ergy storage systems can lead to improved performance and cost savings but also introduces new challenges due to each system’s different dynamics and control requirements. 2. Related work It was suggested in Xu and Shen [13] an algorithm for optimal control of multiple ESSs using individual custom defined boundaries for energy price. However, the study only features Battery Energy Storage Systems (BESSs) and does not specify how to determine the price boundaries for each system. Zhu et al. [14] examines decentral- ized ESSs in urban railway applications and suggests multiagent deep Reinforcement Learning (RL) for cooperative control using Q-learning with recurrent ANNs. ANNs are also at the core of Model Predictive Control (MPC) of TES developed by Cox et al. [15]. Zhang et al. [16] propose Soft Actor-Critic (SAC, [17]) to optimize BESS control with multiple energy production facilities. However, the authors have not clarified if the experiment is based on more than a single 24- hour episode and results are only compared with other simpler RL algorithms. Goldsworthy et al. [18] have implemented a cloud-based Model Predictive Control (MPC) battery control algorithm for energy cost reduction at an office building. The system has been operational for a year and achieved an energy cost reduction of 5.5%. Although some of the related work show promising results, we were unable to find any related work that examines advanced control algorithms for energy cost optimization with multiple ESSs with different dynamics, such as the BESS and TES in our smart warehouse. 2.1. Energy optimization in buildings Similar to the Intelligent Energy Management System (IEMS) imple- mented in the warehouse and described in our previous work Opalic et al. [12], Sechilariu et al. [19] proposed Mixed Integer Linear Pro- gramming (MILP) to optimize energy cost and power flow in a Direct Current (DC) microgrid. Unlike the implemented smart warehouse IEMS, it also features instant power balancing. A hybrid Model, sug- gested by Huang et al. [20], uses MPC for energy cost optimization in a case-study of an airport terminal. The authors suggest ANNs to account for non-linearity. MPC using hierarchical MPCs to provide thermal comfort and reduce energy cost was suggested in [21]. Smarra et al. [22] propose a data-driven MPC, i.e., Data Predictive Control (DPC), using a random forest algorithm for predictions, claiming that physical models are impractical when considering the unique character and complexity of building-related control systems. On the same line, Rätz et al. [23] also explore data-driven energy system modeling for build- ings using RL and MPC. For a twin BESS connected to a wind turbine power plant, Wang et al. [24] suggest MPC. The authors assert greater production dispatchability and increased battery life. To conclude, a review study by Mariano-Hernández et al. [25] determined that the most popular management technique in non-residential buildings is MPC. They come to the conclusion that enabling intelligent control will depend on the building modeling methodology. 2.2. Reinforcement learning According to Sutton and Barto [26], RL is learning through discov- ering which actions that increase a reward. The operational concept of RL is often described as shown in Fig. 1. An agent interacts with an environment, following its internal policy 𝜋, by taking actions and receiving feedback from it as reward or penalty. The policy typically gives the agent certain degrees of freedom to choose actions that deviate from the strictest application of the policy. This allows the agent to discover new states and actions that generate higher reward, consequently updating its policy. Well-known RL algorithms include Q-learning [27] and Deep Q- Networks (DQN) [28]. The Q-learning algorithm maps each state to the expected discounted future value of all the possible actions (Q- value). In Q-learning, the agents’ policy is encoded in the Q-table, and the deterministic version of it maximizes Q-value. DQN deploys a deep ANN to compute the Q-values of available discrete actions given an environment state. The application of RL has been conducted in many different fields, ranging from renewable energy to energy storage, and complex energy systems. An example can be seen in Kuznetsova et al. [29]. The authors developed a simulated microgrid, including a BESS and a wind turbine. The methodology is based on Q-learning taking as inputs the BESS State Of Charge (SOC), energy price, predictions of wind power production, and energy consumption demand. The discrete action space includes three possible BESS actions: charging, discharging, or none. Mbuwir et al. [30] proposed fitted Q-iteration for transfer learning of BESS control to and from systems with comparable properties. Wen et al. Journal of Energy Storage 72 (2023) 108202 3 S.M. Opalic et al. Fig. 1. Interaction between agent and environment. [31] suggest adopting Q-learning and end-user device utilization for controlling load shifting in modest office and apartment buildings. Additionally, Henze and Schoenmann [32] also used Q-learning for TES control. Perera and Kamalaruban [7] found that Q-learning is the most com- mon use of RL techniques in the energy research area, even if simpler algorithms are still deployed. Importantly, there are also attempts at exploring state-of-the-art algorithms in the literature. Mocanu et al. [33] propose Deep Policy Gradient (DPG), similar to DQN, for on– off load shifting in the residential sector. Focusing on residential BESS control, a variant of Deep Deterministic Policy Gradient (DDPG) [8] is developed by Wan et al. [34]. Moreover, an improved DQN was imple- mented also by Cao et al. [9] for BESS arbitrage. This algorithm takes into account a lithium-ion battery degradation model, with discretized action space for full or 50% capacity dynamics together with the stand- by state. Shang et al. [10] combines DQN with bootstrapping and a Monte Carlo tree search for BESS control in a microgrid. However, in all cases except Wan et al. [34], the algorithms work in a discrete domain, having limited action space. In addition, the reward functions are generally complicated and experiment specific. Therefore, most of the approaches mentioned are not ideal for large-scale implementation of IEMS in a multitude of sites using RL. Brandi et al. [35] explored control of a TES using online deep RL, MPC and offline deep RL. For the online RL controller, energy cost was increased by 160% for a four week period before it converged to comparable behavior to the top performing MPC and offline RL controllers. The study is limited to optimizing electricity cost incurred by the chiller while disregarding overall building energy cost and potential peak power cost. Wang and Hong [36] conducted a survey of RL application to control technical systems in buildings. The authors argue that estab- lished techniques such as MPC requires extensive domain knowledge to properly design and implement, making it less applicable in the building control domain compared with mass production domains such as the automobile industry. Furthermore, Wang and Hong [36] state that RL combined with transfer learning should be further explored for building control. The authors in Xu et al. [37] propose a combination of RL with differential evolution to reduce energy cost for industrial users with solar power and thermal energy production, as well as BESS and TES, while satisfying local energy demand and trading energy in an energy trading platform. 2.3. Augmented random search ARS is an optimization of what was named basic random search by Mania et al. [11]. ARS is designed for continuous action space and works with a strictly linear policy matrix, as opposed to other current RL approaches. Moreover, exploration with the ARS is done directly in Table 1 Main components of the smart warehouse energy system. System Characteristic value Unit of measurement Solar power plant 1000 [kW𝑝] BESS 460/200 [kWh/kW] TES 300/300a [m3/kW𝑡ℎ𝑒𝑟𝑚𝑎𝑙] Cooling plant 1140 [kW𝑡ℎ𝑒𝑟𝑚𝑎𝑙] Electric boiler 500 [kW] aAt 10 ◦K temperature difference. Table 2 Thermal energy storage system characteristics. Attribute Values Unit of measurement Measurements L × W × H - 12 × 10 × 2,5 [m] Volume 300 [m3] Average U-value 0.20 [ W m2K ] Ambient temperature 7 [◦C] Storage medium Water N/A Heat exchanger max flow 25 [ m3 h ] Heat exchanger temperature loss 2 [◦K] the parameters of the policy function. In comparison, algorithms such as SAC [17], DDPG [8], TD3 [38], and Trust-Region Policy Optimiza- tion (TRPO) [39], also operating in continuous action space, promote action exploration with random noise added to the agents selected action. In the ARS algorithm, random noise is generated and added directly to the policy parameters and tested in the environment. The rewards from 𝑁such tests, or rollouts, are then sorted in descending order [11]. The top 𝑏directions are used to update the policy according to 𝜃𝑗+1 = 𝜃𝑗+ 𝛼 𝑏𝜎𝑅 𝑏 ∑ 𝑘=1 [𝑟(𝜋𝑗,(𝑘),+ ) −𝑟(𝜋𝑗,(𝑘),− )] 𝛿(𝑘), (1) where 𝜃represents the policy parameters, 𝛼represents the learning rate, 𝜎𝑅is the reward standard deviation, 𝑟(𝜋𝑗,(𝑘),+) and 𝑟(𝜋𝑗,(𝑘),−) are the rewards from rollouts and 𝛿(𝑘) is the random noise fitted in size to 𝜃. Continuously updated mean and standard deviation of input variables are used to normalize the inputs. Mania et al. [11] managed to achieve outstanding performance while also drastically using less computational resources when tested in a variety of well-known RL benchmark problems. 3. Smart warehouse energy system The energy system in the smart warehouse has previously been described in detail in [12,40,41]. Table 1 lists its main components and a scheme of it is visualized in Fig. 2. In this work we focus mainly on describing the thermal components of the energy system, and specifically the TES. The main thermal components of the energy system are: • the cooling plant with cooling energy distribution through evap- orators based on direct expansion of carbon dioxide • heat recovery from the cooling plant with hydronic heating en- ergy distribution • TES in an insulated firewater tank submerged in the ground. • cooling for ventilation and server rooms with hydronic cooling energy distribution The physical characteristics of the tank are listed in Table 2. TES specifications and model parameters are listed in Table 2. Additionally, the energy system also features a BESS, described in detail in [12], that is controlled simultaneously with the TES. The TES is used to store both heating and cooling energy. Switching between heating and cooling storage, on the other hand, incurs a Journal of Energy Storage 72 (2023) 108202 4 S.M. Opalic et al. Fig. 2. The smart warehouse energy system with BESS, TES, cooling system and PV power plant. Arrows indicate the direction of energy flow. significant cost due to the difference in operational temperature levels of the heating and cooling distribution systems at 50 ◦C and 25 ◦C, and 9 ◦C and 15 ◦C, respectively. Therefore, the TES is used only for heat storage in winter and for cooling storage during summer. For the remainder of this paper, we focus on the TES in heat storage mode. Since the TES is located underground, the ambient temperature also remains relatively stable and is modeled as a constant temperature. Excess heat is recovered from the cooling plant and can either be directly distributed to cover the warehouse heating demand or stored in the TES, or both. Available excess heat depends on the cooling demand of the refrigerated areas in the building and will vary proportionally to the cooling work done by the cooling plant. If available heat is not sufficient to cover the heating demand, the remaining demand can either be met by discharging stored energy from the TES or by producing heat with an electrical boiler. The boiler can produce heat at an efficiency of around 0.9, whereas using excess heat from the cooling plant only incurs a small cost based on various operating con- ditions such as internal operating pressure, operational temperature, external cooling demand, and ambient temperature. Recovering and storing excess heat for later discharge can therefore be defined as a time-dependent optimization problem for energy cost reduction. An IEMS currently controls the on-site ESSs by applying machine learning to predict load and PV solar panel production [42]. Addi- tionally, an optimization algorithm calculates a two-day plan for the BESS and a TES deployment. The local Building Management System (BMS) implements the schedule and updates it hourly. The current IEMS system does not react to live operational data. Every hour the system calculates another two-day schedule, implementing the first hour’s actions. Therefore, the system is very dependent on accurate pre- dictions for maximum energy storage and cost reduction. Furthermore, in this scenery, it is challenging to prevent excessive peak power load costs. The magnitude of the challenge is only amplified if we take into account the structure used for the monthly peak power tariff, by the local grid operator: the entire monthly peak power cost is dependent on the highest hourly peak of that month. It is clear then that combining long-term planning with short-term reactions is a key strategy to benefit from the ESS’ capability for peak power shaving. 4. Methodology In this paper, we examine the applicability of the ARS-ANN RL algorithm to a complex energy cost reduction problem through direct control of BESS and TES charging and discharging setpoints in a simulated case-study smart warehouse. Our main research goal is to examine if the ARS-ANN algorithm can efficiently control multiple ESSs with different dynamics and substantially varying degrees of impact on energy cost. The agent is trained in a simulated environment of the smart warehouse, which we mainly designed through the use of data-driven techniques. We have emphasized the use of data-driven techniques as a way to reduce the need for human expertise to design the simulated environment and increase the practical utility of our approach. 4.1. Simulated environment We have built the simulated environment on operational data us- ing linear and polynomial regression in order to make the simulated environment accessible for result analysis. As this potentially decreases the accuracy of the system model, one could consider building a more accurate model of the environment using deep learning neural networks in an operational scenario. The methodology described in [23] or similar approaches would then be considered. The current version of the simulated environment features an ensemble of models of energy system components and dynamics. We use a model for the thermal energy storage, production and distribution featuring: • The heat exchanger temperature loss. • Temperature loss through heat conduction to surroundings. • 4 vertical internal temperature levels. Important components and dynamics of the models for the TES, production, and distribution are the following: • Operational data of TES charging and discharging compared to setpoint. • TES storage loss and internal temperature levels. • Cooling plant electrical power consumption and recoverable ex- cess heat. A schematic of the TES is included in Fig. 3. The schematic shows the TES in the bottom visualized as a rectangular prism. Physically, the TES is a subterranean concrete basin, insulated on all sides with Journal of Energy Storage 72 (2023) 108202 5 S.M. Opalic et al. Fig. 3. Thermal energy storage with valves for reversing direction of water flow. perforated water pipes (1, 2) placed diagonally along opposite walls within. This allows for an even distribution of water flowing into and out of the thermal storage, consistent with a strategy of maintaining water temperature layering inside the tank. The direction of water flowing through the tank can be reversed using an arrangement of four two-way valves (3–6). The TES is physically separated from the main hydronic energy distribution systems by a heat exchanger (8). The flow volume on the TES side of the heat exchanger is automatically balanced with the main hydronic energy distribution system using flow measurements and a frequency controlled pump (7). Our model of the TES includes the ability to reverse the direction of the flow of water such that hotter water is always added to or extracted from the top of the tank and vice versa for colder water. We have not included a model of the heat exchanger due to the physical system automatically balancing volume flow on both sides of the heat exchanger and the observed temperature loss in the heat exchanger is minimal. Modeling the heat exchanger could possibly be considered for future work. On the secondary side of the heat exchanger, the TES is connected to the hydronic distribution system in two ways (not shown in the figure). Firstly, the TES is connected in parallel with all the thermal heat loads with a modulating two-way control valve that controls the charging according to an external thermal power setpoint. Secondly, the TES can be discharged by circulating the combined return flow through a modulating three-way valve that also responds to an external thermal power setpoint. However, the dynamics of the hydronic heating system is compli- cated. We have therefore examined TES operational data in response to charging and discharging set points. The examination shows a high degree of variation between the actual delivered and the requested charge, as well as a non-linear relationship between charging and discharging dynamics. Therefore, we chose to model charging and discharging dynamics with two different functions, using more recent operational data. Charging dynamic is shown in Fig. 4(a), while the dis- charging dynamic is illustrated in Fig. 4(b). However, we provide a TES action space balanced around the origin of [−100, +100] to the agent interacting with the environment. Actions below 0.2 and above −0.2 are regarded as standby, or no-action. The 𝑅2 score for the charging and discharging functions is 0.83 and 0.53, respectively. A qualitative analysis of the figures highlight a larger spread in the data point for the discharge function. Importantly, although the 𝑅2 for the discharge function is rather low, the goal of this function is to have a simple and explainable model of the TES while discharging. The variation in TES discharging, related to the setpoint, is known to depend on a multitude of other variables when considering a priori and empirical knowledge of the hydronic heating system and is beyond the scope of this paper. A more practical way to model the TES dynamic, with a higher degree of accuracy, is likely through the use of ANN and multiple input variables. Fig. 4. Requested TES action vs. actual response with polynomial function fit. However, this would reduce model explainability, and it is not desirable at the current stage. In this article we have implemented the warehouse model described in [40], and configured it to continuously calculate the refrigerant mass flow in the cooling plants. We have fitted a linear regression model, using pressure and mass flow of the refrigerant as inputs and Journal of Energy Storage 72 (2023) 108202 6 S.M. Opalic et al. recoverable heat as output. Consequently, this model can be used to find the recoverable heat upper bound at the maximum pressure of 80 bar and at any given refrigerant mass flow. Moreover, we also model the electric consumption of the cooling plant as a second order polynomial, using refrigerant mass flow and heat recovered as inputs, and the electric consumption as output. The R2 (R-Squared) score of the electric consumption function is 0.87, while the RMSE is 11.17. The cooling work, expressed as the refrigerant mass flow, represents the limiting factor for the maximum heat that can be recovered. We model this dynamic with a simple linear function, using as input the refrigerant mass flow and returning as an output the maximum recoverable heat. Finally, there is a minimum amount of electrical energy required by the cooling plant to keep the storage areas refrigerated. Also in this case we chose a linear model using as input the refrigerant mass flow and returning as an output the least required energy. The following historical data sources were examined and used as input for the smart warehouse model: • Total power consumption and local power production. • Cooling plant power consumption. • Cooling plant mass flow [40]. • Heating demand. • TES charging and discharging. • Energy price for electrical energy bought from and sold to the grid. 4.2. ARS with ANN In [12], we implement a modified version of the ARS algorithm [11]. We deploy an ANN for policy parametrization in place of the linear function proposed by Mania et al. [11], see Algorithm 1. We thereby modify the processing of inputs to output from a linear to a nonlinear function. More specifically, the ARS algorithm is used to train an ANN to output actions for the TES and BESS with the input being the current state of the environment. We take advantage of the functionality for neural networks already implemented in the RLLIB programming library. Refer to [12] for a detailed explanation of the implemented solution. The algorithm in this article is based on the previously suggested approach. We use Pyomo [43,44], an open-source Python tool for optimization modeling, with a GNU Linear Programming Kit (GNU Linear Pro- gramming Kit (GLPK)) solver to calculate near-optimal solutions for performance comparisons and benchmarking. We feed the GLPK solver with all the information about the training scenario and it attempts to find an optimal solution. However, due to the complex nature of our energy system, we did not attempt to implement the TES in the GLPK solver solution. We examined the operational data and found that the electrical boiler had contributed very little to satisfying the heating demand in the selected time period due to the fact that available excess heat from the cooling system seemed to be sufficient. Reducing energy consumption on the boiler is the main way that the TES can contribute to lower electrical energy consumption during winter operation. We argue that the impact of the TES on the energy cost in the time period we pulled our operational data from is very limited. Adopting the performance of the GLPK solver’s control of the BESS as a benchmark is therefore still valid and useful. 5. Scenarios: Results and discussions In this section, we investigate the application of the ARS-ANN algorithm in a case-study smart warehouse, featuring both electrical (BESS) and thermal (TES) energy storage systems. Therefore, we have the opportunity of analyzing algorithm performance on a complex tem- poral energy optimization problem. The objective of the algorithm is to reduce energy cost by controlling charging and discharging setpoints of both energy storage systems, BESS and TES. Algorithm 1 Augmented Random Search with ANN. 1: Set hyperparameters: • 𝛼- learning rate • 𝑛- number of directions sampled per iteration • 𝑣- exploration noise standard deviation • 𝑏- number of top-performing directions to use 2: Run algorithm 2 to initialize policy parameters 𝜃𝑗, i.e. ANN weights 3: Initialize: • Mean - 𝜇0 = 0 ∈R𝑖𝑛𝑝𝑢𝑡𝑠 • Covariance - 𝛴0 = 𝐈𝑛∈R𝑖𝑛𝑝𝑢𝑡𝑠𝑥𝑖𝑛𝑝𝑢𝑡𝑠 4: while ending condition not satisfied do 5: Sample 𝛿1, 𝛿2, ..., 𝛿𝑁of the same size as 𝜃𝑗, with i.i.d. standard normal entries. 6: Normalize input values 𝑥with 𝑥𝑛𝑜𝑟𝑚𝑎𝑙𝑖𝑧𝑒𝑑= 𝑑𝑖𝑎𝑔(𝛴𝑗)−1 2 (𝑥−𝜇𝑗). Collect 2𝑁rollouts of horizon 𝐻and their corresponding rewards using noise modified ANN policies 𝜋𝑗,𝑘,+ and 𝜋𝑗,𝑘,−, where the 𝑣𝛿𝑘 exploration noise is added to the weight parameters 𝜃𝑗of the ANN for 𝜋𝑗,𝑘,+ and subtracted from 𝜃𝑗for 𝜋𝑗,𝑘,−with 𝑘∈{1, 2, ..., 𝑁}. 7: Sort the directions 𝛿𝑘by max{𝑟(𝜋𝑗,𝑘,+), 𝑟(𝜋𝑗,𝑘,−)}, denote by 𝛿(𝑘) the 𝑘-th largest direction, and by 𝜋𝑗,(𝑘),+ and 𝜋𝑗,(𝑘),−the corresponding policies. 8: Make the update step for the ANN weights: 𝜃𝑗+1 = 𝜃𝑗+ 𝛼 𝑏𝜎𝑅 ∑𝑏 𝑘=1[𝑟(𝜋𝑗,𝑘,+) −𝑟(𝜋𝑗,𝑘,−)]𝛿𝑘, where the standard deviation of the 2𝑏rewards for the policy update is 𝜎𝑅. 9: Set the mean and covariance, 𝜇𝑗+1, 𝛴𝑗+1, of the 2𝑁𝐻(𝑗+ 1) training states encountered. 10: 𝑗←𝑗+ 1. 11: end while Algorithm 2 ANN for ARS in RLLIB. 1: Set hyperparameters: • 𝜃ℎ𝑙- ANN hidden layers. • 𝜃𝑛𝑢- number of neurons in each hidden layer. • 𝜃𝑎𝑓- list of activation function for each layer. 2: Initialize: 𝑗= 0, policy parameters 𝜃𝑗of shape defined by 𝜃ℎ𝑙and 𝜃𝑛𝑢and random values 𝑋from 𝑁(𝜇𝜃, 𝜎2 𝜃) normal distribution of mean 𝜇𝜃= 0 and variance 𝜎2 𝜃= 1, multiplied by standard deviation 𝜎= 1.0 for the hidden layers and 𝜎= 0.1 for the output, divided by the square root of the random value 𝑋ℎ𝑙,𝑛𝑢, 𝜃ℎ𝑙,𝑛𝑢 𝑗 = 𝑋ℎ𝑙,𝑛𝑢 𝜎 √ 𝑋. 5.1. Scenario I — proof of concept In scenario I (i.e. first experiment), we apply the ARS-ANN agent to control both BESS and TES for a random 48-hour episode. Our results clearly indicate that the agent is able to find a near-optimal value for BESS charging such that the peak power cost is reduced to a minimum. Change in cooling plant electrical consumption due to control of the TES is shown in Fig. 5, whereas total energy consumption and ESS actions performed by the ARS-ANN agent are shown in Fig. 6. As we can observe in Fig. 6 the maximum hourly energy consumption is flattened, by utilization of the ESS, to around 512 kW, compensating for the consumption peak at almost 600 kW that would occur in the baseline consumption and contributing mainly in the reducing peak power tariff cost. The agent took advantage of the TES, when heating was required, to reduce the electrical energy required by the cooling plant. It is relevant to mention that the heating demand was very low during the random episode used for experiment one. However, the ARS-ANN agent was Journal of Energy Storage 72 (2023) 108202 7 S.M. Opalic et al. Fig. 5. Change in electrical energy consumption for the cooling system due to ARS-ANN agent TES control. Fig. 6. Total energy consumption and ARS-ANN agent ESS utilization in experiment one. Table 3 Results for 10 seeded trials for ARS-ANN vs GLPK — battery only. Trial GLPK — Battery only ARS-ANN Result Percent of GLPK 1 4910 5046 103% 2 7115 7106 100% 3 7540 7498 99% 4 298 361 121% 5 643 639 100% 6 7117 7109 100% 7 5861 5864 100% 8 3771 3780 100% 9 640 641 100% 10 6652 3233 49% still able to find and store excess heat when there was no cost induced, and then in turn used this to partially reduce electrical consumption by discharging when necessary. Doing this, the agent was able to minimize cooling system energy demand when heat was in demand. 5.2. Scenario II — seeded trials and benchmarking To better quantify the performance of the ARS-ANN agent, we compare it with a GLPK optimization solver in multiple seeded trials, as well as benchmark it with other state-of-the-art RL algorithms. The GLPK will be controlling solely the BESS, with perfect information, and the comparison will be done for 10 seeded trials. Opposed to the GLPK, the ARS-ANN agent will have control of both BESS and TES. We have Table 4 Results for 10 seeded trials with state-of-the-art RL algorithms, compared as a percentage to ARS-ANN results from Table 3. Trial SAC TD3 Reward Percentage ARS-ANN Reward Percentage ARS-ANN 1 13 0.3% 346 7% 2 7083 99.7% 290 4% 3 7147 95.3% 43 1% 4 141 39.1% −62 −17% 5 86 13.4% 76 12% 6 1246 17.5% 305 4% 7 133 2.3% 55 1% 8 3772 99.8% 21 1% 9 728 113.5% 232 36% 10 691 21.4% −338 −10% decided that comparing performance to an optimization algorithm, with perfect information, of simultaneous BESS and TES control is out of the scope of this paper due to the complexity. Additionally, the operational data used to pull random seeded trials is from early winter where the potential cost reduction of optimal TES control is minor compared with BESS control. There are two main reasons behind this choice of time period. Firstly, this was the time period with the most available data requiring minimal amounts of data cleaning. Secondly, we decided that observing how the algorithm performs in controlling multiple systems with vastly different impact on the result would be of interest. The results of the simulation are displayed in Table 3. We observe that for the majority of the trials, the energy cost reduction of the ARS-ANN with both BESS and TES control either meets or exceeds the cost reduction of the GLPK with BESS control only. For trial 10, the algorithm seems to get stuck in a local optima where it charges the battery too aggressively on the first timestep. Additional research is required to explore why this happens and how it can be avoided in the future. In the 4th seeded trial we observe that the ARS-ANN outperforms GLPK by 21%. In this trial, the potential of cost reduction using the BESS is quite low due to a relatively low baseline peak power cost. Finally, we compare results for the SAC and TD3 RL algorithms to the ARS-ANN algorithm solution, shown in Table 4. In Table 4 the results for SAC and TD3 are compared to the results for ARS-ANN from Table 3. Here, we can observe that TD3 seems to get stuck around original while SAC actually performs reasonably well and even exceeds ARS-ANN in a single trial, finally achieving an average performance of 50% compared with ARS-ANN. However, on a reasonable time frame of running the algorithms for about a week of training time on 6 GPU’s and 96 CPU’s, both SAC and TD3 achieved similar results. It was only after increasing SAC training time, by a factor of 3, to a total of more than 3 weeks that these results could be achieved. Also, the SAC algorithm results were not stable in the sense that the performance does not stabilize at a high performance. In fact, it drops off entirely in most cases. The results in Table 4 include the maximum award achieved during each training session. We also ran the seeded trials for the original ARS algorithm to quan- tify the improvement represented by ARS-ANN. The results showed that ARS performed at an average of 68% compared to GLPK over the 10 trials and hence was outperformed by ARS-ANN by almost 30 percentage points. 5.3. Discussion In this paper, we examine the applicability of the ARS-ANN RL algorithm to a complex energy cost reduction problem by direct control of BESS and TES charging and discharging setpoints in a simulated environment of an operational smart warehouse. To evaluate our solution, we use a GLPK optimization solver, con- trolling only a BESS, as a benchmark. We have decided not to include the TES in the GLPK solver for two main reasons: (i) our initial Journal of Energy Storage 72 (2023) 108202 8 S.M. Opalic et al. data analysis demonstrated a marginal impact of the TES, and (ii) its complex thermal dynamics. We argue that for this work a GLPK solver with BESS represents a sufficient approximation to a good solution. We show that for nine out of ten of our seeded trials, the algorithm meets or exceeds the performance of a GLPK optimization solver controlling the BESS only, while given perfect information. For the single trial where it only performs at around 50% of the GLPK, the algorithm seems to get stuck in a local optimum which is to be further explored in future research. We also compare our solution to state-of-the-art RL algorithms, showing an average of 100% performance increase compared to the SAC algorithm. However, the SAC algorithm was able to match or slightly exceed the performance of ARS-ANN in a few seeded trials when SAC training time was increased by a factor of 3. Further, the best results for SAC were not maintained as the training progressed, meaning that the performance declined after briefly achieving the high- est performance for each training session. These ‘‘sparks of brilliance’’ could perhaps be leveraged in some way in future research. It would be of interest, for future work, to investigate possible solutions combining ARS-ANN and SAC for managing BESS and TES. It is essential to mention that, due to time constraints and a lack of additional data, we only tested our approach in scenarios in which the heating demand was limited. It would be of interest, in future studies, to explore a broader landscape of scenarios, with higher heating demand, to evaluate the general efficacy of the method. 6. Conclusions We demonstrate that we are able to minimize energy cost in the considered warehouse. We are able to model the dynamics of the TES and to use it in combination with BESS, controlled simultaneously by the ARS-ANN agent. We demonstrate that by combining BESS and TES with the pre- sented ARS-ANN agent, the agent was able to stabilize maximum energy consumption and thereby reducing the peak power cost. Ad- ditionally, the agent was able to exploit the TES when the heat was in demand to reduce the required electrical energy consumption by the cooling plant and electrical boiler. To conclude, we propose a novel approach to control both the BESS and TES of a smart warehouse simultaneously to reduce total energy cost. This is important because combining different energy storage systems can lead to improved performance and cost savings but also introduces new challenges due to each system’s different dynamics and control requirements. The results conclusively show that ARS-ANN outperforms comparable RL algorithms, achieving similar performance to an optimization algorithm controlling the BESS with perfect information. Declaration of competing interest All authors declare there is no conflict of interest. Data availability The data that has been used is confidential. Acknowledgment This work is the result of a collaboration between the Relog AS and University of Agder and it’s Centre for Artificial Intelligence Research (CAIR). The work is also partially supported by the Norwegian Research Council. References [1] IEA, World energy outlook 2021, 2021, energy-outlook-2021. [2] A.A. Kebede, T. Kalogiannis, J. Van Mierlo, M. Berecibar, A comprehensive review of stationary energy storage devices for large scale renewable energy sources grid integration, Renew. Sustain. Energy Rev. 159 (2022) 112213, http: //dx.doi.org/10.1016/j.rser.2022.112213, URL science/article/pii/S1364032122001368. [3] J. Buongiorno, J.E. Parsons, D.A. Petti, J. Parsons, The future of nuclear energy in a carbon-constrained world, Mass. Inst. Technol. Energy Initiative (MITEI) (2019). [4] IEA, Energy efficiency 2020, 2020, efficiency-2020. [5] O. Palizban, K. Kauhaniemi, Energy storage systems in modern grids—Matrix of technologies and applications, J. Energy Storage 6 (2016) 248–259, doi.org/10.1016/j.est.2016.02.001, URL article/pii/S2352152X1630010X. [6] P.M. Bögel, P. Upham, H. Shahrokni, O. Kordas, What is needed for citizen- centered urban energy transitions: Insights on attitudes towards decentralized energy storage, Energy Policy 149 (2021) 112032. [7] A. Perera, P. Kamalaruban, Applications of reinforcement learning in energy systems, Renew. Sustain. Energy Rev. 137 (2021) 110618, 1016/j.rser.2020.110618, URL pii/S1364032120309023. [8] T.P. Lillicrap, J.J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa, D. Silver, D. Wierstra, Continuous control with deep reinforcement learning, 2015, arXiv: 1509.02971. [9] J. Cao, D. Harrold, Z. Fan, T. Morstyn, D. Healey, K. Li, Deep reinforce- ment learning-based energy storage arbitrage with accurate lithium-ion battery degradation model, IEEE Trans. Smart Grid 11 (5) (2020) 4513–4521, http: //dx.doi.org/10.1109/TSG.2020.2986333. [10] Y. Shang, W. Wu, J. Guo, Z. Ma, W. Sheng, Z. Lv, C. Fu, Stochastic dispatch of energy storage in microgrids: An augmented reinforcement learn- ing approach, Appl. Energy 261 (2020) 114423, apenergy.2019.114423, URL S0306261919321105. [11] H. Mania, A. Guy, B. Recht, Simple random search provides a competitive approach to reinforcement learning, 2018, arXiv:1803.07055. [12] S.M. Opalic, M. Goodwin, L. Jiao, H.K. Nielsen, M.L. Kolhe, Augmented random search with artificial neural networks for energy cost optimization with battery control, J. Clean. Prod. (2022) 134676, j.jclepro.2022.134676, URL S0959652622042482. [13] Y. Xu, X. Shen, Optimal control based energy management of multiple energy storage systems in a microgrid, IEEE Access 6 (2018) 32925–32934, doi.org/10.1109/ACCESS.2018.2845408. [14] F. Zhu, Z. Yang, F. Lin, Y. Xin, Decentralized cooperative control of multiple energy storage systems in urban railway based on multiagent deep reinforcement learning, IEEE Trans. Power Electron. 35 (9) (2020) 9368–9379, org/10.1109/TPEL.2020.2971637. [15] S.J. Cox, D. Kim, H. Cho, P. Mago, Real time optimal control of district cooling system with thermal energy storage using neural networks, Appl. Energy 238 (2019) 466–480, URL https: //www.sciencedirect.com/science/article/pii/S0306261919300911. [16] B. Zhang, W. Hu, D. Cao, T. Li, Z. Zhang, Z. Chen, F. Blaabjerg, Soft actor-critic– based multi-objective optimized energy conversion and management strategy for integrated energy systems with renewable energy, Energy Convers. Manage. 243 (2021) 114381. [17] T. Haarnoja, A. Zhou, P. Abbeel, S. Levine, Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor, 2018, CoRR abs/1801.01290 URL [18] M. Goldsworthy, T. Moore, M. Peristy, M. Grimeland, Cloud-based model- predictive-control of a battery storage system at a commercial site, Appl. Energy 327 (2022) 120038, URL [19] M. Sechilariu, B.C. Wang, F. Locment, Supervision control for optimal energy cost management in DC microgrid: Design and simulation, Int. J. Electr. Power Energy Syst. 58 (2014) 140–149, URL [20] H. Huang, L. Chen, E. Hu, A new model predictive control scheme for en- ergy and cost savings in commercial buildings: An airport terminal building case study, Build. Environ. 89 (2015) 203–216, buildenv.2015.01.037, URL S0360132315000530. [21] V. Lešić, A. Martinčević, M. Vašak, Modular energy cost optimization for buildings with integrated microgrid, Appl. Energy 197 (2017) 14–28, doi.org/10.1016/j.apenergy.2017.03.087, URL science/article/pii/S0306261917303276. Journal of Energy Storage 72 (2023) 108202 9 S.M. Opalic et al. [22] F. Smarra, A. Jain, T. de Rubeis, D. Ambrosini, A. D’Innocenzo, R. Mangharam, Data-driven model predictive control using random forests for building energy optimization and climate control, Appl. Energy 226 (2018) 1252–1272, http: //dx.doi.org/10.1016/j.apenergy.2018.02.126, URL com/science/article/pii/S0306261918302575. [23] M. Rätz, A.P. Javadi, M. Baranski, K. Finkbeiner, D. Müller, Automated data- driven modeling of building energy systems via machine learning algorithms, Energy Build. 202 (2019) 109384. [24] B. Wang, G. Cai, D. Yang, Dispatching of a wind farm incorporated with dual- battery energy storage system using model predictive control, IEEE Access 8 (2020) 144442–144452, [25] D. Mariano-Hernández, L. Hernández-Callejo, A. Zorita-Lamadrid, O. Duque- Pérez, F. Santos García, A review of strategies for building energy management system: Model predictive control, demand side management, optimization, and fault detect & diagnosis, J. Build. Eng. 33 (2021) 101692, 1016/j.jobe.2020.101692, URL pii/S2352710220310627. [26] R.S. Sutton, A.G. Barto, Reinforcement Learning: An Introduction, second ed., The MIT Press, 2018, URL [27] C.J.C.H. Watkins, Learning from Delayed Rewards (Ph.D. thesis, Cambridge University, Cambridge, England), King’s College, Cambridge United Kingdom, 1989. [28] V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wierstra, M.A. Riedmiller, Playing atari with deep reinforcement learning, 2013, CoRR abs/1312.5602 URL [29] E. Kuznetsova, Y.-F. Li, C. Ruiz, E. Zio, G. Ault, K. Bell, Reinforcement learning for microgrid energy management, Energy 59 (2013) 133–146, org/10.1016/j.energy.2013.05.060, URL article/pii/S0360544213004817. [30] B.V. Mbuwir, F. Ruelens, F. Spiessens, G. Deconinck, Battery energy management in a microgrid using batch reinforcement learning, Energies 10 (11) (2017) 1846. [31] Z. Wen, D. O’Neill, H. Maei, Optimal demand response using device-based reinforcement learning, IEEE Trans. Smart Grid 6 (5) (2015) 2312–2324. [32] G.P. Henze, J. Schoenmann, Evaluation of reinforcement learning control for thermal energy storage systems, HVAC R Res. 9 (3) (2003) 259– 275, arXiv: tandfonline.com/doi/pdf/10.1080/10789669.2003.10391069 URL tandfonline.com/doi/abs/10.1080/10789669.2003.10391069. [33] E. Mocanu, D.C. Mocanu, P.H. Nguyen, A. Liotta, M.E. Webber, M. Gibescu, J.G. Slootweg, On-line building energy optimization using deep reinforcement learning, IEEE Trans. Smart Grid 10 (4) (2019) 3698–3708, 10.1109/TSG.2018.2834219. [34] Z. Wan, H. Li, H. He, Residential energy management with deep reinforcement learning, in: 2018 International Joint Conference on Neural Networks, IJCNN, 2018, pp. 1–7, [35] S. Brandi, M. Fiorentini, A. Capozzoli, Comparison of online and offline deep reinforcement learning with model predictive control for thermal energy management, Autom. Constr. 135 (2022) 104128. [36] Z. Wang, T. Hong, Reinforcement learning for building controls: The oppor- tunities and challenges, Appl. Energy 269 (2020) 115036, 10.1016/j.apenergy.2020.115036, URL article/pii/S0306261920305481. [37] Z. Xu, G. Han, L. Liu, M. Martínez-García, Z. Wang, Multi-energy scheduling of an industrial integrated energy system by reinforcement learning-based differential evolution, IEEE Trans. Green Commun. Netw. 5 (3) (2021) 1077–1090. [38] S. Fujimoto, H. van Hoof, D. Meger, Addressing function approximation error in actor-critic methods, 2018, CoRR abs/1802.09477 URL 1802.09477. [39] J. Schulman, S. Levine, P. Moritz, M.I. Jordan, P. Abbeel, Trust region pol- icy optimization, 2015, CoRR abs/1502.05477 URL 05477. [40] S.M. Opalic, M. Goodwin, L. Jiao, H.K. Nielsen, Á.Á. Pardiñas, A. Hafner, M.L. Kolhe, ANN modelling of CO2 refrigerant cooling system COP in a smart warehouse, J. Clean. Prod. 260 (2020) 120887, j.jclepro.2020.120887, URL S0959652620309343. [41] S.M. Opalic, M. Goodwin, L. Jiao, H.K. Nielsen, M. Lal Kolhe, A deep reinforce- ment learning scheme for battery energy management, in: 2020 5th International Conference on Smart and Sustainable Technologies, SpliTech, 2020, pp. 1–6, [42] G. Marton, et al., MIP in Demand Side Response (Master thesis), Gergely Marton, 2019. [43] W.E. Hart, J.-P. Watson, D.L. Woodruff, Pyomo: modeling and solving mathematical programs in Python, Math. Program. Comput. 3 (3) (2011) 219–260. [44] M.L. Bynum, G.A. Hackebeil, W.E. Hart, C.D. Laird, B.L. Nicholson, J.D. Siirola, J.-P. Watson, D.L. Woodruff, Pyomo–Optimization Modeling in Python, Vol. 67, third ed., Springer Science & Business Media, 2021."
Genetic Algorithms For Tightening Security,"Palumbo, Fabrizio and Buji, Adam and Yazidi, Anis and Haugerud, Hårek",2022,,,,inproceedings,"Genetic Algorithms For Tightening Security
1stFabrizio Palumbo
Artiﬁcial Intelligence Lab (AI Lab),
Institutt for informasjonsteknologi
Oslo Metropolitan University, Oslo, Norway
fabrizio@oslomet.no
2nd Adam Buji
Artiﬁcial Intelligence Lab (AI Lab),
Institutt for informasjonsteknologi
Oslo Metropolitan University, Oslo, Norway
Adam.buji@hotmail.no
3rd Anis Yazidi
Artiﬁcial Intelligence Lab (AI Lab),
Institutt for informasjonsteknologi
Oslo Metropolitan University, Oslo, Norway
Anis.Yazidi@oslomet.no
4th H˚arek Haugerud
Artiﬁcial Intelligence Lab (AI Lab),
Institutt for informasjonsteknologi
Oslo Metropolitan University, Oslo, Norway
Harek.Haugerud@oslomet.no
Abstract—Proper conﬁguration of operating systems and pro-
gram parameters is known to be a key security factor in order
to remove vulnerabilities. It is known that vulnerabilities can
be caused by a human misconﬁguration or by an improper
chain of parameter settings. It is impossible to ﬁnd an optimal
combination manually due to the enormous number of possible
conﬁgurations. In this article, we resort to a Genetic Algorithm
equipped with a user-deﬁned ﬁtness function in order to compute
a conﬁguration of high ﬁtness.
Our work presents a two-fold contribution. First, we suc-
cessfully use a GA to implement a moving target defense by
alerting the conﬁguration regularly in order to spoil an attacker’s
reconnaissance efforts. The GA tightens the security solution
by evolving the ﬁtness of the conﬁguration over generations
while maintaining diversity within generations across a pool of
servers. This resulted in high-quality conﬁgurations crucial for
a successful moving target defense strategy.
Second, we try to ﬁnd a compromise between tightening the
security of the conﬁguration and maintaining the Quality of
Service (QoS) on a web server. In practice, usually tightening
security on a web server comes at the cost of a decrease in QoS.
I. INTRODUCTION
A. Background
The last two decades of the 21st century experienced an in-
crease in the penetration and expansion of digital technologies.
With the decrease in Internet access’ costs and information
processing, more people are using computers and they expect
a quality of service (QoS) compatible with the QoS they are
used to getting with other utilities [1].
This service is expected to be available continuously, from
anywhere at any time, secure, friendly, and reliable. People
expect to log on to the terminal, read mails, make reservations,
and do other activities, and with wireless technology, people
can access the Internet from anywhere [1].
Web technologies have evolved rapidly in the last ﬁve
years through web-enabled applications where browsers have
become the user interface. Critical functions are done through
web applications, such as money transactions, which make
web applications attractive targets for hackers [2].
The system can therefore be made more difﬁcult to ex-
ploit with better awareness, stronger operating systems, and
improved security defense. There is a need for a better
understanding of web applications’ security since the attackers
have moved from attacking the network layer to attacking the
application layer [1].
Web applications use the HTTP protocol over the internet by
using a web browser which makes it possible to access web
applications from anywhere [3]. However, Web applications
have bugs in their code that make them vulnerable and they
can compromise the system. These vulnerabilities are greater
in web applications than in other applications.
More speciﬁcally, the operations in a software are controlled
by a set of parameters such as the settings of the operating
system or the ﬁle permissions. These parameters affect both
the operating system and the application performance and
have therefore implications for the security posture of the
system [4]. Some conﬁguration parameters affect the security
individually and some do in combination with others.
Many cyber attacks are preceded by a search for vulnerabili-
ties within the network, often caused by a network misconﬁgu-
ration. Such threats can therefore be eliminated by tuning the
correct combination of parameters. Some operating systems
offer solutions to prevent security vulnerabilities. However,
there is a need for a low-cost method to conﬁgure network
parameters in order to prevent and defuse cyber attacks.
Genetic Algorithms (GA), a class of heuristic searching
algorithms, are applied in this article to discover new, secure,
and diverse parameter conﬁgurations by modeling a computer
conﬁguration as chromosomes, and the individual settings
conﬁgurations as alleles. The basic idea behind GA is: good
chromosomes will generate better chromosomes through a
series of selection, crossover, and mutation processes. These
processes are stochastic, ensuring therefore a high degree
of diversity in the outputs. Additionally, a population of
chromosomes can then continuously evolve to become more
and more secure in the current environment.
To improve protection against cyber attacks, a continuous
change of computer or program parameters conﬁguration can
mislead the attacker. The GA will ideally have changed the
conﬁgurations before the attacker is able to launch his attack,
turning obsolete the previously discovered vulnerabilities.
ISBN 978-3-903176-52-2© 2022 IFIP
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
62
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 Therefore, GA can signiﬁcantly improve cyber security by
changing the parameters’ conﬁgurations and increasing their
ﬁtness score.
B. Previous Work
A crucial characteristic, that any cyber security defense
algorithm needs to posses, is the capability to adapt to new
emerging threats and depending on the situation to choose
the best reactive action possible. The concept of learning has
therefore been applied already in the earliest form of the
autonomous defense system, being inspired by reinforcement
learning algorithms [5] and from biology itself, taking as
examples the immune system [6] and the defensive mutualism
in microbial symbiosis [7]. However, also cyber attackers can
learn and adapt over time [8]. As a consequence traditional
static defense techniques (i.e. ﬁrewall) are not successful
anymore [9]. The moving target (MT) defense approach has
therefore emerged and proved successful in increasing network
security [9]–[13]. The overall concept of MT is the following:
the machine conﬁguration changes as a function of time so
that it is more complicated for an attacker to exploit previously
identiﬁed weak conﬁgurations. Importantly, deploying learning
algorithms within the MT strategy can improve drastically
security by learning over time what parameter conﬁgurations
are particularly susceptible to cyber attacks [9]–[13]. The idea
of deploying evolutionary algorithms in the moving target
defense was already introduced in the early 2010s [14]–[17].
GA can play a crucial role in identifying new solutions in the
parameters conﬁguration space that would be more and more
resilient to cyber-attacks over time. The Works of Smith [18]
and Zhou [19] show that an evolutionary strategy is a powerful
approach when defending against cyber-attacks. Smith ﬁrst
investigates the application of GA to learn secure parameter
conﬁgurations, also called chromosomes, and to implement
the moving target defense (MT) strategy. A computer’s ge-
netic code, or DNA, includes all the settings of all of its
parameters. GA then evolves, over iterations/generations, more
secure conﬁgurations which are then used to immunize the
machine to attacks. In his work, Smith [18] also implements
a beam search-based system to select which chromosomes
are inherited across generations. This approach outperformed
GA in increasing average conﬁguration ﬁtness while still
maintaining high diversity. Experimentation showed that a
prototype system using these strategies, for a small number
of attacks per generation, was often successful in creating a
new generation of chromosomes that were immune to attacks
from the previous generation [18] [19]. Additionally, it is also
introduced the idea that the efﬁciency of GA is improved by
using machine learning to classify generated solutions and
ﬁltering the sub-optimal low ﬁtness conﬁgurations [18] [19].
Software conﬁguration consists of parameters and through
them, it is possible to control aspects of the system. Therefore,
a misconﬁgured software, by a single parameter or a combina-
tion of parameters, exposes the system to vulnerabilities. The
huge number of parameters makes it hard to identify vulner-
able settings that can be attacked. Moreover, combinations of
settings might cause hidden vulnerabilities, complicating the
problem.
A ﬁrst solution to the problem exploits the identiﬁcation
of common features across vulnerable conﬁgurations. In her
Ph.D. thesis, Dr.Oddell [20] developed a method to detect
security-relevant parameters. By analyzing conﬁgurations that
are vulnerable to the same exploit and comparing the similarity
of their parameters it is possible to highlight the ones that are
vulnerable to a speciﬁc attack. Genetic Algorithms are then
used to generate the conﬁgurations used for the identiﬁcation
of vulnerable parameters.
Another approach is based on the time of the incorrect
function of a system, which can be caused by errors in its
conﬁguration. In [21], the authors address the problem of
diagnosing conﬁguration errors. For example, changing the
local ﬁrewall policy could cause a network-based application
to malfunction. This approach searches the time point at
which the system transitioned into malfunctioning. The cause
of the failure is then identiﬁed by comparing the system
conﬁguration before and after the malfunction. Whitaker et
al [21] implement a tool called Chronus to reduce the need
for human expertise. Chronus automates the search for failure-
inducing state changes and identiﬁes the conﬁguration errors.
However, this tool requires, among other utils, user-written
software to ﬁnd out if the system is currently working and
only then ﬁnds the error.
A ﬁnal approach is presented by Zhang et al. [22]
and it is implemented in the tool called EnCore. EnCore
detect software misconﬁguration by taking into account the
correlations between conﬁguration entries and their interaction
with the executing environment. Encore consists of four steps;
data collecting, data assembling, rule generator, and anomaly
detection. It is able to learn a broad set of conﬁguration
anomalies that span the entire system and detect real-world
problems as well as injected errors.
The work presented in this article builds on previous
research and aims to improve on its weaknesses as follow:
• By using real parameters for each conﬁguration, allowing
us to replicate possible machine misconﬁgurations lead-
ing to attack vulnerability.
• By directly simulate attackers targeting the system, al-
lowing us to directly test the security level.
II. METHODS
This article uses Apache v2.2 conﬁguration parameters as
deﬁned in STIG [23], which stands for Security Technical
Implementation Guides. The STIG was developed by The
Defense Information Systems Agency in order to implement
conﬁguration guidelines for systems that are deployed across
the Department of Defense. The scores are based on the CVSS
scoring system [24], according to the results of the test code.
In this article, a part of the Apache v2.2 conﬁguration was
used as proof of the GA concept and its capability of ﬁnding
the ﬁttest solution.
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
63
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 DiSA’s Security Technical Implementation Guides gather all
conﬁguration parameters that contribute to known vulnerabil-
ity attack paths.
STIG provides a network administrator with an explanation
on how these conﬁgurations can contribute to a vulnerability
and how it can be ﬁxed [23].
A. Genetic algorithm server
The chromosomes represent a conﬁguration’s combination
of parameters. The size of each chromosome is based on the
conﬁgurations’ parameters, where one allele or more represent
a parameter. In this research, the chromosome size is 25 and
the total number of chromosomes in one generation is 40,
which is enough to keep the parameters’ diversity according
to the number of parameters. The number of solutions in one
generation has been determined after many experiments of the
algorithm. It is possible to increase the number of chromo-
somes in one generation; this might increase the diversity, but
at the same time it would cost more computational resources.
All parameters are represented as a binary presentation, so
the parameter that needs to be integers is converted to integers
while converting the chromosomes into conﬁgurations. The
parameters represented as ”element from a list” are also
converted from binary to element from a list while converting
the chromosome into a conﬁguration.
Two algorithms have been developed and a total of four
scripts have been used.
• The genetic algorithm will generate security solutions.
• The ﬁtness score algorithm is responsible for providing
the genetic algorithm with the ﬁtness scores of the secu-
rity solutions. The scoring system relies on previous pref-
erences from STIG which provides the vulnerabilities, the
parameters responsible for them, and the solutions.
In the beginning, the ﬁrst chromosomes are initiated ran-
domly using a uniform distribution, and then saved to the
population’s pool.
In a Multi-point crossover, two or more random values
are selected and at these selected points, the variables are
exchanged between the individuals as shown in Figure 1.
Fig. 1. multi-points crossover
The experiments presented in Figure 2 and 3 show that
the multi-point crossover is more effective than the single-
point crossover because it increases the probability of the new
chromosomes getting the ﬁt parts of both parents [25].
If we consider the following two individuals with 10 binary
variables in each and the selected points are(4,7):
chromosome 1
0 1 1 0 →010→011
chromosome 2
0 0 1 0 →100→101
The generated new chromosomes would be:
chromosome 3
0 1 1 0 →100→011
chromosome 4
0 0 1 0 →010→101
Fig. 2. Single crossover
Fig. 3. Multi-point crossover
After executing the crossover function it is necessary to
run a mutation process in order to prevent the algorithm from
being trapped in a local minimum. The mutation is an operator
which maintains genetic diversity within the population. The
mutation process introduces a new genetic structure into the
population by modifying some of the alleles. [25].
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
64
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 In this article, binary representatives were used, so the
mutation process was done by ﬂipping a random allele in the
chromosome to the opposite value as shown in the following
example:
If we consider the following two individuals with 10 binary
variables in each and the selected allele location is 5:
chromosome 1
0 1 1 0 —0 — 1 0 0 1 1
In the mutation process, it would ﬂip the value from 0 to
1, so the generated new chromosome would be:
chromosome 2
0 1 1 0 —1 — 1 0 0 1 1
After executing the crossover and mutation process, the
algorithm divides the existing solutions in the population’s
pool between the available docker containers in the farm. This
is done to compute the ﬁtness scores and select the ﬁttest
solutions of the whole population. We then select the best n
solutions for further mating and to produce the next generation.
When the algorithm sends the solutions to the web servers,
it makes sure it sends them only to available web servers. It
checks their availability before sending the solutions in order
to avoid any future errors, and ensure that all the solutions are
tested as planned. After sending the solutions to VM’s farm,
the algorithm opens a port temporarily to receive the scores
for each solution. After receiving all the scores, the algorithm
selects the n ﬁttest solutions for further mating.
The algorithm runs 40 generations and the experiments
show that 40 generations are good enough to reach a solution
close to the optimal ﬁtness. However, the generation number
can be increased in case of the need to improve a more
complex chromosome to optimize the solution.
B. Reconﬁguring the Apache server
The Genetic Algorithm generates solutions and sends them
to the VMs farm which then applies those conﬁgurations to
the Apache server in order to execute the automated attacks.
The VM receives the solutions as a list and through an agent
script, it translates the list into conﬁgurations and then applies
them to the Apache server.
C. Quality of service
It is important to make sure that a good QoS is maintained
while tightening the security.
The QoS was measured by the total used time for the
following processes: Lookup time, Connect time, Pre-transfer
time, and Start-transfer time. The total used time was measured
by running the ”curl” command while pressing the web
server using ”httperf” on two web servers; one web server
with the ﬁttest conﬁguration, and another with a vulnerable
conﬁguration. The experiments on both web servers were done
under the same conditions which contain six load stress levels.
The experiment was run 10,000 tests/webpage requests on
each web server on every stress load level which makes it
60,000 tests/webpage requests in total on each web server,
where each level had a different load rate generated by httperf
tool, and is this explained in more detail later.
III. RESULTS
A. Security solutions
In this article we show experimentally, by using real pa-
rameter conﬁgurations and simulated cyber-attacks, that evolu-
tionary algorithms represent a powerful tool to improve cyber
security.
The experiments were conducted using conﬁgurations of 24
Apache 2.2 parameters.
We show that by using GA it is possible to improve system
security over the course of generations. Through iterations
of trial and error, we identify that the best performance was
achieved by:
• using a population size consisting of 50 individuals.
• running for 40-45 generations.
• One or two genes are modiﬁed in every mutation, using
elitism as the deterministic tournament selection, and
using a two-point crossover.
The start point solution was initialized randomly. In the
documented experiment, the initialized solution was 1035.2
when using a one-point crossover, and it was 1011.6 when
using a two-point crossover. The ﬁttest solution was 1490.0
when using a one-point crossover and 1584.2 when using a
two-point crossover as shown in Figure 4.
The experiment shows maintenance of diversity which is
required in order to ensure the solution space is checked
thoroughly enough, especially in the earlier stages of the
process. Population diversity is considered to be the main
reason for premature convergence.
The experiment also shows that the diversity was high in
the start and it became lower and lower in the later stages,
as shown in Figure 5. The results also show that crossover
types signiﬁcantly impacted ﬁtness or diversity in this article,
as shown in Figure 2 and Figure 3.
A high diversity in the population generates a different
solution from generation to generation implementing a moving
target defense. This results in wasting the attacker’s reconnais-
sance effort by changing the conﬁgurations continuously until
reaching the ﬁttest solution possible.
To quantify the impact of our approach on the QoS for the
user, we focus on the total time used between establishing a
connection and data transfer, as shown in 6. The mean value
of the total time of all test levels for the web server with
the ﬁttest conﬁguration was 0.004062783, while for the web
server with the vulnerable conﬁguration was 0.002006883.
Therefore, using the ﬁttest conﬁguration solution increase the
time necessary to send the requested page, compared to the
vulnerable solution.
B. Fitness score
This article investigates the role of the GA in improving
cyber security. We deﬁne a ﬁtness value for each chromosome,
as an estimate for security. Those values were then used to
select conﬁgurations with higher ﬁtness values.
The ﬁrst scores were decided according to randomly gen-
erated chromosomes, which varied from one experiment to
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
65
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 Fig. 4. Security solution’s evolving
Fig. 5. Diversity
another. Then, the GA performed the selection based on those
scores. Crossovers also used the same scores to decide which
chromosome moves forward, which are based on random
selection and affect the evolution process.
The mutation process took place after the crossover with
randomly selected candidates preventing the algorithm to fall
into local minima.
The scoring system was built over the course of three
experiments:
• An ofﬂine scoring system based on information from the
STIG database.
• An online-scoring system based on the OWASP vulner-
ability scanning
• Real-life attacks were executed on both the most vulner-
able solution and the ﬁttest solution
The GA successfully generated a more secure conﬁguration
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
66
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 Fig. 6. Security impact on QoS of webserver
that was not vulnerable to real-life attacks.
The QoS is an important factor to consider while improving
the security solution. The conducted experiment shows that
tightening the security does affect the QoS.
The experiment reported in Figure 6 and Table 1 shows a
signiﬁcantly longer time required for secure conﬁguration to
start transferring once a connection is established. The average
time used by the ﬁttest conﬁguration was 0.004062783, while
the average time used by the vulnerable conﬁguration was
0.002006883 which is a signiﬁcant difference.
Fittest
solution
Vulnerable
solution
Mean
0.004062783
0.002006883
Standard Deviation
0.004011096
0.001806554
Total tests
60000
60000
Variance
1.60889E-05
3.26364E-06
Table 1. Security impact on QoS of webserver
More investigation and experiments are required in the QoS
area to make a concrete analysis. Time constraints made it
impossible to conduct a more thorough investigation in this
article.
The total ﬁtness (100%) in this article was deﬁned as:
• the conﬁguration ﬁtness (70%)
• Moving target success (10%)
• the 2 attacks experiments’ success (10%)
• the QoS ﬁtness (10%)
The Conﬁguration’s ﬁtness was calculated according to the
expected highest ﬁtness (1700), and the ﬁttest solution was
1584.2. The moving target was calculated according to the
change in every ﬁve generations: a change in the conﬁguration
in every ﬁve generations is considered a ﬁnding. The 2attacks
score was deﬁned by the success or failure of the two
cyber attack strategies tested: Denial of service and buffer
overﬂow. The QoS ﬁtness was calculated according to how
many of the 60000 tests still got a comparable response time
between the case of the ﬁttest security solution and the case
of a vulnerable solution (<0.006s), which was 45620 in the
conducted experiments.
f(TFitness) =
!
ConfScore +
!
MovingTargetScore
+
!
2AttacksScore +
!
QoSScore
(1)
f(TFitness) = 65, 2 + 10 + 10 + 7.6
(2)
TotalFitness = 92.8%
(3)
IV. DISCUSSION
This article shows that GA can contribute to reducing sys-
tem vulnerabilities by detecting and solving misconﬁguration.
The GA evolves ﬁtter solutions within every iteration, reducing
vulnerabilities over generations.
Vulnerabilities caused by human misconﬁguration are hard
to ﬁnd manually, due to the huge number of parameters, and it
is even harder to ﬁnd the right chain of parameters. However,
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
67
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 GA can automate this process and provide more and more
accurate solutions over the course of generations.
The implemented algorithm aims to ﬁnd the ﬁttest conﬁg-
uration in Apache 2.2 server, ﬁxing the vulnerabilities caused
by human misconﬁguration. This algorithm can then replace
manual human work which is impossible to consider due to
time constrain.
The GA manages to reach the ﬁttest solution possible
through 40 generations, ﬁnding the correct parameters and the
correct chain of parameters.
The GA preserves diversity within each generation and
maintain a diverse solution from generation to generation. This
is particularly important since it can mislead an attacker that
has done reconnaissance between the generations.
A. Fitness
The main objective of this article is to reach the ﬁttest
solution through the use of GA. The ﬁtness function showed
ﬂexibility in a constantly changing environment. The ﬁtness
of the chromosome is based on a discovered security concern
that has been run through the penetration test. The test sends
back the security level of each chromosome with the goal to
reach as few vulnerabilities as possible.
The CVSS score of a parameter setting, which has been
used to score the security, is based on the effect it might cause
on information security such as conﬁdentiality, integrity, and
availability.
The scoring system starts with simulated attacks, based on
information from STIG. In the second step, the scoring system
is developed to run a vulnerability scanning using OWASP,
showing results close to the simulated attacks. Finally, the
security level is tested through real-life attacks, showing results
as expected.
B. Moving target
Implementing a moving target defense strategy is an ob-
jective of this article. It protects from attacks by changing
parameter conﬁgurations continuously, so in case the attacker
did his reconnaissance, it would be non-effective because
of the change in the conﬁguration. Diversity is therefore an
important factor during the evolution process to implement a
moving target defense within each generation.
Keeping the diversity of high-quality conﬁgurations is
important within the moving target strategy since different
conﬁgurations are applied on a number of machines.
The difference between the ﬁtness of two different solutions
in one generation represents the diversity within a generation.
The diversity from generation to generation is calculated by
looking at the differences between the ﬁttest solution in the
generation and the following generation.
In this article, the diversity is maintained across generations
which implements a moving target defense until the ﬁttest
solution possible is reached. This misleads an attacker in case
of conﬁguration reconnaissance. The diversity also prevented
the algorithm from falling into a local minimum, which helped
it to evolve the ﬁttest solution.
C. Quality of Service
Improving security is an important factor, but at the same
time, it should be parallel with having good QoS. In this
article, the QoS was investigated in order to see if there is any
noticeable relation between security and QoS. The conducted
experiments do show a negative impact on the QoS when
improving security, in terms of total used time between when a
connection was established and when the data actually began
to be transferred. The impact was measured while the web
server was under continuous stress of HTTP requests load. The
average used time, from starting the connection to starting the
data transfer, signiﬁcantly increase for server conﬁgurations
with tighter security.
V. CONCLUSION
The objective of this article is to improve the security so-
lutions by applying the genetic algorithm to the conﬁguration
parameters of Apache2.2. The genetic algorithm is applied
successfully allowing the conﬁgurations to evolve to be diverse
and more secure over generations. Additionally, this approach
also allows for a moving target defense by changing the
conﬁguration from generation to generation until reaching the
ﬁttest solution possible.
Vulnerabilities can be caused by a misconﬁguration or by
an unlucky chain of conﬁgurations. This is difﬁcult or even
impossible for the system administrator to discover manually
due to the huge amount of parameters, and big amount of
possible combinations. Therefore, a Genetic Algorithm was
used to ﬁnd more secure conﬁgurations. Conﬁgurations were
represented as chromosomes and the GA took those through
a series of selection, crossover, and mutation processes which
resulted in more secure conﬁgurations across each generation.
The results demonstrate the performance of the evolu-
tionary approach for managing conﬁgurations consisting of
24 parameters from Apache 2.2. The simulated attacks of
these conﬁgurations are based on information from the STIG
database. The genetic algorithm discovers better parameter
settings for the attacked parameters in each generation.
At the ﬁrst stages, the solution ﬁtness improves signiﬁcantly.
A reasonable level of diversity is maintained. It starts with a
high level of diversity because the parameters are randomly
initialized. In the late stages, the ﬁtness improvement decrease
alongside a decrease in diversity.
The experiment showed that the diversity within the gener-
ation maintained the ability to have a diverse conﬁguration
from generation to generation. Changing the conﬁguration
from generation to generation creates a moving target that
misleads an attacker based on reconnaissance.
In terms of security, this experiment demonstrates resilience.
As an added contribution of this paper, the genetic algo-
rithm manages to ﬁnd the ﬁttest solution possible, which helps
prevent attacks caused by a misconﬁguration or by a poor
chain of parameters. This is considered to be a new concept
in improving security.
As an added contribution of this paper, the genetic algo-
rithm helps prevent attacks by spoiling an attacker‘s recon-
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
68
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 naissance efforts by continuously changing the conﬁguration.
A series of changes in the conﬁguration from generation to
generation makes it possible to enhance security by deploying
a moving target defense.
As an added contribution of this paper, the investigation
of the relationship between security and QoS shows that the
security level has a signiﬁcant impact on the QoS. Improved
security results in a longer time delay between establishing
the connection and the start of data transfer. This might be
a reasonable price to pay for having a higher security level.
However, to be more concrete about the impact of this delay
on the QoS, it is recommended that further investigation -as
future work- covering other areas in QoS are conducted.
REFERENCES
[1] Y. Liao, V. Vemuri, Enhancing computer security with smart technology
(2006).
[2] A. Tsalgatidou, T. Pilioura, An overview of standards and related
technology in web services, Distributed and Parallel Databases 12 (2-3)
(2002) 135–162.
[3] R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P. Leach,
T. Berners-Lee, Hypertext transfer protocol–http/1.1, Tech. rep. (1999).
[4] J. Oberheide, E. Cooke, F. Jahanian, If it ain’t broke, don’t ﬁx it:
Challenges and new directions for inferring the impact of software
patches., in: HotOS, 2009.
[5] L. Beaudoin, Autonomic computer network defence using risk states
and reinforcement learning, 2009.
[6] S.
Hofmeyr,
S.
Forrest,
Architecture
for
an
artiﬁcial
immune
system,
Evolutionary
computation
8
(2000)
443–73.
doi:10.1162/106365600568257.
[7] S. Stolfo, Symbiotes and defensive Mutualism: Moving Target Defense,
2011, pp. 99–108. doi:10.1007/978-1-4614-0977-9 5.
[8] M. L. Winterrose, K. M. Carter, Strategic evolution of adversaries against
temporal platform diversity active cyber defenses, ADS ’14, Society for
Computer Simulation International, San Diego, CA, USA, 2014.
[9] E. W. Fulp, H. D. Gage, D. J. John, M. R. McNiece, W. H. Turkett,
X. Zhou, An evolutionary strategy for resilient cyber defense, in: 2015
IEEE Global Communications Conference (GLOBECOM), 2015, pp.
1–6. doi:10.1109/GLOCOM.2015.7417814.
[10] M. Carvalho, R. Ford, Moving-target defenses for computer networks,
IEEE Security Privacy 12 (2) (2014) 73–76. doi:10.1109/MSP.2014.30.
[11] P. Pal, R. Schantz, A. Paulos, B. Benyo, D. Johnson, M. Hibler, E. Eide,
A3: An environment for self-adaptive diagnosis and immunization of
novel attacks, in: 2012 IEEE Sixth International Conference on Self-
Adaptive and Self-Organizing Systems Workshops, 2012, pp. 15–22.
doi:10.1109/SASOW.2012.13.
[12] P. Pal, R. Schantz, A. Paulos, B. Benyo, Managed execution environment
as a moving-target defense infrastructure, IEEE Security Privacy 12 (2)
(2014) 51–59. doi:10.1109/MSP.2013.133.
[13] D.
J.
Musliner,
J.
M.
Rye,
D.
Thomsen,
D.
D.
McDonald,
M. H. Burstein, P. Robertson, Fuzzbuster: Towards adaptive immu-
nity from cyber threats, in: 2011 Fifth IEEE Conference on Self-
Adaptive and Self-Organizing Systems Workshops, 2011, pp. 137–140.
doi:10.1109/SASOW.2011.26.
[14] M. Crouse, E. W. Fulp, A moving target environment for computer
conﬁgurations using genetic algorithms, in: Conﬁguration Analytics and
Automation (SAFECONFIG), 2011 4th Symposium on, IEEE, 2011, pp.
1–7.
[15] M. Crouse, E. W. Fulp, D. Canas, Improving the diversity defense of
genetic algorithm-based moving target approaches, in: Proceedings of
the National Symposium on Moving Target Research, 2012.
[16] D. J. John, R. W. Smith, W. H. Turkett, D. A. Ca˜nas, E. W. Fulp,
Evolutionary based moving target cyber defense, in: Proceedings of
the Companion Publication of the 2014 Annual Conference on Genetic
and Evolutionary Computation, GECCO Comp ’14, Association for
Computing Machinery, New York, NY, USA, 2014, p. 1261–1268.
doi:10.1145/2598394.2605437.
URL https://doi.org/10.1145/2598394.2605437
[17] D. Zegzhda, D. Lavrova, E. Pavlenko, A. Shtyrkina, Cyber attack pre-
vention based on evolutionary cybernetics approach, Symmetry 12 (11).
doi:10.3390/sym12111931.
URL https://www.mdpi.com/2073-8994/12/11/1931
[18] R. W. Smith, Evolutionary strategies for secure moving target conﬁgu-
ration discovery, Ph.D. thesis, Wake Forest University (2014).
[19] X. Zhou, Measurements associated with learning more secure computer
conﬁguration parameters, Ph.D. thesis, Wake Forest University (2015).
[20] C. A. Odell, Using genetic algorithms to detect security related software
parameter chains, Ph.D. thesis, Wake Forest University (2016).
[21] A. Whitaker, R. S. Cox, S. D. Gribble, Conﬁguration debugging as
search: Finding the needle in the haystack., in: OSDI, Vol. 4, 2004,
pp. 6–6.
[22] J. Zhang, L. Renganarayana, X. Zhang, N. Ge, V. Bala, T. Xu, Y. Zhou,
Encore: Exploiting system environment and correlation information for
misconﬁguration detection, ACM SIGPLAN Notices 49 (4) (2014) 687–
700.
[23] [Accessed Mars. 08 2017] (Mars 2017). [link].
URL https://www.stigviewer.com/
[24] [link].
URL https://www.first.org/cvss/specification-document
[25] S. Sivanandam, S. Deepa, Introduction to genetic algorithms, Springer
Science & Business Media, 2007.
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
69
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
",10.23919/WMNC56391.2022.9954297,doc7,"Genetic Algorithms For Tightening Security 1stFabrizio Palumbo Artiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi Oslo Metropolitan University, Oslo, Norway fabrizio@oslomet.no 2nd Adam Buji Artiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi Oslo Metropolitan University, Oslo, Norway Adam.buji@hotmail.no 3rd Anis Yazidi Artiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi Oslo Metropolitan University, Oslo, Norway Anis.Yazidi@oslomet.no 4th H˚arek Haugerud Artiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi Oslo Metropolitan University, Oslo, Norway Harek.Haugerud@oslomet.no Abstract—Proper conﬁguration of operating systems and pro- gram parameters is known to be a key security factor in order to remove vulnerabilities. It is known that vulnerabilities can be caused by a human misconﬁguration or by an improper chain of parameter settings. It is impossible to ﬁnd an optimal combination manually due to the enormous number of possible conﬁgurations. In this article, we resort to a Genetic Algorithm equipped with a user-deﬁned ﬁtness function in order to compute a conﬁguration of high ﬁtness. Our work presents a two-fold contribution. First, we suc- cessfully use a GA to implement a moving target defense by alerting the conﬁguration regularly in order to spoil an attacker’s reconnaissance efforts. The GA tightens the security solution by evolving the ﬁtness of the conﬁguration over generations while maintaining diversity within generations across a pool of servers. This resulted in high-quality conﬁgurations crucial for a successful moving target defense strategy. Second, we try to ﬁnd a compromise between tightening the security of the conﬁguration and maintaining the Quality of Service (QoS) on a web server. In practice, usually tightening security on a web server comes at the cost of a decrease in QoS. I. INTRODUCTION A. Background The last two decades of the 21st century experienced an in- crease in the penetration and expansion of digital technologies. With the decrease in Internet access’ costs and information processing, more people are using computers and they expect a quality of service (QoS) compatible with the QoS they are used to getting with other utilities [1]. This service is expected to be available continuously, from anywhere at any time, secure, friendly, and reliable. People expect to log on to the terminal, read mails, make reservations, and do other activities, and with wireless technology, people can access the Internet from anywhere [1]. Web technologies have evolved rapidly in the last ﬁve years through web-enabled applications where browsers have become the user interface. Critical functions are done through web applications, such as money transactions, which make web applications attractive targets for hackers [2]. The system can therefore be made more difﬁcult to ex- ploit with better awareness, stronger operating systems, and improved security defense. There is a need for a better understanding of web applications’ security since the attackers have moved from attacking the network layer to attacking the application layer [1]. Web applications use the HTTP protocol over the internet by using a web browser which makes it possible to access web applications from anywhere [3]. However, Web applications have bugs in their code that make them vulnerable and they can compromise the system. These vulnerabilities are greater in web applications than in other applications. More speciﬁcally, the operations in a software are controlled by a set of parameters such as the settings of the operating system or the ﬁle permissions. These parameters affect both the operating system and the application performance and have therefore implications for the security posture of the system [4]. Some conﬁguration parameters affect the security individually and some do in combination with others. Many cyber attacks are preceded by a search for vulnerabili- ties within the network, often caused by a network misconﬁgu- ration. Such threats can therefore be eliminated by tuning the correct combination of parameters. Some operating systems offer solutions to prevent security vulnerabilities. However, there is a need for a low-cost method to conﬁgure network parameters in order to prevent and defuse cyber attacks. Genetic Algorithms (GA), a class of heuristic searching algorithms, are applied in this article to discover new, secure, and diverse parameter conﬁgurations by modeling a computer conﬁguration as chromosomes, and the individual settings conﬁgurations as alleles. The basic idea behind GA is: good chromosomes will generate better chromosomes through a series of selection, crossover, and mutation processes. These processes are stochastic, ensuring therefore a high degree of diversity in the outputs. Additionally, a population of chromosomes can then continuously evolve to become more and more secure in the current environment. To improve protection against cyber attacks, a continuous change of computer or program parameters conﬁguration can mislead the attacker. The GA will ideally have changed the conﬁgurations before the attacker is able to launch his attack, turning obsolete the previously discovered vulnerabilities. ISBN 978-3-903176-52-2© 2022 IFIP 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 62 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. Therefore, GA can signiﬁcantly improve cyber security by changing the parameters’ conﬁgurations and increasing their ﬁtness score. B. Previous Work A crucial characteristic, that any cyber security defense algorithm needs to posses, is the capability to adapt to new emerging threats and depending on the situation to choose the best reactive action possible. The concept of learning has therefore been applied already in the earliest form of the autonomous defense system, being inspired by reinforcement learning algorithms [5] and from biology itself, taking as examples the immune system [6] and the defensive mutualism in microbial symbiosis [7]. However, also cyber attackers can learn and adapt over time [8]. As a consequence traditional static defense techniques (i.e. ﬁrewall) are not successful anymore [9]. The moving target (MT) defense approach has therefore emerged and proved successful in increasing network security [9]–[13]. The overall concept of MT is the following: the machine conﬁguration changes as a function of time so that it is more complicated for an attacker to exploit previously identiﬁed weak conﬁgurations. Importantly, deploying learning algorithms within the MT strategy can improve drastically security by learning over time what parameter conﬁgurations are particularly susceptible to cyber attacks [9]–[13]. The idea of deploying evolutionary algorithms in the moving target defense was already introduced in the early 2010s [14]–[17]. GA can play a crucial role in identifying new solutions in the parameters conﬁguration space that would be more and more resilient to cyber-attacks over time. The Works of Smith [18] and Zhou [19] show that an evolutionary strategy is a powerful approach when defending against cyber-attacks. Smith ﬁrst investigates the application of GA to learn secure parameter conﬁgurations, also called chromosomes, and to implement the moving target defense (MT) strategy. A computer’s ge- netic code, or DNA, includes all the settings of all of its parameters. GA then evolves, over iterations/generations, more secure conﬁgurations which are then used to immunize the machine to attacks. In his work, Smith [18] also implements a beam search-based system to select which chromosomes are inherited across generations. This approach outperformed GA in increasing average conﬁguration ﬁtness while still maintaining high diversity. Experimentation showed that a prototype system using these strategies, for a small number of attacks per generation, was often successful in creating a new generation of chromosomes that were immune to attacks from the previous generation [18] [19]. Additionally, it is also introduced the idea that the efﬁciency of GA is improved by using machine learning to classify generated solutions and ﬁltering the sub-optimal low ﬁtness conﬁgurations [18] [19]. Software conﬁguration consists of parameters and through them, it is possible to control aspects of the system. Therefore, a misconﬁgured software, by a single parameter or a combina- tion of parameters, exposes the system to vulnerabilities. The huge number of parameters makes it hard to identify vulner- able settings that can be attacked. Moreover, combinations of settings might cause hidden vulnerabilities, complicating the problem. A ﬁrst solution to the problem exploits the identiﬁcation of common features across vulnerable conﬁgurations. In her Ph.D. thesis, Dr.Oddell [20] developed a method to detect security-relevant parameters. By analyzing conﬁgurations that are vulnerable to the same exploit and comparing the similarity of their parameters it is possible to highlight the ones that are vulnerable to a speciﬁc attack. Genetic Algorithms are then used to generate the conﬁgurations used for the identiﬁcation of vulnerable parameters. Another approach is based on the time of the incorrect function of a system, which can be caused by errors in its conﬁguration. In [21], the authors address the problem of diagnosing conﬁguration errors. For example, changing the local ﬁrewall policy could cause a network-based application to malfunction. This approach searches the time point at which the system transitioned into malfunctioning. The cause of the failure is then identiﬁed by comparing the system conﬁguration before and after the malfunction. Whitaker et al [21] implement a tool called Chronus to reduce the need for human expertise. Chronus automates the search for failure- inducing state changes and identiﬁes the conﬁguration errors. However, this tool requires, among other utils, user-written software to ﬁnd out if the system is currently working and only then ﬁnds the error. A ﬁnal approach is presented by Zhang et al. [22] and it is implemented in the tool called EnCore. EnCore detect software misconﬁguration by taking into account the correlations between conﬁguration entries and their interaction with the executing environment. Encore consists of four steps; data collecting, data assembling, rule generator, and anomaly detection. It is able to learn a broad set of conﬁguration anomalies that span the entire system and detect real-world problems as well as injected errors. The work presented in this article builds on previous research and aims to improve on its weaknesses as follow: • By using real parameters for each conﬁguration, allowing us to replicate possible machine misconﬁgurations lead- ing to attack vulnerability. • By directly simulate attackers targeting the system, al- lowing us to directly test the security level. II. METHODS This article uses Apache v2.2 conﬁguration parameters as deﬁned in STIG [23], which stands for Security Technical Implementation Guides. The STIG was developed by The Defense Information Systems Agency in order to implement conﬁguration guidelines for systems that are deployed across the Department of Defense. The scores are based on the CVSS scoring system [24], according to the results of the test code. In this article, a part of the Apache v2.2 conﬁguration was used as proof of the GA concept and its capability of ﬁnding the ﬁttest solution. 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 63 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. DiSA’s Security Technical Implementation Guides gather all conﬁguration parameters that contribute to known vulnerabil- ity attack paths. STIG provides a network administrator with an explanation on how these conﬁgurations can contribute to a vulnerability and how it can be ﬁxed [23]. A. Genetic algorithm server The chromosomes represent a conﬁguration’s combination of parameters. The size of each chromosome is based on the conﬁgurations’ parameters, where one allele or more represent a parameter. In this research, the chromosome size is 25 and the total number of chromosomes in one generation is 40, which is enough to keep the parameters’ diversity according to the number of parameters. The number of solutions in one generation has been determined after many experiments of the algorithm. It is possible to increase the number of chromo- somes in one generation; this might increase the diversity, but at the same time it would cost more computational resources. All parameters are represented as a binary presentation, so the parameter that needs to be integers is converted to integers while converting the chromosomes into conﬁgurations. The parameters represented as ”element from a list” are also converted from binary to element from a list while converting the chromosome into a conﬁguration. Two algorithms have been developed and a total of four scripts have been used. • The genetic algorithm will generate security solutions. • The ﬁtness score algorithm is responsible for providing the genetic algorithm with the ﬁtness scores of the secu- rity solutions. The scoring system relies on previous pref- erences from STIG which provides the vulnerabilities, the parameters responsible for them, and the solutions. In the beginning, the ﬁrst chromosomes are initiated ran- domly using a uniform distribution, and then saved to the population’s pool. In a Multi-point crossover, two or more random values are selected and at these selected points, the variables are exchanged between the individuals as shown in Figure 1. Fig. 1. multi-points crossover The experiments presented in Figure 2 and 3 show that the multi-point crossover is more effective than the single- point crossover because it increases the probability of the new chromosomes getting the ﬁt parts of both parents [25]. If we consider the following two individuals with 10 binary variables in each and the selected points are(4,7): chromosome 1 0 1 1 0 →010→011 chromosome 2 0 0 1 0 →100→101 The generated new chromosomes would be: chromosome 3 0 1 1 0 →100→011 chromosome 4 0 0 1 0 →010→101 Fig. 2. Single crossover Fig. 3. Multi-point crossover After executing the crossover function it is necessary to run a mutation process in order to prevent the algorithm from being trapped in a local minimum. The mutation is an operator which maintains genetic diversity within the population. The mutation process introduces a new genetic structure into the population by modifying some of the alleles. [25]. 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 64 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. In this article, binary representatives were used, so the mutation process was done by ﬂipping a random allele in the chromosome to the opposite value as shown in the following example: If we consider the following two individuals with 10 binary variables in each and the selected allele location is 5: chromosome 1 0 1 1 0 —0 — 1 0 0 1 1 In the mutation process, it would ﬂip the value from 0 to 1, so the generated new chromosome would be: chromosome 2 0 1 1 0 —1 — 1 0 0 1 1 After executing the crossover and mutation process, the algorithm divides the existing solutions in the population’s pool between the available docker containers in the farm. This is done to compute the ﬁtness scores and select the ﬁttest solutions of the whole population. We then select the best n solutions for further mating and to produce the next generation. When the algorithm sends the solutions to the web servers, it makes sure it sends them only to available web servers. It checks their availability before sending the solutions in order to avoid any future errors, and ensure that all the solutions are tested as planned. After sending the solutions to VM’s farm, the algorithm opens a port temporarily to receive the scores for each solution. After receiving all the scores, the algorithm selects the n ﬁttest solutions for further mating. The algorithm runs 40 generations and the experiments show that 40 generations are good enough to reach a solution close to the optimal ﬁtness. However, the generation number can be increased in case of the need to improve a more complex chromosome to optimize the solution. B. Reconﬁguring the Apache server The Genetic Algorithm generates solutions and sends them to the VMs farm which then applies those conﬁgurations to the Apache server in order to execute the automated attacks. The VM receives the solutions as a list and through an agent script, it translates the list into conﬁgurations and then applies them to the Apache server. C. Quality of service It is important to make sure that a good QoS is maintained while tightening the security. The QoS was measured by the total used time for the following processes: Lookup time, Connect time, Pre-transfer time, and Start-transfer time. The total used time was measured by running the ”curl” command while pressing the web server using ”httperf” on two web servers; one web server with the ﬁttest conﬁguration, and another with a vulnerable conﬁguration. The experiments on both web servers were done under the same conditions which contain six load stress levels. The experiment was run 10,000 tests/webpage requests on each web server on every stress load level which makes it 60,000 tests/webpage requests in total on each web server, where each level had a different load rate generated by httperf tool, and is this explained in more detail later. III. RESULTS A. Security solutions In this article we show experimentally, by using real pa- rameter conﬁgurations and simulated cyber-attacks, that evolu- tionary algorithms represent a powerful tool to improve cyber security. The experiments were conducted using conﬁgurations of 24 Apache 2.2 parameters. We show that by using GA it is possible to improve system security over the course of generations. Through iterations of trial and error, we identify that the best performance was achieved by: • using a population size consisting of 50 individuals. • running for 40-45 generations. • One or two genes are modiﬁed in every mutation, using elitism as the deterministic tournament selection, and using a two-point crossover. The start point solution was initialized randomly. In the documented experiment, the initialized solution was 1035.2 when using a one-point crossover, and it was 1011.6 when using a two-point crossover. The ﬁttest solution was 1490.0 when using a one-point crossover and 1584.2 when using a two-point crossover as shown in Figure 4. The experiment shows maintenance of diversity which is required in order to ensure the solution space is checked thoroughly enough, especially in the earlier stages of the process. Population diversity is considered to be the main reason for premature convergence. The experiment also shows that the diversity was high in the start and it became lower and lower in the later stages, as shown in Figure 5. The results also show that crossover types signiﬁcantly impacted ﬁtness or diversity in this article, as shown in Figure 2 and Figure 3. A high diversity in the population generates a different solution from generation to generation implementing a moving target defense. This results in wasting the attacker’s reconnais- sance effort by changing the conﬁgurations continuously until reaching the ﬁttest solution possible. To quantify the impact of our approach on the QoS for the user, we focus on the total time used between establishing a connection and data transfer, as shown in 6. The mean value of the total time of all test levels for the web server with the ﬁttest conﬁguration was 0.004062783, while for the web server with the vulnerable conﬁguration was 0.002006883. Therefore, using the ﬁttest conﬁguration solution increase the time necessary to send the requested page, compared to the vulnerable solution. B. Fitness score This article investigates the role of the GA in improving cyber security. We deﬁne a ﬁtness value for each chromosome, as an estimate for security. Those values were then used to select conﬁgurations with higher ﬁtness values. The ﬁrst scores were decided according to randomly gen- erated chromosomes, which varied from one experiment to 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 65 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. Fig. 4. Security solution’s evolving Fig. 5. Diversity another. Then, the GA performed the selection based on those scores. Crossovers also used the same scores to decide which chromosome moves forward, which are based on random selection and affect the evolution process. The mutation process took place after the crossover with randomly selected candidates preventing the algorithm to fall into local minima. The scoring system was built over the course of three experiments: • An ofﬂine scoring system based on information from the STIG database. • An online-scoring system based on the OWASP vulner- ability scanning • Real-life attacks were executed on both the most vulner- able solution and the ﬁttest solution The GA successfully generated a more secure conﬁguration 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 66 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. Fig. 6. Security impact on QoS of webserver that was not vulnerable to real-life attacks. The QoS is an important factor to consider while improving the security solution. The conducted experiment shows that tightening the security does affect the QoS. The experiment reported in Figure 6 and Table 1 shows a signiﬁcantly longer time required for secure conﬁguration to start transferring once a connection is established. The average time used by the ﬁttest conﬁguration was 0.004062783, while the average time used by the vulnerable conﬁguration was 0.002006883 which is a signiﬁcant difference. Fittest solution Vulnerable solution Mean 0.004062783 0.002006883 Standard Deviation 0.004011096 0.001806554 Total tests 60000 60000 Variance 1.60889E-05 3.26364E-06 Table 1. Security impact on QoS of webserver More investigation and experiments are required in the QoS area to make a concrete analysis. Time constraints made it impossible to conduct a more thorough investigation in this article. The total ﬁtness (100%) in this article was deﬁned as: • the conﬁguration ﬁtness (70%) • Moving target success (10%) • the 2 attacks experiments’ success (10%) • the QoS ﬁtness (10%) The Conﬁguration’s ﬁtness was calculated according to the expected highest ﬁtness (1700), and the ﬁttest solution was 1584.2. The moving target was calculated according to the change in every ﬁve generations: a change in the conﬁguration in every ﬁve generations is considered a ﬁnding. The 2attacks score was deﬁned by the success or failure of the two cyber attack strategies tested: Denial of service and buffer overﬂow. The QoS ﬁtness was calculated according to how many of the 60000 tests still got a comparable response time between the case of the ﬁttest security solution and the case of a vulnerable solution (<0.006s), which was 45620 in the conducted experiments. f(TFitness) = ! ConfScore + ! MovingTargetScore + ! 2AttacksScore + ! QoSScore (1) f(TFitness) = 65, 2 + 10 + 10 + 7.6 (2) TotalFitness = 92.8% (3) IV. DISCUSSION This article shows that GA can contribute to reducing sys- tem vulnerabilities by detecting and solving misconﬁguration. The GA evolves ﬁtter solutions within every iteration, reducing vulnerabilities over generations. Vulnerabilities caused by human misconﬁguration are hard to ﬁnd manually, due to the huge number of parameters, and it is even harder to ﬁnd the right chain of parameters. However, 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 67 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. GA can automate this process and provide more and more accurate solutions over the course of generations. The implemented algorithm aims to ﬁnd the ﬁttest conﬁg- uration in Apache 2.2 server, ﬁxing the vulnerabilities caused by human misconﬁguration. This algorithm can then replace manual human work which is impossible to consider due to time constrain. The GA manages to reach the ﬁttest solution possible through 40 generations, ﬁnding the correct parameters and the correct chain of parameters. The GA preserves diversity within each generation and maintain a diverse solution from generation to generation. This is particularly important since it can mislead an attacker that has done reconnaissance between the generations. A. Fitness The main objective of this article is to reach the ﬁttest solution through the use of GA. The ﬁtness function showed ﬂexibility in a constantly changing environment. The ﬁtness of the chromosome is based on a discovered security concern that has been run through the penetration test. The test sends back the security level of each chromosome with the goal to reach as few vulnerabilities as possible. The CVSS score of a parameter setting, which has been used to score the security, is based on the effect it might cause on information security such as conﬁdentiality, integrity, and availability. The scoring system starts with simulated attacks, based on information from STIG. In the second step, the scoring system is developed to run a vulnerability scanning using OWASP, showing results close to the simulated attacks. Finally, the security level is tested through real-life attacks, showing results as expected. B. Moving target Implementing a moving target defense strategy is an ob- jective of this article. It protects from attacks by changing parameter conﬁgurations continuously, so in case the attacker did his reconnaissance, it would be non-effective because of the change in the conﬁguration. Diversity is therefore an important factor during the evolution process to implement a moving target defense within each generation. Keeping the diversity of high-quality conﬁgurations is important within the moving target strategy since different conﬁgurations are applied on a number of machines. The difference between the ﬁtness of two different solutions in one generation represents the diversity within a generation. The diversity from generation to generation is calculated by looking at the differences between the ﬁttest solution in the generation and the following generation. In this article, the diversity is maintained across generations which implements a moving target defense until the ﬁttest solution possible is reached. This misleads an attacker in case of conﬁguration reconnaissance. The diversity also prevented the algorithm from falling into a local minimum, which helped it to evolve the ﬁttest solution. C. Quality of Service Improving security is an important factor, but at the same time, it should be parallel with having good QoS. In this article, the QoS was investigated in order to see if there is any noticeable relation between security and QoS. The conducted experiments do show a negative impact on the QoS when improving security, in terms of total used time between when a connection was established and when the data actually began to be transferred. The impact was measured while the web server was under continuous stress of HTTP requests load. The average used time, from starting the connection to starting the data transfer, signiﬁcantly increase for server conﬁgurations with tighter security. V. CONCLUSION The objective of this article is to improve the security so- lutions by applying the genetic algorithm to the conﬁguration parameters of Apache2.2. The genetic algorithm is applied successfully allowing the conﬁgurations to evolve to be diverse and more secure over generations. Additionally, this approach also allows for a moving target defense by changing the conﬁguration from generation to generation until reaching the ﬁttest solution possible. Vulnerabilities can be caused by a misconﬁguration or by an unlucky chain of conﬁgurations. This is difﬁcult or even impossible for the system administrator to discover manually due to the huge amount of parameters, and big amount of possible combinations. Therefore, a Genetic Algorithm was used to ﬁnd more secure conﬁgurations. Conﬁgurations were represented as chromosomes and the GA took those through a series of selection, crossover, and mutation processes which resulted in more secure conﬁgurations across each generation. The results demonstrate the performance of the evolu- tionary approach for managing conﬁgurations consisting of 24 parameters from Apache 2.2. The simulated attacks of these conﬁgurations are based on information from the STIG database. The genetic algorithm discovers better parameter settings for the attacked parameters in each generation. At the ﬁrst stages, the solution ﬁtness improves signiﬁcantly. A reasonable level of diversity is maintained. It starts with a high level of diversity because the parameters are randomly initialized. In the late stages, the ﬁtness improvement decrease alongside a decrease in diversity. The experiment showed that the diversity within the gener- ation maintained the ability to have a diverse conﬁguration from generation to generation. Changing the conﬁguration from generation to generation creates a moving target that misleads an attacker based on reconnaissance. In terms of security, this experiment demonstrates resilience. As an added contribution of this paper, the genetic algo- rithm manages to ﬁnd the ﬁttest solution possible, which helps prevent attacks caused by a misconﬁguration or by a poor chain of parameters. This is considered to be a new concept in improving security. As an added contribution of this paper, the genetic algo- rithm helps prevent attacks by spoiling an attacker‘s recon- 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 68 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. naissance efforts by continuously changing the conﬁguration. A series of changes in the conﬁguration from generation to generation makes it possible to enhance security by deploying a moving target defense. As an added contribution of this paper, the investigation of the relationship between security and QoS shows that the security level has a signiﬁcant impact on the QoS. Improved security results in a longer time delay between establishing the connection and the start of data transfer. This might be a reasonable price to pay for having a higher security level. However, to be more concrete about the impact of this delay on the QoS, it is recommended that further investigation -as future work- covering other areas in QoS are conducted. REFERENCES [1] Y. Liao, V. Vemuri, Enhancing computer security with smart technology (2006). [2] A. Tsalgatidou, T. Pilioura, An overview of standards and related technology in web services, Distributed and Parallel Databases 12 (2-3) (2002) 135–162. [3] R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P. Leach, T. Berners-Lee, Hypertext transfer protocol–http/1.1, Tech. rep. (1999). [4] J. Oberheide, E. Cooke, F. Jahanian, If it ain’t broke, don’t ﬁx it: Challenges and new directions for inferring the impact of software patches., in: HotOS, 2009. [5] L. Beaudoin, Autonomic computer network defence using risk states and reinforcement learning, 2009. [6] S. Hofmeyr, S. Forrest, Architecture for an artiﬁcial immune system, Evolutionary computation 8 (2000) 443–73. doi:10.1162/106365600568257. [7] S. Stolfo, Symbiotes and defensive Mutualism: Moving Target Defense, 2011, pp. 99–108. doi:10.1007/978-1-4614-0977-9 5. [8] M. L. Winterrose, K. M. Carter, Strategic evolution of adversaries against temporal platform diversity active cyber defenses, ADS ’14, Society for Computer Simulation International, San Diego, CA, USA, 2014. [9] E. W. Fulp, H. D. Gage, D. J. John, M. R. McNiece, W. H. Turkett, X. Zhou, An evolutionary strategy for resilient cyber defense, in: 2015 IEEE Global Communications Conference (GLOBECOM), 2015, pp. 1–6. doi:10.1109/GLOCOM.2015.7417814. [10] M. Carvalho, R. Ford, Moving-target defenses for computer networks, IEEE Security Privacy 12 (2) (2014) 73–76. doi:10.1109/MSP.2014.30. [11] P. Pal, R. Schantz, A. Paulos, B. Benyo, D. Johnson, M. Hibler, E. Eide, A3: An environment for self-adaptive diagnosis and immunization of novel attacks, in: 2012 IEEE Sixth International Conference on Self- Adaptive and Self-Organizing Systems Workshops, 2012, pp. 15–22. doi:10.1109/SASOW.2012.13. [12] P. Pal, R. Schantz, A. Paulos, B. Benyo, Managed execution environment as a moving-target defense infrastructure, IEEE Security Privacy 12 (2) (2014) 51–59. doi:10.1109/MSP.2013.133. [13] D. J. Musliner, J. M. Rye, D. Thomsen, D. D. McDonald, M. H. Burstein, P. Robertson, Fuzzbuster: Towards adaptive immu- nity from cyber threats, in: 2011 Fifth IEEE Conference on Self- Adaptive and Self-Organizing Systems Workshops, 2011, pp. 137–140. doi:10.1109/SASOW.2011.26. [14] M. Crouse, E. W. Fulp, A moving target environment for computer conﬁgurations using genetic algorithms, in: Conﬁguration Analytics and Automation (SAFECONFIG), 2011 4th Symposium on, IEEE, 2011, pp. 1–7. [15] M. Crouse, E. W. Fulp, D. Canas, Improving the diversity defense of genetic algorithm-based moving target approaches, in: Proceedings of the National Symposium on Moving Target Research, 2012. [16] D. J. John, R. W. Smith, W. H. Turkett, D. A. Ca˜nas, E. W. Fulp, Evolutionary based moving target cyber defense, in: Proceedings of the Companion Publication of the 2014 Annual Conference on Genetic and Evolutionary Computation, GECCO Comp ’14, Association for Computing Machinery, New York, NY, USA, 2014, p. 1261–1268. doi:10.1145/2598394.2605437. URL [17] D. Zegzhda, D. Lavrova, E. Pavlenko, A. Shtyrkina, Cyber attack pre- vention based on evolutionary cybernetics approach, Symmetry 12 (11). doi:10.3390/sym12111931. URL [18] R. W. Smith, Evolutionary strategies for secure moving target conﬁgu- ration discovery, Ph.D. thesis, Wake Forest University (2014). [19] X. Zhou, Measurements associated with learning more secure computer conﬁguration parameters, Ph.D. thesis, Wake Forest University (2015). [20] C. A. Odell, Using genetic algorithms to detect security related software parameter chains, Ph.D. thesis, Wake Forest University (2016). [21] A. Whitaker, R. S. Cox, S. D. Gribble, Conﬁguration debugging as search: Finding the needle in the haystack., in: OSDI, Vol. 4, 2004, pp. 6–6. [22] J. Zhang, L. Renganarayana, X. Zhang, N. Ge, V. Bala, T. Xu, Y. Zhou, Encore: Exploiting system environment and correlation information for misconﬁguration detection, ACM SIGPLAN Notices 49 (4) (2014) 687– 700. [23] [Accessed Mars. 08 2017] (Mars 2017). [link]. URL [24] [link]. URL [25] S. Sivanandam, S. Deepa, Introduction to genetic algorithms, Springer Science & Business Media, 2007. 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 69 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply."
How (not to) Run an AI Project in Investigative Journalism,"M. Fridman, R. Krøvel and F. Palumbo",2023,0.0,0,Journalism Practice,article,"Journalism Practice
ISSN: (Print) (Online) Journal homepage: www.tandfonline.com/journals/rjop20
How (not to) Run an AI Project in Inveﬆigative
Journalism
M. Fridman, R. Krøvel & F. Palumbo
To cite this article: M. Fridman, R. Krøvel & F. Palumbo (04 Sep 2023): How (not to) Run an AI
Project in Investigative Journalism, Journalism Practice, DOI: 10.1080/17512786.2023.2253797
To link to this article:  https://doi.org/10.1080/17512786.2023.2253797
© 2023 The Author(s). Published by Informa
UK Limited, trading as Taylor & Francis
Group
Published online: 04 Sep 2023.
Submit your article to this journal 
Article views: 3867
View related articles 
View Crossmark data
Citing articles: 6 View citing articles 
Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=rjop20
 How (not to) Run an AI Project in Investigative Journalism
M. Fridman
a, R. Krøvel
b and F. Palumbo
a,b
aArtiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi, Oslo Metropolitan University, Oslo,
Norway; bFakultet for samfunnsvitenskap, Institutt for journalistikk og mediefag, Oslo Metropolitan
University, Oslo, Norway
ABSTRACT
Data journalists are increasingly reliant on automation and artiﬁcial
intelligence (AI) to process and analyse massive datasets. AI can
contribute to journalism by creating visualizations, verifying
accuracy of information, analysing historical data, monitoring
social media, ﬁnding patterns and outliers, generating text and
much more. However, the integration of AI into the newsroom
comes with its own challenges. In this article, we take a practice-
based approach to develop a deeper understanding of how to
overcome such challenges. Our teams of data scientists, AI
experts and journalists took on four projects incorporating data
science and machine learning into investigative journalism. From
those experiences, we found that access to data at scale, data
quality and reworking the concept of “newsworthy” as a machine
learning
question
were
the
most
signiﬁcant
obstacles
to
deploying
AI
in
the
newsroom.
We
recommend
closer
collaborations between team members of diﬀerent disciplines to
create a truly trans-disciplinary approach, as well as some
practical
considerations
for
choosing
projects
to
facilitate
successful AI-assisted investigations.
ARTICLE HISTORY
Received 21 March 2023
Accepted 27 August 2023
KEYWORDS
Data journalism;
investigative journalism;
machine learning; data
science; artiﬁcial intelligence;
trans-disciplinary journalism
Introduction
Artiﬁcial Intelligence (AI) is a broad ﬁeld of computer science that aims to develop intel-
ligent machines capable of performing tasks that typically require human intelligence.
Machine learning is a subset of AI that develops algorithms and statistical models
enabling computers to learn and make predictions or decisions without being explicitly
programmed by humans. AI also includes other approaches such as natural language pro-
cessing, computer vision, expert systems, and robotics, which collectively enable AI
systems to understand, reason, learn, and interact with humans and their environments.
Artiﬁcial intelligence (AI) is being rapidly adopted by news media around the world, to
the point that both the public and the journalists themselves start to wonder whether
“robots will replace journalists” (Miroshnichenko 2018). However, while the adoption of
AI in journalism is accelerating, experiential knowledge about AI applications in
© 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group
This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/
licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly
cited. The terms on which this article has been published allow the posting of the Accepted Manuscript in a repository by the author(s)
or with their consent.
CONTACT R. Krøvel
royk@oslomet.no
JOURNALISM PRACTICE
https://doi.org/10.1080/17512786.2023.2253797
 journalism is lagging. Research on AI in journalism has been mostly qualitative and
focused on a few topics such as data journalism, robotic writing, and news review
(Parratt-Fernández, Mayoral-Sánchez, and Mera-Fernández 2021).
With the advent of digital technology and the explosion of data, it is becoming increas-
ingly important to use AI to support investigative journalism, as traditional methods are
no longer practical. The development of new, often open-source, tools makes solutions
easier and faster to implement and requires fewer specialized resources. In this context,
computers can play a central role in automating repetitive and computationally intensive
processes, enabling journalists to extract information that would otherwise be inaccess-
ible (Beckett 2019). To visualize the growth in automated data handling it´s enough to
consider that the “Pandora Papers”, released by ICIJ and composed of 2.94TB of docu-
ments, is 1700 times as large as the “2010 Wikileaks”, which was 1.7GB (Infographic
2021; Pandora Papers 2021).
Upon examining the current research landscape, it is evident that two main research
strands are prominently featured in the ﬁeld: reports by journalists and/or developers
describing a speciﬁc use case, and research articles based on interviews, surveys, and lit-
erature reviews (Ausserhofer et al. 2017; de-Lima-Santos and Ceron 2022; Stray 2019a).
However, the complex nature of investigative journalism requires alternative and exper-
imental research methodologies that enable researchers to understand and analyse often
novel investigative methodologies. One of the biggest challenges for multidisciplinary
teams working on AI in investigative journalism is to be able to communicate and collab-
orate eﬀectively (Santos and de-Lima-Santos 2022).
This article draws on the insights and experiences gained from participation in four
interdisciplinary teams in which data scientists and journalism researchers collaborated
with investigative journalists on various projects. Our goal is to analyse how interdisciplin-
ary teams can overcome the problems and limitations identiﬁed by researchers such as
Stray (Stray 2019a) and lead to a better inclusion of AI methods in investigative journalism.
By understanding the problems that need to be addressed, this paper aims to develop
better methods for incorporating AI into investigative journalism.
Data Journalism and AI in Journalism
Data journalism is a ﬁeld that incorporates data analysis, visualization, and database use
with traditional journalism practices to uncover and tell stories. Data journalism has made
substantial contributions to society, oﬀering information and insights that have led to
increased transparency, accountability, informed decision-making, and public under-
standing (Bounegru and Grey 2021). Data visualization is a critical aspect, as it helps jour-
nalists present complex information in a simple format (Rodríguez, Nunes, and Devezas
2015). Using data and interactive visualization, data journalism has revealed injustices,
held powerful individuals accountable, and improved the functioning of society and
the lives of citizens (Ausserhofer et al. 2017; Borges-Rey 2016; Bounegru and Grey 2021;
Santos and de-Lima-Santos 2022; Young, Hermida, and Fulda 2018).
There has been a push to include more data science and AI in data journalism. Data
journalism and AI journalism are two diﬀerent approaches to journalism that can
overlap. Data journalism involves the use of statistical methods, data visualization tools,
and other techniques to identify patterns and trends in large datasets, and to present
2
M. FRIDMAN ET AL.
 this information in a way that is accessible to the general public. AI in journalism addition-
ally involves using AI technology to analyze data and discover, develop and publish new
stories. Whereas the most used software by data journalists are Microsoft Excel and
Google Sheets (The State of Data Journalism 2023), data scientists regularly use program-
ming to wrangle and scrape data, improve data cleaning, and create custom analysis and
dynamic interfaces to promote data interaction. They can also use machine learning and
recent AI advances to automate repetitive processes, extract relationships that are hard to
see otherwise and detect newsworthy anomalies (Amazon Mining Watch n.d.). Data jour-
nalists are now more reliant on automation and AI to process and analyse massive data-
sets, and even generate new stories (Challenges and Opportunities – Survey – State of
Data Journalism 2022, n.d.). Florian Stalph identiﬁes four main categories of data journal-
ism: explanatory data journalism, investigative data journalism, interactive data journal-
ism, and advocacy data journalism (Stalph 2018). A similar approach is followed by
Konstantin Nicholas Dörr mapping the ﬁeld of AI journalism into automated news
writing, data-driven journalism, personalized news recommendation, and algorithmic
curation (Dörr 2016). In addition, AI can contribute to journalism by creating visualiza-
tions, verifying the accuracy of statements, analysing historical data, and monitoring
social media (AI and the Future of Journalism n.d.; Hacks/Hackers LDN 2019; Miroshni-
chenko 2018; Weber 2021). However, it is important to view AI as an aid to journalists,
not a replacement. The best outcomes are achieved by combining AI with human exper-
tise and ensuring unbiased and diverse data is used for training.
Data collection is a critical aspect of artiﬁcial intelligence (AI) because AI algorithms
rely on large and diverse datasets to make accurate predictions and decisions. However,
data collection for AI can be problematic due to several reasons. First, it can introduce
bias and discrimination if the collected data reﬂects societal biases or discriminates
against certain groups, leading to unfair outcomes (Buolamwini and Gebru 2018;
Zhao et al. 2018). Second, limited or incomplete data can result in models lacking accu-
racy and reliability (Jain et al. 2020). Moreover, privacy concerns arise when personal
data is collected, stored, and potentially used without consent, posing risks to
privacy and data security (Crawford and Schultz 2014). Ethical considerations are also
important, especially when sensitive information is involved, requiring transparency
and adherence to ethical guidelines (O’Neil 2016). Data quality and pre-processing chal-
lenges, including errors and inconsistencies, can undermine AI model eﬀectiveness.
Data imbalance, where certain groups are underrepresented, can lead to biased
results. Additionally, data ownership and access rights can create barriers to research
and fair competition.
The research into data journalism is an ever-evolving ﬁeld, but a few trends are emer-
ging. Several studies highlight the importance of multidisciplinary teams (Borges-Rey
2016; de-Lima-Santos & Salaverría 2021; Santos and de-Lima-Santos 2022). Collaborations
between journalists, data scientists, and developers to create tailored analyses and data-
wrangling solutions are key to an investigations’ success. Teams that instead have to rely
on readily available free online tools struggle with the lack of customization (Young,
Hermida, and Fulda 2018).
Despite the potential beneﬁts, the adoption of AI in the ﬁeld of investigative journalism
has not been widespread. The cost of implementing new technologies, like AI, in various
industries may be a factor. However, there is potential for AI to reduce costs as well, in the
JOURNALISM PRACTICE
3
 scope of automation and lead generation. In addition, given its potential to recognize pat-
terns and ﬁnd stories that would otherwise stay buried, the cost-beneﬁt analysis cannot
be calculated purely in ﬁnancial terms. This value to society allows such projects to turn to
public funds, philanthropy, and crowdfunding.
Apart from the economical hurdles to incorporating AI and data science into data jour-
nalism, there are also the obstacles inherited from data journalism itself. These challenges
are well explained in a comparative study between the United States and North European
countries (Fink and Anderson 2015). Fink and Anderson summarize the main limiting
factor for data journalism across newsrooms in the lack of: Time, Tools, Manpower and
Legal Resources. They also point out that the role of a data journalist within an organiz-
ation often lacks clear deﬁnition, frequently resulting in them either working in isolation
or being burdened with an overwhelming amount of tasks.
An overview of the pros and cons of AI integration within newsrooms is given by Wu
et al. after conducting interviews with professionals. In their work, they discuss the emer-
gence of automation technologies, such as artiﬁcial intelligence, machine learning, and
natural language processing, and their potential applications in journalism. They
explore how these technologies are being integrated into newsrooms to streamline
workﬂows, generate news content, and personalize news delivery. Some of the potentials
of AI consist of increased eﬃciency, improved accuracy, and enhanced audience engage-
ment through personalized news experiences. At the same time, concerns are related to
job displacement, ethical considerations, and the need for human oversight in the auto-
mated news production (Wu, Tandoc, and Salmon 2019).
Nevertheless, AI journalism can play a crucial role in supporting the role of journalists
as “watchdogs”, to quote Tom Felle (Felle 2016), in providing the public with valuable
information and holding those in power accountable for their actions. Of course, this
comes not without challenges, but by focusing on disclosing sources, methodologies,
and limitations journalists can enable audiences to assess the credibility and reliability
of data-driven news stories (Anderson 2018; Zamith 2019).
Methodology
Parratt-Fernández et al. observe that 60% of academic work on AI applications in journal-
ism utilizes qualitative methods, despite the numerical nature of the subject. While digital
methods are prevalent in digital humanities, they are less common in journalism studies
(Parratt-Fernández, Mayoral-Sánchez, and Mera-Fernández 2021). Sjøvaag and Karlsson
attribute this to a higher threshold for journalism scholars, who often lack the necessary
skills and knowledge to perform automated analysis on large datasets (Karlsson and
Sjøvaag 2016). We have consequently chosen to develop and employ alternative method-
ologies to enrich the existing literature from complementary methodological perspec-
tives. The methodology used in this research is practice-based (Biggs and Büchler 2007;
Vear 2022).
Practice-based research emphasizes the study of real-world problems and practices,
rather than solely theoretical or abstract concepts. In contrast to other methodologies,
practice-based research focuses on understanding how people actually do things,
rather than how they should theoretically do them. This allows us to focus on how inves-
tigative journalists do their job. It is an empirical research method, which is based on the
4
M. FRIDMAN ET AL.
 collection of data through observation, discussion, and other forms of direct engagement:
practitioners and researchers work together to identify research questions, collect data,
and analyse results.
Practice-based research allows journalists and scholars to better understand the
practical implications of new technologies and changing newsroom practices. It is
necessary to bridge the gap between academic research and industry practice
and can lead to the development of more innovative and eﬀective journalism
(Barroca et al. 2018; Biesta 2007). In addition to its beneﬁts for practitioners, prac-
tice-based research also proﬁts academia by helping educators and researchers
stay current with the latest trends and developments in the ﬁeld. This results in
the development of more relevant and eﬀective journalism curricula (Niblock
2007; 2012; Robie 2015).
In designing the methodology of this study, we chose to conduct practice-based
research by collaborating with the Norwegian Association for Investigative Journalism
(Skup.No n.d.). SKUP is a non-proﬁt organization that promotes investigative journalism
in Norway. Together with SKUP, we published a call in May 2021 inviting investigative
journalists to submit projects where we could assist using data science and AI
techniques.
By opening a public call, we allocate ﬁnancial resources to support academic staﬀ
dedicated to 4 projects for a period of 6 months. We encouraged all the Norwegian
newsrooms to submit a project proposal and a committee of both AI and Journalism
academics was appointed to select the 3 best ones. By doing so we encourage Norwe-
gian newsrooms to explore avenues with which they are not familiar and that in
normal circumstances they would have not pursued We received several applications
and for the three selected projects, we dedicated an Associate Professor of Artiﬁcial
Intelligence. Each team was then composed of one academic from OsloMet, one Inves-
tigative Journalist daily collaborating with the AI expert, and a staﬀof supporting
journalists.
In our research approach, the investigative journalists were responsible for deciding
the topic, ﬁnding the initial data sources, formulating the research questions, and inter-
preting the results. The teams had variable compositions in terms of the number of jour-
nalists and experience with data handling. A smaller team of data journalists assisted with
data-related issues. Regular meetings ensured alignment between the data-focused
teams and the journalists. This collaborative approach enabled a targeted use of data
science and AI techniques in investigative journalism.
In 2022, we again selected three new projects and provided similar support.
The collaboration with SKUP not only provided access to experienced investigative
journalists but also ensured that the research had a direct impact on the ﬁeld.
The insights drawn from applying data science and AI techniques to investigative jour-
nalistic questions form the backbone of the present study. The journalistic results were
published in various outlets. Here, we have anonymized identities to maintain conﬁdenti-
ality. Team meetings and Discord channels were utilized to ensure eﬃcient collaboration
among stakeholders. Group meetings were held to identify signiﬁcant learning experi-
ences and analyse ﬁndings considering the existing literature. For the purpose of this
article, we draw on notes and discussions in team meetings and on Discord channel to
reconstruct the research processes.
JOURNALISM PRACTICE
5
 Description of Projects
Project 1
Exploration reimbursement scheme in the petroleum industry. The main goal of this
project was to bring attention to the exploration reimbursement tax scheme in the pet-
roleum industry. The journalists proposed to investigate and combine two publicly avail-
able data sources: the Petroleum Tax Lists (The Norwegian Tax Administration 2020) and
the Norwegian Petroleum Directorate (NPD) Fact pages (NPD Fact Pages n.d.). The goal of
the project was to better understand how companies were accessing and using the
exploration reimbursement scheme, which has been in place since 2005. Additionally,
the project aimed to provide some oversight to the program by mapping oil exploration
activities, documented in the NPD fact pages, to the reimbursement claims in annual
taxes. In the process of this investigation, the idea emerged to deploy graph databases
to represent connections between petroleum companies, reimbursement payments
and drilling licenses.
Project 2
Adverse events in elderly care. The main goal of this project was to better understand how
the quality of elderly care varies across municipalities. The journalists proposed to corre-
late publicly available data recording “non-conformity reports” (NCR) and statistics from
SSB. NCR are gathered at the municipality level and are regulated by the government
guidelines “Norsk kodeverk for uønskede pasienthendelser” (Helsedirektoratet 2021).
The statistics available from SSB describe a wide set of municipality parameters. By corre-
lating these datasets, the project aimed to identify critical factors that contribute to the
occurrence of adverse events in elderly care.
Project 3
Eating disorders in professional skiers. The main goal of this project was to investigate the
occurrence of eating disorders among top athletes. The journalists proposed an innova-
tive approach to solve this problem by using computer vision. The core idea was to take
advantage of the mediatic exposure of the athletes. By collecting public images of the
athletes over time it is possible to infer the body mass index and body fat percentage
and consequently investigate drastic changes over the years.
Project 4
Media landscape analysis. The main goal of this project was to better understand
the Norwegian media landscape. The project started with an exploratory data analy-
sis of a dataset of Norwegian news and blog stories. The dataset collected infor-
mation about the article itself, including title, publisher, authors, and links, as well
as information about its social media engagement. In addition to exploratory analy-
sis, this project grew to track how stories move across both traditional and social
media.
6
M. FRIDMAN ET AL.
 Results
In the ﬁeld of data journalism, the deployment of machine learning (ML) and artiﬁcial
intelligence (AI) algorithms requires a thorough understanding of the necessary data
and the feasibility of obtaining and processing that data. Based on existing literature,
we expected this process to be time-consuming – particularly in investigative journal-
ism projects where there is signiﬁcant complexity in both the questions and societal
structures involved. However, as we experienced, one should carefully consider the
quality and availability of the required data to correctly estimate the feasibility of the
project and its potential outcomes. It is crucial to note that input data of poor
quality will result in equally poor output, regardless of the algorithm’s computational
power.
We found similar diﬃculties and challenges across all of three projects, which we could
broadly categorize using the concepts introduced by Stray (Stray 2019b) as follows:
.
Data availability: Data relevant to a story may not be publicly accessible, data collection
results to be challenging, or the available dataset is incomplete/scattered
.
Data quality: Journalistic inference requires high-accuracy data
.
Newsworthiness: The concept of “newsworthy” is diﬃcult to encode computationally
Data Collection is a Critical Aspect of AI in Journalism
We found that the availability of data was a recurring challenge across all projects. Despite
identifying data sources before the project’s start and therefore expecting that data was
readily accessible, each project encountered diﬃculties in obtaining the necessary data.
The project exploring the reimbursement scheme in the petroleum industry stumbled
across a lack of consistent historical records. Despite the presence of publicly available
data from sources such as the Brønnøysund registry (brreg.no n.d.), historical data for
defunct companies was often missing. This required the purchase of data or the use of
alternative methods for collection. This project also suﬀered from a lack of transparent
data from the side of the tax authorities. While the oil exploration reimbursement
amounts are ostensibly available and published every year by the Norwegian Tax
Oﬃce, these reimbursements are not split between exploration and termination reimbur-
sements. The Norwegian Tax Oﬃce refused to release this information on request,
without which it is impossible to evaluate the success or failure of the exploration reim-
bursement policy. Moreover, the life cycle of a company can be complex and involves
merges and splits, takeovers and name changes. This makes it complicated to track
licenses and understand ﬁnancial ﬂows over time. Petroleum extraction licenses are typi-
cally shared between several companies in alliances that might also change over time. It is
consequently very diﬃcult to reconstruct the timeline of company history and reimburse-
ments without support from experts.
The project which sought to investigate the quality of elderly care in Norway also
encountered challenges in obtaining data. Despite the requirement for municipalities
to keep detailed records of non-conformity reports (NCR) in the elderly care sector, a com-
prehensive analysis of these reports had never been conducted. We discovered that often
the data was missing, unstructured or in hard-to-access formats. There were diﬀerent
JOURNALISM PRACTICE
7
 reasons for this, ranging from a lack of human resources in the municipality to a lack of
digital reporting systems. Privacy issues also prevented data sharing in the case of
small municipalities. Even when the municipality invested signiﬁcant resources to
collect and anonymize the records, the data analysis was not trivial due to the lack of stan-
dardization across municipalities. In the best-case scenario, municipalities sent their data
in the shape of Microsoft Excel spreadsheets. This required extensive eﬀort from the team
to restructure the data in a standard format and sometimes led to data loss. Other muni-
cipalities delivered data in unstructured formats such as PDFs, Word ﬁles or just printed
out on A4 paper, leading to additional challenges wrangling the data into a usable
format. At a later stage, the project intended to correlate the NCR statistics with publicly
available data from the Norwegian Central Bureau of Statistics (SSB) (Statistisk sentralbyrå
2023) to better understand factors contributing to adverse events in elderly care facilities.
SSB maintains updated statistics of many societal parameters; however, historical analysis
of the data was challenging given the complex and frequent changes to the structure of
Norwegian municipalities. Upon request, SSB supported our investigation by allowing our
team to purchase restructured datasets, but these datasets were not provided freely
through their platform. Since then, they have integrated our proposed indexing of the
data in their report system for current and future data. This example shows how the struc-
ture and shareability of the data improved through the interaction between journalists
and data collectors.
These experiences highlight the need for increased transparency and accessibility of
data, particularly regarding business and healthcare. The lack of labeled data when
looking for suspicious activity and the unstructured nature of business annual reports
also presented signiﬁcant obstacles in utilizing AI and ML algorithms. Considering
these challenges, it is crucial to consider the feasibility of obtaining a complete and
high-quality dataset before embarking on investigative journalism projects that involve
data analysis.
Journalism would Beneﬁt from Greater Transparency in Company Structure
In recent years, there has been a growing recognition of the need for greater transparency
in the ﬁnancial ﬂows of companies, particularly in the extractive and ﬁnancial sectors (Sti-
glitz 2002). This is because these sectors are often characterized by complex and opaque
ownership structures (Sachs and Warner 2001). One of the main challenges in uncovering
these ﬁnancial ﬂows is the lack of comprehensive and publicly available data on company
ownership and beneﬁcial ownership (Cobham and Janský 2020). While some countries
have made progress in this area, for example by joining the Extractive Industries Transpar-
ency Initiative (EITI) (Extractive Industries Transparency Initiative n.d.), many countries still
lack comprehensive and publicly available registers.
Additionally, even when data is publicly available, it is often unstructured, on paper
and in a customized format, which makes it challenging to extract information even
with state-of-the-art Object Character Recognition (OCR) algorithms. Furthermore, in
some cases, the companies themselves may be unwilling to disclose information about
their ownership and ﬁnancial ﬂows, making it diﬃcult for investigative journalists to
access the necessary data (Making Transparency Possible 2019). Even when a company
is willing to disclose information, it might be diﬃcult to access it as datasets might be
8
M. FRIDMAN ET AL.
 scattered across multiple platforms and in multiple countries, not to mention privacy
legislations limiting data access (EU Court of Justice Delivers Blow to Beneﬁcial Owner-
ship … 2022).
While investigating the reimbursement scheme in the Norwegian petroleum industry
we experienced how complex and opaque ownership structures are. This is a particularly
illustrative example given that Norway, as a member of EITI, commits to disclose infor-
mation regarding the extractive (Extractive Industries Transparency Initiative n.d.).
There are numerous reasons why investigative journalists, and the news media, might
want to investigate complex and opaque ownership structures in the extractive and
ﬁnancial sectors. First, opaque ownership structure makes it diﬃcult to hold companies
accountable for their actions, especially when it comes to taxes and royalties for the
resources they extract. Several studies suggest that investigative journalism, and other
forms of transparency-promoting activities, can play a critical role in exposing complex
and opaque ownership structures in the extractive and ﬁnancial sectors (Beckett 2019;
Radon and Achuthan 2017). Based on our research, we believe data journalism in this
ﬁeld depends on initiatives such as OpenCorporates (OpenCorporates :: The Open Data-
base Of The Corporate World n.d.) and OpenOwnership (Open Ownership n.d.) to
move the ﬁeld forward. These and other organizations are taking the lead in utilizing
advanced Machine Learning and Graph Databases to analyse complex company struc-
tures and beneﬁcial ownership.
Information is Often not Publicly Accessible
In the case of the investigation of accidents in elderly care, Norwegian municipalities are
obliged to provide data to journalists. However, a signiﬁcant number of municipalities did
not provide the requested information. Various factors can inﬂuence whether municipa-
lities provide requested information to journalists or not. However, as the context can vary
from country to country and region to region, it is important to consider the speciﬁc cir-
cumstances and legal framework of each inquiry. Among the municipalities that did not
provide the data in our investigation, the main reasons cited were a lack of digital records,
on-going lawsuits that prevented the sharing of data and insuﬃcient human resources to
anonymize the data for privacy reasons. In addition, some municipalities simply failed to
respond to the journalist’s requests.
Additionally, there were also challenges in obtaining data from SSB (Statistisk sentral-
byrå 2023) due to the frequent rearrangements of municipalities by the government. Fre-
quent re-organization of municipalities leads to several challenges in terms of data
analysis (Kommunereformen 2020, 2021). Administrative boundary changes can impact
data quality, as data collection and reporting procedures may change, resulting in incon-
sistent or inaccurate data. This makes it diﬃcult to conduct accurate and reliable analyses
of parameters over the years.
In the project employing computer vision for BMI estimation, we negotiated with other
researchers to share their datasets, some of which had been scraped from public sources
like Reddit. While at ﬁrst glance there were multiple approaches, public and shared data-
sets available, we quickly realized that these were not suﬃcient for the uses of the project.
It is therefore important to highlight that it’s not only the quantity of data that is crucial,
but also their relevance to the research question.
JOURNALISM PRACTICE
9
 Given the challenges of limited access to data, it is likely that journalists will need to
invest signiﬁcant resources to obtain the necessary data, as demonstrated by the
examples presented in this article. Strategies such as collaborating with organizations
or individuals who have access to relevant data sets, using publicly available data
sources, or using alternative data sources can help obtain relevant datasets.
Journalistic Inference Requires Very High Accuracy
In the context of our practice-based research, it became clear that the process of journal-
istic inference demands high accuracy. Machine learning algorithms have been devel-
oped to identify patterns and common characteristics within datasets. However, when
it comes to investigative journalism, particularly in the realm of fraud detection, the
goal is to uncover the unusual, events that were not expected to occur. These subtle vari-
ations are crucial to consider, as they do not align with the primary purpose for which ML
and AI algorithms were developed.
Deﬁning what constitutes suspicious or unethical practices within the available
datasets is a diﬃcult task, due to obscure business practices and opaqueness in the
law and interpretation of it. This is perhaps unsurprising, as even cases with extensive
evidence have been ruled legal by the courts (Skattemotiverte transaksjoner – opplys-
ningsplikt og fradragsrett 2020). More fundamentally, even deﬁning what is a
“company” over the years within a landscape of multiple organizations and leadership
structures can be prohibitively complex, as we described in the previous chapter. This
makes it precarious to associate any company or private entity with an accusation of
misconduct.
Our research on the care of the elderly highlighted the diﬃculty in categorizing
events into diﬀerent classes. After evaluating multiple language models, we determined
that accurate quantiﬁcation of all categories could not be guaranteed. Thus, we decided
to focus solely on adverse events related to medicine, which were successfully classiﬁed.
It is important to note that we were not investigating causality in this project, but rather
exploring correlations between variables, which can provide insight into relevant vari-
ables for optimizing the services oﬀered by the municipality. Although it was not poss-
ible to quantify issues and problems related to elderly care within this landscape, our
research aimed to guide the journalist’s investigation towards addressing these issues,
supported by data when the administration or leaders of the municipality were
questioned.
A ﬁnal aspect worth mentioning is the variation in data reporting among municipali-
ties. Our analysis of collected databases revealed that each municipality, depending on
its size and structure, may report data on ﬁnances and human resources with varying
degrees of resolution. This makes the analysis process signiﬁcantly more challenging,
as municipalities may report a single budget for their entire health department while
others may report individual budgets for diﬀerent health departments (home assistance,
hospitals, nursing homes, etc.), making comparisons diﬃcult.
In our study on eating disorders in sports, we ultimately had to abandon the model due
to insuﬃcient accuracy. This serves as a crucial example of why expertise in AI is impor-
tant. A team without suﬃcient knowledge of AI may not have been able to understand
that the model was unreliable and unsuitable for use.
10
M. FRIDMAN ET AL.
 Finally, in the research we did with the fact-checking organization Faktisk.no we did
succeed in identifying certain claims that could be conﬁdently made and relayed,
mainly because they were of a generalized, descriptive and qualitative nature.
Discussion
Data Preparation Tasks
According to Stray (Stray 2019a), data preparation tasks represent a signiﬁcant opportu-
nity for AI to beneﬁt investigative journalism in the short term.
In the context of the petroleum exploration reimbursement investigation, we found
that linking databases and transforming into Graph databases can reveal connections
that were previously unknown, by identifying patterns and relationships within large
amounts of data. This enhances the ability to uncover hidden links between entities
and to build a comprehensive picture of the issue at hand.
In the care for the elderly project, we faced the challenge of merging information from
various data types, including excel sheets, pdf ﬁles, and printed papers. Our research indi-
cates that public bodies should play a role in standardizing data dissemination, similar to
the example set by VG during the COVID-19 pandemic, where the government was
weekly providing updated statistics to the media.
Finally, in our study with the fact-checking organization Faktisk.no, we discovered that
most of the “AI”, speciﬁcally unsupervised machine learning, was used in the pre-proces-
sing steps to cluster similar stories. This step greatly assisted in the later analysis, demon-
strating the potential for AI in improving the eﬃciency of investigative journalism.
Our research supports the ﬁndings of Stray that data preparation tasks are the area
where AI seems to have the most immediate impact on investigative journalism.
However, much research and development are still needed to fully realize the potential
of AI in this ﬁeld and to ensure its ethical and eﬀective application.
Cross-Database Record Linkage
The use of AI in investigative journalism presents signiﬁcant potential for cross-database
record linkage. The ability to link records across databases has the potential to greatly
reduce the time, eﬀort, and costs associated with many investigations while producing
more robust results.
Referential integrity across databases refers to the consistency of relationships
between records in diﬀerent databases. Ensuring referential integrity is important in
ensuring the accuracy of the information being analysed and can greatly assist in connect-
ing records that would have been diﬃcult to link otherwise. However, referential integrity
can be diﬃcult to achieve due to diﬀerences in keys and naming conventions across
databases.
In the context of investigative journalism, referential integrity is crucial when linking
records from various sources. For example, in the investigation of petroleum tax reimbur-
sements, linking tax data with petroleum discovery data can help to hold companies
accountable. However, in some cases we found that companies used diﬀerent organiz-
ation numbers for taxation and licensing purposes, which made linking records
JOURNALISM PRACTICE
11
 diﬃcult. Similarly, in the investigation of care for the elderly, referential integrity across
databases is essential to ensure that information is accurate and correctly linked.
Our practice-based research highlights the potential of AI in facilitating cross-database
record linkage, which could greatly enhance the eﬀectiveness of investigative journalism.
Using the Right Tools Saves Time and Money and Enhances the Results’ Quality
In our investigation, we identiﬁed a multitude of tools that can be adapted and leveraged
for the purpose of investigation. These tools, including Pandas (Pandas - Python Data
Analysis Library n.d.), Seaborn (Waskom 2021), Norwegian language models such as
NorBERT or NoTraM (Web64 2016/2023), zero-shot classiﬁcation (NbAiLab/Nb-Bert-Base-
Mnli Hugging Face 2023), Neo4j (Neo4j Graph Data Platform – The Leader in Graph Data-
bases n.d.), NetworkX (NetworkX — NetworkX Documentation n.d.), and HuggingFace
(Hugging Face – The AI Community Building the Future. n.d.), represent only a selection
of the numerous available options that can be utilized to fulﬁll speciﬁc needs. It is of
utmost importance to have a comprehensive understanding of recent advancements in
AI to make informed decisions when selecting the most appropriate tools and platforms
for a given investigation.
Pandas, a data analysis library in Python, provides eﬃcient storage and manipulation of
tabular data through its data structures. Seaborn, another Python library, oﬀers a high-
level interface for generating informative and visually appealing statistical graphics. NB-
NERT, a Norwegian language model for named entity recognition (NER), can be utilized
to identify named entities in text. Zero-shot classiﬁcation, a machine learning technique,
enables categorization of unseen categories without the need for any additional training
data. Neo4j is a graph database management system designed for the storage and query-
ing of complex networked data. NetworkX, a Python library, enables the creation, manipu-
lation, and analysis of the structure, dynamics, and functions of complex networks. Lastly,
HuggingFace is a natural language processing platform providing access to a wide range
of pre-trained language models, including NER models.
These tools can be employed in a variety of ways to support journalistic investigations.
They can be used to analyze data and generate visualizations to gain a deeper under-
standing of trends and patterns, identify named entities in text, categorize text, store
and query complex networked data, and access pre-trained language models for NER
tasks. In our research project, we invested signiﬁcant resources to support the four pro-
jects. Two associate professors were dedicated to the projects and worked almost full-
time. Three masters students also contributed to the work. Additionally, two other pro-
fessors provided support, including time spent on funding and administrative tasks. All
in all, we estimate that the total cost of the projects was close to $200,000.
The sizes of the projects varied greatly. Two of the projects were large-scale eﬀorts that
involved a substantial team of journalists and developers. At times, each team could
consist of over ten individuals. The cost related to data science and AI was a small
portion of the overall budget for the largest projects, estimated to be less than 10%.
On the other hand, one of the smaller projects had a signiﬁcantly higher proportion of
its budget allocated to data science and AI, approximately half of the total. However, it
should be noted that it is challenging to provide precise estimates as several journalists
and developers worked on multiple projects simultaneously.
12
M. FRIDMAN ET AL.
 The projects presented signiﬁcant challenges in terms of budgeting and resource allo-
cation. The extent of the data pre-processing required was unforeseen and caused unfore-
seen expenses. When evaluating the costs of investment in data science and AI, it is
important to weigh them against the potential beneﬁts. In one instance, having
machine learning experts working on the project prevented the publication of unreliable
results. In another instance, the potential beneﬁts could be measured in terms of improve-
ments to quality of life and longevity. While it is diﬃcult to determine the ﬁnancial returns
of these investigations to the news media, we believe that they hold great promise for
long-term beneﬁt to society.
Importantly, the advent of AI in the media industry is already changing the pro-
fessional proﬁle of the journalist, since they have to manage constantly developing tech-
nologies, an increasing amount of accessible data, fake news generation, and last but
not least, the ethical implications introduced by the use of AI in modern society
(Túñez-López, Fieiras-Ceide, and Vaz-Álvarez 2021). Therefore, appropriate training of
journalists, as well as a productive collaboration with experts in the ﬁelds of AI, is necess-
ary to allow them to automate repetitive tasks and to process large amount of data
eﬃciently so that they can focus on creating high-quality human-crafted journalism
(Noain-Sánchez 2022).
Conclusion
In this study, we applied an interdisciplinary approach to enhance investigative journal-
ism with advanced machine learning and data science techniques. We utilized a variety
of tools, including Pandas, Seaborn, Norwegian language models like NB-BERT, zero-
shot classiﬁcation, Neo4j, NetworkX, and HuggingFace to build applications that made
the investigative process more cost-eﬀective. During the course of this project, we
observed that the landscape of large language models and computer vision was
rapidly changing, with the release of four major neural networks in the latter half of
2022. This trend is likely to continue, with the speed of innovation and openness in the
ﬁeld leading to falling costs of investigative projects.
Based on our experiences, we believe that it is crucial to move beyond interdisciplinary
projects and towards true trans-disciplinary projects. “Trans-disciplinary” refers to a colla-
borative approach that integrates knowledge and skills from multiple disciplines to solve
complex problems and address real-world challenges. It diﬀers from interdisciplinary
teamwork in that it involves active participation and collaboration from all stakeholders
including those outside the ﬁeld of expertise, to ensure that the solutions produced
are holistic and relevant to the real-world context. Additionally, it requires participants
to develop joint theoretical and methodological frameworks to guide the teamwork.
In order to maximize the chances of success we have developed a recommended
workﬂow summarized in Figure 1. We recommend prioritizing projects with well-stated
research questions and a clear hypothesis, while also considering the potential value of
the database itself, even in the absence of a “smoking gun”. Moreover, it is important
to keep in mind that historical data can be missing, incomplete and diﬃcult to interpret,
therefore, we recommend focusing on projects based on recent or current time periods.
Happily, data are becoming increasingly available, thanks to the active contribution of
both private and public bodies, such that hopefully this restriction will diminish with
JOURNALISM PRACTICE
13
 time. Additionally, we suggest using explainable methods and visualization techniques
that are easily understandable to journalists, editors, and the general public.
In addition to the tangible outcomes of these projects in the form of news reports and
documentaries, we also gained valuable insights into the challenges and complexities of
these types of collaborations. We found that the investigations were more productive
when both journalists and AI specialists became literate in each other’s ﬁelds and
Figure 1. Recommended workﬂow to successfully implement and develop an AI Journalism project.
This recommendation is based on the practice and experience of the projects we describe in this
article, and it aims to guide other journalists on how to implement AI in their newsrooms.
Figure 2. Schematic representation of what we envision as trans-disciplinary collaborations between
AI experts and Investigative Journalists. These two professional ﬁgures do not work independently,
but actively collaborate with each other integrating their skills to solve complex problems.
14
M. FRIDMAN ET AL.
 engaged in a mutual learning process, as represented in Figure 2. This highlights the
importance of using existing algorithms, programs, and models, as well as developing
an understanding of the broader range of techniques in AI and data analysis.
Data journalism has emerged as an important ﬁeld in contemporary journalism. The
rise of big data, open data and data visualization technologies have enabled journalists
to leverage data in innovative ways to tell more compelling stories. Data journalism
oﬀers a new way of reporting that is grounded in the analysis of large data sets, and
that allows for the creation of new insights that would not be possible through traditional
reporting methods. In this paper, we explore the role of data journalism in contemporary
journalism and examine the ways in which it is transforming the ﬁeld of journalism.
Acknowledgment
We thank Gustavo Borges Moreno e Mello for the main contribution in establishing the “The AI Jour-
nalism Resource Center” and supporting the group in obtaining the necessary fundings supporting
the work presented in this article. We also thank Morten Goodwin for contributing to the develop-
ment of the projects with stimulating discussions and insight.
Disclosure Statement
No potential conﬂict of interest was reported by the author(s).
Funding
This work was supported by Artiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi,
Oslo Metropolitan University, Oslo, Norway and Fritt Ord Foundation and the Norwegian Directorate
for Higher Education and Skills.
ORCID
M. Fridman
http://orcid.org/0000-0002-3065-8888
R. Krøvel
http://orcid.org/0000-0003-2231-7714
F. Palumbo
http://orcid.org/0000-0002-5571-5420
References
AI and the Future of Journalism. n.d. Accessed September 3, 2021. http://ulam.ai/ai-and-the-future-
of-journalism/.
Amazon Mining Watch. n.d. Accessed February 27, 2023. https://amazonminingwatch.org/en.
Anderson, C. W. 2018. Apostles of Certainty. Vol. 1. Oxford University Press. https://doi.org/10.1093/
oso/9780190492335.001.0001.
Ausserhofer, J., R. Gutounig, M. Oppermann, M. Oppermann, S. Matiasek, and E. Goldgruber. 2017.
“The Dataﬁcation of Data Journalism Scholarship: Focal Points, Methods, and Research
Propositions for the Investigation of Data-Intensive Newswork.” Journalism: Theory, Practice &
Criticism 21: 950–973. https://doi.org/10.1177/1464884917700667.
Barroca, L., H. Sharp, D. Salah, K. Taylor, and P. Gregory. 2018. “Bridging the Gap between Research
and Agile Practice: An Evolutionary Model.” International Journal of System Assurance Engineering
and Management 9 (2): 323–334. https://doi.org/10.1007/s13198-015-0355-5.
Beckett, P. 2019. Ownership, Financial Accountability and the law: Transparency Strategies and
Counter-Initiatives. London: Routledge, Taylor & Francis Group.
JOURNALISM PRACTICE
15
 Biesta, G. 2007. “Bridging the Gap between Educational Research and Educational Practice: The
Need for Critical Distance.” Educational Research and Evaluation 13 (3): 295–301. https://doi.
org/10.1080/13803610701640227.
Biggs, M. A. R., and D. Büchler. 2007. “Rigor and Practice-Based Research.” Design Issues 23 (3): 62–69.
https://doi.org/10.1162/desi.2007.23.3.62.
Borges-Rey, E. 2016. “Unravelling Data Journalism a Study of Data Journalism Practice in British
Newsrooms.” Journalism Practice 10 (7): 833–843. https://doi.org/10.1080/17512786.2016.
1159921.
Bounegru, L., and J. Grey, eds. 2021. The Data Journalism Handbook: Towards a Critical Data Practice.
Amsterdam: Amsterdam University Press.
Brreg.no. n.d. Brønnøysundregistrene. Accessed February 28, 2023. https://www.brreg.no.
Buolamwini, J., and T. Gebru. 2018. “Gender Shades: Intersectional Accuracy Disparities in
Commercial
Gender
Classiﬁcation.”
In
Proceedings
of
the
1st
Conference
on
Fairness,
Accountability and Transparency, edited by S. A. Friedler, and C. Wilson, 77–91. Vol. 81. PMLR.
https://proceedings.mlr.press/v81/buolamwini18a.html.
Challenges and Opportunities – Survey – .State of .Data .Journalism 2022. n.d. Accessed February 28,
2023. https://datajournalism.com/survey/2022/challenges-and-opportunities/.
Cobham, A., and P. Janský. 2020. Estimating Illicit Financial Flows: A Critical Guide to the Data,
Methodologies, and Findings. 1st ed. Oxford University PressOxford. https://doi.org/10.1093/
oso/9780198854418.001.0001
Crawford, Kate, and Jason Schultz. 2014. “Big Data and Due Process: Toward a Framework to Redress
Predictive Privacy Harms.” Boston College Law Review 55: 93. https://ssrn.com/abstract=2325784.
de-Lima-Santos, M.-F., and W. Ceron. 2022. “Artiﬁcial Intelligence in News Media: Current
Perceptions and Future Outlook.” Journalism and Media 3 (1): 13–26. https://doi.org/10.3390/
journalmedia3010002.
De-Lima-Santos, M. F., and R. Salaverría. 2021. “From data journalism to artiﬁcial intelligence: chal-
lenges faced by La Nación in implementing computer vision in news reporting.” Palabra Clave 24
(3).
Dörr, K. N. 2016. “Mapping the Field of Algorithmic Journalism.” Digital Journalism 4 (6): 700–722.
https://doi.org/10.1080/21670811.2015.1096748.
EU Court of Justice delivers blow to beneﬁcial ownership … . 2022, November 22. Transparency.Org.
https://www.transparency.org/en/press/eu-court-of-justice-delivers-blow-to-beneﬁcial-
ownership-transparency.
Extractive Industries Transparency Initiative. n.d. EITI. Accessed February 28, 2023. https://eiti.org/.
Felle, T. 2016. “Digital Watchdogs? Data Reporting and the News Media’s Traditional ‘Fourth Estate’
Function.” Journalism 17 (1): 85–96. https://doi.org/10.1177/1464884915593246.
Fink, K., and C. W. Anderson. 2015. “Data Journalism in the United States: Beyond the “Usual
Suspects”.” Journalism Studies 16 (4): 467–481. https://doi.org/10.1080/1461670X.2014.939852.
Hacks/Hackers LDN (Director). 2019, November 29. AI & Journalism: New powers, new responsibil-
ities
\textbar
Charlie
Beckett.
https://www.youtube.com/watch?feature=youtu.be&v=L-
qgP14TK8U&app=desktop.
Helsedirektoratet.
2021.
Norsk
kodeverk
for
uønskede
pasienthendelser.
https://www.
helsedirektoratet.no/rapporter/norsk-kodeverk-for-uonskede-pasienthendelser/Norsk%
20kodeverk%20for%20uønskede%20pasienthendelser.pdf/_/attachment/inline/e95247b1-
bdb4-463b-b730-5a09398db917:88e99f1e911c29fd8101025ad12f685eef995b9c/Norsk%
20kodeverk%20for%20uønskede%20pasienthendelser.pdf.
Hugging Face – The AI community building the future. n.d. Accessed March 1, 2023. https://
huggingface.co/.
Infographic: The Scale Of The Pandora Papers Leak. 2021, October 4. Statista Infographics. https://
www.statista.com/chart/11698/the-scale-of-the-paradise-papers-leak.
Jain, A., H. Patel, L. Nagalapatti, N. Gupta, S. Mehta, S. Guttula, S. Mujumdar, S. Afzal, R. Sharma Mittal,
and V. Munigala. 2020. “Overview and Importance of Data Quality for Machine Learning Tasks.”
Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data
Mining, 3561–3562. https://doi.org/10.1145/3394486.3406477.
16
M. FRIDMAN ET AL.
 Karlsson, M., and H. Sjøvaag. 2016. “Content Analysis and Online News: Epistemologies of Analysing
the Ephemeral Web.” Digital Journalism 4 (1): 177–192. https://doi.org/10.1080/21670811.2015.
1096619.
Kommunereformen 2020. 2021, March 15. ssb.no. https://www.ssb.no/oﬀentlig-sektor/kommune-
stat-rapportering/kommunereformen-2020.
Making Transparency Possible. 2019. Cappelen Damm Akademisk/NOASP. https://doi.org/10.23865/
noasp.64
Miroshnichenko, A. 2018. “AI to Bypass Creativity. Will Robots Replace Journalists? (The Answer Is
“Yes”).” Information 9 (7): 183. https://doi.org/10.3390/info9070183.
NbAiLab/nb-bert-base-mnli Hugging Face. 2023, January 25. https://huggingface.co/NbAiLab/nb-
bert-base-mnli.
Neo4j Graph Data Platform – The Leader in Graph Databases. n.d. Neo4j Graph Data Platform.
Accessed March 1, 2023. https://neo4j.com/.
NetworkX — NetworkX documentation. n.d. Accessed March 1, 2023. https://networkx.org/.
Niblock, S. 2007. “From “Knowing How” to “Being Able”: Negotiating the Meanings of Reﬂective
Practice and Reﬂexive Research in Journalism Studies.” Journalism Practice 1 (1): 20–32. https://
doi.org/10.1080/17512780601078829.
Niblock, S. 2012. “Envisioning Journalism Practice as Research.” Journalism Practice 6 (4): 497–512.
https://doi.org/10.1080/17512786.2011.650922.
Noain-Sánchez, A. 2022. “Addressing the Impact of Artiﬁcial Intelligence on Journalism: The
Perception of Experts, Journalists and Academics.” Communication & Society 35 (3): 105–121.
https://doi.org/10.15581/003.35.3.105-121.
TheNorwegianTaxAdministration.2020.Petroleumsskattpå116milliarderkronerfor2019.https://www.
skatteetaten.no/en/presse/nyhetsrommet/petroleumsskatt-pa-116-milliarder-kroner-for-2019/.
NPD Fact Pages. n.d. Accessed May 1, 2022. https://factpages.npd.no/.
O’Neil, C. 2016. Weapons of Math Destruction: How big Data Increases Inequality and Threatens
Democracy. 1st ed. Crown.
OpenCorporates: The Open Database Of The Corporate World. n.d. Accessed February 28, 2023.
https://opencorporates.com/.
Open
Ownership.
n.d.
Openownership.Org.
Accessed
February
28,
2023.
https://www.
openownership.org/en/.
pandas—Python Data Analysis Library. n.d. Accessed March 1, 2023. https://pandas.pydata.org/.
Pandora Papers: An oﬀshore data tsunami - ICIJ. 2021, October 6. https://web.archive.org/web/
20211006063105/https://www.icij.org/investigations/pandora-papers/about-pandora-papers-
leak-dataset/.
Parratt-Fernández, S., J. Mayoral-Sánchez, and M. Mera-Fernández. 2021. “Aplicación de la inteligen-
cia artiﬁcial al periodismo: Análisis de la producción académica.” El Profesional de La Información,
e300317. https://doi.org/10.3145/epi.2021.may.17.
Radon, J., and M. Achuthan. 2017. “Beneﬁcial Ownership Disclosure.” Journal of International Aﬀairs
70 (2): 85–108. JSTOR.
Robie, D. 2015. “Advocating Journalism Practice-as-research: A Case for Recognition in the New
Zealand PBRF Context.” Asia Paciﬁc Media Educator 25 (1): 62–73. https://doi.org/10.1177/
1326365X15575591.
Rodríguez, M. T., S. Nunes, and T. Devezas. 2015. “Telling Stories with Data Visualization.”
Proceedings of the 2015 Workshop on Narrative & Hypertext - NHT 15: 7–11. https://doi.org/10.
1145/2804565.2804567.
Sachs, J. D., and A. M. Warner. 2001. “The Curse of Natural Resources.” European Economic Review 45
(4–6): 827–838. https://doi.org/10.1016/S0014-2921(01)00125-8.
Santos, M. F. D. L., and M.-F. de-Lima-Santos. 2022. “ProPublica’s Data Journalism: How
Multidisciplinary Teams and Hybrid Proﬁles Create Impactful Data Stories.” Media and
Communication, https://doi.org/10.17645/mac.v10i1.4433.
Skattemotiverte transaksjoner – opplysningsplikt og fradragsrett. November 13, 2020. HR-2020-
2200-A (Høyesterett (Norwegian Supreme Court)). https://www.domstol.no/no/hoyesterett/
avgjorelser/2020/hoyesterett-straﬀ/hr-2020-2200-a/.
JOURNALISM PRACTICE
17
 Skup.no. n.d. Accessed February 28, 2023. https://www.skup.no/.
Stalph, F. 2018. “Classifying Data Journalism: A Content Analysis of Daily Data-Driven Stories.”
Journalism Practice 12 (10): 1332–1350. https://doi.org/10.1080/17512786.2017.1386583.
The State of Data Journalism (No. 2022). 2023. datajournalism.com. https://datajournalism.com/
survey/2022/.
Statistisk sentralbyrå. 2023, February 28. SSB. https://www.ssb.no/.
Stiglitz, J. 2002. “Transparency in Government.” In The Right to Tell: The Role of Mass Media in
Economic Development. 1st ed. World Bank Publications.
Stray, J. 2019a. “Making Artiﬁcial Intelligence Work for Investigative Journalism.” Digital Journalism 7
(8): 1076–1097. https://doi.org/10.1080/21670811.2019.1630289.
Túñez-López, J.-M., C. Fieiras-Ceide, and M. Vaz-Álvarez. 2021. “Impact of Artiﬁcial Intelligence on
Journalism: Transformations in the Company, Products, Contents and Professional Proﬁle.”
Communication & Society 34 (1): 177–193. https://doi.org/10.15581/003.34.1.177-193.
Vear, C. ed. 2022. The Routledge International Handbook of Practice-Based Research. Routledge.
Waskom, M. 2021. “seaborn: Statistical Data Visualization.” Journal of Open Source Software 6 (60):
3021. https://doi.org/10.21105/joss.03021.
Web64. 2023. Norwegian NLP Resources. https://github.com/web64/norwegian-nlp-resources
(Original work published 2016).
Weber, M. 2021. “AI, Media and the Future of News on the Web.” 13th ACM Web Science Conference
2021: 10. https://doi.org/10.1145/3447535.3468474.
Wu, S., E. C. Tandoc, and C. T. Salmon. 2019. “When Journalism and Automation Intersect: Assessing
the Inﬂuence of the Technological Field on Contemporary Newsrooms.” Journalism Practice 13
(10): 1238–1254. https://doi.org/10.1080/17512786.2019.1585198.
Young, M. L., A. Hermida, and J. Fulda. 2018. What Makes for Great Data Journalism. Journalism
Practice 12 (1): 115–135. https://doi.org/10.1080/17512786.2016.1270171.
Zamith, R. 2019. “Transparency, Interactivity, Diversity, and Information Provenance in Everyday
Data Journalism.” Digital Journalism 7 (4): 470–489. https://doi.org/10.1080/21670811.2018.
1554409.
Zhao, J., T. Wang, M. Yatskar, V. Ordonez, and K.-W. Chang. 2018. Gender Bias in Coreference
Resolution: Evaluation and Debiasing Methods. https://doi.org/10.48550/ARXIV.1804.06876.
18
M. FRIDMAN ET AL.
",10.1080/17512786.2023.2253797,doc3,"Journalism Practice (Online) Journal homepage: www.tandfonline.com/journals/rjop20 How (not to) Run an AI Project in Investigative Journalism M. Fridman, R. Krøvel & F. Palumbo To cite this article: M. Fridman, R. Krøvel & F. Palumbo (04 Sep 2023): How (not to) Run an AI Project in Investigative Journalism, Journalism Practice, DOI: 10.1080/17512786.2023.2253797 To link to this article: © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group Published online: 04 Sep 2023. Submit your article to this journal Article views: 3867 View related articles View Crossmark data Citing articles: 6 View citing articles Full Terms & Conditions of access and use can be found at How (not to) Run an AI Project in Investigative Journalism M. Fridman a, R. Krøvel b and F. Palumbo a,b aArtiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi, Oslo Metropolitan University, Oslo, Norway; bFakultet for samfunnsvitenskap, Institutt for journalistikk og mediefag, Oslo Metropolitan University, Oslo, Norway ABSTRACT Data journalists are increasingly reliant on automation and artiﬁcial intelligence (AI) to process and analyse massive datasets. AI can contribute to journalism by creating visualizations, verifying accuracy of information, analysing historical data, monitoring social media, ﬁnding patterns and outliers, generating text and much more. However, the integration of AI into the newsroom comes with its own challenges. In this article, we take a practice- based approach to develop a deeper understanding of how to overcome such challenges. Our teams of data scientists, AI experts and journalists took on four projects incorporating data science and machine learning into investigative journalism. From those experiences, we found that access to data at scale, data quality and reworking the concept of “newsworthy” as a machine learning question were the most signiﬁcant obstacles to deploying AI in the newsroom. We recommend closer collaborations between team members of diﬀerent disciplines to create a truly trans-disciplinary approach, as well as some practical considerations for choosing projects to facilitate successful AI-assisted investigations. ARTICLE HISTORY Received 21 March 2023 Accepted 27 August 2023 KEYWORDS Data journalism; investigative journalism; machine learning; data science; artiﬁcial intelligence; trans-disciplinary journalism Introduction Artiﬁcial Intelligence (AI) is a broad ﬁeld of computer science that aims to develop intel- ligent machines capable of performing tasks that typically require human intelligence. Machine learning is a subset of AI that develops algorithms and statistical models enabling computers to learn and make predictions or decisions without being explicitly programmed by humans. AI also includes other approaches such as natural language pro- cessing, computer vision, expert systems, and robotics, which collectively enable AI systems to understand, reason, learn, and interact with humans and their environments. Artiﬁcial intelligence (AI) is being rapidly adopted by news media around the world, to the point that both the public and the journalists themselves start to wonder whether “robots will replace journalists” (Miroshnichenko 2018). However, while the adoption of AI in journalism is accelerating, experiential knowledge about AI applications in © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group This is an Open Access article distributed under the terms of the Creative Commons Attribution License ( licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. The terms on which this article has been published allow the posting of the Accepted Manuscript in a repository by the author(s) or with their consent. CONTACT R. Krøvel royk@oslomet.no JOURNALISM PRACTICE journalism is lagging. Research on AI in journalism has been mostly qualitative and focused on a few topics such as data journalism, robotic writing, and news review (Parratt-Fernández, Mayoral-Sánchez, and Mera-Fernández 2021). With the advent of digital technology and the explosion of data, it is becoming increas- ingly important to use AI to support investigative journalism, as traditional methods are no longer practical. The development of new, often open-source, tools makes solutions easier and faster to implement and requires fewer specialized resources. In this context, computers can play a central role in automating repetitive and computationally intensive processes, enabling journalists to extract information that would otherwise be inaccess- ible (Beckett 2019). To visualize the growth in automated data handling it´s enough to consider that the “Pandora Papers”, released by ICIJ and composed of 2.94TB of docu- ments, is 1700 times as large as the “2010 Wikileaks”, which was 1.7GB (Infographic 2021; Pandora Papers 2021). Upon examining the current research landscape, it is evident that two main research strands are prominently featured in the ﬁeld: reports by journalists and/or developers describing a speciﬁc use case, and research articles based on interviews, surveys, and lit- erature reviews (Ausserhofer et al. 2017; de-Lima-Santos and Ceron 2022; Stray 2019a). However, the complex nature of investigative journalism requires alternative and exper- imental research methodologies that enable researchers to understand and analyse often novel investigative methodologies. One of the biggest challenges for multidisciplinary teams working on AI in investigative journalism is to be able to communicate and collab- orate eﬀectively (Santos and de-Lima-Santos 2022). This article draws on the insights and experiences gained from participation in four interdisciplinary teams in which data scientists and journalism researchers collaborated with investigative journalists on various projects. Our goal is to analyse how interdisciplin- ary teams can overcome the problems and limitations identiﬁed by researchers such as Stray (Stray 2019a) and lead to a better inclusion of AI methods in investigative journalism. By understanding the problems that need to be addressed, this paper aims to develop better methods for incorporating AI into investigative journalism. Data Journalism and AI in Journalism Data journalism is a ﬁeld that incorporates data analysis, visualization, and database use with traditional journalism practices to uncover and tell stories. Data journalism has made substantial contributions to society, oﬀering information and insights that have led to increased transparency, accountability, informed decision-making, and public under- standing (Bounegru and Grey 2021). Data visualization is a critical aspect, as it helps jour- nalists present complex information in a simple format (Rodríguez, Nunes, and Devezas 2015). Using data and interactive visualization, data journalism has revealed injustices, held powerful individuals accountable, and improved the functioning of society and the lives of citizens (Ausserhofer et al. 2017; Borges-Rey 2016; Bounegru and Grey 2021; Santos and de-Lima-Santos 2022; Young, Hermida, and Fulda 2018). There has been a push to include more data science and AI in data journalism. Data journalism and AI journalism are two diﬀerent approaches to journalism that can overlap. Data journalism involves the use of statistical methods, data visualization tools, and other techniques to identify patterns and trends in large datasets, and to present 2 M. FRIDMAN ET AL. this information in a way that is accessible to the general public. AI in journalism addition- ally involves using AI technology to analyze data and discover, develop and publish new stories. Whereas the most used software by data journalists are Microsoft Excel and Google Sheets (The State of Data Journalism 2023), data scientists regularly use program- ming to wrangle and scrape data, improve data cleaning, and create custom analysis and dynamic interfaces to promote data interaction. They can also use machine learning and recent AI advances to automate repetitive processes, extract relationships that are hard to see otherwise and detect newsworthy anomalies (Amazon Mining Watch n.d.). Data jour- nalists are now more reliant on automation and AI to process and analyse massive data- sets, and even generate new stories (Challenges and Opportunities – Survey – State of Data Journalism 2022, n.d.). Florian Stalph identiﬁes four main categories of data journal- ism: explanatory data journalism, investigative data journalism, interactive data journal- ism, and advocacy data journalism (Stalph 2018). A similar approach is followed by Konstantin Nicholas Dörr mapping the ﬁeld of AI journalism into automated news writing, data-driven journalism, personalized news recommendation, and algorithmic curation (Dörr 2016). In addition, AI can contribute to journalism by creating visualiza- tions, verifying the accuracy of statements, analysing historical data, and monitoring social media (AI and the Future of Journalism n.d.; Hacks/Hackers LDN 2019; Miroshni- chenko 2018; Weber 2021). However, it is important to view AI as an aid to journalists, not a replacement. The best outcomes are achieved by combining AI with human exper- tise and ensuring unbiased and diverse data is used for training. Data collection is a critical aspect of artiﬁcial intelligence (AI) because AI algorithms rely on large and diverse datasets to make accurate predictions and decisions. However, data collection for AI can be problematic due to several reasons. First, it can introduce bias and discrimination if the collected data reﬂects societal biases or discriminates against certain groups, leading to unfair outcomes (Buolamwini and Gebru 2018; Zhao et al. 2018). Second, limited or incomplete data can result in models lacking accu- racy and reliability (Jain et al. 2020). Moreover, privacy concerns arise when personal data is collected, stored, and potentially used without consent, posing risks to privacy and data security (Crawford and Schultz 2014). Ethical considerations are also important, especially when sensitive information is involved, requiring transparency and adherence to ethical guidelines (O’Neil 2016). Data quality and pre-processing chal- lenges, including errors and inconsistencies, can undermine AI model eﬀectiveness. Data imbalance, where certain groups are underrepresented, can lead to biased results. Additionally, data ownership and access rights can create barriers to research and fair competition. The research into data journalism is an ever-evolving ﬁeld, but a few trends are emer- ging. Several studies highlight the importance of multidisciplinary teams (Borges-Rey 2016; de-Lima-Santos & Salaverría 2021; Santos and de-Lima-Santos 2022). Collaborations between journalists, data scientists, and developers to create tailored analyses and data- wrangling solutions are key to an investigations’ success. Teams that instead have to rely on readily available free online tools struggle with the lack of customization (Young, Hermida, and Fulda 2018). Despite the potential beneﬁts, the adoption of AI in the ﬁeld of investigative journalism has not been widespread. The cost of implementing new technologies, like AI, in various industries may be a factor. However, there is potential for AI to reduce costs as well, in the JOURNALISM PRACTICE 3 scope of automation and lead generation. In addition, given its potential to recognize pat- terns and ﬁnd stories that would otherwise stay buried, the cost-beneﬁt analysis cannot be calculated purely in ﬁnancial terms. This value to society allows such projects to turn to public funds, philanthropy, and crowdfunding. Apart from the economical hurdles to incorporating AI and data science into data jour- nalism, there are also the obstacles inherited from data journalism itself. These challenges are well explained in a comparative study between the United States and North European countries (Fink and Anderson 2015). Fink and Anderson summarize the main limiting factor for data journalism across newsrooms in the lack of: Time, Tools, Manpower and Legal Resources. They also point out that the role of a data journalist within an organiz- ation often lacks clear deﬁnition, frequently resulting in them either working in isolation or being burdened with an overwhelming amount of tasks. An overview of the pros and cons of AI integration within newsrooms is given by Wu et al. after conducting interviews with professionals. In their work, they discuss the emer- gence of automation technologies, such as artiﬁcial intelligence, machine learning, and natural language processing, and their potential applications in journalism. They explore how these technologies are being integrated into newsrooms to streamline workﬂows, generate news content, and personalize news delivery. Some of the potentials of AI consist of increased eﬃciency, improved accuracy, and enhanced audience engage- ment through personalized news experiences. At the same time, concerns are related to job displacement, ethical considerations, and the need for human oversight in the auto- mated news production (Wu, Tandoc, and Salmon 2019). Nevertheless, AI journalism can play a crucial role in supporting the role of journalists as “watchdogs”, to quote Tom Felle (Felle 2016), in providing the public with valuable information and holding those in power accountable for their actions. Of course, this comes not without challenges, but by focusing on disclosing sources, methodologies, and limitations journalists can enable audiences to assess the credibility and reliability of data-driven news stories (Anderson 2018; Zamith 2019). Methodology Parratt-Fernández et al. observe that 60% of academic work on AI applications in journal- ism utilizes qualitative methods, despite the numerical nature of the subject. While digital methods are prevalent in digital humanities, they are less common in journalism studies (Parratt-Fernández, Mayoral-Sánchez, and Mera-Fernández 2021). Sjøvaag and Karlsson attribute this to a higher threshold for journalism scholars, who often lack the necessary skills and knowledge to perform automated analysis on large datasets (Karlsson and Sjøvaag 2016). We have consequently chosen to develop and employ alternative method- ologies to enrich the existing literature from complementary methodological perspec- tives. The methodology used in this research is practice-based (Biggs and Büchler 2007; Vear 2022). Practice-based research emphasizes the study of real-world problems and practices, rather than solely theoretical or abstract concepts. In contrast to other methodologies, practice-based research focuses on understanding how people actually do things, rather than how they should theoretically do them. This allows us to focus on how inves- tigative journalists do their job. It is an empirical research method, which is based on the 4 M. FRIDMAN ET AL. collection of data through observation, discussion, and other forms of direct engagement: practitioners and researchers work together to identify research questions, collect data, and analyse results. Practice-based research allows journalists and scholars to better understand the practical implications of new technologies and changing newsroom practices. It is necessary to bridge the gap between academic research and industry practice and can lead to the development of more innovative and eﬀective journalism (Barroca et al. 2018; Biesta 2007). In addition to its beneﬁts for practitioners, prac- tice-based research also proﬁts academia by helping educators and researchers stay current with the latest trends and developments in the ﬁeld. This results in the development of more relevant and eﬀective journalism curricula (Niblock 2007; 2012; Robie 2015). In designing the methodology of this study, we chose to conduct practice-based research by collaborating with the Norwegian Association for Investigative Journalism (Skup.No n.d.). SKUP is a non-proﬁt organization that promotes investigative journalism in Norway. Together with SKUP, we published a call in May 2021 inviting investigative journalists to submit projects where we could assist using data science and AI techniques. By opening a public call, we allocate ﬁnancial resources to support academic staﬀ dedicated to 4 projects for a period of 6 months. We encouraged all the Norwegian newsrooms to submit a project proposal and a committee of both AI and Journalism academics was appointed to select the 3 best ones. By doing so we encourage Norwe- gian newsrooms to explore avenues with which they are not familiar and that in normal circumstances they would have not pursued We received several applications and for the three selected projects, we dedicated an Associate Professor of Artiﬁcial Intelligence. Each team was then composed of one academic from OsloMet, one Inves- tigative Journalist daily collaborating with the AI expert, and a staﬀof supporting journalists. In our research approach, the investigative journalists were responsible for deciding the topic, ﬁnding the initial data sources, formulating the research questions, and inter- preting the results. The teams had variable compositions in terms of the number of jour- nalists and experience with data handling. A smaller team of data journalists assisted with data-related issues. Regular meetings ensured alignment between the data-focused teams and the journalists. This collaborative approach enabled a targeted use of data science and AI techniques in investigative journalism. In 2022, we again selected three new projects and provided similar support. The collaboration with SKUP not only provided access to experienced investigative journalists but also ensured that the research had a direct impact on the ﬁeld. The insights drawn from applying data science and AI techniques to investigative jour- nalistic questions form the backbone of the present study. The journalistic results were published in various outlets. Here, we have anonymized identities to maintain conﬁdenti- ality. Team meetings and Discord channels were utilized to ensure eﬃcient collaboration among stakeholders. Group meetings were held to identify signiﬁcant learning experi- ences and analyse ﬁndings considering the existing literature. For the purpose of this article, we draw on notes and discussions in team meetings and on Discord channel to reconstruct the research processes. JOURNALISM PRACTICE 5 Description of Projects Project 1 Exploration reimbursement scheme in the petroleum industry. The main goal of this project was to bring attention to the exploration reimbursement tax scheme in the pet- roleum industry. The journalists proposed to investigate and combine two publicly avail- able data sources: the Petroleum Tax Lists (The Norwegian Tax Administration 2020) and the Norwegian Petroleum Directorate (NPD) Fact pages (NPD Fact Pages n.d.). The goal of the project was to better understand how companies were accessing and using the exploration reimbursement scheme, which has been in place since 2005. Additionally, the project aimed to provide some oversight to the program by mapping oil exploration activities, documented in the NPD fact pages, to the reimbursement claims in annual taxes. In the process of this investigation, the idea emerged to deploy graph databases to represent connections between petroleum companies, reimbursement payments and drilling licenses. Project 2 Adverse events in elderly care. The main goal of this project was to better understand how the quality of elderly care varies across municipalities. The journalists proposed to corre- late publicly available data recording “non-conformity reports” (NCR) and statistics from SSB. NCR are gathered at the municipality level and are regulated by the government guidelines “Norsk kodeverk for uønskede pasienthendelser” (Helsedirektoratet 2021). The statistics available from SSB describe a wide set of municipality parameters. By corre- lating these datasets, the project aimed to identify critical factors that contribute to the occurrence of adverse events in elderly care. Project 3 Eating disorders in professional skiers. The main goal of this project was to investigate the occurrence of eating disorders among top athletes. The journalists proposed an innova- tive approach to solve this problem by using computer vision. The core idea was to take advantage of the mediatic exposure of the athletes. By collecting public images of the athletes over time it is possible to infer the body mass index and body fat percentage and consequently investigate drastic changes over the years. Project 4 Media landscape analysis. The main goal of this project was to better understand the Norwegian media landscape. The project started with an exploratory data analy- sis of a dataset of Norwegian news and blog stories. The dataset collected infor- mation about the article itself, including title, publisher, authors, and links, as well as information about its social media engagement. In addition to exploratory analy- sis, this project grew to track how stories move across both traditional and social media. 6 M. FRIDMAN ET AL. Results In the ﬁeld of data journalism, the deployment of machine learning (ML) and artiﬁcial intelligence (AI) algorithms requires a thorough understanding of the necessary data and the feasibility of obtaining and processing that data. Based on existing literature, we expected this process to be time-consuming – particularly in investigative journal- ism projects where there is signiﬁcant complexity in both the questions and societal structures involved. However, as we experienced, one should carefully consider the quality and availability of the required data to correctly estimate the feasibility of the project and its potential outcomes. It is crucial to note that input data of poor quality will result in equally poor output, regardless of the algorithm’s computational power. We found similar diﬃculties and challenges across all of three projects, which we could broadly categorize using the concepts introduced by Stray (Stray 2019b) as follows: . Data availability: Data relevant to a story may not be publicly accessible, data collection results to be challenging, or the available dataset is incomplete/scattered . Data quality: Journalistic inference requires high-accuracy data . Newsworthiness: The concept of “newsworthy” is diﬃcult to encode computationally Data Collection is a Critical Aspect of AI in Journalism We found that the availability of data was a recurring challenge across all projects. Despite identifying data sources before the project’s start and therefore expecting that data was readily accessible, each project encountered diﬃculties in obtaining the necessary data. The project exploring the reimbursement scheme in the petroleum industry stumbled across a lack of consistent historical records. Despite the presence of publicly available data from sources such as the Brønnøysund registry (brreg.no n.d.), historical data for defunct companies was often missing. This required the purchase of data or the use of alternative methods for collection. This project also suﬀered from a lack of transparent data from the side of the tax authorities. While the oil exploration reimbursement amounts are ostensibly available and published every year by the Norwegian Tax Oﬃce, these reimbursements are not split between exploration and termination reimbur- sements. The Norwegian Tax Oﬃce refused to release this information on request, without which it is impossible to evaluate the success or failure of the exploration reim- bursement policy. Moreover, the life cycle of a company can be complex and involves merges and splits, takeovers and name changes. This makes it complicated to track licenses and understand ﬁnancial ﬂows over time. Petroleum extraction licenses are typi- cally shared between several companies in alliances that might also change over time. It is consequently very diﬃcult to reconstruct the timeline of company history and reimburse- ments without support from experts. The project which sought to investigate the quality of elderly care in Norway also encountered challenges in obtaining data. Despite the requirement for municipalities to keep detailed records of non-conformity reports (NCR) in the elderly care sector, a com- prehensive analysis of these reports had never been conducted. We discovered that often the data was missing, unstructured or in hard-to-access formats. There were diﬀerent JOURNALISM PRACTICE 7 reasons for this, ranging from a lack of human resources in the municipality to a lack of digital reporting systems. Privacy issues also prevented data sharing in the case of small municipalities. Even when the municipality invested signiﬁcant resources to collect and anonymize the records, the data analysis was not trivial due to the lack of stan- dardization across municipalities. In the best-case scenario, municipalities sent their data in the shape of Microsoft Excel spreadsheets. This required extensive eﬀort from the team to restructure the data in a standard format and sometimes led to data loss. Other muni- cipalities delivered data in unstructured formats such as PDFs, Word ﬁles or just printed out on A4 paper, leading to additional challenges wrangling the data into a usable format. At a later stage, the project intended to correlate the NCR statistics with publicly available data from the Norwegian Central Bureau of Statistics (SSB) (Statistisk sentralbyrå 2023) to better understand factors contributing to adverse events in elderly care facilities. SSB maintains updated statistics of many societal parameters; however, historical analysis of the data was challenging given the complex and frequent changes to the structure of Norwegian municipalities. Upon request, SSB supported our investigation by allowing our team to purchase restructured datasets, but these datasets were not provided freely through their platform. Since then, they have integrated our proposed indexing of the data in their report system for current and future data. This example shows how the struc- ture and shareability of the data improved through the interaction between journalists and data collectors. These experiences highlight the need for increased transparency and accessibility of data, particularly regarding business and healthcare. The lack of labeled data when looking for suspicious activity and the unstructured nature of business annual reports also presented signiﬁcant obstacles in utilizing AI and ML algorithms. Considering these challenges, it is crucial to consider the feasibility of obtaining a complete and high-quality dataset before embarking on investigative journalism projects that involve data analysis. Journalism would Beneﬁt from Greater Transparency in Company Structure In recent years, there has been a growing recognition of the need for greater transparency in the ﬁnancial ﬂows of companies, particularly in the extractive and ﬁnancial sectors (Sti- glitz 2002). This is because these sectors are often characterized by complex and opaque ownership structures (Sachs and Warner 2001). One of the main challenges in uncovering these ﬁnancial ﬂows is the lack of comprehensive and publicly available data on company ownership and beneﬁcial ownership (Cobham and Janský 2020). While some countries have made progress in this area, for example by joining the Extractive Industries Transpar- ency Initiative (EITI) (Extractive Industries Transparency Initiative n.d.), many countries still lack comprehensive and publicly available registers. Additionally, even when data is publicly available, it is often unstructured, on paper and in a customized format, which makes it challenging to extract information even with state-of-the-art Object Character Recognition (OCR) algorithms. Furthermore, in some cases, the companies themselves may be unwilling to disclose information about their ownership and ﬁnancial ﬂows, making it diﬃcult for investigative journalists to access the necessary data (Making Transparency Possible 2019). Even when a company is willing to disclose information, it might be diﬃcult to access it as datasets might be 8 M. FRIDMAN ET AL. scattered across multiple platforms and in multiple countries, not to mention privacy legislations limiting data access (EU Court of Justice Delivers Blow to Beneﬁcial Owner- ship … 2022). While investigating the reimbursement scheme in the Norwegian petroleum industry we experienced how complex and opaque ownership structures are. This is a particularly illustrative example given that Norway, as a member of EITI, commits to disclose infor- mation regarding the extractive (Extractive Industries Transparency Initiative n.d.). There are numerous reasons why investigative journalists, and the news media, might want to investigate complex and opaque ownership structures in the extractive and ﬁnancial sectors. First, opaque ownership structure makes it diﬃcult to hold companies accountable for their actions, especially when it comes to taxes and royalties for the resources they extract. Several studies suggest that investigative journalism, and other forms of transparency-promoting activities, can play a critical role in exposing complex and opaque ownership structures in the extractive and ﬁnancial sectors (Beckett 2019; Radon and Achuthan 2017). Based on our research, we believe data journalism in this ﬁeld depends on initiatives such as OpenCorporates (OpenCorporates :: The Open Data- base Of The Corporate World n.d.) and OpenOwnership (Open Ownership n.d.) to move the ﬁeld forward. These and other organizations are taking the lead in utilizing advanced Machine Learning and Graph Databases to analyse complex company struc- tures and beneﬁcial ownership. Information is Often not Publicly Accessible In the case of the investigation of accidents in elderly care, Norwegian municipalities are obliged to provide data to journalists. However, a signiﬁcant number of municipalities did not provide the requested information. Various factors can inﬂuence whether municipa- lities provide requested information to journalists or not. However, as the context can vary from country to country and region to region, it is important to consider the speciﬁc cir- cumstances and legal framework of each inquiry. Among the municipalities that did not provide the data in our investigation, the main reasons cited were a lack of digital records, on-going lawsuits that prevented the sharing of data and insuﬃcient human resources to anonymize the data for privacy reasons. In addition, some municipalities simply failed to respond to the journalist’s requests. Additionally, there were also challenges in obtaining data from SSB (Statistisk sentral- byrå 2023) due to the frequent rearrangements of municipalities by the government. Fre- quent re-organization of municipalities leads to several challenges in terms of data analysis (Kommunereformen 2020, 2021). Administrative boundary changes can impact data quality, as data collection and reporting procedures may change, resulting in incon- sistent or inaccurate data. This makes it diﬃcult to conduct accurate and reliable analyses of parameters over the years. In the project employing computer vision for BMI estimation, we negotiated with other researchers to share their datasets, some of which had been scraped from public sources like Reddit. While at ﬁrst glance there were multiple approaches, public and shared data- sets available, we quickly realized that these were not suﬃcient for the uses of the project. It is therefore important to highlight that it’s not only the quantity of data that is crucial, but also their relevance to the research question. JOURNALISM PRACTICE 9 Given the challenges of limited access to data, it is likely that journalists will need to invest signiﬁcant resources to obtain the necessary data, as demonstrated by the examples presented in this article. Strategies such as collaborating with organizations or individuals who have access to relevant data sets, using publicly available data sources, or using alternative data sources can help obtain relevant datasets. Journalistic Inference Requires Very High Accuracy In the context of our practice-based research, it became clear that the process of journal- istic inference demands high accuracy. Machine learning algorithms have been devel- oped to identify patterns and common characteristics within datasets. However, when it comes to investigative journalism, particularly in the realm of fraud detection, the goal is to uncover the unusual, events that were not expected to occur. These subtle vari- ations are crucial to consider, as they do not align with the primary purpose for which ML and AI algorithms were developed. Deﬁning what constitutes suspicious or unethical practices within the available datasets is a diﬃcult task, due to obscure business practices and opaqueness in the law and interpretation of it. This is perhaps unsurprising, as even cases with extensive evidence have been ruled legal by the courts (Skattemotiverte transaksjoner – opplys- ningsplikt og fradragsrett 2020). More fundamentally, even defining what is a “company” over the years within a landscape of multiple organizations and leadership structures can be prohibitively complex, as we described in the previous chapter. This makes it precarious to associate any company or private entity with an accusation of misconduct. Our research on the care of the elderly highlighted the diﬃculty in categorizing events into diﬀerent classes. After evaluating multiple language models, we determined that accurate quantiﬁcation of all categories could not be guaranteed. Thus, we decided to focus solely on adverse events related to medicine, which were successfully classiﬁed. It is important to note that we were not investigating causality in this project, but rather exploring correlations between variables, which can provide insight into relevant vari- ables for optimizing the services oﬀered by the municipality. Although it was not poss- ible to quantify issues and problems related to elderly care within this landscape, our research aimed to guide the journalist’s investigation towards addressing these issues, supported by data when the administration or leaders of the municipality were questioned. A ﬁnal aspect worth mentioning is the variation in data reporting among municipali- ties. Our analysis of collected databases revealed that each municipality, depending on its size and structure, may report data on ﬁnances and human resources with varying degrees of resolution. This makes the analysis process signiﬁcantly more challenging, as municipalities may report a single budget for their entire health department while others may report individual budgets for diﬀerent health departments (home assistance, hospitals, nursing homes, etc.), making comparisons diﬃcult. In our study on eating disorders in sports, we ultimately had to abandon the model due to insuﬃcient accuracy. This serves as a crucial example of why expertise in AI is impor- tant. A team without suﬃcient knowledge of AI may not have been able to understand that the model was unreliable and unsuitable for use. 10 M. FRIDMAN ET AL. Finally, in the research we did with the fact-checking organization Faktisk.no we did succeed in identifying certain claims that could be conﬁdently made and relayed, mainly because they were of a generalized, descriptive and qualitative nature. Discussion Data Preparation Tasks According to Stray (Stray 2019a), data preparation tasks represent a signiﬁcant opportu- nity for AI to beneﬁt investigative journalism in the short term. In the context of the petroleum exploration reimbursement investigation, we found that linking databases and transforming into Graph databases can reveal connections that were previously unknown, by identifying patterns and relationships within large amounts of data. This enhances the ability to uncover hidden links between entities and to build a comprehensive picture of the issue at hand. In the care for the elderly project, we faced the challenge of merging information from various data types, including excel sheets, pdf ﬁles, and printed papers. Our research indi- cates that public bodies should play a role in standardizing data dissemination, similar to the example set by VG during the COVID-19 pandemic, where the government was weekly providing updated statistics to the media. Finally, in our study with the fact-checking organization Faktisk.no, we discovered that most of the “AI”, speciﬁcally unsupervised machine learning, was used in the pre-proces- sing steps to cluster similar stories. This step greatly assisted in the later analysis, demon- strating the potential for AI in improving the eﬃciency of investigative journalism. Our research supports the ﬁndings of Stray that data preparation tasks are the area where AI seems to have the most immediate impact on investigative journalism. However, much research and development are still needed to fully realize the potential of AI in this ﬁeld and to ensure its ethical and eﬀective application. Cross-Database Record Linkage The use of AI in investigative journalism presents signiﬁcant potential for cross-database record linkage. The ability to link records across databases has the potential to greatly reduce the time, eﬀort, and costs associated with many investigations while producing more robust results. Referential integrity across databases refers to the consistency of relationships between records in diﬀerent databases. Ensuring referential integrity is important in ensuring the accuracy of the information being analysed and can greatly assist in connect- ing records that would have been diﬃcult to link otherwise. However, referential integrity can be diﬃcult to achieve due to diﬀerences in keys and naming conventions across databases. In the context of investigative journalism, referential integrity is crucial when linking records from various sources. For example, in the investigation of petroleum tax reimbur- sements, linking tax data with petroleum discovery data can help to hold companies accountable. However, in some cases we found that companies used diﬀerent organiz- ation numbers for taxation and licensing purposes, which made linking records JOURNALISM PRACTICE 11 diﬃcult. Similarly, in the investigation of care for the elderly, referential integrity across databases is essential to ensure that information is accurate and correctly linked. Our practice-based research highlights the potential of AI in facilitating cross-database record linkage, which could greatly enhance the eﬀectiveness of investigative journalism. Using the Right Tools Saves Time and Money and Enhances the Results’ Quality In our investigation, we identiﬁed a multitude of tools that can be adapted and leveraged for the purpose of investigation. These tools, including Pandas (Pandas - Python Data Analysis Library n.d.), Seaborn (Waskom 2021), Norwegian language models such as NorBERT or NoTraM (Web64 2016/2023), zero-shot classiﬁcation (NbAiLab/Nb-Bert-Base- Mnli Hugging Face 2023), Neo4j (Neo4j Graph Data Platform – The Leader in Graph Data- bases n.d.), NetworkX (NetworkX — NetworkX Documentation n.d.), and HuggingFace (Hugging Face – The AI Community Building the Future. n.d.), represent only a selection of the numerous available options that can be utilized to fulﬁll speciﬁc needs. It is of utmost importance to have a comprehensive understanding of recent advancements in AI to make informed decisions when selecting the most appropriate tools and platforms for a given investigation. Pandas, a data analysis library in Python, provides eﬃcient storage and manipulation of tabular data through its data structures. Seaborn, another Python library, oﬀers a high- level interface for generating informative and visually appealing statistical graphics. NB- NERT, a Norwegian language model for named entity recognition (NER), can be utilized to identify named entities in text. Zero-shot classiﬁcation, a machine learning technique, enables categorization of unseen categories without the need for any additional training data. Neo4j is a graph database management system designed for the storage and query- ing of complex networked data. NetworkX, a Python library, enables the creation, manipu- lation, and analysis of the structure, dynamics, and functions of complex networks. Lastly, HuggingFace is a natural language processing platform providing access to a wide range of pre-trained language models, including NER models. These tools can be employed in a variety of ways to support journalistic investigations. They can be used to analyze data and generate visualizations to gain a deeper under- standing of trends and patterns, identify named entities in text, categorize text, store and query complex networked data, and access pre-trained language models for NER tasks. In our research project, we invested signiﬁcant resources to support the four pro- jects. Two associate professors were dedicated to the projects and worked almost full- time. Three masters students also contributed to the work. Additionally, two other pro- fessors provided support, including time spent on funding and administrative tasks. All in all, we estimate that the total cost of the projects was close to $200,000. The sizes of the projects varied greatly. Two of the projects were large-scale eﬀorts that involved a substantial team of journalists and developers. At times, each team could consist of over ten individuals. The cost related to data science and AI was a small portion of the overall budget for the largest projects, estimated to be less than 10%. On the other hand, one of the smaller projects had a signiﬁcantly higher proportion of its budget allocated to data science and AI, approximately half of the total. However, it should be noted that it is challenging to provide precise estimates as several journalists and developers worked on multiple projects simultaneously. 12 M. FRIDMAN ET AL. The projects presented signiﬁcant challenges in terms of budgeting and resource allo- cation. The extent of the data pre-processing required was unforeseen and caused unfore- seen expenses. When evaluating the costs of investment in data science and AI, it is important to weigh them against the potential beneﬁts. In one instance, having machine learning experts working on the project prevented the publication of unreliable results. In another instance, the potential beneﬁts could be measured in terms of improve- ments to quality of life and longevity. While it is diﬃcult to determine the ﬁnancial returns of these investigations to the news media, we believe that they hold great promise for long-term beneﬁt to society. Importantly, the advent of AI in the media industry is already changing the pro- fessional proﬁle of the journalist, since they have to manage constantly developing tech- nologies, an increasing amount of accessible data, fake news generation, and last but not least, the ethical implications introduced by the use of AI in modern society (Túñez-López, Fieiras-Ceide, and Vaz-Álvarez 2021). Therefore, appropriate training of journalists, as well as a productive collaboration with experts in the ﬁelds of AI, is necess- ary to allow them to automate repetitive tasks and to process large amount of data eﬃciently so that they can focus on creating high-quality human-crafted journalism (Noain-Sánchez 2022). Conclusion In this study, we applied an interdisciplinary approach to enhance investigative journal- ism with advanced machine learning and data science techniques. We utilized a variety of tools, including Pandas, Seaborn, Norwegian language models like NB-BERT, zero- shot classiﬁcation, Neo4j, NetworkX, and HuggingFace to build applications that made the investigative process more cost-eﬀective. During the course of this project, we observed that the landscape of large language models and computer vision was rapidly changing, with the release of four major neural networks in the latter half of 2022. This trend is likely to continue, with the speed of innovation and openness in the ﬁeld leading to falling costs of investigative projects. Based on our experiences, we believe that it is crucial to move beyond interdisciplinary projects and towards true trans-disciplinary projects. “Trans-disciplinary” refers to a colla- borative approach that integrates knowledge and skills from multiple disciplines to solve complex problems and address real-world challenges. It diﬀers from interdisciplinary teamwork in that it involves active participation and collaboration from all stakeholders including those outside the ﬁeld of expertise, to ensure that the solutions produced are holistic and relevant to the real-world context. Additionally, it requires participants to develop joint theoretical and methodological frameworks to guide the teamwork. In order to maximize the chances of success we have developed a recommended workﬂow summarized in Figure 1. We recommend prioritizing projects with well-stated research questions and a clear hypothesis, while also considering the potential value of the database itself, even in the absence of a “smoking gun”. Moreover, it is important to keep in mind that historical data can be missing, incomplete and diﬃcult to interpret, therefore, we recommend focusing on projects based on recent or current time periods. Happily, data are becoming increasingly available, thanks to the active contribution of both private and public bodies, such that hopefully this restriction will diminish with JOURNALISM PRACTICE 13 time. Additionally, we suggest using explainable methods and visualization techniques that are easily understandable to journalists, editors, and the general public. In addition to the tangible outcomes of these projects in the form of news reports and documentaries, we also gained valuable insights into the challenges and complexities of these types of collaborations. We found that the investigations were more productive when both journalists and AI specialists became literate in each other’s ﬁelds and Figure 1. Recommended workﬂow to successfully implement and develop an AI Journalism project. This recommendation is based on the practice and experience of the projects we describe in this article, and it aims to guide other journalists on how to implement AI in their newsrooms. Figure 2. Schematic representation of what we envision as trans-disciplinary collaborations between AI experts and Investigative Journalists. These two professional ﬁgures do not work independently, but actively collaborate with each other integrating their skills to solve complex problems. 14 M. FRIDMAN ET AL. engaged in a mutual learning process, as represented in Figure 2. This highlights the importance of using existing algorithms, programs, and models, as well as developing an understanding of the broader range of techniques in AI and data analysis. Data journalism has emerged as an important ﬁeld in contemporary journalism. The rise of big data, open data and data visualization technologies have enabled journalists to leverage data in innovative ways to tell more compelling stories. Data journalism oﬀers a new way of reporting that is grounded in the analysis of large data sets, and that allows for the creation of new insights that would not be possible through traditional reporting methods. In this paper, we explore the role of data journalism in contemporary journalism and examine the ways in which it is transforming the ﬁeld of journalism. Acknowledgment We thank Gustavo Borges Moreno e Mello for the main contribution in establishing the “The AI Jour- nalism Resource Center” and supporting the group in obtaining the necessary fundings supporting the work presented in this article. We also thank Morten Goodwin for contributing to the develop- ment of the projects with stimulating discussions and insight. Disclosure Statement No potential conﬂict of interest was reported by the author(s). Funding This work was supported by Artiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi, Oslo Metropolitan University, Oslo, Norway and Fritt Ord Foundation and the Norwegian Directorate for Higher Education and Skills. ORCID M. Fridman R. Krøvel F. Palumbo References AI and the Future of Journalism. n.d. Accessed September 3, 2021. of-journalism/. Amazon Mining Watch. n.d. Accessed February 27, 2023. Anderson, C. W. 2018. Apostles of Certainty. Vol. 1. Oxford University Press. oso/9780190492335.001.0001. Ausserhofer, J., R. Gutounig, M. Oppermann, M. Oppermann, S. Matiasek, and E. Goldgruber. 2017. “The Dataﬁcation of Data Journalism Scholarship: Focal Points, Methods, and Research Propositions for the Investigation of Data-Intensive Newswork.” Journalism: Theory, Practice & Criticism 21: 950–973. Barroca, L., H. Sharp, D. Salah, K. Taylor, and P. Gregory. 2018. “Bridging the Gap between Research and Agile Practice: An Evolutionary Model.” International Journal of System Assurance Engineering and Management 9 (2): 323–334. Beckett, P. 2019. Ownership, Financial Accountability and the law: Transparency Strategies and Counter-Initiatives. London: Routledge, Taylor & Francis Group. JOURNALISM PRACTICE 15 Biesta, G. 2007. “Bridging the Gap between Educational Research and Educational Practice: The Need for Critical Distance.” Educational Research and Evaluation 13 (3): 295–301. org/10.1080/13803610701640227. Biggs, M. A. R., and D. Büchler. 2007. “Rigor and Practice-Based Research.” Design Issues 23 (3): 62–69. Borges-Rey, E. 2016. “Unravelling Data Journalism a Study of Data Journalism Practice in British Newsrooms.” Journalism Practice 10 (7): 833–843. 1159921. Bounegru, L., and J. Grey, eds. 2021. The Data Journalism Handbook: Towards a Critical Data Practice. Amsterdam: Amsterdam University Press. Brreg.no. n.d. Brønnøysundregistrene. Accessed February 28, 2023. Buolamwini, J., and T. Gebru. 2018. “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classiﬁcation.” In Proceedings of the 1st Conference on Fairness, Accountability and Transparency, edited by S. A. Friedler, and C. Wilson, 77–91. Vol. 81. PMLR. Challenges and Opportunities – Survey – .State of .Data .Journalism 2022. n.d. Accessed February 28, 2023. Cobham, A., and P. Janský. 2020. Estimating Illicit Financial Flows: A Critical Guide to the Data, Methodologies, and Findings. 1st ed. Oxford University PressOxford. oso/9780198854418.001.0001 Crawford, Kate, and Jason Schultz. 2014. “Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms.” Boston College Law Review 55: 93. de-Lima-Santos, M.-F., and W. Ceron. 2022. “Artiﬁcial Intelligence in News Media: Current Perceptions and Future Outlook.” Journalism and Media 3 (1): 13–26. journalmedia3010002. De-Lima-Santos, M. F., and R. Salaverría. 2021. “From data journalism to artiﬁcial intelligence: chal- lenges faced by La Nación in implementing computer vision in news reporting.” Palabra Clave 24 (3). Dörr, K. N. 2016. “Mapping the Field of Algorithmic Journalism.” Digital Journalism 4 (6): 700–722. EU Court of Justice delivers blow to beneﬁcial ownership … . 2022, November 22. Transparency.Org. ownership-transparency. Extractive Industries Transparency Initiative. n.d. EITI. Accessed February 28, 2023. Felle, T. 2016. “Digital Watchdogs? Data Reporting and the News Media’s Traditional ‘Fourth Estate’ Function.” Journalism 17 (1): 85–96. Fink, K., and C. W. Anderson. 2015. “Data Journalism in the United States: Beyond the “Usual Suspects”.” Journalism Studies 16 (4): 467–481. Hacks/Hackers LDN (Director). 2019, November 29. AI & Journalism: New powers, new responsibil- ities \textbar Charlie Beckett. qgP14TK8U&app=desktop. Helsedirektoratet. 2021. Norsk kodeverk for uønskede pasienthendelser. helsedirektoratet.no/rapporter/norsk-kodeverk-for-uonskede-pasienthendelser/Norsk% 20kodeverk%20for%20uønskede%20pasienthendelser.pdf/_/attachment/inline/e95247b1- bdb4-463b-b730-5a09398db917:88e99f1e911c29fd8101025ad12f685eef995b9c/Norsk% 20kodeverk%20for%20uønskede%20pasienthendelser.pdf. Hugging Face – The AI community building the future. n.d. Accessed March 1, 2023. https:// huggingface.co/. Infographic: The Scale Of The Pandora Papers Leak. 2021, October 4. Statista Infographics. https:// www.statista.com/chart/11698/the-scale-of-the-paradise-papers-leak. Jain, A., H. Patel, L. Nagalapatti, N. Gupta, S. Mehta, S. Guttula, S. Mujumdar, S. Afzal, R. Sharma Mittal, and V. Munigala. 2020. “Overview and Importance of Data Quality for Machine Learning Tasks.” Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 3561–3562. 16 M. FRIDMAN ET AL. Karlsson, M., and H. Sjøvaag. 2016. “Content Analysis and Online News: Epistemologies of Analysing the Ephemeral Web.” Digital Journalism 4 (1): 177–192. 1096619. Kommunereformen 2020. 2021, March 15. ssb.no. stat-rapportering/kommunereformen-2020. Making Transparency Possible. 2019. Cappelen Damm Akademisk/NOASP. noasp.64 Miroshnichenko, A. 2018. “AI to Bypass Creativity. Will Robots Replace Journalists? (The Answer Is “Yes”).” Information 9 (7): 183. NbAiLab/nb-bert-base-mnli Hugging Face. 2023, January 25. bert-base-mnli. Neo4j Graph Data Platform – The Leader in Graph Databases. n.d. Neo4j Graph Data Platform. Accessed March 1, 2023. NetworkX — NetworkX documentation. n.d. Accessed March 1, 2023. Niblock, S. 2007. “From “Knowing How” to “Being Able”: Negotiating the Meanings of Reﬂective Practice and Reﬂexive Research in Journalism Studies.” Journalism Practice 1 (1): 20–32. https:// doi.org/10.1080/17512780601078829. Niblock, S. 2012. “Envisioning Journalism Practice as Research.” Journalism Practice 6 (4): 497–512. Noain-Sánchez, A. 2022. “Addressing the Impact of Artiﬁcial Intelligence on Journalism: The Perception of Experts, Journalists and Academics.” Communication & Society 35 (3): 105–121. TheNorwegianTaxAdministration.2020.Petroleumsskattpå116milliarderkronerfor2019. skatteetaten.no/en/presse/nyhetsrommet/petroleumsskatt-pa-116-milliarder-kroner-for-2019/. NPD Fact Pages. n.d. Accessed May 1, 2022. O’Neil, C. 2016. Weapons of Math Destruction: How big Data Increases Inequality and Threatens Democracy. 1st ed. Crown. OpenCorporates: The Open Database Of The Corporate World. n.d. Accessed February 28, 2023. Open Ownership. n.d. Openownership.Org. Accessed February 28, 2023. openownership.org/en/. pandas—Python Data Analysis Library. n.d. Accessed March 1, 2023. Pandora Papers: An oﬀshore data tsunami - ICIJ. 2021, October 6. 20211006063105/ leak-dataset/. Parratt-Fernández, S., J. Mayoral-Sánchez, and M. Mera-Fernández. 2021. “Aplicación de la inteligen- cia artiﬁcial al periodismo: Análisis de la producción académica.” El Profesional de La Información, e300317. Radon, J., and M. Achuthan. 2017. “Beneﬁcial Ownership Disclosure.” Journal of International Aﬀairs 70 (2): 85–108. JSTOR. Robie, D. 2015. “Advocating Journalism Practice-as-research: A Case for Recognition in the New Zealand PBRF Context.” Asia Paciﬁc Media Educator 25 (1): 62–73. 1326365X15575591. Rodríguez, M. T., S. Nunes, and T. Devezas. 2015. “Telling Stories with Data Visualization.” Proceedings of the 2015 Workshop on Narrative & Hypertext - NHT 15: 7–11. 1145/2804565.2804567. Sachs, J. D., and A. M. Warner. 2001. “The Curse of Natural Resources.” European Economic Review 45 (4–6): 827–838. Santos, M. F. D. L., and M.-F. de-Lima-Santos. 2022. “ProPublica’s Data Journalism: How Multidisciplinary Teams and Hybrid Proﬁles Create Impactful Data Stories.” Media and Communication, Skattemotiverte transaksjoner – opplysningsplikt og fradragsrett. November 13, 2020. HR-2020- 2200-A (Høyesterett (Norwegian Supreme Court)). avgjorelser/2020/hoyesterett-straﬀ/hr-2020-2200-a/. JOURNALISM PRACTICE 17 Skup.no. n.d. Accessed February 28, 2023. Stalph, F. 2018. “Classifying Data Journalism: A Content Analysis of Daily Data-Driven Stories.” Journalism Practice 12 (10): 1332–1350. The State of Data Journalism (No. 2022). 2023. datajournalism.com. survey/2022/. Statistisk sentralbyrå. 2023, February 28. SSB. Stiglitz, J. 2002. “Transparency in Government.” In The Right to Tell: The Role of Mass Media in Economic Development. 1st ed. World Bank Publications. Stray, J. 2019a. “Making Artiﬁcial Intelligence Work for Investigative Journalism.” Digital Journalism 7 (8): 1076–1097. Túñez-López, J.-M., C. Fieiras-Ceide, and M. Vaz-Álvarez. 2021. “Impact of Artiﬁcial Intelligence on Journalism: Transformations in the Company, Products, Contents and Professional Proﬁle.” Communication & Society 34 (1): 177–193. Vear, C. ed. 2022. The Routledge International Handbook of Practice-Based Research. Routledge. Waskom, M. 2021. “seaborn: Statistical Data Visualization.” Journal of Open Source Software 6 (60): 3021. Web64. 2023. Norwegian NLP Resources. (Original work published 2016). Weber, M. 2021. “AI, Media and the Future of News on the Web.” 13th ACM Web Science Conference 2021: 10. Wu, S., E. C. Tandoc, and C. T. Salmon. 2019. “When Journalism and Automation Intersect: Assessing the Inﬂuence of the Technological Field on Contemporary Newsrooms.” Journalism Practice 13 (10): 1238–1254. Young, M. L., A. Hermida, and J. Fulda. 2018. What Makes for Great Data Journalism. Journalism Practice 12 (1): 115–135. Zamith, R. 2019. “Transparency, Interactivity, Diversity, and Information Provenance in Everyday Data Journalism.” Digital Journalism 7 (4): 470–489. 1554409. Zhao, J., T. Wang, M. Yatskar, V. Ordonez, and K.-W. Chang. 2018. Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods. 18 M. FRIDMAN ET AL."
Information processing in the vertebrate habenula,Stephanie Fore and Fabrizio Palumbo and Robbrecht Pelgrims and Emre Yaksi,2018,,78,Seminars in Cell & Developmental Biology,article,"Seminars
 in
 Cell
 &
 Developmental
 Biology
 78
 (2018)
 130–139
Contents
 lists
 available
 at
 ScienceDirect
Seminars
 in
 Cell
 &
 Developmental
 Biology
j
 ourna
 l
 ho
 me  pa
 g
 e:
 www.elsevier.com/locate/semcdb
Review
Information
 processing
 in
 the
 vertebrate
 habenula
Stephanie
 Fore, Fabrizio
 Palumbo,
 Robbrecht
 Pelgrims,
 Emre
 Yaksi ∗
Kavli
 Institute
 for
 Systems
 Neuroscience
 and
 Centre
 for
 Neural
 Computation,
 Norwegian
 University
 of
 Science
 and
 Technology,
 Olav
 Kyrres
 Gate
 9,
Norwegian
 Brain
 Centre,
 7491
 Trondheim,
 Norway
a
 r  t
 i c  l e  
i  n  f  o
Article
 history:
Received
 23
 March
 2017
Received
 in
 revised
 form
 12
 July
 2017
Accepted
 5
 August
 2017
Available
 online
 7
 August
 2017
Keywords:
Habenula
Prediction
 error
Mood
 disorders
Social
 behavior
Addiction
Spontaneous
 activity
Ongoing
 activity
Default
 mode
 network
Sensory
 activity
Sensory
 processing
Asymmetry
Learning
Neural
 circuits
Stress
Anxiety
Fear
Attractor
 networks
Ventral
 tegmental
 area
Raphe
 nucleus
Interpeduncular
 nucleus
Sensory
 systems
a
 b
 s
 t  r  a
 c  t
The  habenula
 is  a brain
 region
 that  has  gained
 increasing
 popularity
 over  the  recent  years
 due  to
 its
role
 in  processing
 value-related
 and  experience-dependent
 information
 with  a strong
 link to depression,
addiction,
 sleep
 and  social  interactions.
 This  small  diencephalic
 nucleus
 is proposed
 to  act as  a  multimodal
hub
 or  a switchboard,
 where
 inputs
 from  different
 brain  regions  converge.
 These  diverse  inputs  to the
habenula
 carry  information
 about  the sensory
 world  and the  animal’s
 internal
 state,  such  as reward
expectation
 or  mood.
 However,
 it  is not  clear  how  these
 diverse
 habenular
 inputs  interact
 with  each
other
 and  how  such  interactions
 contribute
 to  the  function
 of  habenular
 circuits  in regulating
 behavioral
responses
 in various
 tasks  and
 contexts.
 In  this  review,
 we  aim  to  discuss
 how  information
 processing
 in
habenular
 circuits,
 can  contribute
 to  speciﬁc
 behavioral
 programs
 that  are  attributed  to  the  habenula.
©
 2017  Elsevier
 Ltd.
 All  rights
 reserved.
Contents
1.
 
The  role  of  the  habenula
 in  generating
 complex
 behaviors
 .  . .  .  . . .  .  . . . .  .  .  .  .  . . .  . . .  .  . . .  . . .  . . . .  . . .  .  . . .  .  . . .  . .  . . .  .  . .  . .  .  . . .  .  . . .  .  . .  .  . .  .  . . . . . .  . . .  .  .  .  .  . .  .  .  . .  . . 131
1.1.
 
Learning,  encoding  errors  and  negative
 outcomes
 . . . .  . . . . . .  .  . . .  .  .  .  . . . .  .  . . .  .  . . . . .  .  . . .  .  .  . .  .  .  . . .  . . .  .  . . . .  . . .  . . . .  . . .  .  . . .  .  .  . .  . .  .  .  .  .  . . .  . . . . .
 .  .  . . .  . .  . 131
1.2.
 
Addiction
 . . .  .  .  . . .  .  . . .  . . . . . . .  .  . . .  .  . . .  .  . .  .  .  . . . . . . . . . . . . .  .  . . . .  . . .  . . . . .  . . .  .  .  . . .  . . .  . . .  . . . .  . . .  . . . .  . . .  . . . .  . . .  .  .  . .  .  .  . .  . . .  . .  .  . .  .  . . . .  .  . . . . .  .  .  .  .  . .  . . . .  . . . .  . 132
1.3.
 
Mood  disorders
 and  social  behaviors
 . . . . .  . . . .  . . .  .  . . .  . . . .  . . . .  .  . . . .  .  . .  .  . .  . . .  . . . .  . .  . . . .  . . .  . . . .  .  . .  . . . .  . . .  .  . . .  . . .  . . . .  . . .  .  . . . .  .  .  . . .  .  .  .  . .  .  .  . . . . . . . .  .  .  132
2.
 
Sensory
 representations
 in the  habenula  . .  . . . . . . .  . . .  . . . .  .  . .  . . . .  . . .  .  . . .  .  . .  .  . . .  . . .  .  . . .  . . . .  . . . . .  . . .  . .  . . .  . . .  . . .  . .  . .  .  . .  . .  . . .  . . .  . . . .  .  . . . .
 . . . . .  .  .  .  .  . .  .  . .  . . . . 133
2.1.
 
Electroreception
 and  vestibular
 system
 .  . . .  .  . . . .  . . .  . . . . . . .  . . . .  .  . . .  .  .  . . .  .  .  . . .  . . .  . .  . . . . .  . . .  .  . . .  .  . . .  .  .  . . .  . . . . .  . .  .  . .  .  .  . . .  .  .  .  . . . .  . . .
 .  .  .  .  . .  .
 .  .  . . . . .  . 133
2.2.
 
Olfaction
 .  . . . .  . .  .  . . .  . . . .  . . .  . . . .  . . .  .  . . .  . . .  . .  . .  . . . .  .  . .  .  . . . .  . . .  . . . .  . . .  . . . .  . . .  . . . . .  .  .  . . .  .  . . . .  . . .  . .  . . .  .  .  . . .  .  . . .  .  . . .  . . .  .  . . .  .  . .  . . .  . .  .  .  . .  . . . . . . . . . .  .  .  . .  . 133
2.3.
 
Photoreception
 and  vision  .  .  . . .  .  . . . . . .  . . . . . . . . . . .  .  . . .  .  . . .  . . .  . . .  .  .  .  .  . .  . . . .  . . .  . . .  . . . . . . .  . . .  . . . . .  . . .  . .  .  . . . .  . . .  . . . .  . . . .  . . . .  . . . . .
 .  . . .  .  .  .  . . .  .  . .  . . . .  . . 134
3.
 
Ongoing
 spontaneous
 activity
 in the  habenula  . .  .  . . .  . . . .  . . .  . . . .  . . .  . . . .  .  . . . .  . . .  .  . .  . . .  . . . .  . . .  . .  . .  . . .  .  . . .  . . . .  .  . . . .  .  . .  . . .  . . . .  . . . .  . .  .  . . . .  .  . . .  .  .  . . . .  .  . . .  . . .  134
3.1.
 
Implications
 of  changing
 ongoing  activity  in  habenular
 circuits.  .  .  . . .  .  . .  . . .  .  . .  .  . . .  . . . . . . .  .  . . .  .  . .  .  . . .  . .  . .  .  . .  .  . . .  . . .  .  . . .  .  .  .  .  .  .  . . . . .  .  . . . .  .  . .  . . .  .135
3.2.
 
Interactions
 of spontaneous
 and  sensory
 driven  activity  in  the  habenula
 . .  . . .  . . . . . . .  .  . . .  .  .  . .  . . .  .  .  . . .  . . . . .  . . .  . . . . . . .  .  . . . .  .  . . . .  .  . .  .  . .  .  . . .  .  . . . . 135
Acknowledgments
 . . . .  .  . . .  .  . . .  .  . . .  . . . . . . .  . . . .  . . .  .  . . .  .  .  .  .  .  .  . .  . . .  . . .  .  . . .  .  . . .  .  .  .  .  . .  . .  . . .  . . . . .  . . .  . . .  . . . .  .  . . .  .  .  . .  . .  .  . . .  .  . . .  .  . .  .  .  . . . . .  .  . .  .  . .  .  .  .  .  .  . .  .  . .  .  . . .  . . 136
References
 .  . .  . . .  .  . . . .  .  .  . . .  .  . . .  .  . .  . . . .  . . . . . . .  .  . . .  .  . . .  .  .  . .  .  . . .  .  . .  .  . . .  .  . . .  . . .  . . . .  .  . .  . .  . . .  . . . .  .  .  . .  . .  . . .  . . .  . . .  . . . .  .  . . .  . .  .  .  . . .  .  . . .  .  .  . .  .  . . . . . .  . . .  . .  .  . .  .  . .  . .  . . .  136
∗Corresponding
 author.
E-mail
 address:
 emre.yaksi@ntnu.no
 (E.
 Yaksi).
https://doi.org/10.1016/j.semcdb.2017.08.019
1084-9521/©
 2017
 Elsevier
 Ltd.
 All
 rights
 reserved.
 S.
 Fore
 et
 al.
 /
 Seminars
 in
 Cell
 &
 Developmental
 Biology
 78
 (2018)
 130–139
 
131
The
 habenula
 (Hb)
 is
 an
 evolutionarily
 conserved
 diencephalic
nucleus,
 connecting
 forebrain
 regions
 such
 as
 prefrontal
 cortex
(PFC)
 [1], septohippocampal
 region
 [2]
 and
 the
 Basal
 Ganglia
[3–6], with
 downstream
 monoaminergic
 nuclei,
 such
 as
 the
 ven-
tral
 tegmental
 area/rostromedial
 tegmental
 nucleus
 (VTA/RMTg)
[7–13]
 and
 the
 Raphe
 nuclei
 [2,6,11,14–16], as
 well
 as
 the
 interpe-
duncular
 nucleus
 (IPN)
 [6]
 (Fig.
 1A,B).
Already
 in
 1914,
 experimental
 evidence
 highlighted
 the
 role
 of
the
 Hb
 in
 regulating
 the
 valence
 of
 behavioral
 outcomes.
 It
 was
observed
 that
 electrostimulation
 of
 habenular
 efferents,
 in
 chim-
panzees,
 induced
 a
 respiration
 pattern
 resembling
 laughter
 [17,18].
However,
 it
 was
 not
 until
 the
 eighties
 that
 researchers
 proposed
the
 idea
 of
 the
 Hb
 steering
 emotionally
 involved
 behavior
 by
 the
modulation
 of
 dopamine
 neurons
 [19]. With
 the
 reﬁnement
 of
experimental
 tools,
 as
 well
 as
 the
 advent
 of
 novel
 techniques
 such
as
 optogenetics
 and
 molecular
 tools,
 it
 became
 possible
 to
 investi-
gate
 and
 further
 subdivide
 the
 roles
 of
 the
 Hb
 in
 a
 broader
 range
of
 behaviors
 related
 to
 learning,
 depression,
 addiction,
 sleep
 and
social
 interactions.
The
 mammalian
 Hb
 consists
 of
 at
 least
 two
 functionally
 segre-
gated
 subnuclei:
 the
 medial
 (MHb)
 and
 the
 lateral
 habenula
 (LHb).
The
 MHb
 was
 suggested
 to
 play
 an
 important
 role
 in
 anxiety,
 fear,
depression
 and
 nicotine
 addiction
 [20–24]. Moreover,
 MHb
 activity
was
 shown
 to
 be
 regulated
 by
 circadian
 rhythm
 [25]. Yet,
 functional
studies
 of
 the
 MHb
 have
 been
 difﬁcult
 in
 mammals
 due
 to
 its
 small
volume
 and
 deep
 location
 right
 next
 to
 the
 third
 ventricle
 [26].
 On
the
 other
 hand,
 a
 lot
 more
 studies
 have
 investigated
 the
 role
 of
the
 LHb
 in
 brain
 function
 and
 animal
 behavior,
 with
 a
 strong
 focus
on
 regulation
 of
 dopaminergic
 and
 serotonergic
 nuclei
 in
 order
 to
shape
 both
 innate
 and
 conditioned
 behaviors
 [26].
Research
 on
 the
 Hb
 has
 been
 diverse,
 covering
 multiple
 ques-
tions
 ranging
 from
 the
 role
 of
 the
 Hb
 in
 learning
 and
 cognitive
function,
 to
 its
 involvement
 in
 mood
 disorders
 and
 addiction
 in
human
 patients.
 Moreover,
 the
 Hb
 has
 always
 been
 an
 attractive
brain
 region
 for
 those
 who
 are
 interested
 in
 studying
 the
 devel-
opment
 of
 brain
 asymmetries
 and
 their
 potential
 function.
 Finally,
an
 increasing
 amount
 of
 evidence
 suggests
 an
 important
 role
 for
the
 Hb
 in
 sensory
 information
 processing
 in
 several
 animal
 models.
While
 all
 these
 exciting
 results
 contributed
 to
 our
 understanding
 of
the
 habenular
 function
 in
 the
 brain,
 the
 link
 between
 these
 diverse
disciplines
 of
 habenular
 research
 is
 not
 yet
 fully
 established.
 In
 this
review,
 we
 aim
 to
 provide
 a
 broad
 overview
 of
 the
 research
 con-
ducted
 on
 the
 Hb
 and
 try
 to
 link
 these
 studies
 that
 cover
 different
disciplines
 of
 neuroscience.
In the
 following
 sections,
 we
 will
 ﬁrst
 provide
 an
 overview
 of
the
 inputs
 and
 outputs
 of
 the
 habenular
 circuitry
 and
 the
 role
 of
these
 structures
 in
 different
 behaviors.
 Next,
 we
 will
 describe
 how
sensory
 information
 is
 received
 and
 processed
 in
 the
 Hb.
 We  then
suggest
 several
 hypotheses
 about
 how
 neural
 information
 from
different
 brain
 regions
 can
 be
 integrated
 at
 the
 level
 of
 the
 Hb.
We
 propose
 that
 the
 ongoing
 activity
 observed
 in
 the
 Hb,
 plays
 an
important
 role
 in
 reﬂecting
 the
 internal
 state
 of
 the
 animal,
 inte-
grating
 information
 from
 a
 number
 of
 brain
 regions
 and
 the
 sensory
systems.
1.
 The
 role
 of
 the
 habenula
 in
 generating
 complex
behaviors
1.1.
 Learning,
 encoding
 errors
 and
 negative
 outcomes
Seminal
 studies,
 using
 single-unit
 recordings
 in
 primates,
showed
 a
 direct
 involvement
 of
 the
 LHb
 in
 encoding
 prediction
error.
 One
 of
 these
 studies
 reported
 that
 several
 LHb
 neurons
 were
activated
 by
 no-reward
 predicting
 cues
 as
 well
 as
 the
 absence
 of
 the
reward,
 while
 they
 were
 inhibited
 by
 reward
 and
 reward
 predict-
ing
 stimuli
 [3]. The
 ﬁring
 rate
 of
 neurons
 inhibited
 by
 reward
 and
reward
 predicting
 cues,
 is
 also
 directly
 proportional
 to
 the
 proba-
bility
 of
 receiving
 the
 reward
 [27,28]. Moreover,
 the
 activity
 of
 LHb
neurons
 is
 shown
 to
 follow
 the
 activity
 of
 the
 dopaminergic
 neu-
rons
 in
 the
 substantia
 nigra
 pars
 compacta
 (SNc)
 in
 case
 of
 a
 reward
and
 to
 precede
 it
 in
 case
 of
 reward
 omission
 [3,29].
Rodent
 studies
 have
 further
 unraveled
 the
 complexity
 of
 this
interconnected
 circuit
 composed
 of
 feedback
 and
 feedforward
 sig-
naling
 between
 the
 LHb,
 the
 monoaminergic
 brainstem
 nuclei
 and
the
 basal
 ganglia.
 The
 LHb
 was
 shown
 to
 inhibit
 dopaminergic
 neu-
rons
 of
 the
 VTA
 indirectly
 via
 the
 RMTg
 [8,12,30–33]
 or
 directly
by
 exciting
 local
 GABAergic
 neurons
 in
 the
 VTA
 [12,34]. Exposure
to
 aversive
 stimuli
 such
 as
 foot
 shocks,
 induces
 plasticity
 in
 the
LHb-RMTg
 pathway
 [33]
 but
 also
 results
 in
 an
 increased
 ﬁring
 in
the
 GABAergic
 population
 of
 the
 VTA
 [35]. Stimulating
 LHb
 neu-
rons
 directly
 induces
 place
 avoidance,
 a
 behavior
 characterized
 by
reduced
 exploration
 of
 the
 stimulation-coupled
 area
 [35–37].
 In
addition,
 the
 role
 of
 the
 LHb
 has
 also
 been
 investigated
 in
 terms
of
 cost-beneﬁt
 decision
 making.
 Rats
 learnt
 to
 receive
 a
 greater
beneﬁt
 (four
 food
 pellets
 instead
 of
 one)
 when
 their
 waiting
 time
was
 increased.
 When
 the
 probability
 of
 receiving
 the
 award
 was
low,
 the
 cost
 of
 waiting
 became
 too
 high.
 Lesioning
 the
 LHb
 dis-
abled
 the
 rats
 from
 making
 such
 cost-efﬁcient
 decisions,
 without
affecting
 the
 animal’s
 ability
 to
 evaluate
 the
 magnitude
 of
 the
immediate
 reward
 [32]. While
 VTA
 receives
 information
 directly
or
 indirectly
 from
 LHb,
 it
 also
 sends
 feedback
 projections
 inhibit-
ing
 LHb
 neurons
 [8]. Investigation
 of
 these
 projections
 reveals
 a
co-release
 of
 glutamate
 and
 GABA
 [7,38], which
 suggests
 that
 mod-
ulating
 the
 co-release
 ratio
 can
 be
 a
 potential
 mechanism
 of
 tuning
habenular
 activity.
 Interestingly,
 recordings
 of
 VTA
 neurons
 show
two
 different
 populations
 encoding
 aversive
 and
 rewarding
 stim-
uli
 with
 different
 dynamics.
 The
 authors
 showed
 that,
 while
 most
GABAergic
 VTA
 neurons
 respond
 to
 aversive
 stimuli,
 the
 majority
 of
dopaminergic
 neurons
 respond
 to
 reward
 related
 information
 [39].
These
 results
 indicate
 that
 the
 LHb
 modulates
 and
 is
 modulated
 by
the
 VTA,
 which
 plays
 a
 role
 in
 dopaminergic
 regulation
 of
 animal
behavior.
 In
 addition
 to
 modulating
 dopaminergic
 signaling,
 the
Hb
 was
 also
 shown
 to
 regulate
 serotonin
 release
 directly
 through
LHb
 projections
 to
 the
 Raphe
 nuclei
 [32,40–42]
 and
 indirectly
 via
the
 projections
 of
 the
 LHb
 and
 the
 MHb
 to
 the
 RMTg
 [16]
 and
 the
IPN
 [42]
 respectively.
 The
 role
 of
 serotonin
 in
 reward
 processing
and
 learning
 is
 still
 under
 investigation.
 However,
 accumulating
evidence
 supports
 its
 involvement
 in
 these
 phenomena
 [43–47].
Taken
 together,
 these
 ﬁndings
 suggests
 that
 both
 dopamine
 and
serotonin
 modulate
 the
 processing
 of
 stimulus-related
 information
bidirectionally,
 shaping
 it
 based
 on
 the
 internal
 state
 of
 the
 animal
in
 order
 to
 tune
 subsequent
 behavioral
 outcomes.
The
 mammalian
 lateral
 and
 medial
 Hb
 ﬁnd
 their
 respective
homologues
 as
 the
 ventral
 habenula
 (vHb)
 and
 the
 dorsal
 habenula
(dHb)
 in
 zebraﬁsh
 (Fig.
 1C)
 [4,6]. Lesioning
 the
 dHb,
 was
 shown
to
 prevent
 zebraﬁsh
 from
 coping
 with
 threats
 in
 a
 stressful
 context
and
 induces
 freezing
 (or
 helplessness),
 rather
 than
 escape
 or
 avoid-
ance
 [48,49].
 A
 complementary
 study
 [6]
 further
 showed
 that
 a
population
 of
 vHb
 neurons
 encodes
 the
 negative
 expectation
 value
that
 is
 associated
 with
 the
 conditioned
 stimulus,
 by
 increasing
 their
tonic
 response
 to
 the
 conditioned
 stimulus
 during
 learning.
 In
 addi-
tion,
 the
 phasically
 active
 vHb
 neurons
 represent
 the
 prediction
error.
 Along
 with
 this,
 the
 same
 study
 showed
 that
 lesioning
 the
vHb
 impairs
 the
 ability
 of
 the
 ﬁsh
 to
 perform
 active
 avoidance,
without
 affecting
 the
 switch
 from
 freezing
 to
 agitation
 as
 is
 the
case
 for
 the
 dHb
 ablation.
 These
 results
 are
 in
 line
 with
 the
 two-
factor
 theory
 of
 active
 avoidance.
 At
 ﬁrst,
 an
 aversive
 stimulus
 is
associated
 with
 a
 biologically
 neutral
 stimulus,
 resulting
 in
 a
 fear
response
 when
 the
 neutral
 stimulus
 is
 presented
 (Pavlovian
 factor,
association
 phase).
 Subsequently,
 the
 transition
 from
 an
 unsafe
 to
a
 safe
 state
 can
 then
 be
 further
 associated
 to
 a
 speciﬁc
 performed
 132
 
S.
 Fore
 et
 al.
 /
 Seminars
 in
 Cell
 &
 Developmental
 Biology
 78
 (2018)
 130–139
Fig.
 1.
 Schematic
 overview
 of
 the
 habenula
 homologues
 in
 the
 mammalian
 and
 non-mammalian
 brain
 and
 their
 afferent
 and
 efferent
 neural
 pathways.
 Sagittal
 view
 of
 the
rodent
 (A)
 and
 the
 zebraﬁsh
 (B)
 brain
 showing
 that
 the
 habenula
 connects
 forebrain,
 midbrain
 and
 hindbrain
 nuclei
 in
 both
 vertebrates.
 Green:
 afferents,
 blue:
 efferents,
 yellow:
bidirectional
 connections.
 Schematic
 representations
 of
 transverse
 views
 of
 both
 the
 rodent
 (rat)
 (top
 panel)
 and
 zebraﬁsh
 (bottom
 panel)
 habenula
 showing
 the
 homologue
habenula
 regions
 and
 their
 efferents
 (adapted
 from
 Amo
 et
 al.
 [6])
 (C).Abbreviations:
 Hb,
 habenula;
 mHb,
 medial
 habenula;
 LHb,
 lateral
 habenula;
 dHb,
 dorsal
 habenula;
vHb,
 ventral
 habenula;
 OB,
 olfactory
 bulb;
 EN,
 entopeduncular
 nucleus;
 PO,
 preoptic
 area;
 TH,
 thalamus;
 PP,
 parapineal
 organ;
 Vv,
 ventral
 area
 of
 the
 subpallium;
 pHT/PT,
posterior
 hypothalamus/posterior
 tuberculum;
 IPN,
 interpeduncular
 nucleus;
 R,
 raphe;
 S/DBB,
 septum/diagonal
 band
 of
 Broca;
 RMTg,
 rostromedial
 tegmental
 nucleus;
 NAc,
nucleus
 accumbens;
 LC,
 locus
 coeruleus;
 VTA,
 ventral
 tegmental
 area;
 SCN,
 suprachiasmatic
 nucleus;
 SNc;
 substantia
 nigra
 pars
 compacta;
 SC,
 superior
 colliculus;
 PAG,
periaqueductal
 gray;
 NI,
 nucleus
 Incertus;
 P,
 pineal;
 mPFC
 medial
 prefrontal
 cortex;.
behavior,
 which
 can
 act
 as
 a
 surrogate
 reward
 (instrumental
 factor,
goal-directed
 phase)
 [50,51]. Taken
 together,
 it
 appears
 that
 while
the
 zebraﬁsh
 dHb
 might
 be
 involved
 in
 the
 association
 phase
 of
 clas-
sical
 conditioning
 where
 a
 negative
 value
 is
 assigned
 to
 a
 previously
neutral
 stimulus,
 the
 zebraﬁsh
 vHb
 is
 involved
 in
 the
 goal-directed
phase
 of
 operant
 conditioning,
 when
 the
 animal
 learns
 that
 a
 spe-
ciﬁc
 behavior
 gives
 the
 possibility
 of
 escape
 [6].
1.2.
 Addiction
In
 addition
 to
 the
 extensive
 literature
 linking
 the
 Hb
 to
 learned
behaviors,
 the
 Hb
 is
 gaining
 popularity
 and
 receives
 increasing
clinical
 interest,
 as
 a
 number
 of
 studies
 in
 humans
 [52]
 and
rodents
 [52]
 have
 shown
 its
 involvement
 in
 addiction
 [53–55]
to
 nicotine
 [55–59], cocaine
 [60,61]
 and
 ethanol
 [62]. The
 Hb-
IPN
 pathway
 is
 particularly
 enriched
 with
 nicotinic
 acetylcholine
receptors
 (nAChRs)
 [57,59,63,64]. In
 human
 studies,
 small
 changes
in
 the
 genes
 encoding
 different
 subunits
 of
 these
 receptors,
 were
linked
 to
 a
 predisposition
 to
 nicotine
 addiction
 [52].
 In
 a
 rodent
model,
 high
 doses
 of
 nicotine
 were
 shown
 to
 facilitate
 LHb
 exci-
tation,
 by
 activating
 6-nAChRs,
 while
 low
 doses
 inhibit
 the
 LHb
via
 42-nAChRs
 [65]. This
 dose-dependent
 effect
 of
 nicotine
 is
also
 reﬂected
 in
 the
 behavior
 of
 the
 animal,
 since
 low
 doses
 of
nicotine
 induce
 conditioned
 place
 preference
 [66]
 while
 high
 doses
can
 induce
 place
 avoidance
 [59,67,68]. Moreover,
 nicotine
 has
 an
excitatory
 inﬂuence
 on
 the
 activity
 of
 dopaminergic
 neurons,
 pre-
dominantly
 in
 the
 posterior
 VTA
 [69].
 Similar
 behavioral
 effects
are
 observed
 with
 ethanol,
 where
 low
 doses
 induce
 conditioned
place
 aversion
 while
 higher
 doses
 induce
 place
 preference
 [62].
However,
 it
 is
 not
 clear
 if
 and
 how
 this
 dose-dependent
 behav-
ioral
 switch
 is
 mediated
 by
 the
 Hb.
 It
 was
 suggested
 that
 the
activation
 of
 dopaminergic
 neurons
 in
 the
 VTA,
 by
 high
 doses
 of
ethanol,
 might
 counterbalance
 the
 aversion
 effect
 driven
 by
 the
LHb
 [62]. In
 line
 with
 these
 results,
 cocaine
 self-administration
 was
shown
 to
 increase
 LHb
 neuron
 excitability
 [61]. Moreover,
 cocaine
withdrawal
 changes
 the
 GABA\Glutamate
 co-release
 ratio
 in
 the
pathway
 between
 the
 entopeduncular
 nucleus
 and
 the
 LHb,
 result-
ing
 in
 a
 disinhibition
 of
 the
 LHb,
 which
 could
 potentially
 lead
 to
 a
depressive-like
 state
 [5]. Interestingly,
 deep
 brain
 stimulation
 of
the
 LHb
 was
 shown
 to
 reduce
 cocaine
 intake
 in
 rats,
 as
 well
 as
cocaine
 and
 cocaine-cue
 related
 c-fos
 expression
 in
 the
 LHb
 [70],
suggesting
 that
 the
 LHb
 could
 be
 an
 interesting
 target
 for
 amelio-
rating
 the
 behavioral
 symptoms
 of
 addiction.
1.3.
 Mood
 disorders
 and
 social
 behaviors
Since
 habenular
 circuits
 are
 involved
 in
 encoding
 prediction
errors,
 coping
 with
 stress
 as
 well
 as
 controlling
 the
 activity
 of
dopaminergic
 and
 serotonergic
 brain
 nuclei,
 it
 is
 not
 surprising
that
 habenular
 dysfunction
 is
 associated
 with
 several
 mood
 dis-
orders,
 ranging
 from
 anxiety
 [71]
 to
 depression
 [52]. Patients
suffering
 from
 major
 depressive
 disorder
 were
 shown
 to
 have
 an
altered
 habenular
 volume
 [72,73]
 and
 baseline
 activity
 [40,74].
More
 speciﬁcally,
 during
 a
 passive
 conditioning
 task
 where
 an
 ini-
tially
 neutral
 cue
 is
 associated
 with
 a
 negative
 stimulus
 (an
 electric
shock),
 healthy
 participants
 show
 an
 increased
 cue-evoked
 activ-
ity
 in
 the
 Hb.
 Depressive
 patients
 however,
 show
 a
 decrease
 in
habenular
 activity
 as
 the
 cue-stimulus
 association
 strengthens
 [75].
Excitingly,
 deep
 brain
 stimulation
 of
 the
 Hb
 was
 linked
 to
 reduced
symptoms
 of
 depression
 in
 a
 human
 patient
 [76], which
 opens
 a
range
 of
 therapeutic
 treatments
 for
 depression
 by
 interfering
 with
habenular
 activity.
Despite
 these
 exciting
 results
 in
 humans,
 the
 neural
 mecha-
nisms
 underlying
 the
 role
 of
 habenular
 circuits
 in
 mood
 disorders
are
 still
 not
 fully
 understood.
 The
 dopaminergic
 neurons
 of
 the
medial
 VTA
 show
 a
 reduced
 activity
 in
 a
 rodent
 model
 for
 major
 S.
 Fore
 et
 al.
 /
 Seminars
 in
 Cell
 &
 Developmental
 Biology
 78
 (2018)
 130–139
 
133
Fig.
 2.
 Schematic
 overview
 of
 molecular
 and
 functional
 characteristics
 of
 the
 dHb
 in
 zebraﬁsh.
 (A)
 Dorsal
 view
 of
 dHb
 neurons
 responding
 asymmetrically
 to
 light
 (red),
 odor
(blue)
 or
 both
 (magenta)
 (adapted
 from
 Dreosti
 et
 al.
 [84]).
 L
 =
 left,
 R
 = right.
 Below
 are
 representative
 bar
 graphs
 of
 the
 percentage
 of
 light
 and
 odor-
 responsive
 neurons
 in
the
 total
 dHB
 population,
 showing
 asymmetric
 distribution
 across
 hemispheres.
 (B)
 Dorsal
 view
 of
 spontaneously
 active
 neurons
 in
 the
 dHb
 of
 juvenile
 zebraﬁsh
 (adapted
from
 Jetti
 et
 al.
 [96]).
 The
 neurons
 are
 subdivided
 and
 color
 coded
 into
 six
 different
 clusters,
 based
 on
 their
 similarity
 of
 neural
 activity
 over
 time
 as
 visualized
 in
 the
 activity
traces
 below.
 Neurons
 with
 similar
 neural
 activity
 are
 organized
 into
 spatial
 and
 functional
 clusters.(C)
 Transverse
 view
 of
 the
 neurotransmitter
 populations
 across
 the
 dHb
in
 adult
 zebraﬁsh
 (adapted
 from
 Decarvalho
 et
 al.
 [171]).
 The
 overall
 glutamatergic,
 cholinergic
 and
 peptidergic
 populations
 are
 asymmetrically
 distributed
 over
 the
 two
hemispheres.
 Light
 blue
 plane
 shows
 the
 rough
 location
 of
 cross
 section
 in
 A
 and
 B.
depressive
 disorder
 based
 on
 chronic
 mild
 stress
 (CMS)
 [77]. Fur-
ther
 investigation
 identiﬁed
 two
 potential
 drivers
 for
 this
 activity
decrease
 in
 the
 VTA,
 the
 LHb
 and
 the
 infralimbic
 prefrontal
 cor-
tex
 (ILPFC).
 While
 both
 the
 LHb
 and
 the
 ILPFC
 inhibit
 dopaminergic
neurons
 in
 the
 VTA,
 the
 LHb
 preferentially
 inhibits
 the
 lateral
 VTA
instead
 of
 the
 medial
 VTA
 [77].
 This
 study
 therefore
 questions
 the
involvement
 of
 the
 Hb
 in
 the
 modulation
 of
 dopaminergic
 neurons
linked
 to
 the
 effects
 of
 CMS.
 However,
 parallel
 investigations
 show
 a
direct
 link
 between
 habenular
 hyperactivity
 and
 a
 depression-like
phenotype
 [78,79]. Interestingly,
 inhibiting
 glial
 glutamate
 reup-
take
 in
 the
 LHb
 induces
 an
 increase
 in
 neural
 ﬁring
 rate
 and
 c-fos
expression,
 which
 again
 resulted
 in
 depressive-like
 symptoms
 [80].
A
 recent
 study
 in
 zebraﬁsh,
 using
 another
 paradigm
 of
 inducing
stress
 by
 social
 conﬂict,
 reveals
 a
 direct
 role
 of
 the
 dHb
 in
 regu-
lating
 animal
 behavior.
 After
 a
 ﬁght
 between
 two
 ﬁsh,
 local
 ﬁeld
potential
 recordings
 in
 the
 IPN
 showed
 that
 loser
 ﬁsh
 have
 reduced
transmission
 in
 the
 pathway
 between
 the
 lateral
 dHb
 and
 the
 dor-
sal/intermediate
 IPN
 [81]. Complementary
 studies
 in
 rodents
 also
report
 that
 social
 isolation
 can
 induce
 c-fos
 expression
 in
 the
 MHb.
This
 effect
 could
 further
 be
 rescued
 by
 increasing
 the
 social
 inter-
action
 between
 animals
 [82,83].
Based
 on
 these
 ﬁndings
 Hb
 appears
 to
 have
 several
 roles
 in
 con-
trolling
 mood
 and
 social
 interactions,
 which
 are
 tightly
 linked
 to
one
 another.
 It
 is
 however
 not
 yet
 clear
 how
 neuronal
 signals
 are
processed
 by
 the
 Hb
 and
 how
 they
 relate
 to
 controlling
 mood
 and
social
 interactions
 in
 healthy
 individuals,
 as
 well
 as
 those
 who
 are
suffering
 from
 major
 depressive
 disorder.
2.
 Sensory
 representations
 in
 the
 habenula
Several
 studies
 showed
 that
 a
 diverse
 range
 of
 sensory
 modal-
ities
 can
 evoke
 robust
 responses
 in
 the
 non-mammalian
 Hb
[14,84,85]. On
 the
 contrary,
 only
 a
 smaller
 number
 of
 works
 on
 the
mammalian
 Hb
 report
 such
 sensory
 responses
 [86,87]. To
 gain
 more
insight
 into
 the
 role
 of
 sensory
 processing
 in
 the
 Hb,
 a
 more
 thor-
ough
 comparative
 approach
 is
 needed.
 Below
 we  discuss
 different
sensory
 modalities
 that
 are
 shown
 to
 be
 processed
 by
 habenular
circuits
 in
 a
 diverse
 range
 of
 animal
 models.
2.1.
 Electroreception
 and
 vestibular
 system
Functional
 measurements
 of
 the
 MHb
 homologue
 in
 lampreys,
showed
 that
 exposing
 lampreys
 to
 electric
 ﬁelds
 increases
 the
activity
 of
 Hb
 neurons
 and
 can
 initiate
 responses
 that
 are
 typical
 for
ﬂight
 and
 freezing
 behavior
 [88].
 Most
 likely,
 this
 information
 from
the
 electroreceptive
 organ
 is
 transferred
 indirectly
 to
 the
 Hb
 via
the
 pretectum.
 Retrograde
 tracing
 in
 the
 Hb
 indeed
 showed
 direct
projections
 from
 the
 pretectum,
 while
 retrograde
 tracing
 in
 the
 pre-
tectum
 itself
 showed
 direct
 projections
 from
 the
 electroreceptive
organ
 [14].
2.2.
 Olfaction
Anatomical
 tracing
 studies
 in
 lampreys
 also
 demonstrated
direct
 projections
 from
 the
 medial
 olfactory
 bulb
 (OB)
 to
 the
 MHb
homologue
 [14]. Odor
 stimulation
 of
 these
 medial
 OB
 neurons
 was
shown
 to
 activate
 spinal
 locomotor
 networks
 in
 lampreys
 [89],
which
 suggests
 a
 potential
 link
 between
 MHb
 projecting
 OB  neu-
rons
 and
 the
 initiation
 of
 fast
 motor
 behaviors.
 Such
 characteristic
movements
 that
 are
 tightly
 linked
 to
 odor
 cues
 are
 not
 only
 lim-
ited
 to
 lampreys,
 but
 were
 also
 observed
 in
 newborn
 rats,
 dogs,
mice
 and
 zebraﬁsh
 [90–93]. In
 line
 with
 studies
 in
 lampreys,
 trac-
ing
 studies
 in
 salamanders
 and
 in
 zebraﬁsh
 further
 conﬁrmed
 the
direct
 relay
 of
 olfactory
 information
 from
 OB  to
 the
 MHb
 homo-
logue
 [94,95]. Interestingly,
 it
 was
 also
 shown
 that
 zebraﬁsh
 mitral
cells
 from
 the
 mediodorsal
 OB
 send
 projections
 preferentially
 to
 the
right
 dHb,
 the
 MHb
 homologue
 in
 zebraﬁsh
 [95]. In
 vivo
 recordings
further
 conﬁrmed
 that
 odor
 responses
 in
 the
 dHb
 are
 asymmet-
ric
 across
 the
 hemispheres
 with
 stronger
 odor
 responses
 in
 the
right
 dHb
 [84,96]
 (Fig.
 2a).
 However,
 it
 appears
 that
 while
 odor
identity
 is
 precisely
 encoded
 by
 differential
 activation
 of
 zebraﬁsh
OB
 neurons
 [97,98], odor
 responses
 of
 dHb
 neurons
 are
 less
 odor
speciﬁc
 and
 respond
 broadly
 to
 odors
 from
 different
 categories
[96]. Moreover,
 a
 complementary
 study
 showed
 that
 dHb
 and
 vHb
neurons
 display
 distinct
 temporal
 delays
 in
 response
 to
 different
odorant
 categories
 and
 concentrations
 [85]. These
 results
 suggest
that
 the
 non-mammalian
 Hb
 receives
 information
 from
 a
 distinct
part
 of
 the
 olfactory
 system
 and
 relays
 olfactory
 information
 onto
its
 downstream
 monoaminergic
 targets
 [84].
 It
 is
 worth
 to
 note
 that
despite
 this
 extensive
 work
 in
 the
 non-mammalian
 Hb,
 it
 remains
unclear
 whether
 olfactory
 inputs
 are
 conserved
 in
 the
 mammalian
 134
 
S.
 Fore
 et
 al.
 /
 Seminars
 in
 Cell
 &
 Developmental
 Biology
 78
 (2018)
 130–139
Hb.
 Further
 studies
 are
 needed
 to
 reveal
 whether
 the
 Hb
 receives
olfactory
 information
 from
 the
 piriform
 cortex
 [99]
 or
 other
 parts
of
 the
 higher
 olfactory
 system
 [95,100]
 and
 what
 role
 the
 Hb
 plays
in
 olfactory
 processing
 within
 the
 context
 of
 behavioral
 plasticity
and
 learning.
2.3.
 Photoreception
 and
 vision
The
 parapineal
 (Pp)
 is
 a
 sensory
 organ
 that
 contains
 photorecep-
tors
 conveying
 information
 about
 the
 ambient
 illumination
 to
 the
brain
 and
 is
 thought
 to
 be
 involved
 in
 circadian
 rhythms
 [101–104].
This
 brain
 region
 is
 present
 in
 lampreys,
 bowﬁn,
 teleosts,
 reptiles
and
 birds,
 but
 it
 is
 absent
 in
 other
 vertebrate
 groups
 [105–108]. In
lampreys
 and
 in
 ﬁsh,
 the
 Pp
 projects
 asymmetrically
 to
 the
 left
 MHb
homologue
 [109–113]. The
 inﬂuence
 of
 the
 Pp
 on
 the
 Hb
 was
 shown
to
 contribute
 to
 asymmetries
 in
 gene
 expression,
 development
 and
function
 between
 the
 left
 and
 the
 right
 dHb
 [84,114]. However,
 it
 is
still
 unclear
 whether
 the
 Pp
 relays
 any
 information
 about
 ambient
light
 conditions
 to
 Hb
 neurons
 or
 whether
 it
 is
 merely
 a
 regulator
 in
habenular
 development.
 The
 ﬁrst
 functional
 investigation
 of
 visual
responses
 in
 the
 zebraﬁsh
 dHb
 suggests
 that
 the
 majority
 (if
 not
 all)
of
 the
 visual
 responses
 in
 the
 dHb
 do
 not
 arise
 from
 the
 Pp
 but
 likely
from
 the
 retina
 [84]. Indeed,
 the
 authors
 showed
 that
 eye
 removal
abolished
 all
 dHb
 visual
 responses,
 but
 laser
 ablation
 of
 the
 Pp
 did
not
 have
 a
 signiﬁcant
 effect
 on
 the
 dHb
 visual
 responses.
Intriguingly,
 dHb
 light
 responses,
 like
 odor
 responses,
 are
 asym-
metric
 across
 habenular
 hemispheres
 [84].
 Visual
 responses
 are
more
 prominent
 on
 the
 left
 dHb
 while
 odor
 responses
 are
 pre-
dominantly
 observed
 in
 the
 right
 dHb
 (Fig.
 2A).
 The
 asymmetric
segregation
 of
 sensory
 modalities
 is
 also
 preserved
 in
 the
 dorsoven-
tral
 organization
 of
 the
 Hb
 axonal
 targets
 in
 the
 IPN,
 which
highlights
 the
 importance
 of
 sensory
 segregation
 in
 the
 Hb
 for
information
 processing
 and
 controlling
 animal
 behavior.
 While
 the
function
 of
 the
 dorsoventral
 segregation
 of
 visual
 and
 olfactory
information
 in
 the
 IPN
 is
 not
 yet
 clear,
 the
 left-right
 segregation
of
 sensory
 modalities
 in
 Hb
 suggests
 a
 division
 of
 labor
 across
the
 habenular
 hemispheres.
 This
 could
 in
 principle
 increase
 the
information
 processing
 capacity
 of
 the
 Hb,
 as
 distinct
 computa-
tions
 would
 be
 processed
 by
 a
 dedicated
 hemisphere
 rather
 than
being
 duplicated
 in
 an
 alternatively
 symmetric
 and
 redundant
 sys-
tem
 [115]. Several
 perturbations
 were
 also
 shown
 to
 interfere
 with
these
 functional
 asymmetries
 between
 habenular
 hemispheres
[84]. Such
 experimental
 manipulations
 could
 be
 used
 to
 further
 test
whether
 disrupted
 habenular
 asymmetry
 leads
 to
 impairments
 in
behavioral
 performance
 during
 visual,
 olfactory
 and
 mixed
 visio-
olfactory
 tasks.
In
 the
 meantime,
 recent
 studies
 in
 ﬁsh
 have
 linked
 the
 visual
responses
 in
 Hb
 to
 light-preference
 and
 circadian
 behaviors
[116,117]. Furthermore,
 it
 was
 shown
 that
 a
 subpopulation
 of
ON-responsive
 retinal
 ganglion
 cells
 activates
 the
 dorsal
 thalamic
nuclei,
 which
 in
 turn
 activate
 and
 inhibit
 different
 populations
 of
the
 left
 dHb
 neurons
 with
 complex
 temporal
 response
 patterns
 in
a
 light
 intensity
 dependent
 manner
 [116,118]. In
 line
 with
 the
 role
of
 the
 Hb
 in
 these
 observed
 behaviors,
 Hb
 lesions
 in
 quails
 were
shown
 to
 be
 effective
 in
 suppressing
 inhibitory
 inﬂuences
 of
 light
stimulation
 [119], suggesting
 the
 presence
 of
 visual
 processing,
 also
in
 the
 bird
 Hb.
Only
 a
 limited
 number
 of
 studies
 have
 investigated
 sensory
 pro-
cessing
 in
 the
 mammalian
 Hb
 [86,87]. While
 the
 Hb
 is
 located
deep
 inside
 the
 mammalian
 brain,
 light-evoked
 responses
 were
also
 reported
 in
 the
 rodent
 LHb
 and
 MHb
 [86]. In
 vivo
 recordings
 of
both
 habenular
 subnuclei
 displayed
 excitatory
 and
 inhibitory
 char-
acteristics
 in
 response
 to
 light
 stimuli,
 suggesting
 that
 different
 Hb
neurons
 might
 encode
 light
 stimuli
 in
 different
 ways.
 Moreover,
 a
higher
 tonic
 ﬁring
 rate
 of
 Hb
 neurons
 was
 observed
 during
 the
 day
compared
 to
 night-time
 [86]. When
 visual
 responses
 were
 mea-
sured
 during
 night-time,
 LHb
 neurons
 exhibit
 signiﬁcantly
 stronger
light
 responses
 compared
 to
 the
 MHb.
 Hence,
 visual
 responses
through
 a
 retinoic
 pathway
 in
 the
 rodent
 Hb
 [120,121], might
 there-
fore
 be
 modulated
 by
 circadian
 rhythms
 related
 to
 day-night
 cycles
and
 illumination
 levels.
Nonetheless,
 in
 vivo
 recordings
 of
 neural
 activity
 in
 the
 mam-
malian
 Hb
 remain
 challenging.
 It
 is
 thus
 unclear
 whether
 the
sensory
 responses
 in
 the
 mammalian
 Hb
 are
 part
 of
 an
 evolu-
tionarily
 conserved
 pathway
 or
 whether
 the
 afferent
 regulation
 of
this
 circuitry
 has
 changed
 throughout
 evolution
 [14]. Higher-order
brain
 areas
 that
 process
 more
 complex
 features
 of
 the
 sensory
 infor-
mation
 in
 mammals,
 might
 have
 replaced
 the
 direct
 sensory
 input
to
 the
 Hb
 that
 was
 observed
 in
 lampreys
 and
 teleosts.
 This
 could,
in
 turn,
 help
 mammals
 to
 better
 adapt
 their
 behavioral
 response
to
 contextual
 information
 that
 is
 not
 generated
 by
 direct
 sensory
inputs.
 Even
 if
 so,
 the
 common
 mechanism
 in
 which
 the
 Hb
 gen-
erates
 motivated
 behaviors
 based
 on
 contextual
 information
 and
updates
 the
 behavioral
 strategy
 to
 a
 more
 suitable
 outcome,
 is
 likely
to
 be
 preserved
 across
 all
 species.
 Yet
 how
 sensory
 responses
 in
the
 Hb
 and
 inputs
 from
 the
 limbic
 system
 or
 basal
 ganglia
 interact,
remains
 elusive.
 Hence,
 it
 will
 be
 essential
 to
 continue
 comparing
future
 results
 across
 different
 species,
 focusing
 on
 the
 role
 of
 habe-
nular
 circuitry
 in
 the
 contextual
 modulation
 of
 sensory
 processing.
3.
 Ongoing
 spontaneous
 activity
 in
 the
 habenula
Almost
 all
 measurements
 of
 neural
 activity
 throughout
 the
 brain
suggest
 that
 a
 signiﬁcant
 amount
 of
 activity
 is
 generated
 indepen-
dently
 from
 external
 sensory
 stimulation.
 This
 internally
 produced
spontaneous
 activity
 was
 previously
 undervalued,
 as
 for
 a
 long
 time
it
 was
 considered
 to
 be
 biophysical
 noise
 with
 no
 relevance
 in
 neu-
ronal
 computations
 [122]. Yet,
 the
 ongoing
 spontaneous
 activity
 of
neurons
 consumes
 a
 major
 part
 of
 the
 brain’s
 energy
 and
 is
 arguably
more
 than
 just
 an
 artifact
 [123]. Several
 studies
 have
 suggested
key
 roles
 for
 these
 intrinsic
 activity
 dynamics
 in
 diverse
 neural
processes
 from
 development
 and
 maturation
 of
 brain
 circuits
 to
cognitive
 performance.
Spontaneous
 bursts
 of
 activity
 were
 detected
 in
 different
 parts
of
 the
 nervous
 system
 across
 the
 animal
 kingdom.
 In
 the
 crus-
tacean
 stomatogastric
 system
 [124]
 and
 in
 the
 vertebrate
 spinal
cord
 [125], spontaneous
 activity
 is
 generally
 related
 to
 the
 genera-
tion
 of
 biological
 rhythms
 that
 control
 motor
 actions.
 However,
 the
purpose
 of
 ongoing
 activity
 in
 the
 brain
 such
 as
 the
 vertebrate
 cor-
tex
 [126–128], thalamus
 [129], hippocampus
 [130]
 and
 the
 Hb
 [96],
or
 in
 neural
 parts
 of
 sensory
 organs
 such
 as
 the
 retina
 [131,132], are
much
 more
 diverse
 and
 sometimes
 even
 elusive.
During
 development,
 spontaneous
 activity
 is
 important
 to
form
 appropriate
 connections
 and
 to
 generate
 a
 mature
 network
[129,131–133]. However,
 in
 mature
 networks,
 this
 activity
 has
been
 linked
 to
 various
 functions
 such
 as
 replay
 [130]
 and
 process-
ing
 of
 previous
 sensory
 experiences
 [134], memory
 consolidation
[135,136], and
 event
 planning
 [137]
 as
 well
 as
 the
 reorganiza-
tion
 of
 the
 synaptic
 weights
 of
 the
 network
 [138], bottom-up
thalamic
 control
 [139]
 and
 top-down
 modulation
 [140]. Such
 spon-
taneous
 activity
 can
 be
 generated
 intrinsically
 within
 one
 brain
 area
[141,142], by
 bottom
 up
 pathways
 [143]
 or
 by
 modulation
 from
distal
 areas
 either
 top-down
 or
 subcortical
 [144]. Moreover,
 sev-
eral
 studies
 suggest
 that
 spontaneous
 activity
 can
 reﬂect
 cortical
states,
 which
 can
 ‘gate’
 sensory
 information
 to
 higher
 brain
 areas
[144].
In humans,
 highly
 correlated
 spontaneous
 brain
 activity,
 is
 sug-
gested
 to
 reﬂect
 a
 ‘default
 mode
 network’
 [145]. In
 this
 functionally
deﬁned
 network,
 ongoing
 brain
 activity
 is
 not
 elicited
 by
 one
 sin-
gle
 brain
 region
 but
 is
 rather
 generated
 by
 dynamic
 interactions
 of
several
 brain
 regions
 across
 the
 brain.
 When
 the
 human
 brain
 is
 S.
 Fore
 et
 al.
 /
 Seminars
 in
 Cell
 &
 Developmental
 Biology
 78
 (2018)
 130–139
 
135
at
 rest
 or
 engaged
 in
 internally
 focused
 tasks,
 the
 default
 mode
network’
 is
 thought
 to
 be
 spontaneously
 active.
 If
 and
 how
 the
spontaneous
 activity
 of
 this
 network
 is
 altered
 by
 information
 from
the
 external
 world
 is
 still
 investigated.
 It
 has
 been
 hypothesized
that
 the
 spontaneous
 activity
 at
 rest
 can
 be
 counteracted
 or
 sup-
pressed
 by
 competing
 activity
 from
 additional
 brain
 regions
 that
are
 recruited
 during
 sensory
 processing
 or
 attention
 related
 tasks
[146–150]. On
 the
 contrary,
 a
 handful
 of
 cognitive
 tasks
 were
 also
shown
 to
 increase
 spontaneous
 activity
 [151]. In
 these
 cases
 ongo-
ing
 spontaneous
 activity
 could
 support
 a
 broad
 level
 of
 attention
when
 monitoring
 the
 external
 world
 for
 unexpected
 events
 [152].
While
 this
 idea
 of
 a
 functionally
 deﬁned
 default
 mode
 network,
 was
previously
 only
 applied
 to
 cortical
 areas,
 it
 is
 likely
 that
 other
 parts
of
 the
 brain,
 such
 as
 Hb,
 might
 be
 part
 of
 similar
 networks
 with
related
 network
 properties.
3.1.
 Implications
 of
 changing
 ongoing
 activity
 in
 habenular
circuits
The
 link
 between
 spontaneous
 habenular
 activity
 (Fig.
 2B)
 and
habenular
 inputs
 coming
 from
 converging
 pathways
 across
 the
brain
 is
 not
 well
 understood.
 Nonetheless,
 the
 hypothesis
 of
 the
 Hb
encoding
 expected
 reward
 value
 by
 altering
 its
 activity
 compared
to
 the
 baseline
 activity
 is
 now
 generally
 accepted
 [3,55]. Sponta-
neous
 activity
 in
 the
 Hb
 might
 therefore
 be
 a
 crucial
 feature,
 as
 is
it
 might
 enable
 a
 bidirectional
 coding
 of
 the
 reward
 expectation
value,
 as
 was
 observed
 with
 neurons
 encoding
 odors
 in
 the
 piri-
form
 cortex
 [153]. Such
 an
 increase
 in
 the
 dynamic
 range
 would
not
 be
 possible
 without
 a
 baseline
 activity.
Furthermore,
 several
 studies
 have
 suggested
 that
 changes
 in
spontaneous
 habenular
 activity
 might
 underlie
 behavioral
 symp-
toms
 observed
 in
 mood
 disorders
 or
 addiction.
 This
 is
 not
 very
surprising
 as
 the
 Hb
 is
 regulating
 monoaminergic
 brain
 regions
containing
 dopamine,
 serotonine
 and
 norepinephrine.
 Drugs
 like
cocaine
 for
 example,
 evoke
 withdrawal
 symptoms
 by
 a
 hyperacti-
vation
 of
 the
 LHb
 and
 strengthening
 of
 AMPAR-mediated
 synaptic
transmission
 onto
 RMTg
 neurons
 [154]. Acute
 application
 of
 nico-
tine
 on
 the
 other
 hand,
 increases
 spontaneously
 occurring
 action
potentials
 of
 the
 cholinergic
 neurons
 in
 the
 MHb
 via
 a
 speciﬁc
subtype
 of
 nAChR
 [155]. Blocking
 of
 spontaneous
 ﬁring
 in
 the
MHb,
 was
 shown
 to
 induce
 withdrawal-like
 symptoms
 similar
 to
nicotine
 withdrawal
 [155,156].
 The
 effects
 of
 morphine,
 an
 opi-
oid
 also
 inducing
 wirthdrawal-like
 symptoms,
 on
 the
 MHb
 activity
are
 less
 clear,
 since
 low
 and
 high
 doses
 respectively
 increased
 and
decreased
 spontaneous
 habenular
 activity
 [157,158]. It
 is
 highly
likely
 that
 such
 pharmacological
 alterations
 do
 not
 only
 affect
 the
Hb,
 instead
 this
 could
 alter
 the
 activity
 of
 a
 broadly
 dispersed
 brain
network,
 where
 Hb
 plays
 a
 key
 role.
Furthermore
 stress-inducing
 stimuli
 also
 excite
 neurons
 in
the
 LHb
 and
 prolonged
 stimulation
 could
 even
 generate
 anxiety
and
 depression
 [49,159,160].
 Multiple
 studies
 have
 shown
 that
increased
 background
 activity
 of
 the
 LHb
 is
 linked
 to
 anhedonia
(a
 behavioral
 symptom
 observed
 in
 some
 depressive
 patients),
by
 decreasing
 the
 activity
 of
 dopaminergic
 neurons
 after
 positive
events
 [76]. However,
 stress-induced
 activation
 of
 the
 LHb
 may
 not
only
 lead
 to
 changes
 in
 dopaminergic
 signaling
 but
 also
 to
 alter-
ations
 in
 the
 activity
 of
 serotonergic
 neurons
 located
 in
 the
 dorsal
and
 medial
 raphe
 nuclei
 [161–163].
Under
 general
 anesthesia,
 the
 amount
 of
 habenular
 activity
rises
 [164–166]
 which
 suggests
 that
 habenular
 activity
 can
 be
modulated
 during
 the
 transition
 from
 sleep/low
 arousal
 states
 to
awake/high
 arousal
 states.
 In
 line
 with
 this,
 ﬂuctuations
 in
 the
spontaneous
 activity
 of
 the
 Hb
 are
 regulated
 by
 circadian
 rhythms
[86,167].
 Precise
 mechanisms,
 which
 can
 underlie
 the
 role
 of
 the
Hb
 during
 sleep,
 remain
 to
 be
 elucidated,
 but
 proposed
 roles
 point
towards
 the
 control
 of
 serotonergic
 and
 possibly
 also
 dopaminergic
neurons
 [168–170].
Taken
 together,
 the
 spontaneous
 activity
 in
 the
 Hb,
 both
 in
LHb
 and
 MHb,
 appears
 to
 be
 altered
 in
 many
 different
 condi-
tions
 ranging
 from
 substance
 abuse
 to
 stress,
 sleep,
 reward-based
decision-making
 or
 even
 social
 behaviors.
 The
 baseline
 activity,
which
 can
 be
 characterized
 as
 the
 ongoing
 activity
 in
 the
 Hb
 with-
out
 any
 external
 stimulus,
 can
 therefore
 represent
 an
 internal
 state
of
 the
 animal.
 Depending
 on
 the
 sensory
 inputs
 or
 internal
 informa-
tion
 from
 other
 brain
 areas
 that
 are
 directly
 or
 indirectly
 projecting
to
 the
 Hb,
 this
 activity
 can
 be
 modulated
 to
 eventually
 trigger
behaviors
 that
 are
 better
 adapted
 to
 a
 given
 situation.
3.2.
 Interactions
 of
 spontaneous
 and
 sensory
 driven
 activity
 in
the
 habenula
While
 all
 phenomena
 described
 above
 have
 a
 strong
 relation
to
 changing
 levels
 of
 spontaneous
 habenular
 activity,
 it
 is
 less
 clear
how
 sensory
 responses
 in
 the
 Hb
 and
 spontaneous
 habenular
 activ-
ity
 interact
 with
 each
 other.
 One
 possibility
 is
 that
 spontaneous
activity
 alters
 sensory
 responses
 in
 the
 Hb
 and
 changes
 the
 way
the
 Hb
 transmits
 sensory
 information
 to
 its
 monoaminergic
 tar-
gets.
 Alternatively,
 sensory
 responses
 in
 the
 Hb
 could
 also
 interfere
with
 the
 spontaneous
 activity
 and
 therefore
 modulate
 the
 phenom-
ena
 that
 are
 attributed
 to
 spontaneous
 habenular
 activity,
 such
 as
cognitive
 function,
 depression,
 addiction,
 sleep
 or
 social
 behaviors.
Since
 the
 Hb
 receives
 inputs
 from
 both
 sensory
 and
 non-sensory
regions
 of
 the
 forebrain,
 midbrain
 and
 hindbrain
 [1,2,4–16], one
potential
 role
 of
 spontaneous
 habenular
 activity
 could
 be
 to
 serve
as
 a
 gate
 or
 a
 switchboard.
 In
 such
 a
 model,
 the
 responsiveness
 of
Hb
 neurons
 to
 sensory
 stimulation
 could
 be
 modulated
 (or
 gated)
by
 the
 non-sensory
 inputs
 of
 the
 Hb
 that
 are
 shaping
 its
 ongoing
activity.
 We  have
 previously
 shown
 that
 spontaneous
 activity
 in
 the
zebraﬁsh
 dHb
 is
 not
 random,
 but
 rather
 spatially
 organized
 into
 dif-
ferent
 functionally
 and
 genetically
 distinct
 clusters
 [96]
 (Fig.
 2B).
Neurotransmitter
 maps
 of
 the
 dHb
 were
 shown
 to
 have
 a
 spatial
organization
 that
 is
 asymmetric
 across
 habenular
 hemispheres
 and
this
 organization
 is
 preserved
 in
 the
 targets
 of
 the
 Hb
 [171]
 (Fig.
 2C).
Hence,
 it
 would
 be
 interesting
 to
 classify
 what
 functional
 Hb
 clus-
ters
 identiﬁed
 based
 on
 their
 ongoing
 activity,
 overlap
 with
 the
neurotransmitter
 expression
 patterns
 observed
 in
 the
 Hb.
Additionally,
 we  showed
 that
 the
 neurons
 belonging
 to
 a
 func-
tional
 cluster
 during
 spontaneous
 habenular
 activity
 also
 respond
similarly
 to
 sensory
 stimulation.
 Hence,
 in
 principle,
 modulating
the
 spontaneous
 activity
 of
 a
 given
 Hb
 cluster
 could
 also
 alter
 the
responsiveness
 of
 those
 Hb
 neurons
 to
 a
 given
 sensory
 modal-
ity,
 by
 increasing
 or
 decreasing
 their
 resting
 membrane
 potential.
This
 process
 would
 in
 turn
 control
 if
 or
 when
 the
 sensory
 infor-
mation
 should
 be
 passed
 to
 monoaminergic
 Hb
 targets
 in
 the
locus
 coeruleus
 (LC),
 the
 VTA
 and
 the
 Raphe.
 Therefore,
 it
 will
be
 interesting
 to
 modulate
 spontaneous
 habenular
 activity
 via
direct
 stimulation
 of
 Hb
 inputs
 across
 the
 brain,
 or
 to
 utilize
 those
behavioral
 phenomena
 that
 could
 regulate
 spontaneous
 habenular
activity
 such
 as
 stress
 or
 sleep,
 to
 test
 whether
 altering
 spontaneous
habenular
 activity
 can
 modulate
 sensory
 representations
 within
the
 Hb
 and
 in
 turn
 alter
 the
 animal’s
 behavioral
 response
 to
 sensory
stimuli.
It
 is
 possible
 that
 the
 functional
 clusters
 observed
 in
 ongoing
habenular
 activity
 could
 represent
 stable
 states
 of
 the
 network,
marking
 the
 groups
 of
 neurons
 that
 are
 more
 likely
 to
 act
 together
to
 recall
 a
 given
 behavioral
 program.
 In
 line
 with
 this
 hypothe-
sis,
 functional
 clusters
 of
 Hb
 neurons
 with
 synchronized
 ongoing
activity
 were
 shown
 to
 overlap
 with
 genetically
 labeled
 groups
 of
Hb
 neurons
 [96], which
 were
 shown
 to
 be
 involved
 in
 associative
fear
 learning
 [49]. It
 is
 exciting
 to
 speculate
 that
 these
 stable
 func-
tional
 clusters
 of
 Hb
 neurons
 that
 are
 synchronized
 (or
 co-active)
 at
 136
 
S.
 Fore
 et
 al.
 /
 Seminars
 in
 Cell
 &
 Developmental
 Biology
 78
 (2018)
 130–139
all
 times,
 represent
 favored
 states
 of
 the
 habenular
 circuits.
 These
favored
 states
 of
 the
 habenular
 circuits
 resemble
 an
 attractor
 net-
work,
 which
 is
 a
 network
 of
 recurrently
 connected
 neurons,
 whose
dynamics
 settle
 to
 stable
 states.
 Such
 stable
 states
 are
 generally
believed
 to
 be
 involved
 in
 decision
 making
 and
 provide
 the
 network
with
 an
 increase
 in
 signal-to-noise
 ratio
 resulting
 in
 a
 better
 signal
classiﬁcation
 and
 discretisation
 [172–174].
 In
 the
 mammalian
 cor-
tex,
 attractor
 networks
 are
 proposed
 to
 be
 involved
 in
 gating
 and
gain
 control
 of
 sensory
 information
 [175]. Hence,
 these
 principles
could
 also
 apply
 to
 sensory
 processing
 within
 the
 Hb.
 For
 example
odorant-evoked
 responses
 with
 different
 amplitudes
 and
 distinct
representations
 in
 the
 OB,
 were
 no
 longer
 observed
 in
 dHb
 neurons.
[96]. Instead
 dHb
 neurons
 are
 broadly
 tuned
 to
 odors
 which
 sug-
gests
 that
 discrimination
 between
 odorant
 classes
 might
 no
 longer
be
 relevant
 for
 Hb
 computations.
 A
 robust
 response
 that
 encodes
saliency
 or
 presence
 of
 a
 broad
 odor
 signal
 could
 be
 achieved
 by
keeping
 the
 network
 in
 a
 preferred
 excitable
 state.
 It
 is
 also
 pos-
sible
 that
 these
 stable
 states
 of
 the
 Hb
 networks
 can
 be
 entrained
to
 increase
 the
 response
 likelihood
 of
 Hb
 neurons
 to
 a
 given
 sen-
sory
 modality
 through
 an
 associative
 learning
 process.
 The
 Hb
 was
indeed
 shown
 to
 be
 involved
 in
 such
 processes
 through
 reward
prediction
 and
 error
 estimation.
 One
 way
 to
 test
 this
 hypothesis
is
 to
 measure
 the
 changes
 in
 Hb
 spontaneous
 activity
 throughout
the
 process
 of
 associative
 learning.
 Along
 with
 this
 hypothesis,
 the
cognitive
 capacities
 involved
 in
 associative
 learning
 were
 shown
 to
improve
 drastically
 within
 the
 ﬁrst
 weeks
 of
 development
 [176]. As
the
 Hb
 plays
 a
 role
 in
 this
 associative
 learning
 process,
 it
 is
 likely
that
 the
 spontaneous
 activity
 of
 Hb
 circuits
 might
 change,
 as
 the
 Hb
input
 regions
 across
 the
 brain
 mature
 throughout
 development.
 It
would
 therefore
 be
 exciting
 to
 study
 the
 processes
 that
 regulate
sensory
 responses
 and
 spontaneous
 activity
 of
 Hb
 neurons
 across
different
 stages
 of
 development
 and
 test
 if
 different
 types
 of
 inputs
to
 the
 Hb,
 from
 sensory,
 limbic
 and
 cortical
 brain
 regions
 arrive
with
 a
 developmental
 order
 and
 whether
 spontaneous
 habenular
activity
 shapes
 the
 fate
 and
 the
 function
 of
 Hb
 neurons.
One
 ﬁnal
 possibility
 is
 that
 the
 spontaneous
 habenular
 activ-
ity
 constantly
 links
 the
 cortical
 or
 limbic
 inputs
 of
 the
 Hb
 to
monoaminergic
 Hb
 targets.
 In
 this
 manner,
 the
 Hb
 receives
 infor-
mation
 from
 these
 input
 regions
 about
 the
 animal’s
 internal
 states
(such
 as
 fear,
 stress,
 attention,
 learned
 outcomes)
 and
 spontaneous
activity
 is
 regulated
 accordingly.
 The
 habenula
 can
 then
 act
 as
 a
hub
 and
 relay
 the
 information
 received
 from
 Hb
 input
 regions
 to
the
 neuromodulatory
 nuclei
 that
 control
 behavior.
 In
 this
 scenario,
the
 sensory
 inputs
 to
 the
 Hb
 might
 interfere
 with
 ongoing
 habe-
nular
 activity
 by
 potentiating
 or
 disengaging
 the
 link
 between
 Hb
inputs
 and
 Hb
 targets.
 This
 can
 then
 allow
 to
 activate
 or
 suppress
 a
given
 behavioral
 program
 in
 the
 presence
 of
 a
 salient
 sensory
 stim-
ulus.
 The
 vast
 literature
 on
 the
 Hb
 and
 its
 function
 covers
 several
disciplines.
 While
 most
 studies
 in
 the
 human,
 primate
 and
 rodent
Hb
 focus
 on
 reward
 prediction,
 addiction
 and
 stress,
 work
 on
 the
Hb
 of
 many
 lower
 vertebrates
 focuses
 on
 the
 representations
 of
different
 sensory
 modalities
 in
 the
 Hb
 as
 well
 as
 the
 asymmetric
architecture
 and
 function
 of
 habenular
 circuits.
 There
 is
 a
 strong
parallelism
 in
 molecular
 and
 functional
 architecture
 of
 the
 verte-
brate
 Hb
 as
 well
 as
 in
 its
 role
 in
 regulating
 behavior
 in
 general.
However,
 further
 research
 is
 needed
 in
 order
 to
 understand
 the
interplay
 between
 sensory
 information
 from
 the
 external
 world
and
 the
 internally
 generated
 spontaneous
 activity
 of
 the
 Hb
 and
how
 these
 interactions
 relate
 to
 the
 roles
 of
 the
 Hb
 in
 controlling
animal
 behavior.
Acknowledgments
We
 thank
 all
 members
 of
 the
 Yaksi
 lab
 especially
 to
 Florence
 Ker-
men
 and
 Pradeep
 Lal
 for
 critical
 feedback.
 This
 work
 was
 funded
 by
ERC
 Starting
 Grant
 (335561),
 Norwegian
 Research
 Council
 FRIPRO
grant
 (239973),
 the
 Kavli
 Foundation,
 the
 Egil
 and
 Pauline
 Braathen
and
 Fred
 Kavli
 Centre
 for
 Cortical
 Microcircuits,
 NTNU,
 the
 Centre
 of
Excellence
 Scheme
 and
 the
 National
 Infrastructure
 Scheme
 of
 the
Research
 Council
 of
 Norway
 (223262).
 E.Y.
 acknowledges
 support
from
 the
 FENS-Kavli
 Network
 of
 Excellence.
References
[1]
 M.R.
 Warden,
 et
 al.,
 A
 prefrontal
 cortex-brainstem
 neuronal
 projection
 that
controls
 response
 to
 behavioural
 challenge,
 Nature
 492
 (7429)
 (2012)
428–432.
[2]
 H.
 Okamoto,
 M.
 Agetsuma,
 H.
 Aizawa,
 Genetic
 dissection
 of
 the
 zebraﬁsh
habenula:
 a
 possible
 switching
 board
 for
 selection
 of
 behavioral
 strategy
 to
cope
 with
 fear
 and
 anxiety,
 Dev.
 Neurobiol.
 72
 (3)
 (2012)
 386–394.
[3]
 M.  Matsumoto,
 O.
 Hikosaka,
 Lateral
 habenula
 as
 a
 source
 of
 negative
 reward
signals
 in
 dopamine
 neurons,
 Nature
 447
 (7148)
 (2007)
 1111–1115.
[4]
 I.H.
 Bianco,
 S.W.
 Wilson,
 The
 habenular
 nuclei:
 a
 conserved
 asymmetric
relay
 station
 in
 the
 vertebrate
 brain,
 Philos.
 Trans.
 R.
 Soc.
 Lond.
 B
 Biol.
 Sci.
364 (1519)
 (2009)
 1005–1020.
[5]
 F.J.
 Meye,
 et
 al.,
 Shifted
 pallidal
 co-release
 of
 GABA
 and
 glutamate
 in
habenula
 drives
 cocaine
 withdrawal
 and
 relapse,
 Nat.
 Neurosci.
 19
 (8)
(2016)
 1019–1024.
[6]
 R.
 Amo,
 et
 al.,
 The
 habenulo-raphe
 serotonergic
 circuit
 encodes
 an
 aversive
expectation
 value
 essential
 for
 adaptive
 active
 avoidance
 of
 danger,
 Neuron
84 (5)
 (2014)
 1034–1048.
[7]
 J.H.
 Yoo,
 et
 al.,
 Ventral
 tegmental
 area
 glutamate
 neurons
 co-release
 GABA
and
 promote
 positive
 reinforcement,
 Nat.
 Commun.
 7
 (2016)
 13697.
[8]
 A.M.
 Stamatakis,
 et
 al.,
 A
 unique
 population
 of
 ventral
 tegmental
 area
neurons
 inhibits
 the
 lateral
 habenula
 to
 promote
 reward,
 Neuron
 80
 (4)
(2013)
 1039–1053.
[9]
 D.H.
 Root,
 et
 al.,
 Role
 of
 glutamatergic
 projections
 from
 ventral
 tegmental
area  to
 lateral
 habenula
 in
 aversive
 conditioning,
 J. Neurosci.
 34
 (42)
 (2014)
13906–13910.
[10]
 D.H.
 Root,
 et
 al.,
 Single
 rodent
 mesohabenular
 axons
 release
 glutamate
 and
GABA,
 Nat.
 Neurosci.
 17
 (11)
 (2014)
 1543–1551.
[11]
 R.
 Bernard,
 R.W.
 Veh,
 Individual
 neurons
 in
 the
 rat
 lateral
 habenular
complex
 project
 mostly
 to
 the
 dopaminergic
 ventral
 tegmental
 area
 or
 to
the
 serotonergic
 raphe
 nuclei,
 J.
 Comp.
 Neurol.
 520
 (11)
 (2012)
 2545–2558.
[12]
 K.
 Brinschwitz,
 et
 al.,
 Glutamatergic
 axons
 from
 the
 lateral
 habenula
 mainly
terminate
 on
 GABAergic
 neurons
 of
 the
 ventral
 midbrain,
 Neuroscience
 168
(2) (2010)
 463–476.
[13]
 L.
 Goncalves,
 C.
 Sego,
 M.
 Metzger,
 Differential
 projections
 from
 the
 lateral
habenula
 to
 the
 rostromedial
 tegmental
 nucleus
 and
 ventral
 tegmental
 area
in  the
 rat,
 J.
 Comp.
 Neurol.
 520
 (6)
 (2012)
 1278–1300.
[14]
 M.  Stephenson-Jones,
 et
 al.,
 Evolutionary
 conservation
 of
 the
 habenular
nuclei
 and
 their
 circuitry
 controlling
 the
 dopamine
 and
5-hydroxytryptophan
 (5-HT)
 systems,
 Proc.
 Natl.
 Acad.
 Sci.
 U.
 S.
 A.
 109
 (3)
(2012)
 E164–73.
[15]
 R.P.
 Vertes,
 W.J.
 Fortin,
 A.M.
 Crane,
 Projections
 of
 the
 median
 raphe
 nucleus
in  the
 rat,
 J.
 Comp.
 Neurol.
 407
 (4)
 (1999)
 555–582.
[16]
 C.
 Sego,
 et
 al.,
 Lateral
 habenula
 and
 the
 rostromedial
 tegmental
 nucleus
innervate
 neurochemically
 distinct
 subdivisions
 of
 the
 dorsal
 raphe
 nucleus
in  the
 rat,
 J.
 Comp.
 Neurol.
 522
 (7)
 (2014)
 1454–1484.
[17]
 R.J.
 Sutherland,
 The
 dorsal
 diencephalic
 conduction
 system:
 a
 review
 of
 the
anatomy
 and
 functions
 of
 the
 habenular
 complex,
 Neurosci.
 Biobehav.
 Rev.
 6
(1) (1982)
 1–13.
[18]
 T.G.
 Brown,
 Note
 on
 the
 physiology
 of
 the
 basal
 ganglia
 and
 mid-brain
 of
 the
anthropoid
 ape:
 especially
 in
 reference
 to
 the
 act
 of
 laughter,
 J.
 Physiol.
 49
(4)
 (1915)
 195–207.
[19]
 E.W.
 Thornton,
 G.E.
 Bradbury,
 Effort
 and
 stress
 inﬂuence
 the
 effect
 of
 lesion
of
 the
 habenula
 complex
 in
 one-way
 active
 avoidance
 learning,
 Physiol.
Behav.
 45
 (5)
 (1989)
 929–935.
[20]
 T.
 Yamaguchi,
 et
 al.,
 Distinct
 roles
 of
 segregated
 transmission
 of
 the
septo-habenular
 pathway
 in
 anxiety
 and
 fear,
 Neuron
 78
 (3)
 (2013)
537–544.
[21]
 P.Y.
 Shih,
 et
 al.,
 Differential
 expression
 and
 function
 of
 nicotinic
acetylcholine
 receptors
 in
 subdivisions
 of
 medial
 habenula,
 J.
 Neurosci.
 34
(29)
 (2014)
 9789–9802.
[22]
 P.Y.
 Shih,
 J.M.
 McIntosh,
 R.M.
 Drenan,
 Nicotine
 dependence
 reveals
 distinct
responses
 from
 neurons
 and
 their
 resident
 nicotinic
 receptors
 in
 medial
habenula,
 Mol.
 Pharmacol.
 88
 (6)
 (2015)
 1035–1044.
[23]
 S.
 Frahm,
 et
 al.,
 Aversion
 to
 nicotine
 is
 regulated
 by
 the
 balanced
 activity
 of
beta4
 and
 alpha5
 nicotinic
 receptor
 subunits
 in
 the
 medial
 habenula,
Neuron
 70
 (3)
 (2011)
 522–535.
[24]
 H.
 Viswanath,
 et
 al.,
 The
 medial
 habenula:
 still
 neglected,
 Front.
 Hum.
Neurosci.
 7
 (2013)
 931.
[25]
 K.
 Sakhi,
 et
 al.,
 Daily
 variation
 in
 the
 electrophysiological
 activity
 of
 mouse
medial
 habenula
 neurones,
 J.
 Physiol.
 592
 (4)
 (2014)
 587–603.
[26]
 V.M.
 Namboodiri,
 J. Rodriguez-Romaguera,
 G.D.
 Stuber,
 The
 habenula,
 Curr.
Biol.  26
 (19)
 (2016)
 R873–R877.
[27]
 E.S.
 Bromberg-Martin,
 et
 al.,
 A
 pallidus-habenula-dopamine
 pathway
 signals
inferred
 stimulus
 values,
 J.
 Neurophysiol.
 104
 (2)
 (2010)
 1068–1076.
 S.
 Fore
 et
 al.
 /
 Seminars
 in
 Cell
 &
 Developmental
 Biology
 78
 (2018)
 130–139
 
137
[28]
 T.
 Kawai,
 et
 al.,
 Roles
 of
 the
 lateral
 habenula
 and
 anterior
 cingulate
 cortex
 in
negative
 outcome
 monitoring
 and
 behavioral
 adjustment
 in
 nonhuman
primates,
 Neuron
 88
 (4)
 (2015)
 792–804.
[29]
 M.
 Matsumoto,
 O.
 Hikosaka,
 Two
 types
 of
 dopamine
 neuron
 distinctly
convey
 positive
 and
 negative
 motivational
 signals,
 Nature
 459
 (7248)
(2009)
 837–841.
[30]
 S.
 Hong,
 et
 al.,
 Negative
 reward
 signals
 from
 the
 lateral
 habenula
 to
dopamine
 neurons
 are
 mediated
 by
 rostromedial
 tegmental
 nucleus
 in
primates,
 J.
 Neurosci.
 31
 (32)
 (2011)
 11457–11471.
[31]
 J.J.
 Balcita-Pedicino,
 et
 al.,
 The
 inhibitory
 inﬂuence
 of
 the
 lateral
 habenula
 on
midbrain
 dopamine
 cells:
 ultrastructural
 evidence
 for
 indirect
 mediation
 via
the
 rostromedial
 mesopontine
 tegmental
 nucleus,
 J.
 Comp.
 Neurol.
 519
 (6)
(2011)
 1143–1164.
[32]
 C.M.
 Stopper,
 S.B.
 Floresco,
 What’s
 better
 for
 me?
 Fundamental
 role
 for
lateral
 habenula
 in
 promoting
 subjective
 decision
 biases,
 Nat.
 Neurosci.
 17
(1)  (2014)
 33–35.
[33]
 A.M.
 Stamatakis,
 G.D.
 Stuber,
 Activation
 of
 lateral
 habenula
 inputs
 to
 the
ventral
 midbrain
 promotes
 behavioral
 avoidance,
 Nat.
 Neurosci.
 15
 (8)
(2012)
 1105–1107.
[34]
 E.J.
 Shank,
 et
 al.,
 Selective
 ablation
 of
 GABA
 neurons
 in
 the
 ventral
 tegmental
area increases
 spontaneous
 locomotor
 activity,
 Behav.
 Neurosci.
 121
 (6)
(2007)
 1224–1233.
[35]
 K.R.
 Tan,
 et
 al.,
 GABA
 neurons
 of
 the
 VTA
 drive
 conditioned
 place
 aversion,
Neuron
 73
 (6)
 (2012)
 1173–1183.
[36]
 S.
 Lammel,
 et
 al.,
 Input-speciﬁc
 control
 of
 reward
 and
 aversion
 in
 the
 ventral
tegmental
 area,
 Nature
 491
 (7423)
 (2012)
 212–217.
[37]
 A.
 Friedman,
 et
 al.,
 Electrical
 stimulation
 of
 the
 lateral
 habenula
 produces
 an
inhibitory
 effect
 on
 sucrose
 self-administration,
 Neuropharmacology
 60
(2–3)
 (2011)
 381–387.
[38]
 S.J.
 Shabel,
 et
 al.,
 Mood
 regulation:
 GABA/glutamate
 co-release
 controls
habenula
 output
 and
 is
 modiﬁed
 by
 antidepressant
 treatment,
 Science
 345
(6203)
 (2014)
 1494–1498.
[39]
 J.Y.
 Cohen,
 et
 al.,
 Neuron-type-speciﬁc
 signals
 for
 reward
 and
 punishment
 in
the
 ventral
 tegmental
 area,
 Nature
 482
 (7383)
 (2012)
 85–88.
[40]
 J.S.
 Morris,
 et
 al.,
 Covariation
 of
 activity
 in
 habenula
 and
 dorsal
 raphe
 nuclei
following
 tryptophan
 depletion,
 Neuroimage
 10
 (2)
 (1999)
 163–172.
[41]
 C.D.
 Proulx,
 O.
 Hikosaka,
 R.
 Malinow,
 Reward
 processing
 by
 the
 lateral
habenula
 in
 normal
 and
 depressive
 behaviors,
 Nat.
 Neurosci.
 17
 (9)
 (2014)
1146–1152.
[42]
 O.
 Hikosaka,
 The
 habenula:
 from
 stress
 evasion
 to
 value-based
decision-making,
 Nat.
 Rev.
 Neurosci.
 11
 (7)
 (2010)
 503–513.
[43]
 J.Y.
 Cohen,
 M.W.
 Amoroso,
 N.
 Uchida,
 Serotonergic
 neurons
 signal
 reward
and
 punishment
 on
 multiple
 timescales,
 Elife
 4
 (2015).
[44]
 P.
 Dayan,
 Q.J.
 Huys,
 Serotonin
 in
 affective
 control,
 Annu.
 Rev.
 Neurosci.
 32
(2009)
 95–126.
[45]
 Y.
 Li,
 et
 al.,
 Serotonin
 neurons
 in
 the
 dorsal
 raphe
 nucleus
 encode
 reward
signals,
 Nat.
 Commun.
 7
 (2016)
 10503.
[46]
 E.S.
 Bromberg-Martin,
 O.
 Hikosaka,
 K.
 Nakamura,
 Coding
 of
 task
 reward
value
 in
 the
 dorsal
 raphe
 nucleus,
 J.
 Neurosci.
 30
 (18)
 (2010)
 6262–6272.
[47]
 K.
 Hayashi,
 K.
 Nakao,
 K.
 Nakamura,
 Appetitive
 and
 aversive
 information
coding
 in
 the
 primate
 dorsal
 raphe
 nucleus,
 J.
 Neurosci.
 35
 (15)
 (2015)
6195–6208.
[48]
 M.
 Agetsuma,
 et
 al.,
 The
 habenula
 is
 crucial
 for
 experience-dependent
modiﬁcation
 of
 fear
 responses
 in
 zebraﬁsh,
 Nat.
 Neurosci.
 13
 (11)
 (2010)
1354–1356.
[49]
 A.
 Lee,
 et
 al.,
 The
 habenula
 prevents
 helpless
 behavior
 in
 larval
 zebraﬁsh,
Curr. Biol.
 20
 (24)
 (2010)
 2211–2216.
[50]
 P.
 Dayan,
 Instrumental
 vigour
 in
 punishment
 and
 reward,
 Eur.
 J.
 Neurosci.
35 (7)
 (2012)
 1152–1168.
[51]
 A.M.
 Krypotos,
 et
 al.,
 Avoidance
 learning:
 a
 review
 of
 theoretical
 models
 and
recent
 developments,
 Front.
 Behav.
 Neurosci.
 9
 (2015)
 189.
[52]
 L.J.
 Boulos,
 E.
 Darcq,
 B.L.
 Kieffer,
 Translating
 the
 habenula-from
 rodents
 to
humans,
 Biol.
 Psychiatry
 81
 (4)
 (2017)
 296–305.
[53]
 S.
 Lecca,
 F.J.
 Meye,
 M.
 Mameli,
 The
 lateral
 habenula
 in
 addiction
 and
depression:
 an
 anatomical,
 synaptic
 and
 behavioral
 overview,
 Eur.
 J.
Neurosci.
 39
 (7)
 (2014)
 1170–1178.
[54]
 S.
 Lecca,
 et
 al.,
 Inhibitory
 inputs
 from
 rostromedial
 tegmental
 neurons
regulate
 spontaneous
 activity
 of
 midbrain
 dopamine
 cells
 and
 their
responses
 to
 drugs
 of
 abuse,
 Neuropsychopharmacology
 37
 (5)
 (2012)
1164–1176.
[55]
 K.M.
 Velasquez,
 D.L.
 Molfese,
 R.
 Salas,
 The
 role
 of
 the
 habenula
 in
 drug
addiction,
 Front.
 Hum.
 Neurosci.
 8
 (2014)
 174.
[56]
 M.A.
 Khaled,
 et
 al.,
 Dopamine
 D3
 receptors
 in
 the
 basolateral
 amygdala
 and
the
 lateral
 habenula
 modulate
 cue-induced
 reinstatement
 of
 nicotine
seeking,
 Neuropsychopharmacology
 39
 (13)
 (2014)
 3049–3058.
[57]
 S.
 Frahm,
 et
 al.,
 An
 essential
 role
 of
 acetylcholine-glutamate
 synergy
 at
habenular
 synapses
 in
 nicotine
 dependence,
 Elife
 4
 (2015),
 e11396.
[58]
 P.R.
 Baldwin,
 R.
 Alanis,
 R.
 Salas,
 The
 role
 of
 the
 habenula
 in
 nicotine
addiction,
 J.
 Addict.
 Res.
 Ther.
 S1
 (2)
 (2011).
[59]
 B.
 Antolin-Fontes,
 et
 al.,
 The
 habenulo-interpeduncular
 pathway
 in
 nicotine
aversion
 and
 withdrawal,
 Neuropharmacology
 96
 (Pt.
 B)
 (2015)
 213–222.
[60]
 R.M.
 Brown,
 J.L.
 Short,
 A.J.
 Lawrence,
 Identiﬁcation
 of
 brain
 nuclei
 implicated
in
 cocaine-primed
 reinstatement
 of
 conditioned
 place
 preference:
 a
behaviour
 dissociable
 from
 sensitization,
 PLoS
 One
 5
 (12)
 (2010)
 e15889.
[61]
 P.A.
 Neumann,
 et
 al.,
 Increased
 excitability
 of
 lateral
 habenula
 neurons
 in
adolescent
 rats
 following
 cocaine
 self-administration,
 Int.
 J.
Neuropsychopharmacol.
 18
 (6)
 (2014).
[62]
 W.
 Zuo,
 et
 al.,
 Ethanol
 drives
 aversive
 conditioning
 through
 dopamine
 1
receptor
 and
 glutamate
 receptor-mediated
 activation
 of
 lateral
 habenula
neurons,
 Addict.
 Biol.
 22
 (1)
 (2017)
 103–116.
[63]
 B.L.
 Eggan,
 S.E.
 McCallum,
 alpha3beta4
 nicotinic
 receptors
 in
 the
 medial
habenula
 and
 substance
 P
 transmission
 in
 the
 interpeduncular
 nucleus
modulate
 nicotine
 sensitization,
 Behav.
 Brain
 Res.
 316
 (2017)
 94–103.
[64]
 S.
 Molas,
 et
 al.,
 Anxiety
 and
 nicotine
 dependence:
 emerging
 role
 of
 the
habenulo-interpeduncular
 axis,
 Trends
 Pharmacol.
 Sci.
 38
 (2)
 (2017)
169–180.
[65]
 W.
 Zuo,
 et
 al.,
 Nicotine
 regulates
 activity
 of
 lateral
 habenula
 neurons
 via
presynaptic
 and
 postsynaptic
 mechanisms,
 Sci.
 Rep.
 6
 (2016)
 32937.
[66]
 X.
 Kedikian,
 M.P.
 Faillace,
 R.
 Bernabeu,
 Behavioral
 and
 molecular
 analysis
 of
nicotine-conditioned
 place
 preference
 in
 zebraﬁsh,
 PLoS
 One
 8
 (7)
 (2013)
e69453.
[67]
 B.
 Le
 Foll,
 S.R.
 Goldberg,
 Nicotine
 induces
 conditioned
 place
 preferences
over
 a
 large
 range
 of
 doses
 in
 rats,
 Psychopharmacology
 (Berl.)
 178
 (4)
(2005)
 481–492.
[68]
 C.D.
 Fowler,
 et
 al.,
 Habenular
 alpha5
 nicotinic
 receptor
 subunit
 signalling
controls
 nicotine
 intake,
 Nature
 471
 (7340)
 (2011)
 597–601.
[69]
 F.M.
 Leslie,
 C.Y.
 Mojica,
 D.D.
 Reynaga,
 Nicotinic
 receptors
 in
 addiction
pathways,
 Mol.
 Pharmacol.
 83
 (4)
 (2013)
 753–758.
[70]
 E.
 Lax,
 et
 al.,
 Neurodegeneration
 of
 lateral
 habenula
 efferent
 ﬁbers
 after
intermittent
 cocaine
 administration:
 implications
 for
 deep
 brain
stimulation,
 Neuropharmacology
 75
 (2013)
 246–254.
[71]
 L.R.
 Jacinto,
 et
 al.,
 The
 habenula
 as
 a
 critical
 node
 in
 chronic
 stress-related
anxiety,
 Exp.
 Neurol.
 289
 (2017)
 46–54.
[72]
 F.M.
 Schmidt,
 et
 al.,
 Habenula
 volume
 increases
 with
 disease
 severity
 in
unmedicated
 major
 depressive
 disorder
 as
 revealed
 by
 7T
 MRI,
 Eur.
 Arch.
Psychiatry
 Clin.
 Neurosci.
 267
 (2)
 (2017)
 107–115.
[73]
 K.
 Ranft,
 et
 al.,
 Evidence
 for
 structural
 abnormalities
 of
 the
 human
habenular
 complex
 in
 affective
 disorders
 but
 not
 in
 schizophrenia,
 Psychol.
Med.  40
 (4)
 (2010)
 557–567.
[74]
 D.
 Sourani,
 et
 al.,
 The
 habenula
 couples
 the
 dopaminergic
 and
 the
serotonergic
 systems:
 application
 to
 depression
 in
 Parkinson’s
 disease,
 Eur.
J.
 Neurosci.
 36
 (6)
 (2012)
 2822–2829.
[75]
 R.P.
 Lawson,
 et
 al.,
 Disrupted
 habenula
 function
 in
 major
 depression,
 Mol.
Psychiatry
 22
 (2)
 (2017)
 202–208.
[76]
 A.
 Sartorius,
 et
 al.,
 Remission
 of
 major
 depression
 under
 deep
 brain
stimulation
 of
 the
 lateral
 habenula
 in
 a
 therapy-refractory
 patient,
 Biol.
Psychiatry
 67
 (2)
 (2010)
 e9–e11.
[77]
 J.L.
 Moreines,
 Z.L.
 Owrutsky,
 A.A.
 Grace,
 Involvement
 of
 infralimbic
prefrontal
 cortex
 but
 not
 lateral
 habenula
 in
 dopamine
 attenuation
 after
chronic
 mild
 stress,
 Neuropsychopharmacology
 42
 (4)
 (2017)
 904–913.
[78]
 S.
 Lecca,
 et
 al.,
 Rescue
 of
 GABAB
 and
 GIRK
 function
 in
 the
 lateral
 habenula
 by
protein
 phosphatase
 2A
 inhibition
 ameliorates
 depression-like
 phenotypes
in mice,
 Nat.
 Med.
 22
 (3)
 (2016)
 254–261.
[79]
 K.
 Li,
 et
 al.,
 betaCaMKII
 in
 lateral
 habenula
 mediates
 core
 symptoms
 of
depression,
 Science
 341
 (6149)
 (2013)
 1016–1020.
[80]
 W.
 Cui,
 et
 al.,
 Glial
 dysfunction
 in
 the
 mouse
 habenula
 causes
 depressive-like
behaviors
 and
 sleep
 disturbance,
 J.
 Neurosci.
 34
 (49)
 (2014)
 16273–16285.
[81]
 M.Y.
 Chou,
 et
 al.,
 Social
 conﬂict
 resolution
 regulated
 by
 two
 dorsal
habenular
 subregions
 in
 zebraﬁsh,
 Science
 352
 (6281)
 (2016)
 87–90.
[82]
 L.W.
 van
 Kerkhof,
 et
 al.,
 Functional
 integrity
 of
 the
 habenula
 is
 necessary
 for
social
 play
 behaviour
 in
 rats,
 Eur.
 J. Neurosci.
 38
 (10)
 (2013)
 3465–3475.
[83]
 M.
 Ahern,
 et
 al.,
 Brain
 regional
 differences
 in
 social
 encounter-induced
 Fos
expression
 in
 male
 and
 female
 rats
 after
 post-weaning
 social
 isolation,
 Brain
Res.
 1630
 (2016)
 120–133.
[84]
 E.
 Dreosti,
 et
 al.,
 Left-right
 asymmetry
 is
 required
 for
 the
 habenulae
 to
respond
 to
 both
 visual
 and
 olfactory
 stimuli,
 Curr.
 Biol.
 24
 (4)
 (2014)
440–445.
[85]
 S.
 Krishnan,
 et
 al.,
 The
 right
 dorsal
 habenula
 limits
 attraction
 to
 an
 odor
 in
zebraﬁsh,
 Curr.
 Biol.
 24
 (11)
 (2014)
 1167–1175.
[86]
 H.
 Zhao,
 B.
 Rusak,
 Circadian
 ﬁring-rate
 rhythms
 and
 light
 responses
 of
 rat
habenular
 nucleus
 neurons
 in
 vivo
 and
 in
 vitro,
 Neuroscience
 132
 (2)
 (2005)
519–528.
[87]
 P.
 Semm,
 C.
 Demaine,
 Electrophysiology
 of
 the
 pigeon’s
 habenular
 nuclei:
evidence
 for
 pineal
 connections
 and
 input
 from
 the
 visual
 system,
 Brain
 Res.
Bull.
 12
 (1)
 (1984)
 115–121.
[88]
 Y.W.
 Chung-Davidson,
 et
 al.,
 Brain
 pathways
 and
 behavioral
 responses
 to
weak
 electric
 ﬁelds
 in
 parasitic
 sea
 lampreys
 (Petromyzon
 marinus),
 Behav.
Neurosci.
 118
 (3)
 (2004)
 611–619.
[89]
 D.et
 al.
 Derjean,
 A
 novel
 neural
 substrate
 for
 the
 transformation
 of
 olfactory
inputs
 into
 motor
 output,
 PLoS
 Biol.
 8
 (12)
 (2010)
 e1000567.
[90]
 W.
 Keil,
 F.
 von
 Stralendorff,
 R.
 Hudson,
 A
 behavioral
 bioassay
 for
 analysis
 of
rabbit
 nipple-search
 pheromone,
 Physiol.
 Behav.
 47
 (3)
 (1990)
 525–529.
[91]
 A.
 Thesen,
 J.B.
 Steen,
 K.B.
 Doving,
 Behaviour
 of
 dogs
 during
 olfactory
tracking,
 J.
 Exp.
 Biol.
 180
 (1993)
 247–251.
[92]
 S.J.
 Jesuthasan,
 A.S.
 Mathuru,
 The
 alarm
 response
 in
 zebraﬁsh:
 innate
 fear
 in
a
 vertebrate
 genetic
 model,
 J.
 Neurogenet.
 22
 (3)
 (2008)
 211–228.
[93]
 T.A.
 Oliveira,
 et
 al.,
 Death-associated
 odors
 induce
 stress
 in
 zebraﬁsh,
 Horm.
Behav.
 65
 (4)
 (2014)
 340–344.
[94]
 A.
 Schmidt,
 G.
 Roth,
 Central
 olfactory
 and
 vomeronasal
 pathways
 in
salamanders,
 J.
 Hirnforsch.
 31
 (5)
 (1990)
 543–553.
 138
 
S.
 Fore
 et
 al.
 /
 Seminars
 in
 Cell
 &
 Developmental
 Biology
 78
 (2018)
 130–139
[95]
 N.
 Miyasaka,
 et
 al.,
 Olfactory
 projectome
 in
 the
 zebraﬁsh
 forebrain
 revealed
by
 genetic
 single-neuron
 labelling,
 Nat.
 Commun.
 5
 (2014)
 3639.
[96]
 S.K.
 Jetti,
 N.
 Vendrell-Llopis,
 E.
 Yaksi,
 Spontaneous
 activity
 governs
 olfactory
representations
 in
 spatially
 organized
 habenular
 microcircuits,
 Curr.
 Biol.
 24
(4) (2014)
 434–439.
[97]
 G.
 Laurent,
 et
 al.,
 Odor
 encoding
 as
 an
 active,
 dynamical
 process:
experiments,
 computation,
 and
 theory,
 Annu.
 Rev.
 Neurosci.
 24
 (2001)
263–297.
[98]
 E.
 Yaksi,
 R.W.
 Friedrich,
 Reconstruction
 of
 ﬁring
 rate
 changes
 across
neuronal
 populations
 by
 temporally
 deconvolved
 Ca2+
 imaging,
 Nat.
Methods
 3
 (5)
 (2006)
 377–383.
[99]
 E.
 Yaksi,
 et
 al.,
 Transformation
 of
 odor
 representations
 in
 target
 areas
 of
 the
olfactory
 bulb,
 Nat.
 Neurosci.
 12
 (4)
 (2009)
 474–482.
[100]
 F.
 Kermen,
 et
 al.,
 Neural
 circuits
 mediating
 olfactory-driven
 behavior
 in
 ﬁsh,
Front.
 Neural
 Circuits
 7
 (2013)
 62.
[101]
 C.
 Bertolucci,
 A.
 Foa,
 Extraocular
 photoreception
 and
 circadian
 entrainment
in
 nonmammalian
 vertebrates,
 Chronobiol.
 Int.
 21
 (4–5)
 (2004)
 501–519.
[102]
 G.
 Tosini,
 C.
 Bertolucci,
 A.
 Foa,
 The
 circadian
 system
 of
 reptiles:
 a
multioscillatory
 and
 multiphotoreceptive
 system,
 Physiol.
 Behav.
 72
 (4)
(2001)
 461–471.
[103]
 H.
 Underwood,
 The
 pineal
 and
 melatonin:
 regulators
 of
 circadian
 function
 in
lower
 vertebrates,
 Experientia
 46
 (1)
 (1990)
 120–128.
[104]
 H.
 Underwood,
 G.
 Groos,
 Vertebrate
 circadian
 rhythms:
 retinal
 and
extraretinal
 photoreception,
 Experientia
 38
 (9)
 (1982)
 1013–1021.
[105]
 M.L.
 Concha,
 S.W.
 Wilson,
 Asymmetry
 in
 the
 epithalamus
 of
 vertebrates,
 J.
Anat.
 199
 (Pt.
 1–2)
 (2001)
 63–84.
[106]
 H.W.
 Korf,
 N.H.
 Zimmerman,
 A.
 Oksche,
 Intrinsic
 neurons
 and
 neural
connections
 of
 the
 pineal
 organ
 of
 the
 house
 sparrow:
 passer
 domesticus,
 as
revealed
 by
 anterograde
 and
 retrograde
 transport
 of
 horseradish
peroxidase,
 Cell
 Tissue
 Res.
 222
 (2)
 (1982)
 243–260.
[107]
 O.K.
 Ronnekleiv,
 M.J.
 Kelly,
 W.
 Wuttke,
 Single
 unit
 recordings
 in
 the
 rat
pineal
 gland:
 evidence
 for
 habenulo-pineal
 neural
 connections,
 Exp.
 Brain
Res.
 39
 (2)
 (1980)
 187–192.
[108]
 P.
 Semm,
 C.
 Demaine,
 L.
 Vollrath,
 Electrical
 responses
 of
 pineal
 cells
 to
melatonin
 and
 putative
 transmitters:
 evidence
 for
 circadian
 changes
 in
sensitivity,
 Exp.
 Brain
 Res.
 43
 (3–4)
 (1981)
 361–370.
[109]
 J.
 Yanez,
 M.A.
 Pombal,
 R.
 Anadon,
 Afferent
 and
 efferent
 connections
 of
 the
parapineal
 organ
 in
 lampreys:
 a
 tract
 tracing
 and
 immunocytochemical
study,
 J.
 Comp.
 Neurol.
 403
 (2)
 (1999)
 171–189.
[110]
 C.
 Rudeberg,
 Structure
 of
 the
 parapineal
 organ
 of
 the
 adult
 rainbow
 trout:
Salmo
 gairdneri
 Richardson,
 Z.
 Zellforsch.
 Mikrosk.
 Anat.
 93
 (2)
 (1969)
282–304.
[111]
 C.
 Rudeberg,
 Light
 and
 electron
 microscopic
 studies
 on
 the
 pineal
 organ
 of
the dogﬁsh:
 Scyliorhinus
 canicula
 L,
 Z.
 Zellforsch.
 Mikrosk.
 Anat.
 96
 (4)
(1969)
 548–581.
[112]
 T.
 van
 Veen,
 et
 al.,
 The
 pineal
 complex
 of
 the
 three-spined
 stickleback,
Gasterosteus
 aculeatus
 L.:
 a
 light-,
 electron
 microscopic
 and
 ﬂuorescence
histochemical
 investigation,
 Cell
 Tissue
 Res.
 209
 (1)
 (1980)
 11–28.
[113]
 M.L.
 Concha,
 et
 al.,
 A
 nodal
 signaling
 pathway
 regulates
 the
 laterality
 of
neuroanatomical
 asymmetries
 in
 the
 zebraﬁsh
 forebrain,
 Neuron
 28
 (2)
(2000)
 399–409.
[114]
 M.
 Roussigne,
 et
 al.,
 Nodal
 signalling
 imposes
 left-right
 asymmetry
 upon
neurogenesis
 in
 the
 habenular
 nuclei,
 Development
 136
 (9)
 (2009)
1549–1557.
[115]
 J.
 Levy,
 The
 mammalian
 brain
 and
 the
 adaptive
 advantage
 of
 cerebral
asymmetry,
 Ann.
 N.
 Y.
 Acad.
 Sci.
 299
 (1977)
 264–272.
[116]
 B.B.
 Zhang,
 et
 al.,
 Left
 habenula
 mediates
 light-preference
 behavior
 in
zebraﬁsh
 via
 an
 asymmetrical
 visual
 pathway,
 Neuron
 93
 (4)
 (2017)
914–928,
 e4.
[117]
 S.J.J.
 Qian
 Lin,
 Masking
 of
 a
 Circadian
 Behavior
 in
 Larval
 Zebraﬁsh
 Involves
the  Thalamo-Habenula
 Pathway,
 bioRxiv,
 2017.
[118]
 R.K.
 Cheng,
 et
 al.,
 The
 thalamus
 drives
 light-evoked
 activity
 in
 the
 habenula
of
 larval
 zebraﬁsh,
 bioRxiv
 (2016).
[119]
 S.
 Herbute,
 J.D.
 Bayle,
 Pineal
 multiunit
 activity
 in
 conscious
 quail:
 effects
 of
light,
 blinding,
 ganglionectomy,
 Am.
 J.
 Physiol.
 231
 (1)
 (1976)
 136–140.
[120]
 T.
 Qu,
 et
 al.,
 Demonstration
 of
 direct
 input
 from
 the
 retina
 to
 the
 lateral
habenular
 nucleus
 in
 the
 albino
 rat,
 Brain
 Res.
 709
 (2)
 (1996)
 251–258.
[121]
 S.
 Reuss,
 K.
 Decker,
 Anterograde
 tracing
 of
 retinohypothalamic
 afferents
with
 Fluoro-Gold,
 Brain
 Res.
 745
 (1–2)
 (1997)
 197–204.
[122]
 A.A.
 Faisal,
 L.P.
 Selen,
 D.M.
 Wolpert,
 Noise
 in
 the
 nervous
 system,
 Nat.
 Rev.
Neurosci.
 9
 (4)
 (2008)
 292–303.
[123]
 D.
 Tomasi,
 G.J.
 Wang,
 N.D.
 Volkow,
 Energetic
 cost
 of
 brain
 functional
connectivity,
 Proc.
 Natl.
 Acad.
 Sci.
 U.
 S.
 A.
 110
 (33)
 (2013)
 13642–13647.
[124]
 E.
 Marder,
 D.
 Bucher,
 Central
 pattern
 generators
 and
 the
 control
 of
 rhythmic
movements,
 Curr.
 Biol.
 11
 (23)
 (2001)
 R986–96.
[125]
 M.
 Goulding,
 Circuits
 controlling
 vertebrate
 locomotion:
 moving
 in
 a
 new
direction,
 Nat.
 Rev.
 Neurosci.
 10
 (7)
 (2009)
 507–518.
[126]
 A.
 Luczak,
 P.
 Bartho,
 K.D.
 Harris,
 Spontaneous
 events
 outline
 the
 realm
 of
possible
 sensory
 responses
 in
 neocortical
 populations,
 Neuron
 62
 (3)
 (2009)
413–425.
[127]
 T.
 Kenet,
 et
 al.,
 Spontaneously
 emerging
 cortical
 representations
 of
 visual
attributes,
 Nature
 425
 (6961)
 (2003)
 954–956.
[128]
 A.
 Arieli,
 et
 al.,
 Dynamics
 of
 ongoing
 activity:
 explanation
 of
 the
 large
variability
 in
 evoked
 cortical
 responses,
 Science
 273
 (5283)
 (1996)
1868–1871.
[129]
 V.
 Moreno-Juan,
 et
 al.,
 Prenatal
 thalamic
 waves
 regulate
 cortical
 area
 size
prior
 to
 sensory
 processing,
 Nat.
 Commun.
 8
 (2017)
 14172.
[130]
 M.P.
 Karlsson,
 L.M.
 Frank,
 Awake
 replay
 of
 remote
 experiences
 in
 the
hippocampus,
 Nat.
 Neurosci.
 12
 (7)
 (2009)
 913–918.
[131]
 D.A.
 Butts,
 P.O.
 Kanold,
 C.J.
 Shatz,
 A
 burst-based
 Hebbian
 learning
 rule
 at
retinogeniculate
 synapses
 links
 retinal
 waves
 to
 activity-dependent
reﬁnement,
 PLoS
 Biol.
 5
 (3)
 (2007)
 e61.
[132]
 A.H.
 Leighton,
 C.
 Lohmann,
 The
 wiring
 of
 developing
 sensory
 circuits-from
patterned
 spontaneous
 activity
 to
 synaptic
 plasticity
 mechanisms,
 Front.
Neural
 Circuits
 10
 (2016)
 71.
[133]
 E.
 Kutsarova,
 M.
 Munz,
 E.S.
 Ruthazer,
 Rules
 for
 shaping
 neural
 connections
in
 the
 developing
 brain,
 Front.
 Neural
 Circuits
 10
 (2016)
 111.
[134]
 D.A.
 Wilson,
 Single-unit
 activity
 in
 piriform
 cortex
 during
 slow-wave
 state
 is
shaped
 by
 recent
 odor
 experience,
 J.
 Neurosci.
 30
 (5)
 (2010)
 1760–1765.
[135]
 L.
 Deuker,
 et
 al.,
 Memory
 consolidation
 by
 replay
 of
 stimulus-speciﬁc
 neural
activity,
 J.
 Neurosci.
 33
 (49)
 (2013)
 19373–19383.
[136]
 T.
 Abel,
 et
 al.,
 Sleep:
 plasticity
 and
 memory
 from
 molecules
 to
 whole-brain
networks,
 Curr.
 Biol.
 23
 (17)
 (2013)
 R774–88.
[137]
 T.J.
 Davidson,
 F.
 Kloosterman,
 M.A.
 Wilson,
 Hippocampal
 replay
 of
 extended
experience,
 Neuron
 63
 (4)
 (2009)
 497–507.
[138]
 G.
 Wang,
 et
 al.,
 Synaptic
 plasticity
 in
 sleep:
 learning,
 homeostasis
 and
disease,
 Trends
 Neurosci.
 34
 (9)
 (2011)
 452–463.
[139]
 J.F.
 Poulet,
 C.C.
 Petersen,
 Internal
 brain
 state
 regulates
 membrane
 potential
synchrony
 in
 barrel
 cortex
 of
 behaving
 mice,
 Nature
 454
 (7206)
 (2008)
881–885.
[140]
 K.D.
 Harris,
 A.
 Thiele,
 Cortical
 state
 and
 attention,
 Nat.
 Rev.
 Neurosci.
 12
 (9)
(2011)
 509–523.
[141]
 A.
 Destexhe,
 Self-sustained
 asynchronous
 irregular
 states
 and
 up-down
states
 in
 thalamic:
 cortical
 and
 thalamocortical
 networks
 of
 nonlinear
integrate-and-ﬁre
 neurons,
 J.
 Comput.
 Neurosci.
 27
 (3)
 (2009)
 493–506.
[142]
 A.
 Destexhe,
 D.
 Contreras,
 Neuronal
 computations
 with
 stochastic
 network
states,
 Science
 314
 (5796)
 (2006)
 85–90.
[143]
 M.V.
 Sanchez-Vives,
 D.A.
 McCormick,
 Cellular
 and
 network
 mechanisms
 of
rhythmic
 recurrent
 activity
 in
 neocortex,
 Nat.
 Neurosci.
 3 (10)
 (2000)
1027–1034.
[144]
 A.
 Luczak,
 P.
 Bartho,
 K.D.
 Harris,
 Gating
 of
 sensory
 input
 by
 spontaneous
cortical
 activity,
 J.
 Neurosci.
 33
 (4)
 (2013)
 1684–1695.
[145]
 R.L.
 Buckner,
 J.R.
 Andrews-Hanna,
 D.L.
 Schacter,
 The
 brain’s
 default
 network:
anatomy,
 function,
 and
 relevance
 to
 disease,
 Ann.
 N.
 Y.
 Acad.
 Sci.
 1124
(2008)
 1–38.
[146]
 M.D.
 Greicius,
 et
 al.,
 Functional
 connectivity
 in
 the
 resting
 brain:
 a
 network
analysis
 of
 the
 default
 mode
 hypothesis,
 Proc.
 Natl.
 Acad.
 Sci.
 U.
 S.
 A.
 100
 (1)
(2003)
 253–258.
[147]
 P.
 Fransson,
 Spontaneous
 low-frequency
 BOLD
 signal
 ﬂuctuations:
 an
 fMRI
investigation
 of
 the
 resting-state
 default
 mode
 of
 brain
 function
 hypothesis,
Hum.
 Brain
 Mapp.
 26
 (1)
 (2005)
 15–29.
[148]
 M.D.
 Fox,
 et
 al.,
 The
 human
 brain
 is
 intrinsically
 organized
 into
 dynamic:
anticorrelated
 functional
 networks,
 Proc.
 Natl.
 Acad.
 Sci.
 U.
 S.
 A.
 102
 (27)
(2005)
 9673–9678.
[149]
 Y.
 Golland,
 et
 al.,
 Extrinsic
 and
 intrinsic
 systems
 in
 the
 posterior
 cortex
 of
the
 human
 brain
 revealed
 during
 natural
 sensory
 stimulation,
 Cereb.
 Cortex
17  (4)
 (2007)
 766–777.
[150]
 L.
 Tian,
 et
 al.,
 The
 relationship
 within
 and
 between
 the
 extrinsic
 and
intrinsic
 systems
 indicated
 by
 resting
 state
 correlational
 patterns
 of
 sensory
cortices,
 Neuroimage
 36
 (3)
 (2007)
 684–690.
[151]
 B.
 Mazoyer,
 et
 al.,
 Cortical
 networks
 for
 working
 memory
 and
 executive
functions
 sustain
 the
 conscious
 resting
 state
 in
 man,
 Brain
 Res.
 Bull.
 54
 (3)
(2001)
 287–298.
[152]
 S.J.
 Gilbert,
 et
 al.,
 Comment
 on
 Wandering
 minds:
 the
 default
 network
 and
stimulus-independent
 thought,
 Science
 317
 (5834)
 (2007)
 43,
 author
 reply
43.
[153]
 M.L.
 Tantirigama,
 H.H.
 Huang,
 J.M.
 Bekkers,
 Spontaneous
 activity
 in
 the
piriform
 cortex
 extends
 the
 dynamic
 range
 of
 cortical
 odor
 coding,
 Proc.
Natl. Acad.
 Sci.
 U.
 S.
 A.
 114
 (9)
 (2017)
 2407–2412.
[154]
 T.C.
 Jhou,
 et
 al.,
 Cocaine
 drives
 aversive
 conditioning
 via
 delayed
 activation
of
 dopamine-responsive
 habenular
 and
 midbrain
 pathways,
 J.
 Neurosci.
 33
(17)  (2013)
 7501–7512.
[155]
 A.
 Gorlich,
 et
 al.,
 Reexposure
 to
 nicotine
 during
 withdrawal
 increases
 the
pacemaking
 activity
 of
 cholinergic
 habenular
 neurons,
 Proc.
 Natl.
 Acad.
 Sci.
U.  S.
 A.
 110
 (42)
 (2013)
 17077–17082.
[156]
 D.Q.
 Dao,
 et
 al.,
 Nicotine
 enhances
 excitability
 of
 medial
 habenular
 neurons
via
 facilitation
 of
 neurokinin
 signaling,
 J.
 Neurosci.
 34
 (12)
 (2014)
4273–4284.
[157]
 N.M.
 Neugebauer,
 et
 al.,
 Morphine
 dependence
 and
 withdrawal
 induced
changes
 in
 cholinergic
 signaling,
 Pharmacol.
 Biochem.
 Behav.
 109
 (2013)
77–83.
[158]
 K.P.
 Mohanakumar,
 P.P.
 Sood,
 Acetylcholinesterase
 changes
 in
 the
 central
nervous
 system
 of
 mice
 during
 the
 development
 of
 morphine
 tolerance
addiction
 and
 withdrawal,
 Brain
 Res.
 Bull.
 10
 (5)
 (1983)
 589–596.
[159]
 R.J.
 Katz,
 K.A.
 Roth,
 B.J.
 Carroll,
 Acute
 and
 chronic
 stress
 effects
 on
 open
 ﬁeld
activity
 in
 the
 rat:
 implications
 for
 a
 model
 of
 depression,
 Neurosci.
Biobehav.
 Rev.
 5
 (2)
 (1981)
 247–251.
[160]
 J.
 Shumake,
 F.
 Gonzalez-Lima,
 Brain
 systems
 underlying
 susceptibility
 to
helplessness
 and
 depression,
 Behav.
 Cogn.
 Neurosci.
 Rev.
 2
 (3)
 (2003)
198–221.
 S.
 Fore
 et
 al.
 /
 Seminars
 in
 Cell
 &
 Developmental
 Biology
 78
 (2018)
 130–139
 
139
[161]
 T.
 Nishikawa,
 B.
 Scatton,
 Inhibitory
 inﬂuence
 of
 GABA
 on
 central
serotonergic
 transmission.
 Involvement
 of
 the
 habenulo-raphe
 pathways
 in
the
 GABAergic
 inhibition
 of
 ascending
 cerebral
 serotonergic
 neurons,
 Brain
Res.
 331
 (1)
 (1985)
 81–90.
[162]
 P.
 Kalen,
 et
 al.,
 Regulation
 of
 striatal
 serotonin
 release
 by
 the
 lateral
habenula-dorsal
 raphe
 pathway
 in
 the
 rat
 as
 demonstrated
 by
 in
 vivo
microdialysis:
 role
 of
 excitatory
 amino
 acids
 and
 GABA,
 Brain
 Res.
 492
 (1–2)
(1989)
 187–202.
[163]
 K.
 Nakamura,
 M.
 Matsumoto,
 O.
 Hikosaka,
 Reward-dependent
 modulation
of neuronal
 activity
 in
 the
 primate
 dorsal
 raphe
 nucleus,
 J.
 Neurosci.
 28
 (20)
(2008)
 5331–5343.
[164]
 M.
 Herkenham,
 Anesthetics
 and
 the
 habenulo-interpeduncular
 system:
selective
 sparing
 of
 metabolic
 activity,
 Brain
 Res.
 210
 (1–2)
 (1981)
 461–466.
[165]
 P.S.
 van
 Nieuwenhuijzen,
 I.S.
 McGregor,
 G.E.
 Hunt,
 The
 distribution
 of
gamma-hydroxybutyrate-induced
 Fos
 expression
 in
 rat
 brain:
 comparison
with
 baclofen,
 Neuroscience
 158
 (2)
 (2009)
 441–455.
[166]
 R.
 Abulaﬁa,
 V.
 Zalkind,
 M.
 Devor,
 Cerebral
 activity
 during
 the
 anesthesia-like
state
 induced
 by
 mesopontine
 microinjection
 of
 pentobarbital,
 J.
 Neurosci.
29
 (21)
 (2009)
 7053–7064.
[167]
 C.
 Guilding,
 H.D.
 Piggins,
 Challenging
 the
 omnipotence
 of
 the
suprachiasmatic
 timekeeper:
 are
 circadian
 oscillators
 present
 throughout
the
 mammalian
 brain?
 Eur.
 J.
 Neurosci.
 25
 (11)
 (2007)
 3195–3216.
[168]
 S.
 Pavel,
 C.
 Eisner,
 A
 GABAergic
 habenulo-raphe
 pathway
 mediates
 both
serotoninergic
 and
 hypnogenic
 effects
 of
 vasotocin
 in
 cats,
 Brain
 Res.
 Bull.
13
 (5)
 (1984)
 623–627.
[169]
 R.
 Vetrivelan,
 et
 al.,
 Medullary
 circuitry
 regulating
 rapid
 eye
 movement
 sleep
and
 motor
 atonia,
 J. Neurosci.
 29
 (29)
 (2009)
 9361–9369.
[170]
 G.
 Holstege,
 The
 mesopontine
 rostromedial
 tegmental
 nucleus
 and
 the
emotional
 motor
 system:
 role
 in
 basic
 survival
 behavior,
 J.
 Comp.
 Neurol.
513 (6)
 (2009)
 559–565.
[171]
 T.N.
 deCarvalho,
 et
 al.,
 Neurotransmitter
 map
 of
 the
 asymmetric
 dorsal
habenular
 nuclei
 of
 zebraﬁsh,
 Genesis
 52
 (6)
 (2014)
 636–655.
[172]
 X.J.
 Wang,
 Decision
 making
 in
 recurrent
 neuronal
 circuits,
 Neuron
 60
 (2)
(2008)
 215–234.
[173]
 C.K.
 Machens,
 R.
 Romo,
 C.D.
 Brody,
 Flexible
 control
 of
 mutual
 inhibition:
 a
neural
 model
 of
 two-interval
 discrimination,
 Science
 307
 (5712)
 (2005)
1121–1124.
[174]
 R.
 Fdez
 Galan,
 et
 al.,
 Odor-driven
 attractor
 dynamics
 in
 the
 antennal
 lobe
allow
 for
 simple
 and
 rapid
 olfactory
 pattern
 classiﬁcation,
 Neural
 Comput.
16
 (5)
 (2004)
 999–1012.
[175]
 R.
 Cossart,
 D.
 Aronov,
 R.
 Yuste,
 Attractor
 dynamics
 of
 network
 UP  states
 in
the
 neocortex,
 Nature
 423
 (6937)
 (2003)
 283–288.
[176]
 A.
 Valente,
 et
 al.,
 Ontogeny
 of
 classical
 and
 operant
 learning
 behaviors
 in
zebraﬁsh,
 Learn.
 Mem.
 19
 (4)
 (2012)
 170–177.
",https://doi.org/10.1016/j.semcdb.2017.08.019,doc2,"Seminars in Cell & Developmental Biology 78 (2018) 130–139 Contents lists available at ScienceDirect Seminars in Cell & Developmental Biology j ourna l ho me pa g e: www.elsevier.com/locate/semcdb Review Information processing in the vertebrate habenula Stephanie Fore, Fabrizio Palumbo, Robbrecht Pelgrims, Emre Yaksi ∗ Kavli Institute for Systems Neuroscience and Centre for Neural Computation, Norwegian University of Science and Technology, Olav Kyrres Gate 9, Norwegian Brain Centre, 7491 Trondheim, Norway a r t i c l e i n f o Article history: Received 23 March 2017 Received in revised form 12 July 2017 Accepted 5 August 2017 Available online 7 August 2017 Keywords: Habenula Prediction error Mood disorders Social behavior Addiction Spontaneous activity Ongoing activity Default mode network Sensory activity Sensory processing Asymmetry Learning Neural circuits Stress Anxiety Fear Attractor networks Ventral tegmental area Raphe nucleus Interpeduncular nucleus Sensory systems a b s t r a c t The habenula is a brain region that has gained increasing popularity over the recent years due to its role in processing value-related and experience-dependent information with a strong link to depression, addiction, sleep and social interactions. This small diencephalic nucleus is proposed to act as a multimodal hub or a switchboard, where inputs from different brain regions converge. These diverse inputs to the habenula carry information about the sensory world and the animal’s internal state, such as reward expectation or mood. However, it is not clear how these diverse habenular inputs interact with each other and how such interactions contribute to the function of habenular circuits in regulating behavioral responses in various tasks and contexts. In this review, we aim to discuss how information processing in habenular circuits, can contribute to speciﬁc behavioral programs that are attributed to the habenula. © 2017 Elsevier Ltd. All rights reserved. Contents 1. The role of the habenula in generating complex behaviors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131 1.1. Learning, encoding errors and negative outcomes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131 1.2. Addiction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132 1.3. Mood disorders and social behaviors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132 2. Sensory representations in the habenula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133 2.1. Electroreception and vestibular system . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133 2.2. Olfaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133 2.3. Photoreception and vision . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134 3. Ongoing spontaneous activity in the habenula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134 3.1. Implications of changing ongoing activity in habenular circuits. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135 3.2. Interactions of spontaneous and sensory driven activity in the habenula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135 Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136 ∗Corresponding author. E-mail address: emre.yaksi@ntnu.no (E. Yaksi). 1084-9521/© 2017 Elsevier Ltd. All rights reserved. S. Fore et al. / Seminars in Cell & Developmental Biology 78 (2018) 130–139 131 The habenula (Hb) is an evolutionarily conserved diencephalic nucleus, connecting forebrain regions such as prefrontal cortex (PFC) [1], septohippocampal region [2] and the Basal Ganglia [3–6], with downstream monoaminergic nuclei, such as the ven- tral tegmental area/rostromedial tegmental nucleus (VTA/RMTg) [7–13] and the Raphe nuclei [2,6,11,14–16], as well as the interpe- duncular nucleus (IPN) [6] (Fig. 1A,B). Already in 1914, experimental evidence highlighted the role of the Hb in regulating the valence of behavioral outcomes. It was observed that electrostimulation of habenular efferents, in chim- panzees, induced a respiration pattern resembling laughter [17,18]. However, it was not until the eighties that researchers proposed the idea of the Hb steering emotionally involved behavior by the modulation of dopamine neurons [19]. With the reﬁnement of experimental tools, as well as the advent of novel techniques such as optogenetics and molecular tools, it became possible to investi- gate and further subdivide the roles of the Hb in a broader range of behaviors related to learning, depression, addiction, sleep and social interactions. The mammalian Hb consists of at least two functionally segre- gated subnuclei: the medial (MHb) and the lateral habenula (LHb). The MHb was suggested to play an important role in anxiety, fear, depression and nicotine addiction [20–24]. Moreover, MHb activity was shown to be regulated by circadian rhythm [25]. Yet, functional studies of the MHb have been difﬁcult in mammals due to its small volume and deep location right next to the third ventricle [26]. On the other hand, a lot more studies have investigated the role of the LHb in brain function and animal behavior, with a strong focus on regulation of dopaminergic and serotonergic nuclei in order to shape both innate and conditioned behaviors [26]. Research on the Hb has been diverse, covering multiple ques- tions ranging from the role of the Hb in learning and cognitive function, to its involvement in mood disorders and addiction in human patients. Moreover, the Hb has always been an attractive brain region for those who are interested in studying the devel- opment of brain asymmetries and their potential function. Finally, an increasing amount of evidence suggests an important role for the Hb in sensory information processing in several animal models. While all these exciting results contributed to our understanding of the habenular function in the brain, the link between these diverse disciplines of habenular research is not yet fully established. In this review, we aim to provide a broad overview of the research con- ducted on the Hb and try to link these studies that cover different disciplines of neuroscience. In the following sections, we will ﬁrst provide an overview of the inputs and outputs of the habenular circuitry and the role of these structures in different behaviors. Next, we will describe how sensory information is received and processed in the Hb. We then suggest several hypotheses about how neural information from different brain regions can be integrated at the level of the Hb. We propose that the ongoing activity observed in the Hb, plays an important role in reﬂecting the internal state of the animal, inte- grating information from a number of brain regions and the sensory systems. 1. The role of the habenula in generating complex behaviors 1.1. Learning, encoding errors and negative outcomes Seminal studies, using single-unit recordings in primates, showed a direct involvement of the LHb in encoding prediction error. One of these studies reported that several LHb neurons were activated by no-reward predicting cues as well as the absence of the reward, while they were inhibited by reward and reward predict- ing stimuli [3]. The ﬁring rate of neurons inhibited by reward and reward predicting cues, is also directly proportional to the proba- bility of receiving the reward [27,28]. Moreover, the activity of LHb neurons is shown to follow the activity of the dopaminergic neu- rons in the substantia nigra pars compacta (SNc) in case of a reward and to precede it in case of reward omission [3,29]. Rodent studies have further unraveled the complexity of this interconnected circuit composed of feedback and feedforward sig- naling between the LHb, the monoaminergic brainstem nuclei and the basal ganglia. The LHb was shown to inhibit dopaminergic neu- rons of the VTA indirectly via the RMTg [8,12,30–33] or directly by exciting local GABAergic neurons in the VTA [12,34]. Exposure to aversive stimuli such as foot shocks, induces plasticity in the LHb-RMTg pathway [33] but also results in an increased ﬁring in the GABAergic population of the VTA [35]. Stimulating LHb neu- rons directly induces place avoidance, a behavior characterized by reduced exploration of the stimulation-coupled area [35–37]. In addition, the role of the LHb has also been investigated in terms of cost-beneﬁt decision making. Rats learnt to receive a greater beneﬁt (four food pellets instead of one) when their waiting time was increased. When the probability of receiving the award was low, the cost of waiting became too high. Lesioning the LHb dis- abled the rats from making such cost-efﬁcient decisions, without affecting the animal’s ability to evaluate the magnitude of the immediate reward [32]. While VTA receives information directly or indirectly from LHb, it also sends feedback projections inhibit- ing LHb neurons [8]. Investigation of these projections reveals a co-release of glutamate and GABA [7,38], which suggests that mod- ulating the co-release ratio can be a potential mechanism of tuning habenular activity. Interestingly, recordings of VTA neurons show two different populations encoding aversive and rewarding stim- uli with different dynamics. The authors showed that, while most GABAergic VTA neurons respond to aversive stimuli, the majority of dopaminergic neurons respond to reward related information [39]. These results indicate that the LHb modulates and is modulated by the VTA, which plays a role in dopaminergic regulation of animal behavior. In addition to modulating dopaminergic signaling, the Hb was also shown to regulate serotonin release directly through LHb projections to the Raphe nuclei [32,40–42] and indirectly via the projections of the LHb and the MHb to the RMTg [16] and the IPN [42] respectively. The role of serotonin in reward processing and learning is still under investigation. However, accumulating evidence supports its involvement in these phenomena [43–47]. Taken together, these ﬁndings suggests that both dopamine and serotonin modulate the processing of stimulus-related information bidirectionally, shaping it based on the internal state of the animal in order to tune subsequent behavioral outcomes. The mammalian lateral and medial Hb ﬁnd their respective homologues as the ventral habenula (vHb) and the dorsal habenula (dHb) in zebraﬁsh (Fig. 1C) [4,6]. Lesioning the dHb, was shown to prevent zebraﬁsh from coping with threats in a stressful context and induces freezing (or helplessness), rather than escape or avoid- ance [48,49]. A complementary study [6] further showed that a population of vHb neurons encodes the negative expectation value that is associated with the conditioned stimulus, by increasing their tonic response to the conditioned stimulus during learning. In addi- tion, the phasically active vHb neurons represent the prediction error. Along with this, the same study showed that lesioning the vHb impairs the ability of the ﬁsh to perform active avoidance, without affecting the switch from freezing to agitation as is the case for the dHb ablation. These results are in line with the two- factor theory of active avoidance. At ﬁrst, an aversive stimulus is associated with a biologically neutral stimulus, resulting in a fear response when the neutral stimulus is presented (Pavlovian factor, association phase). Subsequently, the transition from an unsafe to a safe state can then be further associated to a speciﬁc performed 132 S. Fore et al. / Seminars in Cell & Developmental Biology 78 (2018) 130–139 Fig. 1. Schematic overview of the habenula homologues in the mammalian and non-mammalian brain and their afferent and efferent neural pathways. Sagittal view of the rodent (A) and the zebraﬁsh (B) brain showing that the habenula connects forebrain, midbrain and hindbrain nuclei in both vertebrates. Green: afferents, blue: efferents, yellow: bidirectional connections. Schematic representations of transverse views of both the rodent (rat) (top panel) and zebraﬁsh (bottom panel) habenula showing the homologue habenula regions and their efferents (adapted from Amo et al. [6]) (C).Abbreviations: Hb, habenula; mHb, medial habenula; LHb, lateral habenula; dHb, dorsal habenula; vHb, ventral habenula; OB, olfactory bulb; EN, entopeduncular nucleus; PO, preoptic area; TH, thalamus; PP, parapineal organ; Vv, ventral area of the subpallium; pHT/PT, posterior hypothalamus/posterior tuberculum; IPN, interpeduncular nucleus; R, raphe; S/DBB, septum/diagonal band of Broca; RMTg, rostromedial tegmental nucleus; NAc, nucleus accumbens; LC, locus coeruleus; VTA, ventral tegmental area; SCN, suprachiasmatic nucleus; SNc; substantia nigra pars compacta; SC, superior colliculus; PAG, periaqueductal gray; NI, nucleus Incertus; P, pineal; mPFC medial prefrontal cortex;. behavior, which can act as a surrogate reward (instrumental factor, goal-directed phase) [50,51]. Taken together, it appears that while the zebraﬁsh dHb might be involved in the association phase of clas- sical conditioning where a negative value is assigned to a previously neutral stimulus, the zebraﬁsh vHb is involved in the goal-directed phase of operant conditioning, when the animal learns that a spe- ciﬁc behavior gives the possibility of escape [6]. 1.2. Addiction In addition to the extensive literature linking the Hb to learned behaviors, the Hb is gaining popularity and receives increasing clinical interest, as a number of studies in humans [52] and rodents [52] have shown its involvement in addiction [53–55] to nicotine [55–59], cocaine [60,61] and ethanol [62]. The Hb- IPN pathway is particularly enriched with nicotinic acetylcholine receptors (nAChRs) [57,59,63,64]. In human studies, small changes in the genes encoding different subunits of these receptors, were linked to a predisposition to nicotine addiction [52]. In a rodent model, high doses of nicotine were shown to facilitate LHb exci- tation, by activating 6-nAChRs, while low doses inhibit the LHb via 42-nAChRs [65]. This dose-dependent effect of nicotine is also reﬂected in the behavior of the animal, since low doses of nicotine induce conditioned place preference [66] while high doses can induce place avoidance [59,67,68]. Moreover, nicotine has an excitatory inﬂuence on the activity of dopaminergic neurons, pre- dominantly in the posterior VTA [69]. Similar behavioral effects are observed with ethanol, where low doses induce conditioned place aversion while higher doses induce place preference [62]. However, it is not clear if and how this dose-dependent behav- ioral switch is mediated by the Hb. It was suggested that the activation of dopaminergic neurons in the VTA, by high doses of ethanol, might counterbalance the aversion effect driven by the LHb [62]. In line with these results, cocaine self-administration was shown to increase LHb neuron excitability [61]. Moreover, cocaine withdrawal changes the GABA\Glutamate co-release ratio in the pathway between the entopeduncular nucleus and the LHb, result- ing in a disinhibition of the LHb, which could potentially lead to a depressive-like state [5]. Interestingly, deep brain stimulation of the LHb was shown to reduce cocaine intake in rats, as well as cocaine and cocaine-cue related c-fos expression in the LHb [70], suggesting that the LHb could be an interesting target for amelio- rating the behavioral symptoms of addiction. 1.3. Mood disorders and social behaviors Since habenular circuits are involved in encoding prediction errors, coping with stress as well as controlling the activity of dopaminergic and serotonergic brain nuclei, it is not surprising that habenular dysfunction is associated with several mood dis- orders, ranging from anxiety [71] to depression [52]. Patients suffering from major depressive disorder were shown to have an altered habenular volume [72,73] and baseline activity [40,74]. More speciﬁcally, during a passive conditioning task where an ini- tially neutral cue is associated with a negative stimulus (an electric shock), healthy participants show an increased cue-evoked activ- ity in the Hb. Depressive patients however, show a decrease in habenular activity as the cue-stimulus association strengthens [75]. Excitingly, deep brain stimulation of the Hb was linked to reduced symptoms of depression in a human patient [76], which opens a range of therapeutic treatments for depression by interfering with habenular activity. Despite these exciting results in humans, the neural mecha- nisms underlying the role of habenular circuits in mood disorders are still not fully understood. The dopaminergic neurons of the medial VTA show a reduced activity in a rodent model for major S. Fore et al. / Seminars in Cell & Developmental Biology 78 (2018) 130–139 133 Fig. 2. Schematic overview of molecular and functional characteristics of the dHb in zebraﬁsh. (A) Dorsal view of dHb neurons responding asymmetrically to light (red), odor (blue) or both (magenta) (adapted from Dreosti et al. [84]). L = left, R = right. Below are representative bar graphs of the percentage of light and odor- responsive neurons in the total dHB population, showing asymmetric distribution across hemispheres. (B) Dorsal view of spontaneously active neurons in the dHb of juvenile zebraﬁsh (adapted from Jetti et al. [96]). The neurons are subdivided and color coded into six different clusters, based on their similarity of neural activity over time as visualized in the activity traces below. Neurons with similar neural activity are organized into spatial and functional clusters.(C) Transverse view of the neurotransmitter populations across the dHb in adult zebraﬁsh (adapted from Decarvalho et al. [171]). The overall glutamatergic, cholinergic and peptidergic populations are asymmetrically distributed over the two hemispheres. Light blue plane shows the rough location of cross section in A and B. depressive disorder based on chronic mild stress (CMS) [77]. Fur- ther investigation identiﬁed two potential drivers for this activity decrease in the VTA, the LHb and the infralimbic prefrontal cor- tex (ILPFC). While both the LHb and the ILPFC inhibit dopaminergic neurons in the VTA, the LHb preferentially inhibits the lateral VTA instead of the medial VTA [77]. This study therefore questions the involvement of the Hb in the modulation of dopaminergic neurons linked to the effects of CMS. However, parallel investigations show a direct link between habenular hyperactivity and a depression-like phenotype [78,79]. Interestingly, inhibiting glial glutamate reup- take in the LHb induces an increase in neural ﬁring rate and c-fos expression, which again resulted in depressive-like symptoms [80]. A recent study in zebraﬁsh, using another paradigm of inducing stress by social conﬂict, reveals a direct role of the dHb in regu- lating animal behavior. After a ﬁght between two ﬁsh, local ﬁeld potential recordings in the IPN showed that loser ﬁsh have reduced transmission in the pathway between the lateral dHb and the dor- sal/intermediate IPN [81]. Complementary studies in rodents also report that social isolation can induce c-fos expression in the MHb. This effect could further be rescued by increasing the social inter- action between animals [82,83]. Based on these ﬁndings Hb appears to have several roles in con- trolling mood and social interactions, which are tightly linked to one another. It is however not yet clear how neuronal signals are processed by the Hb and how they relate to controlling mood and social interactions in healthy individuals, as well as those who are suffering from major depressive disorder. 2. Sensory representations in the habenula Several studies showed that a diverse range of sensory modal- ities can evoke robust responses in the non-mammalian Hb [14,84,85]. On the contrary, only a smaller number of works on the mammalian Hb report such sensory responses [86,87]. To gain more insight into the role of sensory processing in the Hb, a more thor- ough comparative approach is needed. Below we discuss different sensory modalities that are shown to be processed by habenular circuits in a diverse range of animal models. 2.1. Electroreception and vestibular system Functional measurements of the MHb homologue in lampreys, showed that exposing lampreys to electric ﬁelds increases the activity of Hb neurons and can initiate responses that are typical for ﬂight and freezing behavior [88]. Most likely, this information from the electroreceptive organ is transferred indirectly to the Hb via the pretectum. Retrograde tracing in the Hb indeed showed direct projections from the pretectum, while retrograde tracing in the pre- tectum itself showed direct projections from the electroreceptive organ [14]. 2.2. Olfaction Anatomical tracing studies in lampreys also demonstrated direct projections from the medial olfactory bulb (OB) to the MHb homologue [14]. Odor stimulation of these medial OB neurons was shown to activate spinal locomotor networks in lampreys [89], which suggests a potential link between MHb projecting OB neu- rons and the initiation of fast motor behaviors. Such characteristic movements that are tightly linked to odor cues are not only lim- ited to lampreys, but were also observed in newborn rats, dogs, mice and zebraﬁsh [90–93]. In line with studies in lampreys, trac- ing studies in salamanders and in zebraﬁsh further conﬁrmed the direct relay of olfactory information from OB to the MHb homo- logue [94,95]. Interestingly, it was also shown that zebraﬁsh mitral cells from the mediodorsal OB send projections preferentially to the right dHb, the MHb homologue in zebraﬁsh [95]. In vivo recordings further conﬁrmed that odor responses in the dHb are asymmet- ric across the hemispheres with stronger odor responses in the right dHb [84,96] (Fig. 2a). However, it appears that while odor identity is precisely encoded by differential activation of zebraﬁsh OB neurons [97,98], odor responses of dHb neurons are less odor speciﬁc and respond broadly to odors from different categories [96]. Moreover, a complementary study showed that dHb and vHb neurons display distinct temporal delays in response to different odorant categories and concentrations [85]. These results suggest that the non-mammalian Hb receives information from a distinct part of the olfactory system and relays olfactory information onto its downstream monoaminergic targets [84]. It is worth to note that despite this extensive work in the non-mammalian Hb, it remains unclear whether olfactory inputs are conserved in the mammalian 134 S. Fore et al. / Seminars in Cell & Developmental Biology 78 (2018) 130–139 Hb. Further studies are needed to reveal whether the Hb receives olfactory information from the piriform cortex [99] or other parts of the higher olfactory system [95,100] and what role the Hb plays in olfactory processing within the context of behavioral plasticity and learning. 2.3. Photoreception and vision The parapineal (Pp) is a sensory organ that contains photorecep- tors conveying information about the ambient illumination to the brain and is thought to be involved in circadian rhythms [101–104]. This brain region is present in lampreys, bowﬁn, teleosts, reptiles and birds, but it is absent in other vertebrate groups [105–108]. In lampreys and in ﬁsh, the Pp projects asymmetrically to the left MHb homologue [109–113]. The inﬂuence of the Pp on the Hb was shown to contribute to asymmetries in gene expression, development and function between the left and the right dHb [84,114]. However, it is still unclear whether the Pp relays any information about ambient light conditions to Hb neurons or whether it is merely a regulator in habenular development. The ﬁrst functional investigation of visual responses in the zebraﬁsh dHb suggests that the majority (if not all) of the visual responses in the dHb do not arise from the Pp but likely from the retina [84]. Indeed, the authors showed that eye removal abolished all dHb visual responses, but laser ablation of the Pp did not have a signiﬁcant effect on the dHb visual responses. Intriguingly, dHb light responses, like odor responses, are asym- metric across habenular hemispheres [84]. Visual responses are more prominent on the left dHb while odor responses are pre- dominantly observed in the right dHb (Fig. 2A). The asymmetric segregation of sensory modalities is also preserved in the dorsoven- tral organization of the Hb axonal targets in the IPN, which highlights the importance of sensory segregation in the Hb for information processing and controlling animal behavior. While the function of the dorsoventral segregation of visual and olfactory information in the IPN is not yet clear, the left-right segregation of sensory modalities in Hb suggests a division of labor across the habenular hemispheres. This could in principle increase the information processing capacity of the Hb, as distinct computa- tions would be processed by a dedicated hemisphere rather than being duplicated in an alternatively symmetric and redundant sys- tem [115]. Several perturbations were also shown to interfere with these functional asymmetries between habenular hemispheres [84]. Such experimental manipulations could be used to further test whether disrupted habenular asymmetry leads to impairments in behavioral performance during visual, olfactory and mixed visio- olfactory tasks. In the meantime, recent studies in ﬁsh have linked the visual responses in Hb to light-preference and circadian behaviors [116,117]. Furthermore, it was shown that a subpopulation of ON-responsive retinal ganglion cells activates the dorsal thalamic nuclei, which in turn activate and inhibit different populations of the left dHb neurons with complex temporal response patterns in a light intensity dependent manner [116,118]. In line with the role of the Hb in these observed behaviors, Hb lesions in quails were shown to be effective in suppressing inhibitory inﬂuences of light stimulation [119], suggesting the presence of visual processing, also in the bird Hb. Only a limited number of studies have investigated sensory pro- cessing in the mammalian Hb [86,87]. While the Hb is located deep inside the mammalian brain, light-evoked responses were also reported in the rodent LHb and MHb [86]. In vivo recordings of both habenular subnuclei displayed excitatory and inhibitory char- acteristics in response to light stimuli, suggesting that different Hb neurons might encode light stimuli in different ways. Moreover, a higher tonic ﬁring rate of Hb neurons was observed during the day compared to night-time [86]. When visual responses were mea- sured during night-time, LHb neurons exhibit signiﬁcantly stronger light responses compared to the MHb. Hence, visual responses through a retinoic pathway in the rodent Hb [120,121], might there- fore be modulated by circadian rhythms related to day-night cycles and illumination levels. Nonetheless, in vivo recordings of neural activity in the mam- malian Hb remain challenging. It is thus unclear whether the sensory responses in the mammalian Hb are part of an evolu- tionarily conserved pathway or whether the afferent regulation of this circuitry has changed throughout evolution [14]. Higher-order brain areas that process more complex features of the sensory infor- mation in mammals, might have replaced the direct sensory input to the Hb that was observed in lampreys and teleosts. This could, in turn, help mammals to better adapt their behavioral response to contextual information that is not generated by direct sensory inputs. Even if so, the common mechanism in which the Hb gen- erates motivated behaviors based on contextual information and updates the behavioral strategy to a more suitable outcome, is likely to be preserved across all species. Yet how sensory responses in the Hb and inputs from the limbic system or basal ganglia interact, remains elusive. Hence, it will be essential to continue comparing future results across different species, focusing on the role of habe- nular circuitry in the contextual modulation of sensory processing. 3. Ongoing spontaneous activity in the habenula Almost all measurements of neural activity throughout the brain suggest that a signiﬁcant amount of activity is generated indepen- dently from external sensory stimulation. This internally produced spontaneous activity was previously undervalued, as for a long time it was considered to be biophysical noise with no relevance in neu- ronal computations [122]. Yet, the ongoing spontaneous activity of neurons consumes a major part of the brain’s energy and is arguably more than just an artifact [123]. Several studies have suggested key roles for these intrinsic activity dynamics in diverse neural processes from development and maturation of brain circuits to cognitive performance. Spontaneous bursts of activity were detected in different parts of the nervous system across the animal kingdom. In the crus- tacean stomatogastric system [124] and in the vertebrate spinal cord [125], spontaneous activity is generally related to the genera- tion of biological rhythms that control motor actions. However, the purpose of ongoing activity in the brain such as the vertebrate cor- tex [126–128], thalamus [129], hippocampus [130] and the Hb [96], or in neural parts of sensory organs such as the retina [131,132], are much more diverse and sometimes even elusive. During development, spontaneous activity is important to form appropriate connections and to generate a mature network [129,131–133]. However, in mature networks, this activity has been linked to various functions such as replay [130] and process- ing of previous sensory experiences [134], memory consolidation [135,136], and event planning [137] as well as the reorganiza- tion of the synaptic weights of the network [138], bottom-up thalamic control [139] and top-down modulation [140]. Such spon- taneous activity can be generated intrinsically within one brain area [141,142], by bottom up pathways [143] or by modulation from distal areas either top-down or subcortical [144]. Moreover, sev- eral studies suggest that spontaneous activity can reﬂect cortical states, which can ‘gate’ sensory information to higher brain areas [144]. In humans, highly correlated spontaneous brain activity, is sug- gested to reﬂect a ‘default mode network’ [145]. In this functionally deﬁned network, ongoing brain activity is not elicited by one sin- gle brain region but is rather generated by dynamic interactions of several brain regions across the brain. When the human brain is S. Fore et al. / Seminars in Cell & Developmental Biology 78 (2018) 130–139 135 at rest or engaged in internally focused tasks, the default mode network’ is thought to be spontaneously active. If and how the spontaneous activity of this network is altered by information from the external world is still investigated. It has been hypothesized that the spontaneous activity at rest can be counteracted or sup- pressed by competing activity from additional brain regions that are recruited during sensory processing or attention related tasks [146–150]. On the contrary, a handful of cognitive tasks were also shown to increase spontaneous activity [151]. In these cases ongo- ing spontaneous activity could support a broad level of attention when monitoring the external world for unexpected events [152]. While this idea of a functionally deﬁned default mode network, was previously only applied to cortical areas, it is likely that other parts of the brain, such as Hb, might be part of similar networks with related network properties. 3.1. Implications of changing ongoing activity in habenular circuits The link between spontaneous habenular activity (Fig. 2B) and habenular inputs coming from converging pathways across the brain is not well understood. Nonetheless, the hypothesis of the Hb encoding expected reward value by altering its activity compared to the baseline activity is now generally accepted [3,55]. Sponta- neous activity in the Hb might therefore be a crucial feature, as is it might enable a bidirectional coding of the reward expectation value, as was observed with neurons encoding odors in the piri- form cortex [153]. Such an increase in the dynamic range would not be possible without a baseline activity. Furthermore, several studies have suggested that changes in spontaneous habenular activity might underlie behavioral symp- toms observed in mood disorders or addiction. This is not very surprising as the Hb is regulating monoaminergic brain regions containing dopamine, serotonine and norepinephrine. Drugs like cocaine for example, evoke withdrawal symptoms by a hyperacti- vation of the LHb and strengthening of AMPAR-mediated synaptic transmission onto RMTg neurons [154]. Acute application of nico- tine on the other hand, increases spontaneously occurring action potentials of the cholinergic neurons in the MHb via a speciﬁc subtype of nAChR [155]. Blocking of spontaneous ﬁring in the MHb, was shown to induce withdrawal-like symptoms similar to nicotine withdrawal [155,156]. The effects of morphine, an opi- oid also inducing wirthdrawal-like symptoms, on the MHb activity are less clear, since low and high doses respectively increased and decreased spontaneous habenular activity [157,158]. It is highly likely that such pharmacological alterations do not only affect the Hb, instead this could alter the activity of a broadly dispersed brain network, where Hb plays a key role. Furthermore stress-inducing stimuli also excite neurons in the LHb and prolonged stimulation could even generate anxiety and depression [49,159,160]. Multiple studies have shown that increased background activity of the LHb is linked to anhedonia (a behavioral symptom observed in some depressive patients), by decreasing the activity of dopaminergic neurons after positive events [76]. However, stress-induced activation of the LHb may not only lead to changes in dopaminergic signaling but also to alter- ations in the activity of serotonergic neurons located in the dorsal and medial raphe nuclei [161–163]. Under general anesthesia, the amount of habenular activity rises [164–166] which suggests that habenular activity can be modulated during the transition from sleep/low arousal states to awake/high arousal states. In line with this, ﬂuctuations in the spontaneous activity of the Hb are regulated by circadian rhythms [86,167]. Precise mechanisms, which can underlie the role of the Hb during sleep, remain to be elucidated, but proposed roles point towards the control of serotonergic and possibly also dopaminergic neurons [168–170]. Taken together, the spontaneous activity in the Hb, both in LHb and MHb, appears to be altered in many different condi- tions ranging from substance abuse to stress, sleep, reward-based decision-making or even social behaviors. The baseline activity, which can be characterized as the ongoing activity in the Hb with- out any external stimulus, can therefore represent an internal state of the animal. Depending on the sensory inputs or internal informa- tion from other brain areas that are directly or indirectly projecting to the Hb, this activity can be modulated to eventually trigger behaviors that are better adapted to a given situation. 3.2. Interactions of spontaneous and sensory driven activity in the habenula While all phenomena described above have a strong relation to changing levels of spontaneous habenular activity, it is less clear how sensory responses in the Hb and spontaneous habenular activ- ity interact with each other. One possibility is that spontaneous activity alters sensory responses in the Hb and changes the way the Hb transmits sensory information to its monoaminergic tar- gets. Alternatively, sensory responses in the Hb could also interfere with the spontaneous activity and therefore modulate the phenom- ena that are attributed to spontaneous habenular activity, such as cognitive function, depression, addiction, sleep or social behaviors. Since the Hb receives inputs from both sensory and non-sensory regions of the forebrain, midbrain and hindbrain [1,2,4–16], one potential role of spontaneous habenular activity could be to serve as a gate or a switchboard. In such a model, the responsiveness of Hb neurons to sensory stimulation could be modulated (or gated) by the non-sensory inputs of the Hb that are shaping its ongoing activity. We have previously shown that spontaneous activity in the zebraﬁsh dHb is not random, but rather spatially organized into dif- ferent functionally and genetically distinct clusters [96] (Fig. 2B). Neurotransmitter maps of the dHb were shown to have a spatial organization that is asymmetric across habenular hemispheres and this organization is preserved in the targets of the Hb [171] (Fig. 2C). Hence, it would be interesting to classify what functional Hb clus- ters identiﬁed based on their ongoing activity, overlap with the neurotransmitter expression patterns observed in the Hb. Additionally, we showed that the neurons belonging to a func- tional cluster during spontaneous habenular activity also respond similarly to sensory stimulation. Hence, in principle, modulating the spontaneous activity of a given Hb cluster could also alter the responsiveness of those Hb neurons to a given sensory modal- ity, by increasing or decreasing their resting membrane potential. This process would in turn control if or when the sensory infor- mation should be passed to monoaminergic Hb targets in the locus coeruleus (LC), the VTA and the Raphe. Therefore, it will be interesting to modulate spontaneous habenular activity via direct stimulation of Hb inputs across the brain, or to utilize those behavioral phenomena that could regulate spontaneous habenular activity such as stress or sleep, to test whether altering spontaneous habenular activity can modulate sensory representations within the Hb and in turn alter the animal’s behavioral response to sensory stimuli. It is possible that the functional clusters observed in ongoing habenular activity could represent stable states of the network, marking the groups of neurons that are more likely to act together to recall a given behavioral program. In line with this hypothe- sis, functional clusters of Hb neurons with synchronized ongoing activity were shown to overlap with genetically labeled groups of Hb neurons [96], which were shown to be involved in associative fear learning [49]. It is exciting to speculate that these stable func- tional clusters of Hb neurons that are synchronized (or co-active) at 136 S. Fore et al. / Seminars in Cell & Developmental Biology 78 (2018) 130–139 all times, represent favored states of the habenular circuits. These favored states of the habenular circuits resemble an attractor net- work, which is a network of recurrently connected neurons, whose dynamics settle to stable states. Such stable states are generally believed to be involved in decision making and provide the network with an increase in signal-to-noise ratio resulting in a better signal classiﬁcation and discretisation [172–174]. In the mammalian cor- tex, attractor networks are proposed to be involved in gating and gain control of sensory information [175]. Hence, these principles could also apply to sensory processing within the Hb. For example odorant-evoked responses with different amplitudes and distinct representations in the OB, were no longer observed in dHb neurons. [96]. Instead dHb neurons are broadly tuned to odors which sug- gests that discrimination between odorant classes might no longer be relevant for Hb computations. A robust response that encodes saliency or presence of a broad odor signal could be achieved by keeping the network in a preferred excitable state. It is also pos- sible that these stable states of the Hb networks can be entrained to increase the response likelihood of Hb neurons to a given sen- sory modality through an associative learning process. The Hb was indeed shown to be involved in such processes through reward prediction and error estimation. One way to test this hypothesis is to measure the changes in Hb spontaneous activity throughout the process of associative learning. Along with this hypothesis, the cognitive capacities involved in associative learning were shown to improve drastically within the ﬁrst weeks of development [176]. As the Hb plays a role in this associative learning process, it is likely that the spontaneous activity of Hb circuits might change, as the Hb input regions across the brain mature throughout development. It would therefore be exciting to study the processes that regulate sensory responses and spontaneous activity of Hb neurons across different stages of development and test if different types of inputs to the Hb, from sensory, limbic and cortical brain regions arrive with a developmental order and whether spontaneous habenular activity shapes the fate and the function of Hb neurons. One ﬁnal possibility is that the spontaneous habenular activ- ity constantly links the cortical or limbic inputs of the Hb to monoaminergic Hb targets. In this manner, the Hb receives infor- mation from these input regions about the animal’s internal states (such as fear, stress, attention, learned outcomes) and spontaneous activity is regulated accordingly. The habenula can then act as a hub and relay the information received from Hb input regions to the neuromodulatory nuclei that control behavior. In this scenario, the sensory inputs to the Hb might interfere with ongoing habe- nular activity by potentiating or disengaging the link between Hb inputs and Hb targets. This can then allow to activate or suppress a given behavioral program in the presence of a salient sensory stim- ulus. The vast literature on the Hb and its function covers several disciplines. While most studies in the human, primate and rodent Hb focus on reward prediction, addiction and stress, work on the Hb of many lower vertebrates focuses on the representations of different sensory modalities in the Hb as well as the asymmetric architecture and function of habenular circuits. There is a strong parallelism in molecular and functional architecture of the verte- brate Hb as well as in its role in regulating behavior in general. However, further research is needed in order to understand the interplay between sensory information from the external world and the internally generated spontaneous activity of the Hb and how these interactions relate to the roles of the Hb in controlling animal behavior. Acknowledgments We thank all members of the Yaksi lab especially to Florence Ker- men and Pradeep Lal for critical feedback. This work was funded by ERC Starting Grant (335561), Norwegian Research Council FRIPRO grant (239973), the Kavli Foundation, the Egil and Pauline Braathen and Fred Kavli Centre for Cortical Microcircuits, NTNU, the Centre of Excellence Scheme and the National Infrastructure Scheme of the Research Council of Norway (223262). E.Y. acknowledges support from the FENS-Kavli Network of Excellence. References [1] M.R. Warden, et al., A prefrontal cortex-brainstem neuronal projection that controls response to behavioural challenge, Nature 492 (7429) (2012) 428–432. [2] H. Okamoto, M. Agetsuma, H. Aizawa, Genetic dissection of the zebraﬁsh habenula: a possible switching board for selection of behavioral strategy to cope with fear and anxiety, Dev. Neurobiol. 72 (3) (2012) 386–394. [3] M. Matsumoto, O. Hikosaka, Lateral habenula as a source of negative reward signals in dopamine neurons, Nature 447 (7148) (2007) 1111–1115. [4] I.H. Bianco, S.W. Wilson, The habenular nuclei: a conserved asymmetric relay station in the vertebrate brain, Philos. Trans. R. Soc. Lond. B Biol. Sci. 364 (1519) (2009) 1005–1020. [5] F.J. Meye, et al., Shifted pallidal co-release of GABA and glutamate in habenula drives cocaine withdrawal and relapse, Nat. Neurosci. 19 (8) (2016) 1019–1024. [6] R. Amo, et al., The habenulo-raphe serotonergic circuit encodes an aversive expectation value essential for adaptive active avoidance of danger, Neuron 84 (5) (2014) 1034–1048. [7] J.H. Yoo, et al., Ventral tegmental area glutamate neurons co-release GABA and promote positive reinforcement, Nat. Commun. 7 (2016) 13697. [8] A.M. Stamatakis, et al., A unique population of ventral tegmental area neurons inhibits the lateral habenula to promote reward, Neuron 80 (4) (2013) 1039–1053. [9] D.H. Root, et al., Role of glutamatergic projections from ventral tegmental area to lateral habenula in aversive conditioning, J. Neurosci. 34 (42) (2014) 13906–13910. [10] D.H. Root, et al., Single rodent mesohabenular axons release glutamate and GABA, Nat. Neurosci. 17 (11) (2014) 1543–1551. [11] R. Bernard, R.W. Veh, Individual neurons in the rat lateral habenular complex project mostly to the dopaminergic ventral tegmental area or to the serotonergic raphe nuclei, J. Comp. Neurol. 520 (11) (2012) 2545–2558. [12] K. Brinschwitz, et al., Glutamatergic axons from the lateral habenula mainly terminate on GABAergic neurons of the ventral midbrain, Neuroscience 168 (2) (2010) 463–476. [13] L. Goncalves, C. Sego, M. Metzger, Differential projections from the lateral habenula to the rostromedial tegmental nucleus and ventral tegmental area in the rat, J. Comp. Neurol. 520 (6) (2012) 1278–1300. [14] M. Stephenson-Jones, et al., Evolutionary conservation of the habenular nuclei and their circuitry controlling the dopamine and 5-hydroxytryptophan (5-HT) systems, Proc. Natl. Acad. Sci. U. S. A. 109 (3) (2012) E164–73. [15] R.P. Vertes, W.J. Fortin, A.M. Crane, Projections of the median raphe nucleus in the rat, J. Comp. Neurol. 407 (4) (1999) 555–582. [16] C. Sego, et al., Lateral habenula and the rostromedial tegmental nucleus innervate neurochemically distinct subdivisions of the dorsal raphe nucleus in the rat, J. Comp. Neurol. 522 (7) (2014) 1454–1484. [17] R.J. Sutherland, The dorsal diencephalic conduction system: a review of the anatomy and functions of the habenular complex, Neurosci. Biobehav. Rev. 6 (1) (1982) 1–13. [18] T.G. Brown, Note on the physiology of the basal ganglia and mid-brain of the anthropoid ape: especially in reference to the act of laughter, J. Physiol. 49 (4) (1915) 195–207. [19] E.W. Thornton, G.E. Bradbury, Effort and stress inﬂuence the effect of lesion of the habenula complex in one-way active avoidance learning, Physiol. Behav. 45 (5) (1989) 929–935. [20] T. Yamaguchi, et al., Distinct roles of segregated transmission of the septo-habenular pathway in anxiety and fear, Neuron 78 (3) (2013) 537–544. [21] P.Y. Shih, et al., Differential expression and function of nicotinic acetylcholine receptors in subdivisions of medial habenula, J. Neurosci. 34 (29) (2014) 9789–9802. [22] P.Y. Shih, J.M. McIntosh, R.M. Drenan, Nicotine dependence reveals distinct responses from neurons and their resident nicotinic receptors in medial habenula, Mol. Pharmacol. 88 (6) (2015) 1035–1044. [23] S. Frahm, et al., Aversion to nicotine is regulated by the balanced activity of beta4 and alpha5 nicotinic receptor subunits in the medial habenula, Neuron 70 (3) (2011) 522–535. [24] H. Viswanath, et al., The medial habenula: still neglected, Front. Hum. Neurosci. 7 (2013) 931. [25] K. Sakhi, et al., Daily variation in the electrophysiological activity of mouse medial habenula neurones, J. Physiol. 592 (4) (2014) 587–603. [26] V.M. Namboodiri, J. Rodriguez-Romaguera, G.D. Stuber, The habenula, Curr. Biol. 26 (19) (2016) R873–R877. [27] E.S. Bromberg-Martin, et al., A pallidus-habenula-dopamine pathway signals inferred stimulus values, J. Neurophysiol. 104 (2) (2010) 1068–1076. S. Fore et al. / Seminars in Cell & Developmental Biology 78 (2018) 130–139 137 [28] T. Kawai, et al., Roles of the lateral habenula and anterior cingulate cortex in negative outcome monitoring and behavioral adjustment in nonhuman primates, Neuron 88 (4) (2015) 792–804. [29] M. Matsumoto, O. Hikosaka, Two types of dopamine neuron distinctly convey positive and negative motivational signals, Nature 459 (7248) (2009) 837–841. [30] S. Hong, et al., Negative reward signals from the lateral habenula to dopamine neurons are mediated by rostromedial tegmental nucleus in primates, J. Neurosci. 31 (32) (2011) 11457–11471. [31] J.J. Balcita-Pedicino, et al., The inhibitory inﬂuence of the lateral habenula on midbrain dopamine cells: ultrastructural evidence for indirect mediation via the rostromedial mesopontine tegmental nucleus, J. Comp. Neurol. 519 (6) (2011) 1143–1164. [32] C.M. Stopper, S.B. Floresco, What’s better for me? Fundamental role for lateral habenula in promoting subjective decision biases, Nat. Neurosci. 17 (1) (2014) 33–35. [33] A.M. Stamatakis, G.D. Stuber, Activation of lateral habenula inputs to the ventral midbrain promotes behavioral avoidance, Nat. Neurosci. 15 (8) (2012) 1105–1107. [34] E.J. Shank, et al., Selective ablation of GABA neurons in the ventral tegmental area increases spontaneous locomotor activity, Behav. Neurosci. 121 (6) (2007) 1224–1233. [35] K.R. Tan, et al., GABA neurons of the VTA drive conditioned place aversion, Neuron 73 (6) (2012) 1173–1183. [36] S. Lammel, et al., Input-speciﬁc control of reward and aversion in the ventral tegmental area, Nature 491 (7423) (2012) 212–217. [37] A. Friedman, et al., Electrical stimulation of the lateral habenula produces an inhibitory effect on sucrose self-administration, Neuropharmacology 60 (2–3) (2011) 381–387. [38] S.J. Shabel, et al., Mood regulation: GABA/glutamate co-release controls habenula output and is modiﬁed by antidepressant treatment, Science 345 (6203) (2014) 1494–1498. [39] J.Y. Cohen, et al., Neuron-type-speciﬁc signals for reward and punishment in the ventral tegmental area, Nature 482 (7383) (2012) 85–88. [40] J.S. Morris, et al., Covariation of activity in habenula and dorsal raphe nuclei following tryptophan depletion, Neuroimage 10 (2) (1999) 163–172. [41] C.D. Proulx, O. Hikosaka, R. Malinow, Reward processing by the lateral habenula in normal and depressive behaviors, Nat. Neurosci. 17 (9) (2014) 1146–1152. [42] O. Hikosaka, The habenula: from stress evasion to value-based decision-making, Nat. Rev. Neurosci. 11 (7) (2010) 503–513. [43] J.Y. Cohen, M.W. Amoroso, N. Uchida, Serotonergic neurons signal reward and punishment on multiple timescales, Elife 4 (2015). [44] P. Dayan, Q.J. Huys, Serotonin in affective control, Annu. Rev. Neurosci. 32 (2009) 95–126. [45] Y. Li, et al., Serotonin neurons in the dorsal raphe nucleus encode reward signals, Nat. Commun. 7 (2016) 10503. [46] E.S. Bromberg-Martin, O. Hikosaka, K. Nakamura, Coding of task reward value in the dorsal raphe nucleus, J. Neurosci. 30 (18) (2010) 6262–6272. [47] K. Hayashi, K. Nakao, K. Nakamura, Appetitive and aversive information coding in the primate dorsal raphe nucleus, J. Neurosci. 35 (15) (2015) 6195–6208. [48] M. Agetsuma, et al., The habenula is crucial for experience-dependent modiﬁcation of fear responses in zebraﬁsh, Nat. Neurosci. 13 (11) (2010) 1354–1356. [49] A. Lee, et al., The habenula prevents helpless behavior in larval zebraﬁsh, Curr. Biol. 20 (24) (2010) 2211–2216. [50] P. Dayan, Instrumental vigour in punishment and reward, Eur. J. Neurosci. 35 (7) (2012) 1152–1168. [51] A.M. Krypotos, et al., Avoidance learning: a review of theoretical models and recent developments, Front. Behav. Neurosci. 9 (2015) 189. [52] L.J. Boulos, E. Darcq, B.L. Kieffer, Translating the habenula-from rodents to humans, Biol. Psychiatry 81 (4) (2017) 296–305. [53] S. Lecca, F.J. Meye, M. Mameli, The lateral habenula in addiction and depression: an anatomical, synaptic and behavioral overview, Eur. J. Neurosci. 39 (7) (2014) 1170–1178. [54] S. Lecca, et al., Inhibitory inputs from rostromedial tegmental neurons regulate spontaneous activity of midbrain dopamine cells and their responses to drugs of abuse, Neuropsychopharmacology 37 (5) (2012) 1164–1176. [55] K.M. Velasquez, D.L. Molfese, R. Salas, The role of the habenula in drug addiction, Front. Hum. Neurosci. 8 (2014) 174. [56] M.A. Khaled, et al., Dopamine D3 receptors in the basolateral amygdala and the lateral habenula modulate cue-induced reinstatement of nicotine seeking, Neuropsychopharmacology 39 (13) (2014) 3049–3058. [57] S. Frahm, et al., An essential role of acetylcholine-glutamate synergy at habenular synapses in nicotine dependence, Elife 4 (2015), e11396. [58] P.R. Baldwin, R. Alanis, R. Salas, The role of the habenula in nicotine addiction, J. Addict. Res. Ther. S1 (2) (2011). [59] B. Antolin-Fontes, et al., The habenulo-interpeduncular pathway in nicotine aversion and withdrawal, Neuropharmacology 96 (Pt. B) (2015) 213–222. [60] R.M. Brown, J.L. Short, A.J. Lawrence, Identiﬁcation of brain nuclei implicated in cocaine-primed reinstatement of conditioned place preference: a behaviour dissociable from sensitization, PLoS One 5 (12) (2010) e15889. [61] P.A. Neumann, et al., Increased excitability of lateral habenula neurons in adolescent rats following cocaine self-administration, Int. J. Neuropsychopharmacol. 18 (6) (2014). [62] W. Zuo, et al., Ethanol drives aversive conditioning through dopamine 1 receptor and glutamate receptor-mediated activation of lateral habenula neurons, Addict. Biol. 22 (1) (2017) 103–116. [63] B.L. Eggan, S.E. McCallum, alpha3beta4 nicotinic receptors in the medial habenula and substance P transmission in the interpeduncular nucleus modulate nicotine sensitization, Behav. Brain Res. 316 (2017) 94–103. [64] S. Molas, et al., Anxiety and nicotine dependence: emerging role of the habenulo-interpeduncular axis, Trends Pharmacol. Sci. 38 (2) (2017) 169–180. [65] W. Zuo, et al., Nicotine regulates activity of lateral habenula neurons via presynaptic and postsynaptic mechanisms, Sci. Rep. 6 (2016) 32937. [66] X. Kedikian, M.P. Faillace, R. Bernabeu, Behavioral and molecular analysis of nicotine-conditioned place preference in zebraﬁsh, PLoS One 8 (7) (2013) e69453. [67] B. Le Foll, S.R. Goldberg, Nicotine induces conditioned place preferences over a large range of doses in rats, Psychopharmacology (Berl.) 178 (4) (2005) 481–492. [68] C.D. Fowler, et al., Habenular alpha5 nicotinic receptor subunit signalling controls nicotine intake, Nature 471 (7340) (2011) 597–601. [69] F.M. Leslie, C.Y. Mojica, D.D. Reynaga, Nicotinic receptors in addiction pathways, Mol. Pharmacol. 83 (4) (2013) 753–758. [70] E. Lax, et al., Neurodegeneration of lateral habenula efferent ﬁbers after intermittent cocaine administration: implications for deep brain stimulation, Neuropharmacology 75 (2013) 246–254. [71] L.R. Jacinto, et al., The habenula as a critical node in chronic stress-related anxiety, Exp. Neurol. 289 (2017) 46–54. [72] F.M. Schmidt, et al., Habenula volume increases with disease severity in unmedicated major depressive disorder as revealed by 7T MRI, Eur. Arch. Psychiatry Clin. Neurosci. 267 (2) (2017) 107–115. [73] K. Ranft, et al., Evidence for structural abnormalities of the human habenular complex in affective disorders but not in schizophrenia, Psychol. Med. 40 (4) (2010) 557–567. [74] D. Sourani, et al., The habenula couples the dopaminergic and the serotonergic systems: application to depression in Parkinson’s disease, Eur. J. Neurosci. 36 (6) (2012) 2822–2829. [75] R.P. Lawson, et al., Disrupted habenula function in major depression, Mol. Psychiatry 22 (2) (2017) 202–208. [76] A. Sartorius, et al., Remission of major depression under deep brain stimulation of the lateral habenula in a therapy-refractory patient, Biol. Psychiatry 67 (2) (2010) e9–e11. [77] J.L. Moreines, Z.L. Owrutsky, A.A. Grace, Involvement of infralimbic prefrontal cortex but not lateral habenula in dopamine attenuation after chronic mild stress, Neuropsychopharmacology 42 (4) (2017) 904–913. [78] S. Lecca, et al., Rescue of GABAB and GIRK function in the lateral habenula by protein phosphatase 2A inhibition ameliorates depression-like phenotypes in mice, Nat. Med. 22 (3) (2016) 254–261. [79] K. Li, et al., betaCaMKII in lateral habenula mediates core symptoms of depression, Science 341 (6149) (2013) 1016–1020. [80] W. Cui, et al., Glial dysfunction in the mouse habenula causes depressive-like behaviors and sleep disturbance, J. Neurosci. 34 (49) (2014) 16273–16285. [81] M.Y. Chou, et al., Social conﬂict resolution regulated by two dorsal habenular subregions in zebraﬁsh, Science 352 (6281) (2016) 87–90. [82] L.W. van Kerkhof, et al., Functional integrity of the habenula is necessary for social play behaviour in rats, Eur. J. Neurosci. 38 (10) (2013) 3465–3475. [83] M. Ahern, et al., Brain regional differences in social encounter-induced Fos expression in male and female rats after post-weaning social isolation, Brain Res. 1630 (2016) 120–133. [84] E. Dreosti, et al., Left-right asymmetry is required for the habenulae to respond to both visual and olfactory stimuli, Curr. Biol. 24 (4) (2014) 440–445. [85] S. Krishnan, et al., The right dorsal habenula limits attraction to an odor in zebraﬁsh, Curr. Biol. 24 (11) (2014) 1167–1175. [86] H. Zhao, B. Rusak, Circadian ﬁring-rate rhythms and light responses of rat habenular nucleus neurons in vivo and in vitro, Neuroscience 132 (2) (2005) 519–528. [87] P. Semm, C. Demaine, Electrophysiology of the pigeon’s habenular nuclei: evidence for pineal connections and input from the visual system, Brain Res. Bull. 12 (1) (1984) 115–121. [88] Y.W. Chung-Davidson, et al., Brain pathways and behavioral responses to weak electric ﬁelds in parasitic sea lampreys (Petromyzon marinus), Behav. Neurosci. 118 (3) (2004) 611–619. [89] D.et al. Derjean, A novel neural substrate for the transformation of olfactory inputs into motor output, PLoS Biol. 8 (12) (2010) e1000567. [90] W. Keil, F. von Stralendorff, R. Hudson, A behavioral bioassay for analysis of rabbit nipple-search pheromone, Physiol. Behav. 47 (3) (1990) 525–529. [91] A. Thesen, J.B. Steen, K.B. Doving, Behaviour of dogs during olfactory tracking, J. Exp. Biol. 180 (1993) 247–251. [92] S.J. Jesuthasan, A.S. Mathuru, The alarm response in zebraﬁsh: innate fear in a vertebrate genetic model, J. Neurogenet. 22 (3) (2008) 211–228. [93] T.A. Oliveira, et al., Death-associated odors induce stress in zebraﬁsh, Horm. Behav. 65 (4) (2014) 340–344. [94] A. Schmidt, G. Roth, Central olfactory and vomeronasal pathways in salamanders, J. Hirnforsch. 31 (5) (1990) 543–553. 138 S. Fore et al. / Seminars in Cell & Developmental Biology 78 (2018) 130–139 [95] N. Miyasaka, et al., Olfactory projectome in the zebraﬁsh forebrain revealed by genetic single-neuron labelling, Nat. Commun. 5 (2014) 3639. [96] S.K. Jetti, N. Vendrell-Llopis, E. Yaksi, Spontaneous activity governs olfactory representations in spatially organized habenular microcircuits, Curr. Biol. 24 (4) (2014) 434–439. [97] G. Laurent, et al., Odor encoding as an active, dynamical process: experiments, computation, and theory, Annu. Rev. Neurosci. 24 (2001) 263–297. [98] E. Yaksi, R.W. Friedrich, Reconstruction of ﬁring rate changes across neuronal populations by temporally deconvolved Ca2+ imaging, Nat. Methods 3 (5) (2006) 377–383. [99] E. Yaksi, et al., Transformation of odor representations in target areas of the olfactory bulb, Nat. Neurosci. 12 (4) (2009) 474–482. [100] F. Kermen, et al., Neural circuits mediating olfactory-driven behavior in ﬁsh, Front. Neural Circuits 7 (2013) 62. [101] C. Bertolucci, A. Foa, Extraocular photoreception and circadian entrainment in nonmammalian vertebrates, Chronobiol. Int. 21 (4–5) (2004) 501–519. [102] G. Tosini, C. Bertolucci, A. Foa, The circadian system of reptiles: a multioscillatory and multiphotoreceptive system, Physiol. Behav. 72 (4) (2001) 461–471. [103] H. Underwood, The pineal and melatonin: regulators of circadian function in lower vertebrates, Experientia 46 (1) (1990) 120–128. [104] H. Underwood, G. Groos, Vertebrate circadian rhythms: retinal and extraretinal photoreception, Experientia 38 (9) (1982) 1013–1021. [105] M.L. Concha, S.W. Wilson, Asymmetry in the epithalamus of vertebrates, J. Anat. 199 (Pt. 1–2) (2001) 63–84. [106] H.W. Korf, N.H. Zimmerman, A. Oksche, Intrinsic neurons and neural connections of the pineal organ of the house sparrow: passer domesticus, as revealed by anterograde and retrograde transport of horseradish peroxidase, Cell Tissue Res. 222 (2) (1982) 243–260. [107] O.K. Ronnekleiv, M.J. Kelly, W. Wuttke, Single unit recordings in the rat pineal gland: evidence for habenulo-pineal neural connections, Exp. Brain Res. 39 (2) (1980) 187–192. [108] P. Semm, C. Demaine, L. Vollrath, Electrical responses of pineal cells to melatonin and putative transmitters: evidence for circadian changes in sensitivity, Exp. Brain Res. 43 (3–4) (1981) 361–370. [109] J. Yanez, M.A. Pombal, R. Anadon, Afferent and efferent connections of the parapineal organ in lampreys: a tract tracing and immunocytochemical study, J. Comp. Neurol. 403 (2) (1999) 171–189. [110] C. Rudeberg, Structure of the parapineal organ of the adult rainbow trout: Salmo gairdneri Richardson, Z. Zellforsch. Mikrosk. Anat. 93 (2) (1969) 282–304. [111] C. Rudeberg, Light and electron microscopic studies on the pineal organ of the dogﬁsh: Scyliorhinus canicula L, Z. Zellforsch. Mikrosk. Anat. 96 (4) (1969) 548–581. [112] T. van Veen, et al., The pineal complex of the three-spined stickleback, Gasterosteus aculeatus L.: a light-, electron microscopic and ﬂuorescence histochemical investigation, Cell Tissue Res. 209 (1) (1980) 11–28. [113] M.L. Concha, et al., A nodal signaling pathway regulates the laterality of neuroanatomical asymmetries in the zebraﬁsh forebrain, Neuron 28 (2) (2000) 399–409. [114] M. Roussigne, et al., Nodal signalling imposes left-right asymmetry upon neurogenesis in the habenular nuclei, Development 136 (9) (2009) 1549–1557. [115] J. Levy, The mammalian brain and the adaptive advantage of cerebral asymmetry, Ann. N. Y. Acad. Sci. 299 (1977) 264–272. [116] B.B. Zhang, et al., Left habenula mediates light-preference behavior in zebraﬁsh via an asymmetrical visual pathway, Neuron 93 (4) (2017) 914–928, e4. [117] S.J.J. Qian Lin, Masking of a Circadian Behavior in Larval Zebraﬁsh Involves the Thalamo-Habenula Pathway, bioRxiv, 2017. [118] R.K. Cheng, et al., The thalamus drives light-evoked activity in the habenula of larval zebraﬁsh, bioRxiv (2016). [119] S. Herbute, J.D. Bayle, Pineal multiunit activity in conscious quail: effects of light, blinding, ganglionectomy, Am. J. Physiol. 231 (1) (1976) 136–140. [120] T. Qu, et al., Demonstration of direct input from the retina to the lateral habenular nucleus in the albino rat, Brain Res. 709 (2) (1996) 251–258. [121] S. Reuss, K. Decker, Anterograde tracing of retinohypothalamic afferents with Fluoro-Gold, Brain Res. 745 (1–2) (1997) 197–204. [122] A.A. Faisal, L.P. Selen, D.M. Wolpert, Noise in the nervous system, Nat. Rev. Neurosci. 9 (4) (2008) 292–303. [123] D. Tomasi, G.J. Wang, N.D. Volkow, Energetic cost of brain functional connectivity, Proc. Natl. Acad. Sci. U. S. A. 110 (33) (2013) 13642–13647. [124] E. Marder, D. Bucher, Central pattern generators and the control of rhythmic movements, Curr. Biol. 11 (23) (2001) R986–96. [125] M. Goulding, Circuits controlling vertebrate locomotion: moving in a new direction, Nat. Rev. Neurosci. 10 (7) (2009) 507–518. [126] A. Luczak, P. Bartho, K.D. Harris, Spontaneous events outline the realm of possible sensory responses in neocortical populations, Neuron 62 (3) (2009) 413–425. [127] T. Kenet, et al., Spontaneously emerging cortical representations of visual attributes, Nature 425 (6961) (2003) 954–956. [128] A. Arieli, et al., Dynamics of ongoing activity: explanation of the large variability in evoked cortical responses, Science 273 (5283) (1996) 1868–1871. [129] V. Moreno-Juan, et al., Prenatal thalamic waves regulate cortical area size prior to sensory processing, Nat. Commun. 8 (2017) 14172. [130] M.P. Karlsson, L.M. Frank, Awake replay of remote experiences in the hippocampus, Nat. Neurosci. 12 (7) (2009) 913–918. [131] D.A. Butts, P.O. Kanold, C.J. Shatz, A burst-based Hebbian learning rule at retinogeniculate synapses links retinal waves to activity-dependent reﬁnement, PLoS Biol. 5 (3) (2007) e61. [132] A.H. Leighton, C. Lohmann, The wiring of developing sensory circuits-from patterned spontaneous activity to synaptic plasticity mechanisms, Front. Neural Circuits 10 (2016) 71. [133] E. Kutsarova, M. Munz, E.S. Ruthazer, Rules for shaping neural connections in the developing brain, Front. Neural Circuits 10 (2016) 111. [134] D.A. Wilson, Single-unit activity in piriform cortex during slow-wave state is shaped by recent odor experience, J. Neurosci. 30 (5) (2010) 1760–1765. [135] L. Deuker, et al., Memory consolidation by replay of stimulus-speciﬁc neural activity, J. Neurosci. 33 (49) (2013) 19373–19383. [136] T. Abel, et al., Sleep: plasticity and memory from molecules to whole-brain networks, Curr. Biol. 23 (17) (2013) R774–88. [137] T.J. Davidson, F. Kloosterman, M.A. Wilson, Hippocampal replay of extended experience, Neuron 63 (4) (2009) 497–507. [138] G. Wang, et al., Synaptic plasticity in sleep: learning, homeostasis and disease, Trends Neurosci. 34 (9) (2011) 452–463. [139] J.F. Poulet, C.C. Petersen, Internal brain state regulates membrane potential synchrony in barrel cortex of behaving mice, Nature 454 (7206) (2008) 881–885. [140] K.D. Harris, A. Thiele, Cortical state and attention, Nat. Rev. Neurosci. 12 (9) (2011) 509–523. [141] A. Destexhe, Self-sustained asynchronous irregular states and up-down states in thalamic: cortical and thalamocortical networks of nonlinear integrate-and-ﬁre neurons, J. Comput. Neurosci. 27 (3) (2009) 493–506. [142] A. Destexhe, D. Contreras, Neuronal computations with stochastic network states, Science 314 (5796) (2006) 85–90. [143] M.V. Sanchez-Vives, D.A. McCormick, Cellular and network mechanisms of rhythmic recurrent activity in neocortex, Nat. Neurosci. 3 (10) (2000) 1027–1034. [144] A. Luczak, P. Bartho, K.D. Harris, Gating of sensory input by spontaneous cortical activity, J. Neurosci. 33 (4) (2013) 1684–1695. [145] R.L. Buckner, J.R. Andrews-Hanna, D.L. Schacter, The brain’s default network: anatomy, function, and relevance to disease, Ann. N. Y. Acad. Sci. 1124 (2008) 1–38. [146] M.D. Greicius, et al., Functional connectivity in the resting brain: a network analysis of the default mode hypothesis, Proc. Natl. Acad. Sci. U. S. A. 100 (1) (2003) 253–258. [147] P. Fransson, Spontaneous low-frequency BOLD signal ﬂuctuations: an fMRI investigation of the resting-state default mode of brain function hypothesis, Hum. Brain Mapp. 26 (1) (2005) 15–29. [148] M.D. Fox, et al., The human brain is intrinsically organized into dynamic: anticorrelated functional networks, Proc. Natl. Acad. Sci. U. S. A. 102 (27) (2005) 9673–9678. [149] Y. Golland, et al., Extrinsic and intrinsic systems in the posterior cortex of the human brain revealed during natural sensory stimulation, Cereb. Cortex 17 (4) (2007) 766–777. [150] L. Tian, et al., The relationship within and between the extrinsic and intrinsic systems indicated by resting state correlational patterns of sensory cortices, Neuroimage 36 (3) (2007) 684–690. [151] B. Mazoyer, et al., Cortical networks for working memory and executive functions sustain the conscious resting state in man, Brain Res. Bull. 54 (3) (2001) 287–298. [152] S.J. Gilbert, et al., Comment on Wandering minds: the default network and stimulus-independent thought, Science 317 (5834) (2007) 43, author reply 43. [153] M.L. Tantirigama, H.H. Huang, J.M. Bekkers, Spontaneous activity in the piriform cortex extends the dynamic range of cortical odor coding, Proc. Natl. Acad. Sci. U. S. A. 114 (9) (2017) 2407–2412. [154] T.C. Jhou, et al., Cocaine drives aversive conditioning via delayed activation of dopamine-responsive habenular and midbrain pathways, J. Neurosci. 33 (17) (2013) 7501–7512. [155] A. Gorlich, et al., Reexposure to nicotine during withdrawal increases the pacemaking activity of cholinergic habenular neurons, Proc. Natl. Acad. Sci. U. S. A. 110 (42) (2013) 17077–17082. [156] D.Q. Dao, et al., Nicotine enhances excitability of medial habenular neurons via facilitation of neurokinin signaling, J. Neurosci. 34 (12) (2014) 4273–4284. [157] N.M. Neugebauer, et al., Morphine dependence and withdrawal induced changes in cholinergic signaling, Pharmacol. Biochem. Behav. 109 (2013) 77–83. [158] K.P. Mohanakumar, P.P. Sood, Acetylcholinesterase changes in the central nervous system of mice during the development of morphine tolerance addiction and withdrawal, Brain Res. Bull. 10 (5) (1983) 589–596. [159] R.J. Katz, K.A. Roth, B.J. Carroll, Acute and chronic stress effects on open ﬁeld activity in the rat: implications for a model of depression, Neurosci. Biobehav. Rev. 5 (2) (1981) 247–251. [160] J. Shumake, F. Gonzalez-Lima, Brain systems underlying susceptibility to helplessness and depression, Behav. Cogn. Neurosci. Rev. 2 (3) (2003) 198–221. S. Fore et al. / Seminars in Cell & Developmental Biology 78 (2018) 130–139 139 [161] T. Nishikawa, B. Scatton, Inhibitory inﬂuence of GABA on central serotonergic transmission. Involvement of the habenulo-raphe pathways in the GABAergic inhibition of ascending cerebral serotonergic neurons, Brain Res. 331 (1) (1985) 81–90. [162] P. Kalen, et al., Regulation of striatal serotonin release by the lateral habenula-dorsal raphe pathway in the rat as demonstrated by in vivo microdialysis: role of excitatory amino acids and GABA, Brain Res. 492 (1–2) (1989) 187–202. [163] K. Nakamura, M. Matsumoto, O. Hikosaka, Reward-dependent modulation of neuronal activity in the primate dorsal raphe nucleus, J. Neurosci. 28 (20) (2008) 5331–5343. [164] M. Herkenham, Anesthetics and the habenulo-interpeduncular system: selective sparing of metabolic activity, Brain Res. 210 (1–2) (1981) 461–466. [165] P.S. van Nieuwenhuijzen, I.S. McGregor, G.E. Hunt, The distribution of gamma-hydroxybutyrate-induced Fos expression in rat brain: comparison with baclofen, Neuroscience 158 (2) (2009) 441–455. [166] R. Abulaﬁa, V. Zalkind, M. Devor, Cerebral activity during the anesthesia-like state induced by mesopontine microinjection of pentobarbital, J. Neurosci. 29 (21) (2009) 7053–7064. [167] C. Guilding, H.D. Piggins, Challenging the omnipotence of the suprachiasmatic timekeeper: are circadian oscillators present throughout the mammalian brain? Eur. J. Neurosci. 25 (11) (2007) 3195–3216. [168] S. Pavel, C. Eisner, A GABAergic habenulo-raphe pathway mediates both serotoninergic and hypnogenic effects of vasotocin in cats, Brain Res. Bull. 13 (5) (1984) 623–627. [169] R. Vetrivelan, et al., Medullary circuitry regulating rapid eye movement sleep and motor atonia, J. Neurosci. 29 (29) (2009) 9361–9369. [170] G. Holstege, The mesopontine rostromedial tegmental nucleus and the emotional motor system: role in basic survival behavior, J. Comp. Neurol. 513 (6) (2009) 559–565. [171] T.N. deCarvalho, et al., Neurotransmitter map of the asymmetric dorsal habenular nuclei of zebraﬁsh, Genesis 52 (6) (2014) 636–655. [172] X.J. Wang, Decision making in recurrent neuronal circuits, Neuron 60 (2) (2008) 215–234. [173] C.K. Machens, R. Romo, C.D. Brody, Flexible control of mutual inhibition: a neural model of two-interval discrimination, Science 307 (5712) (2005) 1121–1124. [174] R. Fdez Galan, et al., Odor-driven attractor dynamics in the antennal lobe allow for simple and rapid olfactory pattern classiﬁcation, Neural Comput. 16 (5) (2004) 999–1012. [175] R. Cossart, D. Aronov, R. Yuste, Attractor dynamics of network UP states in the neocortex, Nature 423 (6937) (2003) 283–288. [176] A. Valente, et al., Ontogeny of classical and operant learning behaviors in zebraﬁsh, Learn. Mem. 19 (4) (2012) 170–177."
Functional properties of habenular neurons are determined by developmental stage and sequential neurogenesis,Stephanie Fore  and Francisca Acuña-Hinrichsen  and Kadir Aytac Mutlu  and Ewelina Magdalena Bartoszek  and Bram Serneels  and Nicholas Guy Faturos  and Khac Thanh Phong Chau  and Mehmet Ilyas Cosacak  and Carmen Diaz Verdugo  and Fabrizio Palumbo  and Christa Ringers  and Nathalie Jurisch-Yaksi  and Caghan Kizil  and Emre Yaksi ,2020,36.0,6,Science Advances,article,"Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
1 of 17
D E V E LOPM ENTAL NE U ROS C IE NC E
Functional properties of habenular neurons are 
determined by developmental stage and  
sequential neurogenesis
Stephanie Fore1, Francisca Acuña-Hinrichsen1, Kadir Aytac Mutlu1, Ewelina Magdalena Bartoszek1, 
Bram Serneels1, Nicholas Guy Faturos1, Khac Thanh Phong Chau1, Mehmet Ilyas Cosacak2, 
Carmen Diaz Verdugo1, Fabrizio Palumbo1, Christa Ringers1, Nathalie Jurisch-Yaksi1,3,4, 
Caghan Kizil2,5, Emre Yaksi1*
The developing brain undergoes drastic alterations. Here, we investigated developmental changes in the 
habenula, a brain region that mediates behavioral flexibility during learning, social interactions, and aversive 
experiences. We showed that developing habenular circuits exhibit multiple alterations that lead to an increase in 
the structural and functional diversity of cell types, inputs, and functional modules. As the habenula develops, it 
sequentially transforms into a multisensory brain region that can process visual, olfactory, mechanosensory, and 
aversive stimuli. Moreover, we observed that the habenular neurons display spatiotemporally structured sponta-
neous activity that shows prominent alterations and refinement with age. These alterations in habenular activity 
are accompanied by sequential neurogenesis and the integration of distinct neural clusters across development. 
Last, we revealed that habenular neurons with distinct functional properties are born sequentially at distinct 
developmental time windows. Our results highlight a strong link between the functional properties of habenular 
neurons and their precise birthdate.
INTRODUCTION
During development and maturation, the functional capacity of 
brain circuits increases to support the animals’ expanding behavioral 
repertoire. For example, while a young zebrafish larva mostly needs 
to avoid threats and find food, more cognitively demanding behav-
iors such as associative learning (1, 2) or social interactions (3) 
emerge later in development during the juvenile stage around 3 to 
4 weeks. Such an expansion of the behavioral repertoire is a feature 
that is conserved across vertebrates (4) and is often accompanied 
with the development, establishment, and maturation of distinct 
circuit components generating functional modules within the brain 
(5). Hence, brain development and maturation is not only a linear 
expansion of the already existing building blocks but also a sequential 
increase in the diversity of functional modules and cell types. In the 
cortex, for example, individual layers are born at different time 
points, with deep layers being born earlier than superficial layers 
(6), creating a diversity in the cytoarchitecture of cortical layers and 
regions with distinct functions (5, 7). Similarly, this chronological 
order of neurogenesis in larval zebrafish hindbrain and spinal cord was 
shown to generate functional diversity of neurons, which underlies 
increased sophistication of behaviors across development (8–10).
The maturation and refinement of the developing brain rely on 
neural activity that can be evoked by sensory inputs (11, 12) or 
spontaneously generated (11, 13). In most sensory systems, sensory-­
evoked activity was shown to be critical for the maturation of neural 
circuits and the refinement of topographical maps (12, 14). The 
appearance of spontaneous activity of the developing brain starts 
early and coincides with periods of intense synaptogenesis and neu-
ronal growth (15). For example, spontaneous activity bursts were 
observed in the visual, auditory, and somatosensory systems and 
are shown to be important for the remodeling of these structures 
(13, 14). In higher brain regions, such as the hippocampus, large 
and slow bursts are observed (16) before the appearance of faster 
rhythms and the patterned activity of the adult hippocampus asso-
ciated with learning and memory. Furthermore, spontaneous activ-
ity is also involved in the maturation of connections across distant 
brain regions, as observed between the olfactory bulb and the ento-
rhinal cortex (17). Last, the synchronous bursting during sponta-
neous activity that is important in establishing neural connectivity 
was shown to be mediated via excitatory connections (18), gap 
junctions (19), glial cells (20), or other support cells (21). Together, 
both sensory-driven and spontaneous neural activity are essential in 
the development and maturation of neural circuits. It is, however, 
less clear how sensory-evoked and spontaneous neural activity 
interact as the animals develop.
While the majority of studies have focused on the development 
of sensory and motor systems, less is known about the maturation 
of higher brain areas integrating information from multiple brain 
regions, such as the habenula. The habenula is a particularly inter-
esting brain region, as it was shown to integrate both sensory 
(22, 23) and corticolimbic inputs (24–26) while directly regulating 
the function of monoaminergic brain nuclei controlling behavior 
(23, 25, 27). Dysfunction of the habenula is also shown to be associated 
with several neurological conditions and mood disorders including 
depression (28). The habenula is composed of several subdomains 
or modules based on its neurochemical profiles (29, 30), anatomical 
projections (31–33), and the activity of habenular neurons (33–35). 
1Kavli Institute for Systems Neuroscience and Centre for Neural Computation, 
Faculty of Medicine and Health Sciences, Norwegian University of Science and 
Technology, Olav Kyrres gata 9, 7030 Trondheim, Norway. 2German Center for 
Neurodegenerative Diseases (DZNE) Dresden, Helmholtz Association, Tatzberg 41, 
01307 Dresden, Germany. 3Department of Clinical and Molecular Medicine, Norwegian 
University of Science and Technology, Olav Kyrres Gate 9, 7030 Trondheim, Norway. 
4Department of Neurology and Clinical Neurophysiology, St Olav University Hospital, 
Edvard Griegs Gate 8, 7030 Trondheim, Norway. 5Center for Molecular and Cellular 
Bioengineering (CMCB), TU Dresden, Fetscherstr. 105, 01307 Dresden, Germany.
*Corresponding author. Email: emre.yaksi@ntnu.no
Copyright © 2020 
The Authors, some 
rights reserved; 
exclusive licensee 
American Association 
for the Advancement 
of Science. No claim to 
original U.S. Government 
Works. Distributed 
under a Creative 
Commons Attribution 
NonCommercial 
License 4.0 (CC BY-NC).
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
2 of 17
Two major subnuclei, the lateral and medial habenula in mammals, 
respectively, and the dorsal habenula (dHb) and ventral habenula (vHb) in 
zebrafish, have clear differences in their functional and molecular 
profiles (33). While the dHb is involved in sensory processing (23, 34, 35), 
aggression (36), and experience-dependent fear response (27, 31), the 
vHb was shown to play a role in avoidance learning (33) and active 
coping behavior (37). In zebrafish, dHb and vHb originate from separate 
neural progenitor pools and were suggested to maturate at distinct 
developmental time points (32). Moreover, the dHb was shown to 
undergo asymmetric neurogenesis during the early stages of devel-
opment, with left dHb neurons being born earlier than the ones in the 
right hemisphere (38). The prominent asymmetry in the molecular 
(29) and anatomical properties of habenula (39) is also reflected in 
its asymmetric encoding of visual and olfactory information in the 
left and the right dHb hemispheres, respectively (34, 35). Recent 
transcriptome analysis further revealed multiple molecularly distinct 
and spatially organized functional modules within the zebrafish (30) 
and mammalian (40) habenula, which resemble the spatially organized 
functional clusters of habenular neurons during spontaneous activity 
(35). All of these evidences suggest a fine spatial organization of distinct 
functional modules within habenula (35). In addition, spontaneous 
habenular activity was shown to govern sensory responses and, 
therefore, proposed to represent internal states of the network, 
which could mediate the selection of appropriate behaviors (35). A 
recent study revealed a sequential recruitment of neurons generating 
an increase in vHb activity, during the switch from active to passive 
coping behaviors in juvenile zebrafish (37). Such complex behaviors 
emerge at later stages of zebrafish development (1, 3), suggesting 
pronounced changes in the underlying circuitry across the brain. 
Despite extensive characterization of habenular circuitry during 
very early developmental stages (29, 38, 39), it is still unclear how 
the maturation of habenular networks during development corre-
sponds to the establishment of its distinct functional modules.
In this study, we investigated how the function and the architecture 
of habenular networks change across development and how these 
alterations relate to the formation of distinct functional modules 
within habenula. We showed that as the habenula expands, the number 
of neurons increases, inhibitory connections are formed, and sensory 
inputs are integrated with a temporal order. Moreover, we revealed 
that the habenula is a multisensory brain region, which distinctly 
encodes different sensory modalities. Visual and olfactory responses in 
habenula develop early, while the responses to mechanosensory and 
aversive stimuli develop at later stages. Spontaneous habenular activity 
is present already at early developmental stages, and it is predictive of the 
habenular neurons with sensory responses. We observed a prominent 
restructuring of both spatial and temporal features of spontaneous 
habenular activity during development. These functional changes 
in the habenula were accompanied by a sequential and spatially 
organized addition of newly born neurons across development. Last, 
we showed that habenular neurons born at a distinct developmental 
stage exhibit similar functional properties. Our observations support 
the idea that neuronal birthdate and function are strongly related.
RESULTS
New neurons and new inhibitory connections are added 
to habenula during development
To study the functional development of zebrafish habenula, we 
focused on three developmental stages: early larval stage [3 days 
post-fertilization (dpf)], late larval stage (6 dpf), and juvenile stage 
(21 dpf). During these periods, zebrafish transition from self-feeding 
larvae (via the yolk sac) to an external feeding juvenile animal with 
more complex behaviors including those involving habenular circuits 
(1, 3, 31, 33, 37). First, we visualized the gross morphology of habenula 
in Tg(elavl3:GCaMP6s) (41) zebrafish, labeling most habenular 
neurons. We observed that the number of habenular neurons increases 
drastically from 3 to 21 days of zebrafish development (Fig. 1, A and B). 
Next, we investigated the expression of glutamate and -aminobutyric 
acid (GABA) by using Tg(vglut2a:dsRed) (22) and Tg(gad1b:GFP) 
(42) zebrafish. We found that at 3 dpf, habenula mainly consists of 
glutamatergic neurons, and as the animal gets older, few GABAergic 
neurons are added (Fig. 1C). From 6 dpf, we also observed prominent 
bilateral GABAergic projections that innervate specific domains at 
the lateral sides of habenula (Fig. 1C). These results suggest that 
habenula undergoes a nonlinear expansion with the addition of new 
cell types and inputs arriving at different time points throughout 
development.
Sensory inputs and computations in habenula follow 
a developmental order
Previous studies showed that habenula receives olfactory (22) and 
visual (23) inputs and responds to both of these sensory modalities 
(34, 35, 43). To investigate how these sensory inputs maturate 
during habenula development, we visualized the mitral cell and 
thalamic axon terminals in habenula using Tg(lhx2a:gap-YFP) (22) and 
Et(−0.6hsp70l:Gal4-VP16) s1020t; Tg(UAS:nfsB-mCherry) (31, 44) 
zebrafish lines, respectively. At all ages, thalamic projections were 
found to innervate habenula (Fig. 2A, blue) in distinct locations that 
are different from GABAergic innervations (Fig. 2A, white) or 
mitral cell terminals (Fig. 2A, red). Yet, the density of olfactory bulb 
projections increased with age (Fig. 2A, red). These findings suggest 
that habenular neurons may be predominantly light responsive at 
younger ages, while odor responses develop later. To test this 
hypothesis, we measured odor (food odor) and light (red light flash) 
responses in the habenula by using two-photon calcium imaging 
in Tg(elavl3:GCaMP6s) (41) zebrafish. At 3 dpf, we found that a 
significantly higher portion of habenular neurons responds to the 
visual stimulus compared to food odor (Fig. 2, B and C). As zebrafish 
develop, the ratio of odor- and light-responding neurons became 
similar (Fig. 2, B and C). At all developmental stages, correlations 
between visual and olfactory stimuli were relatively low (Fig. 2D).
To further test whether the development of sensory responses in 
habenula is biased toward aversive or attractive stimuli within one 
sensory modality, we applied amino acid odor, food odor, skin 
extract, and ammonia, which were previously shown to elicit responses 
in the zebrafish habenula (35). Moreover, earlier studies revealed 
that amino acid odor (45) and food odor (46) elicit attraction, and 
skin extract (47) and ammonia (46) elicit freezing and defensive 
behaviors. While we did not observe any preference for habenular 
neurons to respond to aversive or attractive odors in 3-dpf zebrafish 
larvae, we observed that stimulation with aversive odors resulted in 
a higher number of responding neurons compared to attractive 
odors, in four out of four 21-dpf zebrafish (fig. S1, A and B). The 
correlations between aversive versus attractive odors were low in 
3 dpf and increased at 21 dpf (fig. S1, C and D).
Previous studies showed that the zebrafish habenula can encode 
a diverse range of aversive experiences (27, 30, 37). To test the 
developmental order of zebrafish habenula for encoding aversive 
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
3 of 17
Fig. 1. During development, the number of habenular neurons increases and new GABAergic connections are added. (A) Representative examples of three-dimensional 
reconstructions of habenular neurons detected in Tg(elavl3:GCaMP6s) zebrafish line, using volumetric two-photon calcium imaging at three different developmental ages 
(3, 6, and 21 dpf). Coronal view. (B) The average number of neurons detected in Tg(elavl3:GCaMP6s) at 3 dpf (n = 9 fish), 6 dpf (n = 6 fish), and 21 dpf (n = 9 fish). **P < 0.01 
and ***P < 0.001, t test. Data are presented as means ± SEM. (C) Confocal microscopy projections of habenula in Tg(vglut2a:dsRed) and Tg(gad1b:GFP) double transgenic 
zebrafish at 3, 6, and 21 dpf, labeling glutamatergic (red) and GABAergic (white) neurons and projections, dorsal view. White arrowheads indicate GABAergic projections. 
Scale bar, 100 m. L, left hemisphere; R, right hemisphere.
Fig. 2. Visual responses dominate larval habenula, while olfactory responses develop later. (A) Confocal microscopy projections of habenula in Tg(Lhx2:gap-YFP); 
Et(0.6hsp70l:Gal4-VP16) s1020t; Tg(UAS:nfsB-mCherry) and Tg(gad1b:GFP) triple transgenic zebrafish labeling olfactory bulb projections (red), thalamic projections (blue), 
and GABAergic projections (white), dorsal view. Dashed white lines delineate habenula. Scale bar, 100 m. L, left hemisphere; R, right hemisphere. (B) Top panel shows 
average responses of odor-responding (red) and light-responding habenular neurons (blue) over four to five trials at 3 dpf (n = 9), 6 dpf (n = 7), and 21 dpf (n = 9) zebrafish. 
Black bars represent 10% F/F. Shadows represent SEM. Bottom panel shows color-coded sensory responses (F/F) of all individual Hb neurons exposed to 5-s odor 
(O; red) stimulus (left) and 2-s light (L; blue) stimulus (right) in all fish imaged at 3, 6, and 21 dpf. Black bars represent 1000 neurons. (C) Percentage of odor (red dots) 
versus light (blue dots) responding neurons at 3, 6, and 21 dpf. ***P < 0.001, paired t test. All data are presented as means ± SEM. (D) Odor (red) versus light (blue) response 
amplitude of all habenular neurons responses at 3, 6, and 21 dpf. Magenta color depicts the neurons responding to both odor and light. Gray dots represent nonresponsive 
neurons. Average ± SEM correlations between different stimulus representations by habenular responses are represented by “corr.” Note that at all ages, odor and light 
responses are dissimilar, depicted by the negative correlations.
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
4 of 17
stimuli, we applied mechanical vibrations (48) and mild electric 
stimulation (27, 30, 37), both of which were shown to generate aversive 
reactions in developing zebrafish (27, 30, 37, 48). We also compared 
these aversive stimuli to visual responses in the habenula evoked by 
red light. Consistent with our results above (Fig. 2), the zebrafish 
habenula predominantly responds to visual stimulation at 3 dpf 
(Fig. 3, A and B). As zebrafish develop, we observed that a signifi-
cantly larger number of habenular neurons responded to mild 
electric stimulation at 6 and 21 dpf (Fig. 3B). Moreover, we observed 
that significantly larger number of habenular neurons respond to 
light compared to mechanical vibrations at 6 dpf (Fig. 3B). At 21 dpf, 
we no longer observed any significant difference between the number 
of neurons responding to light, electric stimuli, and vibrations 
(Fig. 3B). These three different stimulus modalities exhibit low 
correlations at all developmental stages (Fig. 3C). All these results 
suggest that while the 3-dpf habenula preferentially responds to 
light, the animal develops significantly more habenular neurons 
respond to aversive electrical stimuli, as the animal develops. Together, 
the developing habenula can selectively encode an expanding number 
of sensory modalities with an increasing preference for aversive 
electrical stimuli at later stages.
Functional lateralization of visual and olfactory responses 
decreases across development, and it is not prominent 
for aversive stimuli
Earlier studies revealed a strong molecular (29, 32) and functional 
(34) lateralization of habenular networks, especially across the 
dHb hemispheres of larval zebrafish. There is no evidence for such 
lateralization in the rodent habenula, which is mostly studied in 
adults by using aversive stimuli (25, 26). This made us question 
whether the ontogeny of functional lateralization in the zebrafish 
habenula might resemble the phylogeny of the vertebrate habenula, 
where lateralized responses to light and odors appear first and non-
lateralized responses to aversive stimuli develop later. To test this 
hypothesis, we investigated the lateralization of sensory responses 
in habenular neurons across zebrafish development. First, we showed 
that the dorsal sections of habenula, which likely cover the dHb, 
exhibit lateralized visual and olfactory responses at all ages (Fig. 4, 
A and B). We quantified this functional lateralization by measuring 
the ratio of light- versus odor-responding habenular neurons across 
hemispheres (34) and by using a lateralization index, where 0 
represents symmetry and 1 represents complete segregation of light 
and odor responses across hemispheres. Across development, dHb 
exhibits high functional lateralization of light and odor responses, 
when compared to the ventral sections of habenula (Fig. 4B). Yet, 
we also observed that the functional lateralization of habenular 
circuits significantly decreases across development (Fig. 4, C and D). 
Despite this decrease, light and odor responses exhibit prominent 
spatial organization (Fig. 4E), quantified by the focality index, ranging 
from 0 (for random spatial distribution of sensory responses) to 1 
(for maximally focal sensory responses) (49). Instead, aversive stimuli 
elicited no such lateralization across habenular hemispheres (fig. S2), 
resembling the nonlateralized aversive cue representations in the 
rodent habenula (25, 26). These results indicate that functional 
lateralization is a feature of dHb (34) that develops earlier and 
preferentially responds to visual and olfactory stimuli. Instead, vHb, 
Fig. 3. Aversive electrical stimuli and mechanical vibrations are encoded in developing habenula. (A) Top panel shows average responses in habenular neurons to 
light (L; blue), mild electric stimulation (ES; brown), and mechanical vibrations (V; black) over four to five trials in 3 dpf (n = 11), 6 dpf (n = 9), and 21 dpf (n = 7) zebrafish. 
Black bars represent 10% F/F. Shadows represent SEM. Bottom panel shows color-coded sensory responses (F/F) of all individual Hb neurons exposed to 2-s light stimulus 
(left), 1-s mild electric stimulation (middle), and 0.05 s mechanical vibration (right) in all fish imaged at 3, 6, and 21 dpf. Black bars represent 1000 neurons. (B) Percentage 
of responding neurons to light (blue), mild electric stimulus (brown), and mechanical vibrations (black) at 3, 6, and 21 dpf. *P < 0.05 and **P < 0.01, paired t test for the 
comparisons within groups and unpaired t test for comparisons between groups. (C) Light (blue) versus mild electric stimulus (brown) versus mechanical vibrations 
(black) response amplitude of all habenular neuron responses at 3, 6, and 21 dpf. Magenta color depicts the neurons responding to more than one stimulus. Average ± SEM 
Pearson’s correlation coefficients between different stimulus representations by habenular responses are represented by “corr.” Note that at all ages, different stimulus 
modalities are distinctly represented, depicted by the negative correlations. All data are presented as means ± SEM.
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
5 of 17
which develops later during development, does not exhibit prominent 
functional lateralization.
Functional clusters of habenular neurons exhibit spatially 
organized spontaneous activity at all ages
In juvenile zebrafish, spatially organized functional clusters of 
habenular neurons display synchronous bursts of spontaneous 
activity, which is present even in the absence of sensory inputs (35). 
It is, however, less clear if such spontaneous activity is also present 
in younger zebrafish larvae and to what extent it changes across 
habenular development. To study this, we recorded ongoing 
habenular activity in the absence of external stimuli at different 
developmental stages. We observed that clusters of habenular neurons 
exhibit correlated spontaneous activity already at 3 dpf (Fig. 5A). 
Next, we investigated the stability of these functional clusters during 
different time windows, using k-means clustering (35). We showed 
Fig. 4. Sensory lateralization is prominent in dHb at all ages but decreases with age especially in vHb. (A) Three-dimensional reconstructions of habenular responses 
to light (blue) and odor (red) stimulation recorded by volumetric two-photon microscopy in Tg(elavl3:GCaMP6s) zebrafish, at 3, 6, and 21 dpf. White dots indicate 
nonresponding neurons. Coronal view. (B) The ratio of odor (red) versus light (blue) responding neurons in left versus right habenular hemispheres, as well as associated 
sensory lateralization index at 3 dpf (left), 6 dpf (middle), and 21 dpf (right) zebrafish. Each row represents the average values for neurons within the 10-m plane (from 
the top to bottom). Shades represent ±SEM; 3 dpf (n = 9 fish), 6 dpf (n = 7 fish), and 21 dpf (n = 9 fish). *P < 0.05, **P < 0.01, and ***P < 0.001, t test. (C) Average lateralization 
index of light responses for the entire habenula of all fish at 3, 6, and 21 dpf. *P < 0.05 and **P < 0.01, Wilcoxon rank sum test. (D) Average lateralization index of odor 
responses for the entire habenula of all fish at 3, 6, and 21 dpf. **P < 0.01, Wilcoxon rank sum test. (E) Focality index for odor-responding (red) and light-responding (blue) 
neurons compared to NR (nonresponding neurons, gray) at 3, 6, and 21 dpf. **P < 0.01 and ***P < 0.001, Wilcoxon signed-rank test. All data are presented as means ± SEM.
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
6 of 17
that at all developmental stages, a large portion of habenular neu-
rons that belong to a functional cluster remain in their respective 
cluster with a significantly higher probability compared to chance 
levels (Fig. 5B). To investigate the synchrony between the habenular 
neurons further, we next computed the ratio of significantly posi-
tive and negative correlated pairs of habenular neurons. We ob-
served that as the animal develops, more pairs of neurons displayed 
significant and robust positive correlations (Fig. 5C). We did not 
observe such a change for negative correlations between habenular 
neurons (Fig. 5D). Next, we investigated the spatial organization of 
Fig. 5. Spontaneous habenular activity is structured into spatially organized functional clusters of neurons that are preserved during sensory responses, at all 
ages. (A) Functional clusters of habenular neurons with synchronous spontaneous activity in two different time periods (period 1 and period 2). Three-dimensional 
reconstruction depicts the spatial locations of all neurons. Each color represents a neuronal cluster with similar spontaneous activity, defined by using k-means clustering. 
Color-coded neural traces on the right show the spontaneous activity of each neuron that belongs to a given cluster “C.” Warm color represents increased neural activity. 
Each row represents an example zebrafish at 3, 6, and 21 dpf. D, dorsal; V, ventral; A, anterior; P, posterior. (B) Cluster fidelity, depicting the ratio of neural pairs that remain 
within the same functional cluster during two different time periods for 3 dpf (n = 9), 6 dpf (n = 6), and 21 dpf (n = 9), compared to shuffled chance levels. *P < 0.05 and 
**P < 0.01, Wilcoxon signed-rank test. (C) The ratio of neural pairs with significant (P < 0.05) positive correlations during two periods of spontaneous activity. *P < 0.05 and 
**P < 0.01, Wilcoxon rank sum test. (D) The ratio of neural pairs with significant (P < 0.05) negative correlations during two periods of spontaneous activity. Wilcoxon rank 
sum test. (E) Relation between pairwise correlation of spontaneous neural activity and the distance between each neuron pair in habenula at 3, 6, and 21 dpf. Dashed lines 
represent the results when neuron locations are shuffled. ANOVA-n displayed significance over distances (P < 0.001) and over age groups (P < 0.001) indicated with #. 
(F) Color-coded functional clusters of habenular neurons with synchronous spontaneous activity for an example zebrafish at 3 (top) and 21 (bottom) dpf. On the middle 
and right panels, odor (red) and light (blue) responses of the same neurons are visualized. Scale bars, 50 m. (G) Cluster selectivity, depicting how odor-responding (red) 
or light-responding (blue) neurons are distributed into functional clusters based on their spontaneous activity. High selectivity means that both odor- and light-responding 
neurons belong to fewer clusters compared to the same number of randomly selected nonsensory neurons (gray dots), at 3 and 21 dpf. (H) The ratio of neural pairs with 
significant (P < 0.05) positive correlations of spontaneous activity, for odor- and light-responsive neurons, when compared to the same number of randomly selected 
nonsensory neurons, at 3 and 21 dpf. *P < 0.05, **P < 0.01, Wilcoxon signed-rank test. All data are presented as means ± SEM.
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
7 of 17
synchronous habenular activity by plotting the average pairwise 
correlation of neurons versus the distance between them. We ob-
served that while nearby habenular neurons have more correlated 
spontaneous activity at all developmental stages, they exhibit sig-
nificantly stronger correlations during older developmental stages 
(Fig. 5E). This increase in the ratio (Fig. 5C) and strength (Fig. 5E) 
of positive correlations is likely due to the maturation of synaptic 
connections between habenular neurons, as well as the arrival of 
synaptic inputs to habenula.
Next, we investigated whether habenular neurons with correlated 
spontaneous activity also respond to sensory stimulation similarly 
and how this changes across development. We observed that, 
especially at later developmental stages, odor- and light-responsive 
habenular neurons largely overlap with the distinct functional 
clusters with correlated spontaneous activity, compared to the same 
number of randomly selected nonsensory neurons (Fig. 5, F and G). 
This was also true when comparing sensory responding neurons to 
all nonresponding neurons (fig. S3). Only in older zebrafish did we 
observe that odor- or light-responding habenular neurons exhibit a 
significantly higher ratio of positive correlations during sponta-
neous activity, compared to the same number of randomly selected 
nonsensory habenular neurons (Fig. 5H). These results highlight 
the developmental maturation of habenular circuits while generat-
ing more structured spontaneous activity that better predicts the 
sensory response characteristics of habenular neurons.
Features of spontaneous habenular activity change  
during development
Our results revealed that already at early developmental stages, the 
habenula exhibits prominent spontaneous activity. In several brain 
regions, spontaneous activity during early development is generally 
characterized as large bursts with long quiescent intervals (16), 
whereas adult brains usually exhibit rhythmic activity at faster 
frequencies (16, 50). To test whether the temporal features of 
habenular activity are changing over development, we detected the 
spontaneous activity bursts (51) (Fig. 6A) and quantified the fre-
quency and duration of these events. We observed that as the animals 
develop, the frequency of spontaneous activity bursts significantly 
increases (Fig. 6B) and their duration decreases (Fig. 6C). Moreover, 
while the average activity of habenular neurons decreases (Fig. 6D), 
a larger proportion of habenular neurons shows spontaneous activity 
(Fig. 6E) at later developmental stages. These results are in line with 
the developmental changes observed in other vertebrate brain 
regions and highlight the maturation of habenular spontaneous 
activity across development.
Next, we asked whether such temporal features (i.e., burst duration 
and frequency) of spontaneous habenular activity are also spatially 
organized. We quantified the spatial distribution by using the measure 
of focality index, ranging from 0 (for random spatial distribution) 
to 1 (for an extremely focal point) (49). At all developmental stages, 
the temporal features of habenular spontaneous activity, burst 
frequency, and duration were highly focal and not randomly dis-
tributed (Fig. 6F, also note the mean focality values). To further 
investigate the spatial distribution of habenular activity at different 
developmental stages, we adopted a commonly used reporter of 
neural activity, phospho-ERK (extracellular signal–regulated kinase)/
total-ERK (pERK/tERK) ratio (52). We observed that during early 
developmental stages, pERK/tERK ratio is distributed rather uniformly 
across the habenula (Fig. 6, G and H, top), while at later developmental 
stages, pERK/tERK ratio was concentrated more laterally (Fig. 6, 
G and H, bottom), indicating a higher neural activity toward the 
lateral ends of habenula. We also observed that the most silent 
habenular neurons (black dots in Fig. 5F) were located closer to 
the medial wall of habenula (Fig. 6I), near the location of habenular 
neural progenitors labeled in Tg(her4.1:GFP) (53) zebrafish (Fig. 7A).
Since the juvenile zebrafish habenula displayed an increased 
pERK/tERK ratio toward the lateral ends (Fig. 6, G and H) and a 
higher number of silent neurons toward the medial ends (Fig. 6I), 
we hypothesized that the mediolateral distribution of habenular 
neurons at older stages might represent their physiological and 
developmental maturity. To test this hypothesis, we performed in-
tracellular recordings of habenular neurons across the mediolateral 
axis of juvenile zebrafish at later developmental stages. We observed 
that the input resistance, a hallmark of developmental maturation 
of cortical neurons (7), was significantly higher for medial habenular 
neurons, compared to lateral habenular neurons (Fig. 6J). Together, 
this suggests that neurons near the lateral ends of habenula might 
be more mature neurons that are born during early developmental 
stages, compared to medial habenula neurons born later.
Distinct spatial domains of habenular neurons are born 
through sequential neurogenesis
Next, we asked whether the spatial organization of habenula across 
the mediolateral axis might be a result of sequential neurogenesis 
across development. To test this hypothesis, we first investigated 
the location of habenular neurogenesis. We observed that neural 
progenitors labeled by Tg(her4.1:GFP) (53) expression are located 
at the medial walls of habenular hemispheres (Fig. 7A). To further 
investigate the relationship between the birthdate of habenular 
neurons and their spatial distribution, we labeled habenular neurons 
born during different developmental stages using 5-bromo-2′-­
deoxyuridine (BrdU) incorporation (Fig. 7B). BrdU birthdating 
showed that the habenular neurons that are born during distinct 
developmental stages were spatially organized (Fig. 7C). Moreover, 
we observed that the birthdate of habenular neurons is a good indi-
cator for their spatial location, where oldest neurons (born early in 
development) mostly occupied the lateral wall of habenula and 
youngest neurons (born late in development) were closest to the 
medial wall (Fig. 7, C and D).
Next, we developed an in vivo birthdating method to further 
investigate the distinct clusters of habenular neurons that are born 
during different developmental stages. To do this, we adopted a 
previously described approach to label cohorts of mammalian 
cortical neurons born at distinct developmental stages (54). We 
achieved this by injecting two different colors (far-red and green) of 
a fluorescent cell tracer in the telencephalic ventricle (55), near the 
neural progenitor zone on the medial wall of habenula (Fig. 7A) of 
2.5- and 5-dpf zebrafish larvae (Fig. 7E). Fifteen hours after the cell 
tracer injections, only the cells near the medial wall of habenula 
were labeled (Fig. 7E). We raised the zebrafish larvae injected with 
cell tracers of two different colors (far-red and green) until 12 and 
21 dpf and visualized the cohorts of birthdated habenular neurons 
in living juvenile zebrafish (Fig. 7F). Our results revealed a distinct 
spatial organization of habenular neurons birthdated at 2.5 dpf, 
compared to the neurons birthdated at 5 dpf (Fig. 7F). Further-
more, we observed less than 4% overlap of birthdated neurons by 
injections at 2.5 versus 5 dpf, highlighting the temporal resolution 
of our in vivo birthdating method (Fig. 7G). In addition, these 
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
8 of 17
experiments also revealed that the number of neurons birthdated 
at 2.5 dpf was almost double the number of neurons birthdated at 
5 dpf (Fig. 7, H and I). This higher rate of habenular neurogenesis at 
earlier developmental stages is also in line with our observation for 
a larger number of phospho–histone 3–labeled mitotic cells in 
habenula at earlier developmental stages (Fig. 7, J to K). Together, 
our results revealed that sequential neurogenesis in habenula generates 
spatially organized, nonoverlapping clusters of habenular neurons.
Habenular neurons born at a distinct developmental stage 
form a distinct functional cluster
Our results in previous sections indicate a potential relationship be-
tween the birthdate of habenular neurons, spatial location, and their 
functional properties. On the basis of these results, we hypothesized 
that the habenular neurons that are born together might form distinct 
functional clusters in habenula, with similar features of spontaneous 
activity. To test this hypothesis, we injected a far-red fluorescence 
Fig. 6. Features of habenular spontaneous activity change during development. (A) Individual spontaneous activity bursts (black markings) detected in all habenular 
neurons at 3, 6, and 21 dpf sorted on the basis of their increasing overall activity rate. Black bars represent 100 neurons. Bottom panel shows individual examples of 
spontaneous activity traces from three different neurons, with detected events marked with black color. Black bar represents 10% F/F. (B) Average frequency of spontaneous 
activity bursts in habenular neurons in each zebrafish at 3 dpf (n = 9 fish), 6 dpf (n = 6 fish), and 21 dpf (n = 9 fish). (C) Average duration of spontaneous activity bursts in 
habenular neurons in each zebrafish. (D) Average spontaneous activity in habenular neurons in each zebrafish, represented as total area under the curve of all detected 
events. (E) The ratio of spontaneously active neurons with at least one spontaneous activity burst.*P < 0.05, **P < 0.01, and ***P < 0.001, Wilcoxon rank sum test. 
(F) Three-dimensional reconstructions of habenular neurons based on the duration (left) and frequency of their spontaneous activity events. Frequency and duration are 
color-coded. Black dots are inactive neurons. Coronal view. Scale bars, 50 m. “foc” represents the focality index as means ± SEM for the temporal features of spontaneous 
activity bursts, duration, and frequency across all zebrafish and is depicted on top of the individual example’s three-dimensional reconstruction. (G) Confocal microscopy 
images of pERK/tERK ratio in representative examples of habenula at 3, 6, and 21 dpf in dorsal view. Scale bars, 20 m. White dashed lines delineate the borders of habenula. 
Note the difference in pERK/tERK ratio between medial and lateral ends of habenula. (H) Quantifications of the normalized pERK/tERK ratio along the mediolateral axis for 
each age at 3 dpf (n = 15), 6 dpf (n = 17), and 21 dpf (n = 8). Shading represents SEM. (I) The ratio of silent neurons in relation to their normalized mediolateral location 
along both habenula hemispheres of 3, 6, and 21 dpf. Shading represents SEM. Averages of the two most medial and two most lateral location bins were compared within 
one age. *P < 0.05 for 3 dpf and **P < 0.01 for 21 dpf, Wilcoxon signed-rank test. (J) Input resistance measured by intracellular recordings of habenular neurons (n = 40) 
across the mediolateral axis of juvenile zebrafish. Medial neurons (n = 10), central neurons (n = 9), and lateral neurons (n = 21) in 14 fish. **P < 0.01, Wilcoxon rank sum test. 
All data are presented as means ± SEM. MΩ, megohms.
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
9 of 17
cell tracer to the forebrain ventricles of zebrafish larvae express-
ing GCaMP6s at either 2.5 or 5 dpf (Fig. 8, A and K). Later, 
we raised these animals to 21 dpf and visualized their habenular 
activity in the green spectrum while identifying birthdated habenular 
neurons in the far-red spectrum, by using confocal microscopy 
(Fig. 8, A and K). Our in vivo birthdating injections at 2.5 or 5 dpf 
allowed us to classify habenular neurons into distinct spatial zones 
(Zs), where Z1 represents the earliest born (oldest) neurons and Z2 
Fig. 7. Distinct spatial domains of habenular neurons are born through sequential neurogenesis. (A) Confocal microscopy images of habenula in Tg(vglut2a:dsRed) 
and Tg(Her4:GFP) double transgenic zebrafish at 3, 6, and 21 dpf, displaying the glutamatergic neurons (magenta) and potential neuronal progenitors of habenula labeled 
by Her4 expression (cyan), dorsal view. Scale bar, 50 m. White dashed lines delineate the borders of habenula. (B) Schematic representation of BrdU pulse labeling 
protocol at 3, 5, 7, 14, and 20 dpf. Animals were raised to 21 dpf before imaging. (C) Confocal microscopy images of 21-dpf habenula (white dashed line) showing distribution 
of neurons that are born at different developmental stages. Neurons were birthdated by using BrdU (red) pulse labeling, at the developmental stages indicated in each 
panel. DAPI label marks all cells in blue. Dorsal view. Scale bar, 50 m. (D) Schematic representation of the sequential arrangement of neurons that are born at different 
developmental stages along the mediolateral axis, dorsal view. (E) Confocal microscopy images of telencephalic ventricle 15 hours postinjection with CellTrace Far Red 
(red) at 2.5 dpf (left) and a second injection with CellTrace CFSE (cyan) at 5 dpf (right). Dorsal view. Asterisk shows injection site in the telencephalic ventricle. Borders of 
the zebrafish telencephalon and habenula are delineated by a dashed white line. Scale bar, 50 m. (F) Confocal microscopy images of habenula 1 day postinjection of 
CellTrace Far Red (red) injected at 2.5 dpf and CellTrace CFSE (cyan) injected at 5 dpf (left panels). Birthdated habenular neurons are located near the medial wall of the 
habenula. At 12 and 21 dpf (right panels), habenular neurons labeled at 2.5 and 5 dpf exhibit distinct spatial distributions. Borders of the habenula are delineated by a 
dashed white line. Scale bar, 50 m. (G) The ratio of overlap between the two populations of habenular neurons birthdated by the sequential injections of Far Red and 
CFSE cell tracers at 2.5 and 5 dpf, respectively, and quantified at 12 dpf (n = 8) and 21 dpf (n = 8). (H) The number of habenular neurons that were born at 2.5 dpf versus 
5 dpf, measured at 12 dpf (n = 8) and 21 dpf (n = 8). **P < 0.01, Wilcoxon rank sum test. (I) The ratio of habenular neurons birthdated at 2.5 versus 5 dpf quantified at 
12 dpf (n = 8) and 21 dpf (n = 8). (J) Confocal microscopy images of habenula labeled with phospho-H3 antibody (cyan) indicating mitotic cells at 2 and 4 dpf. DAPI 
label marks all cells in blue. Borders of the habenula are delineated by a dashed white line. Scale bar, 50 m. (K) The number of phospho-H3 positive mitotic cells in the 
habenula, at 2 and 4 dpf. ***P < 0.001, Wilcoxon rank sum test. All data are presented as means ± SEM.
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
10 of 17
and Z3 represent later-born neurons with descending order of 
maturity (Z1 > Z2 > Z3) (Fig. 8, G to Q).
Our analysis revealed notable differences in the functional 
features of the spontaneous activity between habenular neurons 
born at different developmental stages, corresponding to distinct 
spatial zones. Earlier born habenular neurons displayed stronger 
spontaneous activity (Fig. 8, B, C, L, and M) with higher frequency 
(Fig. 8, D to N) and duration (Fig. 8E). Moreover, earlier born 
habenular neurons showed a significantly larger number of pairwise 
correlations, compared to later-born habenular neurons (Fig. 8, 
F and P). Our results suggest that distinct functional clusters of 
habenular neurons with distinct functional features are born at 
different developmental stages. To test this idea further, we asked 
whether the developmentally tagged neurons are also related to the 
spatially organized functional clusters within habenula, observed 
earlier (Fig. 4, A to D) (35). To this end, we clustered the spontaneous 
habenular activity using k-means clustering (Fig. 8, H, I, R, and S) 
and calculated the overlap between developmentally tagged neurons 
and functional clusters, using a “cluster selectivity” index (35). If 
developmentally tagged neurons in different habenular zones overlap 
with one functional cluster, cluster selectivity would result in 1. We 
observed that the developmentally tagged habenular neurons in 
each zone overlap with significantly fewer clusters, when compared 
to the same number of randomly selected habenular neurons 
(Fig. 8, J to T). These results revealed that distinct functional 
clusters of spatially organized habenular neurons are born at 
distinct developmental stages and exhibit similar features of 
spontaneous activity.
DISCUSSION
In this study, we investigated the functional development of 
habenular circuits in zebrafish across development from young 
larvae with relatively simple behaviors to juvenile zebrafish with 
complex behaviors (1–3, 33, 36, 37). The use of juvenile zebrafish 
is gaining popularity due to their transparent brains and their 
expanded behavioral repertoire that requires habenular function 
(1–3, 37). Our results revealed that as the zebrafish develop from 
the larval to the juvenile stage, habenular circuits undergo multiple 
transitions in its architecture, sensory computations, and intrin-
sically generated spontaneous activity, which could support the 
expansion of the behavioral repertoire during development.
Previous studies indicate the presence of olfactory (34, 35) and 
visual (23, 34) responses in habenula, which were suggested to be 
involved in generating odor avoidance (43) and light preference 
(23). Both visual (20) and olfactory (56) responses are reported in 
sensory organs of 2.5-day-old zebrafish larvae. However, the precise 
developmental maturation of these sensory inputs in habenula has 
not been investigated. Our results revealed that at early develop-
mental stages, habenula is first innervated by the visual inputs, 
which are followed by the olfactory inputs. This is also in line with 
our observation of light responses dominating habenula of larval 
zebrafish followed by olfactory responses. We observed that aver-
sive mild electric stimulation (27, 30, 37) elicits responses in 
habenula during later developmental stages. This gradual increase 
in stimulus diversity of habenular responses likely reflects a devel-
opmental transition of habenula into a multisensory processing 
brain region, which can encode stimulus salience and valance. We 
observed that visual, olfactory, vibrational, and electric stimuli are 
distinctly encoded by the activation of separate neural populations. 
Such distinct encoding of different sensory modalities at all devel-
opmental stages highlights the important role of habenula in inte-
grating information from multiple sensory systems (23, 34, 35, 43, 57). 
Future experiments are needed to identify the specific role of 
habenular circuits for distinguishing salience and valance across 
multiple sensory modalities.
As in other lower vertebrates, zebrafish dHb exhibits prominent 
molecular (29, 30) and structural asymmetries (39). As expected, 
habenular lateralization has important consequences with respect 
to the segregation of different sensory modalities across habenular 
hemispheres and for regulating the targeting of habenular axons to 
different output regions (27, 33, 39). We observed that the functional 
lateralization of sensory inputs and computations in habenula is 
prominent mostly in the dHb, which develops early during devel-
opment (38), whereas we did not observe functional lateralization 
in vHb, which develops later (32), despite the prominent sensory-­
evoked vHb responses. This developmental order eventually leads 
to a decrease in functional lateralization across the entire habenula 
as the animals maturate. Similar to primary sensory systems (12), 
maturation of zebrafish habenula requires the early presence of 
sensory inputs (34). When these inputs are removed before a critical 
time window, zebrafish dHb loses its functional lateralization (34). 
It is also important to note that aversive stimuli (mechanical vibrations 
and mild electric stimulation) did not elicit lateralized responses in 
zebrafish habenula, which is in line with studies performed in the 
mammalian lateral habenula, where aversive responses showed no 
apparent lateralization (25, 26, 58). We suggest that the apparent 
lack of lateralization in the mammalian habenula is due to a continued 
maturation of lateral habenula dominated by aversive cue responses 
and reduced availability of sensory information during mammalian 
in utero development.
The activity-dependent maturation of neural circuits does not 
solely rely on sensory inputs but also includes endogenously gener-
ated spontaneous activity (11). In several brain regions, sponta-
neously generated activity is thought to play important roles in the 
maturation of synaptic connections, refining network topography 
(13, 14, 59) and entraining developing circuits (17). In our study, we 
observed that habenular networks exhibit spatially organized spon-
taneous activity already at early developmental stages. A recent 
transcriptomics study revealed a topographic organization of 
habenular neurons based on their distinct molecular features already 
in 10-day-old zebrafish larvae (30) and likely overlap with the 
spatially organized spontaneous activity studied here. Whether the 
spontaneous activity is needed for the proper development of 
distinct habenular clusters or habenular function, as in other brain 
regions (13), is yet to be investigated.
We also observed that temporal features of habenular sponta-
neous activity changed, leading to faster kinetics at older ages. The 
trend for faster kinetics of intrinsically generated activity across 
development was also observed in other higher brain regions, such 
as the hippocampus (16, 50). What may underlie the faster kinetics 
of spontaneous activity bursts in older ages? It is likely that multiple 
processes can modulate spontaneous habenular activity leading to 
the observed dynamical changes during development. One possibility 
is that early spontaneous activity might be driven by glia (20) or 
other support cells (21), which usually generate slow bursts of activity. 
It was previously shown that astrocytes can modulate the bursting 
activity in the rodent habenula (60), and astroglia activation in 
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
11 of 17
Fig. 8. Habenular neurons that are born at a distinct developmental stage exhibit similar functional properties. (A) Confocal microscopy images of elavl3:GCaMP6s 
(white) zebrafish habenula at 3 (top) and 21 (bottom) dpf, after the injection of the CellTrace Far Red (red) at 2.5 dpf. Dorsal view. Habenula is delineated by a dashed white 
line. Developmentally tagged, red-labeled neurons at 21 dpf are in zone 1 (Z1 = early born), whereas unlabeled neurons are in zone 2 (Z2 = later born). Scale bar, 100 m. 
L, left; R, right. (B) The ratio of spontaneously active Z1 (red) versus Z2 (black) habenular neurons at 21 dpf. Note that a higher ratio of early-born habenular neurons in Z1 
are active, when compared to later-born neurons in Z2 (n = 21 planes in 12 fish). (C) Average spontaneous activity that is represented as total area under the curve of all 
detected events, in Z1 versus Z2 habenular neurons at 21 dpf. (D) Average spontaneous activity burst frequency in Z1 versus Z2 habenular neurons at 21 dpf. (E) Average 
spontaneous activity burst duration in Z1 versus Z2 habenular neurons at 21 dpf. (F) Average pairwise correlations of Z1 versus Z2 habenular neurons at 21 dpf. Note that 
Z1 neurons are significantly more correlated than Z2 habenular neurons. **P < 0.01 and ***P < 0.001, Wilcoxon signed-rank test. (G) Spatial distribution of labeled 
early-born (Z1) versus later-born (Z2) habenular neurons, in an example zebrafish at 21 dpf. (H) Spatial distribution of habenular neurons color-coded according to their 
functional clusters based on their spontaneous activity, using k-means clustering in the same example zebrafish as in (I). (I) Color-coded neural traces showing the 
spontaneous activity of each habenular neuron that belong to a given cluster “C,” in the same example zebrafish as (G) and (H). Warm colors represent increased neural 
activity. Note the prominent overlap between the functional cluster C3 (yellow neurons in H) and Z1 neurons in (G). (J) Cluster selectivity of Z1 versus Z2 habenular 
neurons, when compared to the same number of randomly selected habenular neurons (S) in yellow. Note that both Z1 and Z2 habenular neurons belong to fewer 
functional clusters compared to an equal number of random neurons. **P < 0.01, Wilcoxon signed-rank test. Also, note that Z1 neurons are significantly more cluster 
selective than Z2. ***P < 0.001, Wilcoxon rank sum test. (K) Confocal microscopy images of elavl3:GCaMP6s (white) zebrafish habenula at 5 (top) and 21 (bottom) dpf, after 
the injection of the cell tracer (red) at 5 dpf. Oldest neurons (Z1 = early born) are located lateral to the red-labeled neurons (Z2 = intermediate born) that are developmentally 
tagged at 5 dpf. The youngest neurons (Z3 = late born) are located medial to the red-labeled neurons. Scale bar, 100 m. L, left; R, right. (L) The ratio of spontaneously 
active Z1 (gray), Z2 (red), and Z3 (black) habenular neurons at 21 dpf (n = 12 planes in five fish). Note that a higher ratio of Z2 neurons are active, when compared to Z3 
neurons. (M) Average spontaneous activity that is represented as total area under the curve of all detected events, in Z1, Z2, and Z3 habenular neurons at 21 dpf. 
(N) Average spontaneous activity burst frequency in Z1, Z2, and Z3 habenular neurons at 21 dpf. (O) Average spontaneous activity burst duration in Z1, Z2, and Z3 
habenular neurons at 21 dpf. (P) Average pairwise correlations of Z1, Z2, and Z3 habenular neurons at 21 dpf. **P < 0.01, Wilcoxon signed-rank test. (Q) Spatial dis-
tribution of early-born (Z1), intermediate-born (Z2), and later-born (Z3) habenular neurons, in an example zebrafish at 21 dpf. (R) Spatial distribution of habenular neurons 
color-coded according to their functional clusters based on their spontaneous activity, using k-means clustering in the same example zebrafish as in (I). (S) Color-coded 
neural traces showing the spontaneous activity of each habenular neuron that belong to a given cluster “C,” in the same example zebrafish as (G) and (H). Warm colors 
represents increased neural activity. (T) Cluster selectivity of Z1, Z2, and Z3 habenular neurons, when compared to the same number of randomly selected habenular neu-
rons (S) in yellow. Note that Z1, Z2, and Z3 habenular neurons belong to fewer functional clusters compared to equal number of random neurons. ***P < 0.001, 
Wilcoxon signed-rank test. All data are presented as means ± SEM.
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
12 of 17
zebrafish can excite nearby neurons (61). Alternatively, it is possible 
that as the habenula develops, synaptic connections between 
habenular neurons become more mature. Together with the in-
creased inhibition we observed in the habenula, by the addition of 
GABAergic connections, such mature synapses can support faster 
neural dynamics. Last, part of the habenular spontaneous activity 
might also be driven by the activation of the ancestral corticolimbic 
homologs in the zebrafish forebrain. For example, it was shown that 
habenula is strongly driven by inputs received from entopeduncular 
nucleus (24, 62), lateral hypothalamus (26), and cortex (58). Hence, 
it is likely that the homologs of these input regions are not yet fully 
developed and cannot drive habenular activity in young zebrafish 
larvae. A recent study showed that the zebrafish equivalent of amygdala 
(Dm) (63), driving both entopeduncular nucleus and lateral hypo-
thalamus (63), also develops during the late juvenile stage (64). 
Together, we suggest that all these processes jointly contribute to 
the habenular spontaneous activity.
Our results revealed that the developmental changes in the tem-
poral kinetics of habenular spontaneous activity are accompanied 
by the sequential addition of newborn neurons across development. 
More specifically, we found that the spatially confined locations of 
neuronal clusters that are born during distinct developmental stages 
follow a mediolateral arrangement. In this arrangement, youngest 
neurons are located closer to the neural progenitors of the habenula 
on the medial wall, while the oldest habenular neurons are located 
closer to the lateral wall. Similar sequential stacking of newly born 
neurons was also observed during forebrain development in both 
zebrafish (65, 66) and rodents (6, 67). Moreover, such a sequential 
order of neurogenesis contributes to different neural subtypes in 
the zebrafish hindbrain and spinal cord (8–10), as well as the rodent 
entorhinal cortex (5). Hence, it is possible that recently described 
populations of habenular neurons with distinct molecular identities 
(30) might be born during different developmental stages of the 
zebrafish habenula. The topographically organized molecular (30) 
and functional clusters (30, 35, 37) of habenular neurons represent 
the distinct subdomains or functional modules of habenula and are 
likely associated with different aspects of animal behavior. Our data 
revealed that at least two of the functional clusters within habenula 
are born at two different developmental stages, stay in spatially con-
fined locations, and exhibit different functional features. Therefore, 
we propose that the distinct functional clusters of habenular neu-
rons are born at different developmental time points. In turn, such 
a developmental order could contribute to an increased diversity of 
habenular neurons and expand habenular function across develop-
ment. These ideas are in line with several recent studies that suggest 
that complex and cognitively demanding behaviors arise later in 
development as animals maturate (1, 2, 33, 37). Our findings in 
habenula suggest that such expansion of animal behavior might be 
due to the incorporation of new functional modules at different 
developmental time points. In the future, it will be interesting to see 
whether such sequential addition of new neuronal modules with 
distinct functional properties is a feature that is not only unique to 
habenula but also preserved across the brain.
MATERIALS AND METHODS
Fish maintenance
The animal facilities and maintenance of zebrafish, Danio rerio, 
were approved by the Norwegian Food Safety Authority. Fish were 
kept in 3.5-liter tanks at a density of 15 to 20 fish per tank in a Techniplast 
Zebtech Multilinking system at 28°C (pH 7), 6.0 ppm O2, and 700 S, 
at a 14-hour light/10-hour dark cycle. Fish received a normal diet of 
dry food (Zebrafeed, Sparos) two times per day and Artemia nauplii 
once a day (Grade 0, Platinum Label, Argent Laboratories). Larvae 
were maintained in egg water (1.2 g of marine salt and 0.1% methylene 
blue in 20 liters of reverse osmosed water) from fertilization to 
3 dpf. From 3 to 6 dpf, larvae were kept in artificial fish water 
(AFW): 1.2 g of marine salt in 20 liters of RO water. Animals used 
for experiments at 21 dpf were transferred to 3.5-liter tanks in the 
zebrafish facility at 3 dpf.
For experiments, the following fish lines were used: Tg(elavl3:​
GCaMP6s) (41), Tg(gad1b:GFP) (42), Tg(vglut2a:dsRed) (22), Tg(Lhx2a:​
gap-YFP) (22), Et(−0.6hsp70l:Gal4-VP16) s1020t; UAS:nfsB-mCherry 
(44), and Tg(her4.1:GFP) (53). Experiments were performed on 
embryos of nacre [mitfa; (68)] background.
Confocal anatomical imaging
Before embedding, fish were anesthetized with 0.02% tricaine methane-
sulfonate (MS-222). Animals were then embedded in 1% (for 3 to 6 dpf) 
or 2% (for 21 dpf) low–melting point (LMP) agarose (Thermo Fisher 
Scientific) in a recording chamber (FluoroDish, World Precision Instru-
ments) with AFW. Anatomical Z scans were acquired using a Zeiss 
Examiner Z1 confocal microscope with a 20× water immersion objective 
[Zeiss; numerical aperture (NA) of 1.0; Plan-Apochromat] at room 
temperature, using 4× to 10× average for each plane.
BrDU labeling, immunostaining, and imaging
Labeling of newborn neurons with BrdU was performed at 3.5, 5.5, 
7.5, 14.5, and 20.5 dpf in Tg(HuC:GFP) (69) fish outcrossed to wild-
type (AB) fish. Embryos (25 hours post-fertilization) were dechori-
onated by Proteinase K (0.1 mg/ml; catalog number 25530049) at 
room temperature and washed several times with 1× E3 medium. A 
stock of 10 mM BrdU (Sigma-Aldrich, catalog number B5002) in 
1× E3 medium was prepared, aliquoted, and stored at −20°C until 
use. For each treatment, a final concentration of 500 M BrdU was 
applied to 3- and 5-dpf fish. For 7-, 14-, and 21-dpf fish, 2.5 mM 
BrdU was used. Treatments were all performed for 5 hours. Fish 
were kept in a dark incubator until 5 dpf and were transferred to the 
water system at 6 dpf. From this point on, a 14-hour light/10-hour 
dark cycle was maintained. At 22 dpf, fish were sacrificed and fixed in 
4% paraformaldehyde (PFA) to 1% dimethyl sulfoxide (DMSO) at +4°C 
overnight, washed with 0.8% Triton X-100 in 1× phosphate-buffered 
saline (PBS; PBSTx), dehydrated by a serial methanol gradient, and 
kept at −20°C until further use. For immunohistochemical staining, 
fish were rehydrated back to the aqueous phase (1× PBS). Brains 
were dissected out in cold 1× PBS and were incubated in precooled 
acetone for 10 min at −20°C. Brains were incubated in preheated 
2 mM HCl at 37°C for 12 min, cooled at room temperature for 
10 min, and washed with 0.8% PBSTx. Samples were incubated in Rat 
anti-BrdU immunoglobulin G (IgG; 1:200 Bio-Rad, catalog number 
MCA2060) monoclonal antibody overnight at +4°C. After serial washes 
in 0.8% PBSTx, the secondary antibody (Goat anti-rat Alexa 555; 
1:500 dilution; Thermo Fisher Scientific, catalog numberA-21434) 
and 4′,6-diamidino-2-phenylindole (DAPI) at 1:3000 dilution were 
applied. Following an overnight incubation at +4°C, samples were 
washed for a total of 2 hours with 0.8% PBSTx.
To measure pERK/tERK ratio, fish were euthanized and fixed 
in cooled 4% PFA in 0.25% PBTx (0.25% Triton X-100 in 1× PBS) 
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
13 of 17
overnight at 4°C. Samples were permeabilized in 0.50% Trypsin-­
EDTA on ice for 40 min and washed. The samples were then incu-
bated in the blocking solution [2% normal goat serum, 1% bovine 
serum albumin (BSA), and 1% DMSO in 0.25% PBTx] for 1 hour 
followed by incubation in primary antibody solution [1:500 anti-
body (Ab), 1% BSA, and 1% DMSO in 0.25% PBTx] overnight at 
4°C. Next, samples were washed and incubated with secondary 
antibody solution (1:1000 Ab, 1:1000 DAPI, 1% BSA, and 1% DMSO 
in 0.25% PBTx) overnight at 4°C. Last, samples were washed and 
placed in glycerol. pERK/tERK ratio of the median z-projection 
confocal images were calculated in ImageJ (Fiji). The pERK/tERK 
ratio is normalized by the maximum pERK/tERK ratio and adjusted 
for the habenular size using a custom-made script in MATLAB.
For phospho–histone 3 staining, larvae were fixed in 4% PFA for 
2 hours at room temperature or overnight at 4°C. Following washes 
in 0.3% Triton-X in PBS (0.3% PBSTx), fixed samples were perme-
abilized in 100% acetone at −20°C for 20 min and blocked in 0.3% 
PBSTx containing 0.1% BSA. Samples were incubated with the 
primary antibody (phospho–histone 3, Santa Cruz Biotechnology, 
#sc-8656-R; 1:500 dilution) overnight at +4°C, followed by serial washes 
in 0.3% PBSTx and incubation with the secondary antibody (goat 
anti-rabbit Alexa 488 plus, Thermo Fisher Scientific, #A-11034, 
1:1000 dilution) overnight at +4°C. Next, samples were incubated 
in DAPI (1:1000) for 2 hours, before serial washes in 0.3% PBSTx.
For preservation, samples were transferred to 80% glycerol in 1× 
PBS and were kept at +4°C in the dark. For imaging, labeled brains 
were mounted in 80% glycerol on a glass slide with a coverslip. 
Anatomical Z scans of habenula were acquired using a Zeiss Examin-
er Z1 confocal microscope with a 20× plan NA 0.8 objective, using 
2× to 10× average for each plane. Phospho–histone 3–positive cells 
were manually counted on confocal stack using the Cell Counter 
Plugin of Fiji/ImageJ.
In vivo two-photon calcium imaging and sensory stimulation
Two-photon calcium imaging was performed on 3-, 6-, and 21-dpf-
old Tg(elavl3:GCaMP6s) zebrafish. Before embedding, fish were 
anesthetized with cold AFW. Animals were then embedded in 1% 
(for 3 to 6 dpf) and 2% (for 21 dpf) LMP agarose (Thermo Fisher 
Scientific) in a recording chamber (FluoroDish, World Precision 
Instruments). LMP agarose solidified for 20 min, and the section 
covering the nose was carefully removed to expose the nostrils. The 
animal was then placed under the microscope with constant perfu-
sion of AFW bubbled with carbogen (95% O2 and 5% CO2). First, 
spontaneous activity was measured for 30 min. Afterward, five 
repetitions of sensory stimuli (red light flash or food odor) were 
applied. The food odor stimulus was prepared by adding 1 g of 
standard dried fish food (Zebrafeed, Sparos; <100) in 50 ml of AFW, 
dissolved for 1 hour, filtered with a 22-m filter, and diluted 1:50 in 
AFW. For skin extract (70), an adult zebrafish was euthanized in 
ice-cold water and decapitated, and the skin was peeled off from 
the body, incubated in 1 ml of AFW, mixed, and centrifuged at 
1300 rpm and 4°C for 1 hour. One milliliter of the supernatant was 
then dissolved in 300 ml of AFW. Amino acid mixture (70) con-
tained arginine, asparagine, aspartic acid, alanine, phenylalanine, 
histidine, and methionine, all diluted in AFW at 10−4 M final con-
centration. Ammonium chloride was diluted in AFW at 10−4 M 
final concentration. The odor stimulus was delivered for 5 s through 
a tube positioned in the front of the fish, connected to an Arduino 
Due–controlled high-performance liquid chromatography injection 
valve (Valco Instruments). Fluorescein (10−4 M) was dissolved in 
AFW and used to measure the precise onset of odor delivery to the 
nose at the end of each experiment. For the light stimulus, we used 
a red LED (LZ1-00R105, LedEngin; 625-nm wavelength) and placed 
it in the front of the recording chamber near the tube. The light 
stimulus was a flash of 2-s duration with an intensity of 0.318 mW. 
Mechanical vibrations were delivered via solenoid tapper (SparkFun 
Electronics, ROB-10391), via 50-ms application of 6 V. Mild electric 
stimulation was delivered by tungsten electrodes that passed 1-kHz 
oscillating current of 0.05 mA for a period of 1 s. The recordings 
were performed with a two-photon microscope (Scientifica) using a 
16× water immersion, long working-distance objective (Nikon, NA 
0.8, LWD 3.6). A mode-locked Ti:Sapphire laser (MaiTai Spectra-­
Physics) tuned to 920 nm was used for excitation. Volumetric re-
cordings (eight planes with Piezo) were obtained at an acquisition 
rate of 31.9 Hz for a volume of 1536 × 512 pixels × 8 planes. Total 
duration of the recordings was 45 to 60 min.
Juvenile zebrafish electrophysiological recordings 
of habenular neurons
The experiments were conducted in a juvenile zebrafish brain explant 
preparation (61). Juvenile zebrafish were euthanized by immersion 
in ice-cold water, followed by decapitation to ensure death. The 
head was transferred in cold artificial cerebrospinal fluid (ACSF) 
bubbled with carbogen (95% O2/5% CO2). The ACSF (70) was 
composed of the following chemicals diluted in reverse-osmosis 
purified water: 131 mM NaCl, 2 mM KCl, 1.25 mM KH2PO4, 2 mM 
MgSO4⋅7H2O, 10 mM glucose, 2.5 mM CaCl2, and 20 mM NaHCO3. 
The eyes, jaws, and ventral part of the skull were carefully removed 
using forceps, exposing the habenula. The brain explant was then 
affixed using tungsten pins to a small petri dish coated with Sylgard 
(World Precision Instruments) and perfused in constant flow 
bubbled ACSF.
We performed intracellular recordings of single habenular 
neurons, via borosilicate patch pipettes (10 to 12 megohms) mounted on 
a MultiClamp 700B amplifier. Electrodes contained the intracellular 
solution (130 mM k-gluconate, 10 mM Na-gluconate, 10 mM 
Hepes, 10 mM Na2+-phosphocreatine, 4 mM NaCl, 4 mM adenosine 
5′-triphosphate–Mg, and 0.3 mM Na3+-GTP) (70). Negative volt-
age steps (−30 mV) of 500 ms were applied to measure the input 
resistance.
In vivo birthdating of neurons
Before injections, 2.5-dpf larvae were dechorionated manually and 
anesthetized in 0.01% MS-222 in AFW for 5 to 10 min. Injections 
were done on larvae embedded in 1% LMP agarose in AFW and 0.01% 
MS-222 in AFW. The stock solution contained 5 mM CellTrace Far 
Red–AM or CellTrace CFSE Cell Proliferation Kit (Thermo Fisher 
Scientific) dissolved in DMSO provided with the proliferation kit. 
The injection mixtures contained 0.5 l of this CellTrace Far Red/
DMSO stock solution dissolved in 2.5 l of ACSF with a final con-
centration of 1 mM. The ACSF contained the following: 124 mM 
NaCl, 22 mM d-(+)-glucose, 2.0 mM KCl, 1.6 mM MgSO4·7 H2O, 
1.3 mM KH2PO4, 24 mM NaHCO3, and 2.0 mM CaCl2·2H2O. The 
injection needles were pulled with a Sutter Instrument Co. Model 
P-2000, from thin-walled borosilicate capillaries (1.00 mm; VWR), 
with the following settings: heat = 785, filament = 4, velocity = 40, 
delay = 220, and pull = 70. The needle tip was cut open with forceps 
afterward, and a pressure injector (Eppendorf Femtojet 4i) was used 
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
14 of 17
Table 1. Key resource table presenting the source and identifier of chemicals, transgenic lines, and materials.  
Reagent or resource
Source
Identifier
Chemicals
  MS222 (tricaine methanesulfonate)
Sigma-Aldrich
Catalog number E10521
  LMP agarose
Thermo Fisher Scientific
Catalog number 16520100
  PBS
Thermo Fisher Scientific
Catalog number BR0014G
  CellTrace Far Red Cell Proliferation Kit
Thermo Fisher Scientific
Catalog number C34564
  CellTrace CFSE Cell Proliferation Kit
Thermo Fisher Scientific
Catalog number C34554
  Proteinase K
Thermo Fisher Scientific
Catalog number 25530049
  BrdU
Sigma-Aldrich
Catalog number B5002
  Triton-X
Sigma-Aldrich
Catalog number T8787
  DMSO
Sigma-Aldrich
Catalog number D8418
  Rat anti-BrdU
Bio-Rad
Catalog number MCA2060
  Rabbit anti-phosphoh3
Santa Cruz Biotechnology
Catalog number sc-8656-R
  Goat anti-rat Secondary Antibody, Alexa 555
Thermo Fisher Scientific
Catalog number A-21434
  Goat anti-rabbit Secondary Antibody, Alexa 488 
plus
Thermo Fisher Scientific
Catalog number A-11034
  p44/42 MAPK Mouse mAb
Cell Signaling Technology
Catalog number 4696
  Phospho-p44/42 MAPK Rabbit mAb
Cell Signaling Technology
Catalog number 4370
  Goat anti-Mouse IgG Secondary Antibody, Alexa 
Fluor Plus 488
Thermo Fisher Scientific
Catalog number A32723
Zebrafish lines
Source and brief description
  Tg(elavl3:GCaMP6s)
(41)
ZFIN catalog number ZDB-ALT-141023-1, 
RRID:ZFIN_ZDB-ALT-141023-1
Expresses GCaMP6s panneuronally
  Tg(gad1:GFP)
(42)
ZFIN catalog number ZDB-ALT-131127-6, 
RRID:ZFIN_ZDB-ALT-131127-6
Expresses GFP in GABAergic neurons
  Tg(vglut2a:dsRed)
(22)
ZFIN catalog number ZDB-ALT-100505-2, 
RRID:ZFIN_ZDB-ALT-100505-2
Expresses dsRed in glutamatergic neurons
  Tg(lhx2a:gap-YFP)
(22)
ZFIN catalog number ZDB-ALT-100504-12, RRID: 
ZFIN_ZDB-ALT-100504-12
Expresses membrane tagged YFP in mitral cells
  Et(−0.6hsp70l:Gal4-VP16) s1020t
(44)
ZFIN catalog number ZDB-ALT-070420-21, RRID: 
ZFIN_ZDB-ALT-070420-21
Expresses Gal4 in thalamic neurons
  Tg(UAS: nfsB-mCherry)
(44)
Catalog number ZFIN ZDB-ALT-070316-1, RRID: 
ZFIN_ZDB-ALT-070316-1
Expresses UAS:nfsB-mCherry ubiquitously (44)
  Tg(her4.1: GFP)
(53)
ZFIN catalog number ZDB-ALT-070612-3, RRID: 
ZFIN_ZDB-ALT-070612-3
Expresses GFP in neural progenitors
Software and algorithms
  ImageJ/Fiji
https://fiji.sc/
  Cell detection, image alignment, and processing
(35, 61, 71)
  Event detection
(51)
Other
  Pressure injector
Eppendorf
Femtojet 4i
  Confocal microscope (20× plan NA 0.8 objective)
Zeiss
Examiner Z1
  Stereomicroscope (20× Plan-Apochromat, NA 
0.8)
Zeiss
Axio Imager M1
  Two-photon microscope
Scientifica
  Sutter laser puller
Sutter
Model P-200
  Solenoid tapper
SparkFun Electronics
ROB-10391
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
15 of 17
to inject 1 nl of solution in the telencephalic ventricle near habenula 
of either 2.5- or 5-day-old zebrafish larvae (55). The pressure and 
time used for the injection were calibrated for each needle using a 
0.01-mm calibration slide for microscopy. Usually, the pressure 
ranged between 100 and 150 hPa, and the time span of the pressure 
pulse lasted for 0.30 to 0.70 s. After injection, fish were released 
from agarose and recovered at 28°C AFW and transferred to the 
fish facility and raised until 12 or 21 days.
Fish (21 dpf) were prepared for confocal microscopy imaging as 
described above for two-photon calcium imaging. Imaging was 
performed using a Zeiss Examiner Z1 confocal microscope with a 
20× water immersion objective (Zeiss; NA of 1.0; Plan-Apochromat) 
at room temperature and constant perfusion of AFW bubbled with 
carbogen (95% O2 and 5% CO2). In vivo calcium recordings of the 
spontaneous activity in habenula were acquired at an acquisition 
rate of 1.918 Hz for 512 × 1024 pixels during 5 min.
Data analysis
Two-photon microscopy images were aligned using an adapted 
algorithm (71) that corrects for occasional drift in the XY dimension, 
based on “hierarchical model-based motion estimation” (72). Every 
recording was manually checked for motion, and corresponding 
frames were discarded from further analysis. Individual neurons 
were semiautomatically detected using a pattern recognition algo-
rithm as previously described (35, 61, 71). Once neurons were 
detected, their locations were individually tracked during the record-
ing. If any z-motion drift or if some detected neurons were no longer 
visible, those neurons were discarded from further analysis. The 
pixels belonging to each neuron were then averaged providing the 
complete time course of each neuron over time. The same cell-­
detection algorithms were used for the confocal recordings in Fig. 6. 
To distinguish between developmentally tagged and untagged neurons, 
we manually identified the red cells. To normalize the spontaneous 
activity for each cell to its baseline fluorescence, we calculated the 
fractional change in fluorescence (F/F) relative to the baseline, 
which was calculated as the eighth percentile of activity observed 
within a 2-min time window as previously described (51). Clustering 
of neurons was performed as previously reported on the basis of the 
k-means clustering algorithm in MATLAB, as well as the calcula-
tion of cluster fidelity and cluster selectivity for sensory and tagged 
cells (35).
Before event detection, traces from neurons in the two-photon 
recordings were resampled to a final rate of 2 Hz (using decimate 
function in MATLAB), to match the sampling rate with confocal 
experiments. Significant calcium events were detected using an 
algorithm (51) that detects calcium events significantly different from 
noise level within a 95% confidence interval. A cell was considered 
active if at least one event was detected in 4 min of ongoing activity. 
The amplitude of events was defined as the maximum peak in the 
event. The average activity per cell was defined as the sum of the 
area under the curve (using trapezoidal numerical integration 
method, function “trapz” in MATLAB) for all events within one 
neuron. The fractional change in fluorescence (F/F) for the odor 
and light stimulus, as well as mechanical vibrations and mild 
electric stimulus, was calculated by subtracting the average baseline 
fluorescence before stimulus onset (5 s) from the responsive window 
(10 s for odor and 2 s for light, mechanical vibrations, and mild 
electric stimulus from the onset of the stimulus). Cells were classified 
as responding if at least four out of five trials showed the same sign 
difference (+/−) locked to the stimulus onset. Only the positively 
responding neurons were taken into account for further analysis.
The focality index was calculated as 1 minus the average of the 
Euclidean distances between the top 10% neurons (with highest fre-
quencies or durations) divided by the average of the Euclidean distances 
of all neurons within each hemisphere. The average focality index per 
fish was calculated by taking the average over the two hemispheres. 
Same focality index was calculated for the sensory-­responding cells.
Cluster fidelity was calculated by measuring the probability of 
pairs of neurons being in the same cluster during two different time 
periods (35). As a control, we shuffled the cluster identity of neurons 
randomly.
To calculate cluster selectivity, we first calculated the cluster 
identity of each neuron using k-means clustering of spontaneous 
neural activity (35). Later, we identified neurons with a given prop-
erty, in this case, either sensory responding neurons (Fig. 4G) or 
developmentally tagged neurons (Fig. 6L), and measured the sparseness 
in the distribution of identified neurons into clusters (35). We then 
compared this to all and/or equal number of nonsensory responding 
neurons within each fish. If sparseness is 1, all identified neurons 
are selectively members of a single cluster; if sparseness is 0, all 
identified neurons are equally distributed into all functional clusters 
identified by k-means clustering.
The lateralization index was calculated as the difference between 
the percentage of responding neurons in the left and right hemispheres. 
If lateralization index is 1, neurons are lateralized to one hemisphere; if 
lateralization index is 0, neurons are equally distributed among hemispheres.
In the confocal microscopy functional imaging, results for frequency, 
duration, number of active neurons, average activity, and pairwise 
correlations are shown for all planes imaged in each fish. These 
recordings were done at different time points.
Quantification and statistical analysis
Statistical analysis was done using MATLAB, and P values are indicated 
in the figure legends (*P < 0.05, **P < 0.01, and ***P < 0.001). Student 
t test was used for paired data, and unpaired t test was used when data 
were obtained from two independent datasets. For the data that 
displayed no Gaussian distribution, we used Wilcoxon signed-rank 
test for paired data and Wilcoxon rank sum test for unpaired data.
Data and software
All analysis was performed with Fiji and MATLAB as indicated 
in Results.
Key resource table
Table 1 shows the source and identifier of chemicals, transgenic 
lines, and materials used in the study.
SUPPLEMENTARY MATERIALS
Supplementary material for this article is available at http://advances.sciencemag.org/cgi/
content/full/6/36/eaaz3173/DC1
View/request a protocol for this paper from Bio-protocol.
REFERENCES AND NOTES
	 1.	 A. Valente, K.-H. Huang, R. Portugues, F. Engert, Ontogeny of classical and operant 
learning behaviors in zebrafish. Learn. Mem. 19, 170–177 (2012).
	 2.	 Palumbo, F., Serneels, B., Pelgreems, R., Yaksi, E., The zebrafish dorsolateral habenula is 
required for updating learned behaviors. bioRxiv, in revision Cell Reports, 2020: p. 802256.
	 3.	 E. Dreosti, G. Lopes, A. R. Kampff, S. W. Wilson, Development of social behavior in young 
zebrafish. Front. Neural Circuits 9, 39 (2015).
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
16 of 17
	 4.	 E. A. Brenowitz, M. D. Beecher, Song learning in birds: Diversity and plasticity, 
opportunities and challenges. Trends Neurosci. 28, 127–132 (2005).
	 5.	 F. Donato, R. I. Jacobsen, M.-B. Moser, E. I. Moser, Stellate cells drive maturation 
of the entorhinal-hippocampal circuit. Science 355, eaai8178 (2017).
	 6.	 E. S. Lein, T. G. Belgard, M. Hawrylycz, Z. Molnár, Transcriptomic perspectives 
on neocortical structure, development, evolution, and disease. Annu. Rev. Neurosci. 40, 
629–652 (2017).
	 7.	 S. Mayer, J. Chen, D. Velmeshev, A. Mayer, U. C. Eze, A. Bhaduri, C. E. Cunha, D. Jung, 
A. Arjun, E. Li, B. Alvarado, S. Wang, N. Lovegren, M. L. Gonzales, L. Szpankowski, A. Leyrat, 
J. A. A. West, G. Panagiotakos, A. Alvarez-Buylla, M. F. Paredes, T. J. Nowakowski, 
A. A. Pollen, A. R. Kriegstein, Multimodal single-cell analysis reveals physiological 
maturation in the developing human neocortex. Neuron 102, 143–158.e7 (2019).
	 8.	 M. Koyama, A. Kinkhabwala, C. Satou, S.-i. Higashijima, J. Fetcho, Mapping a sensory-
motor network onto a structural and functional ground plan in the hindbrain.  
Proc. Natl. Acad. Sci. U.S.A. 108, 1170–1175 (2011).
	 9.	 A. Pujala, M. Koyama, Chronology-based architecture of descending circuits that underlie 
the development of locomotor repertoire after birth. eLife 8, e42135 (2019).
	10.	 D. L. McLean, J. R. Fetcho, Spinal interneurons differentiate sequentially from those 
driving the fastest swimming movements in larval zebrafish to those driving the slowest 
ones. J. Neurosci. 29, 13566–13577 (2009).
	11.	 A. A. Penn, C. J. Shatz, Brain waves and brain wiring: The role of endogenous and sensory-
driven neural activity in development. Pediatr. Res., 45 (4 Pt 1), 447–458 (1999).
	12.	 T. N. Wiesel, D. H. Hubel, Comparison of the effects of unilateral and bilateral eye closure 
on cortical unit responses in kittens. J. Neurophysiol. 28, 1029–1040 (1965).
	13.	 V. Moreno-Juan, A. Filipchuk, N. Antón-Bolaños, C. Mezzera, H. Gezelius, B. Andrés, 
L. Rodríguez-Malmierca, R. Susín, O. Schaad, T. Iwasato, R. Schüle, M. Rutlin, S. Nelson, 
S. Ducret, M. Valdeolmillos, F. M. Rijli, G. López-Bendito, Prenatal thalamic waves regulate 
cortical area size prior to sensory processing. Nat. Commun. 8, 14172 (2017).
	14.	 L. C. Kat, C. J. Shatz, Synaptic activity and the construction of cortical circuits. Science 274, 
1133–1138 (1996).
	15.	 Y. Ben-Ari, Developing networks play a similar melody. Trends Neurosci. 24, 353–360 
(2001).
	16.	 X. Leinekugel, I. Khalilov, Y. Ben-Ari, R. Khazipov, Giant depolarizing potentials: The septal 
pole of the hippocampus paces the activity of the developing intact septohippocampal 
complex in vitro. J. Neurosci. 18, 6349–6357 (1998).
	17.	 S. Gretenkord, J. K. Kostka, H. Hartung, K. Watznauer, D. Fleck, A. Minier-Toribio, M. Spehr, 
I. L. Hanganu-Opatz, Coordinated electrical activity in the olfactory bulb gates 
the oscillatory entrainment of entorhinal networks in neonatal mice. PLOS Biol. 17, 
e2006994 (2019).
	18.	 M. Meister, R. O. Wong, D. A. Baylor, C. J. Shatz, Synchronous bursts of action potentials 
in ganglion cells of the developing mammalian retina. Science 252, 939–943 (1991).
	19.	 R. Yuste, A. Peinado, L. C. Katz, Neuronal domains in developing neocortex. Science 257, 
665–669 (1992).
	20.	 R.-w. Zhang, W.-j. Du, D. a. Prober, J.-L. Du, Muller glial cells participate in retinal waves 
via glutamate transporters and AMPA receptors. Cell Rep. 27, 2871–2880.e2 (2019).
	21.	 T. A. Babola, S. Li, A. Gribizis, B. J. Lee, J. B. Issa, H. C. Wang, M. C. Crair, D. E. Bergles, 
Homeostatic control of spontaneous activity in the developing auditory system. 
Neuron 99, 511–524.e5 (2018).
	22.	 N. Miyasaka, K. Morimoto, T. Tsubokawa, S.-i. Higashijima, H. Okamoto, Y. Yoshihara, 
From the olfactory bulb to higher brain centers: Genetic visualization of secondary 
olfactory pathways in zebrafish. J. Neurosci. 29, 4756–4767 (2009).
	23.	 B.-b. Zhang, Y.-y. Yao, H.-f. Zhang, K. Kawakami, J.-l. Du, Left habenula mediates 
light-preference behavior in zebrafish via an asymmetrical visual pathway. Neuron 93, 
914–928.e4 (2017).
	24.	 K. J. Turner, T. A. Hawkins, J. Yáñez, R. Anadón, S. W. Wilson, M. Folgueira, Afferent 
connectivity of the zebrafish habenulae. Front. Neural Circuits 10, 30 (2016).
	25.	 M. Matsumoto, O. Hikosaka, Lateral habenula as a source of negative reward signals 
in dopamine neurons. Nature 447, 1111–1115 (2007).
	26.	 I. Lazaridis, O. Tzortzi, M. Weglage, A. Märtin, Y. Xuan, M. Parent, Y. Johansson, J. Fuzik, 
D. Fürth, L. E. Fenno, C. Ramakrishnan, G. Silberberg, K. Deisseroth, M. Carlén, K. Meletis, 
A hypothalamus-habenula circuit controls aversion. Mol. Psychiatry 24, 1351–1368 
(2019).
	27.	 E. R. Duboué, E. Hong, K. C. Eldred, M. E. Halpern, Left habenular activity attenuates fear 
responses in larval zebrafish. Curr. Biol. 27, 2154–2162.e3 (2017).
	28.	 Y. Yang, Y. Cui, K. Sang, Y. Dong, Z. Ni, S. Ma, H. Hu, Ketamine blocks bursting in the lateral 
habenula to rapidly relieve depression. Nature 554, 317–322 (2018).
	29.	 T. N. deCarvalho, A. Subedi, J. Rock, B. D. Harfe, C. Thisse, B. Thisse, M. E. Halpern, E. Hong, 
Neurotransmitter map of the asymmetric dorsal habenular nuclei of zebrafish. Genesis 52, 
636–655 (2014).
	30.	 S. Pandey, K. Shekhar, A. Regev, A. F. Schier, Comprehensive identification and spatial 
mapping of habenular neuronal types using single-cell RNA-seq. Curr. Biol. 28, 
1052–1065.e7 (2018).
	31.	 M. Agetsuma, H. Aizawa, T. Aoki, R. Nakayama, M. Takahoko, M. Goto, T. Sassa, R. Amo, 
T. Shiraki, K. Kawakami, T. Hosoya, S.-i. Higashijima, H. Okamoto, The habenula is crucial 
for experience-dependent modification of fear responses in zebrafish. Nat. Neurosci. 
13, 1354–1356 (2010).
	32.	 R. Amo, H. Aizawa, M. Takahoko, M. Kobayashi, R. Takahashi, T. Aoki, H. Okamoto, 
Identification of the zebrafish ventral habenula as a homolog of the mammalian lateral 
habenula. J. Neurosci. 30, 1566–1574 (2010).
	33.	 R. Amo, F. Fredes, M. Kinoshita, R. Aoki, H. Aizawa, M. Agetsuma, T. Aoki, T. Shiraki, 
H. Kakinuma, M. Matsuda, M. Yamazaki, M. Takahoko, T. Tsuboi, S.-i. Higashijima, 
N. Miyasaka, T. Koide, Y. Yabuki, Y. Yoshihara, T. Fukai, H. Okamoto, The habenulo-raphe 
serotonergic circuit encodes an aversive expectation value essential for adaptive active 
avoidance of danger. Neuron 84, 1034–1048 (2014).
	34.	 E. Dreosti, N. V. Llopis, M. Carl, E. Yaksi, S. W. Wilson, Left-right asymmetry is required 
for the habenulae to respond to both visual and olfactory stimuli. Curr. Biol. 24, 440–445 
(2014).
	35.	 S. K. Jetti, N. Vendrell-Llopis, E. Yaksi, Spontaneous activity governs olfactory 
representations in spatially organized habenular microcircuits. Curr. Biol. 24, 434–439 
(2014).
	36.	 M.-Y. Chou, R. Amo, M. Kinoshita, B.-W. Cherng, H. Shimazaki, M. Agetsuma, T. Shiraki, 
T. Aoki, M. Takahoko, M. Yamazaki, S.-i. Higashijima, H. Okamoto, Social conflict 
resolution regulated by two dorsal habenular subregions in zebrafish. Science 352, 87–90 
(2016).
	37.	 A. S. Andalman, V. M. Burns, M. Lovett-Barron, M. Broxton, B. Poole, S. J. Yang, 
L. Grosenick, T. N. Lerner, R. Chen, T. Benster, P. Mourrain, M. Levoy, K. Rajan, 
K. Deisseroth, Neuronal dynamics regulating brain and behavioral state transitions. Cell 
177, 970–985.e20 (2019).
	38.	 H. Aizawa, M. Goto, T. Sato, H. Okamoto, Temporally regulated asymmetric neurogenesis 
causes left-right difference in the zebrafish habenular structures. Dev. Cell 12, 87–98 
(2007).
	39.	 I. H. Bianco, M. Carl, C. Russell, J. D. W. Clarke, S. W. Wilson, Brain asymmetry is encoded at 
the level of axon terminal morphology. Neural Dev. 3, 9 (2008).
	40.	 Y. Hashikawa, K. Hashikawa, M. A. Rossi, M. L. Basiri, Y. Liu, N. L. Johnston, O. R. Ahmad, 
G. D. Stuber, Transcriptional and spatial resolution of cell types in the mammalian 
habenula. Neuron 106, 743–758.E5 (2020).
	41.	 N. Vladimirov, Y. Mu, T. Kawashima, D. V. Bennett, C.-T. Yang, L. L. Looger, P. J. Keller, 
J. Freeman, M. B. Ahrens, Light-sheet functional imaging in fictively behaving zebrafish. 
Nat. Methods 11, 883–884 (2014).
	42.	 C. Satou, Y. Kimura, H. Hirata, M. L. Suster, K. Kawakami, S.-i. Higashijima, Transgenic tools 
to characterize neuronal properties of discrete populations of zebrafish neurons. 
Development 140, 3927–3931 (2013).
	 43.	 S. Krishnan, A. S. Mathuru, C. Kibat, M. Rahman, C. E. Lupton, J. Stewart, A. Claridge-Chang, 
S.-C. Yen, S. Jesuthasan, The right dorsal habenula limits attraction to an odor 
in zebrafish. Curr. Biol. 24, 1167–1175 (2014).
	44.	 E. K. Scott, H. Baier, The cellular architecture of the larval zebrafish tectum, as revealed by 
gal4 enhancer trap lines. Front. Neural Circuits 3, 13 (2009).
	45.	 T. Koide, N. Miyasaka, K. Morimoto, K. Asakawa, A. Urasaki, K. Kawakami, Y. Yoshihara, 
Olfactory neural circuitry for attraction to amino acids revealed by transposon-mediated 
gene trap approach in zebrafish. Proc. Natl. Acad. Sci. U.S.A. 106, 9884–9889 (2009).
	46.	 F. Kermen, L. Darnet, C. Wiest, F. Palumbo, J. Bechert, O. Uslu, E. Yaksi, Stimulus-specific 
behavioral responses of zebrafish to a large range of odors exhibit individual variability. 
BMC Biol. 18, 66 (2020).
	47.	 A. S. Mathuru, C. Kibat, W. F. Cheong, G. Shui, M. R. Wenk, R. W. Friedrich, S. Jesuthasan, 
Chondroitin fragments are odorants that trigger fear behavior in fish. Curr. Biol. 22, 
538–544 (2012).
	48.	 H. A. Burgess, M. Granato, Sensorimotor gating in larval zebrafish. J. Neurosci. 27, 
4984–4994 (2007).
	49.	 E. Yaksi, B. Judkewitz, R. W. Friedrich, Topological reorganization of odor representations 
in the olfactory bulb. PLOS Biol. 5, e178 (2007).
	50.	 G. Buzsaki, A. Draguhn, Neuronal oscillations in cortical networks. Science 304, 
1926–1929 (2004).
	51.	 S. A. Romano, V. Pérez-Schuster, A. Jouary, J. Boulanger-Weill, A. Candeo, T. Pietri, 
G. Sumbre, An integrated calcium imaging processing toolbox for the analysis 
of neuronal population dynamics. PLOS Comput. Biol. 13, e1005526 (2017).
	52.	 O. Randlett, C. L. Wee, E. A. Naumann, O. Nnaemeka, D. Schoppik, J. E. Fitzgerald, 
R. Portugues, A. M. B. Lacoste, C. Riegler, F. Engert, A. F. Schier, Whole-brain activity 
mapping onto a zebrafish brain atlas. Nat. Methods 12, 1039–1046 (2015).
	53.	 S.-Y. Yeo, M. J. Kim, H.-S. Kim, T.-L. Huh, A. B. Chitnis, Fluorescent protein expression 
driven by her4 regulatory elements reveals the spatiotemporal pattern of Notch 
signaling in the nervous system of zebrafish embryos. Dev. Biol. 301, 555–567 (2007).
	54.	 S. Govindan, P. Oberst, D. Jabaudon, In vivo pulse labeling of isochronic cohorts 
of cells in the central nervous system using FlashTag. Nat. Protoc. 13, 2297–2311 
(2018).
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
 Fore et al., Sci. Adv. 2020; 6 : eaaz3173     4 September 2020
SCIE N C E A D V A NCES | RESEA R CH  A RT ICL E
17 of 17
	55.	 E. W. Olstad, C. Ringers, J. N. Hansen, A. Wens, C. Brandt, D. Wachten, E. Yaksi, 
N. Jurisch-Yaksi, Ciliary beating compartmentalizes cerebrospinal fluid flow in the brain 
and regulates ventricular development. Curr. Biol. 29, 229–241.e6 (2019).
	56.	 J. G. M. Bergboer, C. Wyatt, C. Austin-Tse, E. Yaksi, I. A. Drummond, Assaying sensory 
ciliopathies using calcium biosensor expression in zebrafish ciliated olfactory neurons. 
Cilia 7, 2 (2018).
	57.	 R.-K. Cheng, S. Krishnan, Q. Lin, C. Kibat, S. Jesuthasan, Characterization of a thalamic 
nucleus mediating habenula responses to changes in ambient illumination. BMC Biol. 15, 
104 (2017).
	58.	 M. R. Warden, A. Selimbeyoglu, J. J. Mirzabekov, M. Lo, K. R. Thompson, S.-Y. Kim, 
A. Adhikari, K. M. Tye, L. M. Frank, K. Deisseroth, A prefrontal cortex-brainstem neuronal 
projection that controls response to behavioural challenge. Nature 492, 428–432 (2012).
	59.	 H.-p. Xu, M. Furman, Y. S. Mineur, H. Chen, S. L. King, D. Zenisek, Z. J. Zhou, D. A. Butts, 
N. Tian, M. R. Picciotto, M. C. Crair, An instructive role for patterned spontaneous retinal 
activity in mouse visual map development. Neuron 70, 1115–1127 (2011).
	60.	 Y. Cui, Y. Yang, Z. Ni, Y. Dong, G. Cai, A. Foncelle, S. Ma, K. Sang, S. Tang, Y. Li, Y. Shen, 
H. Berry, S. Wu, H. Hu, Astroglial Kir4.1 in the lateral habenula drives neuronal bursts 
in depression. Nature 554, 323–327 (2018).
	61.	 C. D. Verdugo, S. Myren-Svelstad, E. Aydin, E. Van Hoeymissen, C. Deneubourg, 
S. Vanderhaeghe, J. Vancraeynest, R. Pelgrims, M. I. Cosacak, A. Muto, C. Kizil, 
K. Kawakami, N. Jurisch-Yaksi, E. Yaksi, Glia-neuron interactions underlie state transitions 
to generalized seizures. Nat. Commun. 10, 3830 (2019).
	62.	 S. Hong, O. Hikosaka, The globus pallidus sends reward-related signals to the lateral 
habenula. Neuron 60, 720–729 (2008).
	63.	 P. Lal, H. Tanabe, M. L. Suster, D. Ailani, Y. Kotani, A. Muto, M. Itoh, M. Iwasaki, H. Wada, 
E. Yaksi, K. Kawakami, Identification of a neuronal population in the telencephalon 
essential for fear conditioning in zebrafish. BMC Biol. 16, 45 (2018).
	64.	 J. W. von Trotha, P. Vernier, L. Bally-Cuif, Emotions and motivated behavior converge 
on an amygdala-like structure in the zebrafish. Eur. J. Neurosci. 40, 3302–3315 (2014).
	65.	 G. Furlan, V. Cuccioli, N. Vuillemin, L. Dirian, A. J. Muntasell, M. Coolen, N. Dray, S. Bedu, 
C. Houart, E. Beaurepaire, I. Foucher, L. Bally-Cuif, Life-long neurogenic activity 
of individual neural stem cells and continuous growth establish an outside-in 
architecture in the teleost pallium. Curr. Biol. 27, 3288–3301.e3 (2017).
	66.	 N. Jurisch-Yaksi, E. Yaksi, C. Kizil, Radial glia in the zebrafish brain: Functional, structural, 
and physiological comparison with the mammalian glia. Glia, (2020).
	67.	 M. B. Luskin, C. J. Shatz, Neurogenesis of the cat's primary visual cortex. J. Comp. Neurol. 
242, 611–631 (1985).
	68.	 J. A. Lister, C. P. Robertson, T. Lepage, S. L. Johnson, D. W. Raible, Nacre encodes 
a zebrafish microphthalmia-related protein that regulates neural-crest-derived pigment 
cell fate. Development 126, 3757–3767 (1999).
	69.	 H.-C. Park, C.-H. Kim, Y.-K. Bae, S.-Y. Yeo, S.-H. Kim, S.-K. Hong, J. Shin, K.-W. Yoo, M. Hibi, 
T. Hirano, N. Miki, A. BChitnis, T.-L. Huh, Analysis of upstream elements in the HuC 
promoter leads to the establishment of transgenic zebrafish with fluorescent neurons. 
Dev. Biol. 227, 279–293 (2000).
	70.	 F. Kermen, P. Lal, N. G. Faturos, E. Yaksi, Interhemispheric connections between olfactory 
bulbs improve odor detection. PLoS Biol. 18, e3000701 (2020).
	71.	 I. Reiten, F. E. Uslu, S. Fore, R. Pelgrims, C. Ringers, C. D. Verdugo, M. Hoffman, P. Lal, 
K. Kawakami, K. Pekkan, E. Yaksi, N. Jurisch-Yaksi, Motile-cilia-mediated flow improves 
sensitivity and temporal resolution of olfactory computations. Curr. Biol. 27, 166–174 
(2017).
	72.	 Bergen, J. R., Anandan, P., Hanna, K. J., Hingorani, R. Hierarchical model-based motion 
estimation, in ECCV ’92; Proceedings of the Second European Conference on Computer 
Vision (Springer Berlin Heidelberg, 1992), pp. 237–252.
Acknowledgments: We thank M. Ahrens (HHMI, Janelia Farm, USA), C. Wyart (ICM, Paris, 
France), H. Baier (MPI, Martinsried, Germany), and S.-i. Higashijima (Okazaki Institute for 
Integrative Bioscience, Japan) for transgenic lines. We thank S. Eggen, M. Andresen, V. Nguyen, 
and our fish facility support team for technical assistance. We thank the Yaksi laboratory 
members for stimulating discussions. Funding: This work was funded by ERC starting grant 
335561 (S.F. and E.Y.), Helse Midt-Norge Samarbeidsorganet grant (N.J.-Y. and E.Y.), RCN 
FRIPRO Research Grant 239973 (E.Y.), and Boehringer Ingelheim Fonds (C.R.). Work in the 
E.Y. laboratory is funded by the Kavli Institute for Systems Neuroscience at NTNU. Ethics 
statement: All experimental procedures performed on zebrafish larvae and juveniles were in 
accordance with the Directive 2010/63/EU of the European Parliament and the Council of the 
European Union and approved by the Norwegian Food Safety Authorities and Landesdirektion 
Sachsen, Germany (permit numbers TVV-52/2015 and TVV-35/2016). Author contributions: 
Conceptualization: S.F. and E.Y. Methodology and data: S.F., F.A-H., K.A.M., E.M.B., B.S., N.G.F., 
K.T.P.C., M.I.C., N.J.-Y., and C.K. Data analysis: S.F., F.A-H., K.A.M., E.M.B., B.S., N.G.F., K.T.P.C., 
C.D.V., F.P., C.R., and N.J.-Y. Investigation: all authors. Writing: S.F., F.A-H., and E.Y. Review and 
editing: all authors. Funding acquisition and supervision: E.Y. Competing interests: The 
authors declare that they have no competing interests. Data and materials availability: All 
data needed to evaluate the conclusions in the paper are present in the paper and/or the 
Supplementary Materials. Additional data related to this paper may be requested from the 
authors.
Submitted 29 August 2019
Accepted 17 July 2020
Published 4 September 2020
10.1126/sciadv.aaz3173
Citation: S. Fore, F. Acuña-Hinrichsen, K. A. Mutlu, E. M. Bartoszek, B. Serneels, N. G. Faturos, 
K. T. P. Chau, M. I. Cosacak, C. D. Verdugo, F. Palumbo, C. Ringers, N. Jurisch-Yaksi, C. Kizil, 
E. Yaksi, Functional properties of habenular neurons are determined by developmental stage 
and sequential neurogenesis. Sci. Adv. 6, eaaz3173 (2020).
Downloaded from https://www.science.org at Oslo & Akershus University Col. of Applied Science on February 04, 2025
",10.1126/sciadv.aaz3173,doc1,"Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 1 of 17 D E V E LOPM ENTAL NE U ROS C IE NC E Functional properties of habenular neurons are determined by developmental stage and sequential neurogenesis Stephanie Fore1, Francisca Acuña-Hinrichsen1, Kadir Aytac Mutlu1, Ewelina Magdalena Bartoszek1, Bram Serneels1, Nicholas Guy Faturos1, Khac Thanh Phong Chau1, Mehmet Ilyas Cosacak2, Carmen Diaz Verdugo1, Fabrizio Palumbo1, Christa Ringers1, Nathalie Jurisch-Yaksi1,3,4, Caghan Kizil2,5, Emre Yaksi1* The developing brain undergoes drastic alterations. Here, we investigated developmental changes in the habenula, a brain region that mediates behavioral flexibility during learning, social interactions, and aversive experiences. We showed that developing habenular circuits exhibit multiple alterations that lead to an increase in the structural and functional diversity of cell types, inputs, and functional modules. As the habenula develops, it sequentially transforms into a multisensory brain region that can process visual, olfactory, mechanosensory, and aversive stimuli. Moreover, we observed that the habenular neurons display spatiotemporally structured sponta- neous activity that shows prominent alterations and refinement with age. These alterations in habenular activity are accompanied by sequential neurogenesis and the integration of distinct neural clusters across development. Last, we revealed that habenular neurons with distinct functional properties are born sequentially at distinct developmental time windows. Our results highlight a strong link between the functional properties of habenular neurons and their precise birthdate. INTRODUCTION During development and maturation, the functional capacity of brain circuits increases to support the animals’ expanding behavioral repertoire. For example, while a young zebrafish larva mostly needs to avoid threats and find food, more cognitively demanding behav- iors such as associative learning (1, 2) or social interactions (3) emerge later in development during the juvenile stage around 3 to 4 weeks. Such an expansion of the behavioral repertoire is a feature that is conserved across vertebrates (4) and is often accompanied with the development, establishment, and maturation of distinct circuit components generating functional modules within the brain (5). Hence, brain development and maturation is not only a linear expansion of the already existing building blocks but also a sequential increase in the diversity of functional modules and cell types. In the cortex, for example, individual layers are born at different time points, with deep layers being born earlier than superficial layers (6), creating a diversity in the cytoarchitecture of cortical layers and regions with distinct functions (5, 7). Similarly, this chronological order of neurogenesis in larval zebrafish hindbrain and spinal cord was shown to generate functional diversity of neurons, which underlies increased sophistication of behaviors across development (8–10). The maturation and refinement of the developing brain rely on neural activity that can be evoked by sensory inputs (11, 12) or spontaneously generated (11, 13). In most sensory systems, sensory-­ evoked activity was shown to be critical for the maturation of neural circuits and the refinement of topographical maps (12, 14). The appearance of spontaneous activity of the developing brain starts early and coincides with periods of intense synaptogenesis and neu- ronal growth (15). For example, spontaneous activity bursts were observed in the visual, auditory, and somatosensory systems and are shown to be important for the remodeling of these structures (13, 14). In higher brain regions, such as the hippocampus, large and slow bursts are observed (16) before the appearance of faster rhythms and the patterned activity of the adult hippocampus asso- ciated with learning and memory. Furthermore, spontaneous activ- ity is also involved in the maturation of connections across distant brain regions, as observed between the olfactory bulb and the ento- rhinal cortex (17). Last, the synchronous bursting during sponta- neous activity that is important in establishing neural connectivity was shown to be mediated via excitatory connections (18), gap junctions (19), glial cells (20), or other support cells (21). Together, both sensory-driven and spontaneous neural activity are essential in the development and maturation of neural circuits. It is, however, less clear how sensory-evoked and spontaneous neural activity interact as the animals develop. While the majority of studies have focused on the development of sensory and motor systems, less is known about the maturation of higher brain areas integrating information from multiple brain regions, such as the habenula. The habenula is a particularly inter- esting brain region, as it was shown to integrate both sensory (22, 23) and corticolimbic inputs (24–26) while directly regulating the function of monoaminergic brain nuclei controlling behavior (23, 25, 27). Dysfunction of the habenula is also shown to be associated with several neurological conditions and mood disorders including depression (28). The habenula is composed of several subdomains or modules based on its neurochemical profiles (29, 30), anatomical projections (31–33), and the activity of habenular neurons (33–35). 1Kavli Institute for Systems Neuroscience and Centre for Neural Computation, Faculty of Medicine and Health Sciences, Norwegian University of Science and Technology, Olav Kyrres gata 9, 7030 Trondheim, Norway. 2German Center for Neurodegenerative Diseases (DZNE) Dresden, Helmholtz Association, Tatzberg 41, 01307 Dresden, Germany. 3Department of Clinical and Molecular Medicine, Norwegian University of Science and Technology, Olav Kyrres Gate 9, 7030 Trondheim, Norway. 4Department of Neurology and Clinical Neurophysiology, St Olav University Hospital, Edvard Griegs Gate 8, 7030 Trondheim, Norway. 5Center for Molecular and Cellular Bioengineering (CMCB), TU Dresden, Fetscherstr. 105, 01307 Dresden, Germany. *Corresponding author. Email: emre.yaksi@ntnu.no Copyright © 2020 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC). Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 2 of 17 Two major subnuclei, the lateral and medial habenula in mammals, respectively, and the dorsal habenula (dHb) and ventral habenula (vHb) in zebrafish, have clear differences in their functional and molecular profiles (33). While the dHb is involved in sensory processing (23, 34, 35), aggression (36), and experience-dependent fear response (27, 31), the vHb was shown to play a role in avoidance learning (33) and active coping behavior (37). In zebrafish, dHb and vHb originate from separate neural progenitor pools and were suggested to maturate at distinct developmental time points (32). Moreover, the dHb was shown to undergo asymmetric neurogenesis during the early stages of devel- opment, with left dHb neurons being born earlier than the ones in the right hemisphere (38). The prominent asymmetry in the molecular (29) and anatomical properties of habenula (39) is also reflected in its asymmetric encoding of visual and olfactory information in the left and the right dHb hemispheres, respectively (34, 35). Recent transcriptome analysis further revealed multiple molecularly distinct and spatially organized functional modules within the zebrafish (30) and mammalian (40) habenula, which resemble the spatially organized functional clusters of habenular neurons during spontaneous activity (35). All of these evidences suggest a fine spatial organization of distinct functional modules within habenula (35). In addition, spontaneous habenular activity was shown to govern sensory responses and, therefore, proposed to represent internal states of the network, which could mediate the selection of appropriate behaviors (35). A recent study revealed a sequential recruitment of neurons generating an increase in vHb activity, during the switch from active to passive coping behaviors in juvenile zebrafish (37). Such complex behaviors emerge at later stages of zebrafish development (1, 3), suggesting pronounced changes in the underlying circuitry across the brain. Despite extensive characterization of habenular circuitry during very early developmental stages (29, 38, 39), it is still unclear how the maturation of habenular networks during development corre- sponds to the establishment of its distinct functional modules. In this study, we investigated how the function and the architecture of habenular networks change across development and how these alterations relate to the formation of distinct functional modules within habenula. We showed that as the habenula expands, the number of neurons increases, inhibitory connections are formed, and sensory inputs are integrated with a temporal order. Moreover, we revealed that the habenula is a multisensory brain region, which distinctly encodes different sensory modalities. Visual and olfactory responses in habenula develop early, while the responses to mechanosensory and aversive stimuli develop at later stages. Spontaneous habenular activity is present already at early developmental stages, and it is predictive of the habenular neurons with sensory responses. We observed a prominent restructuring of both spatial and temporal features of spontaneous habenular activity during development. These functional changes in the habenula were accompanied by a sequential and spatially organized addition of newly born neurons across development. Last, we showed that habenular neurons born at a distinct developmental stage exhibit similar functional properties. Our observations support the idea that neuronal birthdate and function are strongly related. RESULTS New neurons and new inhibitory connections are added to habenula during development To study the functional development of zebrafish habenula, we focused on three developmental stages: early larval stage [3 days post-fertilization (dpf)], late larval stage (6 dpf), and juvenile stage (21 dpf). During these periods, zebrafish transition from self-feeding larvae (via the yolk sac) to an external feeding juvenile animal with more complex behaviors including those involving habenular circuits (1, 3, 31, 33, 37). First, we visualized the gross morphology of habenula in Tg(elavl3:GCaMP6s) (41) zebrafish, labeling most habenular neurons. We observed that the number of habenular neurons increases drastically from 3 to 21 days of zebrafish development (Fig. 1, A and B). Next, we investigated the expression of glutamate and -aminobutyric acid (GABA) by using Tg(vglut2a:dsRed) (22) and Tg(gad1b:GFP) (42) zebrafish. We found that at 3 dpf, habenula mainly consists of glutamatergic neurons, and as the animal gets older, few GABAergic neurons are added (Fig. 1C). From 6 dpf, we also observed prominent bilateral GABAergic projections that innervate specific domains at the lateral sides of habenula (Fig. 1C). These results suggest that habenula undergoes a nonlinear expansion with the addition of new cell types and inputs arriving at different time points throughout development. Sensory inputs and computations in habenula follow a developmental order Previous studies showed that habenula receives olfactory (22) and visual (23) inputs and responds to both of these sensory modalities (34, 35, 43). To investigate how these sensory inputs maturate during habenula development, we visualized the mitral cell and thalamic axon terminals in habenula using Tg(lhx2a:gap-YFP) (22) and Et(−0.6hsp70l:Gal4-VP16) s1020t; Tg(UAS:nfsB-mCherry) (31, 44) zebrafish lines, respectively. At all ages, thalamic projections were found to innervate habenula (Fig. 2A, blue) in distinct locations that are different from GABAergic innervations (Fig. 2A, white) or mitral cell terminals (Fig. 2A, red). Yet, the density of olfactory bulb projections increased with age (Fig. 2A, red). These findings suggest that habenular neurons may be predominantly light responsive at younger ages, while odor responses develop later. To test this hypothesis, we measured odor (food odor) and light (red light flash) responses in the habenula by using two-photon calcium imaging in Tg(elavl3:GCaMP6s) (41) zebrafish. At 3 dpf, we found that a significantly higher portion of habenular neurons responds to the visual stimulus compared to food odor (Fig. 2, B and C). As zebrafish develop, the ratio of odor- and light-responding neurons became similar (Fig. 2, B and C). At all developmental stages, correlations between visual and olfactory stimuli were relatively low (Fig. 2D). To further test whether the development of sensory responses in habenula is biased toward aversive or attractive stimuli within one sensory modality, we applied amino acid odor, food odor, skin extract, and ammonia, which were previously shown to elicit responses in the zebrafish habenula (35). Moreover, earlier studies revealed that amino acid odor (45) and food odor (46) elicit attraction, and skin extract (47) and ammonia (46) elicit freezing and defensive behaviors. While we did not observe any preference for habenular neurons to respond to aversive or attractive odors in 3-dpf zebrafish larvae, we observed that stimulation with aversive odors resulted in a higher number of responding neurons compared to attractive odors, in four out of four 21-dpf zebrafish (fig. S1, A and B). The correlations between aversive versus attractive odors were low in 3 dpf and increased at 21 dpf (fig. S1, C and D). Previous studies showed that the zebrafish habenula can encode a diverse range of aversive experiences (27, 30, 37). To test the developmental order of zebrafish habenula for encoding aversive Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 3 of 17 Fig. 1. During development, the number of habenular neurons increases and new GABAergic connections are added. (A) Representative examples of three-dimensional reconstructions of habenular neurons detected in Tg(elavl3:GCaMP6s) zebrafish line, using volumetric two-photon calcium imaging at three different developmental ages (3, 6, and 21 dpf). Coronal view. (B) The average number of neurons detected in Tg(elavl3:GCaMP6s) at 3 dpf (n = 9 fish), 6 dpf (n = 6 fish), and 21 dpf (n = 9 fish). **P < 0.01 and ***P < 0.001, t test. Data are presented as means ± SEM. (C) Confocal microscopy projections of habenula in Tg(vglut2a:dsRed) and Tg(gad1b:GFP) double transgenic zebrafish at 3, 6, and 21 dpf, labeling glutamatergic (red) and GABAergic (white) neurons and projections, dorsal view. White arrowheads indicate GABAergic projections. Scale bar, 100 m. L, left hemisphere; R, right hemisphere. Fig. 2. Visual responses dominate larval habenula, while olfactory responses develop later. (A) Confocal microscopy projections of habenula in Tg(Lhx2:gap-YFP); Et(0.6hsp70l:Gal4-VP16) s1020t; Tg(UAS:nfsB-mCherry) and Tg(gad1b:GFP) triple transgenic zebrafish labeling olfactory bulb projections (red), thalamic projections (blue), and GABAergic projections (white), dorsal view. Dashed white lines delineate habenula. Scale bar, 100 m. L, left hemisphere; R, right hemisphere. (B) Top panel shows average responses of odor-responding (red) and light-responding habenular neurons (blue) over four to five trials at 3 dpf (n = 9), 6 dpf (n = 7), and 21 dpf (n = 9) zebrafish. Black bars represent 10% F/F. Shadows represent SEM. Bottom panel shows color-coded sensory responses (F/F) of all individual Hb neurons exposed to 5-s odor (O; red) stimulus (left) and 2-s light (L; blue) stimulus (right) in all fish imaged at 3, 6, and 21 dpf. Black bars represent 1000 neurons. (C) Percentage of odor (red dots) versus light (blue dots) responding neurons at 3, 6, and 21 dpf. ***P < 0.001, paired t test. All data are presented as means ± SEM. (D) Odor (red) versus light (blue) response amplitude of all habenular neurons responses at 3, 6, and 21 dpf. Magenta color depicts the neurons responding to both odor and light. Gray dots represent nonresponsive neurons. Average ± SEM correlations between different stimulus representations by habenular responses are represented by “corr.” Note that at all ages, odor and light responses are dissimilar, depicted by the negative correlations. Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 4 of 17 stimuli, we applied mechanical vibrations (48) and mild electric stimulation (27, 30, 37), both of which were shown to generate aversive reactions in developing zebrafish (27, 30, 37, 48). We also compared these aversive stimuli to visual responses in the habenula evoked by red light. Consistent with our results above (Fig. 2), the zebrafish habenula predominantly responds to visual stimulation at 3 dpf (Fig. 3, A and B). As zebrafish develop, we observed that a signifi- cantly larger number of habenular neurons responded to mild electric stimulation at 6 and 21 dpf (Fig. 3B). Moreover, we observed that significantly larger number of habenular neurons respond to light compared to mechanical vibrations at 6 dpf (Fig. 3B). At 21 dpf, we no longer observed any significant difference between the number of neurons responding to light, electric stimuli, and vibrations (Fig. 3B). These three different stimulus modalities exhibit low correlations at all developmental stages (Fig. 3C). All these results suggest that while the 3-dpf habenula preferentially responds to light, the animal develops significantly more habenular neurons respond to aversive electrical stimuli, as the animal develops. Together, the developing habenula can selectively encode an expanding number of sensory modalities with an increasing preference for aversive electrical stimuli at later stages. Functional lateralization of visual and olfactory responses decreases across development, and it is not prominent for aversive stimuli Earlier studies revealed a strong molecular (29, 32) and functional (34) lateralization of habenular networks, especially across the dHb hemispheres of larval zebrafish. There is no evidence for such lateralization in the rodent habenula, which is mostly studied in adults by using aversive stimuli (25, 26). This made us question whether the ontogeny of functional lateralization in the zebrafish habenula might resemble the phylogeny of the vertebrate habenula, where lateralized responses to light and odors appear first and non- lateralized responses to aversive stimuli develop later. To test this hypothesis, we investigated the lateralization of sensory responses in habenular neurons across zebrafish development. First, we showed that the dorsal sections of habenula, which likely cover the dHb, exhibit lateralized visual and olfactory responses at all ages (Fig. 4, A and B). We quantified this functional lateralization by measuring the ratio of light- versus odor-responding habenular neurons across hemispheres (34) and by using a lateralization index, where 0 represents symmetry and 1 represents complete segregation of light and odor responses across hemispheres. Across development, dHb exhibits high functional lateralization of light and odor responses, when compared to the ventral sections of habenula (Fig. 4B). Yet, we also observed that the functional lateralization of habenular circuits significantly decreases across development (Fig. 4, C and D). Despite this decrease, light and odor responses exhibit prominent spatial organization (Fig. 4E), quantified by the focality index, ranging from 0 (for random spatial distribution of sensory responses) to 1 (for maximally focal sensory responses) (49). Instead, aversive stimuli elicited no such lateralization across habenular hemispheres (fig. S2), resembling the nonlateralized aversive cue representations in the rodent habenula (25, 26). These results indicate that functional lateralization is a feature of dHb (34) that develops earlier and preferentially responds to visual and olfactory stimuli. Instead, vHb, Fig. 3. Aversive electrical stimuli and mechanical vibrations are encoded in developing habenula. (A) Top panel shows average responses in habenular neurons to light (L; blue), mild electric stimulation (ES; brown), and mechanical vibrations (V; black) over four to five trials in 3 dpf (n = 11), 6 dpf (n = 9), and 21 dpf (n = 7) zebrafish. Black bars represent 10% F/F. Shadows represent SEM. Bottom panel shows color-coded sensory responses (F/F) of all individual Hb neurons exposed to 2-s light stimulus (left), 1-s mild electric stimulation (middle), and 0.05 s mechanical vibration (right) in all fish imaged at 3, 6, and 21 dpf. Black bars represent 1000 neurons. (B) Percentage of responding neurons to light (blue), mild electric stimulus (brown), and mechanical vibrations (black) at 3, 6, and 21 dpf. *P < 0.05 and **P < 0.01, paired t test for the comparisons within groups and unpaired t test for comparisons between groups. (C) Light (blue) versus mild electric stimulus (brown) versus mechanical vibrations (black) response amplitude of all habenular neuron responses at 3, 6, and 21 dpf. Magenta color depicts the neurons responding to more than one stimulus. Average ± SEM Pearson’s correlation coefficients between different stimulus representations by habenular responses are represented by “corr.” Note that at all ages, different stimulus modalities are distinctly represented, depicted by the negative correlations. All data are presented as means ± SEM. Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 5 of 17 which develops later during development, does not exhibit prominent functional lateralization. Functional clusters of habenular neurons exhibit spatially organized spontaneous activity at all ages In juvenile zebrafish, spatially organized functional clusters of habenular neurons display synchronous bursts of spontaneous activity, which is present even in the absence of sensory inputs (35). It is, however, less clear if such spontaneous activity is also present in younger zebrafish larvae and to what extent it changes across habenular development. To study this, we recorded ongoing habenular activity in the absence of external stimuli at different developmental stages. We observed that clusters of habenular neurons exhibit correlated spontaneous activity already at 3 dpf (Fig. 5A). Next, we investigated the stability of these functional clusters during different time windows, using k-means clustering (35). We showed Fig. 4. Sensory lateralization is prominent in dHb at all ages but decreases with age especially in vHb. (A) Three-dimensional reconstructions of habenular responses to light (blue) and odor (red) stimulation recorded by volumetric two-photon microscopy in Tg(elavl3:GCaMP6s) zebrafish, at 3, 6, and 21 dpf. White dots indicate nonresponding neurons. Coronal view. (B) The ratio of odor (red) versus light (blue) responding neurons in left versus right habenular hemispheres, as well as associated sensory lateralization index at 3 dpf (left), 6 dpf (middle), and 21 dpf (right) zebrafish. Each row represents the average values for neurons within the 10-m plane (from the top to bottom). Shades represent ±SEM; 3 dpf (n = 9 fish), 6 dpf (n = 7 fish), and 21 dpf (n = 9 fish). *P < 0.05, **P < 0.01, and ***P < 0.001, t test. (C) Average lateralization index of light responses for the entire habenula of all fish at 3, 6, and 21 dpf. *P < 0.05 and **P < 0.01, Wilcoxon rank sum test. (D) Average lateralization index of odor responses for the entire habenula of all fish at 3, 6, and 21 dpf. **P < 0.01, Wilcoxon rank sum test. (E) Focality index for odor-responding (red) and light-responding (blue) neurons compared to NR (nonresponding neurons, gray) at 3, 6, and 21 dpf. **P < 0.01 and ***P < 0.001, Wilcoxon signed-rank test. All data are presented as means ± SEM. Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 6 of 17 that at all developmental stages, a large portion of habenular neu- rons that belong to a functional cluster remain in their respective cluster with a significantly higher probability compared to chance levels (Fig. 5B). To investigate the synchrony between the habenular neurons further, we next computed the ratio of significantly posi- tive and negative correlated pairs of habenular neurons. We ob- served that as the animal develops, more pairs of neurons displayed significant and robust positive correlations (Fig. 5C). We did not observe such a change for negative correlations between habenular neurons (Fig. 5D). Next, we investigated the spatial organization of Fig. 5. Spontaneous habenular activity is structured into spatially organized functional clusters of neurons that are preserved during sensory responses, at all ages. (A) Functional clusters of habenular neurons with synchronous spontaneous activity in two different time periods (period 1 and period 2). Three-dimensional reconstruction depicts the spatial locations of all neurons. Each color represents a neuronal cluster with similar spontaneous activity, defined by using k-means clustering. Color-coded neural traces on the right show the spontaneous activity of each neuron that belongs to a given cluster “C.” Warm color represents increased neural activity. Each row represents an example zebrafish at 3, 6, and 21 dpf. D, dorsal; V, ventral; A, anterior; P, posterior. (B) Cluster fidelity, depicting the ratio of neural pairs that remain within the same functional cluster during two different time periods for 3 dpf (n = 9), 6 dpf (n = 6), and 21 dpf (n = 9), compared to shuffled chance levels. *P < 0.05 and **P < 0.01, Wilcoxon signed-rank test. (C) The ratio of neural pairs with significant (P < 0.05) positive correlations during two periods of spontaneous activity. *P < 0.05 and **P < 0.01, Wilcoxon rank sum test. (D) The ratio of neural pairs with significant (P < 0.05) negative correlations during two periods of spontaneous activity. Wilcoxon rank sum test. (E) Relation between pairwise correlation of spontaneous neural activity and the distance between each neuron pair in habenula at 3, 6, and 21 dpf. Dashed lines represent the results when neuron locations are shuffled. ANOVA-n displayed significance over distances (P < 0.001) and over age groups (P < 0.001) indicated with #. (F) Color-coded functional clusters of habenular neurons with synchronous spontaneous activity for an example zebrafish at 3 (top) and 21 (bottom) dpf. On the middle and right panels, odor (red) and light (blue) responses of the same neurons are visualized. Scale bars, 50 m. (G) Cluster selectivity, depicting how odor-responding (red) or light-responding (blue) neurons are distributed into functional clusters based on their spontaneous activity. High selectivity means that both odor- and light-responding neurons belong to fewer clusters compared to the same number of randomly selected nonsensory neurons (gray dots), at 3 and 21 dpf. (H) The ratio of neural pairs with significant (P < 0.05) positive correlations of spontaneous activity, for odor- and light-responsive neurons, when compared to the same number of randomly selected nonsensory neurons, at 3 and 21 dpf. *P < 0.05, **P < 0.01, Wilcoxon signed-rank test. All data are presented as means ± SEM. Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 7 of 17 synchronous habenular activity by plotting the average pairwise correlation of neurons versus the distance between them. We ob- served that while nearby habenular neurons have more correlated spontaneous activity at all developmental stages, they exhibit sig- nificantly stronger correlations during older developmental stages (Fig. 5E). This increase in the ratio (Fig. 5C) and strength (Fig. 5E) of positive correlations is likely due to the maturation of synaptic connections between habenular neurons, as well as the arrival of synaptic inputs to habenula. Next, we investigated whether habenular neurons with correlated spontaneous activity also respond to sensory stimulation similarly and how this changes across development. We observed that, especially at later developmental stages, odor- and light-responsive habenular neurons largely overlap with the distinct functional clusters with correlated spontaneous activity, compared to the same number of randomly selected nonsensory neurons (Fig. 5, F and G). This was also true when comparing sensory responding neurons to all nonresponding neurons (fig. S3). Only in older zebrafish did we observe that odor- or light-responding habenular neurons exhibit a significantly higher ratio of positive correlations during sponta- neous activity, compared to the same number of randomly selected nonsensory habenular neurons (Fig. 5H). These results highlight the developmental maturation of habenular circuits while generat- ing more structured spontaneous activity that better predicts the sensory response characteristics of habenular neurons. Features of spontaneous habenular activity change during development Our results revealed that already at early developmental stages, the habenula exhibits prominent spontaneous activity. In several brain regions, spontaneous activity during early development is generally characterized as large bursts with long quiescent intervals (16), whereas adult brains usually exhibit rhythmic activity at faster frequencies (16, 50). To test whether the temporal features of habenular activity are changing over development, we detected the spontaneous activity bursts (51) (Fig. 6A) and quantified the fre- quency and duration of these events. We observed that as the animals develop, the frequency of spontaneous activity bursts significantly increases (Fig. 6B) and their duration decreases (Fig. 6C). Moreover, while the average activity of habenular neurons decreases (Fig. 6D), a larger proportion of habenular neurons shows spontaneous activity (Fig. 6E) at later developmental stages. These results are in line with the developmental changes observed in other vertebrate brain regions and highlight the maturation of habenular spontaneous activity across development. Next, we asked whether such temporal features (i.e., burst duration and frequency) of spontaneous habenular activity are also spatially organized. We quantified the spatial distribution by using the measure of focality index, ranging from 0 (for random spatial distribution) to 1 (for an extremely focal point) (49). At all developmental stages, the temporal features of habenular spontaneous activity, burst frequency, and duration were highly focal and not randomly dis- tributed (Fig. 6F, also note the mean focality values). To further investigate the spatial distribution of habenular activity at different developmental stages, we adopted a commonly used reporter of neural activity, phospho-ERK (extracellular signal–regulated kinase)/ total-ERK (pERK/tERK) ratio (52). We observed that during early developmental stages, pERK/tERK ratio is distributed rather uniformly across the habenula (Fig. 6, G and H, top), while at later developmental stages, pERK/tERK ratio was concentrated more laterally (Fig. 6, G and H, bottom), indicating a higher neural activity toward the lateral ends of habenula. We also observed that the most silent habenular neurons (black dots in Fig. 5F) were located closer to the medial wall of habenula (Fig. 6I), near the location of habenular neural progenitors labeled in Tg(her4.1:GFP) (53) zebrafish (Fig. 7A). Since the juvenile zebrafish habenula displayed an increased pERK/tERK ratio toward the lateral ends (Fig. 6, G and H) and a higher number of silent neurons toward the medial ends (Fig. 6I), we hypothesized that the mediolateral distribution of habenular neurons at older stages might represent their physiological and developmental maturity. To test this hypothesis, we performed in- tracellular recordings of habenular neurons across the mediolateral axis of juvenile zebrafish at later developmental stages. We observed that the input resistance, a hallmark of developmental maturation of cortical neurons (7), was significantly higher for medial habenular neurons, compared to lateral habenular neurons (Fig. 6J). Together, this suggests that neurons near the lateral ends of habenula might be more mature neurons that are born during early developmental stages, compared to medial habenula neurons born later. Distinct spatial domains of habenular neurons are born through sequential neurogenesis Next, we asked whether the spatial organization of habenula across the mediolateral axis might be a result of sequential neurogenesis across development. To test this hypothesis, we first investigated the location of habenular neurogenesis. We observed that neural progenitors labeled by Tg(her4.1:GFP) (53) expression are located at the medial walls of habenular hemispheres (Fig. 7A). To further investigate the relationship between the birthdate of habenular neurons and their spatial distribution, we labeled habenular neurons born during different developmental stages using 5-bromo-2′-­ deoxyuridine (BrdU) incorporation (Fig. 7B). BrdU birthdating showed that the habenular neurons that are born during distinct developmental stages were spatially organized (Fig. 7C). Moreover, we observed that the birthdate of habenular neurons is a good indi- cator for their spatial location, where oldest neurons (born early in development) mostly occupied the lateral wall of habenula and youngest neurons (born late in development) were closest to the medial wall (Fig. 7, C and D). Next, we developed an in vivo birthdating method to further investigate the distinct clusters of habenular neurons that are born during different developmental stages. To do this, we adopted a previously described approach to label cohorts of mammalian cortical neurons born at distinct developmental stages (54). We achieved this by injecting two different colors (far-red and green) of a fluorescent cell tracer in the telencephalic ventricle (55), near the neural progenitor zone on the medial wall of habenula (Fig. 7A) of 2.5- and 5-dpf zebrafish larvae (Fig. 7E). Fifteen hours after the cell tracer injections, only the cells near the medial wall of habenula were labeled (Fig. 7E). We raised the zebrafish larvae injected with cell tracers of two different colors (far-red and green) until 12 and 21 dpf and visualized the cohorts of birthdated habenular neurons in living juvenile zebrafish (Fig. 7F). Our results revealed a distinct spatial organization of habenular neurons birthdated at 2.5 dpf, compared to the neurons birthdated at 5 dpf (Fig. 7F). Further- more, we observed less than 4% overlap of birthdated neurons by injections at 2.5 versus 5 dpf, highlighting the temporal resolution of our in vivo birthdating method (Fig. 7G). In addition, these Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 8 of 17 experiments also revealed that the number of neurons birthdated at 2.5 dpf was almost double the number of neurons birthdated at 5 dpf (Fig. 7, H and I). This higher rate of habenular neurogenesis at earlier developmental stages is also in line with our observation for a larger number of phospho–histone 3–labeled mitotic cells in habenula at earlier developmental stages (Fig. 7, J to K). Together, our results revealed that sequential neurogenesis in habenula generates spatially organized, nonoverlapping clusters of habenular neurons. Habenular neurons born at a distinct developmental stage form a distinct functional cluster Our results in previous sections indicate a potential relationship be- tween the birthdate of habenular neurons, spatial location, and their functional properties. On the basis of these results, we hypothesized that the habenular neurons that are born together might form distinct functional clusters in habenula, with similar features of spontaneous activity. To test this hypothesis, we injected a far-red fluorescence Fig. 6. Features of habenular spontaneous activity change during development. (A) Individual spontaneous activity bursts (black markings) detected in all habenular neurons at 3, 6, and 21 dpf sorted on the basis of their increasing overall activity rate. Black bars represent 100 neurons. Bottom panel shows individual examples of spontaneous activity traces from three different neurons, with detected events marked with black color. Black bar represents 10% F/F. (B) Average frequency of spontaneous activity bursts in habenular neurons in each zebrafish at 3 dpf (n = 9 fish), 6 dpf (n = 6 fish), and 21 dpf (n = 9 fish). (C) Average duration of spontaneous activity bursts in habenular neurons in each zebrafish. (D) Average spontaneous activity in habenular neurons in each zebrafish, represented as total area under the curve of all detected events. (E) The ratio of spontaneously active neurons with at least one spontaneous activity burst.*P < 0.05, **P < 0.01, and ***P < 0.001, Wilcoxon rank sum test. (F) Three-dimensional reconstructions of habenular neurons based on the duration (left) and frequency of their spontaneous activity events. Frequency and duration are color-coded. Black dots are inactive neurons. Coronal view. Scale bars, 50 m. “foc” represents the focality index as means ± SEM for the temporal features of spontaneous activity bursts, duration, and frequency across all zebrafish and is depicted on top of the individual example’s three-dimensional reconstruction. (G) Confocal microscopy images of pERK/tERK ratio in representative examples of habenula at 3, 6, and 21 dpf in dorsal view. Scale bars, 20 m. White dashed lines delineate the borders of habenula. Note the difference in pERK/tERK ratio between medial and lateral ends of habenula. (H) Quantifications of the normalized pERK/tERK ratio along the mediolateral axis for each age at 3 dpf (n = 15), 6 dpf (n = 17), and 21 dpf (n = 8). Shading represents SEM. (I) The ratio of silent neurons in relation to their normalized mediolateral location along both habenula hemispheres of 3, 6, and 21 dpf. Shading represents SEM. Averages of the two most medial and two most lateral location bins were compared within one age. *P < 0.05 for 3 dpf and **P < 0.01 for 21 dpf, Wilcoxon signed-rank test. (J) Input resistance measured by intracellular recordings of habenular neurons (n = 40) across the mediolateral axis of juvenile zebrafish. Medial neurons (n = 10), central neurons (n = 9), and lateral neurons (n = 21) in 14 fish. **P < 0.01, Wilcoxon rank sum test. All data are presented as means ± SEM. MΩ, megohms. Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 9 of 17 cell tracer to the forebrain ventricles of zebrafish larvae express- ing GCaMP6s at either 2.5 or 5 dpf (Fig. 8, A and K). Later, we raised these animals to 21 dpf and visualized their habenular activity in the green spectrum while identifying birthdated habenular neurons in the far-red spectrum, by using confocal microscopy (Fig. 8, A and K). Our in vivo birthdating injections at 2.5 or 5 dpf allowed us to classify habenular neurons into distinct spatial zones (Zs), where Z1 represents the earliest born (oldest) neurons and Z2 Fig. 7. Distinct spatial domains of habenular neurons are born through sequential neurogenesis. (A) Confocal microscopy images of habenula in Tg(vglut2a:dsRed) and Tg(Her4:GFP) double transgenic zebrafish at 3, 6, and 21 dpf, displaying the glutamatergic neurons (magenta) and potential neuronal progenitors of habenula labeled by Her4 expression (cyan), dorsal view. Scale bar, 50 m. White dashed lines delineate the borders of habenula. (B) Schematic representation of BrdU pulse labeling protocol at 3, 5, 7, 14, and 20 dpf. Animals were raised to 21 dpf before imaging. (C) Confocal microscopy images of 21-dpf habenula (white dashed line) showing distribution of neurons that are born at different developmental stages. Neurons were birthdated by using BrdU (red) pulse labeling, at the developmental stages indicated in each panel. DAPI label marks all cells in blue. Dorsal view. Scale bar, 50 m. (D) Schematic representation of the sequential arrangement of neurons that are born at different developmental stages along the mediolateral axis, dorsal view. (E) Confocal microscopy images of telencephalic ventricle 15 hours postinjection with CellTrace Far Red (red) at 2.5 dpf (left) and a second injection with CellTrace CFSE (cyan) at 5 dpf (right). Dorsal view. Asterisk shows injection site in the telencephalic ventricle. Borders of the zebrafish telencephalon and habenula are delineated by a dashed white line. Scale bar, 50 m. (F) Confocal microscopy images of habenula 1 day postinjection of CellTrace Far Red (red) injected at 2.5 dpf and CellTrace CFSE (cyan) injected at 5 dpf (left panels). Birthdated habenular neurons are located near the medial wall of the habenula. At 12 and 21 dpf (right panels), habenular neurons labeled at 2.5 and 5 dpf exhibit distinct spatial distributions. Borders of the habenula are delineated by a dashed white line. Scale bar, 50 m. (G) The ratio of overlap between the two populations of habenular neurons birthdated by the sequential injections of Far Red and CFSE cell tracers at 2.5 and 5 dpf, respectively, and quantified at 12 dpf (n = 8) and 21 dpf (n = 8). (H) The number of habenular neurons that were born at 2.5 dpf versus 5 dpf, measured at 12 dpf (n = 8) and 21 dpf (n = 8). **P < 0.01, Wilcoxon rank sum test. (I) The ratio of habenular neurons birthdated at 2.5 versus 5 dpf quantified at 12 dpf (n = 8) and 21 dpf (n = 8). (J) Confocal microscopy images of habenula labeled with phospho-H3 antibody (cyan) indicating mitotic cells at 2 and 4 dpf. DAPI label marks all cells in blue. Borders of the habenula are delineated by a dashed white line. Scale bar, 50 m. (K) The number of phospho-H3 positive mitotic cells in the habenula, at 2 and 4 dpf. ***P < 0.001, Wilcoxon rank sum test. All data are presented as means ± SEM. Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 10 of 17 and Z3 represent later-born neurons with descending order of maturity (Z1 > Z2 > Z3) (Fig. 8, G to Q). Our analysis revealed notable differences in the functional features of the spontaneous activity between habenular neurons born at different developmental stages, corresponding to distinct spatial zones. Earlier born habenular neurons displayed stronger spontaneous activity (Fig. 8, B, C, L, and M) with higher frequency (Fig. 8, D to N) and duration (Fig. 8E). Moreover, earlier born habenular neurons showed a significantly larger number of pairwise correlations, compared to later-born habenular neurons (Fig. 8, F and P). Our results suggest that distinct functional clusters of habenular neurons with distinct functional features are born at different developmental stages. To test this idea further, we asked whether the developmentally tagged neurons are also related to the spatially organized functional clusters within habenula, observed earlier (Fig. 4, A to D) (35). To this end, we clustered the spontaneous habenular activity using k-means clustering (Fig. 8, H, I, R, and S) and calculated the overlap between developmentally tagged neurons and functional clusters, using a “cluster selectivity” index (35). If developmentally tagged neurons in different habenular zones overlap with one functional cluster, cluster selectivity would result in 1. We observed that the developmentally tagged habenular neurons in each zone overlap with significantly fewer clusters, when compared to the same number of randomly selected habenular neurons (Fig. 8, J to T). These results revealed that distinct functional clusters of spatially organized habenular neurons are born at distinct developmental stages and exhibit similar features of spontaneous activity. DISCUSSION In this study, we investigated the functional development of habenular circuits in zebrafish across development from young larvae with relatively simple behaviors to juvenile zebrafish with complex behaviors (1–3, 33, 36, 37). The use of juvenile zebrafish is gaining popularity due to their transparent brains and their expanded behavioral repertoire that requires habenular function (1–3, 37). Our results revealed that as the zebrafish develop from the larval to the juvenile stage, habenular circuits undergo multiple transitions in its architecture, sensory computations, and intrin- sically generated spontaneous activity, which could support the expansion of the behavioral repertoire during development. Previous studies indicate the presence of olfactory (34, 35) and visual (23, 34) responses in habenula, which were suggested to be involved in generating odor avoidance (43) and light preference (23). Both visual (20) and olfactory (56) responses are reported in sensory organs of 2.5-day-old zebrafish larvae. However, the precise developmental maturation of these sensory inputs in habenula has not been investigated. Our results revealed that at early develop- mental stages, habenula is first innervated by the visual inputs, which are followed by the olfactory inputs. This is also in line with our observation of light responses dominating habenula of larval zebrafish followed by olfactory responses. We observed that aver- sive mild electric stimulation (27, 30, 37) elicits responses in habenula during later developmental stages. This gradual increase in stimulus diversity of habenular responses likely reflects a devel- opmental transition of habenula into a multisensory processing brain region, which can encode stimulus salience and valance. We observed that visual, olfactory, vibrational, and electric stimuli are distinctly encoded by the activation of separate neural populations. Such distinct encoding of different sensory modalities at all devel- opmental stages highlights the important role of habenula in inte- grating information from multiple sensory systems (23, 34, 35, 43, 57). Future experiments are needed to identify the specific role of habenular circuits for distinguishing salience and valance across multiple sensory modalities. As in other lower vertebrates, zebrafish dHb exhibits prominent molecular (29, 30) and structural asymmetries (39). As expected, habenular lateralization has important consequences with respect to the segregation of different sensory modalities across habenular hemispheres and for regulating the targeting of habenular axons to different output regions (27, 33, 39). We observed that the functional lateralization of sensory inputs and computations in habenula is prominent mostly in the dHb, which develops early during devel- opment (38), whereas we did not observe functional lateralization in vHb, which develops later (32), despite the prominent sensory-­ evoked vHb responses. This developmental order eventually leads to a decrease in functional lateralization across the entire habenula as the animals maturate. Similar to primary sensory systems (12), maturation of zebrafish habenula requires the early presence of sensory inputs (34). When these inputs are removed before a critical time window, zebrafish dHb loses its functional lateralization (34). It is also important to note that aversive stimuli (mechanical vibrations and mild electric stimulation) did not elicit lateralized responses in zebrafish habenula, which is in line with studies performed in the mammalian lateral habenula, where aversive responses showed no apparent lateralization (25, 26, 58). We suggest that the apparent lack of lateralization in the mammalian habenula is due to a continued maturation of lateral habenula dominated by aversive cue responses and reduced availability of sensory information during mammalian in utero development. The activity-dependent maturation of neural circuits does not solely rely on sensory inputs but also includes endogenously gener- ated spontaneous activity (11). In several brain regions, sponta- neously generated activity is thought to play important roles in the maturation of synaptic connections, refining network topography (13, 14, 59) and entraining developing circuits (17). In our study, we observed that habenular networks exhibit spatially organized spon- taneous activity already at early developmental stages. A recent transcriptomics study revealed a topographic organization of habenular neurons based on their distinct molecular features already in 10-day-old zebrafish larvae (30) and likely overlap with the spatially organized spontaneous activity studied here. Whether the spontaneous activity is needed for the proper development of distinct habenular clusters or habenular function, as in other brain regions (13), is yet to be investigated. We also observed that temporal features of habenular sponta- neous activity changed, leading to faster kinetics at older ages. The trend for faster kinetics of intrinsically generated activity across development was also observed in other higher brain regions, such as the hippocampus (16, 50). What may underlie the faster kinetics of spontaneous activity bursts in older ages? It is likely that multiple processes can modulate spontaneous habenular activity leading to the observed dynamical changes during development. One possibility is that early spontaneous activity might be driven by glia (20) or other support cells (21), which usually generate slow bursts of activity. It was previously shown that astrocytes can modulate the bursting activity in the rodent habenula (60), and astroglia activation in Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 11 of 17 Fig. 8. Habenular neurons that are born at a distinct developmental stage exhibit similar functional properties. (A) Confocal microscopy images of elavl3:GCaMP6s (white) zebrafish habenula at 3 (top) and 21 (bottom) dpf, after the injection of the CellTrace Far Red (red) at 2.5 dpf. Dorsal view. Habenula is delineated by a dashed white line. Developmentally tagged, red-labeled neurons at 21 dpf are in zone 1 (Z1 = early born), whereas unlabeled neurons are in zone 2 (Z2 = later born). Scale bar, 100 m. L, left; R, right. (B) The ratio of spontaneously active Z1 (red) versus Z2 (black) habenular neurons at 21 dpf. Note that a higher ratio of early-born habenular neurons in Z1 are active, when compared to later-born neurons in Z2 (n = 21 planes in 12 fish). (C) Average spontaneous activity that is represented as total area under the curve of all detected events, in Z1 versus Z2 habenular neurons at 21 dpf. (D) Average spontaneous activity burst frequency in Z1 versus Z2 habenular neurons at 21 dpf. (E) Average spontaneous activity burst duration in Z1 versus Z2 habenular neurons at 21 dpf. (F) Average pairwise correlations of Z1 versus Z2 habenular neurons at 21 dpf. Note that Z1 neurons are significantly more correlated than Z2 habenular neurons. **P < 0.01 and ***P < 0.001, Wilcoxon signed-rank test. (G) Spatial distribution of labeled early-born (Z1) versus later-born (Z2) habenular neurons, in an example zebrafish at 21 dpf. (H) Spatial distribution of habenular neurons color-coded according to their functional clusters based on their spontaneous activity, using k-means clustering in the same example zebrafish as in (I). (I) Color-coded neural traces showing the spontaneous activity of each habenular neuron that belong to a given cluster “C,” in the same example zebrafish as (G) and (H). Warm colors represent increased neural activity. Note the prominent overlap between the functional cluster C3 (yellow neurons in H) and Z1 neurons in (G). (J) Cluster selectivity of Z1 versus Z2 habenular neurons, when compared to the same number of randomly selected habenular neurons (S) in yellow. Note that both Z1 and Z2 habenular neurons belong to fewer functional clusters compared to an equal number of random neurons. **P < 0.01, Wilcoxon signed-rank test. Also, note that Z1 neurons are significantly more cluster selective than Z2. ***P < 0.001, Wilcoxon rank sum test. (K) Confocal microscopy images of elavl3:GCaMP6s (white) zebrafish habenula at 5 (top) and 21 (bottom) dpf, after the injection of the cell tracer (red) at 5 dpf. Oldest neurons (Z1 = early born) are located lateral to the red-labeled neurons (Z2 = intermediate born) that are developmentally tagged at 5 dpf. The youngest neurons (Z3 = late born) are located medial to the red-labeled neurons. Scale bar, 100 m. L, left; R, right. (L) The ratio of spontaneously active Z1 (gray), Z2 (red), and Z3 (black) habenular neurons at 21 dpf (n = 12 planes in five fish). Note that a higher ratio of Z2 neurons are active, when compared to Z3 neurons. (M) Average spontaneous activity that is represented as total area under the curve of all detected events, in Z1, Z2, and Z3 habenular neurons at 21 dpf. (N) Average spontaneous activity burst frequency in Z1, Z2, and Z3 habenular neurons at 21 dpf. (O) Average spontaneous activity burst duration in Z1, Z2, and Z3 habenular neurons at 21 dpf. (P) Average pairwise correlations of Z1, Z2, and Z3 habenular neurons at 21 dpf. **P < 0.01, Wilcoxon signed-rank test. (Q) Spatial dis- tribution of early-born (Z1), intermediate-born (Z2), and later-born (Z3) habenular neurons, in an example zebrafish at 21 dpf. (R) Spatial distribution of habenular neurons color-coded according to their functional clusters based on their spontaneous activity, using k-means clustering in the same example zebrafish as in (I). (S) Color-coded neural traces showing the spontaneous activity of each habenular neuron that belong to a given cluster “C,” in the same example zebrafish as (G) and (H). Warm colors represents increased neural activity. (T) Cluster selectivity of Z1, Z2, and Z3 habenular neurons, when compared to the same number of randomly selected habenular neu- rons (S) in yellow. Note that Z1, Z2, and Z3 habenular neurons belong to fewer functional clusters compared to equal number of random neurons. ***P < 0.001, Wilcoxon signed-rank test. All data are presented as means ± SEM. Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 12 of 17 zebrafish can excite nearby neurons (61). Alternatively, it is possible that as the habenula develops, synaptic connections between habenular neurons become more mature. Together with the in- creased inhibition we observed in the habenula, by the addition of GABAergic connections, such mature synapses can support faster neural dynamics. Last, part of the habenular spontaneous activity might also be driven by the activation of the ancestral corticolimbic homologs in the zebrafish forebrain. For example, it was shown that habenula is strongly driven by inputs received from entopeduncular nucleus (24, 62), lateral hypothalamus (26), and cortex (58). Hence, it is likely that the homologs of these input regions are not yet fully developed and cannot drive habenular activity in young zebrafish larvae. A recent study showed that the zebrafish equivalent of amygdala (Dm) (63), driving both entopeduncular nucleus and lateral hypo- thalamus (63), also develops during the late juvenile stage (64). Together, we suggest that all these processes jointly contribute to the habenular spontaneous activity. Our results revealed that the developmental changes in the tem- poral kinetics of habenular spontaneous activity are accompanied by the sequential addition of newborn neurons across development. More specifically, we found that the spatially confined locations of neuronal clusters that are born during distinct developmental stages follow a mediolateral arrangement. In this arrangement, youngest neurons are located closer to the neural progenitors of the habenula on the medial wall, while the oldest habenular neurons are located closer to the lateral wall. Similar sequential stacking of newly born neurons was also observed during forebrain development in both zebrafish (65, 66) and rodents (6, 67). Moreover, such a sequential order of neurogenesis contributes to different neural subtypes in the zebrafish hindbrain and spinal cord (8–10), as well as the rodent entorhinal cortex (5). Hence, it is possible that recently described populations of habenular neurons with distinct molecular identities (30) might be born during different developmental stages of the zebrafish habenula. The topographically organized molecular (30) and functional clusters (30, 35, 37) of habenular neurons represent the distinct subdomains or functional modules of habenula and are likely associated with different aspects of animal behavior. Our data revealed that at least two of the functional clusters within habenula are born at two different developmental stages, stay in spatially con- fined locations, and exhibit different functional features. Therefore, we propose that the distinct functional clusters of habenular neu- rons are born at different developmental time points. In turn, such a developmental order could contribute to an increased diversity of habenular neurons and expand habenular function across develop- ment. These ideas are in line with several recent studies that suggest that complex and cognitively demanding behaviors arise later in development as animals maturate (1, 2, 33, 37). Our findings in habenula suggest that such expansion of animal behavior might be due to the incorporation of new functional modules at different developmental time points. In the future, it will be interesting to see whether such sequential addition of new neuronal modules with distinct functional properties is a feature that is not only unique to habenula but also preserved across the brain. MATERIALS AND METHODS Fish maintenance The animal facilities and maintenance of zebrafish, Danio rerio, were approved by the Norwegian Food Safety Authority. Fish were kept in 3.5-liter tanks at a density of 15 to 20 fish per tank in a Techniplast Zebtech Multilinking system at 28°C (pH 7), 6.0 ppm O2, and 700 S, at a 14-hour light/10-hour dark cycle. Fish received a normal diet of dry food (Zebrafeed, Sparos) two times per day and Artemia nauplii once a day (Grade 0, Platinum Label, Argent Laboratories). Larvae were maintained in egg water (1.2 g of marine salt and 0.1% methylene blue in 20 liters of reverse osmosed water) from fertilization to 3 dpf. From 3 to 6 dpf, larvae were kept in artificial fish water (AFW): 1.2 g of marine salt in 20 liters of RO water. Animals used for experiments at 21 dpf were transferred to 3.5-liter tanks in the zebrafish facility at 3 dpf. For experiments, the following fish lines were used: Tg(elavl3:​ GCaMP6s) (41), Tg(gad1b:GFP) (42), Tg(vglut2a:dsRed) (22), Tg(Lhx2a:​ gap-YFP) (22), Et(−0.6hsp70l:Gal4-VP16) s1020t; UAS:nfsB-mCherry (44), and Tg(her4.1:GFP) (53). Experiments were performed on embryos of nacre [mitfa; (68)] background. Confocal anatomical imaging Before embedding, fish were anesthetized with 0.02% tricaine methane- sulfonate (MS-222). Animals were then embedded in 1% (for 3 to 6 dpf) or 2% (for 21 dpf) low–melting point (LMP) agarose (Thermo Fisher Scientific) in a recording chamber (FluoroDish, World Precision Instru- ments) with AFW. Anatomical Z scans were acquired using a Zeiss Examiner Z1 confocal microscope with a 20× water immersion objective [Zeiss; numerical aperture (NA) of 1.0; Plan-Apochromat] at room temperature, using 4× to 10× average for each plane. BrDU labeling, immunostaining, and imaging Labeling of newborn neurons with BrdU was performed at 3.5, 5.5, 7.5, 14.5, and 20.5 dpf in Tg(HuC:GFP) (69) fish outcrossed to wild- type (AB) fish. Embryos (25 hours post-fertilization) were dechori- onated by Proteinase K (0.1 mg/ml; catalog number 25530049) at room temperature and washed several times with 1× E3 medium. A stock of 10 mM BrdU (Sigma-Aldrich, catalog number B5002) in 1× E3 medium was prepared, aliquoted, and stored at −20°C until use. For each treatment, a final concentration of 500 M BrdU was applied to 3- and 5-dpf fish. For 7-, 14-, and 21-dpf fish, 2.5 mM BrdU was used. Treatments were all performed for 5 hours. Fish were kept in a dark incubator until 5 dpf and were transferred to the water system at 6 dpf. From this point on, a 14-hour light/10-hour dark cycle was maintained. At 22 dpf, fish were sacrificed and fixed in 4% paraformaldehyde (PFA) to 1% dimethyl sulfoxide (DMSO) at +4°C overnight, washed with 0.8% Triton X-100 in 1× phosphate-buffered saline (PBS; PBSTx), dehydrated by a serial methanol gradient, and kept at −20°C until further use. For immunohistochemical staining, fish were rehydrated back to the aqueous phase (1× PBS). Brains were dissected out in cold 1× PBS and were incubated in precooled acetone for 10 min at −20°C. Brains were incubated in preheated 2 mM HCl at 37°C for 12 min, cooled at room temperature for 10 min, and washed with 0.8% PBSTx. Samples were incubated in Rat anti-BrdU immunoglobulin G (IgG; 1:200 Bio-Rad, catalog number MCA2060) monoclonal antibody overnight at +4°C. After serial washes in 0.8% PBSTx, the secondary antibody (Goat anti-rat Alexa 555; 1:500 dilution; Thermo Fisher Scientific, catalog numberA-21434) and 4′,6-diamidino-2-phenylindole (DAPI) at 1:3000 dilution were applied. Following an overnight incubation at +4°C, samples were washed for a total of 2 hours with 0.8% PBSTx. To measure pERK/tERK ratio, fish were euthanized and fixed in cooled 4% PFA in 0.25% PBTx (0.25% Triton X-100 in 1× PBS) Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 13 of 17 overnight at 4°C. Samples were permeabilized in 0.50% Trypsin-­ EDTA on ice for 40 min and washed. The samples were then incu- bated in the blocking solution [2% normal goat serum, 1% bovine serum albumin (BSA), and 1% DMSO in 0.25% PBTx] for 1 hour followed by incubation in primary antibody solution [1:500 anti- body (Ab), 1% BSA, and 1% DMSO in 0.25% PBTx] overnight at 4°C. Next, samples were washed and incubated with secondary antibody solution (1:1000 Ab, 1:1000 DAPI, 1% BSA, and 1% DMSO in 0.25% PBTx) overnight at 4°C. Last, samples were washed and placed in glycerol. pERK/tERK ratio of the median z-projection confocal images were calculated in ImageJ (Fiji). The pERK/tERK ratio is normalized by the maximum pERK/tERK ratio and adjusted for the habenular size using a custom-made script in MATLAB. For phospho–histone 3 staining, larvae were fixed in 4% PFA for 2 hours at room temperature or overnight at 4°C. Following washes in 0.3% Triton-X in PBS (0.3% PBSTx), fixed samples were perme- abilized in 100% acetone at −20°C for 20 min and blocked in 0.3% PBSTx containing 0.1% BSA. Samples were incubated with the primary antibody (phospho–histone 3, Santa Cruz Biotechnology, #sc-8656-R; 1:500 dilution) overnight at +4°C, followed by serial washes in 0.3% PBSTx and incubation with the secondary antibody (goat anti-rabbit Alexa 488 plus, Thermo Fisher Scientific, #A-11034, 1:1000 dilution) overnight at +4°C. Next, samples were incubated in DAPI (1:1000) for 2 hours, before serial washes in 0.3% PBSTx. For preservation, samples were transferred to 80% glycerol in 1× PBS and were kept at +4°C in the dark. For imaging, labeled brains were mounted in 80% glycerol on a glass slide with a coverslip. Anatomical Z scans of habenula were acquired using a Zeiss Examin- er Z1 confocal microscope with a 20× plan NA 0.8 objective, using 2× to 10× average for each plane. Phospho–histone 3–positive cells were manually counted on confocal stack using the Cell Counter Plugin of Fiji/ImageJ. In vivo two-photon calcium imaging and sensory stimulation Two-photon calcium imaging was performed on 3-, 6-, and 21-dpf- old Tg(elavl3:GCaMP6s) zebrafish. Before embedding, fish were anesthetized with cold AFW. Animals were then embedded in 1% (for 3 to 6 dpf) and 2% (for 21 dpf) LMP agarose (Thermo Fisher Scientific) in a recording chamber (FluoroDish, World Precision Instruments). LMP agarose solidified for 20 min, and the section covering the nose was carefully removed to expose the nostrils. The animal was then placed under the microscope with constant perfu- sion of AFW bubbled with carbogen (95% O2 and 5% CO2). First, spontaneous activity was measured for 30 min. Afterward, five repetitions of sensory stimuli (red light flash or food odor) were applied. The food odor stimulus was prepared by adding 1 g of standard dried fish food (Zebrafeed, Sparos; <100) in 50 ml of AFW, dissolved for 1 hour, filtered with a 22-m filter, and diluted 1:50 in AFW. For skin extract (70), an adult zebrafish was euthanized in ice-cold water and decapitated, and the skin was peeled off from the body, incubated in 1 ml of AFW, mixed, and centrifuged at 1300 rpm and 4°C for 1 hour. One milliliter of the supernatant was then dissolved in 300 ml of AFW. Amino acid mixture (70) con- tained arginine, asparagine, aspartic acid, alanine, phenylalanine, histidine, and methionine, all diluted in AFW at 10−4 M final con- centration. Ammonium chloride was diluted in AFW at 10−4 M final concentration. The odor stimulus was delivered for 5 s through a tube positioned in the front of the fish, connected to an Arduino Due–controlled high-performance liquid chromatography injection valve (Valco Instruments). Fluorescein (10−4 M) was dissolved in AFW and used to measure the precise onset of odor delivery to the nose at the end of each experiment. For the light stimulus, we used a red LED (LZ1-00R105, LedEngin; 625-nm wavelength) and placed it in the front of the recording chamber near the tube. The light stimulus was a flash of 2-s duration with an intensity of 0.318 mW. Mechanical vibrations were delivered via solenoid tapper (SparkFun Electronics, ROB-10391), via 50-ms application of 6 V. Mild electric stimulation was delivered by tungsten electrodes that passed 1-kHz oscillating current of 0.05 mA for a period of 1 s. The recordings were performed with a two-photon microscope (Scientifica) using a 16× water immersion, long working-distance objective (Nikon, NA 0.8, LWD 3.6). A mode-locked Ti:Sapphire laser (MaiTai Spectra-­ Physics) tuned to 920 nm was used for excitation. Volumetric re- cordings (eight planes with Piezo) were obtained at an acquisition rate of 31.9 Hz for a volume of 1536 × 512 pixels × 8 planes. Total duration of the recordings was 45 to 60 min. Juvenile zebrafish electrophysiological recordings of habenular neurons The experiments were conducted in a juvenile zebrafish brain explant preparation (61). Juvenile zebrafish were euthanized by immersion in ice-cold water, followed by decapitation to ensure death. The head was transferred in cold artificial cerebrospinal fluid (ACSF) bubbled with carbogen (95% O2/5% CO2). The ACSF (70) was composed of the following chemicals diluted in reverse-osmosis purified water: 131 mM NaCl, 2 mM KCl, 1.25 mM KH2PO4, 2 mM MgSO4⋅7H2O, 10 mM glucose, 2.5 mM CaCl2, and 20 mM NaHCO3. The eyes, jaws, and ventral part of the skull were carefully removed using forceps, exposing the habenula. The brain explant was then affixed using tungsten pins to a small petri dish coated with Sylgard (World Precision Instruments) and perfused in constant flow bubbled ACSF. We performed intracellular recordings of single habenular neurons, via borosilicate patch pipettes (10 to 12 megohms) mounted on a MultiClamp 700B amplifier. Electrodes contained the intracellular solution (130 mM k-gluconate, 10 mM Na-gluconate, 10 mM Hepes, 10 mM Na2+-phosphocreatine, 4 mM NaCl, 4 mM adenosine 5′-triphosphate–Mg, and 0.3 mM Na3+-GTP) (70). Negative volt- age steps (−30 mV) of 500 ms were applied to measure the input resistance. In vivo birthdating of neurons Before injections, 2.5-dpf larvae were dechorionated manually and anesthetized in 0.01% MS-222 in AFW for 5 to 10 min. Injections were done on larvae embedded in 1% LMP agarose in AFW and 0.01% MS-222 in AFW. The stock solution contained 5 mM CellTrace Far Red–AM or CellTrace CFSE Cell Proliferation Kit (Thermo Fisher Scientific) dissolved in DMSO provided with the proliferation kit. The injection mixtures contained 0.5 l of this CellTrace Far Red/ DMSO stock solution dissolved in 2.5 l of ACSF with a final con- centration of 1 mM. The ACSF contained the following: 124 mM NaCl, 22 mM d-(+)-glucose, 2.0 mM KCl, 1.6 mM MgSO4·7 H2O, 1.3 mM KH2PO4, 24 mM NaHCO3, and 2.0 mM CaCl2·2H2O. The injection needles were pulled with a Sutter Instrument Co. Model P-2000, from thin-walled borosilicate capillaries (1.00 mm; VWR), with the following settings: heat = 785, filament = 4, velocity = 40, delay = 220, and pull = 70. The needle tip was cut open with forceps afterward, and a pressure injector (Eppendorf Femtojet 4i) was used Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 14 of 17 Table 1. Key resource table presenting the source and identifier of chemicals, transgenic lines, and materials. Reagent or resource Source Identifier Chemicals MS222 (tricaine methanesulfonate) Sigma-Aldrich Catalog number E10521 LMP agarose Thermo Fisher Scientific Catalog number 16520100 PBS Thermo Fisher Scientific Catalog number BR0014G CellTrace Far Red Cell Proliferation Kit Thermo Fisher Scientific Catalog number C34564 CellTrace CFSE Cell Proliferation Kit Thermo Fisher Scientific Catalog number C34554 Proteinase K Thermo Fisher Scientific Catalog number 25530049 BrdU Sigma-Aldrich Catalog number B5002 Triton-X Sigma-Aldrich Catalog number T8787 DMSO Sigma-Aldrich Catalog number D8418 Rat anti-BrdU Bio-Rad Catalog number MCA2060 Rabbit anti-phosphoh3 Santa Cruz Biotechnology Catalog number sc-8656-R Goat anti-rat Secondary Antibody, Alexa 555 Thermo Fisher Scientific Catalog number A-21434 Goat anti-rabbit Secondary Antibody, Alexa 488 plus Thermo Fisher Scientific Catalog number A-11034 p44/42 MAPK Mouse mAb Cell Signaling Technology Catalog number 4696 Phospho-p44/42 MAPK Rabbit mAb Cell Signaling Technology Catalog number 4370 Goat anti-Mouse IgG Secondary Antibody, Alexa Fluor Plus 488 Thermo Fisher Scientific Catalog number A32723 Zebrafish lines Source and brief description Tg(elavl3:GCaMP6s) (41) ZFIN catalog number ZDB-ALT-141023-1, RRID:ZFIN_ZDB-ALT-141023-1 Expresses GCaMP6s panneuronally Tg(gad1:GFP) (42) ZFIN catalog number ZDB-ALT-131127-6, RRID:ZFIN_ZDB-ALT-131127-6 Expresses GFP in GABAergic neurons Tg(vglut2a:dsRed) (22) ZFIN catalog number ZDB-ALT-100505-2, RRID:ZFIN_ZDB-ALT-100505-2 Expresses dsRed in glutamatergic neurons Tg(lhx2a:gap-YFP) (22) ZFIN catalog number ZDB-ALT-100504-12, RRID: ZFIN_ZDB-ALT-100504-12 Expresses membrane tagged YFP in mitral cells Et(−0.6hsp70l:Gal4-VP16) s1020t (44) ZFIN catalog number ZDB-ALT-070420-21, RRID: ZFIN_ZDB-ALT-070420-21 Expresses Gal4 in thalamic neurons Tg(UAS: nfsB-mCherry) (44) Catalog number ZFIN ZDB-ALT-070316-1, RRID: ZFIN_ZDB-ALT-070316-1 Expresses UAS:nfsB-mCherry ubiquitously (44) Tg(her4.1: GFP) (53) ZFIN catalog number ZDB-ALT-070612-3, RRID: ZFIN_ZDB-ALT-070612-3 Expresses GFP in neural progenitors Software and algorithms ImageJ/Fiji Cell detection, image alignment, and processing (35, 61, 71) Event detection (51) Other Pressure injector Eppendorf Femtojet 4i Confocal microscope (20× plan NA 0.8 objective) Zeiss Examiner Z1 Stereomicroscope (20× Plan-Apochromat, NA 0.8) Zeiss Axio Imager M1 Two-photon microscope Scientifica Sutter laser puller Sutter Model P-200 Solenoid tapper SparkFun Electronics ROB-10391 Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 15 of 17 to inject 1 nl of solution in the telencephalic ventricle near habenula of either 2.5- or 5-day-old zebrafish larvae (55). The pressure and time used for the injection were calibrated for each needle using a 0.01-mm calibration slide for microscopy. Usually, the pressure ranged between 100 and 150 hPa, and the time span of the pressure pulse lasted for 0.30 to 0.70 s. After injection, fish were released from agarose and recovered at 28°C AFW and transferred to the fish facility and raised until 12 or 21 days. Fish (21 dpf) were prepared for confocal microscopy imaging as described above for two-photon calcium imaging. Imaging was performed using a Zeiss Examiner Z1 confocal microscope with a 20× water immersion objective (Zeiss; NA of 1.0; Plan-Apochromat) at room temperature and constant perfusion of AFW bubbled with carbogen (95% O2 and 5% CO2). In vivo calcium recordings of the spontaneous activity in habenula were acquired at an acquisition rate of 1.918 Hz for 512 × 1024 pixels during 5 min. Data analysis Two-photon microscopy images were aligned using an adapted algorithm (71) that corrects for occasional drift in the XY dimension, based on “hierarchical model-based motion estimation” (72). Every recording was manually checked for motion, and corresponding frames were discarded from further analysis. Individual neurons were semiautomatically detected using a pattern recognition algo- rithm as previously described (35, 61, 71). Once neurons were detected, their locations were individually tracked during the record- ing. If any z-motion drift or if some detected neurons were no longer visible, those neurons were discarded from further analysis. The pixels belonging to each neuron were then averaged providing the complete time course of each neuron over time. The same cell-­ detection algorithms were used for the confocal recordings in Fig. 6. To distinguish between developmentally tagged and untagged neurons, we manually identified the red cells. To normalize the spontaneous activity for each cell to its baseline fluorescence, we calculated the fractional change in fluorescence (F/F) relative to the baseline, which was calculated as the eighth percentile of activity observed within a 2-min time window as previously described (51). Clustering of neurons was performed as previously reported on the basis of the k-means clustering algorithm in MATLAB, as well as the calcula- tion of cluster fidelity and cluster selectivity for sensory and tagged cells (35). Before event detection, traces from neurons in the two-photon recordings were resampled to a final rate of 2 Hz (using decimate function in MATLAB), to match the sampling rate with confocal experiments. Significant calcium events were detected using an algorithm (51) that detects calcium events significantly different from noise level within a 95% confidence interval. A cell was considered active if at least one event was detected in 4 min of ongoing activity. The amplitude of events was defined as the maximum peak in the event. The average activity per cell was defined as the sum of the area under the curve (using trapezoidal numerical integration method, function “trapz” in MATLAB) for all events within one neuron. The fractional change in fluorescence (F/F) for the odor and light stimulus, as well as mechanical vibrations and mild electric stimulus, was calculated by subtracting the average baseline fluorescence before stimulus onset (5 s) from the responsive window (10 s for odor and 2 s for light, mechanical vibrations, and mild electric stimulus from the onset of the stimulus). Cells were classified as responding if at least four out of five trials showed the same sign difference (+/−) locked to the stimulus onset. Only the positively responding neurons were taken into account for further analysis. The focality index was calculated as 1 minus the average of the Euclidean distances between the top 10% neurons (with highest fre- quencies or durations) divided by the average of the Euclidean distances of all neurons within each hemisphere. The average focality index per fish was calculated by taking the average over the two hemispheres. Same focality index was calculated for the sensory-­responding cells. Cluster fidelity was calculated by measuring the probability of pairs of neurons being in the same cluster during two different time periods (35). As a control, we shuffled the cluster identity of neurons randomly. To calculate cluster selectivity, we first calculated the cluster identity of each neuron using k-means clustering of spontaneous neural activity (35). Later, we identified neurons with a given prop- erty, in this case, either sensory responding neurons (Fig. 4G) or developmentally tagged neurons (Fig. 6L), and measured the sparseness in the distribution of identified neurons into clusters (35). We then compared this to all and/or equal number of nonsensory responding neurons within each fish. If sparseness is 1, all identified neurons are selectively members of a single cluster; if sparseness is 0, all identified neurons are equally distributed into all functional clusters identified by k-means clustering. The lateralization index was calculated as the difference between the percentage of responding neurons in the left and right hemispheres. If lateralization index is 1, neurons are lateralized to one hemisphere; if lateralization index is 0, neurons are equally distributed among hemispheres. In the confocal microscopy functional imaging, results for frequency, duration, number of active neurons, average activity, and pairwise correlations are shown for all planes imaged in each fish. These recordings were done at different time points. Quantification and statistical analysis Statistical analysis was done using MATLAB, and P values are indicated in the figure legends (*P < 0.05, **P < 0.01, and ***P < 0.001). Student t test was used for paired data, and unpaired t test was used when data were obtained from two independent datasets. For the data that displayed no Gaussian distribution, we used Wilcoxon signed-rank test for paired data and Wilcoxon rank sum test for unpaired data. Data and software All analysis was performed with Fiji and MATLAB as indicated in Results. Key resource table Table 1 shows the source and identifier of chemicals, transgenic lines, and materials used in the study. SUPPLEMENTARY MATERIALS Supplementary material for this article is available at content/full/6/36/eaaz3173/DC1 View/request a protocol for this paper from Bio-protocol. REFERENCES AND NOTES 1. A. Valente, K.-H. Huang, R. Portugues, F. Engert, Ontogeny of classical and operant learning behaviors in zebrafish. Learn. Mem. 19, 170–177 (2012). 2. Palumbo, F., Serneels, B., Pelgreems, R., Yaksi, E., The zebrafish dorsolateral habenula is required for updating learned behaviors. bioRxiv, in revision Cell Reports, 2020: p. 802256. 3. E. Dreosti, G. Lopes, A. R. Kampff, S. W. Wilson, Development of social behavior in young zebrafish. Front. Neural Circuits 9, 39 (2015). Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 16 of 17 4. E. A. Brenowitz, M. D. Beecher, Song learning in birds: Diversity and plasticity, opportunities and challenges. Trends Neurosci. 28, 127–132 (2005). 5. F. Donato, R. I. Jacobsen, M.-B. Moser, E. I. Moser, Stellate cells drive maturation of the entorhinal-hippocampal circuit. Science 355, eaai8178 (2017). 6. E. S. Lein, T. G. Belgard, M. Hawrylycz, Z. Molnár, Transcriptomic perspectives on neocortical structure, development, evolution, and disease. Annu. Rev. Neurosci. 40, 629–652 (2017). 7. S. Mayer, J. Chen, D. Velmeshev, A. Mayer, U. C. Eze, A. Bhaduri, C. E. Cunha, D. Jung, A. Arjun, E. Li, B. Alvarado, S. Wang, N. Lovegren, M. L. Gonzales, L. Szpankowski, A. Leyrat, J. A. A. West, G. Panagiotakos, A. Alvarez-Buylla, M. F. Paredes, T. J. Nowakowski, A. A. Pollen, A. R. Kriegstein, Multimodal single-cell analysis reveals physiological maturation in the developing human neocortex. Neuron 102, 143–158.e7 (2019). 8. M. Koyama, A. Kinkhabwala, C. Satou, S.-i. Higashijima, J. Fetcho, Mapping a sensory- motor network onto a structural and functional ground plan in the hindbrain. Proc. Natl. Acad. Sci. U.S.A. 108, 1170–1175 (2011). 9. A. Pujala, M. Koyama, Chronology-based architecture of descending circuits that underlie the development of locomotor repertoire after birth. eLife 8, e42135 (2019). 10. D. L. McLean, J. R. Fetcho, Spinal interneurons differentiate sequentially from those driving the fastest swimming movements in larval zebrafish to those driving the slowest ones. J. Neurosci. 29, 13566–13577 (2009). 11. A. A. Penn, C. J. Shatz, Brain waves and brain wiring: The role of endogenous and sensory- driven neural activity in development. Pediatr. Res., 45 (4 Pt 1), 447–458 (1999). 12. T. N. Wiesel, D. H. Hubel, Comparison of the effects of unilateral and bilateral eye closure on cortical unit responses in kittens. J. Neurophysiol. 28, 1029–1040 (1965). 13. V. Moreno-Juan, A. Filipchuk, N. Antón-Bolaños, C. Mezzera, H. Gezelius, B. Andrés, L. Rodríguez-Malmierca, R. Susín, O. Schaad, T. Iwasato, R. Schüle, M. Rutlin, S. Nelson, S. Ducret, M. Valdeolmillos, F. M. Rijli, G. López-Bendito, Prenatal thalamic waves regulate cortical area size prior to sensory processing. Nat. Commun. 8, 14172 (2017). 14. L. C. Kat, C. J. Shatz, Synaptic activity and the construction of cortical circuits. Science 274, 1133–1138 (1996). 15. Y. Ben-Ari, Developing networks play a similar melody. Trends Neurosci. 24, 353–360 (2001). 16. X. Leinekugel, I. Khalilov, Y. Ben-Ari, R. Khazipov, Giant depolarizing potentials: The septal pole of the hippocampus paces the activity of the developing intact septohippocampal complex in vitro. J. Neurosci. 18, 6349–6357 (1998). 17. S. Gretenkord, J. K. Kostka, H. Hartung, K. Watznauer, D. Fleck, A. Minier-Toribio, M. Spehr, I. L. Hanganu-Opatz, Coordinated electrical activity in the olfactory bulb gates the oscillatory entrainment of entorhinal networks in neonatal mice. PLOS Biol. 17, e2006994 (2019). 18. M. Meister, R. O. Wong, D. A. Baylor, C. J. Shatz, Synchronous bursts of action potentials in ganglion cells of the developing mammalian retina. Science 252, 939–943 (1991). 19. R. Yuste, A. Peinado, L. C. Katz, Neuronal domains in developing neocortex. Science 257, 665–669 (1992). 20. R.-w. Zhang, W.-j. Du, D. a. Prober, J.-L. Du, Muller glial cells participate in retinal waves via glutamate transporters and AMPA receptors. Cell Rep. 27, 2871–2880.e2 (2019). 21. T. A. Babola, S. Li, A. Gribizis, B. J. Lee, J. B. Issa, H. C. Wang, M. C. Crair, D. E. Bergles, Homeostatic control of spontaneous activity in the developing auditory system. Neuron 99, 511–524.e5 (2018). 22. N. Miyasaka, K. Morimoto, T. Tsubokawa, S.-i. Higashijima, H. Okamoto, Y. Yoshihara, From the olfactory bulb to higher brain centers: Genetic visualization of secondary olfactory pathways in zebrafish. J. Neurosci. 29, 4756–4767 (2009). 23. B.-b. Zhang, Y.-y. Yao, H.-f. Zhang, K. Kawakami, J.-l. Du, Left habenula mediates light-preference behavior in zebrafish via an asymmetrical visual pathway. Neuron 93, 914–928.e4 (2017). 24. K. J. Turner, T. A. Hawkins, J. Yáñez, R. Anadón, S. W. Wilson, M. Folgueira, Afferent connectivity of the zebrafish habenulae. Front. Neural Circuits 10, 30 (2016). 25. M. Matsumoto, O. Hikosaka, Lateral habenula as a source of negative reward signals in dopamine neurons. Nature 447, 1111–1115 (2007). 26. I. Lazaridis, O. Tzortzi, M. Weglage, A. Märtin, Y. Xuan, M. Parent, Y. Johansson, J. Fuzik, D. Fürth, L. E. Fenno, C. Ramakrishnan, G. Silberberg, K. Deisseroth, M. Carlén, K. Meletis, A hypothalamus-habenula circuit controls aversion. Mol. Psychiatry 24, 1351–1368 (2019). 27. E. R. Duboué, E. Hong, K. C. Eldred, M. E. Halpern, Left habenular activity attenuates fear responses in larval zebrafish. Curr. Biol. 27, 2154–2162.e3 (2017). 28. Y. Yang, Y. Cui, K. Sang, Y. Dong, Z. Ni, S. Ma, H. Hu, Ketamine blocks bursting in the lateral habenula to rapidly relieve depression. Nature 554, 317–322 (2018). 29. T. N. deCarvalho, A. Subedi, J. Rock, B. D. Harfe, C. Thisse, B. Thisse, M. E. Halpern, E. Hong, Neurotransmitter map of the asymmetric dorsal habenular nuclei of zebrafish. Genesis 52, 636–655 (2014). 30. S. Pandey, K. Shekhar, A. Regev, A. F. Schier, Comprehensive identification and spatial mapping of habenular neuronal types using single-cell RNA-seq. Curr. Biol. 28, 1052–1065.e7 (2018). 31. M. Agetsuma, H. Aizawa, T. Aoki, R. Nakayama, M. Takahoko, M. Goto, T. Sassa, R. Amo, T. Shiraki, K. Kawakami, T. Hosoya, S.-i. Higashijima, H. Okamoto, The habenula is crucial for experience-dependent modification of fear responses in zebrafish. Nat. Neurosci. 13, 1354–1356 (2010). 32. R. Amo, H. Aizawa, M. Takahoko, M. Kobayashi, R. Takahashi, T. Aoki, H. Okamoto, Identification of the zebrafish ventral habenula as a homolog of the mammalian lateral habenula. J. Neurosci. 30, 1566–1574 (2010). 33. R. Amo, F. Fredes, M. Kinoshita, R. Aoki, H. Aizawa, M. Agetsuma, T. Aoki, T. Shiraki, H. Kakinuma, M. Matsuda, M. Yamazaki, M. Takahoko, T. Tsuboi, S.-i. Higashijima, N. Miyasaka, T. Koide, Y. Yabuki, Y. Yoshihara, T. Fukai, H. Okamoto, The habenulo-raphe serotonergic circuit encodes an aversive expectation value essential for adaptive active avoidance of danger. Neuron 84, 1034–1048 (2014). 34. E. Dreosti, N. V. Llopis, M. Carl, E. Yaksi, S. W. Wilson, Left-right asymmetry is required for the habenulae to respond to both visual and olfactory stimuli. Curr. Biol. 24, 440–445 (2014). 35. S. K. Jetti, N. Vendrell-Llopis, E. Yaksi, Spontaneous activity governs olfactory representations in spatially organized habenular microcircuits. Curr. Biol. 24, 434–439 (2014). 36. M.-Y. Chou, R. Amo, M. Kinoshita, B.-W. Cherng, H. Shimazaki, M. Agetsuma, T. Shiraki, T. Aoki, M. Takahoko, M. Yamazaki, S.-i. Higashijima, H. Okamoto, Social conflict resolution regulated by two dorsal habenular subregions in zebrafish. Science 352, 87–90 (2016). 37. A. S. Andalman, V. M. Burns, M. Lovett-Barron, M. Broxton, B. Poole, S. J. Yang, L. Grosenick, T. N. Lerner, R. Chen, T. Benster, P. Mourrain, M. Levoy, K. Rajan, K. Deisseroth, Neuronal dynamics regulating brain and behavioral state transitions. Cell 177, 970–985.e20 (2019). 38. H. Aizawa, M. Goto, T. Sato, H. Okamoto, Temporally regulated asymmetric neurogenesis causes left-right difference in the zebrafish habenular structures. Dev. Cell 12, 87–98 (2007). 39. I. H. Bianco, M. Carl, C. Russell, J. D. W. Clarke, S. W. Wilson, Brain asymmetry is encoded at the level of axon terminal morphology. Neural Dev. 3, 9 (2008). 40. Y. Hashikawa, K. Hashikawa, M. A. Rossi, M. L. Basiri, Y. Liu, N. L. Johnston, O. R. Ahmad, G. D. Stuber, Transcriptional and spatial resolution of cell types in the mammalian habenula. Neuron 106, 743–758.E5 (2020). 41. N. Vladimirov, Y. Mu, T. Kawashima, D. V. Bennett, C.-T. Yang, L. L. Looger, P. J. Keller, J. Freeman, M. B. Ahrens, Light-sheet functional imaging in fictively behaving zebrafish. Nat. Methods 11, 883–884 (2014). 42. C. Satou, Y. Kimura, H. Hirata, M. L. Suster, K. Kawakami, S.-i. Higashijima, Transgenic tools to characterize neuronal properties of discrete populations of zebrafish neurons. Development 140, 3927–3931 (2013). 43. S. Krishnan, A. S. Mathuru, C. Kibat, M. Rahman, C. E. Lupton, J. Stewart, A. Claridge-Chang, S.-C. Yen, S. Jesuthasan, The right dorsal habenula limits attraction to an odor in zebrafish. Curr. Biol. 24, 1167–1175 (2014). 44. E. K. Scott, H. Baier, The cellular architecture of the larval zebrafish tectum, as revealed by gal4 enhancer trap lines. Front. Neural Circuits 3, 13 (2009). 45. T. Koide, N. Miyasaka, K. Morimoto, K. Asakawa, A. Urasaki, K. Kawakami, Y. Yoshihara, Olfactory neural circuitry for attraction to amino acids revealed by transposon-mediated gene trap approach in zebrafish. Proc. Natl. Acad. Sci. U.S.A. 106, 9884–9889 (2009). 46. F. Kermen, L. Darnet, C. Wiest, F. Palumbo, J. Bechert, O. Uslu, E. Yaksi, Stimulus-specific behavioral responses of zebrafish to a large range of odors exhibit individual variability. BMC Biol. 18, 66 (2020). 47. A. S. Mathuru, C. Kibat, W. F. Cheong, G. Shui, M. R. Wenk, R. W. Friedrich, S. Jesuthasan, Chondroitin fragments are odorants that trigger fear behavior in fish. Curr. Biol. 22, 538–544 (2012). 48. H. A. Burgess, M. Granato, Sensorimotor gating in larval zebrafish. J. Neurosci. 27, 4984–4994 (2007). 49. E. Yaksi, B. Judkewitz, R. W. Friedrich, Topological reorganization of odor representations in the olfactory bulb. PLOS Biol. 5, e178 (2007). 50. G. Buzsaki, A. Draguhn, Neuronal oscillations in cortical networks. Science 304, 1926–1929 (2004). 51. S. A. Romano, V. Pérez-Schuster, A. Jouary, J. Boulanger-Weill, A. Candeo, T. Pietri, G. Sumbre, An integrated calcium imaging processing toolbox for the analysis of neuronal population dynamics. PLOS Comput. Biol. 13, e1005526 (2017). 52. O. Randlett, C. L. Wee, E. A. Naumann, O. Nnaemeka, D. Schoppik, J. E. Fitzgerald, R. Portugues, A. M. B. Lacoste, C. Riegler, F. Engert, A. F. Schier, Whole-brain activity mapping onto a zebrafish brain atlas. Nat. Methods 12, 1039–1046 (2015). 53. S.-Y. Yeo, M. J. Kim, H.-S. Kim, T.-L. Huh, A. B. Chitnis, Fluorescent protein expression driven by her4 regulatory elements reveals the spatiotemporal pattern of Notch signaling in the nervous system of zebrafish embryos. Dev. Biol. 301, 555–567 (2007). 54. S. Govindan, P. Oberst, D. Jabaudon, In vivo pulse labeling of isochronic cohorts of cells in the central nervous system using FlashTag. Nat. Protoc. 13, 2297–2311 (2018). Fore et al., Sci. Adv. 2020; 6 : eaaz3173 4 September 2020 SCIE N C E A D V A NCES | RESEA R CH A RT ICL E 17 of 17 55. E. W. Olstad, C. Ringers, J. N. Hansen, A. Wens, C. Brandt, D. Wachten, E. Yaksi, N. Jurisch-Yaksi, Ciliary beating compartmentalizes cerebrospinal fluid flow in the brain and regulates ventricular development. Curr. Biol. 29, 229–241.e6 (2019). 56. J. G. M. Bergboer, C. Wyatt, C. Austin-Tse, E. Yaksi, I. A. Drummond, Assaying sensory ciliopathies using calcium biosensor expression in zebrafish ciliated olfactory neurons. Cilia 7, 2 (2018). 57. R.-K. Cheng, S. Krishnan, Q. Lin, C. Kibat, S. Jesuthasan, Characterization of a thalamic nucleus mediating habenula responses to changes in ambient illumination. BMC Biol. 15, 104 (2017). 58. M. R. Warden, A. Selimbeyoglu, J. J. Mirzabekov, M. Lo, K. R. Thompson, S.-Y. Kim, A. Adhikari, K. M. Tye, L. M. Frank, K. Deisseroth, A prefrontal cortex-brainstem neuronal projection that controls response to behavioural challenge. Nature 492, 428–432 (2012). 59. H.-p. Xu, M. Furman, Y. S. Mineur, H. Chen, S. L. King, D. Zenisek, Z. J. Zhou, D. A. Butts, N. Tian, M. R. Picciotto, M. C. Crair, An instructive role for patterned spontaneous retinal activity in mouse visual map development. Neuron 70, 1115–1127 (2011). 60. Y. Cui, Y. Yang, Z. Ni, Y. Dong, G. Cai, A. Foncelle, S. Ma, K. Sang, S. Tang, Y. Li, Y. Shen, H. Berry, S. Wu, H. Hu, Astroglial Kir4.1 in the lateral habenula drives neuronal bursts in depression. Nature 554, 323–327 (2018). 61. C. D. Verdugo, S. Myren-Svelstad, E. Aydin, E. Van Hoeymissen, C. Deneubourg, S. Vanderhaeghe, J. Vancraeynest, R. Pelgrims, M. I. Cosacak, A. Muto, C. Kizil, K. Kawakami, N. Jurisch-Yaksi, E. Yaksi, Glia-neuron interactions underlie state transitions to generalized seizures. Nat. Commun. 10, 3830 (2019). 62. S. Hong, O. Hikosaka, The globus pallidus sends reward-related signals to the lateral habenula. Neuron 60, 720–729 (2008). 63. P. Lal, H. Tanabe, M. L. Suster, D. Ailani, Y. Kotani, A. Muto, M. Itoh, M. Iwasaki, H. Wada, E. Yaksi, K. Kawakami, Identification of a neuronal population in the telencephalon essential for fear conditioning in zebrafish. BMC Biol. 16, 45 (2018). 64. J. W. von Trotha, P. Vernier, L. Bally-Cuif, Emotions and motivated behavior converge on an amygdala-like structure in the zebrafish. Eur. J. Neurosci. 40, 3302–3315 (2014). 65. G. Furlan, V. Cuccioli, N. Vuillemin, L. Dirian, A. J. Muntasell, M. Coolen, N. Dray, S. Bedu, C. Houart, E. Beaurepaire, I. Foucher, L. Bally-Cuif, Life-long neurogenic activity of individual neural stem cells and continuous growth establish an outside-in architecture in the teleost pallium. Curr. Biol. 27, 3288–3301.e3 (2017). 66. N. Jurisch-Yaksi, E. Yaksi, C. Kizil, Radial glia in the zebrafish brain: Functional, structural, and physiological comparison with the mammalian glia. Glia, (2020). 67. M. B. Luskin, C. J. Shatz, Neurogenesis of the cat's primary visual cortex. J. Comp. Neurol. 242, 611–631 (1985). 68. J. A. Lister, C. P. Robertson, T. Lepage, S. L. Johnson, D. W. Raible, Nacre encodes a zebrafish microphthalmia-related protein that regulates neural-crest-derived pigment cell fate. Development 126, 3757–3767 (1999). 69. H.-C. Park, C.-H. Kim, Y.-K. Bae, S.-Y. Yeo, S.-H. Kim, S.-K. Hong, J. Shin, K.-W. Yoo, M. Hibi, T. Hirano, N. Miki, A. BChitnis, T.-L. Huh, Analysis of upstream elements in the HuC promoter leads to the establishment of transgenic zebrafish with fluorescent neurons. Dev. Biol. 227, 279–293 (2000). 70. F. Kermen, P. Lal, N. G. Faturos, E. Yaksi, Interhemispheric connections between olfactory bulbs improve odor detection. PLoS Biol. 18, e3000701 (2020). 71. I. Reiten, F. E. Uslu, S. Fore, R. Pelgrims, C. Ringers, C. D. Verdugo, M. Hoffman, P. Lal, K. Kawakami, K. Pekkan, E. Yaksi, N. Jurisch-Yaksi, Motile-cilia-mediated flow improves sensitivity and temporal resolution of olfactory computations. Curr. Biol. 27, 166–174 (2017). 72. Bergen, J. R., Anandan, P., Hanna, K. J., Hingorani, R. Hierarchical model-based motion estimation, in ECCV ’92; Proceedings of the Second European Conference on Computer Vision (Springer Berlin Heidelberg, 1992), pp. 237–252. Acknowledgments: We thank M. Ahrens (HHMI, Janelia Farm, USA), C. Wyart (ICM, Paris, France), H. Baier (MPI, Martinsried, Germany), and S.-i. Higashijima (Okazaki Institute for Integrative Bioscience, Japan) for transgenic lines. We thank S. Eggen, M. Andresen, V. Nguyen, and our fish facility support team for technical assistance. We thank the Yaksi laboratory members for stimulating discussions. Funding: This work was funded by ERC starting grant 335561 (S.F. and E.Y.), Helse Midt-Norge Samarbeidsorganet grant (N.J.-Y. and E.Y.), RCN FRIPRO Research Grant 239973 (E.Y.), and Boehringer Ingelheim Fonds (C.R.). Work in the E.Y. laboratory is funded by the Kavli Institute for Systems Neuroscience at NTNU. Ethics statement: All experimental procedures performed on zebrafish larvae and juveniles were in accordance with the Directive 2010/63/EU of the European Parliament and the Council of the European Union and approved by the Norwegian Food Safety Authorities and Landesdirektion Sachsen, Germany (permit numbers TVV-52/2015 and TVV-35/2016). Author contributions: Conceptualization: S.F. and E.Y. Methodology and data: S.F., F.A-H., K.A.M., E.M.B., B.S., N.G.F., K.T.P.C., M.I.C., N.J.-Y., and C.K. Data analysis: S.F., F.A-H., K.A.M., E.M.B., B.S., N.G.F., K.T.P.C., C.D.V., F.P., C.R., and N.J.-Y. Investigation: all authors. Writing: S.F., F.A-H., and E.Y. Review and editing: all authors. Funding acquisition and supervision: E.Y. Competing interests: The authors declare that they have no competing interests. Data and materials availability: All data needed to evaluate the conclusions in the paper are present in the paper and/or the Supplementary Materials. Additional data related to this paper may be requested from the authors. Submitted 29 August 2019 Accepted 17 July 2020 Published 4 September 2020 10.1126/sciadv.aaz3173 Citation: S. Fore, F. Acuña-Hinrichsen, K. A. Mutlu, E. M. Bartoszek, B. Serneels, N. G. Faturos, K. T. P. Chau, M. I. Cosacak, C. D. Verdugo, F. Palumbo, C. Ringers, N. Jurisch-Yaksi, C. Kizil, E. Yaksi, Functional properties of habenular neurons are determined by developmental stage and sequential neurogenesis. Sci. Adv. 6, eaaz3173 (2020)."
A new decision making model based on Rank Centrality for GDM with fuzzy preference relations,Anis Yazidi and Magdalena Ivanovska and Fabio M. Zennaro and Pedro G. Lind and Enrique Herrera Viedma,2022,3.0,297,European Journal of Operational Research,article,"European Journal of Operational Research 297 (2022) 1030–1041 
Contents lists available at ScienceDirect 
European Journal of Operational Research 
journal homepage: www.elsevier.com/locate/ejor 
Decision Support 
A new decision making model based on Rank Centrality for GDM with 
fuzzy preference relations 
Anis Yazidi a , b , c , g , h , ∗, Magdalena Ivanovska d , Fabio M. Zennaro e , Pedro G. Lind a , b , c , 
Enrique Herrera Viedma f 
a Department of Computer Science, OsloMet – Oslo Metropolitan University, P.O. Box 4 St. Olavs plass, Oslo N-0130, Norway 
b ORCA – OsloMet Research Center for AI, Pilestredet 52, Oslo N-0166, Norway 
c NordSTAR – Nordic Center for Sustainable and Trustworthy AI Research, Pilestredet 52, Oslo N-0166, Norway 
d Department of Data Science and Analytics, BI Norwegian Business School, Nydalsveien 37, Oslo N-0484, Norway 
e Department of Informatics, University of Oslo, P.O. Box 1080 Blindern, Oslo N-0316, Norway 
f Andalusian Research Institute in Data Science and Computational Intelligence, University of Granada, Granada 18071, Spain 
g Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway 
h Department of Plastic and Reconstructive Surgery, Oslo University Hospital, Oslo, Norway 
a r t i c l e 
i n f o 
Article history: 
Received 2 June 2020 
Accepted 19 May 2021 
Available online 1 June 2021 
Keywords: 
Decision support systems 
Group decision making 
Fuzzy preference relations 
Rank Centrality 
Markov chains 
a b s t r a c t 
Preference aggregation in Group Decision Making (GDM) is a substantial problem that has received a 
lot of research attention. Decision problems involving fuzzy preference relations constitute an important 
class within GDM. Legacy approaches dealing with the latter type of problems can be classiﬁed into in- 
direct approaches, which involve deriving a group preference matrix as an intermediate step, and direct 
approaches, which deduce a group preference ranking based on individual preference rankings. Although 
the work on indirect approaches has been extensive in the literature, there is still a scarcity of research 
dealing with the direct approaches. In this paper we present a direct approach towards aggregating sev- 
eral fuzzy preference relations on a set of alternatives into a single weighted ranking of the alternatives. 
By mapping the pairwise preferences into transitions probabilities, we are able to derive a preference 
ranking from the stationary distribution of a stochastic matrix. Interestingly, the ranking of the alter- 
natives obtained with our method corresponds to the optimizer of the Maximum Likelihood Estimation 
of a particular Bradley-Terry-Luce model. Furthermore, we perform a theoretical sensitivity analysis of 
the proposed method supported by experimental results and illustrate our approach towards GDM with 
a concrete numerical example. This work opens avenues for solving GDM problems using elements of 
probability theory, and thus, provides a sound theoretical fundament as well as plausible statistical inter- 
pretation for the aggregation of expert opinions in GDM. 
© 2021 The Authors. Published by Elsevier B.V. 
This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) 
1. Introduction 
Group decision making (GDM) settings involve a group of indi- 
viduals (experts), where each member of the group expresses her 
preferences over a set of alternatives. Illustrative examples range 
from parliamentary groups working to converge on a political deci- 
sion, to groups of friends deciding on the best choice of restaurant 
for a dinner. The aim of GDM is to identify the most preferred al- 
ternative for the whole group of individuals, or to derive a ranking 
of the alternatives that reﬂects the preferences of the group. 
∗Corresponding author. 
E-mail addresses: anis.yazidi@oslomet.no (A. Yazidi), viedma@decsai.ugr.es (E.H. 
Viedma). 
The literature proposes many different forms of expressing pref- 
erences of experts ( Capuano, Chiclana, Fujita, Herrera-Viedma, & 
Loia, 2017 ). Some of the most popular ones are the following: 
• Rankings , which are ranked lists of the alternatives from the 
most preferred to the least preferred one ( Seo & Sakawa, 1985 ). 
• Utility vectors , where each component of the vector describes 
the utility of the corresponding alternative, which can be seen 
as its ordinal strength ( Tanino, 1990 ). These are sometimes 
called priority vectors or weighted rankings . We use the latter 
expression throughout this paper. 
• Preference relations , where preference is expressed as a binary 
relation on the set of alternatives ( Kitainik, 2012 ). 
• Fuzzy Preference Relations (FPRs) , which relax the binary pref- 
erence relations with the possibility of expressing degrees of 
https://doi.org/10.1016/j.ejor.2021.05.030 
0377-2217/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ) 
 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. 
European Journal of Operational Research 297 (2022) 1030–1041 
preference among the alternatives ( Pedrycz, Ekel, & Parreiras, 
2010 ). Preference degrees can be assessed using linguistic term 
sets which can be more natural for human expert to articulate 
( Ureña, Kou, Wu, Chiclana, & Herrera-Viedma, 2019 ). 
FPR is the most commonly used representation for expressing 
preferences in a set of alternatives, in which an expert expresses 
her preferences as degrees of preference assigned to each pair of 
alternatives. The most common way to store these pairwise pref- 
erences is in the form of a preference matrix. The main reason 
behind the popularity of the preference relations comes from a 
known fact from psychology studies that human beings are better 
at comparing pairs of alternatives than at coming up with a com- 
plete preference ordering of a set of alternatives ( Ureña, Chiclana, 
Morente-Molinera, & Herrera-Viedma, 2015 ). 
Within GDM involving FPR, there are two main families of ap- 
proaches: direct approaches and indirect approaches. The indirect 
approaches ﬁrst compute the group opinion in the form of an FPR 
(we will call it a group or a collective FPR), usually expressed as a 
preference matrix, and then ﬁnd a solution which is a (weighted) 
ranking of the different alternatives based on the collective FPR. 
The collective preference matrix is generally derived by apply- 
ing an aggregation operator to the individual ones. On the other 
hand, the direct approaches do not involve constructing a collec- 
tive preference matrix describing the group opinion as an inter- 
mediate step. They ﬁrst compute an individual ranking for each 
expert based on her FPR, and then the group ranking is obtained 
from the individual rankings of the experts using an aggregation 
operator. For excellent surveys on consensus processes and pref- 
erence aggregation we refer the reader to the comprehensive sur- 
veys ( Cabrerizo, Moreno, Pérez, & Herrera-Viedma, 2010; Herrera- 
Viedma, Cabrerizo, Kacprzyk, & Pedrycz, 2014 ) and to the book by 
Herrera-Viedma et al. (2011) . 
While studies on indirect approaches for aggregating pairwise 
preferences abound, the direct approaches are not as popular, al- 
though there are a few exceptions ( Dong, Xu, & Yu, 2009; Fan, Ma, 
Jiang, Sun, & Ma, 2006 ). Herrera and his collaborators ( Herrera, 
Herrera-Viedma, & Verdegay, 1996 ) pioneered the ﬁrst direct ap- 
proach towards GDM based on FPR. However, the work in this di- 
rection is very scarce, although it is known that direct approaches 
usually possess two desirable properties, internal consistency and 
Pareto principle of the social choice theory ( Dong & Zhang, 2014 ). 
One of the few available direct approaches in the literature was 
recently presented by Dong et al. in ( Dong & Zhang, 2014 ). There, 
the authors extended the original direct approach presented in 
( Herrera et al., 1996 ) in order to support (i) different preferences 
representations, and (ii) a consensus process in the form of rounds 
where experts are required to adjust their pairwise preferences. In- 
terestingly, in order to achieve consensus, Dong et al. resort to a 
form of a feedback based on measuring consensus using the indi- 
vidual weighted rankings of the experts. This is distinct from the 
main stream of research in FPR since consensus degree computa- 
tion is not based on weighted rankings of individual experts but 
rather based on elements from the preference matrices. The ap- 
proach by Dong et al. allows the experts to update their prefer- 
ence matrices in order to reach a consensus, deﬁning two quan- 
tities, namely the cardinal consensus degree, based on the vec- 
tor representation inspired by ( Chiclana, Herrera, Herrera-Viedma, 
& Martínez, 2003; Dong, Xu, Li, & Feng, 2010 ) and the ordinal 
consensus degree inspired by ( Herrera-Viedma, Alonso, Chiclana, & 
Herrera, 2007; Herrera-Viedma, Herrera, & Chiclana, 2002 ). 
In this article, we take a direct approach towards group de- 
cision making given fuzzy preferences over a set of alternatives. 
We propose a method for aggregating the opinions of several 
experts, which are expressed as FPRs, into a single weighted 
ranking of the alternatives. Similarly to the work in ( Dopazo & 
Martínez-Céspedes, 2017 ), we transform the preference matrices 
into stochastic matrices, and then use the theory of Markov chains 
and random walks to compute rankings over the alternatives, as 
implemented in the PageRank algorithm ( Gleich, 2015 ). One main 
difference in this paper compared to the method in ( Dopazo & 
Martínez-Céspedes, 2017 ) lays in the deﬁnition of the stochastic 
matrix. In ( Dopazo & Martínez-Céspedes, 2017 ) the stochastic ma- 
trix is simply a column-normalization of the preference matrix so 
that its entries are proportional to the corresponding preferences 
and represent the probabilities (relative strengths) of dominance 
between the alternatives. In our framework we determine the en- 
tries of the stochastic matrix similarly as in ( Negahban, Oh, & Shah, 
2012; 2016 ) and they represent the probabilities of transiting be- 
tween the corresponding alternatives in the way that the prob- 
ability of transition from alternative x to alternative y is propor- 
tional to the degree of preference of y to x . The stationary vectors, 
however, have similar interpretation in both our approach and the 
approach in ( Dopazo & Martínez-Céspedes, 2017 ) as their entries 
represent preference strengths of the corresponding alternatives in 
both the cases. The difference is that the normalization we use 
leads to a stationary vector that satisﬁes the global balance prop- 
erty with respect to the preference matrix: the preference strength 
of an alternative depends on whether the alternative dominates 
weak or strong alternatives. This is the core idea of the Rank Cen- 
trality method ( Negahban et al., 2012; 2016 ) and we discuss it in 
more detail in Section 3.1 . 
Notice that assigning and interpreting a degree of preference is 
not straightforward. Using a probability value to quantify an FPR 
gives an intuitive interpretation of FPR itself and, moreover, en- 
ables to establish a link between probability theory and preference 
aggregation. Furthermore, we prove that the weighted ranking ob- 
tained as a result of the method presented in this paper corre- 
sponds to the result of Maximum Likelihood Estimation (MLE) of 
the Plackett-Luce model ( Plackett, 1975 ). 
There is a body of literature on methods that compute weighted 
ranking from preference matrices based on optimization tech- 
niques such as least square method ( Gong, 2008 ), least deviation 
method ( Xu & Da, 2005 ), multiobjective optimization ( Fernandez 
& Leyva, 2004 ), new fuzzy linear programming method (FLPM) 
( Zhu & Xu, 2014 ), goal programming ( Fan et al., 2006 ), etc. Al- 
though these methods are shown to provide good results, they re- 
lay on human-engineered techniques or heuristics and do not pro- 
vide plausible theoretical interpretation of their computation and 
modelling steps. Our work is distinct from the latter works as the 
way we derive a ranking vector can be explained using probabil- 
ity theory and thus we provide a theoretical interpretation of our 
framework. 
Indeed, as mentioned above, our work is directly inspired by a 
recent work on Rank Centrality algorithm ( Negahban et al., 2012; 
2016 ), which aggregates a set of pairwise comparisons of alterna- 
tives into a global weighted ranking. In ranking based on pairwise 
comparisons, the goal is to rank, for example, football teams based 
on results of played matches between them. This problem has an 
obvious analogy with ranking of alternatives based on pairwise ex- 
pressed preferences, but despite the vast amount of work on rank- 
ing alternatives based on preferences, to the best of our knowl- 
edge, the ideas of Rank Centrality have not yet been adopted in the 
context of fuzzy preference aggregation. We argue that by properly 
transforming the fuzzy preferences into probabilities of transition 
between alternatives, probability theory can naturally be applied in 
preference aggregation and, consequently, we hope that our frame- 
work can inspire further research in that direction. 
The remainder of this paper is structured as follows. In 
Section 2 we introduce the relevant background and the fun- 
damental concepts of the state of the art in fuzzy preferences. 
Section 3 presents our approach for aggregating preferences based 
1031 
 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. 
European Journal of Operational Research 297 (2022) 1030–1041 
on the concept of Markov chains and discusses the conditions un- 
der which some desirable properties for the aggregation processes 
hold. In Section 4 we provide a theoretical sensitivity analysis 
of the proposed aggregation method. Concrete numerical example 
showing the consistency of our framework followed by an exper- 
imental sensitivity analysis is given in Section 5 . Final discussions 
and conclusions are provided in Section 6 . 
2. Background and preliminary concepts 
In the following we assume that E = { e 1 , . . . , e m } is a set of 
experts and X = { x 1 , . . . , x n } is a set of alternatives. We use the 
following deﬁnition of a fuzzy preference relation as provided in 
( Herrera-Viedma, Herrera, Chiclana, & Luque, 2004 ). 
A Fuzzy Preference Relation (FPR) P on a set of alternatives X is 
a fuzzy set on the product set X × X, i.e. a relation on X character- 
ized by a membership function 
μP : X × X → [0 , 1] . 
(1) 
p ij = μP (x i , x j ) is interpreted as the preference degree of the alter- 
native x i over the alternative x j . A usual natural assumption is that 
p ij + p ji = 1 , for every i, j ∈ { 1 , . . . , n } , i.e. that P is additive recip- 
rocal . If p ij > 0 . 5 , we say that x i is preferred to x j ; if p ij = 0 . 5 , we 
say that we are indifferent between x i and x j ; and p ij = 1 indicates 
that x i is absolutely preferred to x j . The additive reciprocity prop- 
erty ensures that p ii = 0 . 5 and p ij > 0 . 5 iff p ji < 0 . 5 . 
When the set X is not too big, it is convenient to represent 
P as an n × n matrix of preference values, where n = | X| , i.e. P = 
[ p ij ] n ×n . We call this a preference matrix . For convenience, we use 
the same notation for both the fuzzy preference relation and the 
corresponding preference matrix. 
We assume that each of the m experts expresses her prefer- 
ences independently of each other and in the form of a fuzzy pref- 
erence relation. Let us denote by P (k ) the FPR of the k -th expert 
and let P (k ) = [ p (k ) 
ij ] n ×n be the corresponding preference matrix. 
An indirect approach to GDM aims at reaching a collective opin- 
ion by ﬁrst aggregating all the individual preference matrices into a 
collective FPR. A direct approach would predict the collective opin- 
ion or a GDM-”target”, in general, by turning experts’ FPR matrices 
into vectors whose entries measure the ranking of the alternatives. 
More formally, a weighted ranking can be deﬁned as a function 
r : X → R , which maps each alternative in X into its absolute pref- 
erence strength. 1 Aggregating the individual ranking vectors yields 
a possible consensus target for the set of individuals. 
Whatever approach one chooses, direct or indirect, there are 
two main phases in GDM based on FPR, an aggregation phase and 
an exploitation phase . 
In the aggregation phase, the corresponding individual prefer- 
ence values (corresponding entries in FPR matrices or ranking vec- 
tors) are aggregated into a collective preference value using an ag- 
gregation operator . 
There are many aggregation operators, such as weighted aver- 
age (WA), fuzzy majority, etc. One popular example is the opera- 
tor called Ordered Weighted Averaging (OWA) due to ( Yager, 1988 ). 
The WA and the OWA operators presume we have a list of weights 
w = (w 1 , . . . , w m ) , w k ∈ [0 , 1] , k = 1 , . . . , m , such that  w k = 1 . Let 
p 1 , . . . , p m be a list of preference values to be aggregated. While 
the WA operator is deﬁned as a simple weighted average of the 
preferences: 
WA ( p 1 , . . . , p m ) = 
m 
 
k = 1 
w k p k , 
(2) 
1 The ordering of the alternatives is implicit in each weighted ranking and follows 
from the linear order of the real numbers: Alternatives assigned a higher number 
rank higher, and alternatives assigned the same number rank the same. 
the OWA operator is deﬁned as 
OWA ( p 1 , . . . , p m ) = 
m 
 
k = 1 
w k p σ ( k ) , 
(3) 
where σ is a permutation of the set { 1 , . . . , m } such that p σ (k +1) ≥
p σ (k ) for k ∈ { 0 , . . . , m −1 } . 
In the case of WA, the weights w = (w 1 , . . . , w m ) can be as- 
sumed to be corresponding to the importance of the experts in 
the group with respect to the particular decision making problem, 
or to the conﬁdence of the experts in their opinions. In the case 
of OWA, assigning weights w enables weighting differently prefer- 
ences of different strength, giving more value to stronger prefer- 
ences, for example. By choosing different w in WA and OWA, one 
can implement different aggregation operators. 
The exploitation phase is the phase of deducing a (weighted) 
ranking vector based on a fuzzy preference relation (matrix). 
Two relevant approaches towards deﬁning the ranking in this 
phase are ( Herrera et al., 1996 ): Quantiﬁer-Guided Dominance De- 
gree (QGDD), where the rank of each alternative represents the 
dominance or importance of the alternative over the rest of the al- 
ternatives; and Quantiﬁer-Guided Non-Dominance Degree (QGNDD), 
where the rank of each alternative represents the degree to which 
the alternative is not dominated by the rest of the alternatives. An 
alternative to QGDD and QGNDD is the Netﬂow method ( Bouyssou, 
1992 ) which is also based on dominance of an alternative. 2 More 
precisely, this method deﬁnes the rank of an alternative as the 
difference between the inﬂow and the outﬂow of preference from 
it, which, under the additive reciprocity assumption ( p ij + p ji = 1 ), 
reduces to the following expression: 
NF ( x i ) = 
n 
 
j =1 ,j ̸ = i 
p ij −
n 
 
j =1 ,j ̸ = i 
p ji 
= 
n 
 
j =1 ,j ̸ = i 
2 p ij −n + 1 
= 2 
 
n 
 
j =1 ,j ̸ = i 
p ij −n −1 
2 
 
. 
(4) 
Notice that the Netﬂow method is related to the Copeland vot- 
ing rule in ( Marchant, 1996 ). An axiomatic characterization of the 
Copeland rule can be found in ( Henriet, 1985 ). 
The indirect and the direct approaches towards GDM with FPR 
differ in the way the phases of aggregation and exploitation are 
combined: In the indirect approaches, one ﬁrst applies the aggre- 
gation phase to the set of individual FPRs in order to obtain one 
collective FPR. Then the exploitation phase is applied to the col- 
lective FPR to give the ﬁnal (weighted) ranking. In the direct ap- 
proaches, the exploitation phase is applied ﬁrst at each individual 
FPR to give the individual rankings. Then the aggregation phase is 
applied at the individual rankings to ﬁnd the ﬁnal collective rank- 
ing ( Herrera et al., 1996 ). Fig. 1 highlights these differences be- 
tween the two approaches. 
Note that aggregating opinions of experts into a group opin- 
ion by any of the above approaches does not necessarily amount 
to reaching a consensus. To guarantee agreement between the ex- 
perts, one could consider a third phase after the two phases de- 
scribed above, in which one forces the individual opinions of the 
experts to get close to each other ( Palomares, Estrella, Martínez, & 
Herrera, 2014 ). This narrowing phase can be implemented in two 
different ways: (i) through automatic approaches without expert 
feedback, or (ii) through approaches with feedback on preferences 
2 Note that the Netﬂow method has also been deﬁned in ( García-Lapresta, 
Martínez-Panero, & Meneses, 2009 ) as the broad Borda count. 
1032 
 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. 
European Journal of Operational Research 297 (2022) 1030–1041 
Fig. 1. Tensor representation of methods for GDM. Indirect method (above); direct method (below). 
where there is a moderator that will try to reduce the divergence 
of opinions between the experts. In both of these approaches con- 
sensus is considered to be a stage where all the individual opin- 
ions are suﬃciently close to each other. Quantitatively, the close- 
ness can be measured as a distance in the “space of opinions” ei- 
ther between each opinion and the collective (aggregated) opinion, 
or between pairs of individual opinions. 
Having described brieﬂy the decision framework and the main 
approaches for quantitative analysis in GDM, in the next section 
we propose a new method to address the aggregation and ex- 
ploitation processes and we analyse its properties. 
3. A rank centrality-based preference aggregation method 
In this section we introduce a method for aggregating the 
fuzzy preference relations of the experts e 1 , . . . , e m into a collective 
weighted ranking of the alternatives x 1 , . . . , x n . We start by provid- 
ing a way of transforming a preference matrix over the alterna- 
tives into a weighted ranking vector of the alternatives, which will 
be used in the exploitation phase of the general method. Then we 
provide the full GDM procedure. At the end we prove that, un- 
der the assumption that detailed balance relation is satisﬁed, the 
proposed method satisﬁes some desirable properties of aggrega- 
tion processes. 
3.1. From preference matrices to ranking vectors 
We consider an n × n preference matrix P over the alternatives 
x 1 , . . . , x n ( n ≥2 ) which is additive reciprocal, i.e. a matrix whose 
elements p ij are in the unit interval and obey the condition 
p ij = 1 −p ji . 
(5) 
A value p ij > 0 . 5 means that the alternative x i is preferred over x j , 
while p ij = 0 . 5 means that no preference between x i and x j exists. 
Inspired by recent work on ranking based on a dataset of pair- 
wise comparisons ( Negahban et al., 2012; 2016 ), our approach is 
based on a transformation of the given preference matrix P into a 
stochastic matrix S deﬁned in the following way: 
s ij = 
1 
n −1 p ji , 
(6a) 
s ii = 1 −
1 
n −1 
n 
 
j =1 ,j ̸ = i 
p ji . 
(6b) 
The division by n −1 is introduced for normalization purposes, 
 
j s ij = 1 , and to guarantee that each element s ij is proportional 
to the corresponding p ji and fulﬁlls the condition 0 ≤s ij ≤1 . Each 
row can then be seen as a probability distribution and the matrix 
S as the matrix of transition probabilities of a Markov chain with n 
states. 3 The element s ij corresponds to the probability of transiting 
from a state x i to a state x j and, as deﬁned in Eq. (6a) , this prob- 
ability equals the product of the probability of choosing randomly 
the state x j among the n −1 states different from x j and adopting 
that state with probability p ji . This ensures that the probability of 
transition from alternative x i to alternative x j is proportional to the 
preference of x j over x i . Notice that it is always possible to con- 
struct such a stochastic matrix, even if there are missing entries 
in the preference matrix P , i.e. if there is incomplete information 
( Herrera-Viedma et al., 2007 ). 
We impose that the preference matrix P fulﬁlls the condition 
p ij ̸ = 0 , 
(7) 
for every i, j ∈ { 1 , . . . , n } , and therefore also p ij ̸ = 1 , for every i, j ∈ 
{ 1 , . . . , n } , which means that an alternative is never completely 
“excluded” against another one and also never “fully dominates”
another one. (This may be achieved by replacing a zero prefer- 
ence with an arbitrarily small ϵ > 0 preference). It is easy to see 
that under this particular condition the matrix S is irreducible and 
aperiodic (see Appendix A ). Then, according to Perron-Frobenius 
theorem ( Horn & Johnson, 1990; MacCluer, 20 0 0 ), S being an ir- 
reducible aperiodic stochastic matrix, there is a unique stationary 
solution π satisfying: 
π = πS . 
(8) 
The stationary distribution π can be computed iteratively via 
a random walk on the Markov chain deﬁned by the stochastic ma- 
trix S, or analytically via the computation of the eigenvector associ- 
3 In the remainder of the paper we will use the terms alternative and state inter- 
changeably. 
1033 
 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. 
European Journal of Operational Research 297 (2022) 1030–1041 
ated with the highest eigenvalue of the matrix S. We will interpret 
the stationary distribution π as a weighted ranking, where each 
component of the vector π (each “weight”) represents the impor- 
tance of the corresponding alternative with respect to the whole 
set of alternatives, and we will refer to this method for computing 
rankings as a Rank Centrality (RC) method ( Negahban, Oh, & Shah, 
2016 ). We call the corresponding matrix S a centrality matrix . 
To justify the above interpretation of the stationary vector π, 
we analyse its relation with the initially given preference matrix P . 
According to Eq. (8) , the components of the vector π read: 
πi = 
n 
 
j=1 
π j s ji . 
(9) 
The product π j s ji in the above sum represents the probability of 
transitioning from x j to x i adjusted by the weight of x j and, simi- 
larly as in ( Dopazo & Martínez-Céspedes, 2017 ), can be interpreted 
as the relative importance of alternative x i with respect to the al- 
ternative x j . Then, since πi , according to Eq. (9) , is a sum of such 
products, it can be interpreted as the (absolute) importance of x i . 
Now, according to Eq. (6a) , the transition probabilities s ji are pro- 
portional to preferences p ij , hence we can interpret π j s ji as rela- 
tive preference strength of x i with respect to x j , and πi as (absolute) 
preference strength of x i . 
There are two important properties of the RC method. The ﬁrst 
property is that the ranking dynamics follows a continuous time 
Markov chain in global balance, and the respective balance equa- 
tion can be easily derived from Eq. (6) and Eq. (8) . Namely, from 
Eq. (9) we obtain: 
πi = πi s ii + 
n 
 
j =1 ,j ̸ = i 
π j s ji , 
(10) 
which is equivalent to 
(1 −s ii ) πi = 
n 
 
j =1 ,j ̸ = i 
π j s ji . 
(11) 
From Eq. (6) we have 
1 −s ii = 
n 
 
j =1 ,j ̸ = i 
s ij , 
(12) 
which together with Eq. (11) and Eq. (6a) leads to the following 
equations 
n 
 
j =1 ,j ̸ = i 
s ij πi = 
n 
 
j =1 ,j ̸ = i 
s ji π j 
n 
 
j =1 ,j ̸ = i 
p ji πi = 
n 
 
j =1 ,j ̸ = i 
p ij π j , 
(13) 
which we call the global balance equations. Notice that the stronger 
condition which assumes a term-by-term equality between the 
sums in Eq. (13) , for every i ∈ { 1 , . . . , n } , is called a detailed balance . 
We discuss the case of a detailed balance in a subsequent section. 
The second property is given by the relation between the com- 
ponents of the stationary solution (ranking) and the initial prefer- 
ence degrees that follows directly from the second global balance 
equation: 
πi = 
1 
 n 
j =1 ,j ̸ = i p ji 
n 
 
j =1 ,j ̸ = i 
p ij π j . 
(14) 
Note that if we did not have the terms π j on the right hand- 
side of the Eq. (14) , then the method would have been equivalent 
to the Netﬂow method since πi would be proportional to  n 
j̸ = i p ij 
which is the case for NF (x i ) too as seen in Eq. (4) . However, hav- 
ing π j on the right-hand side of Eq. (14) reﬂects the idea of cen- 
trality ranking. Namely, the importance of each alternative x j ̸ = x i 
quantiﬁed by π j is taken into account when determining πi . Thus, 
weak alternatives that have low π j due to being dominated by 
many other alternatives will not contribute much to the increase 
of πi even if p ij is large, because one needs to consider the prod- 
uct p ij π j and not only p ij as in the classical Netﬂow method. In- 
formally, this means that beating weak alternatives, i.e. alternatives 
with low π j , does not increase much the ranking. This is one of the 
core ideas of the Rank Centrality method ( Negahban et al., 2016 ). 
3.2. The GDM method 
Our framework for preference aggregation consists of the fol- 
lowing subsequent steps: 
1. Consider a set of m experts E = { e 1 , . . . , e m } . Each expert e k , 
1 ≤k ≤m , has a pairwise preference matrix P (k ) over the set 
of alternatives X = { x 1 , . . . , x n } . 
2. Using Eq. (6) , for each matrix P (k ) we compute the correspond- 
ing stochastic matrix S (k ) . 
3. We solve Eq. (8) for each expert e k , i.e. we solve π = πS (k ) , for 
k = 1 , . . . , m , and denote the unique solution by π (k ) . The vector 
π (k ) = [ π (k ) 
1 , . . . , π (k ) 
n ] deﬁnes a weighted ranking of the alter- 
natives corresponding to the preferences of the expert e k over 
the set of n alternatives. As observed in the previous section, 
π (k ) 
i 
can be interpreted as the preference strength of the alter- 
native x i according to expert e k . Then, since π (k ) is a probability 
distribution over X, it can be seen as representing the expert 
e k ’s distribution of preference strengths over X. 
4. We deﬁne the collective ranking vector as the arithmetic aver- 
age of the individual ranking vectors, determining its compo- 
nents as follows: 
π (c) 
i 
= 1 
m 
m 
 
k =1 
π (k ) 
i . 
(15) 
Notice that, by taking the arithmetic average of the individual 
ranking vectors as the aggregated state π (c) , one naturally deﬁnes 
the consensual stage with respect to that aggregated state: perfect 
consensus occurs when all the experts arrive at the same opinion 
given by π (c) . Moreover, such deﬁnition of perfect consensus state 
reﬂects the assumption that the perfect consensus state should 
not be near to some speciﬁc expert and in prejudice to the other. 
From a more physical perspective, one can take π (c) as the cen- 
ter of mass of the set of opinions of the m experts (expressed as 
weighted rankings), in the space of all the possible opinions, i.e. it 
is the unique point from which all the experts’ opinions are seen 
equally distributed,  m 
k =1 (π (k ) 
i 
−π (c) 
i ) = 0 , for every i = 1 , . . . , n . In 
other words, using the arithmetic average in the aggregation phase 
of the GDM process provides a safe alternative to reaching a con- 
sensus, in the absence of a special third phase for that purpose in 
the process. 
An extension to WA or OWA is straightforward and does not 
compromise the bulk of our framework: For any choice of weights, 
which should depend on the speciﬁc set of experts and/or the spe- 
ciﬁc decision making context, rankings and preferences will still be 
treatable within our framework. 
3.3. The detailed balance case 
Recall that the stationary vector satisﬁes the detailed balance 
(time reversibility) property if the following equation holds: 
πi s ij = π j s ji , 
(16) 
for every i, j ∈ { 1 , . . . , n } . 
1034 
 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. 
European Journal of Operational Research 297 (2022) 1030–1041 
In this section we assume that Eq. (16) holds for the elements 
of the stochastic matrix S and the components of the correspond- 
ing stationary vector obtained in steps 2. and 3. in the previous 
section. Then, combining Eq. (5) , Eq. (6) and Eq. (16) , one arrives 
to the following equation equivalent to Eq. (16) : 
p ij = 
πi 
πi + π j 
. 
(17) 
Eq. (17) highlights the correspondence between pairwise expressed 
preferences in the form of a preference matrix and the prefer- 
ence strengths assigned to the alternatives in the corresponding 
weighted ranking vector. Note that Eq. (17) implies transitivity 
of the preference matrix P (from p ij > 0 . 5 and p jk > 0 . 5 follows 
p ik > 0 . 5 ). 
Notice that Eq. (17) means that the preference relation P satis- 
ﬁes the Bradley-Terry-Luce (BTL) model ( van Berkum, 1997 ). It was 
demonstrated also by Rajkumar and Shivani ( Rajkumar & Agarwal, 
2014 ) that the time-reversibility of S is equivalent to the existence 
of an underlying BTL model that describes the preferences in P ac- 
cording to their preference strengths π. 
At this juncture, we shall present a theorem that provides 
a mathematical interpretation of the stationary distribution of 
the centrality matrix S corresponding to the preference matrix P , 
namely that the stationary distribution of S is a maximum likeli- 
hood estimate of the BTL model underlying P . 
Theorem 1. Let the BTL pairwise comparison model be deﬁned by 
a parameter vector π = [ π1 , . . . , πn ] , πi ∈ (0 , 1) , i.e. p ij = 
πi 
πi + πj , for 
i, j ∈ { 1 , . . . , n } , where p ij = P (x i > x j ) . 4 Let P = [ p ij ] be a preference 
matrix and let S be its corresponding centrality matrix deﬁned by Eq. 
(6a) and Eq. (6b) . Then the Maximum Likelihood Estimate (MLE) of 
the BTL model satisﬁes the global balance equation with P . 
The proof of the above theorem can be found in Appendix B . 
The theorem states that the MLE of the parameter vector π of the 
BTL model for pairwise comparisons of n alternatives, π ∗, satisﬁes 
the global balance property given in Eq. (13) with the ground truth 
probabilities P of the model. This means that π ∗is a stationary 
distribution of the centrality matrix S corresponding to P , since the 
global balance equations in Eq. (13) are derived from the stationary 
distribution in Eq. (9) through a series of equivalence steps. Finally, 
since the stationary distribution of S is unique on the unit interval, 
we can conclude that it is equal to π ∗, the MLE of the BTL model 
in which P describes the probabilities of the pairwise comparisons. 
In Section 3.1 we discussed two general properties of the RC 
method. Here, we observe that in the special case when the rank- 
ing vectors determined in step 3. of the GDM procedure satisfy de- 
tailed balance, i.e. the equations (16) and (17) , two desirable prop- 
erties of the aggregation processes are satisﬁed: internal consis- 
tency and the Pareto principle. We interpret these properties simi- 
larly as in ( Dong & Zhang, 2014 ) and ( Chiclana, Herrera, & Herrera- 
Viedma, 2002 ). 
Internal Consistency. In our setting, internal consistency can 
be understood as the consistency of the process that transforms 
each expert’s opinion from its initial form of a preference matrix, 
through a stochastic matrix, to its end form of a weighted ranking 
vector. In other words, the property of internal consistency is sat- 
isﬁed if the following holds: The derived individual ranking of the 
k -th expert by the procedure described in Section 3.1 , reﬂects her 
initial preference relation, ranking higher (assigning higher weights 
to) the alternatives she prefers more: p (k ) 
ij ≥p (k ) 
ji if and only if 
4 x i > x j can be interpreted as “x i wins over x j ”, “x i is preferred to x j ”, etc., and 
P(x i > x j ) is the probability of this event that is to be estimated from a number of 
pairwise comparisons in the set of alternatives X = { x 1 , . . . , x n } . 
π (k ) 
i 
≥π (k ) 
j , for every i, j ∈ { 1 , . . . , n } . This property follows imme- 
diately from Eq. (17) . 
Pareto principle. The general interpretation of the Pareto princi- 
ple (unanimity) in the social-choice theory is as follows: If all the 
experts agree upon a certain issue, then this agreement is reﬂected 
in the derived collective opinion. In our framework, it can be inter- 
preted as the following requirement: If all the experts prefer the 
alternative x i over the alternative x j in their individual preference 
relations, then x i ranks higher than x j in the collective ranking. 
More formally, if p (k ) 
ij ≥p (k ) 
ji , for every k = 1 , . . . , m , then π c 
i ≥π c 
j . 
This is a consequence of Eq. (17) and Eq. (15) : If p (k ) 
ij ≥p (k ) 
ji , for 
every k = 1 , . . . , m , then, from Eq. (17) it follows that π (k ) 
i 
≥π (k ) 
j , 
for every k = 1 , . . . , m . From the last and Eq. (15) , it follows that 
π (c) 
i 
≥π (c) 
j . 
Note that the above two properties are based on qualitative 
comparisons between preferences where neither the magnitude 
of preferences and preference strengths nor the information on 
whether the dominated alternatives are weak or strong, is taken 
into account. Since these are crucial elements in the Rank Central- 
ity method that enable deriving meaningful rankings, they justify 
the violation of the properties of internal consistency and Pareto 
optimality in the general case. This is clearly demonstrated by our 
example in Section 5.1 . It would be interesting, however, to exam- 
ine the sensitivity of the latter properties to changes in the initial 
matrices. 
4. Sensitivity Analysis (SA) 
In this section we perform a theoretical sensitivity analysis of 
the Rank Centrality method. More speciﬁcally, we analyse the sen- 
sitivity of the output of the procedure described in Section 3.1 in 
face of small variations of the input, i.e. small variations in the val- 
ues of the matrix parameters. The aim of this analysis is to under- 
stand how the centrality-based ranking of the alternatives is af- 
fected by small changes in the experts’ opinions. As a basis for our 
analysis we use the derivatives of the output, and we largely apply 
results from Golub and Meyer ( Golub & Meyer, 1986 ). 
Recall that the input of the RC ranking method is an n × n pref- 
erence matrix P ( n ≥2 ) that is additive reciprocal, i.e. a matrix 
whose elements p ij are in the unit interval and obey the condi- 
tion 
p ij = 1 −p ji . 
(18) 
We consider an ϵ-perturbation of the matrix P resulting in a 
new matrix ˜ 
P (ϵ) , where the preferences associated with one par- 
ticular pair of alternatives (x k , x l ) change as follows: 5 
˜ 
p kl = p kl + ϵ
(19) 
with 0 < ϵ ≪1 , and consequently, from Eq. (5) , 
˜ 
p lk = 1 −˜ 
p kl = p lk −ϵ. 
(20) 
Let S and ˜ 
S (ϵ) be the centrality matrices of P and ˜ 
P (ϵ) respec- 
tively. Note that ˜ 
P (0) = P and ˜ 
S (0) = S. Whenever there is no con- 
fusion, we will omit the dependency on ϵ from the notation. Ac- 
cording to Eq. (6) , the corresponding entries of ˜ 
S (ϵ) are then given 
by: 
˜ 
s kl = 
1 
n −1 ˜ 
p lk = s kl −
ϵ
n −1 , 
˜ 
s lk = s lk + ϵ
n −1 . 
5 For simplicity, but also for clarity of the observations we make, we restrict to 
the case of varying the preferences related to only one pair of alternatives. 
1035 
 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. 
European Journal of Operational Research 297 (2022) 1030–1041 
As for the diagonal terms, the only terms affected by the per- 
turbation in the preference matrix are ˜ 
s kk and ˜ 
s ll : 
˜ 
s kk = s kk + ϵ
n −1 , 
˜ 
s ll = s ll −
ϵ
n −1 . 
All these variations can be written in a compact form for the 
centrality matrix as 
˜ 
S (ϵ) = S + S ϵ
where 
S ϵ = 
k 
l 
⎛ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎝ 
⎞ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎠ 
0 
. . . 
0 
. . . 
0 
. . . 
0 
. . . 
. . . 
. . . 
. . . 
. . . 
. . . 
. . . 
0 
. . . 
ϵ
n −1 
. . . 
−ϵ
n −1 
. . . 
0 
k 
. . . 
. . . 
. . . 
. . . 
. . . 
. . . 
. . . 
0 
. . . 
ϵ
n −1 
. . . 
−ϵ
n −1 
. . . 
0 
l 
. . . 
. . . 
. . . 
. . . 
. . . 
. . . 
. . . 
0 
. . . 
0 
. . . 
0 
. . . 
0 
(23) 
Theorem 2. Let ˜ 
π(ϵ) be the stationary distribution of ˜ 
S (ϵ) . Then 
∂ ˜ 
πi (ϵ) 
∂ϵ
= ˜ 
πk + ˜ 
πl 
n −1 (t li −t ki ) πi , 
(24) 
where t ji denotes the mean ﬁrst passage time from x i to x j , i.e. the 
expected number of steps to reach state x j for the ﬁrst time starting 
from state x i , in the unperturbed centrality matrix ˜ 
S (0) = S. 
The proof of Theorem 2 is given in Appendix C . Note that Eq. 
(24) implies ∂ ˜ 
πk (ϵ) 
∂ϵ
= ˜ 
πk + ˜ 
πl 
n −1 t lk πk > 0 and ∂ ˜ 
πl (ϵ) 
∂ϵ
= −˜ 
πk + ˜ 
πl 
n −1 t kl πl < 0 
which is expected. 
The perturbation of the preference associated with the pair 
(x k , x l ) affects every component ˜ 
πi in the stationary distribution 
˜ 
π(ϵ) of the centrality matrix ˜ 
S (ϵ) . For suﬃciently small ϵ these 
components can be written as 6 
˜ 
πi ≃ πi + ϵ
∂ ˜ 
πi 
∂ϵ

ϵ=0 
= πi 

1 + ϵ ˜ 
πk + ˜ 
πl 
n −1 (t li −t ki ) 

. 
(25) 
Equation (25) can be interpreted as follows: For similar ﬁrst pas- 
sage times between alternatives, the perturbation of preferences in 
a single alternative-pair has an effect in the stationary distribution 
that is proportional to the amplitude of its components: dominant 
alternatives (higher rank) are more affected than other alternatives. 
One important consequence of Eq. (25) is that one can estimate 
ﬁrst passage times for all possible transitions between alternatives. 
Indeed, for k = i and l = i , since t kk = t ll = 0 by deﬁnition of ﬁrst 
passage time, Eq. (25) yields respectively 
t lk = 

˜ 
πk 
πk 
−1 

n −1 
ϵ
1 
˜ 
πk + ˜ 
πl 
, 
(26a) 
t kl = 

1 −˜ 
πl 
πl 

n −1 
ϵ
1 
˜ 
πk + ˜ 
πl 
. 
(26b) 
Equation (25) can be used to estimate the global deviation of 
˜ 
π(ϵ) from the ”unperturbed” stationary distribution ˜ 
π(0) : 
|| ˜ 
π(ϵ) −˜ 
π(0) || 2 ≃ ϵ2 ( ˜ 
πk + ˜ 
πl ) 2 
n −1 ⟨ (t li −t ki ) 2 π 2 
i ⟩ i , 
(27) 
6 It is worth mentioning that those two equations can be obtained too by apply- 
ing Proposition 2.1 due to Cho and Meyer ( Cho & Meyer, 20 0 0 ) 
where 
⟨ (t li −t ki ) 2 π 2 
i ⟩ i ≡
1 
n −1 
n 
 
i =1 
(t li −t ki ) 2 π 2 
i . 
(28) 
This equation can be interpreted as follows. The global deviation of 
˜ 
π(ϵ) from the unperturbed stationary distribution ˜ 
π(0) increases 
with a ”weighted” second moment of the components of the un- 
perturbed stationary distribution. The weights for the component 
πi are given by the difference between the ﬁrst passage times from 
the corresponding alternative x i to the ”perturbed altrenatives” x k 
and x l . 
This observation has two main consequences. First, the result 
in Eq. (27) uncovers another intuitive consequence: the compo- 
nents of the stationary distribution which remain unchanged by 
perturbing the preference for a pair of alternatives (x k , x l ) are 
those for which the mean ﬁrst passage times from the corre- 
sponding alternative x i to each alternative in the perturbed pair 
is equal, i.e. t ki = t li . In particular, perturbing the preference for 
pairs of alternatives (x k , x l ) , which are evenly chosen in front of 
all other alternatives x i , i.e. t ki = t li for all i ̸ = k and i ̸ = l, will 
have no impact on the global preference strengths of the al- 
ternatives. Their impact is reduced to local changes of the am- 
plitudes of each alternative in the perturbed pair, namely ˜ 
πk 
and ˜ 
πl . 
Second, since deviations between perturbed and unperturbed 
stationary distribution are easy to measure in practice, Eq. (25) and 
(27) provide new insight for establishing a framework to assess, 
at least at a qualitative level, the impact of local perturbations in 
the global dynamics towards consensus. Namely, the results of this 
section have some implications when it comes to reaching consen- 
sus worth pursuing as future work. In fact, we can formalize the 
consensus problem as a gradient descent optimization where ex- 
perts need to do small adjustment to their preference matrices. 
The sensitivity of Markov chains to their transition probabilities 
can be used for computing the gradient in order to make the in- 
dividual stationary distribution of each expert move towards col- 
lective stationary distribution, by only adjusting the corresponding 
preference matrices. 
5. Testing GDM with FPR: numerical experiments 
In this section we provide a concrete example of a GDM with 
FPR using our method. We ﬁrst compare the results of using our 
method against the results of using the popular Netﬂow method. 
Then, we perform an experimental sensitivity analyses to ex- 
plore what happens to the resulting ranking vector if we vary 
the entries of the initial preference matrices 1. by several values 
of ϵ > 0 applied to the same pair of alternatives; and 2. by a 
small ﬁxed ϵ > 0 applied to different pairs of alternatives in the 
matrix. 
We start by a numerical example highlighting the similarities 
and differences between our algorithm and an algorithm that uses 
the standard Netﬂow (NF) method. 
5.1. A numerical example 
We consider a ﬁrst scenario with two experts ( m = 2 ) and four 
alternatives ( n = 4 ) 7 The experts’ opinions are expressed in the fol- 
7 The code for performing the computations involved in the examples of this sec- 
tion is available at https://github.com/FMZennaro/GDM . The code can be straightfor- 
wardly changed for another number of experts. We have also tested for m = 3 and 
m = 4 , observing the same qualitative results. 
1036 
 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. 
European Journal of Operational Research 297 (2022) 1030–1041 
lowing preference matrices: 
P 1 = 
⎡ 
⎢ 
⎣ 
0 . 50 
0 . 60 
0 . 30 
0 . 10 
0 . 40 
0 . 50 
0 . 25 
0 . 05 
0 . 70 
0 . 75 
0 . 50 
0 . 55 
0 . 90 
0 . 95 
0 . 45 
0 . 50 
⎤ 
⎥ 
⎦ , 
(29a) 
P 2 = 
⎡ 
⎢ 
⎣ 
0 . 50 
0 . 55 
0 . 25 
0 . 05 
0 . 45 
0 . 50 
0 . 25 
0 . 05 
0 . 75 
0 . 75 
0 . 50 
0 . 58 
0 . 95 
0 . 95 
0 . 42 
0 . 50 
⎤ 
⎥ 
⎦ . 
(29b) 
The entries of the preferences matrices P 1 and P 2 differ by 5% or 
more, in a scale from 0 to 1. They can be provided by experts di- 
rectly as numerical values or obtained, for example, by qualitative 
preference modelling. 8 
Assuming, for the sake of illustration, that these preferences 
represent relationships between pairs of four different sport teams 
in two different leagues, the relationships in both leagues share 
two common features: (i) the third team is moderately better than 
the ﬁrst and the second team, while the fourth team is much bet- 
ter than the ﬁrst and the second team, and (ii) the third team 
seems, against intuition, to be better than the fourth team. We ob- 
serve what happens with the ranking vectors derived from these 
two matrices when we apply our method. 
First of all, we normalize the preference matrices into stochastic 
matrices applying the Eq. (6) from Section 3.1 . This produces the 
following centrality matrices: 
S 1 = 
⎡ 
⎢ 
⎣ 
0 . 33 
0 . 13 
0 . 23 
0 . 30 
0 . 20 
0 . 23 
0 . 25 
0 . 32 
0 . 10 
0 . 08 
0 . 67 
0 . 15 
0 . 03 
0 . 02 
0 . 18 
0 . 77 
⎤ 
⎥ 
⎦ , 
S 2 = 
⎡ 
⎢ 
⎣ 
0 . 28 
0 . 15 
0 . 25 
0 . 32 
0 . 18 
0 . 25 
0 . 25 
0 . 32 
0 . 08 
0 . 08 
0 . 69 
0 . 14 
0 . 02 
0 . 02 
0 . 19 
0 . 77 
⎤ 
⎥ 
⎦ . 
Then we apply two direct methods to derive a group ranking of 
the alternatives: 
• (NF+WA) : exploitation is performed by computing a per-expert 
ranking using Netﬂow, and then aggregation is performed by 
computing the ﬁnal collective ranking using WA with uniform 
weights. 
• (RC+WA) : exploitation is performed by computing a per-expert 
ranking using Rank Centrality, and then aggregation is per- 
formed by computing the ﬁnal collective ranking using WA 
with uniform weights. 
The output weighted rankings produced by these methods are 
the following: 
output NF+WA = 
−0 . 383 
−0 . 517 
0 . 36 
0 . 54 
output RC+WA = 
0 . 087 
0 . 069 
0 . 388 
0 . 456 
, 
8 One can, for example, use linguistic preference modelling ( Herrera, Alonso, Chi- 
clana, & Herrera-Viedma, 2009 ), and even give each individual expert the possibility 
to use different preference domains to express their respective preferences. This is- 
sue is studied in ( Delgado, Herrera, Herrera-Viedma, & Martinez, 1998 ) where it is 
shown that in such heterogeneous decision contexts, it is possible to achieve a so- 
lution by ﬁrst making the preferences uniform by converting them into FPRs over 
[0,1] by means of transformation functions. 
corresponding to the following qualitative rankings: 
rank NF+WA = 
4 
3 
1 
2 
rank RC+WA = 
4 
3 
1 
2 
, 
where the i-th element is the index of the alternative with the i- 
th best preference strength (in this case, the 4-th alternative is the 
most preferred, the 3-rd alternative is the second most preferred, 
and so on). The results are identical, and they rank the fourth al- 
ternative at the top, which captures the intuition in the football 
teams example. Note that in the above example, we have violation 
of both Internal Consistency and Pareto Optimality at the alterna- 
tives 3 and 4, but we still obtain a meaningful ranking. 
We now consider a second scenario, again with two experts 
( m = 2 ) and four alternatives ( n = 4 ), but with the following pref- 
erence matrices: 
P 3 = 
⎡ 
⎢ 
⎣ 
0 . 50 
0 . 60 
0 . 20 
0 . 10 
0 . 40 
0 . 50 
0 . 15 
0 . 05 
0 . 80 
0 . 85 
0 . 50 
0 . 55 
0 . 90 
0 . 95 
0 . 45 
0 . 50 
⎤ 
⎥ 
⎦ , 
P 4 = 
⎡ 
⎢ 
⎣ 
0 . 50 
0 . 55 
0 . 15 
0 . 05 
0 . 45 
0 . 50 
0 . 2 
0 . 05 
0 . 85 
0 . 8 
0 . 50 
0 . 58 
0 . 95 
0 . 95 
0 . 42 
0 . 50 
⎤ 
⎥ 
⎦ . 
Notice that this new set of preference matrices preserves the rela- 
tionships of dominance described in i) and ii) above; however the 
degrees by which the third alternative dominates the ﬁrst and the 
second one have been increased, although they remain lower than 
the corresponding ones of the fourth alternative. 
After normalization according to Eq. (6) from Section 3.1 we ob- 
tain the following stochastic centrality matrices: 
S 3 = 
⎡ 
⎢ 
⎣ 
0 . 30 
0 . 13 
0 . 27 
0 . 30 
0 . 20 
0 . 20 
0 . 28 
0 . 32 
0 . 07 
0 . 05 
0 . 73 
0 . 15 
0 . 03 
0 . 02 
0 . 18 
0 . 77 
⎤ 
⎥ 
⎦ , 
S 4 = 
⎡ 
⎢ 
⎣ 
0 . 25 
0 . 15 
0 . 28 
0 . 32 
0 . 18 
0 . 23 
0 . 27 
0 . 32 
0 . 05 
0 . 07 
0 . 74 
0 . 14 
0 . 02 
0 . 02 
0 . 19 
0 . 77 
⎤ 
⎥ 
⎦ . 
Again we apply the two GDM strategies described above 
(NF+WA and RC+WA). The outcomes are: 
output NF+WA = 
−0 . 45 
−0 . 567 
0 . 477 
0 . 54 
output RC+WA = 
0 . 065 
0 . 054 
0 . 441 
0 . 439 
, 
with corresponding rankings: 
rank NF+WA = 
4 
3 
1 
2 
rank RC+WA = 
3 
4 
1 
2 
. 
This time, the results differ in the ordering of the third and the 
forth alternative. The difference in the results between the ﬁrst and 
the second scenario shows that the approach based on rank cen- 
trality has a distinctive sensitivity to the magnitude of the relations 
of preference among the alternatives. In particular, the approach 
based on RC+WA may rank higher alternatives that marginally 
dominate weak alternatives but also marginally dominate strong 
alternatives. This is consistent with the interpretation of rank cen- 
trality provided in ( Negahban et al., 2012; 2016 ). 
1037 
 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. 
European Journal of Operational Research 297 (2022) 1030–1041 
Fig. 2. Output of the two GDM strategies (NF+WA and RC+WA) when applied to ˜ 
P 1 (ϵ) and P 2 as a function of the parameter ϵ. See Eq. (29a) and (30) . 
5.2. Experimental sensitivity analysis 
In this section we perform experimental sensitivity analysis, in- 
vestigating how the result of the group decision making changes 
under a perturbation of amplitude ϵ in the initial preference matri- 
ces. We restrict to the case when only one of the initial preference 
matrices changes in only one pair of alternatives, and we observe 
how various degrees of change affect the result. We consider again 
the ﬁrst scenario we presented in the previous simulation, but this 
time we instantiate a parametric version of the matrix P 1 for the 
ﬁrst expert: 
˜ 
P 1 (ϵ) = 
⎡ 
⎢ 
⎣ 
0 . 50 
0 . 60 
0 . 30 −ϵ
0 . 10 
0 . 40 
0 . 50 
0 . 25 
0 . 05 
0 . 70 + ϵ
0 . 75 
0 . 50 
0 . 55 
0 . 90 
0 . 95 
0 . 45 
0 . 50 
⎤ 
⎥ 
⎦ 
(30) 
with the parameter ϵ assuming values in the interval [0,0.3) in or- 
der to satisfy the requirement that, for every entry, 0 < p ij < 1 . The 
ϵ parameter allows us to increase the margin of the preference of 
the third alternative over the ﬁrst, and, consequently, to narrow 
the gap between the third and the fourth alternative. The prefer- 
ence matrix of the second expert is taken to be the same ﬁxed 
matrix P 2 used in the previous section. We then apply the two di- 
rect methods we considered before (NF+WA and RC+WA) to the 
matrices ˜ 
P 1 (ϵ) and P 2 , while changing the value of the parameter 
ϵ. 
Fig. 2 shows the variation in the output of the two methods as 
a function of the parameter ϵ. The results show that the two direct 
methods respond differently to similar changes. As the parameter 
ϵ increases, the gap between the third and the fourth alternative 
narrows more signiﬁcantly when using RC+WA instead of NF+WA. 
This change also leads to a decrease in the value of the ﬁrst al- 
ternative that is more marked for the RC+WA method; indeed, for 
values of ϵ around 0.20 the ﬁrst alternative becomes less prefer- 
able than the second one; for the range of ϵ that we considered, 
we do not notice a similar change in the ordering of the ﬁrst and 
the second alternative in the NF+WA method. 
When applying RC+WA in a scenario with many alternatives 
where we only perturb one pair of them, it is not always obvi- 
ous how this perturbation will reﬂect on the resulting preference 
strengths of the alternatives: which of them will have their pref- 
Table 1 
Estimates of all ﬁrst passages times ˆ 
t ij according to Eq. (26) for matrix S 1 , com- 
pared with the values computed directly from the respective Markov chain simu- 
lation. 
k/l
1 
2 
3 
4 
1 
—
ˆ 
t 12 = 11 . 7042 
ˆ 
t 13 = 12 . 7304 
ˆ 
t 14 = 15 . 1242 
ˆ 
t 21 = 16 . 3057 
ˆ 
t 31 = 4 . 8454 
ˆ 
t 41 = 4 . 1701 
t 12 = 11 . 7039 
t 13 = 12 . 7326 
t 14 = 15 . 1259 
t 21 = 16 . 3063 
t 31 = 4 . 8463 
t 41 = 4 . 1706 
2 
ˆ 
t 21 = 16 . 3057 
—
ˆ 
t 23 = 16 . 8106 
ˆ 
t 24 = 19 . 8224 
ˆ 
t 12 = 11 . 7024 
ˆ 
t 32 = 4 . 7643 
ˆ 
t 42 = 4 . 1132 
t 21 = 16 . 3063 
t 23 = 16 . 8135 
t 24 = 19 . 8258 
t 12 = 11 . 7039 
t 32 = 4 . 7653 
t 42 = 4 . 1140 
3 
ˆ 
t 31 = 4 . 8473 
ˆ 
t 32 = 4 . 7665 
—
ˆ 
t 34 = 5 . 3176 
ˆ 
t 13 = 12 . 7349 
ˆ 
t 23 = 16 . 8167 
ˆ 
t 43 = 5 . 2789 
t 31 = 4 . 8463 
t 32 = 4 . 7653 
t 34 = 5 . 3184 
t 13 = 12 . 7326 
t 23 = 16 . 8135 
t 43 = 5 . 2797 
4 
ˆ 
t 41 = 4 . 1713 
ˆ 
t 42 = 4 . 1148 
ˆ 
t 43 = 5 . 2805 
—
ˆ 
t 14 = 15 . 1280 
ˆ 
t 24 = 19 . 8291 
ˆ 
t 34 = 5 . 3192 
t 41 = 4 . 1706 
t 42 = 4 . 1140 
t 43 = 5 . 2797 
t 14 = 15 . 1259 
t 24 = 19 . 8258 
t 34 = 5 . 3184 
erence strengths increased or decreased and for how much. As we 
will see, our theoretical perturbation analysis given by Eq. (24) can 
predict and interpret the changes based on the mean ﬁrst pas- 
sage times and the magnitudes of the preference strengths. The 
true mean ﬁrst passage times are given in Table 1 . In our case, 
the pair that is changed is (x k , x l ) = (3 , 1) . As per our theoretical 
results, the preference strength of the alternative 3 for expert 1 
computed by RC will increase proportionally to t 13 = 12 . 7326 mod- 
erated by the strength π (1) 
3 
of the alternative itself. 9 Similarly the 
preference strength of the alternative 1 for expert 1 computed by 
RC will decrease proportionally to t 31 = 4 . 8463 moderated by the 
strength π (1) 
1 
of the alternative itself. But what about the rest of 
alternatives? The changes in the preference strength of the alterna- 
tive 4 for expert 1 is proportional to t 34 −t 14 = 5 . 3184 −15 . 1259 = 
−9 . 8075 moderated by π (1) 
4 , meaning it will decrease. For alterna- 
tive 2, the changes in the preference strength for the ﬁrst expert is 
proportional to t 32 −t 12 = 4 . 7653 −11 . 7039 = −6 . 9386 moderated 
9 Thus the aggregated preference strength of the alternative 3 will increase. 
1038 
 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. 
European Journal of Operational Research 297 (2022) 1030–1041 
-0.3
-0.15
0
0.15
0.3
Deviation (%)
-0.3
-0.15
0
0.15
0.3
Deviation (%)
1
2
3
4
i
-0.3
-0.15
0
0.15
0.3
Deviation (%)
1
2
3
4
i
1
2
3
4
i
1
2
3
4
i
(k,l)=(1,2)
(k,l)=(1,3)
(k,l)=(1,4)
(k,l)=(2,1)
(k,l)=(2,3)
(k,l)=(2,4)
(k,l)=(3,1)
(k,l)=(3,2)
(k,l)=(3,4)
(k,l)=(4,3)
(k,l)=(4,2)
(k,l)=(4,1)
Fig. 3. Deviation of each component of the perturbed stationary distribution ˜ 
π(ϵ) 
in percentage of the respective component of the unperturbed stationary distribu- 
tion π(0) , when the preference matrix is changed for one single pair of alternatives 
(x k , x l ) . In all cases ϵ = 0 . 001 . See Eq. (25) . 
by the strength the alternative itself π (1) 
2 . Since π (1) 
2 
is small, the 
magnitude of the latter changes is small too as can be seen in the 
aggregated weighted ranking given in Fig. 2 . 
To end the sensitivity analysis for this particular numerical 
experiment, we ﬁx the perturbation amplitude at a small value, 
namely ϵ = 0 . 001 , and apply it to each pair of alternatives (x k , x l ) 
in the matrix P 1 . The results are shown in Fig. 3 . While the larger 
deviations are typically observed for the components of the sta- 
tionary distribution associated with the perturbed pair, namely πk 
and πl , one also observes signiﬁcant changes in the other compo- 
nents. For example, when perturbing the pair (4,2) one observes 
also a signiﬁcant change in the amplitude of the ﬁrst component, 
and when perturbing the pair (3,4), all components are signiﬁ- 
cantly affected. Note that, in all cases the deviations for (x k , x l ) and 
(x l , x k ) are symmetric, as expected from Eq. (25) . 
Finally, in Fig. 4 we show the difference of the ﬁrst passage 
times, t li −t ki , for each perturbated pair of alternatives (x k , x l ) con- 
sidered in Fig. 3 , as computed directly from Eq. (25) . Similarly, one 
also observes cases where the perturbation of one particular pair 
of alternatives induces a change in the transitions from another al- 
-20
-10
0
10
20
tli-tki
-20
-10
0
10
20
tli-tki
1
2
3
4
i
-20
-10
0
10
20
tli-tki
1
2
3
4
i
1
2
3
4
i
1
2
3
4
i
(k,l)=(1,2)
(k,l)=(1,3)
(k,l)=(1,4)
(k,l)=(2,1)
(k,l)=(2,3)
(k,l)=(2,4)
(k,l)=(3,1)
(k,l)=(3,2)
(k,l)=(3,4)
(k,l)=(4,3)
(k,l)=(4,2)
(k,l)=(4,1)
Fig. 4. For each perturbation of the preference matrix shown in Fig. 3 one plots the 
difference of ﬁrst passage times, t li −t ki , from each alternative x i to each alternative 
of the perturbed pair (x k , x l ) . The values were obtained by solving Eq. (25) for t li −
t ki . 
ternative to the alternatives in the perturbed pair. Moreover, ap- 
plying Eq. (26) we estimate the ﬁrst passage times for all pairs of 
alternatives. Notice that, repeating the numerical experiment in- 
terchanging the role of k and l enables to make two estimates for 
each ﬁrst passage time. As shown in Tab. 1 , in all the cases both 
estimates are close to each other, showing the ability of our pro- 
cedure for estimating this dynamical property of consensus pro- 
cesses. 
6. Conclusions and future work 
In this paper we have presented a direct approach to aggregat- 
ing fuzzy preference relations proposing a GDM method based on 
rank centrality. The method has the advantage of providing a natu- 
ral interpretation of the preference degrees as transition probabil- 
ities in a Markov chain and obtaining the corresponding weighted 
rankings by well-established computational methods. Moreover, as 
we show with our numerical examples, our approach shows more 
sensitivity to small variations in the preference values compared to 
other similar approaches. 
The natural next step is to design an experiment to test our 
framework and compare it with other GDM with FPR frameworks 
in the literature. We have implemented an online platform for col- 
lecting data during an iterative process towards consensus, which 
will enable to investigate the distances in the opinion space, either 
to the collective opinion, or pairwise distances between experts’ 
opinions. In this way we can test our framework for modelling 
processes towards reaching a consensus, and examine which ini- 
tial preference matrices lead to a consensual opinion. Finally, such 
experimental setup will also enable to investigate the time inter- 
val needed for achieving consensus in various real-life applications, 
and determine which framework enables the fastest converging it- 
erative processes. Moreover, investigating the inconsistency ( Kou, 
Ergu, & Shang, 2014; Kou & Lin, 2014; Lin, Kou, Peng, & Alsaadi, 
2020 ) directly from a centrality matrix is a future research direc- 
tion worth investigating. 
We hope that the current work can fuel more research interest 
in bridging the gap between the GDM community and researchers 
in probability theory and its applications. 
Acknowledgement 
The work of Enrique Herrera Viedma was supported by the 
Spanish State Research Agency under Project PID2019-103880RB- 
I00/AEI/10.13039/501100011033. 
Appendix A. Irreducibility and aperiodicity of the stochastic 
matrix 
A Markov chain is irreducible if it is possible to get to any 
state from any state. Clearly, if the stochastic matrix S of a Markov 
chain with n states satisﬁes the condition: s ij > 0 , for every i, j ∈ 
{ 1 , . . . , n } , then it (and so the Markov chain) is irreducible. The 
above condition is easy to prove under the assumption we made 
in Eq. (7) . Namely, from Eq. (6a) and the assumption p ij > 0 (fol- 
lowing from Eq. (7) ), it follows that s ij > 0 , for every i ̸ = j. If we 
suppose that s ii = 0 for some i , then, from Eq. (6b) , it will follows 
that  
i ̸ = j p ij = n −1 . From this and the fact that p ij ∈ [0 , 1] , it fol- 
lows p ij = 1 , for i ̸ = j, which is in contradiction with the assump- 
tion p ij ̸ = 1 (again following from Eq. (7) ). 
It is easy to observe that the centrality matrix and the corre- 
sponding Markov chain are aperiodic. For a Markov chain to be 
aperiodic, every state has to be aperiodic, that is, for any state i 
the greatest common divisor of the number of steps k that it may 
take to return to i is 1. Now, from Eq. (6) and from the discus- 
sion on irreducibility, we have that s ij > 0 for all i, j. Therefore, for 
1039 
 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. 
European Journal of Operational Research 297 (2022) 1030–1041 
any state i , there is a non-zero probability of returning to state i 
in k steps, for k = { 1 , 2 , 3 , . . . } . The greatest common divisor of this 
number of steps is then 1. Thus every state i is aperiodic, and the 
Markov chain with its associated centrality matrix is aperiodic. 
Appendix B. Proof of Theorem 1 
To prove Theorem 1 , let us consider a BTL model with parame- 
ter vector π such that p ij = 
πi 
πi + πj . Let M ij be the number of sam- 
ple comparisons between x i and x j and m ij the samples in which 
alternative x i wins over x j . Hence, there is a real number, M, such 
that 
M ij = m ij + m ji ≡
M(πi + π j ) 
. 
(B.1) 
where ⌈ . ⌉ denotes the operator that rounds to nearest integer. In 
what follows we will only need the limit of large values of M ij 
(i.e. M ij → ∞ ) for which M → ∞ and 
M(πi + π j ) 
→ M(πi + π j ) . 
Under the assumption of independent and identically dis- 
tributed samples, the likelihood function of the BTL model is given 
by: 
L (π) = 
n 
 
i =1 
n 
 
j=1 
j̸ = i 
p 
m ij 
ij = 
n 
 
i =1 
n 
 
j=1 
j̸ = i 

πi 
πi + π j 
m ij 
, 
(B.2) 
where we disregard the case πi = 0 , which only occurs in the 
“pathological” case where for some j ̸ = i , p ij = 0 . We take the log- 
likelihood function of (B.2) 
log L (π) = 
n 
 
i =1 
n 
 
j =1 ,j ̸ = i 
m ij log 
πi 
πi + π j 
. 
(B.3) 
To ﬁnd the Maximum Likelihood Estimate (MLE) of the BTL model 
we take the partial derivative of the likelihood function with re- 
spect to the parameters of the model: 
∂ log L (π) 
∂πi 
= 
n 
 
j =1 ,j ̸ = i 

m ij 
1 
πi 
−(m ij + m ji ) 
1 
πi + π j 

= 
n 
 
j =1 ,j ̸ = i 

m ij ( 1 
πi 
−
1 
πi + π j ) −m ji 
1 
πi + π j 

= 
n 
 
j =1 ,j ̸ = i 

m ij 
1 
πi 
π j 
πi + π j 
−m ji 
1 
πi + π j 

= 1 
πi 
n 
 
j =1 ,j ̸ = i 

m ij π j 
πi + π j 
−m ji 
πi 
πi + π j 

We determine the MLE π ∗as the value of π at which the par- 
tial derivatives are zero, that is: 
n 
 
j =1 ,j ̸ = i 
m ij 
π ∗
j 
π ∗
i + π ∗
j 
= 
n 
 
j =1 ,j ̸ = i 
m ji 
π ∗
i 
π ∗
i + π ∗
j 
(B.4) 
By applying the law of large numbers, p ij can also be deﬁned as: 
p ij = lim 
M ij →∞ 
m ij 
M ij 
= lim 
M→∞ 
m ij 
M(πi + π j ) = lim 
M→∞ 
m ij 
M(π ∗
i + π ∗
j ) 
Please note that we used the argument that π ∗
i + π ∗
j ≈πi + π j by 
virtue of the MLE. Similarly, 
p ji = lim 
M→∞ 
m ji 
M(π ∗
i + π ∗
j ) 
Hence in the limit of M → ∞ 
m ij = p ij M(π ∗
i + π ∗
j ) 
(B.5) 
and 
m ji = p ji M(π ∗
i + π ∗
j ) . 
(B.6) 
By substituting Eq. (B.5) and Eq. (B.6) in Eq. (B.4) we obtain 
n 
 
j =1 ,j ̸ = i 
p ij M(π ∗
i + π ∗
j ) 
π ∗
j 
π ∗
i + π ∗
j 
= 
n 
 
j =1 ,j ̸ = i 
p ji M(π ∗
i + π ∗
j ) 
π ∗
i 
π ∗
i + π ∗
j 
, 
which yields the following global balance equation: 
n 
 
j =1 ,j ̸ = i 
p ij π ∗
j = 
n 
 
j =1 ,j ̸ = i 
p ji π ∗
i . 
Appendix C. Proof of Theorem 2 
Let A ∗be the group inverse of A = I −S ( Golub & Meyer, 1986 ), 
i.e. A ∗is the unique matrix 10 satisfying the three equations AA ∗A = 
A , A ∗AA ∗= A ∗and A ∗A = AA ∗. Let a ∗
ij denote the entries of A ∗, and 
let A ∗
∗i be the i-th column of A ∗. Then, we can apply Theorem 3.2 
from Golub and Meyer ( Golub & Meyer, 1986 ) to study the sensi- 
tivity of the ranking to changes of ϵ, namely: 
∂ ˜ 
πi (ϵ) 
∂ϵ
= ˜ 
π(ϵ) ∂ ˜ 
S (ϵ) 
∂ϵ
A ∗
∗i = ˜ 
π(ϵ) ∂S ϵ(ϵ) 
∂ϵ
A ∗
∗i , 
(C.1) 
where 
∂S ϵ(ϵ) 
∂ϵ
= 
k 
l 
⎛ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎜ 
⎝ 
⎞ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎟ 
⎠ 
0 
. . . 
0 
. . . 
0 
. . . 
0 
. . . 
. . . 
. . . 
. . . 
. . . 
. . . 
. . . 
0 
. . . 
1 
n −1 
. . . 
−
1 
n −1 
. . . 
0 
k 
. . . 
. . . 
. . . 
. . . 
. . . 
. . . 
. . . 
0 
. . . 
1 
n −1 
. . . 
−
1 
n −1 
. . . 
0 
l 
. . . 
. . . 
. . . 
. . . 
. . . 
. . . 
. . . 
0 
. . . 
0 
. . . 
0 
. . . 
0 
(C.2) 
Let e i = (0 , . . . , 0 , 1 , 0 , . . . , 0) T be the unit vector with entries δik 
for k = 1 , . . . , n . Then, ∂S ϵ(ϵ) 
∂ϵ
can be written as 
∂S ϵ(ϵ) 
∂ϵ
= 
1 
n −1 [ e k  e k −e k  e l −e l  e l + e l  e k ] , 
where  denotes the tensor product between unit vectors. Substi- 
tuting this expression in Eq. (C.1) yields 
∂ ˜ 
πi (ϵ) 
∂ϵ
= 
1 
n −1 
n 
 
r=1 
n 
 
s =1 
˜ 
πr 
 
(e k  e k ) rs −(e k  e l ) rs 
−(e l  e l ) rs + (e l  e k ) rs 
 
a ∗
si 
= 
1 
n −1 
n 
 
r=1 
n 
 
s =1 
˜ 
πr (δkr δks −δkr δls 
−δlr δls + δlr δks ) a ∗
si 
= 
1 
n −1 ( ˜ 
πk a ∗
ki −˜ 
πk a ∗
li −˜ 
πl a ∗
li + ˜ 
πl a ∗
ki ) 
= ˜ 
πk + ˜ 
πl 
n −1 (a ∗
ki −a ∗
li ) , 
(C.3) 
where δij is the Kronecker-delta, δij = 1 if i = j and zero otherwise. 
10 Matrix A ∗is also called ”Drazin inverse” of Laplacian, which according to 
Mahadevan et al. (2009) ”reveals a great deal of information about the structure of 
the Markov chain ”. 
1040 
 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. 
European Journal of Operational Research 297 (2022) 1030–1041 
According to Cho and Meyer ( Cho & Meyer, 20 0 0 ), A ∗is diago- 
nally dominant over the columns, meaning that for all pairs (i, j) 
a ∗
ji = a ∗
ii −t ji πi 
(C.4) 
where t ji denotes the mean ﬁrst passage time from x i to x j . Intro- 
ducing Eq. (C.4) in Eq. (C.3) yields Eq. (24) in Theorem 2 . 
References 
van Berkum, E. (1997). Bradley-terry model. In Encyclopaedia of mathematics. sup- 
plement i (pp. 148–148). Kluwer Academic Publishers. 
Bouyssou, D. (1992). Ranking methods based on valued preference relations: a char- 
acterization of the net ﬂow method. European Journal of Operational Research, 
60 (1), 61–67 . 
Cabrerizo, F. J. , Moreno, J. M. , Pérez, I. J. , & Herrera-Viedma, E. (2010). Analyzing con- 
sensus approaches in fuzzy group decision making: Advantages and drawbacks. 
Soft Computing, 14 (5), 451–463 . 
Capuano, N. , Chiclana, F. , Fujita, H. , Herrera-Viedma, E. , & Loia, V. (2017). Fuzzy 
group decision making with incomplete information guided by social inﬂuence. 
IEEE Transactions on Fuzzy Systems, 26 (3), 1704–1718 . 
Chiclana, F. , Herrera, F. , & Herrera-Viedma, E. (2002). A note on the internal con- 
sistency of various preference representations. Fuzzy Sets and Systems, 131 (1), 
75–78 . 
Chiclana, F. , Herrera, F. , Herrera-Viedma, E. , & Martínez, L. (2003). A note on the 
reciprocity in the aggregation of fuzzy preference relations using OWA opera- 
tors. Fuzzy Sets and Systems, 137 (1), 71–83 . 
Cho, G. E. , & Meyer, C. D. (20 0 0). Markov chain sensitivity measured by mean ﬁrst 
passage times. Linear Algebra and its Applications, 316 (1–3), 21–28 . 
Delgado, M. , Herrera, F. , Herrera-Viedma, E. , & Martinez, L. (1998). Combining nu- 
merical and linguistic information in group decision making. Information Sci- 
ences, 107 (1–4), 177–194 . 
Dong, Y. , Xu, Y. , Li, H. , & Feng, B. (2010). The OWA-based consensus operator un- 
der linguistic representation models using position indexes. European Journal of 
Operational Research, 203 (2), 455–463 . 
Dong, Y. , Xu, Y. , & Yu, S. (2009). Linguistic multiperson decision making based 
on the use of multiple preference relations. Fuzzy Sets and Systems, 160 (5), 
603–623 . 
Dong, Y. , & Zhang, H. (2014). Multiperson decision making with different prefer- 
ence representation structures: A direct consensus framework and its proper- 
ties. Knowledge-based Systems, 58 , 45–57 . 
Dopazo, E. , & Martínez-Céspedes, M. L. (2017). Rank aggregation methods deal- 
ing with ordinal uncertain preferences. Expert Systems with Applications, 78 , 
103–109 . 
Fan, Z.-P. , Ma, J. , Jiang, Y.-P. , Sun, Y.-H. , & Ma, L. (2006). A goal programming ap- 
proach to group decision making based on multiplicative preference relations 
and fuzzy preference relations. European Journal of Operational Research, 174 (1), 
311–321 . 
Fernandez, E. , & Leyva, J. C. (2004). A method based on multiobjective optimiza- 
tion for deriving a ranking from a fuzzy preference relation. European Journal of 
Operational Research, 154 (1), 110–124 . 
García-Lapresta, J. L. , Martínez-Panero, M. , & Meneses, L. C. (2009). Deﬁning the 
borda count in a linguistic decision making context. Information Sciences, 
179 (14), 2309–2316 . 
Gleich, D. F. (2015). Pagerank beyond the web. SIAM Review, 57 (3), 321–363 . 
Golub, G. H. , & Meyer, C. D., Jr (1986). Using the QR factorization and group inver- 
sion to compute, differentiate, and estimate the sensitivity of stationary prob- 
abilities for Markov chains. SIAM Journal on Algebraic Discrete Methods, 7 (2), 
273–281 . 
Gong, Z.-W. (2008). Least-square method to priority of the fuzzy preference rela- 
tions with incomplete information. International Journal of Approximate Reason- 
ing, 47 (2), 258–264 . 
Henriet, D. (1985). The copeland choice function an axiomatic characterization. So- 
cial Choice and Welfare, 2 (1), 49–63 . 
Herrera, F. , Alonso, S. , Chiclana, F. , & Herrera-Viedma, E. (2009). Computing with 
words in decision making: Foundations, trends and prospects. Fuzzy Optimiza- 
tion and Decision Making, 8 (4), 337–364 . 
Herrera, F. , Herrera-Viedma, E. , & Verdegay, J. L. (1996). Direct approach processes in 
group decision making using linguistic OWA operators. Fuzzy Sets and Systems, 
79 (2), 175–190 . 
Herrera-Viedma, E. , Alonso, S. , Chiclana, F. , & Herrera, F. (2007). A consensus model 
for group decision making with incomplete fuzzy preference relations. IEEE 
Transactions on Fuzzy Systems, 15 (5), 863–877 . 
Herrera-Viedma, E. , Cabrerizo, F. J. , Kacprzyk, J. , & Pedrycz, W. (2014). A review of 
soft consensus models in a fuzzy environment. Information Fusion, 17 , 4–13 . 
Herrera-Viedma, E. , García-Lapresta, J. L. , Kacprzyk, J. , Fedrizzi, M. , Nurmi, H. , & Sła- 
womir, Z. (2011). Consensual processes : vol. 267. Springer . 
Herrera-Viedma, E. , Herrera, F. , & Chiclana, F. (2002). A consensus model for mul- 
tiperson decision making with different preference structures. IEEE Transactions 
on Systems, Man, and Cybernetics-Part A: Systems and Humans, 32 (3), 394–402 . 
Herrera-Viedma, E. , Herrera, F. , Chiclana, F. , & Luque, M. (2004). Some issues on con- 
sistency of fuzzy preference relations. European Journal of Operational Research, 
154 (1), 98–109 . 
Horn, R. A. , & Johnson, C. R. (1990). Matrix analysis . Cambridge University Press . 
Kitainik, L. (2012). Fuzzy decision procedures with binary relations: towards a uniﬁed 
theory : vol. 13. Springer Science & Business Media . 
Kou, G. , Ergu, D. , & Shang, J. (2014). Enhancing data consistency in decision matrix: 
adapting hadamard model to mitigate judgment contradiction. European Journal 
of Operational Research, 236 (1), 261–271 . 
Kou, G. , & Lin, C. (2014). A cosine maximization method for the priority vector 
derivation in AHP. European Journal of Operational Research, 235 (1), 225–232 . 
Lin, C. , Kou, G. , Peng, Y. , & Alsaadi, F. E. (2020). Aggregation of the nearest consis- 
tency matrices with the acceptable consensus in AHP-GDM. Annals of Operations 
Research , 1–17 . 
MacCluer, C. R. (20 0 0). The many proofs and applications of perrons theorem. SIAM 
Review, 42 , 4 87–4 98 . 
Mahadevan, S. , et al. (2009). Learning representation and control in markov de- 
cision processes: New frontiers. Foundations and Trends® in Machine Learning, 
1 (4), 403–565 . 
Marchant, T. (1996). Valued relations aggregation with the borda method. Journal of 
Multi-Criteria Decision Analysis, 5 (2), 127–132 . 
Negahban, S. , Oh, S. , & Shah, D. (2012). Iterative ranking from pair-wise compar- 
isons. In Advances in neural information processing systems (pp. 2474–2482) . 
Negahban, S. , Oh, S. , & Shah, D. (2016). Rank centrality: Ranking from pairwise com- 
parisons. Operations research, 65 (1), 266–287 . 
Palomares, I. , Estrella, F. J. , Martínez, L. , & Herrera, F. (2014). Consensus under a 
fuzzy context: Taxonomy, analysis framework AFRYCA and experimental case of 
study. Information Fusion, 20 , 252–271 . 
Pedrycz, W. , Ekel, P. , & Parreiras, R. (2010). Introduction to preference modeling with 
binary fuzzy relations (pp. 137–153)). John Wiley & Sons, Ltd . 
Plackett, R. L. (1975). The analysis of permutations. Journal of the Royal Statistical 
Society: Series C (Applied Statistics), 24 (2), 193–202 . 
Rajkumar, A. , & Agarwal, S. (2014). A statistical convergence perspective of algo- 
rithms for rank aggregation from pairwise data. In International conference on 
machine learning (pp. 118–126) . 
Seo, F., & Sakawa, M. (1985). Fuzzy multiattribute utility analysis for collective 
choice. IEEE transactions on systems, man, and cybernetics, SMC-15 (1), 45–53. 
https://doi.org/10.1109/TSMC.1985.6313393 . 
Tanino, T. (1990). On group decision making under fuzzy preferences. In Multiper- 
son decision making models using fuzzy sets and possibility theory (pp. 172–185). 
Springer . 
Ureña, R. , Chiclana, F. , Morente-Molinera, J. A. , & Herrera-Viedma, E. (2015). Man- 
aging incomplete preference relations in decision making: A review and future 
trends. Information Sciences, 302 , 14–32 . 
Ureña, R. , Kou, G. , Wu, J. , Chiclana, F. , & Herrera-Viedma, E. (2019). Dealing with in- 
complete information in linguistic group decision making by means of interval 
type-2 fuzzy sets. International Journal of Intelligent Systems, 34 (6), 1261–1280 . 
Xu, Z. , & Da, Q. (2005). A least deviation method to obtain a priority vector of 
a fuzzy preference relation. European Journal of Operational Research, 164 (1), 
206–216 . 
Yager, R. R. (1988). On ordered weighted averaging aggregation operators in mul- 
ticriteria decisionmaking. IEEE Transactions on Systems, Man, and Cybernetics, 
18 (1), 183–190 . 
Zhu, B. , & Xu, Z. (2014). A fuzzy linear programming method for group decision 
making with additive reciprocal fuzzy preference relations. Fuzzy Sets and Sys- 
tems, 246 , 19–33 . 
1041 
",https://doi.org/10.1016/j.ejor.2021.05.030,doc23,"European Journal of Operational Research 297 (2022) 1030–1041 Contents lists available at ScienceDirect European Journal of Operational Research journal homepage: www.elsevier.com/locate/ejor Decision Support A new decision making model based on Rank Centrality for GDM with fuzzy preference relations Anis Yazidi a , b , c , g , h , ∗, Magdalena Ivanovska d , Fabio M. Zennaro e , Pedro G. Lind a , b , c , Enrique Herrera Viedma f a Department of Computer Science, OsloMet – Oslo Metropolitan University, P.O. Box 4 St. Olavs plass, Oslo N-0130, Norway b ORCA – OsloMet Research Center for AI, Pilestredet 52, Oslo N-0166, Norway c NordSTAR – Nordic Center for Sustainable and Trustworthy AI Research, Pilestredet 52, Oslo N-0166, Norway d Department of Data Science and Analytics, BI Norwegian Business School, Nydalsveien 37, Oslo N-0484, Norway e Department of Informatics, University of Oslo, P.O. Box 1080 Blindern, Oslo N-0316, Norway f Andalusian Research Institute in Data Science and Computational Intelligence, University of Granada, Granada 18071, Spain g Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway h Department of Plastic and Reconstructive Surgery, Oslo University Hospital, Oslo, Norway a r t i c l e i n f o Article history: Received 2 June 2020 Accepted 19 May 2021 Available online 1 June 2021 Keywords: Decision support systems Group decision making Fuzzy preference relations Rank Centrality Markov chains a b s t r a c t Preference aggregation in Group Decision Making (GDM) is a substantial problem that has received a lot of research attention. Decision problems involving fuzzy preference relations constitute an important class within GDM. Legacy approaches dealing with the latter type of problems can be classiﬁed into in- direct approaches, which involve deriving a group preference matrix as an intermediate step, and direct approaches, which deduce a group preference ranking based on individual preference rankings. Although the work on indirect approaches has been extensive in the literature, there is still a scarcity of research dealing with the direct approaches. In this paper we present a direct approach towards aggregating sev- eral fuzzy preference relations on a set of alternatives into a single weighted ranking of the alternatives. By mapping the pairwise preferences into transitions probabilities, we are able to derive a preference ranking from the stationary distribution of a stochastic matrix. Interestingly, the ranking of the alter- natives obtained with our method corresponds to the optimizer of the Maximum Likelihood Estimation of a particular Bradley-Terry-Luce model. Furthermore, we perform a theoretical sensitivity analysis of the proposed method supported by experimental results and illustrate our approach towards GDM with a concrete numerical example. This work opens avenues for solving GDM problems using elements of probability theory, and thus, provides a sound theoretical fundament as well as plausible statistical inter- pretation for the aggregation of expert opinions in GDM. © 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license ( ) 1. Introduction Group decision making (GDM) settings involve a group of indi- viduals (experts), where each member of the group expresses her preferences over a set of alternatives. Illustrative examples range from parliamentary groups working to converge on a political deci- sion, to groups of friends deciding on the best choice of restaurant for a dinner. The aim of GDM is to identify the most preferred al- ternative for the whole group of individuals, or to derive a ranking of the alternatives that reﬂects the preferences of the group. ∗Corresponding author. E-mail addresses: anis.yazidi@oslomet.no (A. Yazidi), viedma@decsai.ugr.es (E.H. Viedma). The literature proposes many different forms of expressing pref- erences of experts ( Capuano, Chiclana, Fujita, Herrera-Viedma, & Loia, 2017 ). Some of the most popular ones are the following: • Rankings , which are ranked lists of the alternatives from the most preferred to the least preferred one ( Seo & Sakawa, 1985 ). • Utility vectors , where each component of the vector describes the utility of the corresponding alternative, which can be seen as its ordinal strength ( Tanino, 1990 ). These are sometimes called priority vectors or weighted rankings . We use the latter expression throughout this paper. • Preference relations , where preference is expressed as a binary relation on the set of alternatives ( Kitainik, 2012 ). • Fuzzy Preference Relations (FPRs) , which relax the binary pref- erence relations with the possibility of expressing degrees of 0377-2217/ A. Yazidi, M. Ivanovska, F.M. Zennaro et al. European Journal of Operational Research 297 (2022) 1030–1041 preference among the alternatives ( Pedrycz, Ekel, & Parreiras, 2010 ). Preference degrees can be assessed using linguistic term sets which can be more natural for human expert to articulate ( Ureña, Kou, Wu, Chiclana, & Herrera-Viedma, 2019 ). FPR is the most commonly used representation for expressing preferences in a set of alternatives, in which an expert expresses her preferences as degrees of preference assigned to each pair of alternatives. The most common way to store these pairwise pref- erences is in the form of a preference matrix. The main reason behind the popularity of the preference relations comes from a known fact from psychology studies that human beings are better at comparing pairs of alternatives than at coming up with a com- plete preference ordering of a set of alternatives ( Ureña, Chiclana, Morente-Molinera, & Herrera-Viedma, 2015 ). Within GDM involving FPR, there are two main families of ap- proaches: direct approaches and indirect approaches. The indirect approaches ﬁrst compute the group opinion in the form of an FPR (we will call it a group or a collective FPR), usually expressed as a preference matrix, and then ﬁnd a solution which is a (weighted) ranking of the different alternatives based on the collective FPR. The collective preference matrix is generally derived by apply- ing an aggregation operator to the individual ones. On the other hand, the direct approaches do not involve constructing a collec- tive preference matrix describing the group opinion as an inter- mediate step. They ﬁrst compute an individual ranking for each expert based on her FPR, and then the group ranking is obtained from the individual rankings of the experts using an aggregation operator. For excellent surveys on consensus processes and pref- erence aggregation we refer the reader to the comprehensive sur- veys ( Cabrerizo, Moreno, Pérez, & Herrera-Viedma, 2010; Herrera- Viedma, Cabrerizo, Kacprzyk, & Pedrycz, 2014 ) and to the book by Herrera-Viedma et al. (2011) . While studies on indirect approaches for aggregating pairwise preferences abound, the direct approaches are not as popular, al- though there are a few exceptions ( Dong, Xu, & Yu, 2009; Fan, Ma, Jiang, Sun, & Ma, 2006 ). Herrera and his collaborators ( Herrera, Herrera-Viedma, & Verdegay, 1996 ) pioneered the ﬁrst direct ap- proach towards GDM based on FPR. However, the work in this di- rection is very scarce, although it is known that direct approaches usually possess two desirable properties, internal consistency and Pareto principle of the social choice theory ( Dong & Zhang, 2014 ). One of the few available direct approaches in the literature was recently presented by Dong et al. in ( Dong & Zhang, 2014 ). There, the authors extended the original direct approach presented in ( Herrera et al., 1996 ) in order to support (i) different preferences representations, and (ii) a consensus process in the form of rounds where experts are required to adjust their pairwise preferences. In- terestingly, in order to achieve consensus, Dong et al. resort to a form of a feedback based on measuring consensus using the indi- vidual weighted rankings of the experts. This is distinct from the main stream of research in FPR since consensus degree computa- tion is not based on weighted rankings of individual experts but rather based on elements from the preference matrices. The ap- proach by Dong et al. allows the experts to update their prefer- ence matrices in order to reach a consensus, defining two quan- tities, namely the cardinal consensus degree, based on the vec- tor representation inspired by ( Chiclana, Herrera, Herrera-Viedma, & Martínez, 2003; Dong, Xu, Li, & Feng, 2010 ) and the ordinal consensus degree inspired by ( Herrera-Viedma, Alonso, Chiclana, & Herrera, 2007; Herrera-Viedma, Herrera, & Chiclana, 2002 ). In this article, we take a direct approach towards group de- cision making given fuzzy preferences over a set of alternatives. We propose a method for aggregating the opinions of several experts, which are expressed as FPRs, into a single weighted ranking of the alternatives. Similarly to the work in ( Dopazo & Martínez-Céspedes, 2017 ), we transform the preference matrices into stochastic matrices, and then use the theory of Markov chains and random walks to compute rankings over the alternatives, as implemented in the PageRank algorithm ( Gleich, 2015 ). One main difference in this paper compared to the method in ( Dopazo & Martínez-Céspedes, 2017 ) lays in the deﬁnition of the stochastic matrix. In ( Dopazo & Martínez-Céspedes, 2017 ) the stochastic ma- trix is simply a column-normalization of the preference matrix so that its entries are proportional to the corresponding preferences and represent the probabilities (relative strengths) of dominance between the alternatives. In our framework we determine the en- tries of the stochastic matrix similarly as in ( Negahban, Oh, & Shah, 2012; 2016 ) and they represent the probabilities of transiting be- tween the corresponding alternatives in the way that the prob- ability of transition from alternative x to alternative y is propor- tional to the degree of preference of y to x . The stationary vectors, however, have similar interpretation in both our approach and the approach in ( Dopazo & Martínez-Céspedes, 2017 ) as their entries represent preference strengths of the corresponding alternatives in both the cases. The difference is that the normalization we use leads to a stationary vector that satisﬁes the global balance prop- erty with respect to the preference matrix: the preference strength of an alternative depends on whether the alternative dominates weak or strong alternatives. This is the core idea of the Rank Cen- trality method ( Negahban et al., 2012; 2016 ) and we discuss it in more detail in Section 3.1 . Notice that assigning and interpreting a degree of preference is not straightforward. Using a probability value to quantify an FPR gives an intuitive interpretation of FPR itself and, moreover, en- ables to establish a link between probability theory and preference aggregation. Furthermore, we prove that the weighted ranking ob- tained as a result of the method presented in this paper corre- sponds to the result of Maximum Likelihood Estimation (MLE) of the Plackett-Luce model ( Plackett, 1975 ). There is a body of literature on methods that compute weighted ranking from preference matrices based on optimization tech- niques such as least square method ( Gong, 2008 ), least deviation method ( Xu & Da, 2005 ), multiobjective optimization ( Fernandez & Leyva, 2004 ), new fuzzy linear programming method (FLPM) ( Zhu & Xu, 2014 ), goal programming ( Fan et al., 2006 ), etc. Al- though these methods are shown to provide good results, they re- lay on human-engineered techniques or heuristics and do not pro- vide plausible theoretical interpretation of their computation and modelling steps. Our work is distinct from the latter works as the way we derive a ranking vector can be explained using probabil- ity theory and thus we provide a theoretical interpretation of our framework. Indeed, as mentioned above, our work is directly inspired by a recent work on Rank Centrality algorithm ( Negahban et al., 2012; 2016 ), which aggregates a set of pairwise comparisons of alterna- tives into a global weighted ranking. In ranking based on pairwise comparisons, the goal is to rank, for example, football teams based on results of played matches between them. This problem has an obvious analogy with ranking of alternatives based on pairwise ex- pressed preferences, but despite the vast amount of work on rank- ing alternatives based on preferences, to the best of our knowl- edge, the ideas of Rank Centrality have not yet been adopted in the context of fuzzy preference aggregation. We argue that by properly transforming the fuzzy preferences into probabilities of transition between alternatives, probability theory can naturally be applied in preference aggregation and, consequently, we hope that our frame- work can inspire further research in that direction. The remainder of this paper is structured as follows. In Section 2 we introduce the relevant background and the fun- damental concepts of the state of the art in fuzzy preferences. Section 3 presents our approach for aggregating preferences based 1031 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. European Journal of Operational Research 297 (2022) 1030–1041 on the concept of Markov chains and discusses the conditions un- der which some desirable properties for the aggregation processes hold. In Section 4 we provide a theoretical sensitivity analysis of the proposed aggregation method. Concrete numerical example showing the consistency of our framework followed by an exper- imental sensitivity analysis is given in Section 5 . Final discussions and conclusions are provided in Section 6 . 2. Background and preliminary concepts In the following we assume that E = { e 1 , . . . , e m } is a set of experts and X = { x 1 , . . . , x n } is a set of alternatives. We use the following deﬁnition of a fuzzy preference relation as provided in ( Herrera-Viedma, Herrera, Chiclana, & Luque, 2004 ). A Fuzzy Preference Relation (FPR) P on a set of alternatives X is a fuzzy set on the product set X × X, i.e. a relation on X character- ized by a membership function μP : X × X → [0 , 1] . (1) p ij = μP (x i , x j ) is interpreted as the preference degree of the alter- native x i over the alternative x j . A usual natural assumption is that p ij + p ji = 1 , for every i, j ∈ { 1 , . . . , n } , i.e. that P is additive recip- rocal . If p ij > 0 . 5 , we say that x i is preferred to x j ; if p ij = 0 . 5 , we say that we are indifferent between x i and x j ; and p ij = 1 indicates that x i is absolutely preferred to x j . The additive reciprocity prop- erty ensures that p ii = 0 . 5 and p ij > 0 . 5 iff p ji < 0 . 5 . When the set X is not too big, it is convenient to represent P as an n × n matrix of preference values, where n = | X| , i.e. P = [ p ij ] n ×n . We call this a preference matrix . For convenience, we use the same notation for both the fuzzy preference relation and the corresponding preference matrix. We assume that each of the m experts expresses her prefer- ences independently of each other and in the form of a fuzzy pref- erence relation. Let us denote by P (k ) the FPR of the k -th expert and let P (k ) = [ p (k ) ij ] n ×n be the corresponding preference matrix. An indirect approach to GDM aims at reaching a collective opin- ion by ﬁrst aggregating all the individual preference matrices into a collective FPR. A direct approach would predict the collective opin- ion or a GDM-”target”, in general, by turning experts’ FPR matrices into vectors whose entries measure the ranking of the alternatives. More formally, a weighted ranking can be deﬁned as a function r : X → R , which maps each alternative in X into its absolute pref- erence strength. 1 Aggregating the individual ranking vectors yields a possible consensus target for the set of individuals. Whatever approach one chooses, direct or indirect, there are two main phases in GDM based on FPR, an aggregation phase and an exploitation phase . In the aggregation phase, the corresponding individual prefer- ence values (corresponding entries in FPR matrices or ranking vec- tors) are aggregated into a collective preference value using an ag- gregation operator . There are many aggregation operators, such as weighted aver- age (WA), fuzzy majority, etc. One popular example is the opera- tor called Ordered Weighted Averaging (OWA) due to ( Yager, 1988 ). The WA and the OWA operators presume we have a list of weights w = (w 1 , . . . , w m ) , w k ∈ [0 , 1] , k = 1 , . . . , m , such that  w k = 1 . Let p 1 , . . . , p m be a list of preference values to be aggregated. While the WA operator is deﬁned as a simple weighted average of the preferences: WA ( p 1 , . . . , p m ) = m  k = 1 w k p k , (2) 1 The ordering of the alternatives is implicit in each weighted ranking and follows from the linear order of the real numbers: Alternatives assigned a higher number rank higher, and alternatives assigned the same number rank the same. the OWA operator is deﬁned as OWA ( p 1 , . . . , p m ) = m  k = 1 w k p σ ( k ) , (3) where σ is a permutation of the set { 1 , . . . , m } such that p σ (k +1) ≥ p σ (k ) for k ∈ { 0 , . . . , m −1 } . In the case of WA, the weights w = (w 1 , . . . , w m ) can be as- sumed to be corresponding to the importance of the experts in the group with respect to the particular decision making problem, or to the conﬁdence of the experts in their opinions. In the case of OWA, assigning weights w enables weighting differently prefer- ences of different strength, giving more value to stronger prefer- ences, for example. By choosing different w in WA and OWA, one can implement different aggregation operators. The exploitation phase is the phase of deducing a (weighted) ranking vector based on a fuzzy preference relation (matrix). Two relevant approaches towards defining the ranking in this phase are ( Herrera et al., 1996 ): Quantiﬁer-Guided Dominance De- gree (QGDD), where the rank of each alternative represents the dominance or importance of the alternative over the rest of the al- ternatives; and Quantiﬁer-Guided Non-Dominance Degree (QGNDD), where the rank of each alternative represents the degree to which the alternative is not dominated by the rest of the alternatives. An alternative to QGDD and QGNDD is the Netﬂow method ( Bouyssou, 1992 ) which is also based on dominance of an alternative. 2 More precisely, this method deﬁnes the rank of an alternative as the difference between the inﬂow and the outﬂow of preference from it, which, under the additive reciprocity assumption ( p ij + p ji = 1 ), reduces to the following expression: NF ( x i ) = n  j =1 ,j ̸ = i p ij − n  j =1 ,j ̸ = i p ji = n  j =1 ,j ̸ = i 2 p ij −n + 1 = 2  n  j =1 ,j ̸ = i p ij −n −1 2  . (4) Notice that the Netﬂow method is related to the Copeland vot- ing rule in ( Marchant, 1996 ). An axiomatic characterization of the Copeland rule can be found in ( Henriet, 1985 ). The indirect and the direct approaches towards GDM with FPR differ in the way the phases of aggregation and exploitation are combined: In the indirect approaches, one ﬁrst applies the aggre- gation phase to the set of individual FPRs in order to obtain one collective FPR. Then the exploitation phase is applied to the col- lective FPR to give the ﬁnal (weighted) ranking. In the direct ap- proaches, the exploitation phase is applied ﬁrst at each individual FPR to give the individual rankings. Then the aggregation phase is applied at the individual rankings to ﬁnd the ﬁnal collective rank- ing ( Herrera et al., 1996 ). Fig. 1 highlights these differences be- tween the two approaches. Note that aggregating opinions of experts into a group opin- ion by any of the above approaches does not necessarily amount to reaching a consensus. To guarantee agreement between the ex- perts, one could consider a third phase after the two phases de- scribed above, in which one forces the individual opinions of the experts to get close to each other ( Palomares, Estrella, Martínez, & Herrera, 2014 ). This narrowing phase can be implemented in two different ways: (i) through automatic approaches without expert feedback, or (ii) through approaches with feedback on preferences 2 Note that the Netﬂow method has also been deﬁned in ( García-Lapresta, Martínez-Panero, & Meneses, 2009 ) as the broad Borda count. 1032 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. European Journal of Operational Research 297 (2022) 1030–1041 Fig. 1. Tensor representation of methods for GDM. Indirect method (above); direct method (below). where there is a moderator that will try to reduce the divergence of opinions between the experts. In both of these approaches con- sensus is considered to be a stage where all the individual opin- ions are suﬃciently close to each other. Quantitatively, the close- ness can be measured as a distance in the “space of opinions” ei- ther between each opinion and the collective (aggregated) opinion, or between pairs of individual opinions. Having described brieﬂy the decision framework and the main approaches for quantitative analysis in GDM, in the next section we propose a new method to address the aggregation and ex- ploitation processes and we analyse its properties. 3. A rank centrality-based preference aggregation method In this section we introduce a method for aggregating the fuzzy preference relations of the experts e 1 , . . . , e m into a collective weighted ranking of the alternatives x 1 , . . . , x n . We start by provid- ing a way of transforming a preference matrix over the alterna- tives into a weighted ranking vector of the alternatives, which will be used in the exploitation phase of the general method. Then we provide the full GDM procedure. At the end we prove that, un- der the assumption that detailed balance relation is satisﬁed, the proposed method satisﬁes some desirable properties of aggrega- tion processes. 3.1. From preference matrices to ranking vectors We consider an n × n preference matrix P over the alternatives x 1 , . . . , x n ( n ≥2 ) which is additive reciprocal, i.e. a matrix whose elements p ij are in the unit interval and obey the condition p ij = 1 −p ji . (5) A value p ij > 0 . 5 means that the alternative x i is preferred over x j , while p ij = 0 . 5 means that no preference between x i and x j exists. Inspired by recent work on ranking based on a dataset of pair- wise comparisons ( Negahban et al., 2012; 2016 ), our approach is based on a transformation of the given preference matrix P into a stochastic matrix S deﬁned in the following way: s ij = 1 n −1 p ji , (6a) s ii = 1 − 1 n −1 n  j =1 ,j ̸ = i p ji . (6b) The division by n −1 is introduced for normalization purposes,  j s ij = 1 , and to guarantee that each element s ij is proportional to the corresponding p ji and fulﬁlls the condition 0 ≤s ij ≤1 . Each row can then be seen as a probability distribution and the matrix S as the matrix of transition probabilities of a Markov chain with n states. 3 The element s ij corresponds to the probability of transiting from a state x i to a state x j and, as deﬁned in Eq. (6a) , this prob- ability equals the product of the probability of choosing randomly the state x j among the n −1 states different from x j and adopting that state with probability p ji . This ensures that the probability of transition from alternative x i to alternative x j is proportional to the preference of x j over x i . Notice that it is always possible to con- struct such a stochastic matrix, even if there are missing entries in the preference matrix P , i.e. if there is incomplete information ( Herrera-Viedma et al., 2007 ). We impose that the preference matrix P fulﬁlls the condition p ij ̸ = 0 , (7) for every i, j ∈ { 1 , . . . , n } , and therefore also p ij ̸ = 1 , for every i, j ∈ { 1 , . . . , n } , which means that an alternative is never completely “excluded” against another one and also never “fully dominates” another one. (This may be achieved by replacing a zero prefer- ence with an arbitrarily small ϵ > 0 preference). It is easy to see that under this particular condition the matrix S is irreducible and aperiodic (see Appendix A ). Then, according to Perron-Frobenius theorem ( Horn & Johnson, 1990; MacCluer, 20 0 0 ), S being an ir- reducible aperiodic stochastic matrix, there is a unique stationary solution π satisfying: π = πS . (8) The stationary distribution π can be computed iteratively via a random walk on the Markov chain deﬁned by the stochastic ma- trix S, or analytically via the computation of the eigenvector associ- 3 In the remainder of the paper we will use the terms alternative and state inter- changeably. 1033 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. European Journal of Operational Research 297 (2022) 1030–1041 ated with the highest eigenvalue of the matrix S. We will interpret the stationary distribution π as a weighted ranking, where each component of the vector π (each “weight”) represents the impor- tance of the corresponding alternative with respect to the whole set of alternatives, and we will refer to this method for computing rankings as a Rank Centrality (RC) method ( Negahban, Oh, & Shah, 2016 ). We call the corresponding matrix S a centrality matrix . To justify the above interpretation of the stationary vector π, we analyse its relation with the initially given preference matrix P . According to Eq. (8) , the components of the vector π read: πi = n  j=1 π j s ji . (9) The product π j s ji in the above sum represents the probability of transitioning from x j to x i adjusted by the weight of x j and, simi- larly as in ( Dopazo & Martínez-Céspedes, 2017 ), can be interpreted as the relative importance of alternative x i with respect to the al- ternative x j . Then, since πi , according to Eq. (9) , is a sum of such products, it can be interpreted as the (absolute) importance of x i . Now, according to Eq. (6a) , the transition probabilities s ji are pro- portional to preferences p ij , hence we can interpret π j s ji as rela- tive preference strength of x i with respect to x j , and πi as (absolute) preference strength of x i . There are two important properties of the RC method. The ﬁrst property is that the ranking dynamics follows a continuous time Markov chain in global balance, and the respective balance equa- tion can be easily derived from Eq. (6) and Eq. (8) . Namely, from Eq. (9) we obtain: πi = πi s ii + n  j =1 ,j ̸ = i π j s ji , (10) which is equivalent to (1 −s ii ) πi = n  j =1 ,j ̸ = i π j s ji . (11) From Eq. (6) we have 1 −s ii = n  j =1 ,j ̸ = i s ij , (12) which together with Eq. (11) and Eq. (6a) leads to the following equations n  j =1 ,j ̸ = i s ij πi = n  j =1 ,j ̸ = i s ji π j n  j =1 ,j ̸ = i p ji πi = n  j =1 ,j ̸ = i p ij π j , (13) which we call the global balance equations. Notice that the stronger condition which assumes a term-by-term equality between the sums in Eq. (13) , for every i ∈ { 1 , . . . , n } , is called a detailed balance . We discuss the case of a detailed balance in a subsequent section. The second property is given by the relation between the com- ponents of the stationary solution (ranking) and the initial prefer- ence degrees that follows directly from the second global balance equation: πi = 1  n j =1 ,j ̸ = i p ji n  j =1 ,j ̸ = i p ij π j . (14) Note that if we did not have the terms π j on the right hand- side of the Eq. (14) , then the method would have been equivalent to the Netﬂow method since πi would be proportional to  n j̸ = i p ij which is the case for NF (x i ) too as seen in Eq. (4) . However, hav- ing π j on the right-hand side of Eq. (14) reﬂects the idea of cen- trality ranking. Namely, the importance of each alternative x j ̸ = x i quantiﬁed by π j is taken into account when determining πi . Thus, weak alternatives that have low π j due to being dominated by many other alternatives will not contribute much to the increase of πi even if p ij is large, because one needs to consider the prod- uct p ij π j and not only p ij as in the classical Netﬂow method. In- formally, this means that beating weak alternatives, i.e. alternatives with low π j , does not increase much the ranking. This is one of the core ideas of the Rank Centrality method ( Negahban et al., 2016 ). 3.2. The GDM method Our framework for preference aggregation consists of the fol- lowing subsequent steps: 1. Consider a set of m experts E = { e 1 , . . . , e m } . Each expert e k , 1 ≤k ≤m , has a pairwise preference matrix P (k ) over the set of alternatives X = { x 1 , . . . , x n } . 2. Using Eq. (6) , for each matrix P (k ) we compute the correspond- ing stochastic matrix S (k ) . 3. We solve Eq. (8) for each expert e k , i.e. we solve π = πS (k ) , for k = 1 , . . . , m , and denote the unique solution by π (k ) . The vector π (k ) = [ π (k ) 1 , . . . , π (k ) n ] deﬁnes a weighted ranking of the alter- natives corresponding to the preferences of the expert e k over the set of n alternatives. As observed in the previous section, π (k ) i can be interpreted as the preference strength of the alter- native x i according to expert e k . Then, since π (k ) is a probability distribution over X, it can be seen as representing the expert e k ’s distribution of preference strengths over X. 4. We deﬁne the collective ranking vector as the arithmetic aver- age of the individual ranking vectors, determining its compo- nents as follows: π (c) i = 1 m m  k =1 π (k ) i . (15) Notice that, by taking the arithmetic average of the individual ranking vectors as the aggregated state π (c) , one naturally deﬁnes the consensual stage with respect to that aggregated state: perfect consensus occurs when all the experts arrive at the same opinion given by π (c) . Moreover, such deﬁnition of perfect consensus state reﬂects the assumption that the perfect consensus state should not be near to some speciﬁc expert and in prejudice to the other. From a more physical perspective, one can take π (c) as the cen- ter of mass of the set of opinions of the m experts (expressed as weighted rankings), in the space of all the possible opinions, i.e. it is the unique point from which all the experts’ opinions are seen equally distributed,  m k =1 (π (k ) i −π (c) i ) = 0 , for every i = 1 , . . . , n . In other words, using the arithmetic average in the aggregation phase of the GDM process provides a safe alternative to reaching a con- sensus, in the absence of a special third phase for that purpose in the process. An extension to WA or OWA is straightforward and does not compromise the bulk of our framework: For any choice of weights, which should depend on the speciﬁc set of experts and/or the spe- ciﬁc decision making context, rankings and preferences will still be treatable within our framework. 3.3. The detailed balance case Recall that the stationary vector satisﬁes the detailed balance (time reversibility) property if the following equation holds: πi s ij = π j s ji , (16) for every i, j ∈ { 1 , . . . , n } . 1034 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. European Journal of Operational Research 297 (2022) 1030–1041 In this section we assume that Eq. (16) holds for the elements of the stochastic matrix S and the components of the correspond- ing stationary vector obtained in steps 2. and 3. in the previous section. Then, combining Eq. (5) , Eq. (6) and Eq. (16) , one arrives to the following equation equivalent to Eq. (16) : p ij = πi πi + π j . (17) Eq. (17) highlights the correspondence between pairwise expressed preferences in the form of a preference matrix and the prefer- ence strengths assigned to the alternatives in the corresponding weighted ranking vector. Note that Eq. (17) implies transitivity of the preference matrix P (from p ij > 0 . 5 and p jk > 0 . 5 follows p ik > 0 . 5 ). Notice that Eq. (17) means that the preference relation P satis- ﬁes the Bradley-Terry-Luce (BTL) model ( van Berkum, 1997 ). It was demonstrated also by Rajkumar and Shivani ( Rajkumar & Agarwal, 2014 ) that the time-reversibility of S is equivalent to the existence of an underlying BTL model that describes the preferences in P ac- cording to their preference strengths π. At this juncture, we shall present a theorem that provides a mathematical interpretation of the stationary distribution of the centrality matrix S corresponding to the preference matrix P , namely that the stationary distribution of S is a maximum likeli- hood estimate of the BTL model underlying P . Theorem 1. Let the BTL pairwise comparison model be deﬁned by a parameter vector π = [ π1 , . . . , πn ] , πi ∈ (0 , 1) , i.e. p ij = πi πi + πj , for i, j ∈ { 1 , . . . , n } , where p ij = P (x i > x j ) . 4 Let P = [ p ij ] be a preference matrix and let S be its corresponding centrality matrix deﬁned by Eq. (6a) and Eq. (6b) . Then the Maximum Likelihood Estimate (MLE) of the BTL model satisﬁes the global balance equation with P . The proof of the above theorem can be found in Appendix B . The theorem states that the MLE of the parameter vector π of the BTL model for pairwise comparisons of n alternatives, π ∗, satisﬁes the global balance property given in Eq. (13) with the ground truth probabilities P of the model. This means that π ∗is a stationary distribution of the centrality matrix S corresponding to P , since the global balance equations in Eq. (13) are derived from the stationary distribution in Eq. (9) through a series of equivalence steps. Finally, since the stationary distribution of S is unique on the unit interval, we can conclude that it is equal to π ∗, the MLE of the BTL model in which P describes the probabilities of the pairwise comparisons. In Section 3.1 we discussed two general properties of the RC method. Here, we observe that in the special case when the rank- ing vectors determined in step 3. of the GDM procedure satisfy de- tailed balance, i.e. the equations (16) and (17) , two desirable prop- erties of the aggregation processes are satisﬁed: internal consis- tency and the Pareto principle. We interpret these properties simi- larly as in ( Dong & Zhang, 2014 ) and ( Chiclana, Herrera, & Herrera- Viedma, 2002 ). Internal Consistency. In our setting, internal consistency can be understood as the consistency of the process that transforms each expert’s opinion from its initial form of a preference matrix, through a stochastic matrix, to its end form of a weighted ranking vector. In other words, the property of internal consistency is sat- isﬁed if the following holds: The derived individual ranking of the k -th expert by the procedure described in Section 3.1 , reﬂects her initial preference relation, ranking higher (assigning higher weights to) the alternatives she prefers more: p (k ) ij ≥p (k ) ji if and only if 4 x i > x j can be interpreted as “x i wins over x j ”, “x i is preferred to x j ”, etc., and P(x i > x j ) is the probability of this event that is to be estimated from a number of pairwise comparisons in the set of alternatives X = { x 1 , . . . , x n } . π (k ) i ≥π (k ) j , for every i, j ∈ { 1 , . . . , n } . This property follows imme- diately from Eq. (17) . Pareto principle. The general interpretation of the Pareto princi- ple (unanimity) in the social-choice theory is as follows: If all the experts agree upon a certain issue, then this agreement is reﬂected in the derived collective opinion. In our framework, it can be inter- preted as the following requirement: If all the experts prefer the alternative x i over the alternative x j in their individual preference relations, then x i ranks higher than x j in the collective ranking. More formally, if p (k ) ij ≥p (k ) ji , for every k = 1 , . . . , m , then π c i ≥π c j . This is a consequence of Eq. (17) and Eq. (15) : If p (k ) ij ≥p (k ) ji , for every k = 1 , . . . , m , then, from Eq. (17) it follows that π (k ) i ≥π (k ) j , for every k = 1 , . . . , m . From the last and Eq. (15) , it follows that π (c) i ≥π (c) j . Note that the above two properties are based on qualitative comparisons between preferences where neither the magnitude of preferences and preference strengths nor the information on whether the dominated alternatives are weak or strong, is taken into account. Since these are crucial elements in the Rank Central- ity method that enable deriving meaningful rankings, they justify the violation of the properties of internal consistency and Pareto optimality in the general case. This is clearly demonstrated by our example in Section 5.1 . It would be interesting, however, to exam- ine the sensitivity of the latter properties to changes in the initial matrices. 4. Sensitivity Analysis (SA) In this section we perform a theoretical sensitivity analysis of the Rank Centrality method. More speciﬁcally, we analyse the sen- sitivity of the output of the procedure described in Section 3.1 in face of small variations of the input, i.e. small variations in the val- ues of the matrix parameters. The aim of this analysis is to under- stand how the centrality-based ranking of the alternatives is af- fected by small changes in the experts’ opinions. As a basis for our analysis we use the derivatives of the output, and we largely apply results from Golub and Meyer ( Golub & Meyer, 1986 ). Recall that the input of the RC ranking method is an n × n pref- erence matrix P ( n ≥2 ) that is additive reciprocal, i.e. a matrix whose elements p ij are in the unit interval and obey the condi- tion p ij = 1 −p ji . (18) We consider an ϵ-perturbation of the matrix P resulting in a new matrix ˜ P (ϵ) , where the preferences associated with one par- ticular pair of alternatives (x k , x l ) change as follows: 5 ˜ p kl = p kl + ϵ (19) with 0 < ϵ ≪1 , and consequently, from Eq. (5) , ˜ p lk = 1 −˜ p kl = p lk −ϵ. (20) Let S and ˜ S (ϵ) be the centrality matrices of P and ˜ P (ϵ) respec- tively. Note that ˜ P (0) = P and ˜ S (0) = S. Whenever there is no con- fusion, we will omit the dependency on ϵ from the notation. Ac- cording to Eq. (6) , the corresponding entries of ˜ S (ϵ) are then given by: ˜ s kl = 1 n −1 ˜ p lk = s kl − ϵ n −1 , ˜ s lk = s lk + ϵ n −1 . 5 For simplicity, but also for clarity of the observations we make, we restrict to the case of varying the preferences related to only one pair of alternatives. 1035 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. European Journal of Operational Research 297 (2022) 1030–1041 As for the diagonal terms, the only terms affected by the per- turbation in the preference matrix are ˜ s kk and ˜ s ll : ˜ s kk = s kk + ϵ n −1 , ˜ s ll = s ll − ϵ n −1 . All these variations can be written in a compact form for the centrality matrix as ˜ S (ϵ) = S + S ϵ where S ϵ = k l ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ 0 . . . 0 . . . 0 . . . 0 . . . . . . . . . . . . . . . . . . . . . 0 . . . ϵ n −1 . . . −ϵ n −1 . . . 0 k . . . . . . . . . . . . . . . . . . . . . 0 . . . ϵ n −1 . . . −ϵ n −1 . . . 0 l . . . . . . . . . . . . . . . . . . . . . 0 . . . 0 . . . 0 . . . 0 (23) Theorem 2. Let ˜ π(ϵ) be the stationary distribution of ˜ S (ϵ) . Then ∂ ˜ πi (ϵ) ∂ϵ = ˜ πk + ˜ πl n −1 (t li −t ki ) πi , (24) where t ji denotes the mean ﬁrst passage time from x i to x j , i.e. the expected number of steps to reach state x j for the ﬁrst time starting from state x i , in the unperturbed centrality matrix ˜ S (0) = S. The proof of Theorem 2 is given in Appendix C . Note that Eq. (24) implies ∂ ˜ πk (ϵ) ∂ϵ = ˜ πk + ˜ πl n −1 t lk πk > 0 and ∂ ˜ πl (ϵ) ∂ϵ = −˜ πk + ˜ πl n −1 t kl πl < 0 which is expected. The perturbation of the preference associated with the pair (x k , x l ) affects every component ˜ πi in the stationary distribution ˜ π(ϵ) of the centrality matrix ˜ S (ϵ) . For suﬃciently small ϵ these components can be written as 6 ˜ πi ≃ πi + ϵ ∂ ˜ πi ∂ϵ ϵ=0 = πi 1 + ϵ ˜ πk + ˜ πl n −1 (t li −t ki ) . (25) Equation (25) can be interpreted as follows: For similar ﬁrst pas- sage times between alternatives, the perturbation of preferences in a single alternative-pair has an effect in the stationary distribution that is proportional to the amplitude of its components: dominant alternatives (higher rank) are more affected than other alternatives. One important consequence of Eq. (25) is that one can estimate ﬁrst passage times for all possible transitions between alternatives. Indeed, for k = i and l = i , since t kk = t ll = 0 by deﬁnition of ﬁrst passage time, Eq. (25) yields respectively t lk = ˜ πk πk −1 n −1 ϵ 1 ˜ πk + ˜ πl , (26a) t kl = 1 −˜ πl πl n −1 ϵ 1 ˜ πk + ˜ πl . (26b) Equation (25) can be used to estimate the global deviation of ˜ π(ϵ) from the ”unperturbed” stationary distribution ˜ π(0) : || ˜ π(ϵ) −˜ π(0) || 2 ≃ ϵ2 ( ˜ πk + ˜ πl ) 2 n −1 ⟨ (t li −t ki ) 2 π 2 i ⟩ i , (27) 6 It is worth mentioning that those two equations can be obtained too by apply- ing Proposition 2.1 due to Cho and Meyer ( Cho & Meyer, 20 0 0 ) where ⟨ (t li −t ki ) 2 π 2 i ⟩ i ≡ 1 n −1 n  i =1 (t li −t ki ) 2 π 2 i . (28) This equation can be interpreted as follows. The global deviation of ˜ π(ϵ) from the unperturbed stationary distribution ˜ π(0) increases with a ”weighted” second moment of the components of the un- perturbed stationary distribution. The weights for the component πi are given by the difference between the ﬁrst passage times from the corresponding alternative x i to the ”perturbed altrenatives” x k and x l . This observation has two main consequences. First, the result in Eq. (27) uncovers another intuitive consequence: the compo- nents of the stationary distribution which remain unchanged by perturbing the preference for a pair of alternatives (x k , x l ) are those for which the mean ﬁrst passage times from the corre- sponding alternative x i to each alternative in the perturbed pair is equal, i.e. t ki = t li . In particular, perturbing the preference for pairs of alternatives (x k , x l ) , which are evenly chosen in front of all other alternatives x i , i.e. t ki = t li for all i ̸ = k and i ̸ = l, will have no impact on the global preference strengths of the al- ternatives. Their impact is reduced to local changes of the am- plitudes of each alternative in the perturbed pair, namely ˜ πk and ˜ πl . Second, since deviations between perturbed and unperturbed stationary distribution are easy to measure in practice, Eq. (25) and (27) provide new insight for establishing a framework to assess, at least at a qualitative level, the impact of local perturbations in the global dynamics towards consensus. Namely, the results of this section have some implications when it comes to reaching consen- sus worth pursuing as future work. In fact, we can formalize the consensus problem as a gradient descent optimization where ex- perts need to do small adjustment to their preference matrices. The sensitivity of Markov chains to their transition probabilities can be used for computing the gradient in order to make the in- dividual stationary distribution of each expert move towards col- lective stationary distribution, by only adjusting the corresponding preference matrices. 5. Testing GDM with FPR: numerical experiments In this section we provide a concrete example of a GDM with FPR using our method. We ﬁrst compare the results of using our method against the results of using the popular Netﬂow method. Then, we perform an experimental sensitivity analyses to ex- plore what happens to the resulting ranking vector if we vary the entries of the initial preference matrices 1. by several values of ϵ > 0 applied to the same pair of alternatives; and 2. by a small ﬁxed ϵ > 0 applied to different pairs of alternatives in the matrix. We start by a numerical example highlighting the similarities and differences between our algorithm and an algorithm that uses the standard Netﬂow (NF) method. 5.1. A numerical example We consider a ﬁrst scenario with two experts ( m = 2 ) and four alternatives ( n = 4 ) 7 The experts’ opinions are expressed in the fol- 7 The code for performing the computations involved in the examples of this sec- tion is available at . The code can be straightfor- wardly changed for another number of experts. We have also tested for m = 3 and m = 4 , observing the same qualitative results. 1036 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. European Journal of Operational Research 297 (2022) 1030–1041 lowing preference matrices: P 1 = ⎡ ⎢ ⎣ 0 . 50 0 . 60 0 . 30 0 . 10 0 . 40 0 . 50 0 . 25 0 . 05 0 . 70 0 . 75 0 . 50 0 . 55 0 . 90 0 . 95 0 . 45 0 . 50 ⎤ ⎥ ⎦ , (29a) P 2 = ⎡ ⎢ ⎣ 0 . 50 0 . 55 0 . 25 0 . 05 0 . 45 0 . 50 0 . 25 0 . 05 0 . 75 0 . 75 0 . 50 0 . 58 0 . 95 0 . 95 0 . 42 0 . 50 ⎤ ⎥ ⎦ . (29b) The entries of the preferences matrices P 1 and P 2 differ by 5% or more, in a scale from 0 to 1. They can be provided by experts di- rectly as numerical values or obtained, for example, by qualitative preference modelling. 8 Assuming, for the sake of illustration, that these preferences represent relationships between pairs of four different sport teams in two different leagues, the relationships in both leagues share two common features: (i) the third team is moderately better than the ﬁrst and the second team, while the fourth team is much bet- ter than the ﬁrst and the second team, and (ii) the third team seems, against intuition, to be better than the fourth team. We ob- serve what happens with the ranking vectors derived from these two matrices when we apply our method. First of all, we normalize the preference matrices into stochastic matrices applying the Eq. (6) from Section 3.1 . This produces the following centrality matrices: S 1 = ⎡ ⎢ ⎣ 0 . 33 0 . 13 0 . 23 0 . 30 0 . 20 0 . 23 0 . 25 0 . 32 0 . 10 0 . 08 0 . 67 0 . 15 0 . 03 0 . 02 0 . 18 0 . 77 ⎤ ⎥ ⎦ , S 2 = ⎡ ⎢ ⎣ 0 . 28 0 . 15 0 . 25 0 . 32 0 . 18 0 . 25 0 . 25 0 . 32 0 . 08 0 . 08 0 . 69 0 . 14 0 . 02 0 . 02 0 . 19 0 . 77 ⎤ ⎥ ⎦ . Then we apply two direct methods to derive a group ranking of the alternatives: • (NF+WA) : exploitation is performed by computing a per-expert ranking using Netﬂow, and then aggregation is performed by computing the ﬁnal collective ranking using WA with uniform weights. • (RC+WA) : exploitation is performed by computing a per-expert ranking using Rank Centrality, and then aggregation is per- formed by computing the ﬁnal collective ranking using WA with uniform weights. The output weighted rankings produced by these methods are the following: output NF+WA =  −0 . 383 −0 . 517 0 . 36 0 . 54  output RC+WA =  0 . 087 0 . 069 0 . 388 0 . 456  , 8 One can, for example, use linguistic preference modelling ( Herrera, Alonso, Chi- clana, & Herrera-Viedma, 2009 ), and even give each individual expert the possibility to use different preference domains to express their respective preferences. This is- sue is studied in ( Delgado, Herrera, Herrera-Viedma, & Martinez, 1998 ) where it is shown that in such heterogeneous decision contexts, it is possible to achieve a so- lution by ﬁrst making the preferences uniform by converting them into FPRs over [0,1] by means of transformation functions. corresponding to the following qualitative rankings: rank NF+WA =  4 3 1 2  rank RC+WA =  4 3 1 2  , where the i-th element is the index of the alternative with the i- th best preference strength (in this case, the 4-th alternative is the most preferred, the 3-rd alternative is the second most preferred, and so on). The results are identical, and they rank the fourth al- ternative at the top, which captures the intuition in the football teams example. Note that in the above example, we have violation of both Internal Consistency and Pareto Optimality at the alterna- tives 3 and 4, but we still obtain a meaningful ranking. We now consider a second scenario, again with two experts ( m = 2 ) and four alternatives ( n = 4 ), but with the following pref- erence matrices: P 3 = ⎡ ⎢ ⎣ 0 . 50 0 . 60 0 . 20 0 . 10 0 . 40 0 . 50 0 . 15 0 . 05 0 . 80 0 . 85 0 . 50 0 . 55 0 . 90 0 . 95 0 . 45 0 . 50 ⎤ ⎥ ⎦ , P 4 = ⎡ ⎢ ⎣ 0 . 50 0 . 55 0 . 15 0 . 05 0 . 45 0 . 50 0 . 2 0 . 05 0 . 85 0 . 8 0 . 50 0 . 58 0 . 95 0 . 95 0 . 42 0 . 50 ⎤ ⎥ ⎦ . Notice that this new set of preference matrices preserves the rela- tionships of dominance described in i) and ii) above; however the degrees by which the third alternative dominates the ﬁrst and the second one have been increased, although they remain lower than the corresponding ones of the fourth alternative. After normalization according to Eq. (6) from Section 3.1 we ob- tain the following stochastic centrality matrices: S 3 = ⎡ ⎢ ⎣ 0 . 30 0 . 13 0 . 27 0 . 30 0 . 20 0 . 20 0 . 28 0 . 32 0 . 07 0 . 05 0 . 73 0 . 15 0 . 03 0 . 02 0 . 18 0 . 77 ⎤ ⎥ ⎦ , S 4 = ⎡ ⎢ ⎣ 0 . 25 0 . 15 0 . 28 0 . 32 0 . 18 0 . 23 0 . 27 0 . 32 0 . 05 0 . 07 0 . 74 0 . 14 0 . 02 0 . 02 0 . 19 0 . 77 ⎤ ⎥ ⎦ . Again we apply the two GDM strategies described above (NF+WA and RC+WA). The outcomes are: output NF+WA =  −0 . 45 −0 . 567 0 . 477 0 . 54  output RC+WA =  0 . 065 0 . 054 0 . 441 0 . 439  , with corresponding rankings: rank NF+WA =  4 3 1 2  rank RC+WA =  3 4 1 2  . This time, the results differ in the ordering of the third and the forth alternative. The difference in the results between the ﬁrst and the second scenario shows that the approach based on rank cen- trality has a distinctive sensitivity to the magnitude of the relations of preference among the alternatives. In particular, the approach based on RC+WA may rank higher alternatives that marginally dominate weak alternatives but also marginally dominate strong alternatives. This is consistent with the interpretation of rank cen- trality provided in ( Negahban et al., 2012; 2016 ). 1037 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. European Journal of Operational Research 297 (2022) 1030–1041 Fig. 2. Output of the two GDM strategies (NF+WA and RC+WA) when applied to ˜ P 1 (ϵ) and P 2 as a function of the parameter ϵ. See Eq. (29a) and (30) . 5.2. Experimental sensitivity analysis In this section we perform experimental sensitivity analysis, in- vestigating how the result of the group decision making changes under a perturbation of amplitude ϵ in the initial preference matri- ces. We restrict to the case when only one of the initial preference matrices changes in only one pair of alternatives, and we observe how various degrees of change affect the result. We consider again the ﬁrst scenario we presented in the previous simulation, but this time we instantiate a parametric version of the matrix P 1 for the ﬁrst expert: ˜ P 1 (ϵ) = ⎡ ⎢ ⎣ 0 . 50 0 . 60 0 . 30 −ϵ 0 . 10 0 . 40 0 . 50 0 . 25 0 . 05 0 . 70 + ϵ 0 . 75 0 . 50 0 . 55 0 . 90 0 . 95 0 . 45 0 . 50 ⎤ ⎥ ⎦ (30) with the parameter ϵ assuming values in the interval [0,0.3) in or- der to satisfy the requirement that, for every entry, 0 < p ij < 1 . The ϵ parameter allows us to increase the margin of the preference of the third alternative over the ﬁrst, and, consequently, to narrow the gap between the third and the fourth alternative. The prefer- ence matrix of the second expert is taken to be the same ﬁxed matrix P 2 used in the previous section. We then apply the two di- rect methods we considered before (NF+WA and RC+WA) to the matrices ˜ P 1 (ϵ) and P 2 , while changing the value of the parameter ϵ. Fig. 2 shows the variation in the output of the two methods as a function of the parameter ϵ. The results show that the two direct methods respond differently to similar changes. As the parameter ϵ increases, the gap between the third and the fourth alternative narrows more signiﬁcantly when using RC+WA instead of NF+WA. This change also leads to a decrease in the value of the ﬁrst al- ternative that is more marked for the RC+WA method; indeed, for values of ϵ around 0.20 the ﬁrst alternative becomes less prefer- able than the second one; for the range of ϵ that we considered, we do not notice a similar change in the ordering of the ﬁrst and the second alternative in the NF+WA method. When applying RC+WA in a scenario with many alternatives where we only perturb one pair of them, it is not always obvi- ous how this perturbation will reﬂect on the resulting preference strengths of the alternatives: which of them will have their pref- Table 1 Estimates of all ﬁrst passages times ˆ t ij according to Eq. (26) for matrix S 1 , com- pared with the values computed directly from the respective Markov chain simu- lation. k/l 1 2 3 4 1 — ˆ t 12 = 11 . 7042 ˆ t 13 = 12 . 7304 ˆ t 14 = 15 . 1242 ˆ t 21 = 16 . 3057 ˆ t 31 = 4 . 8454 ˆ t 41 = 4 . 1701 t 12 = 11 . 7039 t 13 = 12 . 7326 t 14 = 15 . 1259 t 21 = 16 . 3063 t 31 = 4 . 8463 t 41 = 4 . 1706 2 ˆ t 21 = 16 . 3057 — ˆ t 23 = 16 . 8106 ˆ t 24 = 19 . 8224 ˆ t 12 = 11 . 7024 ˆ t 32 = 4 . 7643 ˆ t 42 = 4 . 1132 t 21 = 16 . 3063 t 23 = 16 . 8135 t 24 = 19 . 8258 t 12 = 11 . 7039 t 32 = 4 . 7653 t 42 = 4 . 1140 3 ˆ t 31 = 4 . 8473 ˆ t 32 = 4 . 7665 — ˆ t 34 = 5 . 3176 ˆ t 13 = 12 . 7349 ˆ t 23 = 16 . 8167 ˆ t 43 = 5 . 2789 t 31 = 4 . 8463 t 32 = 4 . 7653 t 34 = 5 . 3184 t 13 = 12 . 7326 t 23 = 16 . 8135 t 43 = 5 . 2797 4 ˆ t 41 = 4 . 1713 ˆ t 42 = 4 . 1148 ˆ t 43 = 5 . 2805 — ˆ t 14 = 15 . 1280 ˆ t 24 = 19 . 8291 ˆ t 34 = 5 . 3192 t 41 = 4 . 1706 t 42 = 4 . 1140 t 43 = 5 . 2797 t 14 = 15 . 1259 t 24 = 19 . 8258 t 34 = 5 . 3184 erence strengths increased or decreased and for how much. As we will see, our theoretical perturbation analysis given by Eq. (24) can predict and interpret the changes based on the mean ﬁrst pas- sage times and the magnitudes of the preference strengths. The true mean ﬁrst passage times are given in Table 1 . In our case, the pair that is changed is (x k , x l ) = (3 , 1) . As per our theoretical results, the preference strength of the alternative 3 for expert 1 computed by RC will increase proportionally to t 13 = 12 . 7326 mod- erated by the strength π (1) 3 of the alternative itself. 9 Similarly the preference strength of the alternative 1 for expert 1 computed by RC will decrease proportionally to t 31 = 4 . 8463 moderated by the strength π (1) 1 of the alternative itself. But what about the rest of alternatives? The changes in the preference strength of the alterna- tive 4 for expert 1 is proportional to t 34 −t 14 = 5 . 3184 −15 . 1259 = −9 . 8075 moderated by π (1) 4 , meaning it will decrease. For alterna- tive 2, the changes in the preference strength for the ﬁrst expert is proportional to t 32 −t 12 = 4 . 7653 −11 . 7039 = −6 . 9386 moderated 9 Thus the aggregated preference strength of the alternative 3 will increase. 1038 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. European Journal of Operational Research 297 (2022) 1030–1041 -0.3 -0.15 0 0.15 0.3 Deviation (%) -0.3 -0.15 0 0.15 0.3 Deviation (%) 1 2 3 4 i -0.3 -0.15 0 0.15 0.3 Deviation (%) 1 2 3 4 i 1 2 3 4 i 1 2 3 4 i (k,l)=(1,2) (k,l)=(1,3) (k,l)=(1,4) (k,l)=(2,1) (k,l)=(2,3) (k,l)=(2,4) (k,l)=(3,1) (k,l)=(3,2) (k,l)=(3,4) (k,l)=(4,3) (k,l)=(4,2) (k,l)=(4,1) Fig. 3. Deviation of each component of the perturbed stationary distribution ˜ π(ϵ) in percentage of the respective component of the unperturbed stationary distribu- tion π(0) , when the preference matrix is changed for one single pair of alternatives (x k , x l ) . In all cases ϵ = 0 . 001 . See Eq. (25) . by the strength the alternative itself π (1) 2 . Since π (1) 2 is small, the magnitude of the latter changes is small too as can be seen in the aggregated weighted ranking given in Fig. 2 . To end the sensitivity analysis for this particular numerical experiment, we ﬁx the perturbation amplitude at a small value, namely ϵ = 0 . 001 , and apply it to each pair of alternatives (x k , x l ) in the matrix P 1 . The results are shown in Fig. 3 . While the larger deviations are typically observed for the components of the sta- tionary distribution associated with the perturbed pair, namely πk and πl , one also observes signiﬁcant changes in the other compo- nents. For example, when perturbing the pair (4,2) one observes also a signiﬁcant change in the amplitude of the ﬁrst component, and when perturbing the pair (3,4), all components are signiﬁ- cantly affected. Note that, in all cases the deviations for (x k , x l ) and (x l , x k ) are symmetric, as expected from Eq. (25) . Finally, in Fig. 4 we show the difference of the ﬁrst passage times, t li −t ki , for each perturbated pair of alternatives (x k , x l ) con- sidered in Fig. 3 , as computed directly from Eq. (25) . Similarly, one also observes cases where the perturbation of one particular pair of alternatives induces a change in the transitions from another al- -20 -10 0 10 20 tli-tki -20 -10 0 10 20 tli-tki 1 2 3 4 i -20 -10 0 10 20 tli-tki 1 2 3 4 i 1 2 3 4 i 1 2 3 4 i (k,l)=(1,2) (k,l)=(1,3) (k,l)=(1,4) (k,l)=(2,1) (k,l)=(2,3) (k,l)=(2,4) (k,l)=(3,1) (k,l)=(3,2) (k,l)=(3,4) (k,l)=(4,3) (k,l)=(4,2) (k,l)=(4,1) Fig. 4. For each perturbation of the preference matrix shown in Fig. 3 one plots the difference of ﬁrst passage times, t li −t ki , from each alternative x i to each alternative of the perturbed pair (x k , x l ) . The values were obtained by solving Eq. (25) for t li − t ki . ternative to the alternatives in the perturbed pair. Moreover, ap- plying Eq. (26) we estimate the ﬁrst passage times for all pairs of alternatives. Notice that, repeating the numerical experiment in- terchanging the role of k and l enables to make two estimates for each ﬁrst passage time. As shown in Tab. 1 , in all the cases both estimates are close to each other, showing the ability of our pro- cedure for estimating this dynamical property of consensus pro- cesses. 6. Conclusions and future work In this paper we have presented a direct approach to aggregat- ing fuzzy preference relations proposing a GDM method based on rank centrality. The method has the advantage of providing a natu- ral interpretation of the preference degrees as transition probabil- ities in a Markov chain and obtaining the corresponding weighted rankings by well-established computational methods. Moreover, as we show with our numerical examples, our approach shows more sensitivity to small variations in the preference values compared to other similar approaches. The natural next step is to design an experiment to test our framework and compare it with other GDM with FPR frameworks in the literature. We have implemented an online platform for col- lecting data during an iterative process towards consensus, which will enable to investigate the distances in the opinion space, either to the collective opinion, or pairwise distances between experts’ opinions. In this way we can test our framework for modelling processes towards reaching a consensus, and examine which ini- tial preference matrices lead to a consensual opinion. Finally, such experimental setup will also enable to investigate the time inter- val needed for achieving consensus in various real-life applications, and determine which framework enables the fastest converging it- erative processes. Moreover, investigating the inconsistency ( Kou, Ergu, & Shang, 2014; Kou & Lin, 2014; Lin, Kou, Peng, & Alsaadi, 2020 ) directly from a centrality matrix is a future research direc- tion worth investigating. We hope that the current work can fuel more research interest in bridging the gap between the GDM community and researchers in probability theory and its applications. Acknowledgement The work of Enrique Herrera Viedma was supported by the Spanish State Research Agency under Project PID2019-103880RB- I00/AEI/10.13039/501100011033. Appendix A. Irreducibility and aperiodicity of the stochastic matrix A Markov chain is irreducible if it is possible to get to any state from any state. Clearly, if the stochastic matrix S of a Markov chain with n states satisﬁes the condition: s ij > 0 , for every i, j ∈ { 1 , . . . , n } , then it (and so the Markov chain) is irreducible. The above condition is easy to prove under the assumption we made in Eq. (7) . Namely, from Eq. (6a) and the assumption p ij > 0 (fol- lowing from Eq. (7) ), it follows that s ij > 0 , for every i ̸ = j. If we suppose that s ii = 0 for some i , then, from Eq. (6b) , it will follows that  i ̸ = j p ij = n −1 . From this and the fact that p ij ∈ [0 , 1] , it fol- lows p ij = 1 , for i ̸ = j, which is in contradiction with the assump- tion p ij ̸ = 1 (again following from Eq. (7) ). It is easy to observe that the centrality matrix and the corre- sponding Markov chain are aperiodic. For a Markov chain to be aperiodic, every state has to be aperiodic, that is, for any state i the greatest common divisor of the number of steps k that it may take to return to i is 1. Now, from Eq. (6) and from the discus- sion on irreducibility, we have that s ij > 0 for all i, j. Therefore, for 1039 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. European Journal of Operational Research 297 (2022) 1030–1041 any state i , there is a non-zero probability of returning to state i in k steps, for k = { 1 , 2 , 3 , . . . } . The greatest common divisor of this number of steps is then 1. Thus every state i is aperiodic, and the Markov chain with its associated centrality matrix is aperiodic. Appendix B. Proof of Theorem 1 To prove Theorem 1 , let us consider a BTL model with parame- ter vector π such that p ij = πi πi + πj . Let M ij be the number of sam- ple comparisons between x i and x j and m ij the samples in which alternative x i wins over x j . Hence, there is a real number, M, such that M ij = m ij + m ji ≡ M(πi + π j )  . (B.1) where ⌈ . ⌉ denotes the operator that rounds to nearest integer. In what follows we will only need the limit of large values of M ij (i.e. M ij → ∞ ) for which M → ∞ and  M(πi + π j )  → M(πi + π j ) . Under the assumption of independent and identically dis- tributed samples, the likelihood function of the BTL model is given by: L (π) = n  i =1 n  j=1 j̸ = i p m ij ij = n  i =1 n  j=1 j̸ = i πi πi + π j m ij , (B.2) where we disregard the case πi = 0 , which only occurs in the “pathological” case where for some j ̸ = i , p ij = 0 . We take the log- likelihood function of (B.2) log L (π) = n  i =1 n  j =1 ,j ̸ = i m ij log πi πi + π j . (B.3) To ﬁnd the Maximum Likelihood Estimate (MLE) of the BTL model we take the partial derivative of the likelihood function with re- spect to the parameters of the model: ∂ log L (π) ∂πi = n  j =1 ,j ̸ = i m ij 1 πi −(m ij + m ji ) 1 πi + π j = n  j =1 ,j ̸ = i m ij ( 1 πi − 1 πi + π j ) −m ji 1 πi + π j = n  j =1 ,j ̸ = i m ij 1 πi π j πi + π j −m ji 1 πi + π j = 1 πi n  j =1 ,j ̸ = i m ij π j πi + π j −m ji πi πi + π j We determine the MLE π ∗as the value of π at which the par- tial derivatives are zero, that is: n  j =1 ,j ̸ = i m ij π ∗ j π ∗ i + π ∗ j = n  j =1 ,j ̸ = i m ji π ∗ i π ∗ i + π ∗ j (B.4) By applying the law of large numbers, p ij can also be deﬁned as: p ij = lim M ij →∞ m ij M ij = lim M→∞ m ij M(πi + π j ) = lim M→∞ m ij M(π ∗ i + π ∗ j ) Please note that we used the argument that π ∗ i + π ∗ j ≈πi + π j by virtue of the MLE. Similarly, p ji = lim M→∞ m ji M(π ∗ i + π ∗ j ) Hence in the limit of M → ∞ m ij = p ij M(π ∗ i + π ∗ j ) (B.5) and m ji = p ji M(π ∗ i + π ∗ j ) . (B.6) By substituting Eq. (B.5) and Eq. (B.6) in Eq. (B.4) we obtain n  j =1 ,j ̸ = i p ij M(π ∗ i + π ∗ j ) π ∗ j π ∗ i + π ∗ j = n  j =1 ,j ̸ = i p ji M(π ∗ i + π ∗ j ) π ∗ i π ∗ i + π ∗ j , which yields the following global balance equation: n  j =1 ,j ̸ = i p ij π ∗ j = n  j =1 ,j ̸ = i p ji π ∗ i . Appendix C. Proof of Theorem 2 Let A ∗be the group inverse of A = I −S ( Golub & Meyer, 1986 ), i.e. A ∗is the unique matrix 10 satisfying the three equations AA ∗A = A , A ∗AA ∗= A ∗and A ∗A = AA ∗. Let a ∗ ij denote the entries of A ∗, and let A ∗ ∗i be the i-th column of A ∗. Then, we can apply Theorem 3.2 from Golub and Meyer ( Golub & Meyer, 1986 ) to study the sensi- tivity of the ranking to changes of ϵ, namely: ∂ ˜ πi (ϵ) ∂ϵ = ˜ π(ϵ) ∂ ˜ S (ϵ) ∂ϵ A ∗ ∗i = ˜ π(ϵ) ∂S ϵ(ϵ) ∂ϵ A ∗ ∗i , (C.1) where ∂S ϵ(ϵ) ∂ϵ = k l ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ 0 . . . 0 . . . 0 . . . 0 . . . . . . . . . . . . . . . . . . . . . 0 . . . 1 n −1 . . . − 1 n −1 . . . 0 k . . . . . . . . . . . . . . . . . . . . . 0 . . . 1 n −1 . . . − 1 n −1 . . . 0 l . . . . . . . . . . . . . . . . . . . . . 0 . . . 0 . . . 0 . . . 0 (C.2) Let e i = (0 , . . . , 0 , 1 , 0 , . . . , 0) T be the unit vector with entries δik for k = 1 , . . . , n . Then, ∂S ϵ(ϵ) ∂ϵ can be written as ∂S ϵ(ϵ) ∂ϵ = 1 n −1 [ e k  e k −e k  e l −e l  e l + e l  e k ] , where  denotes the tensor product between unit vectors. Substi- tuting this expression in Eq. (C.1) yields ∂ ˜ πi (ϵ) ∂ϵ = 1 n −1 n  r=1 n  s =1 ˜ πr  (e k  e k ) rs −(e k  e l ) rs −(e l  e l ) rs + (e l  e k ) rs  a ∗ si = 1 n −1 n  r=1 n  s =1 ˜ πr (δkr δks −δkr δls −δlr δls + δlr δks ) a ∗ si = 1 n −1 ( ˜ πk a ∗ ki −˜ πk a ∗ li −˜ πl a ∗ li + ˜ πl a ∗ ki ) = ˜ πk + ˜ πl n −1 (a ∗ ki −a ∗ li ) , (C.3) where δij is the Kronecker-delta, δij = 1 if i = j and zero otherwise. 10 Matrix A ∗is also called ”Drazin inverse” of Laplacian, which according to Mahadevan et al. (2009) ”reveals a great deal of information about the structure of the Markov chain ”. 1040 A. Yazidi, M. Ivanovska, F.M. Zennaro et al. European Journal of Operational Research 297 (2022) 1030–1041 According to Cho and Meyer ( Cho & Meyer, 20 0 0 ), A ∗is diago- nally dominant over the columns, meaning that for all pairs (i, j) a ∗ ji = a ∗ ii −t ji πi (C.4) where t ji denotes the mean ﬁrst passage time from x i to x j . Intro- ducing Eq. (C.4) in Eq. (C.3) yields Eq. (24) in Theorem 2 . References van Berkum, E. (1997). Bradley-terry model. In Encyclopaedia of mathematics. sup- plement i (pp. 148–148). Kluwer Academic Publishers. Bouyssou, D. (1992). Ranking methods based on valued preference relations: a char- acterization of the net ﬂow method. European Journal of Operational Research, 60 (1), 61–67 . Cabrerizo, F. J. , Moreno, J. M. , Pérez, I. J. , & Herrera-Viedma, E. (2010). Analyzing con- sensus approaches in fuzzy group decision making: Advantages and drawbacks. Soft Computing, 14 (5), 451–463 . Capuano, N. , Chiclana, F. , Fujita, H. , Herrera-Viedma, E. , & Loia, V. (2017). Fuzzy group decision making with incomplete information guided by social inﬂuence. IEEE Transactions on Fuzzy Systems, 26 (3), 1704–1718 . Chiclana, F. , Herrera, F. , & Herrera-Viedma, E. (2002). A note on the internal con- sistency of various preference representations. Fuzzy Sets and Systems, 131 (1), 75–78 . Chiclana, F. , Herrera, F. , Herrera-Viedma, E. , & Martínez, L. (2003). A note on the reciprocity in the aggregation of fuzzy preference relations using OWA opera- tors. Fuzzy Sets and Systems, 137 (1), 71–83 . Cho, G. E. , & Meyer, C. D. (20 0 0). Markov chain sensitivity measured by mean ﬁrst passage times. Linear Algebra and its Applications, 316 (1–3), 21–28 . Delgado, M. , Herrera, F. , Herrera-Viedma, E. , & Martinez, L. (1998). Combining nu- merical and linguistic information in group decision making. Information Sci- ences, 107 (1–4), 177–194 . Dong, Y. , Xu, Y. , Li, H. , & Feng, B. (2010). The OWA-based consensus operator un- der linguistic representation models using position indexes. European Journal of Operational Research, 203 (2), 455–463 . Dong, Y. , Xu, Y. , & Yu, S. (2009). Linguistic multiperson decision making based on the use of multiple preference relations. Fuzzy Sets and Systems, 160 (5), 603–623 . Dong, Y. , & Zhang, H. (2014). Multiperson decision making with different prefer- ence representation structures: A direct consensus framework and its proper- ties. Knowledge-based Systems, 58 , 45–57 . Dopazo, E. , & Martínez-Céspedes, M. L. (2017). Rank aggregation methods deal- ing with ordinal uncertain preferences. Expert Systems with Applications, 78 , 103–109 . Fan, Z.-P. , Ma, J. , Jiang, Y.-P. , Sun, Y.-H. , & Ma, L. (2006). A goal programming ap- proach to group decision making based on multiplicative preference relations and fuzzy preference relations. European Journal of Operational Research, 174 (1), 311–321 . Fernandez, E. , & Leyva, J. C. (2004). A method based on multiobjective optimiza- tion for deriving a ranking from a fuzzy preference relation. European Journal of Operational Research, 154 (1), 110–124 . García-Lapresta, J. L. , Martínez-Panero, M. , & Meneses, L. C. (2009). Deﬁning the borda count in a linguistic decision making context. Information Sciences, 179 (14), 2309–2316 . Gleich, D. F. (2015). Pagerank beyond the web. SIAM Review, 57 (3), 321–363 . Golub, G. H. , & Meyer, C. D., Jr (1986). Using the QR factorization and group inver- sion to compute, differentiate, and estimate the sensitivity of stationary prob- abilities for Markov chains. SIAM Journal on Algebraic Discrete Methods, 7 (2), 273–281 . Gong, Z.-W. (2008). Least-square method to priority of the fuzzy preference rela- tions with incomplete information. International Journal of Approximate Reason- ing, 47 (2), 258–264 . Henriet, D. (1985). The copeland choice function an axiomatic characterization. So- cial Choice and Welfare, 2 (1), 49–63 . Herrera, F. , Alonso, S. , Chiclana, F. , & Herrera-Viedma, E. (2009). Computing with words in decision making: Foundations, trends and prospects. Fuzzy Optimiza- tion and Decision Making, 8 (4), 337–364 . Herrera, F. , Herrera-Viedma, E. , & Verdegay, J. L. (1996). Direct approach processes in group decision making using linguistic OWA operators. Fuzzy Sets and Systems, 79 (2), 175–190 . Herrera-Viedma, E. , Alonso, S. , Chiclana, F. , & Herrera, F. (2007). A consensus model for group decision making with incomplete fuzzy preference relations. IEEE Transactions on Fuzzy Systems, 15 (5), 863–877 . Herrera-Viedma, E. , Cabrerizo, F. J. , Kacprzyk, J. , & Pedrycz, W. (2014). A review of soft consensus models in a fuzzy environment. Information Fusion, 17 , 4–13 . Herrera-Viedma, E. , García-Lapresta, J. L. , Kacprzyk, J. , Fedrizzi, M. , Nurmi, H. , & Sła- womir, Z. (2011). Consensual processes : vol. 267. Springer . Herrera-Viedma, E. , Herrera, F. , & Chiclana, F. (2002). A consensus model for mul- tiperson decision making with different preference structures. IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans, 32 (3), 394–402 . Herrera-Viedma, E. , Herrera, F. , Chiclana, F. , & Luque, M. (2004). Some issues on con- sistency of fuzzy preference relations. European Journal of Operational Research, 154 (1), 98–109 . Horn, R. A. , & Johnson, C. R. (1990). Matrix analysis . Cambridge University Press . Kitainik, L. (2012). Fuzzy decision procedures with binary relations: towards a uniﬁed theory : vol. 13. Springer Science & Business Media . Kou, G. , Ergu, D. , & Shang, J. (2014). Enhancing data consistency in decision matrix: adapting hadamard model to mitigate judgment contradiction. European Journal of Operational Research, 236 (1), 261–271 . Kou, G. , & Lin, C. (2014). A cosine maximization method for the priority vector derivation in AHP. European Journal of Operational Research, 235 (1), 225–232 . Lin, C. , Kou, G. , Peng, Y. , & Alsaadi, F. E. (2020). Aggregation of the nearest consis- tency matrices with the acceptable consensus in AHP-GDM. Annals of Operations Research , 1–17 . MacCluer, C. R. (20 0 0). The many proofs and applications of perrons theorem. SIAM Review, 42 , 4 87–4 98 . Mahadevan, S. , et al. (2009). Learning representation and control in markov de- cision processes: New frontiers. Foundations and Trends® in Machine Learning, 1 (4), 403–565 . Marchant, T. (1996). Valued relations aggregation with the borda method. Journal of Multi-Criteria Decision Analysis, 5 (2), 127–132 . Negahban, S. , Oh, S. , & Shah, D. (2012). Iterative ranking from pair-wise compar- isons. In Advances in neural information processing systems (pp. 2474–2482) . Negahban, S. , Oh, S. , & Shah, D. (2016). Rank centrality: Ranking from pairwise com- parisons. Operations research, 65 (1), 266–287 . Palomares, I. , Estrella, F. J. , Martínez, L. , & Herrera, F. (2014). Consensus under a fuzzy context: Taxonomy, analysis framework AFRYCA and experimental case of study. Information Fusion, 20 , 252–271 . Pedrycz, W. , Ekel, P. , & Parreiras, R. (2010). Introduction to preference modeling with binary fuzzy relations (pp. 137–153)). John Wiley & Sons, Ltd . Plackett, R. L. (1975). The analysis of permutations. Journal of the Royal Statistical Society: Series C (Applied Statistics), 24 (2), 193–202 . Rajkumar, A. , & Agarwal, S. (2014). A statistical convergence perspective of algo- rithms for rank aggregation from pairwise data. In International conference on machine learning (pp. 118–126) . Seo, F., & Sakawa, M. (1985). Fuzzy multiattribute utility analysis for collective choice. IEEE transactions on systems, man, and cybernetics, SMC-15 (1), 45–53. . Tanino, T. (1990). On group decision making under fuzzy preferences. In Multiper- son decision making models using fuzzy sets and possibility theory (pp. 172–185). Springer . Ureña, R. , Chiclana, F. , Morente-Molinera, J. A. , & Herrera-Viedma, E. (2015). Man- aging incomplete preference relations in decision making: A review and future trends. Information Sciences, 302 , 14–32 . Ureña, R. , Kou, G. , Wu, J. , Chiclana, F. , & Herrera-Viedma, E. (2019). Dealing with in- complete information in linguistic group decision making by means of interval type-2 fuzzy sets. International Journal of Intelligent Systems, 34 (6), 1261–1280 . Xu, Z. , & Da, Q. (2005). A least deviation method to obtain a priority vector of a fuzzy preference relation. European Journal of Operational Research, 164 (1), 206–216 . Yager, R. R. (1988). On ordered weighted averaging aggregation operators in mul- ticriteria decisionmaking. IEEE Transactions on Systems, Man, and Cybernetics, 18 (1), 183–190 . Zhu, B. , & Xu, Z. (2014). A fuzzy linear programming method for group decision making with additive reciprocal fuzzy preference relations. Fuzzy Sets and Sys- tems, 246 , 19–33 . 1041"
A New Adaptive Mixture Distance-Based Improved Density Peaks Clustering for Gearbox Fault Diagnosis,"Sharma, Krishna Kumar and Seal, Ayan and Yazidi, Anis and Krejcar, Ondrej",2022,,71,IEEE Transactions on Instrumentation and Measurement,article,"IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
3528716
A New Adaptive Mixture Distance-Based
Improved Density Peaks Clustering for
Gearbox Fault Diagnosis
Krishna Kumar Sharma
, Ayan Seal
, Senior Member, IEEE,
Anis Yazidi
, Senior Member, IEEE, and Ondrej Krejcar
Abstract—With the rapid development of sensors and mechan-
ical systems, we produce an exponentially large amount of data
daily. Usually, faults are prevalent in these sensory systems due
to harsh operational conditions. Thus, detecting and diagnosing
faults in the gearbox of mechanical systems are done by analyzing
an exponentially large amount of data in the form of vibration
signals and categorical features. However, the automatic fault
detection method can match the increasing requirement for
high-quality products in the course of intelligent manufacture.
Thus, to acquire more distinguishable fault features under varied
conditions, a new adaptive mixture distance-based simple and
efﬁcient density peaks clustering algorithm is proposed for
handling mixed data as real-world datasets encompassing both
numerical and categorical attributes. Our approach revolves
around the concept of a sequence of the weighted exponential ker-
nel using a symmetry-favored c-nearest neighbor to estimate the
global parameter and the local density of each data point. Then,
the initial clusters are extracted from a decision graph using an
adaptive threshold parameter. The ﬁnal step is to allocate the
remaining data objects, if they are density reachable, to either
of the initial groups. Thirteen UCI datasets and one real-world
dataset from a mechanical system for gearbox defect diagnosis
are employed to validate the proposed method. Five external and
two internal evaluation criteria are considered to gauge how well
the strategies are working. All of the ﬁndings indicate that the
proposed method outperforms 13 other approaches.
Manuscript
received
10
July
2022;
revised
16
September
2022;
accepted 9 October 2022. Date of publication 21 October 2022; date of current
version 9 November 2022. This work was supported in part by the SPEV
project “Smart Solutions in Ubiquitous Computing Environments” (under
ID: UHK-FIMSPEV-2022-2102), University of Hradec Kralove, Faculty of
Informatics and Management, Czech Republic. The Associate Editor coordi-
nating the review process was Dr. Xiaofeng Yuan. (Corresponding author:
Ayan Seal.)
Krishna Kumar Sharma is with the Department of Computer Science
and Informatics, University of Kota, Kota, Rajasthan 324005, India (e-mail:
krisshna.sharma@gmail.com).
Ayan Seal is with the Department of Computer Science and Engi-
neering, PDPM Indian Institute of Information Technology, Design and
Manufacturing Jabalpur, Jabalpur, Madhya Pradesh 482005, India (e-mail:
ayanseal30@ieee.org).
Anis Yazidi is with the Department of Computer Science, Oslo Metropol-
itan University (OsloMet), 0166 Oslo, Norway, also with the Department
of Computer Science, Norwegian University of Science and Technology
(NTNU), 7034 Trondheim, Norway, and also with the Department of Plastic
and Reconstructive Surgery, Oslo University Hospital (OuS), 460167 Oslo,
Norway (e-mail: anis.yazidi@oslomet.no).
Ondrej Krejcar is with the Center for Basic and Applied Science, Faculty of
Informatics and Management, University of Hradec Kralove, 500 03 Hradec
Kralove, Czech Republic, and also with the Malaysia-Japan International Insti-
tute of Technology (MJIIT), Universiti Teknologi Malaysia, Kuala Lumpur
54100 , Malaysia (e-mail: ondrej.krejcar@uhk.cz).
Digital Object Identiﬁer 10.1109/TIM.2022.3216366
Index Terms—Density peaks clustering (DPC), mixed data
(MD), S-distance, symmetric favored c-nearest neighbors (c-NN).
I. INTRODUCTION
A
PPROPRIATE fault detection of the gearbox and bearing
will be advantageous for the rotary machine, as they are
indispensable components of it. Typically, rotary machines
operate under harsh conditions, for example, uncertain or
driving loads, up/variable speeds, and material fatigue, which
generate possibilities for faults in the gearbox and bearings [1],
[2], [22]. Thus, it creates improper situations for the machines
and may cause downtime, economic loss, and maintenance
costs to the organizations [3], [4], [5]. Therefore, effective sig-
nal processing techniques can protect the gearbox and bearing
from the unforeseen situations mentioned above. Generally,
vibration signal analysis is an efﬁcient and viable approach
for detecting faults, as they have a high correlation with the
states of machine parts and organizations [6], [7]. There are
various learning methods, such as supervised classiﬁcation and
unsupervised clustering, for fault identiﬁcation. In addition,
the most fundamental exploratory, meta-learning data analysis
method, is clustering, which splits a set of data objects,
denoted as a feature or observation vector, into nonempty,
mutually exclusive subsets, groups, or clusters, such that
elements of the same group are similar to one another based
on some similarity metrics, whereas members of different
subsets are dissimilar [8]. Therefore, much consideration must
be paid to ﬁnding the obscure but imperative information in the
data, for example, insights, patterns, and rules. These primitive
data have no class information that represents the type of
unsupervised learning.
Some frequently employed clustering techniques in machine
fault detection are k-means, hierarchical, afﬁnity propagation,
fuzzy c-means (FCM), and kernel spectral. Shuqing et al. [9]
and Ramos et al. [10] used FCM for fault detection. How-
ever, it adopts the spherical distance data together with the
speciﬁcation and is only effective for homogeneous data dis-
tribution. An improved method built on FCM was Gustafson–
Kessel. After combining the adaptive distance rule and the
covariance matrix, it can handle data with subspace dispersion
in any direction [11]. Gustafson–Kessel was applied in the
fault detection of the roller bearing by Wang et al. [12].
1557-9662 © 2022 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
Liu et al. [13] presented a k-means clustering-based fault
identiﬁcation technique for wind turbines. A fuzzy rule-
based clustering approach was employed for the detection
of anomalies in wind turbines [14]. It was also adopted for
bearing fault detection [15]. An improved FCM clustering
approach was applied for dissolved gas analysis-data-based
transformer fault detection [16]. A hierarchical-based cluster-
ing method was adopted for the evaluation of the vibration
level and interior noise of vehicles [17]. Only a spherical
pattern dataset is suitable for fuzzy and Gustafson–Kessel
algorithms, but data obtained from practical systems have a
variety of structures and shapes. Consequently, a Gath–Geva
was developed to enhance the results. It follows the fuzzy
maximum likelihood estimator. It is appropriate for data from
variant orientations [18], [19]. In [20], afﬁnity propagation
clustering was implemented with adaptive feature selection
on vibration signals for the detection of bearing faults.
Langone et al. [21] introduced a spectral clustering-based
method to identify the normal and erroneous states of a
machine. A sparse subspace clustering technique using a com-
posite graph with a new distance was presented to diagnose
faults in machines [22]. Fong et al. [23] designed a mean
shift-based clustering approach for machinery diagnostics
on vibration signals. Hou et al. [24] presented the fuzzy
Gath–Geva clustering technique, linear discriminant analysis,
and ensemble empirical mode decomposition to diagnose
rolling bearing faults. Although the majority of the studies
mentioned above on intelligent defect identiﬁcation have
shown useful ﬁndings, they still have some obvious ﬂaws,
which are given as follows.
1) Most clustering algorithms for fault diagnosis rely on the
hypothesis that data comprise only numerical values.
2) Most previous works exploit the FCM to diagnose
machine faults. It means that, in the case of high-
dimensional data, the selection of the fuzziﬁer will
be crucial, and it may be trapped in local minima.
Generally, FCM-based fault diagnosis algorithms pre-
fer overlapping and spherical-shaped vibration signal
datasets.
3) Existing clustering-based fault diagnosis methods are not
sufﬁciently general and rely on the input parameters and
the number of clusters for fault types. Thus, there are
situations where they fail due to quite complicated actual
working conditions of the systems.
In
this study, we
explore the possibilities of using
density-based clustering approaches, such as DENCLUE,
OPTICS, and DBSCAN, for fault diagnosis to handle the
limitations stated above because they are suitable for arbitrary-
shaped clusters. Moreover, these algorithms can ﬁlter out
noise from data [25]. However, they are parameter-dependent.
In particular, DBSCAN relies on two parameters, i.e., the
minimum number of data objects in a neighborhood (MinPts)
and the radius of the neighborhood for a data object. The
values of MinPts and the radius of the neighborhood are
determined by users manually, which is intrinsically hard
to ﬁx [25]. Rodriguez and Laio [26] presented a density
peaks clustering (DPC) algorithm to detect arbitrary-shaped
clusters. Since then, DPC has received increased research
attention over the past few years. Generally, the DPC algo-
rithm assumes that the cluster’s center is farther from other
cluster centers and is in a zone with a higher local density
than its neighbors. For each data object or point, the DPC
algorithm computes the local density and the distance from
locations of higher density. Cluster centers are positioned in
the top-right corner of a decision graph that has been created.
Finally, all the data objects are assigned to one of the cluster
centers. However, reliable density estimation is a complex
problem. In their seminal paper, Rodriguez and Laio [26]
suggested estimating density irrespective of the dataset size.
However, small datasets are affected by the cutoff distance
while estimating local density [26]. The DPC algorithm’s
signiﬁcant beneﬁt is its capacity to locate nonspherical clusters
without prior knowledge of the number of classes. The
DPC does not involve an iterative process. However, DPC
might not automatically determine the correct number of
clusters.
A density reachable concept and a divide-and-conquer-
based 3DC clustering algorithm were given in [27] and [28],
respectively, to address the aforementioned problem. Yaohui
et al. [28] and Du et al. [29] investigated the concept of
c-nearest neighbors (c-NN) in DPC for estimating local
density. However, asymmetric edges are given the same
weight as symmetric ones in c-NN-based DPC. Moreover,
evidence from the literature has shown that data objects
with asymmetric edges may end up in different clusters
[30]. Furthermore, cluster representatives are selected based
on the decision graph using a parameter cutoff distance.
Thus, inappropriate selection of parameters may lead to
an inaccurate decision graph and, consequently, incorrect
cluster representatives. Furthermore, most of the clustering
algorithms work under the assumption of numerical or cat-
egorical attributes [25], [31], [32], [33], [34], [35], [36].
In reality, all datasets have categorical and numerical attributes,
which is known as a mixed-attribute dataset. As we will
explain later, clustering unlabeled-mixed datasets is thus a
tedious task. To deal with the latter issue, some clustering
algorithms transform the categorical attributes into numeric
attributes by performing binary encoding. Then, the similarity
between the transformed data objects is then determined
using the Euclidean distance. However, the obtained dis-
tances cannot capture the original structures of categorical
attributes.
Moreover, when it comes to categories with two possible
values, an associated binary representation of them is meaning-
less and hard to interpret [37]. Hsu [38] presented a weighted
distance tree structure with a distance hierarchy. However,
domain knowledge is required for both the creation of distance
hierarchies and the assignment of weights. The interested
readers are referred to [26], [29], [37], [39], [40], [41], [42],
[43], [44] for more information related to several similarity
measures for mixed data (MD) clustering. However, there is
a trend to introduce nonlinearity into similarity measures for
clustering [31]. Thus, clustering a dataset involving mixed
attributes is still a challenging task.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
This article suggests a novel adaptive mixture distance
(AD)-based DPC technique to diagnose mechanical system
gearbox failures. The following are some imperative contribu-
tions made by the proposed approach.
1) The inherent pattern of categorical characteristics is
squashed by most existing techniques, which convert
categorical attributes into sets of binary features. In other
words, transformed binary features have no use. More-
over, their values are difﬁcult to comprehend [37]. Thus,
an entropy-based distance is presented to categorical
features of the 13 UCI datasets and one real-world
dataset, which keeps the original pattern of categorical
attributes without transforming their representation. The
real-world dataset consists of nonstationary vibration
signals from a mechanical system for gearbox fault
diagnosis.
2) A novel AD metric is introduced in this study that
utilizes a weight parameter to merge the two similarity
metrics, S-distance and similarity index. The former is
deﬁned in the open cone of positive deﬁnite matrices
and is based on the concept of S-divergence [8], [31].
It is considered to calculate the separation between two
numerical properties of the datasets examined. The latter
is employed to determine how far apart categorized fea-
tures are from one another. If there are more categorical
features than numerical attributes, the similarity index is
given a higher weight and vice versa.
3) A relatively new local density metric is specially adopted
to deal with the noise that may be produced in real time
while recording nonstationary vibration signals from a
mechanical system. The local density metric relies on
a sequence of the weighted exponential kernel using
a symmetry-favored c-NN (SFCNN). It is capable of
overcoming the limitations of ﬁxed c-NN. Moreover,
it characterizes the implicit geometrical structures. Fur-
thermore, it increases the space in the density between
outliers and core objects, which helps in generating
efﬁcient and correct cluster representatives.
4) A new method for the selection of initial cluster centers
is presented, which assures correct cluster centers even
in the case of an unbalanced dataset and nonuniform
distribution of classes.
The modiﬁed DPC based on AD (MDPC-AD) is implemented
on a total of 13 UCI datasets and a real-world dataset
for gearbox fault diagnosis of a mechanical machine. Five
clustering validation indices, namely, accuracy (A), precision
(P), recall (R), F-Score (F), and the Jaccard index (JI), are
used to show the superiority of the MDPC-AD. However,
abbreviated forms of the validation indices mentioned above
will be used only in ﬁgures for better accommodation and
presentation. Moreover, two internal validation indices, for
example, average clustering error and ratio of separation and
compactness, are also adopted in this study. According to the
results, the MDPC-AD outranks 13 state-of-the-art (SOTA)
approaches.
The remaining work consists of the following. Section II
discusses pertinent related studies. In Section III, the proposed
distance metric deﬁnition is discussed, followed by MDPC-
AD. In Section IV, all experimental ﬁndings are presented.
The work is ﬁnally concluded in Section V.
II. THEORETICAL FOUNDATION OF DPC
A. Notations
Let O
= {O1, O2, . . . , Oi, . . . , On} be a dataset of n
MD objects. Each data object Oi ∈ℜd=|ψ|+|φ|, where 1 ≤
i
≤n, has d number of features or attributes in total.
However, each Oi has |ψ| and |φ| number of numerical
ψ and categorical φ attributes, respectively. Thus, Oψ
i,l is
the lth numerical feature of Oψ
i . Similarly, Oφ
i,l is the lth
categorical attribute of Oφ
i . The domain of lth categorical
feature dm(H φ
l ) = {hl,1, hl,2, . . . , hl,sl } has sl discrete values,
whereas domain of the lth numerical attribute dm(H ψ
l ) is
continuous. Therefore, each Oi is a combination of categorical
and numerical values and it is denoted by [Oψ
i , Oφ
i ] =
[Oψ
i,1, Oψ
i,2, . . . , Oψ
i,|ψ|, Oφ
i,|ψ|+1, . . . , Oφ
i,d={|ψ|+|φ|}].
B. Density Peaks Clustering
Fundamentally, DPC identiﬁes cluster representatives with
a higher density in comparison to their neighbors, and cluster
representatives are located at a relatively large distance from
each other. The two main parameters of this method are the
local density βi of each data object Oi and the distance
γi from objects with greater densities. Furthermore, two
hypotheses correspond to the cluster representatives: 1) cluster
representatives are located in higher density areas and their
neighbors have lower densities and 2) cluster representatives
are in relatively distant positions from each other or at a
relatively higher distance to the data objects of higher density.
The detailed discussion of the computation of βi and γi is
given as follows.
Generally, the DPC algorithm works on numerical values
and adopts the linear Euclidean distance function as a similar-
ity measure for numerical attributes in the clustering analysis.
The Euclidean distance λe between two data objects Oi and
O j is deﬁned by (1) with the assumption that data consist only
of numerical attributes
λ2
e

Oi, O j

=
l=d

l=1

Oi,l −O j,l
2.
(1)
The local density of a data object, Oi, is represented by βi
and is deﬁned by the following equation:
βi =

j
exp

−λ2
e

Oi, O j

αt

(2)
where αt denotes an adjustable variable, which controls the
weight decrease rate. αt is the single variable in (2), and it
relies on choosing the average number of neighbors of all
data objects in the dataset. Rodriguez and Laio [26] deﬁned
αt as given in the following equation:
αt = α⌈τ⌉
(3)
where α⌈τ⌉∈{α1, α2, . . . , α(
n
2)} and this set contains distances
between every pair of two data objects in the dataset, arranged
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
ascendingly. Another parameter γi is also computed using (4),
which shows the minimum distance between the data object
Oi and other data objects with larger density
γi =
⎧
⎨
⎩
min
j
λe
Oi, O j
,
if ∃s.t. βi < β j
max
j

λe

Oi, O j

, else.
(4)
When βi and γi for each data object have been computed,
large values of βi and γi are explored anomalously in this
method to identify the cluster representatives. Based on this
concept, cluster representatives are always located on the
decision graph’s top right side. Once cluster representatives
are identiﬁed, the remaining data objects are assigned to the
nearest cluster with a higher density.
III. PROPOSED METHOD
It is clear from the previous discussion that there are still
some limitations to DPC and its peer methods. Hence, the
DPC algorithm is improved in this study by introducing a
novel adaptive mixture similarity measure. A new method for
estimating the density of data points is introduced. Moreover,
we present a novel way to construct a decision graph. In this
section, we provide the details of the proposed clustering
algorithm, MDPC-AD, and its theoretical complexity analysis.
A. Similarity Measure of Numerical Attributes
For revealing the natural cluster structure in a given dataset,
which is a topic of active research, selecting an appropriate
similarity/dissimilarity metric is essential. Since its inception,
the proper selection of a similarity/difference metric has been
a challenge. Recently, there has been an upsurge of interest
in divergence-based nonlinear similarity measure [8], [31] for
clustering analysis as this type of distance is susceptible to
ﬁnding more appropriate complex cluster boundaries. Thus,
nonlinear S-distance λs is considered here for computing the
distance between two numerical data objects Oψ
i
and Oψ
j in
the |ψ|-dimensional Euclidean space ℜ|ψ|
+
using (5) [31].
Deﬁnition 1: Deﬁne λs : ℜ|ψ|
+ × ℜ|ψ|
+ →ℜ+ ∪{0} as
λ2
s

Oψ
i , Oψ
j

=
|ψ|

l=1

log


Oψ
i,l + Oψ
j,l

/2

−

log

Oψ
i,l

+ log

Oψ
j,l

/2

.
(5)
The fact that f is an injective function with the deﬁnition
f : ℜ|ψ|
+ →M|ψ| ensures that the S-distance is well-deﬁned.
In particular, Oψ
i
= f (Oψ
i ) = diag((Oψ
i,1, Oψ
i,2, . . . , Oψ
i,|ψ|)).
In this case, M|ψ| is a positive deﬁnite matrix with the
dimensions |ψ| × |ψ|. The notion of S-divergence [8], which
is described mathematically by (6), is used to derive the
S-distance
λ2
s

Oψ
i , Oψ
j

= log

Oψ
i + Oψ
j
2


−
log

Oψ
i


+ log

Oψ
j


2
(6)
where | · | is a determinant of a matrix and λ2
s(Oψ
i , Oψ
j ) =
λ2
s( f (Oψ
i ), f (Oψ
j )).
The S-distance satisﬁes all the metric properties. Moreover,
it also obeys the property of Hadamard product. It is also
neither Bregman divergence nor f-divergence. However, it is a
Burbea–Rao divergence. Thus, it is convex on ℜ|ψ|
+ . According
to a prior study [8], when two data objects are close to the
origin and have the same Euclidean distance, their S-distance
is bigger than when they are far from the origin. The
scope of this study does not include the various S-distance
characteristics. To learn more about these features, interested
readers are encouraged to explore [8], [31].
Now, the similarity between two data objects is computed
using a monotonically decreasing spatial generalization expo-
nential function [45]. Mathematically, the exponential function
is deﬁned by the following equation:
χψ

Oψ
i , Oψ
j

= exp
⎛
⎜⎝
−

λs

Oψ
i , Oψ
j
2
2
⎞
⎟⎠
(7)
where χψ ∈[0, 1]. A value of χψ close to 1 indicates that
two data objects Oψ
i
and Oψ
j are similar. On the other hand,
a value of χψ close to 0 indicates that two data objects Oψ
i
and Oψ
j are highly dissimilar.
B. Similarity Measure of Categorical Attributes
Now, it is time to calculate the similarity λφ between two
data objects, namely, Oφ
i and Oφ
j having categorical features
on H φ
l . Most of the existing approaches [39], [41], [43], [44]
transform categorical attributes into sets of binary attributes,
which squashes the native pattern of categorical features.
In other words, converted binary features are purposeless, and
their values are difﬁcult to understand. Thus, an entropy-based
distance is applied to categorical features, which keeps the
original pattern of categorical features without transforming
their representation in this study. First, the similarity between
the lth feature of Oφ
i and Oφ
j is computed by the following
equation:
λφ

Oφ
i,l, Oφ
j,l

=

1,
if Oφ
i,l = Oφ
j,l
0,
if Oφ
i,l ̸= Oφ
j,l.
(8)
Thus, the similarity between two data objects is estimated
by summing the signiﬁcance of each categorical attribute.
Mathematically, it is deﬁned by the following equation:
χφ

Oφ
i , Oφ
j

=
|φ|

l=1
ωlλφ

Oφ
i,l, Oφ
j,l

(9)
where ωl is known as the signiﬁcance of the lth feature. The
value of ωl varies from 0 and 1 and |φ|
l=1 ωl = 1. The
signiﬁcance of the lth attribute is computed with the help of
entropy in information theory by the following equation:
Gφ
l = −

hl,q∈dm

H φ
l
 p

hl,q

log

p

hl,q

(10)
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
where p(hl,q) represents the probability of hl,q feature and
is estimated as (n
i=1 λφ(Oφ
i,l, hl,q)/n). In other words, it is
a ratio of number of objects whose value is equal to
hl,q of categorical feature H φ
l
to the total number of objects
n in a given dataset. It is clear from (10) that if the number
of sl is very large, then the entropy of feature H φ
l will also be
large. However, this is not how things actually are. The entropy
of a categorical feature is reformulated by (11) to lessen the
impact of categorical characteristics having numerous unique
or distinct values, such as an ID number
G φ
l = −1
sl
sl

q=1
p

hl,q

log

p

hl,q

.
(11)
Thus, the weight assigned to each categorical feature H φ
l
is
computed by
ωl =
G φ
l
|φ|
l=1 G φ
l
.
(12)
The similarity measure of categorical attributes can be com-
puted by combining (9) and (12), which is shown in the
following equation:
χφ

Oφ
i , Oφ
j

=
|φ|

l=1
G φ
l
|φ|
l=1 G φ
l
λφ

Oφ
i,l, Oφ
j,l

.
(13)
C. Similarity Measure for MD
The similarity between two data points Oi and O j having
|ψ| number of numerical attributes and |φ| number of cate-
gorical features is computed by merging (7) and (13) with the
help of the more importance concept of information theory,
and the new equation is given by
χOi, O j
 =
|ψ|
|ψ| + |φ| exp
⎛
⎜⎝
−λs

Oψ
i , Oψ
j
2
2
⎞
⎟⎠
+
|φ|
|ψ| + |φ|
|φ|

l=1
G φ
l
|φ|
l=1 G φ
l
λφ

Oφ
i,l, Oφ
j,l

.
(14)
The value of the similarity measure lies between 0 and 1 due to
normalized coefﬁcients. Generally, a DPC algorithm requires
a distance function instead of a similarity measure. Hence,
a logarithmic function is applied to the negative exponent
of (14) as shown in (15). If two data objects are similar, then
the distance would be smaller
λm

Oi, O j

= log

χ

Oi, O j
−1
.
(15)
D. Local Density Metric
In this section, we present: 1) a new local density metric
based on SFCNN; 2) a new method to initialize the cluster
centers; and 3) a way to group density-reachable clusters.
For estimating the local density of a data object Xi in a
set of data, an SFCNN graph is built in this study instead
of a conventional c-NN graph since it is more resistant to
noise and outliers. Fig. 1 is used to explain the distinction
Fig. 1. (a) 3-NN graph’s differences from (b) symmetry-favored 3-NN graphs
(red edges show higher edge weights).
Fig. 2.
Decision graph of Statlog Heart dataset with αt = 0.54.
between a standard c-NN graph and one that favors symmetry.
The graph’s symmetric edges have heavier weights than its
asymmetric edges because the locations they connect are
located in the same submanifold [30], [46]. The underlying
manifold characteristics of the data space can also be used to
explain the SFCNN graph. It can describe implicit geometrical
structures. Moreover, it also increases the space in the density
between outliers and core objects, which helps in generating
efﬁcient and correct cluster representatives. Generally, density
metrics consider Gaussian kernels to estimate the local density
values. Data objects in DPC are represented as points in a
space, where cluster representatives are always on the top-right
part of the decision graph. Once the local density βi and
minimum distance γi from data points of higher density are
calculated for each data object, cluster representatives are
identiﬁed by searching the large parameters βi and γi for
anomalies. The parameter αt determines the average number
of neighbors of all data objects in a dataset. The value of
αt is computed by (16), which depends on the value of “c.”
Based on this idea, cluster centers for the Statlog Heart [47]
sample dataset is estimated, and they can be seen in the
top-right quadrant of the decision graph in Fig. 2. Here, circles
with red color are the initial cluster representatives that are
characterized relatively by the higher distance, γi, and larger
density, βi. They are computed based on the threshold value,
αt = 0.54 (dashed line). After the selection of the cluster
representatives, the remaining data objects are assigned to the
nearest cluster with a higher density. A decision graph assists
in taking a decision. The decision graph is a plot of γi as a
function of βi for each data object
αt = vc +
n
i=1
γ c
i −vc2
n −1
(16)
where γ c
i is the distance between SFCNN and a data object
i, deﬁned as γ c
i = max j∈SFCNNi (λi, j
m ), and vc is the average
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
value of γ c
i and is computed by (17). SFCNNi is a set of data
objects in an SFCNN to data object i
vc =
n
i=1 γ c
i
n
.
(17)
The second part in the right-hand side of (16) represents the
standard deviation of distance calculated between each data
object and its corresponding SFCNN. The local densities can
be estimated by the following equation:
βi =

j∈SFCNNi
exp
⎛
⎜⎝−

λi, j
m
2
(αt)2
⎞
⎟⎠.
(18)
Equation (18) illustrates the distribution information of the
SFCNN of a data object i and uses αt to estimate the local
density βi. Equation (18) considers the sum of all distances
using an exponential kernel. The previous studies [28] reveal
that the value of c in an SFCNN graph has a signiﬁcant impact
while estimating density, and it was ﬁxed to 5 because 2-NN,
3-NN, and 4-NN may be close to normal data objects. Thus,
an enhanced local density is proposed by combining a ﬁxed
SFCNN and a weighted sequence as shown in the following
equation:
βi =

j∈SFCNNi
exp
⎛
⎜⎝−

λi, j
m
2
(αt)2
⎞
⎟⎠
+

j /∈SFCNNi and j̸=i
exp

−

λi, j
m
2
max
j′∈SFCNNi

λ j′, j
m
 .
(19)
The ﬁrst part of (19) takes care of the symmetry-favored
5-NN estimation, which is inherited from (18). On the other
hand, the second part of (19) sums the weighted Gaussian
kernel sequence. This second part is a complement to the
ﬁrst part and compensates for the clustering performance
by overcoming the limitations of ﬁxed c-NN in density
estimation. The weights in the second part have a lesser value
in the case of data objects away from the c-NN and a higher
weightage near the c-NN.
In this work, the DPC algorithm is enhanced by considering
some of the concepts of DBSCAN and OPTICS, which are
given as follows.
Deﬁnition 2 (Core Distance γ e of a Cluster Ce): γ e of a
cluster Ce is computed by the following equation:
γ e =

Oi∈Ce λm(CPe, Oi)
|Ce|
(20)
where |Ce| represents the cardinality of a cluster set Ce and
CPe is the cluster center of Ce. γ e of a Ce is the average of
distances between all the data points belonging to Ce and CPe.
Deﬁnition 3 (Boundary-Data-Object-Pair Set ρx,y Between
Two Clusters, Namely, Cx and C y): ρx,y between Cx and C y
is expressed as follows:
ρx,y =

Oi, O j

|λm

Oi, O j

< min

γ x, γ y
,
Oi ∈Cx, O j ∈C y
(21)
where ρx,y is symmetric in nature.
Deﬁnition 4 (Border Density βe
ρ of Cluster Ce): βe
ρ of Ce
is computed by the following equation:
βe
ρ =
max
(Oi,O j)∈ρx

βi + β j

2
(22)
where ρx consists all boundary-data-objects-pairs between Cx
and other clusters such that ρx = ∪y̸=xρx,y.
Deﬁnition 5 (Density Directly Reachable): In terms of bor-
der density, a cluster Cx is density directly reachable from
another cluster C y if the following conditions hold.
1) ρx,y ̸= {Null}.
2) ∃(Oi, O j) ∈ρx,y, βi < βx
ρ and β j < β y
ρ
It also satisﬁes the symmetric property.
Deﬁnition 6 (Density Reachable): If there is a path con-
necting two clusters Cx and C y such that Cx = C1, C2,
. . . , Cn = C y, each Ci is directly reachable to Ci+1, then
the two clusters are said to be density reachable to one
another. Moreover, it obeys the symmetric as well as transitive
properties.
E. Improved DPC Algorithm and Its Complexity
In this section, the essential details of the MDPC-AD are
discussed with an analysis of its complexity. Algorithm 1 is a
logical step-by-step analysis of the MDPC-AD. The algorithm
of the MDPC-AD is presented to make it easy for the reader
to identify the process, major decision points, and variables
necessary to implement MDPC-AD.
Fig. 3 is employed to illustrate the detailed processes of the
MDPC-AD on a particular dataset named Wine [47] consisting
of numerical attributes only. The ﬁrst two principal compo-
nents of each data object of the Wine dataset are obtained
using PCA and are shown on a 2-D plane using pink color in
Fig. 3(a). Here, a dataset consisting of numerical features is
considered because PCA can only work on numerical attributes
to generate principal components. Three density peaks in
the top-right corner are automatically recognized as cluster
representatives in Fig. 3(b), which shows the decision graph
of γi as a function of βi for each data object and data objects in
red are initial cluster representatives above the threshold αt and
threshold αt is displayed as green dashed line. The remaining
data objects are then assigned to the closest clusters to obtain
the corresponding cluster, as shown in Fig. 3(c). Finally,
a grouping of the density reachable clusters is performed and
the ﬁnal obtained clusters are shown in Fig. 3(d).
The
following
factors
are
used
to
discuss
how
time-consuming
the
MDPC-AD
is.
First,
the
distance
between data objects is calculated with complexity O(n2E),
where E is the time required to compute λm() between two
data objects and n represents the number of data objects
in the dataset. Later, sorting of distance vector will require
O(n2 log(n)) complexity. An SFCNN graph will take O(cn)
times for calculation of βi, where c is smaller than n. The
calculation of distance γi for each data object requires O(n2)
steps. Furthermore, initial representatives for clusters are
selected and the assignment of data objects to clusters is
completed in O(n2) times. The calculation of core distance
γ e and border density βe
ρ will take only O(n). The estimation
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
Fig. 3.
Illustration of the MDPC AD that has been proposed. (a) Visualization of the wine dataset using the ﬁrst two principal components, showing the ﬁrst
and second corresponding vectors of the data matrix along the axes. (b) Decision graph for the wine dataset in (a). (c) Clustering result after nearest cluster
assignment. (d) Clustering result after grouping of density reachable clusters.
of boundary-data-object-pair sets will require approximately
O(n2) steps. In conclusion, the time complexity of the
MDPC-AD is O(n2 log(n)).
IV. EXPERIMENTAL RESULTS AND DISCUSSION
This work is done on a laptop running Windows 10 with an
Intel1 Core2 i7-2620M CPU clocked at 2.70 GHz and 8 GB
of RAM using the Spyder 3.2.8 Python development environ-
ment. This study does not include I/O costs.
A. Experimental Setup and Dataset Description
1) Dataset #1: Thirteen well-known real-world datasets
from the UCI repository are considered in this study. Table I
contains some statistical information, such as name, type, the
number of clusters (k), the total number of features (d), the
number of numerical features (Fψ), the number of categorical
features (Fφ), and the total number of samples (n) from
these datasets. Interested readers may discover more details
regarding these datasets in [47].
1Registered trademark.
2Trademarked.
TABLE I
STATISTICS OF UCI DATASETS USED IN THIS STUDY
2) Dataset #2: The proposed method’s efﬁciency is also
tested on machine fault diagnostics, with data containing three
categories of gearbox problems, such as missing teeth, tooth
wear, and root faults. As shown in Fig. 5, a test rig is
used to identify the faults in a gearbox that are shown in
Fig. 4 [22], [23]. The three defective gears, as well as one
healthy gear, are installed in the test setup. Then, using a
controller, it is powered at its rotational speed by a regulated
motor. A brake is used at the shaft’s end location to provide
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
Fig. 4.
Faults of the gears: (a) normal, (b) missing teeth, (c) wear in teeth, and (d) fault in root.
Algorithm 1 Proposed DPC Algorithm
Require: O = {O1, . . . , Oi, . . . , On}
▷where
Oi ∈ℜd=|ψ|+|φ|
Ensure: C = {C1, C2, . . . , Ck}
▷a set of resultant clusters
1: Calculate distance matrix and parameter αt using Eqs. 15
and16, respectively
2: Calculate βi and γi for all data objects Oi ∈O by Eqs. 16
to 19.
3: Choose all data objects whose γi is larger than the αt
cutoff distance in the decision graph and set k′ initial
representatives of clusters as C P = {C Pi|1 ≤i ≤k′}
and remaining data object will be O′ = O −C P.
4: for all Oi ∈O′ do
label =
min
CP j ∈C j &1≤j≤k′{λm(Oi, C P j)}; ▷nearest cluster
Clabel ←Clabel ∪Oi
5: end for
6: Compute the core distance γ e and boundary density βe
ρ of
each cluster e using Eqs. 20 to 22.
7: repeat
▷Group all density-reachable clusters
8:
for all Ci ∈C do
9:
for all C j ∈C −Ci do
10:
if Ci and C j satisfy Defs. 5 and 6 then
11:
Ci ←Ci ∪C j and update set C
12:
end if
13:
end for
14:
end for
15: until Grouping of density reachable clusters
16: Return C = {C1, . . . , Ck} as the set of the clusters.
a load to the system. As shown in Fig. 5, an experiment for
intelligent fault detection was carried out. The gearbox was not
loaded, and the motor’s speed was set to 1800 r/min. Three
acceleration sensors that were ﬁxed in the housing’s vertical,
horizontal, and axial directions and connected to its right end
were employed to collect vibration data at a sampling rate
of 12.8 kHz. However, categorical data, such as the number
of cylinders, the forwarding gear values, and the number
of carburetors, are discontinuous parameters. Four separate
conditions, namely, tooth wear, root defect, missing teeth, and
healthy, were used to collect vibration signals. As shown in
Fig. 6, the original vibration signal is split into 90 segments,
each of which contains 5023 samples.
The
MDPC-AD
method
is
presented
to
diagnose
machine
faults
via
vibration
signals,
and
categorical
features
are
obtained
to
determine
the
state
variation
due to faults [22], [23]. As discussed in Section II-A,
O = {O1, O2, . . . , Oi, . . . , On} is a dataset of n MD vectors.
Each data vector Oi ∈ℜd=|ψ|+|φ|, where 1 ≤i ≤n, has
a total of d features or attributes. However, each Oi has a
|ψ| and |φ| number of signal features ψ and categorical
φ attributes, respectively. One assumption is made in this
application that the number of data objects in each cluster
is equal. Let k be the number of clusters, and the data
objects from each cluster are n/k. The MDPC-AD method is
performed for the diagnosis of a faulty gearbox, as discussed
in Algorithm 1.
B. Evaluation Metrics
Accuracy is one of the most commonly reported evaluation
measures. It describes the percentage of accurate clustering
outcomes among all the outcomes a machine learning algo-
rithm produces. It is an intuitive and straightforward evaluation
metric. A machine learning algorithm is better and more
preferable if its percentage accuracy is near 100. On the other
hand, depending just on accuracy for unbalanced data can
be deceptive. In this situation, in addition to accuracy, other
assessment measures, including precision, recall, F-Score, and
JI, may be considered to determine how effective a model
is [25]. Moreover, two internal validation indices, for example,
the average clustering error and the ratio of separation to
compactness, are also adopted in this study.
C. Computational Protocol
This study compares the performance of the proposed
approach, MDPC-AD, with 13 SOTA methods.
1) K-PC: k-prototypes clustering algorithm for mixed
datasets [39].
2) EK-PC: An evolutionary k-prototypes clustering algo-
rithm for mixed-type datasets [41].
3) KL-FCM-GM:
An
FCM-type
clustering
algorithm
for mixed datasets with a probabilistic dissimilarity
function [42].
4) FK-PC: A fuzzy k-prototypes clustering algorithm for
MD [43].
5) IK-PC: An improved k-prototypes clustering algorithm
for mixed numerical and categorical data [44].
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
Fig. 5.
(a) Gear test rig and (b) accelerometers ﬁxed in the vertical, axial, and horizontal directions.
Fig. 6.
Vibration signal in four different conditions of the gear from the
experiment.
6) CAVE: A clustering algorithm based on variance and
entropy for mixed datasets [40].
7) SBAC:
A
similarity-based
agglomerative clustering
algorithm for data with mixed features [37].
8) SpectralCAT: Categorical spectral clustering for numer-
ical and nominal data [48].
9) DKFCM: A density-oriented kernel FCM algorithm for
fault diagnosis [10].
10) DPC-MD: A novel DPC method for MD using a
distance for MD [29].
11) PE-EEMD-GG:
A
method
based
on
permutation
entropy, ensemble empirical mode decomposition, and
the Gath–Geva clustering method for bearing fault diag-
nosis [24].
12) CG-SSC: A composite graph-based sparse subspace
clustering method for machine fault diagnosis [22].
13) MSC: A mean shift clustering-based approach with
a
spectral
preprocessing
technique
for
machinery
diagnostics [23].
Since the researchers have not given their works a name,
appropriate
nomenclatures
for
these
methodologies
are
employed. The scope of this study does not include a thor-
ough description of these techniques. However, we use the
precise procedures outlined in the original papers. As a result,
interested readers are directed to the source works for more
information.
D. Results and Comparison
In this study, a total of nine experiments are conducted to
validate the MDPC-AD. The ﬁrst eight experiments are carried
out on the UCI datasets using ﬁve external validation indices.
The last experiment is performed to identify the faults in the
gearbox of a rotary mechanical machine with the help of two
internal validation measures.
1) Experiment on Categorical Datasets: In the ﬁrst exper-
iment, the MDPC-AD is executed on datasets, namely, D1,
D2, and D3, having categorical attributes only. These datasets
do not possess numerical features. The second part of (14),
followed by (15), is considered while computing distance.
The clustering report obtained by the MDPC-AD is noted in
the last column of Table II. The clustering reports generated
by existing methods are also included in Table II. The best
clustering report produced by a method is marked by bold
characters. All the results of Table II demonstrate that the
MDPC-AD outperforms all the above-discussed 13 SOTA
methods. However, the performance of DPC-MD and MSC
on D3 is the same as that of the MDPC-AD.
2) Experiment on Numerical Datasets: In the second exper-
iment, the MDPC-AD is implemented on datasets, namely,
D4, D5, D6, and D7, having only numerical attributes. These
datasets do not have categorical features. Fig. 7 shows the
ﬁrst two principal components of D4, D5, D6, and D7 plotted
in 2D planes. It is clear from Table I and Fig. 7 that each
dataset consists of a varying number of data points. Moreover,
they have arbitrary shape clusters. Now, the ﬁrst part of (14),
followed by (15), is employed while computing distance.
The clustering reports of all the 14 methods, including the
MDPC-AD, are reported in Table III. The best performance
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
TABLE II
CLUSTERING REPORTS ON D1, D2, AND D3 USING FIVE VALIDATION INDICES
TABLE III
CLUSTERING REPORTS ON D4, D5, D6, AND D7 USING FIVE VALIDATION INDICES
TABLE IV
CLUSTERING REPORTS ON D8, D9, D10, D11, D12, AND D13 USING FIVE VALIDATION INDICES
achieved by a method is marked by a bold character. We can
conclude after observing all the results of Table III that the
MDPC-AD outperforms all 13 SOTA methods even when the
data points of D4, D5, D6, and D7 are varying and have
arbitrary shape clusters.
3) Experiment on Mixed Datasets: In the third experiment,
the MDPC-AD is executed on mixed datasets, namely, D8,
D9, D10, D11, D12, and D13. These datasets contain both
numerical as well as categorical variables. Here, (15) is used
to compute the distance between data objects. The clustering
reports produced are presented in Table IV. The best clustering
report generated by a method is marked by bold characters.
It is clear from Table IV that the MDPC-AD outperforms all
the above-discussed 13 SOTA methods.
In summary, we can say that the clustering reports in
terms of precision, recall, F-Score, JI, and accuracy obtained
by the proposed method named MDPC-AD are higher
than the other 13 SOTA existing approaches mentioned in
Section IV-C. The primary reason is that K-PC, EK-PC,
IK-PC, FK-PC, DKFCM, PE-EEMD, CG-SSC, MSC, and
DPC-MD are sensitive to the initialization of cluster rep-
resentatives and are improper for nonspherically distributed
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
Fig. 7.
First two principal components of the dataset on the left and its updated version with noise features as the number of genuine features on the
right were shown on a plane to display the ﬁrst and second matching vectors of the data matrix along the axes. Different colors indicate different data point
classiﬁcations. (a) D4. (b) D4 with noisy features. (c) D5. (d) D5 with noisy features. (e) D6. (f) D6 with noisy features. (g) D7. (h) D7 with noisy features.
data. Moreover, SBAC addresses similarity measures with the
assumption that the unusual matched feature values correspond
to higher weights. DKFCM adopts a fuzzy objective func-
tion that is designed based on several probabilistic theories
regarding the organization of the obtained clusters. CAVE
is sensitive to the procedure of sampling. The efﬁciency
of SpectralCAT depends on the selection of kernel func-
tion to compute the Markov matrix. On the other hand,
MDPC-AD overcomes some of the abovementioned issues.
Thus, MDPC-AD achieved good clustering results on the
above-discussed numerical, categorical, and mixed datasets.
4) Experiment on Noisy Datasets: The fourth experiment is
conducted on datasets, namely, D4, D5, D6, and D6, having
only numerical variables to know whether the MDPC-AD is
robust against the noisy features. After adding noisy features
produced by a uniform random distribution in the length and
size limit of the original dataset, the inﬂuence of noisy features
is examined. Therefore, a dataset’s number of features would
be twice as many as its initial number of attributes. The
ﬁrst two principal components of each of the aforementioned
datasets, as plotted on 2-D planes, are shown in Fig. 7 before
and after the addition of noisy features. Fig. 7 makes it obvious
that for a dataset; practically, all of the mapped locations have
signiﬁcant overlaps with one another. This simply means that
the existence of noisy features hurts these datasets. The results
obtained by all techniques after including noisy features are
shown in Fig. 8 against ﬁve assessment metrics, including
accuracy, precision, recall, F-Score, and Jaccard index on
D4–D7. The results show that the MDPC-AD performs better
than any other approach, from K-PC to SpectralCAT. For a
small number of datasets, clustering performance is dramati-
cally reduced. Nevertheless, the S-distance, which is utilized
to calculate the separations between numerical data items and
is invariant to the Hadamard product, makes the MDPC-AD
resilient [8].
5) Experiment for Knowing the Impact of “c” in Symmetric
Favored c-NN: In this work, local density is estimated based
on a sequence of the weighted exponential kernel using an
SFCNN. In the previous four experiments, the value of “c” is
considered 5, as suggested by the past studies [28]. However,
the ﬁfth experiment is conducted to verify the previous claim.
The value of “c” varies from 1 to 19 with a step size of 2.
The values of accuracy, precision, recall, F-Score, and Jaccard
index for each value of “c” over all 13 datasets are shown in
Fig. 9. The values of “c” are shown on the x-axis, and the
clustering results are shown on the y-axis. It is clear from
Fig. 9 that the values of clustering metrics are maximum
when the value of “c” varies from 1 to 5 on datasets, i.e.,
D3, D8, and D9. However, the performance increases slightly
on D6 when the value of “c” is beyond 5. On the other
hand, the performances remain consistent on D11 and D13.
The clustering performances deteriorate on D1, D2, D4, D5,
D7, D10, and D12 when the value of “c” is beyond 12.
It means that it is really difﬁcult to ﬁnd out the optimum
value of “c.” However, it relies on the characteristics of a
dataset.
6) Experiment on Order Sensitivity: In the ﬁnal experiment,
the order of the data objects in a dataset is changed while
still analyzing the clustering result. This sensitivity analysis
measures the stability of the algorithm due to randomness and
erroneous assessment. The MDPC-AD is executed ten times
on 13 datasets. However, the positions of data objects are
changed by shufﬂing them randomly, and the corresponding
clustering results are shown in Fig. 10. The x-axis and y-axis
of each plot in Fig. 10 denote, respectively, the number of
iterations and the value of the metric in question. It is clear
from Fig. 9 that the MDPC-AD is not sensitive to the position
of data objects or order since the performance is the same or
constant in all ten runs.
7) Experiment for Run-Time Comparison: All the methods
mentioned in Section IV-C are not only compared based on
their clustering reports but also compared based on their
execution time, which is measured and noted in Table V. It is
clear from Table V that most of the time MDPC-AD takes
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
Fig. 8.
Comparison of clustering results on numerical datasets with noisy features. (a) Precision. (b) Recall. (c) F-Score. (d) Jaccard index. (e) Accuracy.
TABLE V
METHODS RUN TIME (UNIT: s)
less time compared to K-PC, EK-PC, KL-FCM-GM, FK-PC,
IK-PC, CAVE, DKFCM, DPC-MD, SpectralCAT, PE-EEMD,
CG-SSC, MSC, and SBAC. However, in some cases, K-PC
has a lesser execution time compared to the MDPC-AD,
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
Fig. 9.
Evaluation of MDPC-AD for different values of “c” values on all the datasets. (a) Precision. (b) Recall. (c) F-Score. (d) Jaccard index. (e) Accuracy.
Fig. 10.
Evaluation of MDPC-AD for testing sensitivity on 13 datasets. (a) Precision. (b) Recall. (c) F-Score. (d) Jaccard index. (e) Accuracy.
whereas MDPC-AD has a lesser execution time than EK-PC,
KL-FCM-GM, IK-PC, CAVE, DKFCM, SpectralCAT, PE-
EEMD, CG-SSC, MSC, and SBAC. Overall, the proposed
MDPC-AD executes in lesser time and outperforms other
methods. Moreover, the best execution times are bold in
Table V.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
TABLE VI
ABLATION STUDY ON D8, D9, D10, D11, D12, AND D13
TABLE VII
GEARBOX FAULT DIAGNOSIS USING TWO
INTERNAL VALIDATION INDICES
8) Ablation Study: The steps of MDPC-AD are determined
after conducting an ablation study on mixed datasets only.
DPC presented by Rodriguez and Laio [26] is implemented
in the ﬁrst analysis. In the second analysis, the impact of the
proposed AD mentioned in (12) is evaluated by incorporating
it in DPC and renaming the modiﬁed algorithm as DPC-
AD. In the third analysis, a new method to estimate local
density is adopted, which relies on a sequence of the weighted
exponential kernel using an SFCNN to overcome the limitation
of ﬁxed c-NN and names the method DPC-AD-SFCNN. In the
fourth study, a method for automatic selection of the initial
cluster representatives is utilized from MDPC-AD and merged
with DPC-AD-SFCNN and marked as DPC-AD-SFCNN-
CR. The MDPC-CNN-MD considers the c-NN in place of
an SFCNN for estimating local density. It also adopts the
presented distance from [29]. The MDPC-CNN-AD is similar
to the MDPC-CNN-MD, except that instead of using the
presented distance in [29], it employs the proposed distance.
Finally, CNN in MDPC-CNN-MD is substituted with SFCNN,
which is now called MDPC-SFCNN-MD. Furthermore, the
results of these studies are noted in Table VI to validate the
superiority of the proposed method, MDPC-AD. All the results
demonstrate that the proposed method, MDPC-AD, is superior
to other combinations of the DPC algorithm.
9) Case Study for Gearbox Fault Diagnosis Using Clus-
tering: In this section, MDPC-AD is compared with DPC,
DPC-AD, DPC-AD-SFCNN, and DPC-AD-SFCNN-CR. This
experiment is performed to group the state of the gears of
a mechanical machine. For the same, features of the data
obtained in 1 s are considered as a sample, and 90 samples/data
objects are analyzed. A quantitative clustering analysis is
conducted using two internal validation indices. First, a ratio
of separation SP and compactness CM is computed, and their
ratio ID1 = SP/CM is used as the metric for comparison. For
this metric, a high value of SP is desired, and a low value
of CM is suitable for good clusters. Thus, a high value of
ID1 indicates effective clustering results. Second, a clustering
error, ID2, is adopted for comparison and a smaller value of
clustering error shows the most effective. A comparison of
ID1 index on the above discussed ﬁve methods is shown in
Table VII. In the case of MDPC-AD, SP has a high value, and
CM obtained the ideal value equal to zero; thus, the value of
ID1 is extremely large or tends to inﬁnity, which shows that
MDPC-AD outperforms other SOTA methods. It indicates that
MDPC-AD can yield well-separated and most compact clus-
ters. Second, a comparison is shown using ID2 where all the
methods are executed 50 times, and the average error is com-
puted and presented in Table VII. As mentioned in Table VII,
MDPC-AD achieved the lowest value equal to zero, meaning
that there was nil clustering error in the proposed method while
diagnosing the faults in a gearbox. Therefore, the proposed
study is an effective method for gearbox fault diagnosis.
V. CONCLUSION
This study introduces the DPC-based clustering technique
named MDPC-AD for gearbox fault diagnostics. An ablation
study is conducted to demonstrate the effectiveness of each
part of the MDPC-AD. The obtained results illustrate that the
novel AD can more clearly reveal the structure of the 13 real-
world datasets from UCI under examination. To calculate the
global parameter and the local density of each data object, the
MDPC-AD employs the idea of a series of weighted Gaussian
kernels based on an SFCNN. In addition, the MDPC-AD is
easier to control than DBSCAN and DPC since it can choose
the initial cluster representatives automatically by establishing
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
the cutoff distance as a function of parameter c. The ﬁrst
cluster representatives’ computation, however, ensures the
inclusion of genuine initial cluster representatives. The con-
cept of grouping density reachable clusters is employed to
solve this problem in subsequent iterations, even though our
method may initially choose incorrect cluster representatives.
According to experiments on different real-world datasets, the
MDPC-AD outperforms the 13 SOTA approaches mentioned
in this article. Even though an experiment is run to see how ‘c’
affects things, more research is still required. Finding the ideal
value for “c” and understanding the relationship between the
parameters αt and “c” call for more investigation. It would also
be intriguing to expand the capabilities of the current algorithm
to manage large datasets with mixed attributes. Although
MDPC-AD improves clustering efﬁciency, the decreased efﬁ-
ciency of MDPC-AD compared to DPC is due to the high
computational complexity of density estimation. Therefore,
it is essential to reduce the computational complexity of
density estimation, a subject that merits more study. Finally,
in mechanical systems, clustering algorithms have proven to
be more reliable, particularly for fault diagnosis. The names
of two faults that could affect gearboxes, bearings, and wind
turbines, are mentioned in this study. The last two, which merit
additional research, have not been covered in this article.
ACKNOWLEDGMENT
The authors would like to thank the support of Ph.D. student
Michal Dobrovolny for consultations.
REFERENCES
[1] J. Sun, C. Yan, and J. Wen, “Intelligent bearing fault diagnosis method
combining compressed data acquisition and deep learning,” IEEE Trans.
Instrum. Meas., vol. 67, no. 1, pp. 185–195, Jan. 2018.
[2] C. Sun, M. Ma, Z. B. Zhao, and X. Chen, “Sparse deep stacking network
for fault diagnosis of motor,” IEEE Trans. Ind. Informat., vol. 14, no. 7,
pp. 3261–3270, Mar. 2018.
[3] S. B. Wang, X. F. Chen, C. W. Tong, and Z. B. Zhao, “Matching syn-
chrosqueezing wavelet transform and application to aeroengine vibration
monitoring,” IEEE Trans. Instrum. Meas., vol. 66, no. 2, pp. 360–372,
Feb. 2017.
[4] Y. Chen and M. J. Zuo, “A sparse multivariate time series model-based
fault detection method for gearboxes under variable speed condition,”
Mech. Syst. Signal Process., vol. 167, Mar. 2022, Art. no. 108539.
[5] Y. Liu, B. Liu, X. Zhao, and M. Xie, “A mixture of variational
canonical correlation analysis for nonlinear and quality-relevant process
monitoring,” IEEE Trans. Ind. Electron., vol. 65, no. 8, pp. 6478–6486,
Aug. 2018.
[6] W. Teng, Y. Liu, Y. Huang, L. Song, Y. Liu, and Z. Ma, “Fault detection
of planetary subassemblies in a wind turbine gearbox using TQWT
based sparse representation,” J. Sound Vibrat., vol. 490, Jan. 2021,
Art. no. 115707.
[7] Y. Liao, L. Zhang, and W. Li, “Regrouping particle swarm optimization
based variable neural network for gearbox fault diagnosis,” J. Intell.
Fuzzy Syst., vol. 34, no. 6, pp. 3671–3680, 2018.
[8] S. Chakraborty and S. Das, “K—Means clustering with a new
divergence-based distance metric: Convergence and performance analy-
sis,” Pattern Recognit. Lett., vol. 100, pp. 67–73, Dec. 2017.
[9] Z. Shuqing, S. Guoxiu, L. Liang, L. Xinxin, and J. Xiong, “Study on
mechanical fault diagnosis method based on LMD approximate entropy
and fuzzy C-means clustering,” Chinese J. Sci. Instrum., vol. 34, no. 3,
pp. 714–720, 2013.
[10] A. R. Ramos et al., “A novel fault diagnosis scheme applying fuzzy clus-
tering algorithms,” Appl. Soft Comput., vol. 58, pp. 605–619, Sep. 2017.
[11] D. Gustafson and W. Kessel, “Fuzzy clustering with a fuzzy covariance
matrix,” in Proc. IEEE Conf. Decis. Control including 17th Symp. Adapt.
Processes, Jan. 1978, pp. 761–766.
[12] S. Wang, L. Li, S. Zhang, and G. Sun, “Mechanical fault diagnosis
method based on EEMD sample entropy and GK fuzzy clustering,”
China Mech. Eng., vol. 24, no. 22, p. 3036, 2013.
[13] X. Liu, M. Li, S. Qin, X. Ma, and W. Wang, “A predictive fault
diagnose method of wind turbine based on K-means clustering and
neural networks,” J. Internet Technol., vol. 17, no. 7, pp. 1521–1528,
2016.
[14] P. Baraldi, F. D. Maio, M. Rigamonti, E. Zio, and R. Seraoui, “Unsuper-
vised clustering of vibration signals for identifying anomalous conditions
in a nuclear turbine,” J. Intell. Fuzzy Syst., vol. 28, no. 4, pp. 1723–1731,
2015.
[15] S. Fu, K. Liu, Y. Xu, and Y. Liu, “Rolling bearing diagnosing method
based on time domain analysis and adaptive fuzzy C-means clustering,”
Shock Vibrat., vol. 2016, pp. 1–8, Jan. 2016.
[16] E. Li, L. Wang, B. Song, and S. Jian, “Improved fuzzy C-means
clustering for transformer fault diagnosis using dissolved gas analysis
data,” Energies, vol. 11, no. 9, p. 2344, Sep. 2018.
[17] Z. M. Nopiah, A. K. Junoh, and A. K. Arifﬁn, “Vehicle interior noise
and vibration level assessment through the data clustering and hybrid
classiﬁcation model,” Appl. Acoust., vol. 87, pp. 9–22, Jan. 2015.
[18] I. Gath and A. B. Geva, “Unsupervised optimal fuzzy clustering,” IEEE
Trans. Pattern Anal. Mach. Intell., vol. 11, no. 7, pp. 773–780, Jul. 1989.
[19] J. C. Bezdek and J. C. Dunn, “Optimal fuzzy partitions: A heuristic for
estimating the parameters in a mixture of normal distributions,” IEEE
Trans. Comput., vol. C-24, no. 8, pp. 835–838, Aug. 1975.
[20] Z. X. Wei, Y. X. Wang, S. L. He, and J. D. Bao, “A novel intelli-
gent method for bearing fault diagnosis based on afﬁnity propagation
clustering and adaptive feature selection,” Knowl.-Based Syst., vol. 116,
pp. 1–12, Jan. 2017.
[21] R. Langone, C. Alzate, B. D. Ketelaere, J. Vlasselaerc, W. Meertc, and
J. A. K. Suykensa, “LS-SVM based spectral clustering and regression
for predicting maintenance of industrial machines,” Eng. Appl. Artif.
Intell., vol. 37, pp. 268–278, Jan. 2015.
[22] C. Sun, X. Chen, R. Yan, and R. X. Gao, “Composite-graph-based sparse
subspace clustering for machine fault diagnosis,” IEEE Trans. Instrum.
Meas., vol. 69, no. 5, pp. 1850–1859, May 2020.
[23] S. Fong, J. Harmouche, S. Narasimhan, and J. Antoni, “Mean
shift clustering-based analysis of nonstationary vibration signals for
machinery diagnostics,” IEEE Trans. Instrum. Meas., vol. 69, no. 7,
pp. 4056–4066, Jul. 2020.
[24] J. Hou, Y. Wu, H. Gong, A. S. Ahmad, and L. Liu, “A novel intelligent
method for bearing fault diagnosis based on EEMD permutation entropy
and GG clustering,” Appl. Sci., vol. 10, no. 1, p. 386, Jan. 2020.
[25] A. Fahad et al., “A survey of clustering algorithms for big data:
Taxonomy and empirical analysis,” IEEE Trans. Emerg. Topics Comput.,
vol. 2, no. 3, pp. 267–279, Sep. 2014.
[26] A. Rodriguez and A. Laio, “Clustering by fast search and ﬁnd of density
peaks,” Science, vol. 344, no. 6191, pp. 1492–1496, Jun. 2014.
[27] Z. Liang and P. Chen, “Delta-density based clustering with a divide-
and-conquer strategy: 3DC clustering,” Pattern Recognit. Lett., vol. 73,
pp. 52–59, Apr. 2016.
[28] L. Yaohui, M. Zhengming, and Y. Fang, “Adaptive density peak
clustering based on K-nearest neighbors with aggregating strategy,”
Knowl.-Based Syst., vol. 133, pp. 208–220, Oct. 2017.
[29] M. Du, S. Ding, and Y. Xue, “A novel density peaks clustering algorithm
for mixed data,” Pattern Recognit. Lett., vol. 97, pp. 46–53, Oct. 2017.
[30] L. C. Jiao, F. Shang, F. Wang, and Y. Liu, “Fast semi-supervised clus-
tering with enhanced spectral embedding,” Pattern Recognit., vol. 45,
no. 12, pp. 4358–4369, 2012.
[31] A. Karlekar, A. Seal, O. Krejcar, and C. Gonzalo-Martín, “Fuzzy
K-means
using
non-linear
S-distance,”
IEEE
Access,
vol.
7,
pp. 55121–55131, 2019.
[32] F. Cao, J. Z. Huang, and J. Liang, “A fuzzy SV-K-modes algorithm
for clustering categorical data with set-valued attributes,” Appl. Math.
Comput., vol. 295, pp. 1–15, Feb. 2017.
[33] U. Maulik, S. Bandyopadhyay, and I. Saha, “Integrating clustering and
supervised learning for categorical data analysis,” IEEE Trans. Syst.,
Man, Cybern. A, Syst. Humans, vol. 40, no. 4, pp. 664–675, Jul. 2010.
[34] I. Saha and U. Maulik, “Incremental learning based multiobjective fuzzy
clustering for categorical data,” Inf. Sci., vol. 267, pp. 35–57, May 2014.
[35] I. T. R. Yanto, M. A. Ismail, and T. Herawan, “A modiﬁed fuzzy K-
partition based on indiscernibility relation for categorical data cluster-
ing,” Eng. Appl. Artif. Intell., vol. 53, pp. 41–52, Aug. 2016.
[36] M. Li, S. Deng, L. Wang, S. Feng, and J. Fan, “Hierarchical clustering
algorithm for categorical data using a probabilistic rough set model,”
Knowl.-Based Syst., vol. 65, pp. 60–71, Jul. 2014.
[37] C. Li and G. Biswas, “Unsupervised learning with mixed numeric
and nominal data,” IEEE Trans. Knowl. Data Eng., vol. 14, no. 4,
pp. 673–690, Jul./Aug. 2002.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
[38] C.-C. Hsu, “Generalizing self-organizing map for categorical data,”
IEEE Trans. Neural Netw., vol. 17, no. 2, pp. 294–304, Mar. 2006.
[39] Z. Huang, “Clustering large data sets with mixed numeric and categorical
values,” in Proc. 1st Paciﬁc–Asia Conf. Knowl. Discovery Data Mining,
1997, pp. 21–34.
[40] C.-C. Hsu and Y.-C. Chen, “Mining of mixed data with application to
catalog marketing,” Exp. Syst. Appl., vol. 32, no. 1, pp. 12–23, 2007.
[41] Z. Zheng, M. Gong, J. Ma, L. Jiao, and Q. Wu, “Unsupervised
evolutionary clustering algorithm for mixed type data,” in Proc. IEEE
Congr. Evol. Comput., Jul. 2010, pp. 1–8.
[42] S. P. Chatzis, “A fuzzy C-means-type algorithm for clustering of data
with mixed numeric and categorical attributes employing a probabilistic
dissimilarity functional,” Exp. Syst. Appl., vol. 38, no. 7, pp. 8684–8689,
2011.
[43] J. Ji, W. Pang, C. Zhou, X. Han, and Z. Wang, “A fuzzy K-prototype
clustering algorithm for mixed numeric and categorical data,” Knowl.-
Based Syst., vol. 30, pp. 129–135, Jun. 2012.
[44] J. Ji, T. Bai, C. Zhou, C. Ma, and Z. Wang, “An improved K-
prototypes clustering algorithm for mixed numeric and categorical data,”
Neurocomputing, vol. 120, pp. 590–596, Nov. 2013.
[45] S. Santini and R. Jain, “Similarity measures,” IEEE Trans. Pattern Anal.
Mach. Intell., vol. 21, no. 9, pp. 871–883, Sep. 1999.
[46] J. Jiang, Y. Chen, X. Meng, L. Wang, and K. Li, “A novel density
peaks clustering algorithm based on K nearest neighbors for improving
assignment process,” Phys. A, Stat. Mech. Appl., vol. 523, pp. 702–713,
Jun. 2019.
[47] D. Dheeru and E. K. Taniskidou. (2017). UCI Machine Learning
Repository. [Online]. Available: http://archive.ics.uci.edu/ml
[48] G. David and A. Averbuch, “SpectralCAT: Categorical spectral cluster-
ing of numerical and nominal data,” Pattern Recognit., vol. 45, no. 1,
pp. 416–433, 2012.
Krishna Kumar Sharma received the M.Tech.
(Information
Technology)
degree
from
IIIT
Allahabad, Allahabad, India, in 2011, and the
Ph.D. degree from the Department of Computer
Science and Engineering, PDPM Indian Institute of
Information Technology, Design and Manufacturing
Jabalpur, Jabalpur, India, in 2021.
He is currently an Assistant Professor with the
Department of Computer Science and Informatics,
University of Kota, Kota, India. His current research
interests include pattern recognition.
Ayan Seal (Senior Member, IEEE) received the
Ph.D. degree in engineering from Jadavpur Univer-
sity, Kolkata, India, in 2014.
He is currently an Assistant Professor with the
Department of Computer Science and Engineer-
ing, PDPM Indian Institute of Information Technol-
ogy, Design and Manufacturing Jabalpur, Jabalpur,
India. He has visited the Universidad Politécnica
de Madrid, Madrid, Spain, as a Visiting Research
Scholar. He has authored or coauthored several
journals, conferences, and book chapters in the area
of biometric and medical image processing. His current research interests
include image processing and pattern recognition.
Dr. Seal was a recipient of several awards. Recently, he received the Sir
Visvesvaraya Young Faculty Research Fellowship from Media Lab Asia,
Ministry of Electronics and Information Technology, Government of India.
Anis Yazidi (Senior Member, IEEE) received the
M.Sc. and Ph.D. degrees from the University of
Agder, Grimstad,
Norway, in 2008 and 2012,
respectively.
He was a Researcher with Teknova AS, Grimstad.
From 2014 to 2019, he was an Associate Pro-
fessor with the Department of Computer Science,
Oslo Metropolitan University, Oslo, Norway. He is
currently a Full Professor with the Department of
Computer Science, Oslo Metropolitan University,
where he is leading the research group in applied
artiﬁcial intelligence. He is also a Professor II with the Norwegian University
of Science and Technology (NTNU), Trondheim, Norway, and a Senior
Researcher with Oslo University Hospital, Oslo. His current research interests
include machine learning, learning automata, stochastic optimization, and
autonomous computing.
Ondrej Krejcar received the Ph.D. degree in tech-
nical cybernetics from the Technical University of
Ostrava, Ostrava, Czechia, in 2008.
He is currently a Full Professor in systems engi-
neering and informatics with the University of
Hradec Kralove (UHK), Hradec Kralove, Czechia,
and the Faculty of Informatics and Management,
Center for Basic and Applied Research, UHK; and
a Research Fellow with the Malaysia-Japan Interna-
tional Institute of Technology, University of Tech-
nology Malaysia, Kuala Lumpur, Malaysia. Since
June 2020, he has been a Vice-Rector for science and creative activities of the
UHK. He is also the Director of the Center for Basic and Applied Research,
UHK. From 2016 to 2020, he was the Vice-Dean for science and research
with the Faculty of Informatics and Management, UHK. His H-index is 21,
with more than 1800 citations received in the Web of Science, where more
than 120 IF journal articles are indexed in JCR index.
Dr. Krejcar has been a Management Committee Member substitute at Project
COST CA16226 since 2017. In 2018, he was the 14th top peer Reviewer in
Multidisciplinary in the World according to Publons and a Top Reviewer in
the Global Peer Review Awards 2019 by Publons. He is currently on the
Editorial Board of the MDPI Sensors IF journal (Q1/Q2 at JCR) and several
other ESCI-indexed journals. Since 2018, he has also been a Vice-Leader
and a Management Committee Member at WG4 at project COST CA17136.
Since 2019, he has been the Chairperson of the Program Committee of
the KAPPA Program, Technological Agency of the Czech Republic as a
regulator of the EEA/Norwegian Financial Mechanism in the Czech Republic
for the term 2019–2024. Since 2020, he has been the Chairperson of
Panel 1 (Computer, Physical and Chemical Sciences) of the ZETA Program,
Technological Agency of the Czech Republic. From 2014 to 2019, he has
been the Deputy Chairperson of Panel 7 (Processing Industry, Robotics, and
Electrical Engineering) of the Epsilon Program, Technological Agency of the
Czech Republic. He is also a guarantee of the doctoral study program in
applied informatics with UHK, where he is focusing on lecturing on smart
approaches to the development of information systems and applications in
ubiquitous computing environments.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
",10.1109/TIM.2022.3216366,doc22,"IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 3528716 A New Adaptive Mixture Distance-Based Improved Density Peaks Clustering for Gearbox Fault Diagnosis Krishna Kumar Sharma , Ayan Seal , Senior Member, IEEE, Anis Yazidi , Senior Member, IEEE, and Ondrej Krejcar Abstract—With the rapid development of sensors and mechan- ical systems, we produce an exponentially large amount of data daily. Usually, faults are prevalent in these sensory systems due to harsh operational conditions. Thus, detecting and diagnosing faults in the gearbox of mechanical systems are done by analyzing an exponentially large amount of data in the form of vibration signals and categorical features. However, the automatic fault detection method can match the increasing requirement for high-quality products in the course of intelligent manufacture. Thus, to acquire more distinguishable fault features under varied conditions, a new adaptive mixture distance-based simple and efﬁcient density peaks clustering algorithm is proposed for handling mixed data as real-world datasets encompassing both numerical and categorical attributes. Our approach revolves around the concept of a sequence of the weighted exponential ker- nel using a symmetry-favored c-nearest neighbor to estimate the global parameter and the local density of each data point. Then, the initial clusters are extracted from a decision graph using an adaptive threshold parameter. The ﬁnal step is to allocate the remaining data objects, if they are density reachable, to either of the initial groups. Thirteen UCI datasets and one real-world dataset from a mechanical system for gearbox defect diagnosis are employed to validate the proposed method. Five external and two internal evaluation criteria are considered to gauge how well the strategies are working. All of the ﬁndings indicate that the proposed method outperforms 13 other approaches. Manuscript received 10 July 2022; revised 16 September 2022; accepted 9 October 2022. Date of publication 21 October 2022; date of current version 9 November 2022. This work was supported in part by the SPEV project “Smart Solutions in Ubiquitous Computing Environments” (under ID: UHK-FIMSPEV-2022-2102), University of Hradec Kralove, Faculty of Informatics and Management, Czech Republic. The Associate Editor coordi- nating the review process was Dr. Xiaofeng Yuan. (Corresponding author: Ayan Seal.) Krishna Kumar Sharma is with the Department of Computer Science and Informatics, University of Kota, Kota, Rajasthan 324005, India (e-mail: krisshna.sharma@gmail.com). Ayan Seal is with the Department of Computer Science and Engi- neering, PDPM Indian Institute of Information Technology, Design and Manufacturing Jabalpur, Jabalpur, Madhya Pradesh 482005, India (e-mail: ayanseal30@ieee.org). Anis Yazidi is with the Department of Computer Science, Oslo Metropol- itan University (OsloMet), 0166 Oslo, Norway, also with the Department of Computer Science, Norwegian University of Science and Technology (NTNU), 7034 Trondheim, Norway, and also with the Department of Plastic and Reconstructive Surgery, Oslo University Hospital (OuS), 460167 Oslo, Norway (e-mail: anis.yazidi@oslomet.no). Ondrej Krejcar is with the Center for Basic and Applied Science, Faculty of Informatics and Management, University of Hradec Kralove, 500 03 Hradec Kralove, Czech Republic, and also with the Malaysia-Japan International Insti- tute of Technology (MJIIT), Universiti Teknologi Malaysia, Kuala Lumpur 54100 , Malaysia (e-mail: ondrej.krejcar@uhk.cz). Digital Object Identiﬁer 10.1109/TIM.2022.3216366 Index Terms—Density peaks clustering (DPC), mixed data (MD), S-distance, symmetric favored c-nearest neighbors (c-NN). I. INTRODUCTION A PPROPRIATE fault detection of the gearbox and bearing will be advantageous for the rotary machine, as they are indispensable components of it. Typically, rotary machines operate under harsh conditions, for example, uncertain or driving loads, up/variable speeds, and material fatigue, which generate possibilities for faults in the gearbox and bearings [1], [2], [22]. Thus, it creates improper situations for the machines and may cause downtime, economic loss, and maintenance costs to the organizations [3], [4], [5]. Therefore, effective sig- nal processing techniques can protect the gearbox and bearing from the unforeseen situations mentioned above. Generally, vibration signal analysis is an efﬁcient and viable approach for detecting faults, as they have a high correlation with the states of machine parts and organizations [6], [7]. There are various learning methods, such as supervised classiﬁcation and unsupervised clustering, for fault identiﬁcation. In addition, the most fundamental exploratory, meta-learning data analysis method, is clustering, which splits a set of data objects, denoted as a feature or observation vector, into nonempty, mutually exclusive subsets, groups, or clusters, such that elements of the same group are similar to one another based on some similarity metrics, whereas members of different subsets are dissimilar [8]. Therefore, much consideration must be paid to ﬁnding the obscure but imperative information in the data, for example, insights, patterns, and rules. These primitive data have no class information that represents the type of unsupervised learning. Some frequently employed clustering techniques in machine fault detection are k-means, hierarchical, afﬁnity propagation, fuzzy c-means (FCM), and kernel spectral. Shuqing et al. [9] and Ramos et al. [10] used FCM for fault detection. How- ever, it adopts the spherical distance data together with the speciﬁcation and is only effective for homogeneous data dis- tribution. An improved method built on FCM was Gustafson– Kessel. After combining the adaptive distance rule and the covariance matrix, it can handle data with subspace dispersion in any direction [11]. Gustafson–Kessel was applied in the fault detection of the roller bearing by Wang et al. [12]. 1557-9662 © 2022 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 Liu et al. [13] presented a k-means clustering-based fault identiﬁcation technique for wind turbines. A fuzzy rule- based clustering approach was employed for the detection of anomalies in wind turbines [14]. It was also adopted for bearing fault detection [15]. An improved FCM clustering approach was applied for dissolved gas analysis-data-based transformer fault detection [16]. A hierarchical-based cluster- ing method was adopted for the evaluation of the vibration level and interior noise of vehicles [17]. Only a spherical pattern dataset is suitable for fuzzy and Gustafson–Kessel algorithms, but data obtained from practical systems have a variety of structures and shapes. Consequently, a Gath–Geva was developed to enhance the results. It follows the fuzzy maximum likelihood estimator. It is appropriate for data from variant orientations [18], [19]. In [20], afﬁnity propagation clustering was implemented with adaptive feature selection on vibration signals for the detection of bearing faults. Langone et al. [21] introduced a spectral clustering-based method to identify the normal and erroneous states of a machine. A sparse subspace clustering technique using a com- posite graph with a new distance was presented to diagnose faults in machines [22]. Fong et al. [23] designed a mean shift-based clustering approach for machinery diagnostics on vibration signals. Hou et al. [24] presented the fuzzy Gath–Geva clustering technique, linear discriminant analysis, and ensemble empirical mode decomposition to diagnose rolling bearing faults. Although the majority of the studies mentioned above on intelligent defect identiﬁcation have shown useful ﬁndings, they still have some obvious ﬂaws, which are given as follows. 1) Most clustering algorithms for fault diagnosis rely on the hypothesis that data comprise only numerical values. 2) Most previous works exploit the FCM to diagnose machine faults. It means that, in the case of high- dimensional data, the selection of the fuzziﬁer will be crucial, and it may be trapped in local minima. Generally, FCM-based fault diagnosis algorithms pre- fer overlapping and spherical-shaped vibration signal datasets. 3) Existing clustering-based fault diagnosis methods are not sufﬁciently general and rely on the input parameters and the number of clusters for fault types. Thus, there are situations where they fail due to quite complicated actual working conditions of the systems. In this study, we explore the possibilities of using density-based clustering approaches, such as DENCLUE, OPTICS, and DBSCAN, for fault diagnosis to handle the limitations stated above because they are suitable for arbitrary- shaped clusters. Moreover, these algorithms can ﬁlter out noise from data [25]. However, they are parameter-dependent. In particular, DBSCAN relies on two parameters, i.e., the minimum number of data objects in a neighborhood (MinPts) and the radius of the neighborhood for a data object. The values of MinPts and the radius of the neighborhood are determined by users manually, which is intrinsically hard to ﬁx [25]. Rodriguez and Laio [26] presented a density peaks clustering (DPC) algorithm to detect arbitrary-shaped clusters. Since then, DPC has received increased research attention over the past few years. Generally, the DPC algo- rithm assumes that the cluster’s center is farther from other cluster centers and is in a zone with a higher local density than its neighbors. For each data object or point, the DPC algorithm computes the local density and the distance from locations of higher density. Cluster centers are positioned in the top-right corner of a decision graph that has been created. Finally, all the data objects are assigned to one of the cluster centers. However, reliable density estimation is a complex problem. In their seminal paper, Rodriguez and Laio [26] suggested estimating density irrespective of the dataset size. However, small datasets are affected by the cutoff distance while estimating local density [26]. The DPC algorithm’s signiﬁcant beneﬁt is its capacity to locate nonspherical clusters without prior knowledge of the number of classes. The DPC does not involve an iterative process. However, DPC might not automatically determine the correct number of clusters. A density reachable concept and a divide-and-conquer- based 3DC clustering algorithm were given in [27] and [28], respectively, to address the aforementioned problem. Yaohui et al. [28] and Du et al. [29] investigated the concept of c-nearest neighbors (c-NN) in DPC for estimating local density. However, asymmetric edges are given the same weight as symmetric ones in c-NN-based DPC. Moreover, evidence from the literature has shown that data objects with asymmetric edges may end up in different clusters [30]. Furthermore, cluster representatives are selected based on the decision graph using a parameter cutoff distance. Thus, inappropriate selection of parameters may lead to an inaccurate decision graph and, consequently, incorrect cluster representatives. Furthermore, most of the clustering algorithms work under the assumption of numerical or cat- egorical attributes [25], [31], [32], [33], [34], [35], [36]. In reality, all datasets have categorical and numerical attributes, which is known as a mixed-attribute dataset. As we will explain later, clustering unlabeled-mixed datasets is thus a tedious task. To deal with the latter issue, some clustering algorithms transform the categorical attributes into numeric attributes by performing binary encoding. Then, the similarity between the transformed data objects is then determined using the Euclidean distance. However, the obtained dis- tances cannot capture the original structures of categorical attributes. Moreover, when it comes to categories with two possible values, an associated binary representation of them is meaning- less and hard to interpret [37]. Hsu [38] presented a weighted distance tree structure with a distance hierarchy. However, domain knowledge is required for both the creation of distance hierarchies and the assignment of weights. The interested readers are referred to [26], [29], [37], [39], [40], [41], [42], [43], [44] for more information related to several similarity measures for mixed data (MD) clustering. However, there is a trend to introduce nonlinearity into similarity measures for clustering [31]. Thus, clustering a dataset involving mixed attributes is still a challenging task. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 This article suggests a novel adaptive mixture distance (AD)-based DPC technique to diagnose mechanical system gearbox failures. The following are some imperative contribu- tions made by the proposed approach. 1) The inherent pattern of categorical characteristics is squashed by most existing techniques, which convert categorical attributes into sets of binary features. In other words, transformed binary features have no use. More- over, their values are difﬁcult to comprehend [37]. Thus, an entropy-based distance is presented to categorical features of the 13 UCI datasets and one real-world dataset, which keeps the original pattern of categorical attributes without transforming their representation. The real-world dataset consists of nonstationary vibration signals from a mechanical system for gearbox fault diagnosis. 2) A novel AD metric is introduced in this study that utilizes a weight parameter to merge the two similarity metrics, S-distance and similarity index. The former is deﬁned in the open cone of positive deﬁnite matrices and is based on the concept of S-divergence [8], [31]. It is considered to calculate the separation between two numerical properties of the datasets examined. The latter is employed to determine how far apart categorized fea- tures are from one another. If there are more categorical features than numerical attributes, the similarity index is given a higher weight and vice versa. 3) A relatively new local density metric is specially adopted to deal with the noise that may be produced in real time while recording nonstationary vibration signals from a mechanical system. The local density metric relies on a sequence of the weighted exponential kernel using a symmetry-favored c-NN (SFCNN). It is capable of overcoming the limitations of ﬁxed c-NN. Moreover, it characterizes the implicit geometrical structures. Fur- thermore, it increases the space in the density between outliers and core objects, which helps in generating efﬁcient and correct cluster representatives. 4) A new method for the selection of initial cluster centers is presented, which assures correct cluster centers even in the case of an unbalanced dataset and nonuniform distribution of classes. The modiﬁed DPC based on AD (MDPC-AD) is implemented on a total of 13 UCI datasets and a real-world dataset for gearbox fault diagnosis of a mechanical machine. Five clustering validation indices, namely, accuracy (A), precision (P), recall (R), F-Score (F), and the Jaccard index (JI), are used to show the superiority of the MDPC-AD. However, abbreviated forms of the validation indices mentioned above will be used only in ﬁgures for better accommodation and presentation. Moreover, two internal validation indices, for example, average clustering error and ratio of separation and compactness, are also adopted in this study. According to the results, the MDPC-AD outranks 13 state-of-the-art (SOTA) approaches. The remaining work consists of the following. Section II discusses pertinent related studies. In Section III, the proposed distance metric deﬁnition is discussed, followed by MDPC- AD. In Section IV, all experimental ﬁndings are presented. The work is ﬁnally concluded in Section V. II. THEORETICAL FOUNDATION OF DPC A. Notations Let O = {O1, O2, . . . , Oi, . . . , On} be a dataset of n MD objects. Each data object Oi ∈ℜd=|ψ|+|φ|, where 1 ≤ i ≤n, has d number of features or attributes in total. However, each Oi has |ψ| and |φ| number of numerical ψ and categorical φ attributes, respectively. Thus, Oψ i,l is the lth numerical feature of Oψ i . Similarly, Oφ i,l is the lth categorical attribute of Oφ i . The domain of lth categorical feature dm(H φ l ) = {hl,1, hl,2, . . . , hl,sl } has sl discrete values, whereas domain of the lth numerical attribute dm(H ψ l ) is continuous. Therefore, each Oi is a combination of categorical and numerical values and it is denoted by [Oψ i , Oφ i ] = [Oψ i,1, Oψ i,2, . . . , Oψ i,|ψ|, Oφ i,|ψ|+1, . . . , Oφ i,d={|ψ|+|φ|}]. B. Density Peaks Clustering Fundamentally, DPC identiﬁes cluster representatives with a higher density in comparison to their neighbors, and cluster representatives are located at a relatively large distance from each other. The two main parameters of this method are the local density βi of each data object Oi and the distance γi from objects with greater densities. Furthermore, two hypotheses correspond to the cluster representatives: 1) cluster representatives are located in higher density areas and their neighbors have lower densities and 2) cluster representatives are in relatively distant positions from each other or at a relatively higher distance to the data objects of higher density. The detailed discussion of the computation of βi and γi is given as follows. Generally, the DPC algorithm works on numerical values and adopts the linear Euclidean distance function as a similar- ity measure for numerical attributes in the clustering analysis. The Euclidean distance λe between two data objects Oi and O j is deﬁned by (1) with the assumption that data consist only of numerical attributes λ2 e  Oi, O j  = l=d  l=1  Oi,l −O j,l 2. (1) The local density of a data object, Oi, is represented by βi and is deﬁned by the following equation: βi =  j exp  −λ2 e  Oi, O j  αt  (2) where αt denotes an adjustable variable, which controls the weight decrease rate. αt is the single variable in (2), and it relies on choosing the average number of neighbors of all data objects in the dataset. Rodriguez and Laio [26] deﬁned αt as given in the following equation: αt = α⌈τ⌉ (3) where α⌈τ⌉∈{α1, α2, . . . , α( n 2)} and this set contains distances between every pair of two data objects in the dataset, arranged Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 ascendingly. Another parameter γi is also computed using (4), which shows the minimum distance between the data object Oi and other data objects with larger density γi = ⎧ ⎨ ⎩ min j λe Oi, O j , if ∃s.t. βi < β j max j  λe  Oi, O j  , else. (4) When βi and γi for each data object have been computed, large values of βi and γi are explored anomalously in this method to identify the cluster representatives. Based on this concept, cluster representatives are always located on the decision graph’s top right side. Once cluster representatives are identiﬁed, the remaining data objects are assigned to the nearest cluster with a higher density. III. PROPOSED METHOD It is clear from the previous discussion that there are still some limitations to DPC and its peer methods. Hence, the DPC algorithm is improved in this study by introducing a novel adaptive mixture similarity measure. A new method for estimating the density of data points is introduced. Moreover, we present a novel way to construct a decision graph. In this section, we provide the details of the proposed clustering algorithm, MDPC-AD, and its theoretical complexity analysis. A. Similarity Measure of Numerical Attributes For revealing the natural cluster structure in a given dataset, which is a topic of active research, selecting an appropriate similarity/dissimilarity metric is essential. Since its inception, the proper selection of a similarity/difference metric has been a challenge. Recently, there has been an upsurge of interest in divergence-based nonlinear similarity measure [8], [31] for clustering analysis as this type of distance is susceptible to ﬁnding more appropriate complex cluster boundaries. Thus, nonlinear S-distance λs is considered here for computing the distance between two numerical data objects Oψ i and Oψ j in the |ψ|-dimensional Euclidean space ℜ|ψ| + using (5) [31]. Deﬁnition 1: Deﬁne λs : ℜ|ψ| + × ℜ|ψ| + →ℜ+ ∪{0} as λ2 s Oψ i , Oψ j = |ψ|  l=1 log Oψ i,l + Oψ j,l /2 − log Oψ i,l + log Oψ j,l /2 . (5) The fact that f is an injective function with the deﬁnition f : ℜ|ψ| + →M|ψ| ensures that the S-distance is well-deﬁned. In particular, Oψ i = f (Oψ i ) = diag((Oψ i,1, Oψ i,2, . . . , Oψ i,|ψ|)). In this case, M|ψ| is a positive deﬁnite matrix with the dimensions |ψ| × |ψ|. The notion of S-divergence [8], which is described mathematically by (6), is used to derive the S-distance λ2 s Oψ i , Oψ j = log  Oψ i + Oψ j 2   − log Oψ i  + log Oψ j  2 (6) where | · | is a determinant of a matrix and λ2 s(Oψ i , Oψ j ) = λ2 s( f (Oψ i ), f (Oψ j )). The S-distance satisﬁes all the metric properties. Moreover, it also obeys the property of Hadamard product. It is also neither Bregman divergence nor f-divergence. However, it is a Burbea–Rao divergence. Thus, it is convex on ℜ|ψ| + . According to a prior study [8], when two data objects are close to the origin and have the same Euclidean distance, their S-distance is bigger than when they are far from the origin. The scope of this study does not include the various S-distance characteristics. To learn more about these features, interested readers are encouraged to explore [8], [31]. Now, the similarity between two data objects is computed using a monotonically decreasing spatial generalization expo- nential function [45]. Mathematically, the exponential function is deﬁned by the following equation: χψ Oψ i , Oψ j = exp ⎛ ⎜⎝ − λs Oψ i , Oψ j 2 2 ⎞ ⎟⎠ (7) where χψ ∈[0, 1]. A value of χψ close to 1 indicates that two data objects Oψ i and Oψ j are similar. On the other hand, a value of χψ close to 0 indicates that two data objects Oψ i and Oψ j are highly dissimilar. B. Similarity Measure of Categorical Attributes Now, it is time to calculate the similarity λφ between two data objects, namely, Oφ i and Oφ j having categorical features on H φ l . Most of the existing approaches [39], [41], [43], [44] transform categorical attributes into sets of binary attributes, which squashes the native pattern of categorical features. In other words, converted binary features are purposeless, and their values are difﬁcult to understand. Thus, an entropy-based distance is applied to categorical features, which keeps the original pattern of categorical features without transforming their representation in this study. First, the similarity between the lth feature of Oφ i and Oφ j is computed by the following equation: λφ Oφ i,l, Oφ j,l =  1, if Oφ i,l = Oφ j,l 0, if Oφ i,l ̸= Oφ j,l. (8) Thus, the similarity between two data objects is estimated by summing the signiﬁcance of each categorical attribute. Mathematically, it is deﬁned by the following equation: χφ Oφ i , Oφ j = |φ|  l=1 ωlλφ Oφ i,l, Oφ j,l (9) where ωl is known as the signiﬁcance of the lth feature. The value of ωl varies from 0 and 1 and |φ| l=1 ωl = 1. The signiﬁcance of the lth attribute is computed with the help of entropy in information theory by the following equation: Gφ l = −  hl,q∈dm H φ l p  hl,q  log  p  hl,q  (10) Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 where p(hl,q) represents the probability of hl,q feature and is estimated as (n i=1 λφ(Oφ i,l, hl,q)/n). In other words, it is a ratio of number of objects whose value is equal to hl,q of categorical feature H φ l to the total number of objects n in a given dataset. It is clear from (10) that if the number of sl is very large, then the entropy of feature H φ l will also be large. However, this is not how things actually are. The entropy of a categorical feature is reformulated by (11) to lessen the impact of categorical characteristics having numerous unique or distinct values, such as an ID number G φ l = −1 sl sl  q=1 p  hl,q  log  p  hl,q  . (11) Thus, the weight assigned to each categorical feature H φ l is computed by ωl = G φ l |φ| l=1 G φ l . (12) The similarity measure of categorical attributes can be com- puted by combining (9) and (12), which is shown in the following equation: χφ Oφ i , Oφ j = |φ|  l=1 G φ l |φ| l=1 G φ l λφ Oφ i,l, Oφ j,l . (13) C. Similarity Measure for MD The similarity between two data points Oi and O j having |ψ| number of numerical attributes and |φ| number of cate- gorical features is computed by merging (7) and (13) with the help of the more importance concept of information theory, and the new equation is given by χOi, O j  = |ψ| |ψ| + |φ| exp ⎛ ⎜⎝ −λs Oψ i , Oψ j 2 2 ⎞ ⎟⎠ + |φ| |ψ| + |φ| |φ|  l=1 G φ l |φ| l=1 G φ l λφ Oφ i,l, Oφ j,l . (14) The value of the similarity measure lies between 0 and 1 due to normalized coefﬁcients. Generally, a DPC algorithm requires a distance function instead of a similarity measure. Hence, a logarithmic function is applied to the negative exponent of (14) as shown in (15). If two data objects are similar, then the distance would be smaller λm  Oi, O j  = log χ  Oi, O j −1 . (15) D. Local Density Metric In this section, we present: 1) a new local density metric based on SFCNN; 2) a new method to initialize the cluster centers; and 3) a way to group density-reachable clusters. For estimating the local density of a data object Xi in a set of data, an SFCNN graph is built in this study instead of a conventional c-NN graph since it is more resistant to noise and outliers. Fig. 1 is used to explain the distinction Fig. 1. (a) 3-NN graph’s differences from (b) symmetry-favored 3-NN graphs (red edges show higher edge weights). Fig. 2. Decision graph of Statlog Heart dataset with αt = 0.54. between a standard c-NN graph and one that favors symmetry. The graph’s symmetric edges have heavier weights than its asymmetric edges because the locations they connect are located in the same submanifold [30], [46]. The underlying manifold characteristics of the data space can also be used to explain the SFCNN graph. It can describe implicit geometrical structures. Moreover, it also increases the space in the density between outliers and core objects, which helps in generating efﬁcient and correct cluster representatives. Generally, density metrics consider Gaussian kernels to estimate the local density values. Data objects in DPC are represented as points in a space, where cluster representatives are always on the top-right part of the decision graph. Once the local density βi and minimum distance γi from data points of higher density are calculated for each data object, cluster representatives are identiﬁed by searching the large parameters βi and γi for anomalies. The parameter αt determines the average number of neighbors of all data objects in a dataset. The value of αt is computed by (16), which depends on the value of “c.” Based on this idea, cluster centers for the Statlog Heart [47] sample dataset is estimated, and they can be seen in the top-right quadrant of the decision graph in Fig. 2. Here, circles with red color are the initial cluster representatives that are characterized relatively by the higher distance, γi, and larger density, βi. They are computed based on the threshold value, αt = 0.54 (dashed line). After the selection of the cluster representatives, the remaining data objects are assigned to the nearest cluster with a higher density. A decision graph assists in taking a decision. The decision graph is a plot of γi as a function of βi for each data object αt = vc + n i=1 γ c i −vc2 n −1 (16) where γ c i is the distance between SFCNN and a data object i, deﬁned as γ c i = max j∈SFCNNi (λi, j m ), and vc is the average Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 value of γ c i and is computed by (17). SFCNNi is a set of data objects in an SFCNN to data object i vc = n i=1 γ c i n . (17) The second part in the right-hand side of (16) represents the standard deviation of distance calculated between each data object and its corresponding SFCNN. The local densities can be estimated by the following equation: βi =  j∈SFCNNi exp ⎛ ⎜⎝− λi, j m 2 (αt)2 ⎞ ⎟⎠. (18) Equation (18) illustrates the distribution information of the SFCNN of a data object i and uses αt to estimate the local density βi. Equation (18) considers the sum of all distances using an exponential kernel. The previous studies [28] reveal that the value of c in an SFCNN graph has a signiﬁcant impact while estimating density, and it was ﬁxed to 5 because 2-NN, 3-NN, and 4-NN may be close to normal data objects. Thus, an enhanced local density is proposed by combining a ﬁxed SFCNN and a weighted sequence as shown in the following equation: βi =  j∈SFCNNi exp ⎛ ⎜⎝− λi, j m 2 (αt)2 ⎞ ⎟⎠ +  j /∈SFCNNi and j̸=i exp  − λi, j m 2 max j′∈SFCNNi λ j′, j m . (19) The ﬁrst part of (19) takes care of the symmetry-favored 5-NN estimation, which is inherited from (18). On the other hand, the second part of (19) sums the weighted Gaussian kernel sequence. This second part is a complement to the ﬁrst part and compensates for the clustering performance by overcoming the limitations of ﬁxed c-NN in density estimation. The weights in the second part have a lesser value in the case of data objects away from the c-NN and a higher weightage near the c-NN. In this work, the DPC algorithm is enhanced by considering some of the concepts of DBSCAN and OPTICS, which are given as follows. Deﬁnition 2 (Core Distance γ e of a Cluster Ce): γ e of a cluster Ce is computed by the following equation: γ e =  Oi∈Ce λm(CPe, Oi) |Ce| (20) where |Ce| represents the cardinality of a cluster set Ce and CPe is the cluster center of Ce. γ e of a Ce is the average of distances between all the data points belonging to Ce and CPe. Deﬁnition 3 (Boundary-Data-Object-Pair Set ρx,y Between Two Clusters, Namely, Cx and C y): ρx,y between Cx and C y is expressed as follows: ρx,y =  Oi, O j  |λm  Oi, O j  < min  γ x, γ y , Oi ∈Cx, O j ∈C y (21) where ρx,y is symmetric in nature. Deﬁnition 4 (Border Density βe ρ of Cluster Ce): βe ρ of Ce is computed by the following equation: βe ρ = max (Oi,O j)∈ρx  βi + β j  2 (22) where ρx consists all boundary-data-objects-pairs between Cx and other clusters such that ρx = ∪y̸=xρx,y. Deﬁnition 5 (Density Directly Reachable): In terms of bor- der density, a cluster Cx is density directly reachable from another cluster C y if the following conditions hold. 1) ρx,y ̸= {Null}. 2) ∃(Oi, O j) ∈ρx,y, βi < βx ρ and β j < β y ρ It also satisﬁes the symmetric property. Deﬁnition 6 (Density Reachable): If there is a path con- necting two clusters Cx and C y such that Cx = C1, C2, . . . , Cn = C y, each Ci is directly reachable to Ci+1, then the two clusters are said to be density reachable to one another. Moreover, it obeys the symmetric as well as transitive properties. E. Improved DPC Algorithm and Its Complexity In this section, the essential details of the MDPC-AD are discussed with an analysis of its complexity. Algorithm 1 is a logical step-by-step analysis of the MDPC-AD. The algorithm of the MDPC-AD is presented to make it easy for the reader to identify the process, major decision points, and variables necessary to implement MDPC-AD. Fig. 3 is employed to illustrate the detailed processes of the MDPC-AD on a particular dataset named Wine [47] consisting of numerical attributes only. The ﬁrst two principal compo- nents of each data object of the Wine dataset are obtained using PCA and are shown on a 2-D plane using pink color in Fig. 3(a). Here, a dataset consisting of numerical features is considered because PCA can only work on numerical attributes to generate principal components. Three density peaks in the top-right corner are automatically recognized as cluster representatives in Fig. 3(b), which shows the decision graph of γi as a function of βi for each data object and data objects in red are initial cluster representatives above the threshold αt and threshold αt is displayed as green dashed line. The remaining data objects are then assigned to the closest clusters to obtain the corresponding cluster, as shown in Fig. 3(c). Finally, a grouping of the density reachable clusters is performed and the ﬁnal obtained clusters are shown in Fig. 3(d). The following factors are used to discuss how time-consuming the MDPC-AD is. First, the distance between data objects is calculated with complexity O(n2E), where E is the time required to compute λm() between two data objects and n represents the number of data objects in the dataset. Later, sorting of distance vector will require O(n2 log(n)) complexity. An SFCNN graph will take O(cn) times for calculation of βi, where c is smaller than n. The calculation of distance γi for each data object requires O(n2) steps. Furthermore, initial representatives for clusters are selected and the assignment of data objects to clusters is completed in O(n2) times. The calculation of core distance γ e and border density βe ρ will take only O(n). The estimation Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 Fig. 3. Illustration of the MDPC AD that has been proposed. (a) Visualization of the wine dataset using the ﬁrst two principal components, showing the ﬁrst and second corresponding vectors of the data matrix along the axes. (b) Decision graph for the wine dataset in (a). (c) Clustering result after nearest cluster assignment. (d) Clustering result after grouping of density reachable clusters. of boundary-data-object-pair sets will require approximately O(n2) steps. In conclusion, the time complexity of the MDPC-AD is O(n2 log(n)). IV. EXPERIMENTAL RESULTS AND DISCUSSION This work is done on a laptop running Windows 10 with an Intel1 Core2 i7-2620M CPU clocked at 2.70 GHz and 8 GB of RAM using the Spyder 3.2.8 Python development environ- ment. This study does not include I/O costs. A. Experimental Setup and Dataset Description 1) Dataset #1: Thirteen well-known real-world datasets from the UCI repository are considered in this study. Table I contains some statistical information, such as name, type, the number of clusters (k), the total number of features (d), the number of numerical features (Fψ), the number of categorical features (Fφ), and the total number of samples (n) from these datasets. Interested readers may discover more details regarding these datasets in [47]. 1Registered trademark. 2Trademarked. TABLE I STATISTICS OF UCI DATASETS USED IN THIS STUDY 2) Dataset #2: The proposed method’s efﬁciency is also tested on machine fault diagnostics, with data containing three categories of gearbox problems, such as missing teeth, tooth wear, and root faults. As shown in Fig. 5, a test rig is used to identify the faults in a gearbox that are shown in Fig. 4 [22], [23]. The three defective gears, as well as one healthy gear, are installed in the test setup. Then, using a controller, it is powered at its rotational speed by a regulated motor. A brake is used at the shaft’s end location to provide Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 Fig. 4. Faults of the gears: (a) normal, (b) missing teeth, (c) wear in teeth, and (d) fault in root. Algorithm 1 Proposed DPC Algorithm Require: O = {O1, . . . , Oi, . . . , On} ▷where Oi ∈ℜd=|ψ|+|φ| Ensure: C = {C1, C2, . . . , Ck} ▷a set of resultant clusters 1: Calculate distance matrix and parameter αt using Eqs. 15 and16, respectively 2: Calculate βi and γi for all data objects Oi ∈O by Eqs. 16 to 19. 3: Choose all data objects whose γi is larger than the αt cutoff distance in the decision graph and set k′ initial representatives of clusters as C P = {C Pi|1 ≤i ≤k′} and remaining data object will be O′ = O −C P. 4: for all Oi ∈O′ do label = min CP j ∈C j &1≤j≤k′{λm(Oi, C P j)}; ▷nearest cluster Clabel ←Clabel ∪Oi 5: end for 6: Compute the core distance γ e and boundary density βe ρ of each cluster e using Eqs. 20 to 22. 7: repeat ▷Group all density-reachable clusters 8: for all Ci ∈C do 9: for all C j ∈C −Ci do 10: if Ci and C j satisfy Defs. 5 and 6 then 11: Ci ←Ci ∪C j and update set C 12: end if 13: end for 14: end for 15: until Grouping of density reachable clusters 16: Return C = {C1, . . . , Ck} as the set of the clusters. a load to the system. As shown in Fig. 5, an experiment for intelligent fault detection was carried out. The gearbox was not loaded, and the motor’s speed was set to 1800 r/min. Three acceleration sensors that were ﬁxed in the housing’s vertical, horizontal, and axial directions and connected to its right end were employed to collect vibration data at a sampling rate of 12.8 kHz. However, categorical data, such as the number of cylinders, the forwarding gear values, and the number of carburetors, are discontinuous parameters. Four separate conditions, namely, tooth wear, root defect, missing teeth, and healthy, were used to collect vibration signals. As shown in Fig. 6, the original vibration signal is split into 90 segments, each of which contains 5023 samples. The MDPC-AD method is presented to diagnose machine faults via vibration signals, and categorical features are obtained to determine the state variation due to faults [22], [23]. As discussed in Section II-A, O = {O1, O2, . . . , Oi, . . . , On} is a dataset of n MD vectors. Each data vector Oi ∈ℜd=|ψ|+|φ|, where 1 ≤i ≤n, has a total of d features or attributes. However, each Oi has a |ψ| and |φ| number of signal features ψ and categorical φ attributes, respectively. One assumption is made in this application that the number of data objects in each cluster is equal. Let k be the number of clusters, and the data objects from each cluster are n/k. The MDPC-AD method is performed for the diagnosis of a faulty gearbox, as discussed in Algorithm 1. B. Evaluation Metrics Accuracy is one of the most commonly reported evaluation measures. It describes the percentage of accurate clustering outcomes among all the outcomes a machine learning algo- rithm produces. It is an intuitive and straightforward evaluation metric. A machine learning algorithm is better and more preferable if its percentage accuracy is near 100. On the other hand, depending just on accuracy for unbalanced data can be deceptive. In this situation, in addition to accuracy, other assessment measures, including precision, recall, F-Score, and JI, may be considered to determine how effective a model is [25]. Moreover, two internal validation indices, for example, the average clustering error and the ratio of separation to compactness, are also adopted in this study. C. Computational Protocol This study compares the performance of the proposed approach, MDPC-AD, with 13 SOTA methods. 1) K-PC: k-prototypes clustering algorithm for mixed datasets [39]. 2) EK-PC: An evolutionary k-prototypes clustering algo- rithm for mixed-type datasets [41]. 3) KL-FCM-GM: An FCM-type clustering algorithm for mixed datasets with a probabilistic dissimilarity function [42]. 4) FK-PC: A fuzzy k-prototypes clustering algorithm for MD [43]. 5) IK-PC: An improved k-prototypes clustering algorithm for mixed numerical and categorical data [44]. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 Fig. 5. (a) Gear test rig and (b) accelerometers ﬁxed in the vertical, axial, and horizontal directions. Fig. 6. Vibration signal in four different conditions of the gear from the experiment. 6) CAVE: A clustering algorithm based on variance and entropy for mixed datasets [40]. 7) SBAC: A similarity-based agglomerative clustering algorithm for data with mixed features [37]. 8) SpectralCAT: Categorical spectral clustering for numer- ical and nominal data [48]. 9) DKFCM: A density-oriented kernel FCM algorithm for fault diagnosis [10]. 10) DPC-MD: A novel DPC method for MD using a distance for MD [29]. 11) PE-EEMD-GG: A method based on permutation entropy, ensemble empirical mode decomposition, and the Gath–Geva clustering method for bearing fault diag- nosis [24]. 12) CG-SSC: A composite graph-based sparse subspace clustering method for machine fault diagnosis [22]. 13) MSC: A mean shift clustering-based approach with a spectral preprocessing technique for machinery diagnostics [23]. Since the researchers have not given their works a name, appropriate nomenclatures for these methodologies are employed. The scope of this study does not include a thor- ough description of these techniques. However, we use the precise procedures outlined in the original papers. As a result, interested readers are directed to the source works for more information. D. Results and Comparison In this study, a total of nine experiments are conducted to validate the MDPC-AD. The ﬁrst eight experiments are carried out on the UCI datasets using ﬁve external validation indices. The last experiment is performed to identify the faults in the gearbox of a rotary mechanical machine with the help of two internal validation measures. 1) Experiment on Categorical Datasets: In the ﬁrst exper- iment, the MDPC-AD is executed on datasets, namely, D1, D2, and D3, having categorical attributes only. These datasets do not possess numerical features. The second part of (14), followed by (15), is considered while computing distance. The clustering report obtained by the MDPC-AD is noted in the last column of Table II. The clustering reports generated by existing methods are also included in Table II. The best clustering report produced by a method is marked by bold characters. All the results of Table II demonstrate that the MDPC-AD outperforms all the above-discussed 13 SOTA methods. However, the performance of DPC-MD and MSC on D3 is the same as that of the MDPC-AD. 2) Experiment on Numerical Datasets: In the second exper- iment, the MDPC-AD is implemented on datasets, namely, D4, D5, D6, and D7, having only numerical attributes. These datasets do not have categorical features. Fig. 7 shows the ﬁrst two principal components of D4, D5, D6, and D7 plotted in 2D planes. It is clear from Table I and Fig. 7 that each dataset consists of a varying number of data points. Moreover, they have arbitrary shape clusters. Now, the ﬁrst part of (14), followed by (15), is employed while computing distance. The clustering reports of all the 14 methods, including the MDPC-AD, are reported in Table III. The best performance Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 TABLE II CLUSTERING REPORTS ON D1, D2, AND D3 USING FIVE VALIDATION INDICES TABLE III CLUSTERING REPORTS ON D4, D5, D6, AND D7 USING FIVE VALIDATION INDICES TABLE IV CLUSTERING REPORTS ON D8, D9, D10, D11, D12, AND D13 USING FIVE VALIDATION INDICES achieved by a method is marked by a bold character. We can conclude after observing all the results of Table III that the MDPC-AD outperforms all 13 SOTA methods even when the data points of D4, D5, D6, and D7 are varying and have arbitrary shape clusters. 3) Experiment on Mixed Datasets: In the third experiment, the MDPC-AD is executed on mixed datasets, namely, D8, D9, D10, D11, D12, and D13. These datasets contain both numerical as well as categorical variables. Here, (15) is used to compute the distance between data objects. The clustering reports produced are presented in Table IV. The best clustering report generated by a method is marked by bold characters. It is clear from Table IV that the MDPC-AD outperforms all the above-discussed 13 SOTA methods. In summary, we can say that the clustering reports in terms of precision, recall, F-Score, JI, and accuracy obtained by the proposed method named MDPC-AD are higher than the other 13 SOTA existing approaches mentioned in Section IV-C. The primary reason is that K-PC, EK-PC, IK-PC, FK-PC, DKFCM, PE-EEMD, CG-SSC, MSC, and DPC-MD are sensitive to the initialization of cluster rep- resentatives and are improper for nonspherically distributed Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 Fig. 7. First two principal components of the dataset on the left and its updated version with noise features as the number of genuine features on the right were shown on a plane to display the ﬁrst and second matching vectors of the data matrix along the axes. Different colors indicate different data point classiﬁcations. (a) D4. (b) D4 with noisy features. (c) D5. (d) D5 with noisy features. (e) D6. (f) D6 with noisy features. (g) D7. (h) D7 with noisy features. data. Moreover, SBAC addresses similarity measures with the assumption that the unusual matched feature values correspond to higher weights. DKFCM adopts a fuzzy objective func- tion that is designed based on several probabilistic theories regarding the organization of the obtained clusters. CAVE is sensitive to the procedure of sampling. The efﬁciency of SpectralCAT depends on the selection of kernel func- tion to compute the Markov matrix. On the other hand, MDPC-AD overcomes some of the abovementioned issues. Thus, MDPC-AD achieved good clustering results on the above-discussed numerical, categorical, and mixed datasets. 4) Experiment on Noisy Datasets: The fourth experiment is conducted on datasets, namely, D4, D5, D6, and D6, having only numerical variables to know whether the MDPC-AD is robust against the noisy features. After adding noisy features produced by a uniform random distribution in the length and size limit of the original dataset, the inﬂuence of noisy features is examined. Therefore, a dataset’s number of features would be twice as many as its initial number of attributes. The ﬁrst two principal components of each of the aforementioned datasets, as plotted on 2-D planes, are shown in Fig. 7 before and after the addition of noisy features. Fig. 7 makes it obvious that for a dataset; practically, all of the mapped locations have signiﬁcant overlaps with one another. This simply means that the existence of noisy features hurts these datasets. The results obtained by all techniques after including noisy features are shown in Fig. 8 against ﬁve assessment metrics, including accuracy, precision, recall, F-Score, and Jaccard index on D4–D7. The results show that the MDPC-AD performs better than any other approach, from K-PC to SpectralCAT. For a small number of datasets, clustering performance is dramati- cally reduced. Nevertheless, the S-distance, which is utilized to calculate the separations between numerical data items and is invariant to the Hadamard product, makes the MDPC-AD resilient [8]. 5) Experiment for Knowing the Impact of “c” in Symmetric Favored c-NN: In this work, local density is estimated based on a sequence of the weighted exponential kernel using an SFCNN. In the previous four experiments, the value of “c” is considered 5, as suggested by the past studies [28]. However, the ﬁfth experiment is conducted to verify the previous claim. The value of “c” varies from 1 to 19 with a step size of 2. The values of accuracy, precision, recall, F-Score, and Jaccard index for each value of “c” over all 13 datasets are shown in Fig. 9. The values of “c” are shown on the x-axis, and the clustering results are shown on the y-axis. It is clear from Fig. 9 that the values of clustering metrics are maximum when the value of “c” varies from 1 to 5 on datasets, i.e., D3, D8, and D9. However, the performance increases slightly on D6 when the value of “c” is beyond 5. On the other hand, the performances remain consistent on D11 and D13. The clustering performances deteriorate on D1, D2, D4, D5, D7, D10, and D12 when the value of “c” is beyond 12. It means that it is really difﬁcult to ﬁnd out the optimum value of “c.” However, it relies on the characteristics of a dataset. 6) Experiment on Order Sensitivity: In the ﬁnal experiment, the order of the data objects in a dataset is changed while still analyzing the clustering result. This sensitivity analysis measures the stability of the algorithm due to randomness and erroneous assessment. The MDPC-AD is executed ten times on 13 datasets. However, the positions of data objects are changed by shufﬂing them randomly, and the corresponding clustering results are shown in Fig. 10. The x-axis and y-axis of each plot in Fig. 10 denote, respectively, the number of iterations and the value of the metric in question. It is clear from Fig. 9 that the MDPC-AD is not sensitive to the position of data objects or order since the performance is the same or constant in all ten runs. 7) Experiment for Run-Time Comparison: All the methods mentioned in Section IV-C are not only compared based on their clustering reports but also compared based on their execution time, which is measured and noted in Table V. It is clear from Table V that most of the time MDPC-AD takes Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 Fig. 8. Comparison of clustering results on numerical datasets with noisy features. (a) Precision. (b) Recall. (c) F-Score. (d) Jaccard index. (e) Accuracy. TABLE V METHODS RUN TIME (UNIT: s) less time compared to K-PC, EK-PC, KL-FCM-GM, FK-PC, IK-PC, CAVE, DKFCM, DPC-MD, SpectralCAT, PE-EEMD, CG-SSC, MSC, and SBAC. However, in some cases, K-PC has a lesser execution time compared to the MDPC-AD, Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 Fig. 9. Evaluation of MDPC-AD for different values of “c” values on all the datasets. (a) Precision. (b) Recall. (c) F-Score. (d) Jaccard index. (e) Accuracy. Fig. 10. Evaluation of MDPC-AD for testing sensitivity on 13 datasets. (a) Precision. (b) Recall. (c) F-Score. (d) Jaccard index. (e) Accuracy. whereas MDPC-AD has a lesser execution time than EK-PC, KL-FCM-GM, IK-PC, CAVE, DKFCM, SpectralCAT, PE- EEMD, CG-SSC, MSC, and SBAC. Overall, the proposed MDPC-AD executes in lesser time and outperforms other methods. Moreover, the best execution times are bold in Table V. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 TABLE VI ABLATION STUDY ON D8, D9, D10, D11, D12, AND D13 TABLE VII GEARBOX FAULT DIAGNOSIS USING TWO INTERNAL VALIDATION INDICES 8) Ablation Study: The steps of MDPC-AD are determined after conducting an ablation study on mixed datasets only. DPC presented by Rodriguez and Laio [26] is implemented in the ﬁrst analysis. In the second analysis, the impact of the proposed AD mentioned in (12) is evaluated by incorporating it in DPC and renaming the modiﬁed algorithm as DPC- AD. In the third analysis, a new method to estimate local density is adopted, which relies on a sequence of the weighted exponential kernel using an SFCNN to overcome the limitation of ﬁxed c-NN and names the method DPC-AD-SFCNN. In the fourth study, a method for automatic selection of the initial cluster representatives is utilized from MDPC-AD and merged with DPC-AD-SFCNN and marked as DPC-AD-SFCNN- CR. The MDPC-CNN-MD considers the c-NN in place of an SFCNN for estimating local density. It also adopts the presented distance from [29]. The MDPC-CNN-AD is similar to the MDPC-CNN-MD, except that instead of using the presented distance in [29], it employs the proposed distance. Finally, CNN in MDPC-CNN-MD is substituted with SFCNN, which is now called MDPC-SFCNN-MD. Furthermore, the results of these studies are noted in Table VI to validate the superiority of the proposed method, MDPC-AD. All the results demonstrate that the proposed method, MDPC-AD, is superior to other combinations of the DPC algorithm. 9) Case Study for Gearbox Fault Diagnosis Using Clus- tering: In this section, MDPC-AD is compared with DPC, DPC-AD, DPC-AD-SFCNN, and DPC-AD-SFCNN-CR. This experiment is performed to group the state of the gears of a mechanical machine. For the same, features of the data obtained in 1 s are considered as a sample, and 90 samples/data objects are analyzed. A quantitative clustering analysis is conducted using two internal validation indices. First, a ratio of separation SP and compactness CM is computed, and their ratio ID1 = SP/CM is used as the metric for comparison. For this metric, a high value of SP is desired, and a low value of CM is suitable for good clusters. Thus, a high value of ID1 indicates effective clustering results. Second, a clustering error, ID2, is adopted for comparison and a smaller value of clustering error shows the most effective. A comparison of ID1 index on the above discussed ﬁve methods is shown in Table VII. In the case of MDPC-AD, SP has a high value, and CM obtained the ideal value equal to zero; thus, the value of ID1 is extremely large or tends to inﬁnity, which shows that MDPC-AD outperforms other SOTA methods. It indicates that MDPC-AD can yield well-separated and most compact clus- ters. Second, a comparison is shown using ID2 where all the methods are executed 50 times, and the average error is com- puted and presented in Table VII. As mentioned in Table VII, MDPC-AD achieved the lowest value equal to zero, meaning that there was nil clustering error in the proposed method while diagnosing the faults in a gearbox. Therefore, the proposed study is an effective method for gearbox fault diagnosis. V. CONCLUSION This study introduces the DPC-based clustering technique named MDPC-AD for gearbox fault diagnostics. An ablation study is conducted to demonstrate the effectiveness of each part of the MDPC-AD. The obtained results illustrate that the novel AD can more clearly reveal the structure of the 13 real- world datasets from UCI under examination. To calculate the global parameter and the local density of each data object, the MDPC-AD employs the idea of a series of weighted Gaussian kernels based on an SFCNN. In addition, the MDPC-AD is easier to control than DBSCAN and DPC since it can choose the initial cluster representatives automatically by establishing Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 the cutoff distance as a function of parameter c. The ﬁrst cluster representatives’ computation, however, ensures the inclusion of genuine initial cluster representatives. The con- cept of grouping density reachable clusters is employed to solve this problem in subsequent iterations, even though our method may initially choose incorrect cluster representatives. According to experiments on different real-world datasets, the MDPC-AD outperforms the 13 SOTA approaches mentioned in this article. Even though an experiment is run to see how ‘c’ affects things, more research is still required. Finding the ideal value for “c” and understanding the relationship between the parameters αt and “c” call for more investigation. It would also be intriguing to expand the capabilities of the current algorithm to manage large datasets with mixed attributes. Although MDPC-AD improves clustering efﬁciency, the decreased efﬁ- ciency of MDPC-AD compared to DPC is due to the high computational complexity of density estimation. Therefore, it is essential to reduce the computational complexity of density estimation, a subject that merits more study. Finally, in mechanical systems, clustering algorithms have proven to be more reliable, particularly for fault diagnosis. The names of two faults that could affect gearboxes, bearings, and wind turbines, are mentioned in this study. The last two, which merit additional research, have not been covered in this article. ACKNOWLEDGMENT The authors would like to thank the support of Ph.D. student Michal Dobrovolny for consultations. REFERENCES [1] J. Sun, C. Yan, and J. Wen, “Intelligent bearing fault diagnosis method combining compressed data acquisition and deep learning,” IEEE Trans. Instrum. Meas., vol. 67, no. 1, pp. 185–195, Jan. 2018. [2] C. Sun, M. Ma, Z. B. Zhao, and X. Chen, “Sparse deep stacking network for fault diagnosis of motor,” IEEE Trans. Ind. Informat., vol. 14, no. 7, pp. 3261–3270, Mar. 2018. [3] S. B. Wang, X. F. Chen, C. W. Tong, and Z. B. Zhao, “Matching syn- chrosqueezing wavelet transform and application to aeroengine vibration monitoring,” IEEE Trans. Instrum. Meas., vol. 66, no. 2, pp. 360–372, Feb. 2017. [4] Y. Chen and M. J. Zuo, “A sparse multivariate time series model-based fault detection method for gearboxes under variable speed condition,” Mech. Syst. Signal Process., vol. 167, Mar. 2022, Art. no. 108539. [5] Y. Liu, B. Liu, X. Zhao, and M. Xie, “A mixture of variational canonical correlation analysis for nonlinear and quality-relevant process monitoring,” IEEE Trans. Ind. Electron., vol. 65, no. 8, pp. 6478–6486, Aug. 2018. [6] W. Teng, Y. Liu, Y. Huang, L. Song, Y. Liu, and Z. Ma, “Fault detection of planetary subassemblies in a wind turbine gearbox using TQWT based sparse representation,” J. Sound Vibrat., vol. 490, Jan. 2021, Art. no. 115707. [7] Y. Liao, L. Zhang, and W. Li, “Regrouping particle swarm optimization based variable neural network for gearbox fault diagnosis,” J. Intell. Fuzzy Syst., vol. 34, no. 6, pp. 3671–3680, 2018. [8] S. Chakraborty and S. Das, “K—Means clustering with a new divergence-based distance metric: Convergence and performance analy- sis,” Pattern Recognit. Lett., vol. 100, pp. 67–73, Dec. 2017. [9] Z. Shuqing, S. Guoxiu, L. Liang, L. Xinxin, and J. Xiong, “Study on mechanical fault diagnosis method based on LMD approximate entropy and fuzzy C-means clustering,” Chinese J. Sci. Instrum., vol. 34, no. 3, pp. 714–720, 2013. [10] A. R. Ramos et al., “A novel fault diagnosis scheme applying fuzzy clus- tering algorithms,” Appl. Soft Comput., vol. 58, pp. 605–619, Sep. 2017. [11] D. Gustafson and W. Kessel, “Fuzzy clustering with a fuzzy covariance matrix,” in Proc. IEEE Conf. Decis. Control including 17th Symp. Adapt. Processes, Jan. 1978, pp. 761–766. [12] S. Wang, L. Li, S. Zhang, and G. Sun, “Mechanical fault diagnosis method based on EEMD sample entropy and GK fuzzy clustering,” China Mech. Eng., vol. 24, no. 22, p. 3036, 2013. [13] X. Liu, M. Li, S. Qin, X. Ma, and W. Wang, “A predictive fault diagnose method of wind turbine based on K-means clustering and neural networks,” J. Internet Technol., vol. 17, no. 7, pp. 1521–1528, 2016. [14] P. Baraldi, F. D. Maio, M. Rigamonti, E. Zio, and R. Seraoui, “Unsuper- vised clustering of vibration signals for identifying anomalous conditions in a nuclear turbine,” J. Intell. Fuzzy Syst., vol. 28, no. 4, pp. 1723–1731, 2015. [15] S. Fu, K. Liu, Y. Xu, and Y. Liu, “Rolling bearing diagnosing method based on time domain analysis and adaptive fuzzy C-means clustering,” Shock Vibrat., vol. 2016, pp. 1–8, Jan. 2016. [16] E. Li, L. Wang, B. Song, and S. Jian, “Improved fuzzy C-means clustering for transformer fault diagnosis using dissolved gas analysis data,” Energies, vol. 11, no. 9, p. 2344, Sep. 2018. [17] Z. M. Nopiah, A. K. Junoh, and A. K. Arifﬁn, “Vehicle interior noise and vibration level assessment through the data clustering and hybrid classiﬁcation model,” Appl. Acoust., vol. 87, pp. 9–22, Jan. 2015. [18] I. Gath and A. B. Geva, “Unsupervised optimal fuzzy clustering,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 11, no. 7, pp. 773–780, Jul. 1989. [19] J. C. Bezdek and J. C. Dunn, “Optimal fuzzy partitions: A heuristic for estimating the parameters in a mixture of normal distributions,” IEEE Trans. Comput., vol. C-24, no. 8, pp. 835–838, Aug. 1975. [20] Z. X. Wei, Y. X. Wang, S. L. He, and J. D. Bao, “A novel intelli- gent method for bearing fault diagnosis based on afﬁnity propagation clustering and adaptive feature selection,” Knowl.-Based Syst., vol. 116, pp. 1–12, Jan. 2017. [21] R. Langone, C. Alzate, B. D. Ketelaere, J. Vlasselaerc, W. Meertc, and J. A. K. Suykensa, “LS-SVM based spectral clustering and regression for predicting maintenance of industrial machines,” Eng. Appl. Artif. Intell., vol. 37, pp. 268–278, Jan. 2015. [22] C. Sun, X. Chen, R. Yan, and R. X. Gao, “Composite-graph-based sparse subspace clustering for machine fault diagnosis,” IEEE Trans. Instrum. Meas., vol. 69, no. 5, pp. 1850–1859, May 2020. [23] S. Fong, J. Harmouche, S. Narasimhan, and J. Antoni, “Mean shift clustering-based analysis of nonstationary vibration signals for machinery diagnostics,” IEEE Trans. Instrum. Meas., vol. 69, no. 7, pp. 4056–4066, Jul. 2020. [24] J. Hou, Y. Wu, H. Gong, A. S. Ahmad, and L. Liu, “A novel intelligent method for bearing fault diagnosis based on EEMD permutation entropy and GG clustering,” Appl. Sci., vol. 10, no. 1, p. 386, Jan. 2020. [25] A. Fahad et al., “A survey of clustering algorithms for big data: Taxonomy and empirical analysis,” IEEE Trans. Emerg. Topics Comput., vol. 2, no. 3, pp. 267–279, Sep. 2014. [26] A. Rodriguez and A. Laio, “Clustering by fast search and ﬁnd of density peaks,” Science, vol. 344, no. 6191, pp. 1492–1496, Jun. 2014. [27] Z. Liang and P. Chen, “Delta-density based clustering with a divide- and-conquer strategy: 3DC clustering,” Pattern Recognit. Lett., vol. 73, pp. 52–59, Apr. 2016. [28] L. Yaohui, M. Zhengming, and Y. Fang, “Adaptive density peak clustering based on K-nearest neighbors with aggregating strategy,” Knowl.-Based Syst., vol. 133, pp. 208–220, Oct. 2017. [29] M. Du, S. Ding, and Y. Xue, “A novel density peaks clustering algorithm for mixed data,” Pattern Recognit. Lett., vol. 97, pp. 46–53, Oct. 2017. [30] L. C. Jiao, F. Shang, F. Wang, and Y. Liu, “Fast semi-supervised clus- tering with enhanced spectral embedding,” Pattern Recognit., vol. 45, no. 12, pp. 4358–4369, 2012. [31] A. Karlekar, A. Seal, O. Krejcar, and C. Gonzalo-Martín, “Fuzzy K-means using non-linear S-distance,” IEEE Access, vol. 7, pp. 55121–55131, 2019. [32] F. Cao, J. Z. Huang, and J. Liang, “A fuzzy SV-K-modes algorithm for clustering categorical data with set-valued attributes,” Appl. Math. Comput., vol. 295, pp. 1–15, Feb. 2017. [33] U. Maulik, S. Bandyopadhyay, and I. Saha, “Integrating clustering and supervised learning for categorical data analysis,” IEEE Trans. Syst., Man, Cybern. A, Syst. Humans, vol. 40, no. 4, pp. 664–675, Jul. 2010. [34] I. Saha and U. Maulik, “Incremental learning based multiobjective fuzzy clustering for categorical data,” Inf. Sci., vol. 267, pp. 35–57, May 2014. [35] I. T. R. Yanto, M. A. Ismail, and T. Herawan, “A modiﬁed fuzzy K- partition based on indiscernibility relation for categorical data cluster- ing,” Eng. Appl. Artif. Intell., vol. 53, pp. 41–52, Aug. 2016. [36] M. Li, S. Deng, L. Wang, S. Feng, and J. Fan, “Hierarchical clustering algorithm for categorical data using a probabilistic rough set model,” Knowl.-Based Syst., vol. 65, pp. 60–71, Jul. 2014. [37] C. Li and G. Biswas, “Unsupervised learning with mixed numeric and nominal data,” IEEE Trans. Knowl. Data Eng., vol. 14, no. 4, pp. 673–690, Jul./Aug. 2002. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 [38] C.-C. Hsu, “Generalizing self-organizing map for categorical data,” IEEE Trans. Neural Netw., vol. 17, no. 2, pp. 294–304, Mar. 2006. [39] Z. Huang, “Clustering large data sets with mixed numeric and categorical values,” in Proc. 1st Paciﬁc–Asia Conf. Knowl. Discovery Data Mining, 1997, pp. 21–34. [40] C.-C. Hsu and Y.-C. Chen, “Mining of mixed data with application to catalog marketing,” Exp. Syst. Appl., vol. 32, no. 1, pp. 12–23, 2007. [41] Z. Zheng, M. Gong, J. Ma, L. Jiao, and Q. Wu, “Unsupervised evolutionary clustering algorithm for mixed type data,” in Proc. IEEE Congr. Evol. Comput., Jul. 2010, pp. 1–8. [42] S. P. Chatzis, “A fuzzy C-means-type algorithm for clustering of data with mixed numeric and categorical attributes employing a probabilistic dissimilarity functional,” Exp. Syst. Appl., vol. 38, no. 7, pp. 8684–8689, 2011. [43] J. Ji, W. Pang, C. Zhou, X. Han, and Z. Wang, “A fuzzy K-prototype clustering algorithm for mixed numeric and categorical data,” Knowl.- Based Syst., vol. 30, pp. 129–135, Jun. 2012. [44] J. Ji, T. Bai, C. Zhou, C. Ma, and Z. Wang, “An improved K- prototypes clustering algorithm for mixed numeric and categorical data,” Neurocomputing, vol. 120, pp. 590–596, Nov. 2013. [45] S. Santini and R. Jain, “Similarity measures,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 21, no. 9, pp. 871–883, Sep. 1999. [46] J. Jiang, Y. Chen, X. Meng, L. Wang, and K. Li, “A novel density peaks clustering algorithm based on K nearest neighbors for improving assignment process,” Phys. A, Stat. Mech. Appl., vol. 523, pp. 702–713, Jun. 2019. [47] D. Dheeru and E. K. Taniskidou. (2017). UCI Machine Learning Repository. [Online]. Available: [48] G. David and A. Averbuch, “SpectralCAT: Categorical spectral cluster- ing of numerical and nominal data,” Pattern Recognit., vol. 45, no. 1, pp. 416–433, 2012. Krishna Kumar Sharma received the M.Tech. (Information Technology) degree from IIIT Allahabad, Allahabad, India, in 2011, and the Ph.D. degree from the Department of Computer Science and Engineering, PDPM Indian Institute of Information Technology, Design and Manufacturing Jabalpur, Jabalpur, India, in 2021. He is currently an Assistant Professor with the Department of Computer Science and Informatics, University of Kota, Kota, India. His current research interests include pattern recognition. Ayan Seal (Senior Member, IEEE) received the Ph.D. degree in engineering from Jadavpur Univer- sity, Kolkata, India, in 2014. He is currently an Assistant Professor with the Department of Computer Science and Engineer- ing, PDPM Indian Institute of Information Technol- ogy, Design and Manufacturing Jabalpur, Jabalpur, India. He has visited the Universidad Politécnica de Madrid, Madrid, Spain, as a Visiting Research Scholar. He has authored or coauthored several journals, conferences, and book chapters in the area of biometric and medical image processing. His current research interests include image processing and pattern recognition. Dr. Seal was a recipient of several awards. Recently, he received the Sir Visvesvaraya Young Faculty Research Fellowship from Media Lab Asia, Ministry of Electronics and Information Technology, Government of India. Anis Yazidi (Senior Member, IEEE) received the M.Sc. and Ph.D. degrees from the University of Agder, Grimstad, Norway, in 2008 and 2012, respectively. He was a Researcher with Teknova AS, Grimstad. From 2014 to 2019, he was an Associate Pro- fessor with the Department of Computer Science, Oslo Metropolitan University, Oslo, Norway. He is currently a Full Professor with the Department of Computer Science, Oslo Metropolitan University, where he is leading the research group in applied artiﬁcial intelligence. He is also a Professor II with the Norwegian University of Science and Technology (NTNU), Trondheim, Norway, and a Senior Researcher with Oslo University Hospital, Oslo. His current research interests include machine learning, learning automata, stochastic optimization, and autonomous computing. Ondrej Krejcar received the Ph.D. degree in tech- nical cybernetics from the Technical University of Ostrava, Ostrava, Czechia, in 2008. He is currently a Full Professor in systems engi- neering and informatics with the University of Hradec Kralove (UHK), Hradec Kralove, Czechia, and the Faculty of Informatics and Management, Center for Basic and Applied Research, UHK; and a Research Fellow with the Malaysia-Japan Interna- tional Institute of Technology, University of Tech- nology Malaysia, Kuala Lumpur, Malaysia. Since June 2020, he has been a Vice-Rector for science and creative activities of the UHK. He is also the Director of the Center for Basic and Applied Research, UHK. From 2016 to 2020, he was the Vice-Dean for science and research with the Faculty of Informatics and Management, UHK. His H-index is 21, with more than 1800 citations received in the Web of Science, where more than 120 IF journal articles are indexed in JCR index. Dr. Krejcar has been a Management Committee Member substitute at Project COST CA16226 since 2017. In 2018, he was the 14th top peer Reviewer in Multidisciplinary in the World according to Publons and a Top Reviewer in the Global Peer Review Awards 2019 by Publons. He is currently on the Editorial Board of the MDPI Sensors IF journal (Q1/Q2 at JCR) and several other ESCI-indexed journals. Since 2018, he has also been a Vice-Leader and a Management Committee Member at WG4 at project COST CA17136. Since 2019, he has been the Chairperson of the Program Committee of the KAPPA Program, Technological Agency of the Czech Republic as a regulator of the EEA/Norwegian Financial Mechanism in the Czech Republic for the term 2019–2024. Since 2020, he has been the Chairperson of Panel 1 (Computer, Physical and Chemical Sciences) of the ZETA Program, Technological Agency of the Czech Republic. From 2014 to 2019, he has been the Deputy Chairperson of Panel 7 (Processing Industry, Robotics, and Electrical Engineering) of the Epsilon Program, Technological Agency of the Czech Republic. He is also a guarantee of the doctoral study program in applied informatics with UHK, where he is focusing on lecturing on smart approaches to the development of information systems and applications in ubiquitous computing environments. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply."
A personality-aware group recommendation system based on pairwise preferences,Roza Abolghasemi and Paal Engelstad and Enrique Herrera-Viedma and Anis Yazidi,2022,,595,Information Sciences,article,"A personality-aware group recommendation system based on
pairwise preferences
Roza Abolghasemi a,⇑, Paal Engelstad a, Enrique Herrera-Viedma b,c,⇑, Anis Yazidi a,⇑
a Department of Computer Science, Oslo Metropolitan University, Oslo, Norway
b Department of Computer Science and AI, Andalusian Research Institute in Data Science and Computational Intelligence, University of Granada, Granada, Spain
c Faculty of Engineering, The School of Computing, Universiti Teknologi Malaysia, Johor Bahru, Malaysia
a r t i c l e
i n f o
Article history:
Received 26 April 2021
Received in revised form 9 February 2022
Accepted 18 February 2022
Available online 23 February 2022
Keywords:
Group recommendation system
Pairwise preferences
Group decision-making
Personality traits
Reaching consensus
a b s t r a c t
Human personality plays a crucial role in decision-making and it has paramount impor-
tance when individuals negotiate with each other to reach a common group decision.
Such situations are conceivable, for instance, when a group of individuals want to watch
a movie together. It is well known that people inﬂuence each other’s decisions, the more
assertive a person is, the more inﬂuence they will have on the ﬁnal decision. In order to
obtain a more realistic group recommendation system (GRS), we need to accommodate
the assertiveness of the different group members’ personalities. Although pairwise prefer-
ences are long-established in group decision-making (GDM), they have received very little
attention in the recommendation systems community. Driven by the advantages of pair-
wise preferences on ratings in the recommendation systems domain, we have further pur-
sued this approach in this paper, however we have done so for GRS. We have devised a
three-stage approach to GRS in which we 1) resort to three binary matrix factorization
methods, 2) develop an inﬂuence graph that includes assertiveness and cooperativeness
as personality traits, and 3) apply an opinion dynamics model in order to reach consensus.
We have shown that the ﬁnal opinion is related to the stationary distribution of a Markov
chain associated with the inﬂuence graph. Our experimental results demonstrate that our
approach results in high precision and fairness.
 2022 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY
license (http://creativecommons.org/licenses/by/4.0/).
1. Introduction
Recommendation Systems (RS) aim to ﬁnd and recommend a set of items to a single user, and are commonly used in var-
ious domains, such as movies, music, travel, e-commerce, and so on. While a classic RS tries to recommend a suitable set of
items for an individual user based on their preferences, group recommendation systems are concerned with recommending
a set of items that appeal to a group of people. There are numerous applications of GRS in real-life settings. Application
scenarios for GRS include examples such as a group of friends who want a recommendation for a movie to watch together,
passengers in a car who want to listen to the same music while driving, etc.
https://doi.org/10.1016/j.ins.2022.02.033
0020-0255/ 2022 The Authors. Published by Elsevier Inc.
This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
⇑Corresponding authors at: Department of Computer Science and Artiﬁcial Intelligence, University of Granada, Granada, Spain (E. Herrera-Viedma)
Department of Computer Science, Oslo Metropolitan University, Oslo, Norway (A. Yazidi) (R. Abolghasemi).
E-mail addresses: rozaabol@oslomet.no (R. Abolghasemi), viedma@decsai.ugr.es (E. Herrera-Viedma), anisy@oslomet.no (A. Yazidi).
Information Sciences 595 (2022) 1–17
Contents lists available at ScienceDirect
Information Sciences
journal homepage: www.elsevier.com/locate/ins
 There are different types of recommendation systems: Collaborative Filtering (CF) RS [1], content-based RS [2],
demographic-based RS, utility-based RS, knowledge-based RS [3], and hybrid RS, which is a combination of other methods.
The CF models have shown promising results as compared to the different recommendation systems. The datasets used in
the CF models include hundreds of thousands of item ratings given by users. These ratings are used to compute recommen-
dations for target users based on two main methods: 1.) KNN-based CF [4,5], which generates recommendations based on
the ratings given by the k most similar users, 2.) Model-based CF [6], which builds the model based on a rating matrix. The
most popular model-based CF is Matrix Factorization (MF) [7], which decomposes the rating matrix into a product of two
smaller matrices containing latent factors, namely a user matrix, and an item matrix. In matrix factorization, the data are
usually the ratings of the items given by the users. However, some authors claim that comparing items or pairwise prefer-
ences can yield more accurate preferences than the rating in a predeﬁned scale [8]. For instance, in a normal rating system, if
a user gives two movies ﬁve stars, we cannot know which of the two they prefer. For this reason, a predeﬁned rating scale
consisting of discrete values is not considered to be very precise. Instead, by using pairwise preferences, two-by-two com-
parisons of movies can be made, and thus users’ movie preferences can be better expressed.
Although pairwise preferences are long-standing in group decision-making (GDM) [9–11], they have, with a few excep-
tions [12–14], received very little attention from the recommendation system community. Driven by the recently reported
advantages of pairwise preferences on ratings in the ﬁeld of recommendation systems, in this paper we have further pursued
this approach, however we have done so for GRS.
In [14], a new RS was introduced which used pairwise preference scores instead of pure rating data. Relying on pairwise
preference scores led to better performance in terms of Normalized Discounted Cumulative Gain (NDCG) and better preci-
sion than that obtained by the legacy methods based on single item ratings. Among the most popular approaches to matrix
factorization based on pairwise preference scores are Bayesian Personalized Ranking (BPR) [15] and Multiple Pairwise Rank-
ing (MPR) [16], which formulate the matrix factorization problem as a maximum likelihood estimation problem and use
stochastic gradient descent to deduce the latent factors.
Pairwise matrix factorization also aims to ﬁnd an embedding of items and users. The advantage of pairwise preference
rating methods compared to other single rating methods is that they are more precise and can yield better predictions
due to their pairwise comparison nature [12,15,16]. In this paper, we calculated personalized item scores based on the pre-
viously mentioned pairwise preference rating methods, and then we computed a ﬁnal group score for each item based on
opinion dynamics theory [17]. The weights of the inﬂuence graph were computed from the personality values collected from
the TKI test. Finally, according to the stationary distribution of a Markov chain, we have proven that the group members will
reach consensus. Moreover, we have provided an alternative proof and interpretation of the convergence results.
A brief explanation of the contribution of our work is detailed as follows. We have resorted to opinion dynamics theory
(social inﬂuence) in order to model how users inﬂuence each other’s opinions within a group based on deﬁning mutual inﬂu-
ence relations derived from the TKI personality test. We prove that the group will reach a consensus under some mild con-
ditions on the weight matrix describing mutual inﬂuences. We also show a link between our approach to aggregating user
ratings based on opinion dynamics and the widely used I-OWA approach to group decision-making.
Another contribution of this paper is that while most of the group recommendation systems use single rating scores, we
have used pairwise preferences instead. Using pairwise preferences is known in the literature to provide more precise rec-
ommendations due to the derivation of more implicit feedback from users compared to a single rating [12,15,16]. We have
also tested our approach by using three pairwise preference ranking approaches and different experimental results have
been reported in different scenarios.
The rest of this paper is organized as follows. In Section 2, we ﬁrst outline a state-of-the-art review of work where per-
sonality has been used for RS and GRS systems. Section 3 explains the three pairwise ranking methods that we adopted to
predict the personalized item ranking scores. Moreover, fuzzy preference aggregation is explained in a subsection. We then
describe our proposed model for a personality-based group recommendation system in Section 4. Next, Section 5 introduces
our experimental settings and evaluation metrics and Section 6 reports our experimental results and our main ﬁndings in
light of the existing studies. Finally, Section 7 discusses the ﬁndings further and includes some of their managerial
implications.
2. Related work
2.1. Personality-based RS
In this section, we focus on the articles concerning personality-based RS and GRS systems.
Personality-based RS refers to a class of RS that takes the personality characteristics of a person into account when mak-
ing a recommendation. We will ﬁrst provide some examples of studies of the role personality plays in RS for a single user
before shedding light on the role personality plays in GRS. The work in [18] concerns recommendations for a single user
(as opposed to a group) based on a personality proﬁle derived from information about their professional activities. The role
of personality in tourism destination recommendations is highlighted in [19]. This article classiﬁes users based on travel per-
sonality categories, which leads to particular travel behavior. To address the recommendation redundancy and cold start
problems, Dhelim et al. [20] proposed a personality-aware product RS based on metapath discovery and user interest.
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
2
 The proposed method aspires to incorporate the users’ personality traits in the associated items. The main personality theory
used in that paper is the Five-Factor Model (FFM), which is based on the following traits: neuroticism, openness to experi-
ence, extraversion, agreeableness, and conscientiousness. The work in [21] investigated the role of Twitter users’ personality
traits when recommending followers. The role personality plays is often ignored in follower recommendation methods, since
most RS systems only use graph topology and user-generated content for this task. For a comprehensive overview of
personality-based RS, we refer the reader to [22]. This paper discusses some challenges and future research directions con-
cerning this subject.
2.2. Group recommendations
Although single-user recommendation systems have received signiﬁcant research attention and have gained a lot of pop-
ularity due to their use by Internet giants such as Google, Amazon, and Netﬂix, studies of GRS systems are rather sparse. A
GRS aims to provide group recommendations that maximize group members’ satisfaction and minimize inequality among
users. GRS systems are usually more complex than single RS systems. For instance, Xiao et al. [23] have shown that solving
a GRS problem is usually NP-hard in different semantics. They mapped the group recommendation problem to a multiple
objective optimization problem and used Pareto optimality as the criterion for the solution. Recently, remarkable work
has been carried out with GRS based on deep learning. For instance, in 2020, Zhenhua et al. proposed a Multi-attention-
based Group Recommendation Model (MAGRM) [24], which uses multi-attention-based deep neural network structures
to achieve accurate group recommendations. To achieve this goal and to capture the internal social features of groups, a vec-
tor representation of group features was used to capture each of the groups’ deep semantic features. Then, group preferences
for items were inferred using a neural attention mechanism that takes the preference interaction into account among group
members.
Group recommendations based on implicit feedback (like or buy) have attracted much attention in services such as Face-
book and Amazon. An example of such a recommendation is Group Preference Based Bayesian Personalized Ranking (GBPR)
[25], which was introduced by Pan and Chen.
There is little research on GRS systems that takes the psychological nature of interactions between group members into
account when making a joint decision. One of the ﬁrst prominent studies to address this issue was carried out by Recio-
Garcia et al. [26], who proposed a personality-aware group recommendation model based on the Thomas-Kilmann Conﬂict
Mode Instrument (TKI) [27]. This test is based on conﬂict management and its effect on personal and group dynamics.
According to this test, there are ﬁve different styles of conﬂict management: Competing, Collaborating, Avoiding, Accommo-
dating, and Compromising. For a more detailed explanation of these styles, we refer the reader to Section 4.1.
In this paper, we have applied the concept of TKI to represent the group members’ personality scores. In practice, our
method works well when all the users are able to participate in the TKI test, which is not always a convenient option, espe-
cially for large groups. For large groups in social media, however, it is possible to automatically predict the personality traits
of users based on their information and activity in social media without requiring a TKI test [28]. The TKI metaphor is
another alternative to the TKI test [29] that consists in showing the users two movie characters that have opposite person-
alities, and requiring the user to decide which character has a personality that is more similar to theirs.
To improve group recommendations, some papers have combined the inﬂuence of personality and social trust. In [30],
personality factors were derived from TKI and, based on these factors, a value called Conﬂict Mode Weight (CMW) was cal-
culated to reﬂect the inﬂuence of personality on group decisions. Moreover, mutual-trust relationships between group mem-
bers were extracted from the underlying social network that connects them. The trust value is based on various network
measures, combining their distance in the social network, the number of mutual friends, duration of friendship, shared pic-
tures, etc. In [31], agreeableness was used as a personality factor that models altruistic behavior and is based on the Big-Five
model [32].
The majority of the studies in the ﬁeld of group recommendation systems consider the opinion of all members equally.
While in real life, personality traits inﬂuence the group’s ﬁnal decision signiﬁcantly. Although there are some studies that
take the impact users’ personalities have on group decisions into the consideration, they lack a sound theory that quantiﬁes
group dynamics. Furthermore, few group recommendation works use pairwise preference. As previously mentioned, it has
been shown that, in general, pairwise preference methods in recommendation systems show greater precision than individ-
ual rating methods [12,15,16].
At this point, we will mention some notable works that are more relevant to our method. In a group recommendation
system, it is very important that group members negotiate with each other to be able to reach a ﬁnal decision. In some works,
a coordinator interacts with members to ﬁnd out their opinion. Wang et al. [33] created a virtual user that acted as a coor-
dinator who tried to solve the members’ conﬂicts in a group in order to reach a ﬁnal decision. This was done based on the
mutual trust that existed between the coordinator and members, and not their personalities. In other words, users’ trust-
relations created some sort of personal inﬂuence, which had an impact on the virtual coordinator’s opinion.
There are some works in group recommendation systems like [34] which used the results of the TKI method in both social
relationships and social behavior, not only to infer a group’s preference, but also to model the tolerance and altruism char-
acteristics of the group members. Quijano et al. used personality traits in [29] to design a system called HappyMovie, which
recommends movies to Facebook users based on their level of trust derived from the social network and the TKI metaphor,
which serves as an alternative to the TKI test. They expressed the adjustment of a user rating based on the ratings of users
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
3
 they trust using a simplistic formula where the inﬂuence of other users is inversely proportional to the user personality. The
formula is similar to the memory-based approach for recommendation systems, where the authors use trust instead of sim-
ilarity between users. The main shortcoming of their method is that it does not take the personalities of other users into
account, and only applies the personality of one user at a time.
From the literature, we see that the vast majority of works that take personality traits into account by using the TKI test
employ some sort of ad hoc formula (heuristics) to ﬁnd the group score. In contrast to all of these works, we rely on the social
inﬂuence theory in order to accurately simulate the effect of other users in the ﬁnal group rating. Another personality-aware
group recommendation based on the TKI test was proposed by Recio-Garcia et al. [26]. Their recommendation is based on
existing collaborative ﬁltering techniques and considers group personality composition.
Among the models that used the TKI test, we ﬁnd the work of Guo et.al. [35] who introduced a group recommendation
model using individual personality, the impact preference similarities between users, susceptibility, intimacy, and expertise
factor have on the ability to improve the recommendation system. Their approach, however, is not suitable for large-scale
applications, while our proposed method works well on any group size. Moreover, their work did not use pairwise prefer-
ences, and its efﬁciency on heterogeneous data has not been studied. We, however, use random personality values derived
from different probability distributions in our work to show the applicability of our model to any type of data.
Additionally, although group recommendation systems based on TKI and personality traits have been used in these
papers, as noted, none of them applied pairwise preference to ratings in their methods. In our paper, besides using person-
ality traits to understand the impact has user on the ﬁnal group decision, we have applied three pairwise preferences meth-
ods in order to calculate the item ratings more accurately compared to single-item ratings.
3. Preliminaries
3.1. Item Ranking based on pairwise preferences
In this section, we present three popular methods for ranking items based on the pairwise preferences that we have used
in our experiments.
3.1.1. Bayesian Personalized Ranking (BPR)
Rendle et al. [15] proposed a generic optimization criterion, BPR-OPT, for personalized ranking that converts a user-item
matrix into a set of per-user item-to-item matrices and tries to maximize the likelihood of per-user pairwise preferences. To
this end, they considered two assumptions: 1. the observed item i by user u is preferred over all unobserved items. 2. The
likelihood of pairwise preference of user u is independent of the others. The likelihood of BPR is formulated as:
BPR ¼
Y
u2U
Y
i2Iþ
u
Y
j2IIþ
u
prðrui > rujÞ  1  prðruj > ruiÞ


ð1Þ
where the set of all users is represented as U and the set of all items as I. In this equation, Iþ
u  I denotes items that received
positive feedback from the user and rui is user u’s preference as regards to item i. prðrui > rujÞ is deﬁned as the individual
probability that the user u prefers item i over j. This is obtained using the logistic sigmoid function:
prðrui > rujjHÞ ¼
1
1 þ exuijðHÞ
ð2Þ
where xuijðHÞ is an arbitrary real-value function of the model parameter vector H, which captures the special relationship
between user u, item i, and item j from the matrix factorization model [15].
This method solves the matrix factorization problem using stochastic gradient descent with the aim of maximizing the
Area Under the Curve (AUC)..
3.1.2. Multiple Pairwise Ranking (MPR)
There are two main reasons that can explain unobserved items I  Iþ
u in BPR: a user either dislikes the unrated items or
has not seen them. To account for these two reasons, Yu et al. [16] introduced a new version of BPR called Multiple Pairwise
Ranking (MPR). They divided unobserved items into two subsets I
u and I
u, then deﬁned three subsets of items I as:
Iþ
u : The items that user u has seen and expressed positive feedback on.
I
u : The items that user u has seen but has not expressed feedback on.
I
u: The uncertain negative items that user u has not seen.
MPR states that items for which the user has given positive feedback (Iþ
u ) have a higher probability of being preferred by
the user than items that the user has not seen (I
u). Furthermore, the items that the user has not seen (I
u) have a higher prob-
ability of being preferred by the user than the items that they have seen but have not provided feedback on (I
u ). Considering
ruij ¼ rui  ruj, the likelihood of MPR among items can be given as follows:
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
4
 MPR ¼
Y
u2U
Y
i;p;p02Iþ
u
Y
j;q02I
u ;q2I
u
prðruij P ruqq0; ruqq0 P rupp0Þ
 1  prðruij < ruqq0; ruqq0 < rupp0Þ


8
>
<
>
:
ð3Þ
where i; p; p0 2 Iþ
u , while j; q0 2 I
u , and q 2 I
u.
3.1.3. Matrix factorization pair-score prediction (MFP)
MFP, introduced by Kalloori et al. [12], provides pairwise scores for a set of items that indicate how much a user prefers
one item over another. By integrating the pairwise scores, personalized item scores are computed that indicate how much a
user prefers an item. Let R be a matrix with elements ruij, where ruij indicates how much a user u prefers item i over item j.
MFP factorizes a matrix R into two smaller d-dimensional matrices X and Y such that R ¼ X:Y is the dot product of the two.
Here, R 2 Rusers items is the user-item rating matrix, X 2 Rusers latentfactors is user matrix containing the user’s latent factors (xu)
and Y 2 Ritems pairitemslatentfactors is the item matrix that contains the latent factors of the pair item (yij). The pair-score of a user
u for the pair-item i; j is:
r
uij ¼ l þ bu þ bij þ xT
uyij
ð4Þ
where l is the average of all pair scores in the matrix R and bu and bij are the baseline parameters for modeling the deviation
from the average score for a user u and item pair ði; jÞ, respectively. In MFP, the model parameters are learnt using stochastic
gradient descent, which minimizes the prediction error on the training data ðruij  r
uijÞ. The result is a matrix R with elements
consisting of predicted missing pair scores r
uij. The ﬁnal personalized item score vui is calculated according to the following
equation:
vui ¼
X
j2In if g
r
uij
Ij j
ð5Þ
3.2. Fuzzy preference aggregation
In this section, we focus on preliminaries about GDM and preference aggregation as a method for reaching consensus. A
GDM problem consists of a group of m members G ¼ fg1; g2; . . . ; gmg expressing their preferences for a set of items
X ¼ fx1; x2; . . . ; xng to reach a common solution. These preferences might be fuzzy preference relations (FPR), which are pair-
wise preferences of items. An FPR P on a set of items X can be represented as a matrix P ¼ ðpijÞ, where pij ¼ lPðxi; xjÞ is the
membership function lP : X  X ! ½0; 1, such that [36]:
lPðxi; xjÞ ¼
1
if xi is definitely preferred to xj;
x 2 ð0:5; 1Þ
if xi is slightly preferred to xj;
0:5
if xi and xj are equally preferred;
y 2 ð0; 0:5Þ
if xj is slightly preferred to xi;
0
if xj is definitely preferred to xi:
8
>
>
>
>
>
>
<
>
>
>
>
>
>
:
ð6Þ
In a group with m members, there are m FPRs P1; . . . ; Pm, where Pk ¼ ðpkijÞ for k 2 1; . . . ; m
f
g and i; j 2 1; . . . ; n
f
g. To obtain a
combined FPR, an aggregation rule called Ordered Weighted Average (OWA) [37] [38] is often used. An OWA is deﬁned as:
OWAðp1; . . . ; pmÞ ¼
X
m
k¼1
wkprðkÞ
ð7Þ
where W ¼ ðw1; . . . ; wmÞ 2 ½0; 1m is a list of weights such that Pm
k¼1wk ¼ 1 and ðp1; . . . ; pmÞ is a list of preference values. In
this equation, r : 1; . . . ; m
f
g ! 1; . . . ; m
f
g is a permutation function, such that prðkÞ P prðkþ1Þ for each k 2 1; . . . ; m  1
f
g.
Therefore, pij ¼ OWAðp1ij; . . . ; pmijÞ.
The behaviour of OWA strongly depends on the weight vector. A non-decreasing proportional fuzzy quantiﬁer is proposed
by Chiclana et al. [39] to initialise the weight vector inspired by the behaviour of soft majority. A non-decreasing proportional
fuzzy quantiﬁer can be deﬁned by a membership function as:
lQðyÞ ¼
0
if y < a
ðy  aÞ=ðb  aÞ
if a 6 y 6 b
1
if y > b:
8
>
<
>
:
ð8Þ
Depending on the chosen quantiﬁer Q, the values of a and b are different (see [40]). The weights of the OWA operator can be
calculated as follows [37]:
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
5
 wk ¼ lQð k
mÞ  lQðk  1
m Þ; k 2 1; . . . ; m
½

ð9Þ
If we extend the notation to matrices, then the aggregated FPR P is P ¼ OWAQðP1; . . . ; PmÞ, where the weights of OWAQ are
initialized with the quantiﬁer Q. Another way to obtain the weight vector is to use each group member’s contribution to
the ﬁnal decision, which means how much each member’s opinion inﬂuences the ﬁnal decision. This goal can be achieved
by assigning an importance degree uk 2 ½0; 1 to each individual member in the group ðgk 2 GÞ. The concept of Induced OWA
(IOWA) introduced by Yager et al. [41] relies on reordering the set of values and weighting them using some order-
dependent weights. Later, in [42] importance IOWA (I-IOWA) used the same concept as IOWA and considered the importance
of each preference. Therefore, the I-IOWA is deﬁned as:
I  IOWAQððp1; u1Þ; . . . ; ðpm; umÞÞ ¼
X
m
k¼1
wkprðkÞ
ð10Þ
where uk and pk are the importance degree and preference values of user k, respectively. Q is a non-decreasing proportional
fuzzy quantiﬁer and r is a permutation function where ðurðkÞ P urðkþ1ÞÞ. The weight vectors in 10 can be obtained as:
wk ¼ lQð SðkÞ
SðmÞÞ  lQðSðk  1Þ
SðmÞ Þ; k 2 1; . . . ; m
½

ð11Þ
In this equation, SðkÞ ¼ Pk
l¼1urðkÞ. Extending the notation to matrices, for m individual FPRs and user’s importance degree U,
the aggregated FPR P is:
P ¼ I  IOWAQððP1; u1Þ; . . . ; ðPm; umÞÞ
ð12Þ
4. Proposed personality-based GRS
This section describes our proposed personality-based group recommendation system. The ﬁrst subsection deals with
personality traits and how we used the personality values to develop an inﬂuence graph in order to reach a consensus
between the group members. In Section 4.2 an overview of the proposed method has been described in detail.
4.1. Decision-making based on Personality traits
The reason for using personality traits in group recommendation systems is due to the fact that, when a group of people
want their preferences to converge to a common item, such as a movie to watch together, their individual impact on the ﬁnal
decision often varies depending on their individual personalities. Some people in the group may have a stronger personality,
be more assertive, and have or display a conﬁdent and forceful personality. On the other hand, some people are cooperative
and rely on mutual assistance when working towards a common goal. The more assertive a person is, the greater the effect
they will have on the ﬁnal decision. Psychological tests can be used to help us perceive people’s different personalities. The
Thomas-Kilmann Conﬂict Mode Instrument (TKI) [27] is a test designed to measure the personality of people in conﬂict sit-
uations. Based on this test, ﬁve personality styles can be identiﬁed, namely,
 Competing: a person who wants to be the winner, stands up for their rights and defends the position that they think is
right.
 Collaborating: a person who is concerned with ﬁnding an appealing solution that completely satisﬁes all the group mem-
bers as well as themselves.
 Avoiding: an unassertive and uncooperative individual who postpones an issue to a more suitable time.
 Accommodating: a very generous and selﬂess individual who obeys others.
 Compromising: neither a very cooperative nor a very assertive person who attempts to ﬁnd an expedient, acceptable deci-
sion for both parties
Along the ﬁrst dimension in Fig. 1, we can observe that a person will be assigned a high cooperativeness value if their
personality style is very collaborative and accommodating. Similarly, a person with a very competitive and collaborative per-
sonality style will be given a high assertiveness value. Further explanations of how these values are calculated are provided
in [26]. To mathematically formulate the result of the TKI test, we consider peru to be the personality value of user u and
compute it using the following equation [43]:
peru ¼ 1 þ AssertivenessðuÞ  CooperativenessðuÞ
2
ð13Þ
In this equation, peru is a number in the range of ½0; 1 and 1 will be assigned to a very selﬁsh person and 0 to a very easy-
going person.
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
6
 In [44], social inﬂuence is deﬁned as changing someone’s thoughts, feelings, attitudes, or behavior as a result of interact-
ing with other people or belonging to a group. Therefore, a decision made by a group is the result of the group members’
interaction. From a psychological point of view, this decision strongly depends on the personality of the group members.
To model this inﬂuence, we propose using a graph that represents the different mutual inﬂuences between groups members
(see Fig. 2). In this graph, the nodes are users in the group, and each arc ðgi; gjÞ represents the strength of the inﬂuence of user
j on user i in the group by wij 2 ½0; 1. According to the normalization property, the inﬂuence of peers on each user should
sum to one: 8i 2 1; 2; . . . ; m
f
g; Pm
j¼1wij ¼ 1 (m is the number of users in the group). So, we deﬁne the pairwise inﬂuence of
peers j on i ðwi;jÞ as:
wi;j ¼
1
m1
perj
periþperj
if i – j
1 
X
m
j¼1;j–i
wi;j
if i ¼ j
8
>
>
>
>
<
>
>
>
>
:
ð14Þ
where peri is the personality value of user i as deﬁned in Eq. (13). It is worth noting that the formula is quite intuitive: wi;j is
proportional to
perj
periþperj which reﬂects the inﬂuence j has on i, while the factor
1
m1 acts as a normalization factor.
If we consider G ¼ g1; g2; . . . ; gm
f
g as a group of m members, then yð1Þ
x
¼ ½vg1x;vg2x; . . . ;vgmx will be a vector, representing
the group members’ score for item x (see Eq. (5)). It is assumed that, after the group members interact, their opinions will
change based on the inﬂuence they have on each other. Mathematically, yð2Þ
x
¼ Wyð1Þ
x
where W ¼ ðwi;jÞ [40] is an m  m
weight matrix (see Eq. (14)). By iterating the process, after t iterations, the group members opinion will be:
Fig. 1. TKI personality modes inspired by [43].
Fig. 2. A graph indicating the pairwise inﬂuence of peers in a group of three users.
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
7
 yðtÞ
x ¼ Wyðt1Þ
x
ð15Þ
which is equal to:
yðtÞ
x ¼ Wt1yð1Þ
x
ð16Þ
Since matrix W is a square stochastic matrix, it can be considered as being the transition probability matrix of a Markov
chain with m states and stationary transition probabilities. Based on [17], if a positive integer l exists such that every element
in at least one column of the matrix Wl is positive, then m opinions are expected to converge to the same value. Accordingly,
in our model, as the group members interact more, their opinions will eventually converge to the same value. So, after inﬁ-
nite iterations reaching a consensus is guaranteed:
yð1Þ
x
¼ W1yð1Þ
x
ð17Þ
Since, in reality, interaction between group members over an inﬁnite number of iterations is not feasible, we show how we
obtain the ﬁnal consensus value based on the stationary distribution of the associated Markov chain without applying inﬁ-
nite iterations. Furthermore, in practice, as our simulation results have shown, we can usually approach a consensus value
very rapidly with only a few iterations. According to [45], the stationary distribution of a Markov chain is a vector
p ¼ p1;p2; . . . ;pm
½
 that satisﬁes the following conditions:
1. pW ¼ p
2. 8i 2 1; 2; . . . ; m
f
g : pi P 0
3. Pm
i¼1pi ¼ 1
where W is the transition matrix and m is the number of states (in our model, m is the number of group members). From the
ﬁrst condition ðpW ¼ pÞ, we generate pW1 ¼ p. Therefore, the ﬁnal group score SG;x for item x will be calculated using the
following equation.
SG;x ¼ pyð1Þ
x
ð18Þ
Note: At this point, it is worth mentioning that the above results can be also viewed from a GDM point of view. Therefore, we
provide an alternative proof and interpretation of the convergence results. If we consider Pð1Þ
k
¼ ðpð1Þ
kij Þ as the FPR of the kth
member in the group (in our paper, pkij ¼ r
uij in Eq. (4) or a pairwise preference score in the BPR and MPR model given by
the member k), then, after t iterations, it is possible to compute k’s user FPR as:
pðtÞ
kij ¼ I  IOWAQððpðt1Þ
1ij
; wk1Þ; . . . ; ðpðt1Þ
mij ; wkmÞÞ
ð19Þ
where wki is the pairwise inﬂuence of peers i on k. Extending the notation to matrices, the previous equation changes to:
PðtÞ
k ¼ I  IOWAQððPðt1Þ
1
; wk1Þ; . . . ; Pðt1Þ
m
; wkmÞÞ
ð20Þ
In the Appendix, it is demonstrated that m FPRs converge to the same FPR if there is a positive integer l, so that every element
in at least one column of Wl is positive. The convergence proof relies on demonstrating that our inﬂuence model coincides
with a special case of a GDM model with a particular I-IOWA operator.
In the next section, we will show that by applying this method to the MovieLens dataset, the individual scores of the
group members 8gi 2 G : vgix for every item will change after some iterations and converge to the same group score SG;x. Note
that our consensus model and the corresponding theoretical result can be seen as a special case of the model reported in the
research carried out by one of the authors of this article [40].
4.2. Summary of the proposed method
This section describes the different steps of the proposed method shown in Fig. 3.
In order to be able to use the BPR and MPR methods, the dataset described in Section 5.1 should be changed to implicit
feedback. In fact, both BPR and MPR rely on the fact that an observed item that is not chosen represents a form of negative
implicit feedback (see Section 3). Generally, the implicit feedback is click, purchase, etc.
Here, we follow the same experimental methodology as [25], which considers ratings higher than 3 as the observed pos-
itive feedback.
The personalized item score vui for MFP is calculated using Eq. (5). When it comes to BPR and MPR, vui ¼ xT
uyi where xu and
yi are uth row in matrix X and jth row in matrix Y, respectively. It is worth noting that X and Y are user and item factorized
matrices in the matrix factorization process.
The personality-based weights for the group members have been calculated using Eq. (13) and Eq. (14). Since the users’
personality traits in the aforementioned dataset was not available, we tested the proposed method using synthetic person-
ality numbers ðperuÞ. In this way, we were able to demonstrate the inﬂuence of each group member’s personality on the ﬁnal
item ratings, which could serve as an example of a real-life situation.
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
8
 5. Experimental settings, and evaluation metrics
5.1. Dataset
The dataset for the MFP method was acquired from an online experiment performed by Blèdaitè et al. [14] to collect users’
pairwise preferences. The authors developed an online interface that allows users to compare different movie pairs and enter
their pairwise scores. In this experiment, a total of 2,262 pairwise scores related to 100 movies from the MovieLens dataset
were collected based on feedback from 46 users. In addition, 73,078 movie ratings from 1,128 users in the MovieLens 100 K
dataset were used. These movie ratings were converted into pairwise scores using the equation:
ruij ¼ rui  ruj
ð21Þ
where rui 2 1; 5
½
 is user u’s rating for item i and ruij 2 4; þ4
½
 is user u’s pair score for items i and j, indicating how much user
u prefers i over j. The dataset is summarized in Table 1. The dataset used for the BPR and MPR methods is MovieLens 100 K.
Fig. 3. Steps of the proposed method.
Table 1
Dataset used for MFP method.
Dataset
#Users
#Movies
#Pair-scores
Online interface
46
100
2262
Dataset
#Users
#Movies
#Ratings
MovieLens 100 K
1128
100
73078
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
9
 5.2. Evaluation metrics
In order to check the quality of the proposed method, we used precision, consensus, and fairness. Precision is the fraction
of the number of relevant recommended items (true positives) in relation to the total number of recommended items.
precisionG ¼
#TPG
#ðTPG [ FPGÞ
ð22Þ
where TPG and FPG denote the true positive and false positive, respectively. They are deﬁned as:
TPG ¼
i 2 RGj9g 2 G
suchthat
rg;i – 
and
8u 2 G ru;i –  ! ru;i P h


ð23Þ
FPG ¼
i 2 RGj9g 2 G
suchthat
rg;i < h


ð24Þ
Here, the set of items recommended to group G is denoted RG, while the rating of user u for item i is ru;i. To measure whether
a user likes or dislikes an item, we used a threshold h ¼ 4. Note that the user test-ratings are on a scale from 1 to 5. In Eq. (23)
the dot point () means that the rating is missing (not given by the user).
Consensus is a measure used to evaluate the extent to which the group members reached agreement [46]. In collaborative
ﬁltering, consensus is deﬁned as the pairwise distance between the ﬁnal item-x ratings rðÞ
gi;x of each group member gi (see Eq.
(25)). To normalize the result, the maximum possible rating rmax is used.
consensus ¼ 1 
X
ðgi;gjÞ2G;ði–jÞ
rðÞ
gi;x  rðÞ
gj;x


G
j j  ð G
j j  1Þ=2  rmax
ð25Þ
Fairness can be regarded as a measure that evaluates how much the group members are satisﬁed with the ﬁnal recom-
mended items. In this work, fairness for every recommended item x 2 RG is the fraction of group members g 2 G such that
their rating rg;x for item x is greater than a threshold h ¼ 3:5.
fairnessðG; xÞ ¼
[
g2G
: rg;x > h


G
j j
ð26Þ
6. Results and evaluation
In Section 6.1, we provide some proof of concept experiments to illustrate how consensus is reached in our model. Then,
in Section 6.2 we provide a more thorough evaluation of the performance of our approach on varying group sizes.
6.1. Reaching consensus using personality-based opinion dynamics
In this section, we will provide a few examples that show how our approach can reach consensus using the personality-
based opinion dynamics model presented in Eq. (17). These examples will help to illustrate the effect of personality (Eq. (13))
on the achieved consensus.
6.1.1. Reaching consensus
In
order
to
explain
the
procedure
whereby
consensus
is
reached,
we
generated
six
random
numbers
PER ¼ ½0:53; 0:84; 0:12; 0:41; 0:22; 0:30 2 ½0; 1 as personality values of six individuals in the group, then converted them into
personality-based weights using Eq. (14) (see Table 2). Each row i in the table indicates the weight of inﬂuence of others on
person i ðwijforj ¼ f1; . . . ; mgÞ. It is obvious that the diagonal entries in this matrix wii contain the inﬂuence each individual
has on themselves, and the higher the peri the higher the wii. This matrix W is considered to be a transition matrix of the
Markov chain. According to the DeGroot opinion dynamics model [17], the item rating of the individuals changes after they
Table 2
Personality-based weights.
Person 1
Person 2
Person 3
Person 4
Person 5
Person 6
Person 1
0.62
0.12
0.03
0.08
0.05
0.07
Person 2
0.07
0.74
0.02
0.06
0.04
0.05
Person 3
0.16
0.18
0.23
0.16
0.13
0.14
Person 4
0.11
0.13
0.04
0.56
0.06
0.08
Person 5
0.14
0.16
0.07
0.13
0.38
0.11
Person 6
0.13
0.15
0.05
0.12
0.08
0.47
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
10
 interact due to the inﬂuence these individuals might have on each other, until they eventually agree on a rating after some
iterations (see Fig. 4).Fig. 5 illustrates how, after few iterations, a group of six individuals can reach a consensus. In this
example, per2 ¼ 1:0 indicates a very selﬁsh person and per5 ¼ 0:0 indicates a completely obedient person. As expected,
the ﬁnal item score is very close to person 2’s score and very different from person 5’s score. In this sense, person 5 changed
their opinion dramatically after just one interaction, while in all the interactions between the group members, person 2’s
opinion only changed slightly. Moreover, in the beginning, person 5 and person 6 started with the same opinion, namely,
they both gave the item a score of 0.0. Although they ﬁnally agreed on 3.5 as the item score, it took more time for the less
obedient person to converge to the ﬁnal score. This ﬁgure conﬁrms that adopting the weights according to the pairwise inﬂu-
ence of peers given in Eq. (14) could model the role of group members’ personality traits in making decisions and reaching
consensus.
Item ranking and recommendation We applied the inﬂuence model described in Section 6.1.1 to all of the items in the data-
set in order to deduce the group’s ﬁnal personalized item scores for every item as given by Eq. (5). Then, we sorted them in
descending order and recommended top-10 items to the group. Fig. 6 illustrates an example of convergence to ﬁnal group
personalized item scores in the case of six experts, each with a different initial score for each of the four items. We observe
that, after some iterations, all group members reach consensus on every item score. The higher the ﬁnal item score is, the
better the rank in the ﬁnal order will be. Please note that each of the four colors in the graph corresponds to a different item.
6.2. Evaluation under varying group sizes
In Tables 3–5, the evaluation results for three models, with and without considering members’ personalities, are reported.
The results correspond to the average evaluation of four group sizes: small (i.e.. f8G # U : G
j j 2 ½2; 4g), mid-size (i.e..
f8G # U : G
j j 2 ½5; 8g), large (i.e.. f8G # U : G
j j 2 ½9; 12g) and very large (i.e.. f8G # U : G
j j 2 ½13; 20g). Interestingly, for all
of the models, the consensus is 1, which means that the preference score for the recommended items given by all members
in every group converged to the same number. This is a consequence of the inﬂuence model we adopted. Furthermore, since
assertive members have more inﬂuence on the ﬁnal decision, it seems that taking personality traits into consideration in
item recommendations will result in an unfair recommendation. To investigate this, we adopted 1,000 random conﬁgura-
tions for every group size. Interestingly, our results summarized in the tables show that the precision and fairness in our
models are almost the same with and without taking personality into consideration. Although some members are more
inﬂuential than others, on average, our recommendation model is still able to ﬁnd a set of top items that appeal to all
members.
Moreover, in order to show different personality scenarios and the impact they have on precision and fairness, we
repeated the experiment with a group of four users. The results can be seen in Table 6. According to this table, one possibility
is that all the users have the same personality, for instance, all are strongly assertive (ﬁrst row). Therefore, all personality
values are 1 (peri ¼ 1; 8i 2 G) (see Eq. (13)). Then according to Eq. (14), wi;j ¼ wj;i; 8i; j 2 G. This means that all users have
the same inﬂuence on the ﬁnal decision. The weights will be the same when all users are strongly easy-going or when they
all have equal personality values. Since every user in this scenario has the same impact on the ﬁnal decision, we expect to get
a fair recommendation. The results reported in the table conﬁrm this expected result and maximum fairness (0.7) value is
achieved in this scenario.
The second scenario in the table is when there is a very assertive person and the others are highly easy-going, like a leader
and his followers (second row in the table). In such a situation in the real world, all users would follow the ”leader” and the
ﬁnal decision would be as much closer to the opinion of the leader than to the opinions of the followers. The results reported
in the table conﬁrm this and the lowest fairness (0.6) value is reported in this scenario.
Fig. 4. Reaching consensus in a group of 6 members (15,16,17).
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
11
 We repeated the experiment with different random personalities. The results show slight changes in precision and fair-
ness, on different types of distributions. However, the closer the personality values are to the second model (leader and fol-
lowers), the higher the precision and the lower the fairness.
Figs. 7–9 indicate the precision vs. fairness of three models based on MFP, BPR, and MPR, respectively, in two different
states: a) personality traits are not considered, b) random personalities are assigned to group members. Models were run
in groups of sizes varying from 2 to 20. In the ﬁgures, the sizes of the bubbles are proportional to the group sizes.
Fig. 5. Reaching consensus in a group of six members – per values in the upper right corner of the ﬁgure indicate personality traits of the group members
((15)–(17)).
Fig. 6. Illustration of convergence to group ﬁnal personalized item scores corresponding to four different items for six experts ((15)–(17)).
Table 3
Comparing precision and fairness with and without consider-
ing members’ personalities from the model based on BPR.
Personalities
Group Size
Precision
Fairness
Same
Small
0.68
0.76
Random
Small
0.69
0.76
Same
Mid-size
0.81
0.76
Random
Mid-size
0.82
0.76
Same
Large
0.87
0.76
Random
Large
0.87
0.76
Same
Very large
0.91
0.77
Random
Very large
0.91
0.77
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
12
 Table 4
Comparing precision and fairness with and without consider-
ing members’ personalities from the model based on MPR.
Personalities
Group Size
Precision
Fairness
Same
Small
0.71
0.79
Random
Small
0.72
0.79
Same
Mid-size
0.85
0.79
Random
Mid-size
0.85
0.79
Same
Large
0.90
0.79
Random
Large
0.91
0.79
Same
Very large
0.93
0.80
Random
Very large
0.93
0.80
Table 5
Comparing precision and fairness with and without consider-
ing members’ personalities from the model based on MFP.
Personalities
Group Size
Precision
Fairness
Same
Small
0.74
0.72
Random
Small
0.75
0.70
Same
Mid-size
0.84
0.69
Random
Mid-size
0.84
0.67
Same
Large
0.89
0.68
Random
Large
0.89
0.68
Same
Very large
0.92
0.68
Random
Very large
0.92
0.68
Table 6
Different personalities in a group of four members result in different fairness.
Personality Traits
personality values
Precision
Fairness
1
All assertive (All the same personality)
1.00, 1.00, 1.00, 1.00
0.80
0.70
2
One assertive, rest easy-going
1.00, 0.00, 0.00, 0.00
1.00
0.60
3
Three assertive, one easy-going
1.00, 1.00, 0.00, 1.00
0.80
0.68
4
Four random personalities
0.50, 0.10, 0.30, 0.20
0.80
0.69
5
Four random personalities
0.40, 0.28, 0.65, 0.84
0.80
0.69
6
Four random personalities
0.24, 0.57, 0.97, 0.24
0.80
0.69
7
Four random personalities
0.54, 0.52, 0.48, 0.38
0.80
0.70
8
Four random personalities
0.05, 0.12, 0.50, 0.52
0.81
0.67
9
Four random personalities
0.04, 0.11, 0.47, 0.62
0.79
0.68
10
Four random personalities
0.12, 0.60, 0.51, 0.04
0.78
0.67
11
Two assertive personalities
1.00, 1.00, 0.00, 0.00
0.88
0.63
Fig. 7. Precision vs fairness from the model based on MFP in two different states: a) same personality traits, b) random personality traits (Bubble sizes
indicate the group sizes).
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
13
 7. Managerial implications and discussions
By comparing Figs. 7–9, primarily, we observe that the average fairness in the methods based on BPR and MPR is better
than it is with methods based on MFP. This might be due to the fact that in BPR and MPR based methods, items with positive
feedback have been pushed up and those without feedback pushed down. Therefore, the proposed method could recommend
items that appeal to more users in the group and as a result, the average fairness is higher.
As stated in [47,48], generally, in group recommendation system, fairness decreases as the group size increases, which is
the same trend as observed in Fig. 7. However, in Figs. 8 and 9, we observe that the larger the group size, the fairer the model.
This is because the inﬂuence of the personality score on the outcome is greater for smaller group sizes. For instance, in a
group of two users, the opinion of the stronger personality would dominate the weaker personality. Thus, if the result is
not preferred by the non-dominant user, it would be unfair to 50% of the group members (one of the two), while, in
larger-sized groups, the inﬂuence of the personality has diminished. This is because the outcome is less likely to be domi-
nated by one personality in larger groups as compared with smaller groups. Consequently, the recommended items would
be appealing to more members.
By the discussion above, we have presented new models for group recommendation, in which the pairwise preference is
focused on achieving stronger results. We have also focused on a real-life scenario in which members not only discuss their
preferences, but also inﬂuence each other’s decisions through a factor we call ‘personality’. We have also observed that when
there is a strong desire for fairness, BPR and MPR based models perform better. Similarly, when the group size is large, it is
better not to use the MFP based model.
Fig. 8. Precision vs fairness from the model based on BPR in two different states: a) same personality traits, b) random personality traits (Bubble sizes
indicate the group sizes).
Fig. 9. Precision vs fairness from the model based on MPR in two different states: a) same personality traits, b) random personality traits (Bubble sizes
indicate the group sizes).
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
14
 8. Conclusion
This paper proposes an approach to group recommendations that takes the personalities of group members into account.
In the proposed approach, three pairwise scoring methods (BPR, MPR, and MFP) were used to predict item scores. We also
designed a consensus model based on personality traits that results in a joint group recommendation, and we evaluated the
fairness and precision of the proposed GRS for different member personalities using real-life datasets.
One of the limitations of the proposed method is the way the personality traits are computed. In fact, our method requires
users to ﬁll in a TKI test composed of 30 questions. As performing such a test might not be so practical in real-life scenarios or
for large groups, as future work we would like to investigate other more lightweight alternatives to assess users’ personality
traits. For instance, in [28], personality values were predicted from each user’s social media content, while in [29], a TKI
metaphor was used to replace the TKI test.
Moreover, in our paper, users were considered to have ‘ﬁxed’ personality traits. However, in practice, users may change
their attitude if they start to understand the impact of their personality value. An open research question is whether it is
possible to design an approach that gives incentives to the users to report their personality traits truthfully.
In the future, in addition to the personality traits of the users used in this work (assertiveness and cooperativeness), we
could also take into account the level of curiosity of the individuals. It might be of interest to investigate whether individuals
with a high level of curiosity are more interested in receiving recommendations that are different from their previous expe-
riences, while individuals with a low level of curiosity tend to do the same things they did in the past, with no interest in new
or different areas.
CRediT authorship contribution statement
Roza Abolghasemi: Conceptualization, Methodology, Software, Validation, Formal analysis, Writing - original draft, Writ-
ing - review & editing, Visualization. Paal Engelstad: Conceptualization, Methodology, Writing - review & editing. Enrique
Herrera-Viedma: Conceptualization, Methodology, Supervision, Writing - review & editing, Project administration.
Declaration of Competing Interest
The authors declare that they have no known competing ﬁnancial interests or personal relationships that could have
appeared to inﬂuence the work reported in this paper.
Acknowledgement
The work of the third author is supported by both Spanish State Research Agency Project PID2019-10380RBI00/AEI/10.
13039/501100011033 and Andalusian Government Project P20_00673.
Appendix A. Appendix
In this section, we prove the convergence of the inﬂuence model as a special case of the GDM model with a particular I-
IOWA operator, which works similarly to [40]. In Eq. (8), if we consider a ¼ 0 and b ¼ 1 for the quantiﬁer Q and a positive
integer l exists such that at least one column in the weight matrix has positive elements, then all FPRs converge to the same
FPR.
Combining the deﬁnition of FPR in Eq. (19) with the I-IOWA operator (Eq. (11)) and weight Eq. (10), the elements of FPR P
are deﬁned as:
pðtÞ
k ¼ I  IOWAQððpðt1Þ
1
; wk1Þ; . . . ; ðpðt1Þ
m
; wkmÞÞ
¼
X
m
i¼1
ðlQð SðiÞ
SðmÞÞ  lQðSði1Þ
SðmÞ ÞÞpt1
rðiÞ
ð27Þ
In this equation, SðiÞ ¼ Pi
j¼1wkrðjÞ and r is a permutation function. If we consider a ¼ 0 and b ¼ 1 in quantiﬁer Q, then accord-
ing to Eq. (8), for 0 6 y 6 1;lQðyÞ ¼ y. Since SðiÞ 6 SðmÞ then it is clear that 0 6 SðiÞ
SðmÞ 6 1. Therefore, lQð SðiÞ
SðmÞÞ ¼ SðiÞ
SðmÞ. Substituting
this into the previous equation gives:
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
15
 pðtÞ
k ¼
X
m
i¼1
ð SðiÞ
SðmÞ  Sði1Þ
SðmÞ Þpðt1Þ
rðiÞ
¼
X
m
i¼1
X
i
j¼1
wkrðjÞ
X
i1
j¼1
wkrðjÞ
X
m
j¼1
wkrðjÞ
pðt1Þ
rðiÞ
¼
X
m
i¼1
wkrðiÞ
X
m
j¼1
wkrðjÞ
pðt1Þ
rðiÞ
ð28Þ
According to the paper, Pm
j¼1wkj ¼ 1. Since r is a permutation function, it only changes the order of the items. Therefore,
Pm
j¼1wkrðjÞ ¼ 1, as well. By replacing this in the previous equation, we get:
pðtÞ
k ¼
X
m
i¼1
wkrðiÞpðt1Þ
rðiÞ
¼
X
m
i¼1
wkipðt1Þ
i
ð29Þ
Extending the notation to the matrix W, we can generalize the preceding equation to pðtÞ ¼ Wpðt1Þ ¼ Wt1pð1Þ. As explained
in Section 4.1, W can be considered as the transition probability matrix of a Markov chain with m states and stationary tran-
sition probabilities. Based on [17], if a positive integer l exists such that every element in at least one column of the matrix Wl
is positive, then a value p exists such that m opinions are expected to converge to it (8k 2 1; . . . ; m
f
glimt!1pðtÞ
k ¼ p). This
means that after t iterations, users’ preferences will converge to the same value. Extending the notation to the FPRs, after
t iterations, all FPRs converge to the same FPR.
References
[1] M.A. Hameed, O. Al Jadaan, S. Ramachandram, Collaborative ﬁltering based recommendation system: A survey, Int. J. Comput. Sci. Eng. 4 (5) (2012)
859.
[2] M.J. Pazzani and D. Billsus, Content-based recommendation systems, in The adaptive web. Springer, 2007, pp. 325–341..
[3] S. Bouraga, I. Jureta, S. Faulkner, C. Herssens, Knowledge-based recommendation systems: A survey, Int. J. Intell. Inform. Technol. (IJIIT) 10 (2) (2014) 1–
19.
[4] J. Bobadilla, F. Serradilla, J. Bernal, A new collaborative ﬁltering metric that improves the behavior of recommender systems, Knowl.-Based Syst. 23 (6)
(2010) 520–528.
[5] Y. Park, S. Park, W. Jung, S. Lee, Reversed CF: A fast collaborative ﬁltering algorithm using a k-nearest neighbor graph, Expert Syst. Appl. 42 (8) (2015)
4022–4028.
[6] C.C. Aggarwal, Model-based collaborative ﬁltering, in Recommender systems. Springer, 2016, pp. 71–138..
[7] D. Bokde, S. Girase, D. Mukhopadhyay, Matrix factorization model in collaborative ﬁltering algorithms: A survey, Procedia Comput. Sci. 49 (2015) 136–
146.
[8] N. Jones, A. Brun, A. Boyer, and A. Hamad, An exploratory work in using comparisons instead of ratings, in E-Commerce and Web Technologies - 12th
International Conference, ser. Lecture Notes in Business Information Processing, vol. 85. Springer, 2011, pp. 184–195..
[9] E. Herrera-Viedma, S. Alonso, F. Chiclana, F. Herrera, A consensus model for group decision making with incomplete fuzzy preference relations, IEEE
Trans. Fuzzy Syst. 15 (5) (2007) 863–877.
[10] Y. Dong, Q. Zha, H. Zhang, G. Kou, H. Fujita, F. Chiclana, E. Herrera-Viedma, Consensus reaching in social network group decision making: Research
paradigms and challenges, Knowl.-Based Syst. 162 (2018) 3–13.
[11] J.A. Morente-Molinera, G. Kou, I.J. Pérez, K.E. Samouylov, A. Selamat, E. Herrera-Viedma, A group decision making support system for the web: How to
work in environments with a high number of participants and alternatives, Appl. Soft Comput. 68 (2018) 191–201.
[12] S. Kalloori, F. Ricci, M. Tkalcic, Pairwise preferences based matrix factorization and nearest neighbor recommendation techniques, in: Proceedings of
the 10th ACM Conference on Recommender Systems, Boston, ACM, 2016, pp. 143–146.
[13] S. Kalloori, F. Ricci, R. Gennari, Eliciting pairwise preferences in recommender systems, in: Proceedings of the 12th ACM Conference on Recommender
Systems ACM, 2018, pp. 329–337.
[14] L. Blédaité, F. Ricci, Pairwise preferences elicitation and exploitation for conversational collaborative ﬁltering, in: Proceedings of the 26th ACM
Conference on Hypertext & Social Media ACM, 2015, pp. 231–236.
[15] S. Rendle, C. Freudenthaler, Z. Gantner, L. Schmidt-Thieme, BPR: bayesian personalized ranking from implicit feedback, in UAI 2009, in: Proceedings of
the Twenty-Fifth Conference on Uncertainty in Artiﬁcial Intelligence, 2009, pp. 452–461.
[16] R. Yu, Y. Zhang, Y. Ye, L. Wu, C. Wang, Q. Liu, E. Chen, Multiple pairwise ranking with implicit feedback, in: Proceedings of the 27th ACM International
Conference on Information and Knowledge Management ACM, 2018, pp. 1727–1730.
[17] M.H. DeGroot, Reaching a consensus, J. Am. Stat. Assoc. 69 (345) (1974) 118–121.
[18] C. Bologna, A.C.D. Rosa, A.D. Vivo, M. Gaeta, G. Sansonetti, and V. Viserta, Personality-based recommendation in e-commerce, in Late-Breaking Results,
Project Papers and Workshop Proceedings of the 21st Conference on User Modeling, Adaptation, and Personalization, vol. 997, 2013..
[19] U. Gretzel, N. Mitsche, Y. Hwang, D.R. Fesenmaier, Tell me who you are and I will tell you where to go: Use of travel personalities in destination
recommendation systems, Inform. Technol. Tourism 7 (1) (2004) 3–12.
[20] S. Dhelim, H. Ning, N. Aung, R. Huang, J. Ma, Personality-aware product recommendation system based on user interests mining and metapath
discovery, IEEE Trans. Comput. Soc. Syst. (2020).
[21] A. Tommasel, A. Corbellini, D. Godoy, S.N. Schiafﬁno, Exploring the role of personality traits in followee recommendation, Online Inform. Rev. 39 (6)
(2015) 812–830.
[22] M.A.S.N. Nunes, R. Hu, Personality-based recommender systems: an overview, in Sixth ACM Conference on Recommender Systems. ACM, 2012, pp. 5–
6..
[23] X. Lin, M. Zhang, Y. Zhang, Z. Gu, Y. Liu, S. Ma, Fairness-aware group recommendation with pareto-efﬁciency, in: Proceedings of the Eleventh ACM
Conference on Recommender Systems ACM, 2017, pp. 107–115.
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
16
 [24] Z. Huang, X. Xu, H. Zhu, M. Zhou, An efﬁcient group recommendation model with multiattention-based neural networks, IEEE Trans. Neural Networks
Learn. Syst. 31 (11) (2020) 4461–4474.
[25] W. Pan, L. Chen, GBPR group preference based bayesian personalized ranking for one-class collaborative ﬁltering, in IJCAI 2013, in: Proceedings of the
23rd International Joint Conference on Artiﬁcial Intelligence, 2013, pp. 2691–2697.
[26] J.A. Recio-Garcia, G. Jimenez-Diaz, A.A. Sanchez-Ruiz, B. Diaz-Agudo, Personality aware recommendations to groups, in: Proceedings of the third ACM
conference on Recommender systems, 2009, pp. 325–328.
[27] R.H. Kilmann, K.W. Thomas, Developing a forced-choice measure of conﬂict-handling behavior: The mode instrument, Educat. Psychol. Meas. 37 (2)
(1977) 309–325.
[28] R. Gao, B. Hao, S. Bai, L. Li, A. Li, T. Zhu, Improving user proﬁle with personality traits predicted from social media content, in: Proceedings of the 7th
ACM conference on recommender systems, 2013, pp. 355–358.
[29] L.Q. Sánchez, J.A. Recio-García, B. Díaz-Agudo, Happymovie: A facebook application for recommending movies to groups, in: IEEE 23rd International
Conference on Tools with Artiﬁcial Intelligence, 2011, pp. 239–244.
[30] L.Q. Sánchez, Personality and social trust in group recommendations, in 22nd IEEE International Conference on Tools with Artiﬁcial Intelligence. IEEE
Computer Society, 2010, pp. 121–126..
[31] F. Barile, F. Cervone, and S. Rossi, Evaluating user’s personality and social interactions for groups recommendations, in Proceedings of the 2nd
International Workshop on Decision Making and Recommender Systems, vol. 1533, 2015, pp. 17–20..
[32] P.T. Costa Jr, R.R. McCrae, The Revised NEO Personality Inventory (NEO-PI-R), Sage Publications Inc, 2008.
[33] X. Wang, Y. Liu, J. Lu, F. Xiong, G. Zhang, Trugrc: Trust-aware group recommendation with virtual coordinators, Future Gener. Comput. Syst. 94 (2019)
224–236.
[34] L. Sun, X. Wang, Z. Wang, H. Zhao, W. Zhu, Social-aware video recommendation for online social groups, IEEE Trans. Multimedia 19 (3) (2017) 609–618.
[35] J. Guo, Y. Zhu, A. Li, Q. Wang, W. Han, A social inﬂuence approach for group user modeling in group recommendation systems, IEEE Intell. Syst. 31 (5)
(2016) 40–48.
[36] Y.-M. Wang, Z.-P. Fan, Fuzzy preference relations: Aggregation and weight determination, Comput. Ind. Eng. 53 (1) (2007) 163–172.
[37] R.R. Yager, Families of owa operators, Fuzzy Sets Syst. 59 (2) (1993) 125–148.
[38] J. Malczewski, Ordered weighted averaging with fuzzy quantiﬁers: Gis-based multicriteria evaluation for land-use suitability analysis, Int. J. Appl.
Earth Observ. Geoinform. 8 (4) (2006) 270–277.
[39] F. Chiclana, F. Herrera, E. Herrera-Viedma, Integrating three representation models in fuzzy multipurpose decision making based on fuzzy preference
relations, Fuzzy Sets Syst. 97 (1) (1998) 33–48.
[40] N. Capuano, F. Chiclana, H. Fujita, E. Herrera-Viedma, V. Loia, Fuzzy group decision making with incomplete information guided by social inﬂuence,
IEEE Trans. Fuzzy Syst. 26 (3) (2017) 1704–1718.
[41] R.R. Yager, D.P. Filev, Induced ordered weighted averaging operators, IEEE Trans. Syst., Man, Cybern. Part B (Cybernetics) 29 (2) (1999) 141–150.
[42] F. Chiclana, E. Herrera-Viedma, F. Herrera, S. Alonso, Some induced ordered weighted averaging operators and their use for solving group decision-
making problems based on fuzzy preference relations, Eur. J. Oper. Res. 182 (1) (2007) 383–399.
[43] L. Quijano-Sanchez, J.A. Recio-Garcia, B. Diaz-Agudo, G. Jimenez-Diaz, Social factors in group recommender systems, ACM Transactions on Intelligent
Systems and Technology (TIST) 4 (1) (2013) 1–30.
[44] Q. Liang, X. Liao, J. Liu, A social ties-based approach for group decision-making problems with incomplete additive preference relations, Knowl.-Based
Syst. 119 (2017) 68–86.
[45] E. Seneta, Computing the stationary distribution for inﬁnite markov chains, Linear Algebra and Its Applications 34 (1980) 259–267.
[46] A. Felfernig, L. Boratto, M. Stettinger, M. Tkalcˇicˇ, Group recommender systems: An introduction, Springer, 2018.
[47] M. Kaya, D. Bridge, N. Tintarev, Ensuring fairness in group recommendations by rank-sensitive balancing of relevance, in: Fourteenth ACM Conference
on Recommender Systems, 2020, pp. 101–110.
[48] D. Sacharidis, Top-n group recommendations with fairness, in Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing. ACM, 2019, pp.
1663–1670..
R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al.
Information Sciences 595 (2022) 1–17
17
",https://doi.org/10.1016/j.ins.2022.02.033,doc20,"A personality-aware group recommendation system based on pairwise preferences Roza Abolghasemi a,⇑, Paal Engelstad a, Enrique Herrera-Viedma b,c,⇑, Anis Yazidi a,⇑ a Department of Computer Science, Oslo Metropolitan University, Oslo, Norway b Department of Computer Science and AI, Andalusian Research Institute in Data Science and Computational Intelligence, University of Granada, Granada, Spain c Faculty of Engineering, The School of Computing, Universiti Teknologi Malaysia, Johor Bahru, Malaysia a r t i c l e i n f o Article history: Received 26 April 2021 Received in revised form 9 February 2022 Accepted 18 February 2022 Available online 23 February 2022 Keywords: Group recommendation system Pairwise preferences Group decision-making Personality traits Reaching consensus a b s t r a c t Human personality plays a crucial role in decision-making and it has paramount impor- tance when individuals negotiate with each other to reach a common group decision. Such situations are conceivable, for instance, when a group of individuals want to watch a movie together. It is well known that people inﬂuence each other’s decisions, the more assertive a person is, the more inﬂuence they will have on the ﬁnal decision. In order to obtain a more realistic group recommendation system (GRS), we need to accommodate the assertiveness of the different group members’ personalities. Although pairwise prefer- ences are long-established in group decision-making (GDM), they have received very little attention in the recommendation systems community. Driven by the advantages of pair- wise preferences on ratings in the recommendation systems domain, we have further pur- sued this approach in this paper, however we have done so for GRS. We have devised a three-stage approach to GRS in which we 1) resort to three binary matrix factorization methods, 2) develop an inﬂuence graph that includes assertiveness and cooperativeness as personality traits, and 3) apply an opinion dynamics model in order to reach consensus. We have shown that the ﬁnal opinion is related to the stationary distribution of a Markov chain associated with the inﬂuence graph. Our experimental results demonstrate that our approach results in high precision and fairness.  2022 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license ( 1. Introduction Recommendation Systems (RS) aim to ﬁnd and recommend a set of items to a single user, and are commonly used in var- ious domains, such as movies, music, travel, e-commerce, and so on. While a classic RS tries to recommend a suitable set of items for an individual user based on their preferences, group recommendation systems are concerned with recommending a set of items that appeal to a group of people. There are numerous applications of GRS in real-life settings. Application scenarios for GRS include examples such as a group of friends who want a recommendation for a movie to watch together, passengers in a car who want to listen to the same music while driving, etc. 0020-0255/ 2022 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license ( ⇑Corresponding authors at: Department of Computer Science and Artiﬁcial Intelligence, University of Granada, Granada, Spain (E. Herrera-Viedma) Department of Computer Science, Oslo Metropolitan University, Oslo, Norway (A. Yazidi) (R. Abolghasemi). E-mail addresses: rozaabol@oslomet.no (R. Abolghasemi), viedma@decsai.ugr.es (E. Herrera-Viedma), anisy@oslomet.no (A. Yazidi). Information Sciences 595 (2022) 1–17 Contents lists available at ScienceDirect Information Sciences journal homepage: www.elsevier.com/locate/ins There are different types of recommendation systems: Collaborative Filtering (CF) RS [1], content-based RS [2], demographic-based RS, utility-based RS, knowledge-based RS [3], and hybrid RS, which is a combination of other methods. The CF models have shown promising results as compared to the different recommendation systems. The datasets used in the CF models include hundreds of thousands of item ratings given by users. These ratings are used to compute recommen- dations for target users based on two main methods: 1.) KNN-based CF [4,5], which generates recommendations based on the ratings given by the k most similar users, 2.) Model-based CF [6], which builds the model based on a rating matrix. The most popular model-based CF is Matrix Factorization (MF) [7], which decomposes the rating matrix into a product of two smaller matrices containing latent factors, namely a user matrix, and an item matrix. In matrix factorization, the data are usually the ratings of the items given by the users. However, some authors claim that comparing items or pairwise prefer- ences can yield more accurate preferences than the rating in a predeﬁned scale [8]. For instance, in a normal rating system, if a user gives two movies ﬁve stars, we cannot know which of the two they prefer. For this reason, a predeﬁned rating scale consisting of discrete values is not considered to be very precise. Instead, by using pairwise preferences, two-by-two com- parisons of movies can be made, and thus users’ movie preferences can be better expressed. Although pairwise preferences are long-standing in group decision-making (GDM) [9–11], they have, with a few excep- tions [12–14], received very little attention from the recommendation system community. Driven by the recently reported advantages of pairwise preferences on ratings in the ﬁeld of recommendation systems, in this paper we have further pursued this approach, however we have done so for GRS. In [14], a new RS was introduced which used pairwise preference scores instead of pure rating data. Relying on pairwise preference scores led to better performance in terms of Normalized Discounted Cumulative Gain (NDCG) and better preci- sion than that obtained by the legacy methods based on single item ratings. Among the most popular approaches to matrix factorization based on pairwise preference scores are Bayesian Personalized Ranking (BPR) [15] and Multiple Pairwise Rank- ing (MPR) [16], which formulate the matrix factorization problem as a maximum likelihood estimation problem and use stochastic gradient descent to deduce the latent factors. Pairwise matrix factorization also aims to ﬁnd an embedding of items and users. The advantage of pairwise preference rating methods compared to other single rating methods is that they are more precise and can yield better predictions due to their pairwise comparison nature [12,15,16]. In this paper, we calculated personalized item scores based on the pre- viously mentioned pairwise preference rating methods, and then we computed a ﬁnal group score for each item based on opinion dynamics theory [17]. The weights of the inﬂuence graph were computed from the personality values collected from the TKI test. Finally, according to the stationary distribution of a Markov chain, we have proven that the group members will reach consensus. Moreover, we have provided an alternative proof and interpretation of the convergence results. A brief explanation of the contribution of our work is detailed as follows. We have resorted to opinion dynamics theory (social inﬂuence) in order to model how users inﬂuence each other’s opinions within a group based on defining mutual inﬂu- ence relations derived from the TKI personality test. We prove that the group will reach a consensus under some mild con- ditions on the weight matrix describing mutual inﬂuences. We also show a link between our approach to aggregating user ratings based on opinion dynamics and the widely used I-OWA approach to group decision-making. Another contribution of this paper is that while most of the group recommendation systems use single rating scores, we have used pairwise preferences instead. Using pairwise preferences is known in the literature to provide more precise rec- ommendations due to the derivation of more implicit feedback from users compared to a single rating [12,15,16]. We have also tested our approach by using three pairwise preference ranking approaches and different experimental results have been reported in different scenarios. The rest of this paper is organized as follows. In Section 2, we ﬁrst outline a state-of-the-art review of work where per- sonality has been used for RS and GRS systems. Section 3 explains the three pairwise ranking methods that we adopted to predict the personalized item ranking scores. Moreover, fuzzy preference aggregation is explained in a subsection. We then describe our proposed model for a personality-based group recommendation system in Section 4. Next, Section 5 introduces our experimental settings and evaluation metrics and Section 6 reports our experimental results and our main ﬁndings in light of the existing studies. Finally, Section 7 discusses the ﬁndings further and includes some of their managerial implications. 2. Related work 2.1. Personality-based RS In this section, we focus on the articles concerning personality-based RS and GRS systems. Personality-based RS refers to a class of RS that takes the personality characteristics of a person into account when mak- ing a recommendation. We will ﬁrst provide some examples of studies of the role personality plays in RS for a single user before shedding light on the role personality plays in GRS. The work in [18] concerns recommendations for a single user (as opposed to a group) based on a personality proﬁle derived from information about their professional activities. The role of personality in tourism destination recommendations is highlighted in [19]. This article classiﬁes users based on travel per- sonality categories, which leads to particular travel behavior. To address the recommendation redundancy and cold start problems, Dhelim et al. [20] proposed a personality-aware product RS based on metapath discovery and user interest. R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 2 The proposed method aspires to incorporate the users’ personality traits in the associated items. The main personality theory used in that paper is the Five-Factor Model (FFM), which is based on the following traits: neuroticism, openness to experi- ence, extraversion, agreeableness, and conscientiousness. The work in [21] investigated the role of Twitter users’ personality traits when recommending followers. The role personality plays is often ignored in follower recommendation methods, since most RS systems only use graph topology and user-generated content for this task. For a comprehensive overview of personality-based RS, we refer the reader to [22]. This paper discusses some challenges and future research directions con- cerning this subject. 2.2. Group recommendations Although single-user recommendation systems have received signiﬁcant research attention and have gained a lot of pop- ularity due to their use by Internet giants such as Google, Amazon, and Netﬂix, studies of GRS systems are rather sparse. A GRS aims to provide group recommendations that maximize group members’ satisfaction and minimize inequality among users. GRS systems are usually more complex than single RS systems. For instance, Xiao et al. [23] have shown that solving a GRS problem is usually NP-hard in different semantics. They mapped the group recommendation problem to a multiple objective optimization problem and used Pareto optimality as the criterion for the solution. Recently, remarkable work has been carried out with GRS based on deep learning. For instance, in 2020, Zhenhua et al. proposed a Multi-attention- based Group Recommendation Model (MAGRM) [24], which uses multi-attention-based deep neural network structures to achieve accurate group recommendations. To achieve this goal and to capture the internal social features of groups, a vec- tor representation of group features was used to capture each of the groups’ deep semantic features. Then, group preferences for items were inferred using a neural attention mechanism that takes the preference interaction into account among group members. Group recommendations based on implicit feedback (like or buy) have attracted much attention in services such as Face- book and Amazon. An example of such a recommendation is Group Preference Based Bayesian Personalized Ranking (GBPR) [25], which was introduced by Pan and Chen. There is little research on GRS systems that takes the psychological nature of interactions between group members into account when making a joint decision. One of the ﬁrst prominent studies to address this issue was carried out by Recio- Garcia et al. [26], who proposed a personality-aware group recommendation model based on the Thomas-Kilmann Conﬂict Mode Instrument (TKI) [27]. This test is based on conﬂict management and its effect on personal and group dynamics. According to this test, there are ﬁve different styles of conﬂict management: Competing, Collaborating, Avoiding, Accommo- dating, and Compromising. For a more detailed explanation of these styles, we refer the reader to Section 4.1. In this paper, we have applied the concept of TKI to represent the group members’ personality scores. In practice, our method works well when all the users are able to participate in the TKI test, which is not always a convenient option, espe- cially for large groups. For large groups in social media, however, it is possible to automatically predict the personality traits of users based on their information and activity in social media without requiring a TKI test [28]. The TKI metaphor is another alternative to the TKI test [29] that consists in showing the users two movie characters that have opposite person- alities, and requiring the user to decide which character has a personality that is more similar to theirs. To improve group recommendations, some papers have combined the inﬂuence of personality and social trust. In [30], personality factors were derived from TKI and, based on these factors, a value called Conﬂict Mode Weight (CMW) was cal- culated to reﬂect the inﬂuence of personality on group decisions. Moreover, mutual-trust relationships between group mem- bers were extracted from the underlying social network that connects them. The trust value is based on various network measures, combining their distance in the social network, the number of mutual friends, duration of friendship, shared pic- tures, etc. In [31], agreeableness was used as a personality factor that models altruistic behavior and is based on the Big-Five model [32]. The majority of the studies in the ﬁeld of group recommendation systems consider the opinion of all members equally. While in real life, personality traits inﬂuence the group’s ﬁnal decision signiﬁcantly. Although there are some studies that take the impact users’ personalities have on group decisions into the consideration, they lack a sound theory that quantiﬁes group dynamics. Furthermore, few group recommendation works use pairwise preference. As previously mentioned, it has been shown that, in general, pairwise preference methods in recommendation systems show greater precision than individ- ual rating methods [12,15,16]. At this point, we will mention some notable works that are more relevant to our method. In a group recommendation system, it is very important that group members negotiate with each other to be able to reach a ﬁnal decision. In some works, a coordinator interacts with members to ﬁnd out their opinion. Wang et al. [33] created a virtual user that acted as a coor- dinator who tried to solve the members’ conﬂicts in a group in order to reach a ﬁnal decision. This was done based on the mutual trust that existed between the coordinator and members, and not their personalities. In other words, users’ trust- relations created some sort of personal inﬂuence, which had an impact on the virtual coordinator’s opinion. There are some works in group recommendation systems like [34] which used the results of the TKI method in both social relationships and social behavior, not only to infer a group’s preference, but also to model the tolerance and altruism char- acteristics of the group members. Quijano et al. used personality traits in [29] to design a system called HappyMovie, which recommends movies to Facebook users based on their level of trust derived from the social network and the TKI metaphor, which serves as an alternative to the TKI test. They expressed the adjustment of a user rating based on the ratings of users R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 3 they trust using a simplistic formula where the inﬂuence of other users is inversely proportional to the user personality. The formula is similar to the memory-based approach for recommendation systems, where the authors use trust instead of sim- ilarity between users. The main shortcoming of their method is that it does not take the personalities of other users into account, and only applies the personality of one user at a time. From the literature, we see that the vast majority of works that take personality traits into account by using the TKI test employ some sort of ad hoc formula (heuristics) to ﬁnd the group score. In contrast to all of these works, we rely on the social inﬂuence theory in order to accurately simulate the effect of other users in the ﬁnal group rating. Another personality-aware group recommendation based on the TKI test was proposed by Recio-Garcia et al. [26]. Their recommendation is based on existing collaborative ﬁltering techniques and considers group personality composition. Among the models that used the TKI test, we ﬁnd the work of Guo et.al. [35] who introduced a group recommendation model using individual personality, the impact preference similarities between users, susceptibility, intimacy, and expertise factor have on the ability to improve the recommendation system. Their approach, however, is not suitable for large-scale applications, while our proposed method works well on any group size. Moreover, their work did not use pairwise prefer- ences, and its efﬁciency on heterogeneous data has not been studied. We, however, use random personality values derived from different probability distributions in our work to show the applicability of our model to any type of data. Additionally, although group recommendation systems based on TKI and personality traits have been used in these papers, as noted, none of them applied pairwise preference to ratings in their methods. In our paper, besides using person- ality traits to understand the impact has user on the ﬁnal group decision, we have applied three pairwise preferences meth- ods in order to calculate the item ratings more accurately compared to single-item ratings. 3. Preliminaries 3.1. Item Ranking based on pairwise preferences In this section, we present three popular methods for ranking items based on the pairwise preferences that we have used in our experiments. 3.1.1. Bayesian Personalized Ranking (BPR) Rendle et al. [15] proposed a generic optimization criterion, BPR-OPT, for personalized ranking that converts a user-item matrix into a set of per-user item-to-item matrices and tries to maximize the likelihood of per-user pairwise preferences. To this end, they considered two assumptions: 1. the observed item i by user u is preferred over all unobserved items. 2. The likelihood of pairwise preference of user u is independent of the others. The likelihood of BPR is formulated as: BPR ¼ Y u2U Y i2Iþ u Y j2IIþ u prðrui > rujÞ  1  prðruj > ruiÞ   ð1Þ where the set of all users is represented as U and the set of all items as I. In this equation, Iþ u  I denotes items that received positive feedback from the user and rui is user u’s preference as regards to item i. prðrui > rujÞ is deﬁned as the individual probability that the user u prefers item i over j. This is obtained using the logistic sigmoid function: prðrui > rujjHÞ ¼ 1 1 þ exuijðHÞ ð2Þ where xuijðHÞ is an arbitrary real-value function of the model parameter vector H, which captures the special relationship between user u, item i, and item j from the matrix factorization model [15]. This method solves the matrix factorization problem using stochastic gradient descent with the aim of maximizing the Area Under the Curve (AUC).. 3.1.2. Multiple Pairwise Ranking (MPR) There are two main reasons that can explain unobserved items I  Iþ u in BPR: a user either dislikes the unrated items or has not seen them. To account for these two reasons, Yu et al. [16] introduced a new version of BPR called Multiple Pairwise Ranking (MPR). They divided unobserved items into two subsets I u and I u, then deﬁned three subsets of items I as: Iþ u : The items that user u has seen and expressed positive feedback on. I u : The items that user u has seen but has not expressed feedback on. I u: The uncertain negative items that user u has not seen. MPR states that items for which the user has given positive feedback (Iþ u ) have a higher probability of being preferred by the user than items that the user has not seen (I u). Furthermore, the items that the user has not seen (I u) have a higher prob- ability of being preferred by the user than the items that they have seen but have not provided feedback on (I u ). Considering ruij ¼ rui  ruj, the likelihood of MPR among items can be given as follows: R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 4 MPR ¼ Y u2U Y i;p;p02Iþ u Y j;q02I u ;q2I u prðruij P ruqq0; ruqq0 P rupp0Þ  1  prðruij < ruqq0; ruqq0 < rupp0Þ   8 > < > : ð3Þ where i; p; p0 2 Iþ u , while j; q0 2 I u , and q 2 I u. 3.1.3. Matrix factorization pair-score prediction (MFP) MFP, introduced by Kalloori et al. [12], provides pairwise scores for a set of items that indicate how much a user prefers one item over another. By integrating the pairwise scores, personalized item scores are computed that indicate how much a user prefers an item. Let R be a matrix with elements ruij, where ruij indicates how much a user u prefers item i over item j. MFP factorizes a matrix R into two smaller d-dimensional matrices X and Y such that R ¼ X:Y is the dot product of the two. Here, R 2 Rusers items is the user-item rating matrix, X 2 Rusers latentfactors is user matrix containing the user’s latent factors (xu) and Y 2 Ritems pairitemslatentfactors is the item matrix that contains the latent factors of the pair item (yij). The pair-score of a user u for the pair-item i; j is: r uij ¼ l þ bu þ bij þ xT uyij ð4Þ where l is the average of all pair scores in the matrix R and bu and bij are the baseline parameters for modeling the deviation from the average score for a user u and item pair ði; jÞ, respectively. In MFP, the model parameters are learnt using stochastic gradient descent, which minimizes the prediction error on the training data ðruij  r uijÞ. The result is a matrix R with elements consisting of predicted missing pair scores r uij. The ﬁnal personalized item score vui is calculated according to the following equation: vui ¼ X j2In if g r uij Ij j ð5Þ 3.2. Fuzzy preference aggregation In this section, we focus on preliminaries about GDM and preference aggregation as a method for reaching consensus. A GDM problem consists of a group of m members G ¼ fg1; g2; . . . ; gmg expressing their preferences for a set of items X ¼ fx1; x2; . . . ; xng to reach a common solution. These preferences might be fuzzy preference relations (FPR), which are pair- wise preferences of items. An FPR P on a set of items X can be represented as a matrix P ¼ ðpijÞ, where pij ¼ lPðxi; xjÞ is the membership function lP : X  X ! ½0; 1, such that [36]: lPðxi; xjÞ ¼ 1 if xi is definitely preferred to xj; x 2 ð0:5; 1Þ if xi is slightly preferred to xj; 0:5 if xi and xj are equally preferred; y 2 ð0; 0:5Þ if xj is slightly preferred to xi; 0 if xj is definitely preferred to xi: 8 > > > > > > < > > > > > > : ð6Þ In a group with m members, there are m FPRs P1; . . . ; Pm, where Pk ¼ ðpkijÞ for k 2 1; . . . ; m f g and i; j 2 1; . . . ; n f g. To obtain a combined FPR, an aggregation rule called Ordered Weighted Average (OWA) [37] [38] is often used. An OWA is deﬁned as: OWAðp1; . . . ; pmÞ ¼ X m k¼1 wkprðkÞ ð7Þ where W ¼ ðw1; . . . ; wmÞ 2 ½0; 1m is a list of weights such that Pm k¼1wk ¼ 1 and ðp1; . . . ; pmÞ is a list of preference values. In this equation, r : 1; . . . ; m f g ! 1; . . . ; m f g is a permutation function, such that prðkÞ P prðkþ1Þ for each k 2 1; . . . ; m  1 f g. Therefore, pij ¼ OWAðp1ij; . . . ; pmijÞ. The behaviour of OWA strongly depends on the weight vector. A non-decreasing proportional fuzzy quantiﬁer is proposed by Chiclana et al. [39] to initialise the weight vector inspired by the behaviour of soft majority. A non-decreasing proportional fuzzy quantiﬁer can be deﬁned by a membership function as: lQðyÞ ¼ 0 if y < a ðy  aÞ=ðb  aÞ if a 6 y 6 b 1 if y > b: 8 > < > : ð8Þ Depending on the chosen quantiﬁer Q, the values of a and b are different (see [40]). The weights of the OWA operator can be calculated as follows [37]: R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 5 wk ¼ lQð k mÞ  lQðk  1 m Þ; k 2 1; . . . ; m ½  ð9Þ If we extend the notation to matrices, then the aggregated FPR P is P ¼ OWAQðP1; . . . ; PmÞ, where the weights of OWAQ are initialized with the quantiﬁer Q. Another way to obtain the weight vector is to use each group member’s contribution to the ﬁnal decision, which means how much each member’s opinion inﬂuences the ﬁnal decision. This goal can be achieved by assigning an importance degree uk 2 ½0; 1 to each individual member in the group ðgk 2 GÞ. The concept of Induced OWA (IOWA) introduced by Yager et al. [41] relies on reordering the set of values and weighting them using some order- dependent weights. Later, in [42] importance IOWA (I-IOWA) used the same concept as IOWA and considered the importance of each preference. Therefore, the I-IOWA is deﬁned as: I  IOWAQððp1; u1Þ; . . . ; ðpm; umÞÞ ¼ X m k¼1 wkprðkÞ ð10Þ where uk and pk are the importance degree and preference values of user k, respectively. Q is a non-decreasing proportional fuzzy quantiﬁer and r is a permutation function where ðurðkÞ P urðkþ1ÞÞ. The weight vectors in 10 can be obtained as: wk ¼ lQð SðkÞ SðmÞÞ  lQðSðk  1Þ SðmÞ Þ; k 2 1; . . . ; m ½  ð11Þ In this equation, SðkÞ ¼ Pk l¼1urðkÞ. Extending the notation to matrices, for m individual FPRs and user’s importance degree U, the aggregated FPR P is: P ¼ I  IOWAQððP1; u1Þ; . . . ; ðPm; umÞÞ ð12Þ 4. Proposed personality-based GRS This section describes our proposed personality-based group recommendation system. The ﬁrst subsection deals with personality traits and how we used the personality values to develop an inﬂuence graph in order to reach a consensus between the group members. In Section 4.2 an overview of the proposed method has been described in detail. 4.1. Decision-making based on Personality traits The reason for using personality traits in group recommendation systems is due to the fact that, when a group of people want their preferences to converge to a common item, such as a movie to watch together, their individual impact on the ﬁnal decision often varies depending on their individual personalities. Some people in the group may have a stronger personality, be more assertive, and have or display a conﬁdent and forceful personality. On the other hand, some people are cooperative and rely on mutual assistance when working towards a common goal. The more assertive a person is, the greater the effect they will have on the ﬁnal decision. Psychological tests can be used to help us perceive people’s different personalities. The Thomas-Kilmann Conﬂict Mode Instrument (TKI) [27] is a test designed to measure the personality of people in conﬂict sit- uations. Based on this test, ﬁve personality styles can be identiﬁed, namely,  Competing: a person who wants to be the winner, stands up for their rights and defends the position that they think is right.  Collaborating: a person who is concerned with ﬁnding an appealing solution that completely satisﬁes all the group mem- bers as well as themselves.  Avoiding: an unassertive and uncooperative individual who postpones an issue to a more suitable time.  Accommodating: a very generous and selﬂess individual who obeys others.  Compromising: neither a very cooperative nor a very assertive person who attempts to ﬁnd an expedient, acceptable deci- sion for both parties Along the ﬁrst dimension in Fig. 1, we can observe that a person will be assigned a high cooperativeness value if their personality style is very collaborative and accommodating. Similarly, a person with a very competitive and collaborative per- sonality style will be given a high assertiveness value. Further explanations of how these values are calculated are provided in [26]. To mathematically formulate the result of the TKI test, we consider peru to be the personality value of user u and compute it using the following equation [43]: peru ¼ 1 þ AssertivenessðuÞ  CooperativenessðuÞ 2 ð13Þ In this equation, peru is a number in the range of ½0; 1 and 1 will be assigned to a very selﬁsh person and 0 to a very easy- going person. R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 6 In [44], social inﬂuence is deﬁned as changing someone’s thoughts, feelings, attitudes, or behavior as a result of interact- ing with other people or belonging to a group. Therefore, a decision made by a group is the result of the group members’ interaction. From a psychological point of view, this decision strongly depends on the personality of the group members. To model this inﬂuence, we propose using a graph that represents the different mutual inﬂuences between groups members (see Fig. 2). In this graph, the nodes are users in the group, and each arc ðgi; gjÞ represents the strength of the inﬂuence of user j on user i in the group by wij 2 ½0; 1. According to the normalization property, the inﬂuence of peers on each user should sum to one: 8i 2 1; 2; . . . ; m f g; Pm j¼1wij ¼ 1 (m is the number of users in the group). So, we deﬁne the pairwise inﬂuence of peers j on i ðwi;jÞ as: wi;j ¼ 1 m1 perj periþperj if i – j 1  X m j¼1;j–i wi;j if i ¼ j 8 > > > > < > > > > : ð14Þ where peri is the personality value of user i as deﬁned in Eq. (13). It is worth noting that the formula is quite intuitive: wi;j is proportional to perj periþperj which reﬂects the inﬂuence j has on i, while the factor 1 m1 acts as a normalization factor. If we consider G ¼ g1; g2; . . . ; gm f g as a group of m members, then yð1Þ x ¼ ½vg1x;vg2x; . . . ;vgmx will be a vector, representing the group members’ score for item x (see Eq. (5)). It is assumed that, after the group members interact, their opinions will change based on the inﬂuence they have on each other. Mathematically, yð2Þ x ¼ Wyð1Þ x where W ¼ ðwi;jÞ [40] is an m  m weight matrix (see Eq. (14)). By iterating the process, after t iterations, the group members opinion will be: Fig. 1. TKI personality modes inspired by [43]. Fig. 2. A graph indicating the pairwise inﬂuence of peers in a group of three users. R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 7 yðtÞ x ¼ Wyðt1Þ x ð15Þ which is equal to: yðtÞ x ¼ Wt1yð1Þ x ð16Þ Since matrix W is a square stochastic matrix, it can be considered as being the transition probability matrix of a Markov chain with m states and stationary transition probabilities. Based on [17], if a positive integer l exists such that every element in at least one column of the matrix Wl is positive, then m opinions are expected to converge to the same value. Accordingly, in our model, as the group members interact more, their opinions will eventually converge to the same value. So, after inﬁ- nite iterations reaching a consensus is guaranteed: yð1Þ x ¼ W1yð1Þ x ð17Þ Since, in reality, interaction between group members over an inﬁnite number of iterations is not feasible, we show how we obtain the ﬁnal consensus value based on the stationary distribution of the associated Markov chain without applying inﬁ- nite iterations. Furthermore, in practice, as our simulation results have shown, we can usually approach a consensus value very rapidly with only a few iterations. According to [45], the stationary distribution of a Markov chain is a vector p ¼ p1;p2; . . . ;pm ½  that satisﬁes the following conditions: 1. pW ¼ p 2. 8i 2 1; 2; . . . ; m f g : pi P 0 3. Pm i¼1pi ¼ 1 where W is the transition matrix and m is the number of states (in our model, m is the number of group members). From the ﬁrst condition ðpW ¼ pÞ, we generate pW1 ¼ p. Therefore, the ﬁnal group score SG;x for item x will be calculated using the following equation. SG;x ¼ pyð1Þ x ð18Þ Note: At this point, it is worth mentioning that the above results can be also viewed from a GDM point of view. Therefore, we provide an alternative proof and interpretation of the convergence results. If we consider Pð1Þ k ¼ ðpð1Þ kij Þ as the FPR of the kth member in the group (in our paper, pkij ¼ r uij in Eq. (4) or a pairwise preference score in the BPR and MPR model given by the member k), then, after t iterations, it is possible to compute k’s user FPR as: pðtÞ kij ¼ I  IOWAQððpðt1Þ 1ij ; wk1Þ; . . . ; ðpðt1Þ mij ; wkmÞÞ ð19Þ where wki is the pairwise inﬂuence of peers i on k. Extending the notation to matrices, the previous equation changes to: PðtÞ k ¼ I  IOWAQððPðt1Þ 1 ; wk1Þ; . . . ; Pðt1Þ m ; wkmÞÞ ð20Þ In the Appendix, it is demonstrated that m FPRs converge to the same FPR if there is a positive integer l, so that every element in at least one column of Wl is positive. The convergence proof relies on demonstrating that our inﬂuence model coincides with a special case of a GDM model with a particular I-IOWA operator. In the next section, we will show that by applying this method to the MovieLens dataset, the individual scores of the group members 8gi 2 G : vgix for every item will change after some iterations and converge to the same group score SG;x. Note that our consensus model and the corresponding theoretical result can be seen as a special case of the model reported in the research carried out by one of the authors of this article [40]. 4.2. Summary of the proposed method This section describes the different steps of the proposed method shown in Fig. 3. In order to be able to use the BPR and MPR methods, the dataset described in Section 5.1 should be changed to implicit feedback. In fact, both BPR and MPR rely on the fact that an observed item that is not chosen represents a form of negative implicit feedback (see Section 3). Generally, the implicit feedback is click, purchase, etc. Here, we follow the same experimental methodology as [25], which considers ratings higher than 3 as the observed pos- itive feedback. The personalized item score vui for MFP is calculated using Eq. (5). When it comes to BPR and MPR, vui ¼ xT uyi where xu and yi are uth row in matrix X and jth row in matrix Y, respectively. It is worth noting that X and Y are user and item factorized matrices in the matrix factorization process. The personality-based weights for the group members have been calculated using Eq. (13) and Eq. (14). Since the users’ personality traits in the aforementioned dataset was not available, we tested the proposed method using synthetic person- ality numbers ðperuÞ. In this way, we were able to demonstrate the inﬂuence of each group member’s personality on the ﬁnal item ratings, which could serve as an example of a real-life situation. R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 8 5. Experimental settings, and evaluation metrics 5.1. Dataset The dataset for the MFP method was acquired from an online experiment performed by Blèdaitè et al. [14] to collect users’ pairwise preferences. The authors developed an online interface that allows users to compare different movie pairs and enter their pairwise scores. In this experiment, a total of 2,262 pairwise scores related to 100 movies from the MovieLens dataset were collected based on feedback from 46 users. In addition, 73,078 movie ratings from 1,128 users in the MovieLens 100 K dataset were used. These movie ratings were converted into pairwise scores using the equation: ruij ¼ rui  ruj ð21Þ where rui 2 1; 5 ½  is user u’s rating for item i and ruij 2 4; þ4 ½  is user u’s pair score for items i and j, indicating how much user u prefers i over j. The dataset is summarized in Table 1. The dataset used for the BPR and MPR methods is MovieLens 100 K. Fig. 3. Steps of the proposed method. Table 1 Dataset used for MFP method. Dataset #Users #Movies #Pair-scores Online interface 46 100 2262 Dataset #Users #Movies #Ratings MovieLens 100 K 1128 100 73078 R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 9 5.2. Evaluation metrics In order to check the quality of the proposed method, we used precision, consensus, and fairness. Precision is the fraction of the number of relevant recommended items (true positives) in relation to the total number of recommended items. precisionG ¼ #TPG #ðTPG [ FPGÞ ð22Þ where TPG and FPG denote the true positive and false positive, respectively. They are deﬁned as: TPG ¼ i 2 RGj9g 2 G suchthat rg;i –  and 8u 2 G ru;i –  ! ru;i P h   ð23Þ FPG ¼ i 2 RGj9g 2 G suchthat rg;i < h   ð24Þ Here, the set of items recommended to group G is denoted RG, while the rating of user u for item i is ru;i. To measure whether a user likes or dislikes an item, we used a threshold h ¼ 4. Note that the user test-ratings are on a scale from 1 to 5. In Eq. (23) the dot point () means that the rating is missing (not given by the user). Consensus is a measure used to evaluate the extent to which the group members reached agreement [46]. In collaborative ﬁltering, consensus is deﬁned as the pairwise distance between the ﬁnal item-x ratings rðÞ gi;x of each group member gi (see Eq. (25)). To normalize the result, the maximum possible rating rmax is used. consensus ¼ 1  X ðgi;gjÞ2G;ði–jÞ rðÞ gi;x  rðÞ gj;x   G j j  ð G j j  1Þ=2  rmax ð25Þ Fairness can be regarded as a measure that evaluates how much the group members are satisﬁed with the ﬁnal recom- mended items. In this work, fairness for every recommended item x 2 RG is the fraction of group members g 2 G such that their rating rg;x for item x is greater than a threshold h ¼ 3:5. fairnessðG; xÞ ¼ [ g2G : rg;x > h   G j j ð26Þ 6. Results and evaluation In Section 6.1, we provide some proof of concept experiments to illustrate how consensus is reached in our model. Then, in Section 6.2 we provide a more thorough evaluation of the performance of our approach on varying group sizes. 6.1. Reaching consensus using personality-based opinion dynamics In this section, we will provide a few examples that show how our approach can reach consensus using the personality- based opinion dynamics model presented in Eq. (17). These examples will help to illustrate the effect of personality (Eq. (13)) on the achieved consensus. 6.1.1. Reaching consensus In order to explain the procedure whereby consensus is reached, we generated six random numbers PER ¼ ½0:53; 0:84; 0:12; 0:41; 0:22; 0:30 2 ½0; 1 as personality values of six individuals in the group, then converted them into personality-based weights using Eq. (14) (see Table 2). Each row i in the table indicates the weight of inﬂuence of others on person i ðwijforj ¼ f1; . . . ; mgÞ. It is obvious that the diagonal entries in this matrix wii contain the inﬂuence each individual has on themselves, and the higher the peri the higher the wii. This matrix W is considered to be a transition matrix of the Markov chain. According to the DeGroot opinion dynamics model [17], the item rating of the individuals changes after they Table 2 Personality-based weights. Person 1 Person 2 Person 3 Person 4 Person 5 Person 6 Person 1 0.62 0.12 0.03 0.08 0.05 0.07 Person 2 0.07 0.74 0.02 0.06 0.04 0.05 Person 3 0.16 0.18 0.23 0.16 0.13 0.14 Person 4 0.11 0.13 0.04 0.56 0.06 0.08 Person 5 0.14 0.16 0.07 0.13 0.38 0.11 Person 6 0.13 0.15 0.05 0.12 0.08 0.47 R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 10 interact due to the inﬂuence these individuals might have on each other, until they eventually agree on a rating after some iterations (see Fig. 4).Fig. 5 illustrates how, after few iterations, a group of six individuals can reach a consensus. In this example, per2 ¼ 1:0 indicates a very selﬁsh person and per5 ¼ 0:0 indicates a completely obedient person. As expected, the ﬁnal item score is very close to person 2’s score and very different from person 5’s score. In this sense, person 5 changed their opinion dramatically after just one interaction, while in all the interactions between the group members, person 2’s opinion only changed slightly. Moreover, in the beginning, person 5 and person 6 started with the same opinion, namely, they both gave the item a score of 0.0. Although they ﬁnally agreed on 3.5 as the item score, it took more time for the less obedient person to converge to the ﬁnal score. This ﬁgure conﬁrms that adopting the weights according to the pairwise inﬂu- ence of peers given in Eq. (14) could model the role of group members’ personality traits in making decisions and reaching consensus. Item ranking and recommendation We applied the inﬂuence model described in Section 6.1.1 to all of the items in the data- set in order to deduce the group’s ﬁnal personalized item scores for every item as given by Eq. (5). Then, we sorted them in descending order and recommended top-10 items to the group. Fig. 6 illustrates an example of convergence to ﬁnal group personalized item scores in the case of six experts, each with a different initial score for each of the four items. We observe that, after some iterations, all group members reach consensus on every item score. The higher the ﬁnal item score is, the better the rank in the ﬁnal order will be. Please note that each of the four colors in the graph corresponds to a different item. 6.2. Evaluation under varying group sizes In Tables 3–5, the evaluation results for three models, with and without considering members’ personalities, are reported. The results correspond to the average evaluation of four group sizes: small (i.e.. f8G # U : G j j 2 ½2; 4g), mid-size (i.e.. f8G # U : G j j 2 ½5; 8g), large (i.e.. f8G # U : G j j 2 ½9; 12g) and very large (i.e.. f8G # U : G j j 2 ½13; 20g). Interestingly, for all of the models, the consensus is 1, which means that the preference score for the recommended items given by all members in every group converged to the same number. This is a consequence of the inﬂuence model we adopted. Furthermore, since assertive members have more inﬂuence on the ﬁnal decision, it seems that taking personality traits into consideration in item recommendations will result in an unfair recommendation. To investigate this, we adopted 1,000 random conﬁgura- tions for every group size. Interestingly, our results summarized in the tables show that the precision and fairness in our models are almost the same with and without taking personality into consideration. Although some members are more inﬂuential than others, on average, our recommendation model is still able to ﬁnd a set of top items that appeal to all members. Moreover, in order to show different personality scenarios and the impact they have on precision and fairness, we repeated the experiment with a group of four users. The results can be seen in Table 6. According to this table, one possibility is that all the users have the same personality, for instance, all are strongly assertive (ﬁrst row). Therefore, all personality values are 1 (peri ¼ 1; 8i 2 G) (see Eq. (13)). Then according to Eq. (14), wi;j ¼ wj;i; 8i; j 2 G. This means that all users have the same inﬂuence on the ﬁnal decision. The weights will be the same when all users are strongly easy-going or when they all have equal personality values. Since every user in this scenario has the same impact on the ﬁnal decision, we expect to get a fair recommendation. The results reported in the table conﬁrm this expected result and maximum fairness (0.7) value is achieved in this scenario. The second scenario in the table is when there is a very assertive person and the others are highly easy-going, like a leader and his followers (second row in the table). In such a situation in the real world, all users would follow the ”leader” and the ﬁnal decision would be as much closer to the opinion of the leader than to the opinions of the followers. The results reported in the table conﬁrm this and the lowest fairness (0.6) value is reported in this scenario. Fig. 4. Reaching consensus in a group of 6 members (15,16,17). R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 11 We repeated the experiment with different random personalities. The results show slight changes in precision and fair- ness, on different types of distributions. However, the closer the personality values are to the second model (leader and fol- lowers), the higher the precision and the lower the fairness. Figs. 7–9 indicate the precision vs. fairness of three models based on MFP, BPR, and MPR, respectively, in two different states: a) personality traits are not considered, b) random personalities are assigned to group members. Models were run in groups of sizes varying from 2 to 20. In the ﬁgures, the sizes of the bubbles are proportional to the group sizes. Fig. 5. Reaching consensus in a group of six members – per values in the upper right corner of the ﬁgure indicate personality traits of the group members ((15)–(17)). Fig. 6. Illustration of convergence to group ﬁnal personalized item scores corresponding to four different items for six experts ((15)–(17)). Table 3 Comparing precision and fairness with and without consider- ing members’ personalities from the model based on BPR. Personalities Group Size Precision Fairness Same Small 0.68 0.76 Random Small 0.69 0.76 Same Mid-size 0.81 0.76 Random Mid-size 0.82 0.76 Same Large 0.87 0.76 Random Large 0.87 0.76 Same Very large 0.91 0.77 Random Very large 0.91 0.77 R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 12 Table 4 Comparing precision and fairness with and without consider- ing members’ personalities from the model based on MPR. Personalities Group Size Precision Fairness Same Small 0.71 0.79 Random Small 0.72 0.79 Same Mid-size 0.85 0.79 Random Mid-size 0.85 0.79 Same Large 0.90 0.79 Random Large 0.91 0.79 Same Very large 0.93 0.80 Random Very large 0.93 0.80 Table 5 Comparing precision and fairness with and without consider- ing members’ personalities from the model based on MFP. Personalities Group Size Precision Fairness Same Small 0.74 0.72 Random Small 0.75 0.70 Same Mid-size 0.84 0.69 Random Mid-size 0.84 0.67 Same Large 0.89 0.68 Random Large 0.89 0.68 Same Very large 0.92 0.68 Random Very large 0.92 0.68 Table 6 Different personalities in a group of four members result in different fairness. Personality Traits personality values Precision Fairness 1 All assertive (All the same personality) 1.00, 1.00, 1.00, 1.00 0.80 0.70 2 One assertive, rest easy-going 1.00, 0.00, 0.00, 0.00 1.00 0.60 3 Three assertive, one easy-going 1.00, 1.00, 0.00, 1.00 0.80 0.68 4 Four random personalities 0.50, 0.10, 0.30, 0.20 0.80 0.69 5 Four random personalities 0.40, 0.28, 0.65, 0.84 0.80 0.69 6 Four random personalities 0.24, 0.57, 0.97, 0.24 0.80 0.69 7 Four random personalities 0.54, 0.52, 0.48, 0.38 0.80 0.70 8 Four random personalities 0.05, 0.12, 0.50, 0.52 0.81 0.67 9 Four random personalities 0.04, 0.11, 0.47, 0.62 0.79 0.68 10 Four random personalities 0.12, 0.60, 0.51, 0.04 0.78 0.67 11 Two assertive personalities 1.00, 1.00, 0.00, 0.00 0.88 0.63 Fig. 7. Precision vs fairness from the model based on MFP in two different states: a) same personality traits, b) random personality traits (Bubble sizes indicate the group sizes). R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 13 7. Managerial implications and discussions By comparing Figs. 7–9, primarily, we observe that the average fairness in the methods based on BPR and MPR is better than it is with methods based on MFP. This might be due to the fact that in BPR and MPR based methods, items with positive feedback have been pushed up and those without feedback pushed down. Therefore, the proposed method could recommend items that appeal to more users in the group and as a result, the average fairness is higher. As stated in [47,48], generally, in group recommendation system, fairness decreases as the group size increases, which is the same trend as observed in Fig. 7. However, in Figs. 8 and 9, we observe that the larger the group size, the fairer the model. This is because the inﬂuence of the personality score on the outcome is greater for smaller group sizes. For instance, in a group of two users, the opinion of the stronger personality would dominate the weaker personality. Thus, if the result is not preferred by the non-dominant user, it would be unfair to 50% of the group members (one of the two), while, in larger-sized groups, the inﬂuence of the personality has diminished. This is because the outcome is less likely to be domi- nated by one personality in larger groups as compared with smaller groups. Consequently, the recommended items would be appealing to more members. By the discussion above, we have presented new models for group recommendation, in which the pairwise preference is focused on achieving stronger results. We have also focused on a real-life scenario in which members not only discuss their preferences, but also inﬂuence each other’s decisions through a factor we call ‘personality’. We have also observed that when there is a strong desire for fairness, BPR and MPR based models perform better. Similarly, when the group size is large, it is better not to use the MFP based model. Fig. 8. Precision vs fairness from the model based on BPR in two different states: a) same personality traits, b) random personality traits (Bubble sizes indicate the group sizes). Fig. 9. Precision vs fairness from the model based on MPR in two different states: a) same personality traits, b) random personality traits (Bubble sizes indicate the group sizes). R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 14 8. Conclusion This paper proposes an approach to group recommendations that takes the personalities of group members into account. In the proposed approach, three pairwise scoring methods (BPR, MPR, and MFP) were used to predict item scores. We also designed a consensus model based on personality traits that results in a joint group recommendation, and we evaluated the fairness and precision of the proposed GRS for different member personalities using real-life datasets. One of the limitations of the proposed method is the way the personality traits are computed. In fact, our method requires users to ﬁll in a TKI test composed of 30 questions. As performing such a test might not be so practical in real-life scenarios or for large groups, as future work we would like to investigate other more lightweight alternatives to assess users’ personality traits. For instance, in [28], personality values were predicted from each user’s social media content, while in [29], a TKI metaphor was used to replace the TKI test. Moreover, in our paper, users were considered to have ‘ﬁxed’ personality traits. However, in practice, users may change their attitude if they start to understand the impact of their personality value. An open research question is whether it is possible to design an approach that gives incentives to the users to report their personality traits truthfully. In the future, in addition to the personality traits of the users used in this work (assertiveness and cooperativeness), we could also take into account the level of curiosity of the individuals. It might be of interest to investigate whether individuals with a high level of curiosity are more interested in receiving recommendations that are different from their previous expe- riences, while individuals with a low level of curiosity tend to do the same things they did in the past, with no interest in new or different areas. CRediT authorship contribution statement Roza Abolghasemi: Conceptualization, Methodology, Software, Validation, Formal analysis, Writing - original draft, Writ- ing - review & editing, Visualization. Paal Engelstad: Conceptualization, Methodology, Writing - review & editing. Enrique Herrera-Viedma: Conceptualization, Methodology, Supervision, Writing - review & editing, Project administration. Declaration of Competing Interest The authors declare that they have no known competing ﬁnancial interests or personal relationships that could have appeared to inﬂuence the work reported in this paper. Acknowledgement The work of the third author is supported by both Spanish State Research Agency Project PID2019-10380RBI00/AEI/10. 13039/501100011033 and Andalusian Government Project P20_00673. Appendix A. Appendix In this section, we prove the convergence of the inﬂuence model as a special case of the GDM model with a particular I- IOWA operator, which works similarly to [40]. In Eq. (8), if we consider a ¼ 0 and b ¼ 1 for the quantiﬁer Q and a positive integer l exists such that at least one column in the weight matrix has positive elements, then all FPRs converge to the same FPR. Combining the deﬁnition of FPR in Eq. (19) with the I-IOWA operator (Eq. (11)) and weight Eq. (10), the elements of FPR P are deﬁned as: pðtÞ k ¼ I  IOWAQððpðt1Þ 1 ; wk1Þ; . . . ; ðpðt1Þ m ; wkmÞÞ ¼ X m i¼1 ðlQð SðiÞ SðmÞÞ  lQðSði1Þ SðmÞ ÞÞpt1 rðiÞ ð27Þ In this equation, SðiÞ ¼ Pi j¼1wkrðjÞ and r is a permutation function. If we consider a ¼ 0 and b ¼ 1 in quantiﬁer Q, then accord- ing to Eq. (8), for 0 6 y 6 1;lQðyÞ ¼ y. Since SðiÞ 6 SðmÞ then it is clear that 0 6 SðiÞ SðmÞ 6 1. Therefore, lQð SðiÞ SðmÞÞ ¼ SðiÞ SðmÞ. Substituting this into the previous equation gives: R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 15 pðtÞ k ¼ X m i¼1 ð SðiÞ SðmÞ  Sði1Þ SðmÞ Þpðt1Þ rðiÞ ¼ X m i¼1 X i j¼1 wkrðjÞ X i1 j¼1 wkrðjÞ X m j¼1 wkrðjÞ pðt1Þ rðiÞ ¼ X m i¼1 wkrðiÞ X m j¼1 wkrðjÞ pðt1Þ rðiÞ ð28Þ According to the paper, Pm j¼1wkj ¼ 1. Since r is a permutation function, it only changes the order of the items. Therefore, Pm j¼1wkrðjÞ ¼ 1, as well. By replacing this in the previous equation, we get: pðtÞ k ¼ X m i¼1 wkrðiÞpðt1Þ rðiÞ ¼ X m i¼1 wkipðt1Þ i ð29Þ Extending the notation to the matrix W, we can generalize the preceding equation to pðtÞ ¼ Wpðt1Þ ¼ Wt1pð1Þ. As explained in Section 4.1, W can be considered as the transition probability matrix of a Markov chain with m states and stationary tran- sition probabilities. Based on [17], if a positive integer l exists such that every element in at least one column of the matrix Wl is positive, then a value p exists such that m opinions are expected to converge to it (8k 2 1; . . . ; m f glimt!1pðtÞ k ¼ p). This means that after t iterations, users’ preferences will converge to the same value. Extending the notation to the FPRs, after t iterations, all FPRs converge to the same FPR. References [1] M.A. Hameed, O. Al Jadaan, S. Ramachandram, Collaborative ﬁltering based recommendation system: A survey, Int. J. Comput. Sci. Eng. 4 (5) (2012) 859. [2] M.J. Pazzani and D. Billsus, Content-based recommendation systems, in The adaptive web. Springer, 2007, pp. 325–341.. [3] S. Bouraga, I. Jureta, S. Faulkner, C. Herssens, Knowledge-based recommendation systems: A survey, Int. J. Intell. Inform. Technol. (IJIIT) 10 (2) (2014) 1– 19. [4] J. Bobadilla, F. Serradilla, J. Bernal, A new collaborative ﬁltering metric that improves the behavior of recommender systems, Knowl.-Based Syst. 23 (6) (2010) 520–528. [5] Y. Park, S. Park, W. Jung, S. Lee, Reversed CF: A fast collaborative ﬁltering algorithm using a k-nearest neighbor graph, Expert Syst. Appl. 42 (8) (2015) 4022–4028. [6] C.C. Aggarwal, Model-based collaborative ﬁltering, in Recommender systems. Springer, 2016, pp. 71–138.. [7] D. Bokde, S. Girase, D. Mukhopadhyay, Matrix factorization model in collaborative ﬁltering algorithms: A survey, Procedia Comput. Sci. 49 (2015) 136– 146. [8] N. Jones, A. Brun, A. Boyer, and A. Hamad, An exploratory work in using comparisons instead of ratings, in E-Commerce and Web Technologies - 12th International Conference, ser. Lecture Notes in Business Information Processing, vol. 85. Springer, 2011, pp. 184–195.. [9] E. Herrera-Viedma, S. Alonso, F. Chiclana, F. Herrera, A consensus model for group decision making with incomplete fuzzy preference relations, IEEE Trans. Fuzzy Syst. 15 (5) (2007) 863–877. [10] Y. Dong, Q. Zha, H. Zhang, G. Kou, H. Fujita, F. Chiclana, E. Herrera-Viedma, Consensus reaching in social network group decision making: Research paradigms and challenges, Knowl.-Based Syst. 162 (2018) 3–13. [11] J.A. Morente-Molinera, G. Kou, I.J. Pérez, K.E. Samouylov, A. Selamat, E. Herrera-Viedma, A group decision making support system for the web: How to work in environments with a high number of participants and alternatives, Appl. Soft Comput. 68 (2018) 191–201. [12] S. Kalloori, F. Ricci, M. Tkalcic, Pairwise preferences based matrix factorization and nearest neighbor recommendation techniques, in: Proceedings of the 10th ACM Conference on Recommender Systems, Boston, ACM, 2016, pp. 143–146. [13] S. Kalloori, F. Ricci, R. Gennari, Eliciting pairwise preferences in recommender systems, in: Proceedings of the 12th ACM Conference on Recommender Systems ACM, 2018, pp. 329–337. [14] L. Blédaité, F. Ricci, Pairwise preferences elicitation and exploitation for conversational collaborative ﬁltering, in: Proceedings of the 26th ACM Conference on Hypertext & Social Media ACM, 2015, pp. 231–236. [15] S. Rendle, C. Freudenthaler, Z. Gantner, L. Schmidt-Thieme, BPR: bayesian personalized ranking from implicit feedback, in UAI 2009, in: Proceedings of the Twenty-Fifth Conference on Uncertainty in Artiﬁcial Intelligence, 2009, pp. 452–461. [16] R. Yu, Y. Zhang, Y. Ye, L. Wu, C. Wang, Q. Liu, E. Chen, Multiple pairwise ranking with implicit feedback, in: Proceedings of the 27th ACM International Conference on Information and Knowledge Management ACM, 2018, pp. 1727–1730. [17] M.H. DeGroot, Reaching a consensus, J. Am. Stat. Assoc. 69 (345) (1974) 118–121. [18] C. Bologna, A.C.D. Rosa, A.D. Vivo, M. Gaeta, G. Sansonetti, and V. Viserta, Personality-based recommendation in e-commerce, in Late-Breaking Results, Project Papers and Workshop Proceedings of the 21st Conference on User Modeling, Adaptation, and Personalization, vol. 997, 2013.. [19] U. Gretzel, N. Mitsche, Y. Hwang, D.R. Fesenmaier, Tell me who you are and I will tell you where to go: Use of travel personalities in destination recommendation systems, Inform. Technol. Tourism 7 (1) (2004) 3–12. [20] S. Dhelim, H. Ning, N. Aung, R. Huang, J. Ma, Personality-aware product recommendation system based on user interests mining and metapath discovery, IEEE Trans. Comput. Soc. Syst. (2020). [21] A. Tommasel, A. Corbellini, D. Godoy, S.N. Schiafﬁno, Exploring the role of personality traits in followee recommendation, Online Inform. Rev. 39 (6) (2015) 812–830. [22] M.A.S.N. Nunes, R. Hu, Personality-based recommender systems: an overview, in Sixth ACM Conference on Recommender Systems. ACM, 2012, pp. 5– 6.. [23] X. Lin, M. Zhang, Y. Zhang, Z. Gu, Y. Liu, S. Ma, Fairness-aware group recommendation with pareto-efﬁciency, in: Proceedings of the Eleventh ACM Conference on Recommender Systems ACM, 2017, pp. 107–115. R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 16 [24] Z. Huang, X. Xu, H. Zhu, M. Zhou, An efﬁcient group recommendation model with multiattention-based neural networks, IEEE Trans. Neural Networks Learn. Syst. 31 (11) (2020) 4461–4474. [25] W. Pan, L. Chen, GBPR group preference based bayesian personalized ranking for one-class collaborative ﬁltering, in IJCAI 2013, in: Proceedings of the 23rd International Joint Conference on Artiﬁcial Intelligence, 2013, pp. 2691–2697. [26] J.A. Recio-Garcia, G. Jimenez-Diaz, A.A. Sanchez-Ruiz, B. Diaz-Agudo, Personality aware recommendations to groups, in: Proceedings of the third ACM conference on Recommender systems, 2009, pp. 325–328. [27] R.H. Kilmann, K.W. Thomas, Developing a forced-choice measure of conﬂict-handling behavior: The mode instrument, Educat. Psychol. Meas. 37 (2) (1977) 309–325. [28] R. Gao, B. Hao, S. Bai, L. Li, A. Li, T. Zhu, Improving user proﬁle with personality traits predicted from social media content, in: Proceedings of the 7th ACM conference on recommender systems, 2013, pp. 355–358. [29] L.Q. Sánchez, J.A. Recio-García, B. Díaz-Agudo, Happymovie: A facebook application for recommending movies to groups, in: IEEE 23rd International Conference on Tools with Artiﬁcial Intelligence, 2011, pp. 239–244. [30] L.Q. Sánchez, Personality and social trust in group recommendations, in 22nd IEEE International Conference on Tools with Artiﬁcial Intelligence. IEEE Computer Society, 2010, pp. 121–126.. [31] F. Barile, F. Cervone, and S. Rossi, Evaluating user’s personality and social interactions for groups recommendations, in Proceedings of the 2nd International Workshop on Decision Making and Recommender Systems, vol. 1533, 2015, pp. 17–20.. [32] P.T. Costa Jr, R.R. McCrae, The Revised NEO Personality Inventory (NEO-PI-R), Sage Publications Inc, 2008. [33] X. Wang, Y. Liu, J. Lu, F. Xiong, G. Zhang, Trugrc: Trust-aware group recommendation with virtual coordinators, Future Gener. Comput. Syst. 94 (2019) 224–236. [34] L. Sun, X. Wang, Z. Wang, H. Zhao, W. Zhu, Social-aware video recommendation for online social groups, IEEE Trans. Multimedia 19 (3) (2017) 609–618. [35] J. Guo, Y. Zhu, A. Li, Q. Wang, W. Han, A social inﬂuence approach for group user modeling in group recommendation systems, IEEE Intell. Syst. 31 (5) (2016) 40–48. [36] Y.-M. Wang, Z.-P. Fan, Fuzzy preference relations: Aggregation and weight determination, Comput. Ind. Eng. 53 (1) (2007) 163–172. [37] R.R. Yager, Families of owa operators, Fuzzy Sets Syst. 59 (2) (1993) 125–148. [38] J. Malczewski, Ordered weighted averaging with fuzzy quantiﬁers: Gis-based multicriteria evaluation for land-use suitability analysis, Int. J. Appl. Earth Observ. Geoinform. 8 (4) (2006) 270–277. [39] F. Chiclana, F. Herrera, E. Herrera-Viedma, Integrating three representation models in fuzzy multipurpose decision making based on fuzzy preference relations, Fuzzy Sets Syst. 97 (1) (1998) 33–48. [40] N. Capuano, F. Chiclana, H. Fujita, E. Herrera-Viedma, V. Loia, Fuzzy group decision making with incomplete information guided by social inﬂuence, IEEE Trans. Fuzzy Syst. 26 (3) (2017) 1704–1718. [41] R.R. Yager, D.P. Filev, Induced ordered weighted averaging operators, IEEE Trans. Syst., Man, Cybern. Part B (Cybernetics) 29 (2) (1999) 141–150. [42] F. Chiclana, E. Herrera-Viedma, F. Herrera, S. Alonso, Some induced ordered weighted averaging operators and their use for solving group decision- making problems based on fuzzy preference relations, Eur. J. Oper. Res. 182 (1) (2007) 383–399. [43] L. Quijano-Sanchez, J.A. Recio-Garcia, B. Diaz-Agudo, G. Jimenez-Diaz, Social factors in group recommender systems, ACM Transactions on Intelligent Systems and Technology (TIST) 4 (1) (2013) 1–30. [44] Q. Liang, X. Liao, J. Liu, A social ties-based approach for group decision-making problems with incomplete additive preference relations, Knowl.-Based Syst. 119 (2017) 68–86. [45] E. Seneta, Computing the stationary distribution for inﬁnite markov chains, Linear Algebra and Its Applications 34 (1980) 259–267. [46] A. Felfernig, L. Boratto, M. Stettinger, M. Tkalcˇicˇ, Group recommender systems: An introduction, Springer, 2018. [47] M. Kaya, D. Bridge, N. Tintarev, Ensuring fairness in group recommendations by rank-sensitive balancing of relevance, in: Fourteenth ACM Conference on Recommender Systems, 2020, pp. 101–110. [48] D. Sacharidis, Top-n group recommendations with fairness, in Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing. ACM, 2019, pp. 1663–1670.. R. Abolghasemi, P. Engelstad, E. Herrera-Viedma et al. Information Sciences 595 (2022) 1–17 17"
Graphical representation learning-based approach for automatic classification of electroencephalogram signals in depression,Surbhi Soni and Ayan Seal and Anis Yazidi and Ondrej Krejcar,2022,,145,Computers in Biology and Medicine,article,"Computers in Biology and Medicine 145 (2022) 105420
Available online 2 April 2022
0010-4825/© 2022 Elsevier Ltd. All rights reserved.
Graphical representation learning-based approach for automatic 
classification of electroencephalogram signals in depression 
Surbhi Soni a, Ayan Seal a,*, Anis Yazidi b,d,c, Ondrej Krejcar e,f 
a PDPM Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, 482005, India 
b Department of Computer Science, OsloMet – Oslo Metropolitan University, Oslo, Norway 
c Department of Plastic and Reconstructive Surgery, Oslo University Hospital, Oslo, Norway 
d Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway 
e Center for Basic and Applied Research, Faculty of Informatics and Management, University of Hradec Kralove, Hradecka 1249, Hradec Kralove, 50003, Czech Republic 
f Malaysia Japan International Institute of Technology, Universiti Teknologi Malaysia, Jalan Sultan Yahya Petra, 54100, Kuala Lumpur, Malaysia   
A R T I C L E  I N F O   
Keywords: 
Node2vec 
Electroencephalography 
Graph-level fusion 
Feature-level fusion 
Decision-level fusion 
A B S T R A C T   
Depression is a major depressive disorder characterized by persistent sadness and a sense of worthlessness, as 
well as a loss of interest in pleasurable activities, which leads to a variety of physical and emotional problems. It 
is a worldwide illness that affects millions of people and should be detected at an early stage to prevent negative 
effects on an individual’s life. Electroencephalogram (EEG) is a non-invasive technique for detecting depression 
that analyses brain signals to determine the current mental state of depressed subjects. In this study, we propose a 
method for automatic feature extraction to detect depression by first constructing a graph from the dataset where 
the nodes represent the subjects in the dataset and where the edge weights obtained using the Euclidean distance 
reflect the relationship between them. The Node2vec algorithmic framework is then used to compute feature 
representations for nodes in a graph in the form of node embeddings ensuring that similar nodes in the graph 
remain near in the embedding. These node embeddings act as useful features which can be directly used by 
classification algorithms to determine whether a subject is depressed thus reducing the effort required for manual 
handcrafted feature extraction. To combine the features collected from the multiple channels of the EEG data, the 
method proposes three types of fusion methods: graph-level fusion, feature-level fusion, and decision-level 
fusion. The proposed method is tested on three publicly available datasets with 3, 20, and 128 channels, 
respectively, and compared to five state-of-the-art methods. The results show that the proposed method detects 
depression effectively with a peak accuracy of 0.933 in decision-level fusion, which is the highest among the 
state-of-the-art methods.   
1. Introduction 
Depressive disorders are characterized by sadness, loss of interest or 
pleasure, disturbed sleep or appetite, a sense of guilt and hopelessness, 
poor concentration, and can even lead to suicide in its most severe form. 
According to the World Health Organization, 322 million people 
worldwide suffer from depression [1]. Thus, diagnosing at an early stage 
is critical to protect patients from the severe and irreversible conse­
quences of depression. It has three levels, namely mild, moderate, and 
acute. Doctors diagnose the same based on classification criteria such as 
the Diagnostic and Statistical Manual of Mental Disorders Fifth Edition, 
Beck Depression Inventory, which are a questionnaire containing a set of 
questions score of which determines the level of depression. Also, the 
interactive sessions between the patients and health practitioners play 
an imperative role in detecting depression. However, these sessions may 
not always produce the desired results because it is dependent on the 
practitioner’s knowledge and skill in dealing with depressive patients. 
Moreover, patients suffering from a mental disorder are hesitant to 
admit that they require treatment because they are afraid of being 
labeled mentally ill. As a result, clinical treatment is ineffective in 
assisting depressive patients in receiving proper treatment, resulting in 
further deterioration of the illness and its detrimental effect on an in­
dividual’s life. Alternative approaches to effectively detect and diagnose 
depression are required to overcome the drawbacks of clinical methods. 
The advancement of sensor technology and communication systems has 
resulted in the development of electronic devices that are critical in 
* Corresponding author. 
E-mail address: ayan@iiitdmj.ac.in (A. Seal).  
Contents lists available at ScienceDirect 
Computers in Biology and Medicine 
journal homepage: www.elsevier.com/locate/compbiomed 
https://doi.org/10.1016/j.compbiomed.2022.105420 
Received 30 December 2021; Received in revised form 1 February 2022; Accepted 19 February 2022   
 Computers in Biology and Medicine 145 (2022) 105420
2
monitoring an individual’s health conditions. These devices are 
commonly employed to investigate the activity of the human brain in 
techniques such as electroencephalography (EEG), magnetoencepha­
lography, magnetic resonance imaging, and functional magnetic reso­
nance imaging. Out of these, EEG is a portable and non-invasive 
technique that uses electrodes attached to the scalp to evaluate the 
electrical activity of the brain. This electrical activity is represented on 
EEG recordings by a wavy line, which is then used by physicians and 
scientists to study brain functions and diagnose neurological disorders. 
The electrodes employed are generally useable and are labeled as F, P, O, 
and T, which represent the areas of the brain from which the signals are 
acquired, such as the frontal, parietal, occipital, and temporal lobes. The 
electrode in the midline of the brain is designated as z. 
EEG evaluates the functioning of the brain and is used for diagnosis 
of illness like epileptic seizure [2], Parkinson’s Disease [3], Schizo­
phrenia [4], Stress Detection [5] and Sleep Disorder [6]. The use of EEG 
signals in the detection of depression is a new area of study. It begins 
with the extraction of EEG signals using an electroencephalogram de­
vice, followed by pre-processing, which removes disturbances in EEG 
signals caused by environmental changes, commonly referred to as ar­
tifacts. Following the removal of artifacts, the important features of EEG 
signals are extracted and fed into the classification algorithms, that 
determine whether or not the subject is depressed. Because of nonlinear 
properties EEG data, extracting useful features from it is difficult. The 
features and behaviour of EEG signals cannot be clearly explained using 
time, frequency, or time-frequency analysis. As a result, it’s critical to 
locate stable features and create accurate models with high classification 
performance [7]. Hence the feature extraction procedure entails the 
manual extraction of handcrafted features, which is tedious and 
labor-intensive. The proposed method is based on an automated feature 
extraction process based on graphical representations, which overcomes 
the problem of manual feature extraction. 
1.1. Motivation and contributions 
EEG processing entails signal processing and analysis, which begins 
with the extraction of useful features in the time, frequency, and time- 
frequency domains. This process takes a long time and a lot of human 
effort; additionally, there are no fixed global biomarker features for 
detecting depression. As a result, the work aims to reduce the manual 
effort required for feature extraction and propose an automatic method 
for detecting depressive patients using graphical representation 
learning. The contributions of this work are as follows:  
● The proposed method aims to develop a predictive model that 
automatically extracts features from EEG signals using graph repre­
sentation learning followed by the classification of the depressed and 
healthy subjects using machine learning algorithms.  
● The proposed method develops three novel approaches graph-level, 
feature-level, and decision-level data fusion techniques that provides 
a way to combine the features extracted from each channel of the 
dataset that are obtained after applying the Node2cec algorithm in 
order to obtain a greater predictive power. As far as these fusion 
techniques are concerned, they are mainly exploiting the Node2vec 
algorithmic framework to carry out the data fusion procedure.  
● The Node2vec algorithmic framework is adopted that computes a 
vector representation of a node based on random walks in the graph. 
These vectors corresponding to each node acts as features and is fed 
into machine learning algorithms to classify depressed and healthy 
subjects.  
● The proposed method is executed on three datasets consisting of 3 
channels, 20 channels, and 128 channels respectively. It is then 
compared with five state-of-the-art methods using different evalua­
tion metrics, namely accuracy, sensitivity/recall, specificity, preci­
sion, and ROC curve. Empirical results illustrate that the decision- 
level-based proposed method outranks some existing approaches. 
The paper’s structure is as follows, Section II discusses a literature 
review of existing depression-related works. The proposed work is 
described in detail in Section III, which includes a detailed explanation 
of the Node2vec method. The results and discussions are presented in 
Section IV, followed by the conclusion and future scope in Section V. 
2. Related work 
A substantial amount of research had been conducted in the field of 
depression detection using EEG signals. Hinrikus et al. [8] presented a 
new method for analyzing EEG signals based on the frequency spectrum, 
assuming that beta-band played an important role in the detection of 
depression. The Spectral Asymmetry Index (SASI) was exploited as a 
promising measure to detect depressed patients and was found positive 
in the depressed groups and negative in the healthy group. However, no 
statistically significant features related to hemispherical asymmetry had 
been observed. Grin-Yatsenko et al. [9] employed the Independent 
Component Analysis method to decompose raw EEG data extracted from 
multiple channels into separate components for each eye open and eye 
closed state. Every component’s and each subjects’s frequency band 
power spectra were computed. A comparison of the power spectrum in 
theta, alpha, and beta bands reported exceptionally high alpha power 
during resting state in depressed patients, which was contradicted by 
Stewart et al. [10], whose findings showed low alpha activity in all parts 
of the brain during the depression. Gerard E. Bruder et al. [11] used 
dichotic test demonstrations in which external stimuli such as Fusion 
words and complex tones were delivered and hemisphere Asymmetry 
[12] was computed to classify depressed and healthy subjects. It claimed 
that healthy men had greater hemispheric asymmetry than women in 
perceiving tones and words, whereas depressed patients showed no 
gender difference. Other measures, however, were required to further 
depict the gender differences in depression. Discrete Wavelet transform 
was employed by Puthankattil and Joseph [13] to decompose the EEG 
signal data extracted from 15 depressed and 15 healthy subjects into 
different frequency bands and Parseval’s method [14], was applied to 
calculate energy present at various decomposition levels. The 
two-layered feed-forward neural network with twenty neurons was 
adopted to classify the depressed and healthy subjects based on relative 
wave entropy and signal entropy features. However, it was a preliminary 
study that accepted a small number of features and a conventional al­
gorithm on a smaller dataset. Ahmadlou et al. [15] found the Higuchi 
Fractal Dimension of the left, right, and overall frontal brain beta 
sub-bands effective in distinguishing between depressed and healthy 
subjects when passed to the enhanced probabilistic neural network for 
classification. The research findings were preliminary because it 
experimented on a smaller dataset and additional data was required to 
draw definite conclusions. Bachmann et al. [16] in their findings used 
SASI and HFD to differentiate between depressive and healthy subjects 
and suggested that the HFD alone did not perform well in the frontal 
region. According to Khoa et al. [17], HFD served as a successful 
discriminator in detecting depressed subjects in the parietooccipital 
region and not in the frontal region as it is more sensitive to noise 
because of its high variability. Hosseinifard et al. [18] findings 
concluded that non-linear features such as Correlation Dimension, 
Higuchi Fractal Dimension, and Lyapunov exponent were more effective 
in detecting depression; however, combining both linear and non-linear 
features can improve accuracy even further. Faust [19] findings sug­
gested that the Probabilistic Neural Network was capable of dis­
tinguishing between depressed and healthy subjects based on non-linear 
features such as Sample Entropy, Approximate Entropy, Renyl’s En­
tropy, and Bispectral Entropy. However, the method used redundant 
features as the feature selection technique was not involved and high 
accuracy could have resulted from overfitting. Acharya et al. [20] 
extracted fifteen non-linear features and then ranked them using the 
t-test, and the features with the highest rank in both the left and right 
hemispheres were then combined to form the Depression Diagnostic 
S. Soni et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 145 (2022) 105420
3
Index to effectively discriminate between the depressive and healthy 
groups. However, because there is no proof of the relationship of fea­
tures used as a combination in the index’s formulation, its use is ques­
tionable. Cai et al. [21] suggested a method in which EEG data was 
collected from three electrodes, namely Fp1, Fz, and Fp2 followed by its 
division into alpha, beta, gamma, and theta frequency bands. 
Twenty-seven linear and non-linear features were extracted from these 
frequency bands and fed into four classifiers, namely K-Nearest 
Neighbor (KNN), Support Vector Machine (SVM), Artificial Neural 
Network and, Deep Belief Neural Network (DBNN). The results indicated 
that the absolute power of the beta sub-band combined with the DBNN 
Classifier provided an accuracy of 78.24% in distinguishing between the 
depressed and healthy groups. However, there was a need to increase 
data collection to gradually improve accuracy. Mumtaz et al. [22] 
extracted features from the EEG dataset consisting of nineteen channels 
which included the powers of different frequency bands and alpha 
interhemispheric asymmetry. Receiver Operating Criterion (ROC) [23] 
was used to select the most significant features to avoid irrelevant and 
redundant features and the passed for classification. The findings sug­
gested that alpha interhemispheric asymmetry was the most promising 
characteristic when combined with an SVM Classifier. Liao et al. [24] 
developed a spectral-spatial feature extractor-based method that first 
filters raw multi-channel EEG signals into frequency bands and then 
transformed the original signals from each sub-band to an optimal 
feature vector space by reducing it into a lower-dimensional feature 
vector space. The resulting vector space provided the highest classifi­
cation accuracy with the SVM classifier to distinguish between the 
depressed and healthy subjects. Sharma et al. [25] decomposed raw EEG 
signal from three channels into seven wavelet sub-bands using three 
Channel Orthogonal Wavelet Filter Bank. The logarithmic norm feature 
was extracted from each wavelet sub-band and fed into the support 
vector machine to differentiate between the depressed and healthy 
subjects. Cai et al. [26] conducted a study on 213 subjects, out of which 
92 were depressed and 121 were normal and collected their EEG signals 
through a pervasive three-electrode EEG collector. The signals were 
denoised using a Finite Impulse Response Filter, then features were 
extracted and classified into three categories: time-domain features, 
frequency domain features, and non-linear features. To select the most 
important features the Minimal-Redundancy-Maximum-Relevancy 
method was adopted, and the results indicated that Absolute power 
theta in combination with the KNN classifier produced the best the 
highest accuracy of 76.98% in differentiating between the two groups, 
which was higher than previous studies. Byun et al. [27] used a machine 
learning approach to classify healthy and depressed subjects using Heat 
Rate Variability demonstration to evaluate cardiac autonomic regula­
tion connection with depression. by extracting twenty HRV features—13 
linear, five nonlinear, and two Poincar´e plot from electrocardiogram 
(ECG) recordings of 37 depressed and 41 healthy subjects. The results 
suggested that SVM classifier distinguished the two groups with 74% 
accuracy. Cai et al. [28] presented a multimodal approach by fusing 
features extracted from three-channel EEG signals recorded in response 
to different modalities of positive, negative, and neutral audio stimu­
lation. The extracted features combined with the KNN classifier yielded 
an accuracy of 86.98%. The studies mentioned above demonstrate the 
use of handcrafted features to detect depression that requires a lot of 
human effort. Our proposed method focuses on automated feature 
extraction using graphical representation hence reducing human effort 
in the feature extraction phase. 
3. Methods and materials 
The primary goal of this research is to propose a computer-aided 
automatic method for detecting depression using a graphical approach 
to feature extraction, thereby avoiding the use of handcrafted features 
that require human effort. 
3.1. Feature extraction using Node2vec 
A feature is a collection of variables that, when combined, best 
represent a larger set of data. Feature extraction is directly related to 
dimensionality reduction because it reduces the data set passed for 
training while accurately representing the original data set without 
sacrificing critical information. Node2vec [29] is an algorithmic 
framework that learns feature representation in the form of network 
nodes and is used for feature extraction from EEG data. It learns a node’s 
dense representation in such a way that when it is plotted in a 
low-dimensional space, the nodes near it in that space are also its 
neighbors in the actual formation structure. 
The Node2vec algorithm is divided into three steps. The first step is 
to generate a graph from the dataset, with nodes representing each 
subjects in the dataset and edges representing their Euclidean distance 
from one another. In the second step, for each node in a graph, second- 
order random walks are generated to form a sentence, which is a 
collection of node ids. A corpus, which is a collection of all sentences, is 
created. The third step is to generate node embedding, which is 
accomplished by passing the corpus to the skip-gram model, which 
treats each node id as a unique word/token in a dictionary to calculate 
the embedding vectors for each node, which are represented in a two- 
dimensional plane using the T-SNE algorithm, as shown in Fig. 1. 
These node embeddings serve as important features that will be used for 
classification in the future. Random walks can be thought of as a walker 
traversing the edges of a graph, deciding where to go next, and then 
moving on to the next step. The majority of existing random walk 
measures are based on the first-order Markov model, in which the next 
random walk step is determined solely by the current node. However, it 
is ineffective in many real-world applications, and experimental results 
show that second-order measures outperform their first-order counter­
parts in a variety of applications [30]. As a result, second-order random 
measures are used, which also consider the previously visited node and 
efficiently explore the various neighborhoods of a given node using 
hyper-parameters, which are as follows:  
● Return parameter (m): The parameter controls the likelihood of the 
random walk returning to a previously visited node. The greater the 
value of m, the less likely it is that the random walk will return to a 
node. An m value less than one indicates that the random walk tends 
to return to a previously visited node in order to keep it close to the 
start node.  
● Inout parameter (o): The parameter instructs the random walk to 
explore inward and outward from a specified source node. If o is less 
than one, a random walk will tend to stay close to the source node, 
demonstrating breadth first search behavior. As a result, the random 
walk includes nodes that are close to the source node, encouraging 
inward exploration. If o is greater than one, a random walk will tend 
to move away from the source node, demonstrating depth first search 
behavior to promote outward exploration.  
● Embedding dimension (d): it denotes size of the embedding 
dimension.  
● Length of a random walk (l): it denotes the number of nodes in a 
walk.  
● Walks per node (r): it denotes the number of random walks for each 
node 
The steps involved in the Node2vec algorithm are enlisted below.  
1. Construct an undirected and weighted complete graph G(V, E) from 
the EEG dataset, where V represents the set of nodes that depicts the 
subjects in the dataset and E is the set of weighted edges that reflect 
the distance between two nodes computed using euclidian distance.  
2. Save the weights of all nodes to their neighbors, and calculate the 
transition probabilities between each node and its neighbors with the 
help of hyperparameters m and n using Eqs. (1) and (2), respectively. 
S. Soni et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 145 (2022) 105420
4
πtx = αmo(u, x)⋅wtx
(1)  
αmo(u, x) =
⎧
⎨
⎩
1/m
if
dux = 0
1
if
dux = 1
1/o
if
dux = 2
(2)  
where t and x are nodes Vt and Vx respectively and wt,x reflects the 
weight between the two nodes. Consider Fig. 2 where a random walk 
that has just visited edge (u, t) and now resides at node t. The walk must 
now decide what to do next, so it computes and analyzes the transition 
probabilities πtx on edges (t, x) leading from t. Here dux denotes the 
shortest path distance between nodes u and x.  
3. Obtain random walks for a node u of fixed length l by generating 
nodes ci using Eq. (3). 
P(ci = x|ci−1 = t) =
⎧
⎨
⎩
πtx
Z
if
(i, j)ϵE
0
otherwise
(3)  
where ci denotes the ith node of the random walk starting from source 
node u and c(i−1) is the previously visited node, πtxj is the unnormalized 
transition probability between nodes t and x, and Z denotes the nor­
malizating factor which is a sum of all transition probabilities.  
4. Train all the walk paths of each node using a skip-gram model and 
then obtain the node embeddings of dimension d which act as rele­
vant features. 
3.2. Classification 
In this study, a 10-fold cross-validation technique is adopted to 
evaluate the performance of the proposed method, where the original 
dataset is randomly divided into ten equal-size subsamples [31]. A single 
subsample from the ten is kept as validation data for testing the method, 
while the remaining nine are used as training data. The cross-validation 
process is then performed ten times (the folds), with each of the ten 
subsamples serving as validation data exactly once. The evaluation 
metrics obtained from the 10 folds is then averaged (or otherwise 
combined) to estimate the performance of the proposed method. Here, 
six classifiers, namely Decision Tree (DT), KNN, XGBoost, SVM, Logistic 
Regression (LR), and Linear Discriminant Analysis (LDA), are adopted. 
These classifiers take feature vectors obtained from the validation set 
using the Node2vec algorithm separately and predict categories, namely 
depressed and healthy subjects. The classification algorithms along with 
their various parameters are listed in Table 1. 
3.3. Evaluation metric 
Generally, evaluation metrics are employed to measure the quality of 
a classification model. There are many different types of evaluation 
metrics available to validate a classification model. In this work, we 
note, precision, sensitivity, specificity, f1-score and accuracy measures. 
Precision determines that out of all the depressed predicted, what per­
centage is truly depressed. Sensitivity also called as Recall tells us how 
many subjects in the diseased class are correctly classified. The ability of 
the method to reliably identify subjects without the ailment is known as 
specificity [32]. f1-score which is the harmonic mean of precision, and 
sensitivity [33]. Accuracy is determined by the capacity of the model to 
appropriately distinguish between depressed and healthy subjects. The 
precision, sensitivity, specificity, f1-score and accuracy measures are 
computed using Eqs. (4)–(9), respectively. 
Precision =
TP
TP + FP
(4)  
Sensitivity =
TP
TP + FN
(5) 
Fig. 1. Node2vec method of feature representation.  
Fig. 2. Illustration of the random walk procedure in Node2vec method. The 
walk just transitioned from u to t and is now evaluating its next step out of node 
t to the neighboring nodes x1, x2 and x3. Search biases are shown by edge labels. 
Table 1 
Classification Algorithms with their Parameters.  
Classification_Algorithm 
Parameters 
KNN 
n_neighbors = 7, weight = ”uniform”, algorithm =
”kd_tree”, leaf_size = 30, metric = ”minkowski”, n_jobs =
1 
DT 
criterion = ’gini’, splitter = ”best”, max_depth = ”None”, 
min_samples_split = 2, max_features = None 
XGBoost 
n_estimators = 100, booster = ”gbtree”, learning_rate =
0.1, subsample = 1.0, criterion = ”friedman_mse”, 
min_saples_split = 2 
SVM 
kernel = ”linear”, degree = 3, gamma = ”scale”, 
shrinking = ”True”, tol = 1e-3, cache_size = 200, 
class_weight = ”balanced” 
LR 
penalty = 12, dual = ”false”, tol = 1e-4, fit_intercept =
”True”, intercept_scaling = 1, class_weight = ”balanced” 
LDA 
n_components = 1, solver = ”svd”, shrinkage = ”None”, 
priors = ”None”, tol = 1.0e-4, covariance_estimator =
”None”  
S. Soni et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 145 (2022) 105420
5
Specificity =
TN
TN + FP
(6)  
FPR = 1 −Specificity
(7)  
F1 −score = 2 × Precision × Recall
Precision + Recall
(8)  
Accuracy =
TP + TN
TP + TN + FP + FN
(9)  
where TP, TN, FP, and FN denote true-positive, true-negative, false- 
positive, and false-negative, respectively. In this study, the ROC curve 
is also used to graphically display a classifier’s performance with vary­
ing threshold settings [34]. It is a probability curve and area under curve 
(auc) represents the degree or measure of separability to distinguish 
between classes. The ROC curve is plotted with TP rate (TPR) on the 
y-axis and FP rate (FPR) on the x-axis. The higher the auc, the better the 
model distinguish between subjects with and without the disease. 
3.4. Dataset description 
3.4.1. Dataset 1 
The dataset used in the experiment is borrowed from a Multi-modal 
Open Dataset for Mental-disorder Analysis (MODMA) [35] which is 
openly available for depression analysis. The EEG signals were collected 
using a three-electrode Pervasive EEG collector at a frequency of 250 Hz. 
The EEG signals of 55 subjects were captured, out of which 23 were 
suffering from depression and the rest 33 were healthy subjects. The 
signals were collected from the pre-frontal part of the brain by placing 
three electrodes on the scalp at locations, namely Fp1, Fpz, and Fp3 
based on a 10–20 system of electrode placement. 
3.4.2. Dataset 2 
The second dataset considered in this paper is taken from paper [36] 
which consists of EEG data signals of 33 subjects for 9 min at a resting 
state, out of which 15 subjects were depressed and 18 are healthy. The 
EEG data were collected using 20 electrodes at a frequency of 512 Hz. 
During the recording 0.1-Hz, high-pass filter, 100-Hz low-pass filter, and 
50-Hz notch filter was employed to remove low-frequency noise and 
irrelevant baseline noise from the recorded data. 
3.4.3. Dataset 3 
The third dataset is also borrowed from MODMA that consists of an 
EEG recording of 53 subjects, out of which 24 subjects were depressed 
patients, out of which 13 were males and 11 were females, and 29 
subjects were healthy, out of which 20 were males and 9 were females. 
The EEG signals were recorded using 128-channel HydroCel Geodesic 
Sensor Net (Electrical Geodesics Inc., Oregon Eugene, USA) and Net 
Station acquisition software at a sampling frequency of 256-Hz. To 
maintain good contact the impedance of the electrodes was checked and 
kept below 50 Kilo Ohms. 
It should be noted that noise contained in EEG signals hinders 
increasing the classification accuracy of a machine learning algorithm to 
some extent, hence pre-processing step is required. Although many 
denoising techniques have been developed in previous studies [37,38], 
however the pre-processed versions of the raw datasets are already 
available publicly. Three such pre-processed datasets are considered for 
this study. Thus, no pre-processing step is required separately. The 
pre-processing steps widely used in the field of neuroscience permit to 
remove noise which is commonly known as artifact. There are mainly 
two types of artifacts: physiological and extra-physiological. Physio­
logical are mainly related to movement artifacts and blinking artifacts. 
Extra-physiological are related mainly to the equipment and interfer­
ence from the environment. However, how the pre-processing had been 
carried out is beyond the scope of the study. The interested readers are 
referred to Refs. [35,36] to know more about the pre-processing step. In 
addition, the subjects were subjected to a clinical test assisted by pro­
fessional psychologists to complete a preliminary judgment of depres­
sion by filling out a Patient Health Questionnaire (PHQ-9). The 
questionnaire consisted of 9 questions used for diagnosis, screening, and 
monitoring the severity of depression. It is based on Diagnostic and 
Statistical Manual of Mental Disorders, fourth edition (DSM-IV) criteria, 
with questions designed to detect symptoms of depression that have 
lasted at least two weeks. Based on it, a score known as the PHQ-9 score 
is assigned to each patient, which is employed to determine whether or 
not a subject is depressed. PHQ-9’s sensitivity and specificity for iden­
tifying depressed patients have been reported to be 86.0% percent and 
91.1% percent, respectively [39]. 
3.5. Fusion methods 
Node2vec is used to extract relevant features from a dataset that will 
best represent it in a reduced dimension, as previously discussed. Three 
different types of fusion methods have been proposed at the graph, 
feature and decision levels described as follows: 
3.5.1. Graph-level fusion 
Graph-level fusion occurs immediately following the first step of 
graph construction as displayed in Fig. 3 (Appendix). In the first step, for 
each channel, a complete graph is created in which each node represents 
a subject in a dataset and the edge weight represents the euclidian dis­
tance between them. As a result, if the dataset contains n channels, 
namely C1, C2, C3 … Cn, then n graphs that is G1, G2, G3 … Gn are 
generated each of which contains p(p−1)
2 
edges where p is the total number 
of subjects in the dataset. The graph-level fusion method works by 
concatenating the graphs G1, G2, G3 … Gn and then constructing the final 
graph where each edge is computed using Eq. (10). 
sq =
∑n
i=1 wiq
(10)  
Here, q denotes the total number of edges present in the graph and sq 
denotes a specific edge of the final graph. Consider if each of the com­
plete graphs G1, G2, G3 … Gn consists of four nodes then a total of six 
edges are generated then the concatenated final graph will also contain 
four nodes and six edges, namely s1, s2, s3, s4, s5 and s6 whose value is 
computed using Eq. (10). It then generates a second order random walk 
for each node in the final graph, resulting in the creation of a corpus 
trained by the skip-gram model to obtain the embedding for each node 
in a two-dimensional space using the t-SNE algorithm [40]. These node 
embeddings of size size n × d act as feature vectors and are then passed 
to the classification algorithms to distinguish between depressed and 
healthy subjects. 
3.5.2. Feature-level fusion 
After the step of node embedding generation, the feature-level fusion 
is performed as shown in Fig. 4 (Appendix). After constructing n graphs, 
namely G1, G2, G3 … Gn from n different channels that is C1, C2, C3 … Cn, 
random walks for each node are generated to form a corpus, which is 
then trained by the skip-gram model to generate node embeddings for 
each channel, namely F1, F2, F3 … Fn, that act as feature vectors 
embedded in a two-dimensional space. The feature vectors generated by 
each channel are then combined to form the final set of feature vectors, 
which is called feature-level fusion. These feature vectors are of size n ×
d which are then fed into different classification algorithms, that cate­
gorize subjects as depressed or healthy. The size of d is taken to be 128. 
3.5.3. Decision-level fusion 
Another type of feature combination method used at the output level 
is decision level fusion as displayed in Fig. 3. After constructing n graphs, 
namely G1, G2, G3 … Gn from n different channels that is C1, C2, C3 … Cn, 
random walks for each node are generated to form a corpus, which is 
S. Soni et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 145 (2022) 105420
6
then trained by the skip-gram model to generate node embeddings for 
each channel, namely F1, F2, F3 … Fn, that act as feature vectors 
embedded in a two-dimensional space. These feature vectors of size size 
n × d are then passed to the classification algorithms to generate pre­
dictions P1, P2, P3 … Pn by dividing the feature vectors into training and 
testing. It compares the classifier’s prediction decision in classifying the 
depressed and healthy groups for each channel and then makes the 
decision to give the final predicted output based on the Majority func­
tion. It is the Boolean function that evaluates to false when half or more 
of the arguments are false and true otherwise, i.e. the function’s value 
equals the value of the majority of the inputs. We can use the (real- 
valued) formula to represent depressed groups as 1 and healthy groups 
as 0 as shown in Eq. (11). 
Fig. 3. Block diagram for decision-level fusion.  
S. Soni et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 145 (2022) 105420
7
(p1….pn) = Majority(p1….pn) = ⌊1
2 +
( ∑n
i=1pi
)
−
1
2
n
⌋
(11) 
When the number of arguments n is even, the “1/2” in the formula 
breaks ties in favor of zeros otherwise the function breaks ties in favour 
of ones. 
4. Experimental results and discussions 
4.1. Experimental settings 
The Keras framework and Google Colab platform have been used for 
the implementation of the experiment in this study. Python 3.8.1 lan­
guage is employed for the implementation task using GPU RAM of 16 
GB, System RAM of 15 GB, Intel(R) 2.30 GHz CPU, Tesla P100-PCIE 
Graphic Processor, and GDDR5X memory type. 
4.2. Computational protocol 
The proposed method’s classification report is compared to three 
recent DL-based models and three machine learning approaches, 
●AchLSTM: Automated depression detection using deep representa­
tion and sequence learning with EEG signals [41].  
● AchCNN: Automated EEG-based screening of depression using deep 
CNN [42]. 
●DeprNet:A deep convolution neural network framework for detect­
ing depression using EEG [36]. 
●CaiH-KNN1: A pervasive approach to EEG-based depression detec­
tion [26]. 
●CaiH-KNN2:Feature-Level fusion approaches for depression recog­
nition based on multimodal EEG data [43].  
● CaiH-DBN Pervasive EEG diagnosis of depression using Deep Belief 
Network with three-electrodes EEG collector [21]. 
We provide meaningful names because the scholars have not used 
any names to refer for their works. These state-of-the-art methods are 
implemented on the above-said three datasets. The above state-of-the- 
art methods are implemented as they are in the presented papers. The 
detailed description of these are beyond the scope of this study. The 
interested readers can refer to Refs. [41,42]. [26,36,43], and [21] to 
know about these methods in detail. 
4.3. Results 
Node2vec is a simple, scalable, and successful technique for learning 
low-dimensional embeddings for nodes in a graph. The first step to 
implement the node2vec algorithm is the generation of a graph from the 
dataset. where the nodes of the graph represent the subjects present in 
the dataset and the edges between them represent the euclidian distance 
between them. Since the EEG data is in the form of a NumPy array hence 
it is feasible to determine the euclidian distance between them. After the 
formation of the complete graph, the algorithm creates sentences from 
this graph which is a list of node ids. Hence a collection of all sentences 
called the corpus is generated using four parameters: l, r, m, and o. The 
value of d here is taken as 128. The values of the parameters taken in the 
experiment are reflected in Table 2. Finally, the corpus is fed to the skip- 
gram model which gives a set of feature vectors in a two-dimensional 
plane where the blue point reflects healthy subjects and red points 
represents the depressed subjects. 
Since dataset 1 includes 55 subjects hence, a complete graph with 55 
nodes and 1540 edges is generated. Because the length of the random 
walks in our case is set to 10, 550 biased random walks are generated 
using the parameters m and n. The corpus of 550 random walks is then 
fed into the skip-gram model, which produces features in the form of 
node vectors of size 55 × 128 embedded in a two-dimensional plane. 
In the case of dataset 2, the complete graph consists of 33 nodes and 
551 edges. Because each node generates ten random walks, a total of 330 
random walks are generated and fed to the skip-gram model, which 
generates feature vectors of size 33 × 128 embedded in a two- 
dimensional plane. 
Similarly dataset 3 contains 53 subjects, with a complete graph of 53 
nodes and 1431 edges. In this case, 530 biased random walks are 
generated and fed into the skip-gram model, which generates feature 
vectors of size 53 × 128 embedded in a two-dimensional plane. 
4.3.1. Graph-level fusion results 
As previously stated, graph-level fusion is carried out by concate­
nating the graphs obtained from the n channels and then using the 
Node2vec algorithm to obtain the feature vectors from the concatenated 
graph. The obtained feature vectors are then fed into the classification 
algorithms, which classifies the depressed and healthy subjects. As a 
result, three, twenty, and one twenty-eight graphs will be produced from 
datasets 1, 2 and 3 respectively. In case of dataset 1, the edges of three 
graphs are concatenated to form a final graph, on which the Node2vec 
algorithm is applied to generate a final set of features. Similarly, in the 
dataset 2, the edges of twenty graphs are concatenated to generate a 
feature set, and in the dataset 3, the edges of one twenty-eight graphs are 
concatenated to generate a feature set. The classification algorithms is 
then applied over the feature set to distinguish the healthy and 
depressed subjects. 
In dataset 1, the result of the graph-level fusion is reported in Table 3. 
Among the five classification algorithms applied on the feature vectors 
which is obtained as a result of the Node2vec algorithm, the KNN 
classifier gives the highest accuracy of 0.785 in classifying the depressed 
and healthy subjects. 
Apart from the accuracy metric, the auc metric is also taken into 
consideration to determine the performance of the proposed algorithm 
in distinguishing between depressed and healthy subjects. The KNN al­
gorithm achieves the greatest auc of 0.875, which is the highest among 
all classifiers in dataset 1 as displayed in Fig. 4. 
Similarly, for dataset 2, out of the five classifiers, the KNN algorithm 
gives the highest accuracy of 0.928 in classifying depressed and healthy 
subjects as noted in Table 4. 
In dataset 2, the ROC curve is plotted and observed that the KNN 
algorithm provides the highest auc of 0.962 which is the highest among 
all the algorithms as shown in Fig. 5. 
In the dataset 3, on classifying the feature vectors that are obtained 
by applying Node2vec algorithm on the graph generated as a result of 
graph-level fusion when passed to five classification algorithms, the 
KNN algorithm achieves the highest accuracy of 0.857 among all the 
different classifiers as noted in Table 5. 
Table 2 
Parameters table.  
Parameters 
Values 
No of random walks (r) 
10 
length of a random walk (l) 
100 
Return Parameter (m) 
0.5 
In out Parameter (o) 
2.0  
Table 3 
Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 1 for graph- 
level fusion.  
Algorithm 
Precision 
Sensitivity 
Specificity 
F1-score 
Accuracy 
KNN 
0.743 
0.754 
0.782 
0.748 
0.785 
SVM 
0.612 
0.632 
0.629 
0.621 
0.647 
LR 
0.723 
0.750 
0.672 
0.734 
0.688 
LDA 
0.675 
0.720 
0.687 
0.624 
0.705 
XGBoost 
0.613 
0.637 
0.625 
0.624 
0.647 
DT 
0.698 
0.688 
0.673 
0.692 
0.667  
S. Soni et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 145 (2022) 105420
8
In dataset 3, the ROC curve is plotted and observed that the KNN 
algorithm provides auc of 0.875 which is the highest among all the al­
gorithms as displayed in Fig. 6. 
4.3.2. Feature-level fusion results 
As stated above in feature level fusion, the EEG signals extracted 
from different channels are passed individually to the Node2vec algo­
rithm which provides the feature vectors of each channel embedded in a 
two-dimensional plane, which is then combined and passed to the 
classification algorithms.In the case of dataset 1, the feature vectors are 
obtained by combining the features of three channels are then fed into 
classification algorithms to differentiate between the depressed and 
healthy subjects. The results show that KNN outperforms the classifi­
cation with the highest accuracy of 0.777 among the five algorithms 
used in the methodology as described in Table 6. 
The ROC curve is plotted for feature-level fusion in the case of 
dataset 1 using different machine learning algorithms KNN algorithm 
provides the highest auc of 0.742 among all the other classification al­
gorithms used in the proposed methodology as shown in Fig. 7. 
For the dataset 2, the feature vectors are obtained by combining the 
feature vectors generated from the twenty channels when passed to the 
Node2vec algorithm which are then fed to the classification algorithms. 
The results show that among the five algorithms used in the method­
ology, KNN performs better with the highest accuracy of 0.909, as re­
ported in Table 7. 
The ROC curve plotted for feature level fusion in the case of the 
dataset 2 using classification algorithms provides the highest auc of 
0.944 in the case of the LR algorithm among all the other algorithms as 
Fig. 4. ROC curve of dataset 1 for graph-level fusion.  
Table 4 
Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 2 for graph- 
level fusion.  
Algorithm 
Precision 
Sensitivity 
Specificity 
F1-score 
Accuracy 
KNN 
0.912 
0.903 
0.923 
0.907 
0.928 
SVM 
0.866 
0.870 
0.910 
0.867 
0.866 
LR 
0.857 
0/860 
0.847 
0.858 
0.837 
LDA 
0.713 
0.723 
0.730 
0.717 
0.733 
XGBoost 
0.767 
0.790 
0.730 
0.778 
0.823 
DT 
0.663 
0.686 
0.678 
0.674 
0.666  
Fig. 5. ROC curve dataset 2 for graph-level fusion.  
Table 5 
Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 3 for graph- 
level fusion.  
Algorithm 
Precision 
Sensitivity 
Specificity 
F1-score 
Accuracy 
KNN 
0.822 
0.862 
0.832 
0.841 
0.857 
SVM 
0.817 
0.823 
0.802 
0.819 
0.833 
LR 
0.634 
0.656 
0.602 
0.644 
0.625 
LDA 
0.677 
0.687 
0.632 
0.681 
0.668 
XGBoost 
0.666 
0.682 
0.622 
0.673 
0.666 
DT 
0.666 
0.672 
0.612 
0.668 
0.625  
Fig. 6. ROC curve of dataset 3 for graph-level fusion.  
S. Soni et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 145 (2022) 105420
9
displayed in Fig. 8. 
In the case of dataset 3, the feature vectors obtained by combining 
the feature vectors of one twenty-eight channels generated by passing 
the channels individually to the Node2vec algorithm are then passed to 
the classification algorithms to distinguish depressed and healthy sub­
jects. Out of the five classification algorithms, the KNN algorithm ach­
ieves the highest accuracy of 0.833 as described in Table 8. 
The ROC curve is plotted for feature-level fusion in the case of 
dataset 3. The KNN algorithm provides the highest auc of 0.944 among 
all the other algorithms, as shown in Fig. 9. 
4.3.3. Decision-level fusion results 
As previously stated, decision-level fusion is similar to feature-level 
fusion with the exception of one additional step. The channels of the 
EEG dataset were individually passed to the Node2vec algorithm in this 
Table 6 
Precision, Sensitivity, Specificity, f1-scor, and Accuracy in dataset 1 for feature- 
level fusion.  
Algorithm 
Precision 
Sensitivity 
Specificity 
F1-score 
Accuracy 
KNN 
0.776 
0.783 
0.792 
0.779 
0.777 
SVM 
0.622 
0.603 
0.643 
0.612 
0.666 
LR 
0.678 
0.665 
0.703 
0.671 
0.683 
LDA 
0.613 
0.673 
0.653 
0.641 
0.636 
XGBoost 
0.556 
0.543 
0.579 
0.549 
0.555 
DT 
0.524 
0.533 
0.563 
0.528 
0.575  
Fig. 7. ROC curve of dataset 1 for feature-level fusion.  
Table 7 
Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 2 for 
feature-level fusion.  
Algorithm 
Precision 
Sensitivity 
Specificity 
F1-score 
Accuracy 
KNN 
0.875 
0.890 
0.888 
0.882 
0.909 
SVM 
0.788 
0.777 
0.874 
0.782 
0.800 
LR 
0.822 
0.833 
0.876 
0.827 
0.908 
LDA 
0.755 
0.733 
0.789 
0.743 
0.802 
XGBoost 
0.843 
0.822 
0.868 
0.832 
0.900 
DT 
0.643 
0.666 
0.683 
0.654 
0.700  
Fig. 8. ROC curve of dataset 2 for feature-level fusion.  
Table 8 
Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 3 for 
feature-level fusion.  
Algorithm 
Precision 
Sensitivity 
Specificity 
F1-score 
Accuracy 
KNN 
0.799 
0.811 
0.822 
0.804 
0.833 
SVM 
0.711 
0.732 
0.722 
0.721 
0.752 
LR 
0.698 
0.703 
0.702 
0.700 
0.714 
LDA 
0.673 
0.693 
0.687 
0.682 
0.704 
XGBoost 
0.587 
0.607 
0.623 
0.596 
0.636 
DT 
0.579 
0.542 
0.612 
0.559 
0.606  
Fig. 9. ROC curve of dataset 3 for feature-level fusion.  
S. Soni et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 145 (2022) 105420
10
fusion method, and the feature vectors obtained are passed to the clas­
sifiers for classification. The predictions obtained from the classifiers for 
each channel are then analyzed, and a final prediction based on the 
majority voting rule is obtained. The predictions obtained by the three 
channels when the feature vectors of each channel are passed to the 
classification algorithms in the case of dataset 1 are then analyzed and a 
final prediction decision is made. The KNN algorithm achieves the 
highest accuracy of 0.823 in classifying depressed and healthy groups 
using decision-level fusion among all five classification algorithms used 
in this methodology, as reported in Table 9. 
The ROC curve plotted in the case of the dataset 1 gave the highest 
auc of 0.875 with the KNN algorithm when compared to the other al­
gorithms as displayed in Fig. 10. 
In the case of dataset 2, the predictions that are obtained by the 
twenty channels when the feature vectors of each channel are passed to 
the classification algorithm are analyzed and a final prediction decision 
is taken. The highest accuracy of 0.933 is obtained with the KNN using 
the decision-level fusion among all the other five classification algo­
rithm used in this methodology as noted in Table 10. 
In the case of dataset 2, the ROC curve plotted gives the highest auc 
of 0.964 in the case of the KNN algorithm when compared to the other 
algorithms as displayed in Fig. 11. 
The predictions obtained in case of dataset 3 when the feature vec­
tors of each channel are passed to the classification algorithms were 
analyzed and a final prediction decision is made based on Majority 
voting rule. The KNN algorithm achieves the highest accuracy of 0.888 
among all five classification algorithms used in this methodology, as 
described in Table 11. 
The ROC curve plotted in the case dataset 3 gives the highest auc of 
0.875 with the KNN algorithm when compared to the other algorithms 
as shown in Fig. 12. 
4.4. Comparative study 
The proposed method is compared three deep learning methods and 
three handcrafted feature methods on three datasets that are collected 
from three different sources. The aim of this work is to check how good 
the proposed method is over state-of-the-art methods. A comparative 
analysis to benchmark state-of-the-art methods for depression detection 
using EEG signals with respect to validation metrics, such as precision, 
recall, F1-score, and accuracy, is performed. However, the meta-data of 
these datasets, for example, the sample rate, data size, etc, are not 
considered, which deserve further study. The comparative study dem­
onstrates that the proposed method outperforms all other methods in 
terms of validation metrics in detecting depressed and healthy subjects 
as described in Table 12. 
4.5. Empirical study 
The Node2vec algorithm generates feature vectors by performing 
biased random walks using four parameters m, o, l, and r. The value of 
these parameters is decided to be optimal by an experimental study 
performed on the datasets taking the different values of the parameters. 
Table 9 
Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 1 for 
decision-level fusion.  
Algorithm 
Precision 
Sensitivity 
Specificity 
F1-score 
Accuracy 
KNN 
0.777 
0.818 
0.789 
0.796 
0.823 
SVM 
0.727 
0.723 
0.666 
0.724 
0.714 
LR 
0.634 
0.689 
0.646 
0.660 
0.666 
LDA 
0.724 
0.714 
0.750 
0.718 
0.727 
XGBoost 
0.513 
0.533 
0.562 
0.522 
0.545 
DT 
0.688 
0.673 
0.697 
0.680 
0.683  
Fig. 10. ROC curve of dataset 1 for decision-level fusion.  
Table 10 
Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 2 for 
decision-level fusion.  
Algorithm 
Precision 
Sensitivity 
Specificity 
F1-score 
Accuracy 
KNN 
0.895 
0.915 
0.923 
0.904 
0.933 
SVM 
0.865 
0.859 
0.908 
0.861 
0.900 
LR 
0.877 
0.899 
0.843 
0.875 
0.916 
LDA 
0.832 
0.865 
0.900 
0.848 
0.923 
XGBoost 
0.813 
0.842 
0.823 
0.836 
0.866 
DT 
0.708 
0.710 
0.702 
0.708 
0.733  
Fig. 11. ROC curve of dataset 2 for decision-level fusion.  
S. Soni et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 145 (2022) 105420
11
4.5.1. Varying r with constants m, o, and l 
The values of m, o, and l are kept constant as reported in Table 2, but 
different values of r are used, and the change in accuracy is observed. 
The values taken are 5, 10, 15, 20, and 25. It is discovered that the 
highest accuracy is obtained when the value of r is set to 10. The 
experiment is carried out on all three datasets, and the variation in ac­
curacy with change in r value is shown in Fig. 13. 
4.5.2. Varying l with constants m, o, and r 
To observe the change in accuracy, the values of m, o, and r are kept 
constant as specified in Table 2, and different values of l are used. The 
values taken are 50, 100, 150, 200, 250, and 300. During the experi­
ment, it is discovered that the case of 100 yielded the highest accuracy. 
The experiment is carried out on all three datasets, and the variation in 
accuracy with change in l value is demonstrated in Fig. 14. 
4.5.3. Varying m with constants l, o, and v 
The values of l, o, and r remains constant as noted in Table 2, while 
different values of m are used to observe the change in accuracy. The 
values chosen are 0.1, 0.3, 0.5, 0.7, 0.9, and 1.0. While experimenting, it 
is discovered that the case of 0.5 yielded the highest accuracy. The 
experiment is carried out on all three datasets, and the variation in ac­
curacy with change in m value is shown in Fig. 15. 
4.5.4. Varying o with constants r, l, and m 
The values of r, l, and m are held constant as specified in Table 2, and 
the accuracy is measured for a variety of o values. The values of n during 
the experiment are 0.5, 1.0, 1.5, 2.0, and 2.5. It is discovered that when 
the value of o are set to 2.0, the highest accuracy is obtained. The 
experiment is carried out across all three datasets, and the variation in 
accuracy with change in o value is shown in Fig. 16. 
4.6. Discussion 
We present a discussion on each of the methods implemented and 
Table 11 
Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 3 for 
decision-level fusion.  
Algorithm 
Precision 
Sensitivity 
Specificity 
F1-score 
Accuracy 
KNN 
0.852 
0.872 
0.863 
0.861 
0.888 
SVM 
0.743 
0.723 
0.733 
0.737 
0.750 
LR 
0.788 
0.803 
0.792 
0.795 
0.818 
LDA 
0.743 
0.827 
0.803 
0.782 
0.833 
XGBoost 
0.666 
0.653 
0.627 
0.659 
0.666 
DT 
0.687 
0.702 
0.692 
0.694 
0.714  
Fig. 12. ROC curve of dataset 3 for decision-level fusion.  
Table 12 
Comparative study: The classification report of AchCNN, AchLSTM, DepreNet, CaiHH-KNN1, CaiH-KNN2, CaiH-DBN and proposed method for dataset 1, dataset 2 and 
dataset 3.  
Method 
Dataset 1 
Dataset 2 
Dataset 3 
Precision 
Recall 
f1-score 
Accuracy 
Precision 
Recall 
f1-score 
Accuracy 
Precision 
Recall 
f1-score 
Accuracy 
AchCNN [42] 
0.564 
0. 612 
0.587 
0.635 
0.581 
0.639 
0.610 
0.681 
0.702 
0.713 
0.707 
0.732 
AchLSTM [41] 
0.607 
0.643 
0.624 
0.678 
0.613 
0.913 
0.734 
0.744 
0.744 
0.733 
0.738 
0.753 
DeprNet [36] 
0.651 
0.688 
0.668 
0.702 
0.919 
0.887 
0.895 
0.914 
0.775 
0.723 
0.748 
0.782 
\CaiH-KNN1 [26] 
0.666 
0.633 
0.649 
0.684 
0.527 
0.655 
0.588 
0.723 
0.688 
0.697 
0.692 
0.703 
CaiH-KNN2 [43] 
0.668 
0.704 
0.685 
0.713 
0.667 
0.735 
0.699 
0.724 
0.688 
0.701 
0.694 
0.723 
\CaiH-DBN\} [21] 
0.622 
0.597 
0.609 
0.635 
0,617 
0.680 
0.647 
0.671 
0.652 
0.643 
0.647. 
0.662 
Proposed Method 
0.789 
0.818 
0.803 
0.823 
0.888 
0.915 
0.901 
0.933 
0.866 
0.872 
0.871 
0.888  
Fig. 13. Change in Accuracy with variation in values of r.  
Fig. 14. Change in Accuracy with variation in values of l.  
S. Soni et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 145 (2022) 105420
12
analyzed in this paper. Relying solely on traditional approaches, such as 
questionnaires, might fail to detect depression. With the technological 
advances in brain signal analysis, human brain activities in the form of 
non-invasive EEG recordings can produce more reliable results. In this 
work, three fusion methods are proposed at three different levels. 
However, all the three above-said methods exploit Node2vec algo­
rithmic framework. This study evaluates the performance of the pro­
posed methods on the three publicly available pre-processed datasets 
consisting of 3, 20, and 128 channels, respectively, using different 
evaluation metrics. Out of them, the performance of the proposed 
method at the decision level is superior since it tries to combine the 
decisions of several channels to produce a single final decision using 
majority voting technique. The decision of each channel is the classifi­
cation conducted on the test dataset. However, the contribution of the 
individual channels of these datasets towards the performance of the 
method is not analyzed and will be carried out in near future. 
5. Conclusion 
The study successfully uses the graph representation learning 
approach for automatically extracting features from each channel and 
applies three different types of fusion, namely a graph-level fusion, 
feature-level fusion, and decision-level fusion for analyzing EEG data 
and classifying healthy and depressed subjects. The proposed method 
can successfully distinguish the healthy and depressed subjects with the 
highest accuracy of 0.933, sensitivity of 0.916, specificity of 0.923, the 
precision of 0.895, f1-score of 0.904, and an auc of 0.966 with the KNN 
Algorithm in case of decision-level fusion that outperforms the other 
state-of-art methods. The proposed method’s accuracy is promising, but 
there is still potential for improvement. The method works by first 
constructing a graph from the dataset, in which the nodes represent the 
subjects in the dataset and where the edge weights obtained using the 
Euclidean distance reflect their relationship. The Node2vec algorithm is 
applied over the graph to create distinct features in the form of node 
embeddings, which are then fed to classification algorithms to classify 
the depressed and healthy subjects. Our next steps will focus on creating 
a sparse graph rather than a complete graph, which will aid in the 
extraction of more different characteristics and improve the model’s 
accuracy. Furthermore, due to the very complicated and informative 
graph structure, machine learning on graphs is know to be a difficult 
task. As a result, future research will concentrate on using graph con­
volutional networks (GCNs) to work directly on graphs, leveraging 
structural information and producing useful feature representations for 
nodes in the graph, which will help to improve the method’s accuracy in 
detecting depressed subjects. 
Declaration of competing interest 
The authors declare no conflict of interest. 
Acknowledgment 
This work is partially supported by the project IT4Neuro (degener­
ation), reg. nr. CZ.02.1.01/0.0/0.0/18 069/0010054 and by the project 
“Smart Solutions in Ubiquitous Computing Environments”, Grant 
Agency of Excellence, University of Hradec Kralove, Faculty of Infor­
matics and Management, Czech Republic (under ID: UHK-FIM-GE- 
2022). 
Appendix A. Supplementary data 
Supplementary data to this article can be found online at https://doi. 
org/10.1016/j.compbiomed.2022.105420. 
References 
[1] W.H. Organization, et al., Depression and other common mental disorders: global 
health estimates, Tech. rep. (2017) 1–24. 
[2] A. Shoeibi, N. Ghassemi, R. Alizadehsani, M. Rouhani, H. Hosseini-Nejad, 
A. Khosravi, M. Panahiazar, S. Nahavandi, A comprehensive comparison of 
handcrafted features and convolutional autoencoders for epileptic seizures 
detection in eeg signals, Expert Systems with Applications 163 (2021) 1–16. 
[3] S.K. Khare, V. Bajaj, U.R. Acharya, Detection of Parkinson’s disease using 
automated tunable q wavelet transform technique with eeg signals, Biocybernetics 
and Biomedical Engineering 41 (2021) 679–689. 
[4] M. Sharma, U.R. Acharya, Automated Detection of Schizophrenia Using Optimal 
Wavelet-Based Norm Features Extracted from Single-Channel Eeg, Cognitive 
Neurodynamics, 2021, pp. 1–14. 
[5] A. Asif, M. Majid, S.M. Anwar, Human stress classification using eeg signals in 
response to music tracks, Computers in biology and medicine 107 (2019) 182–196. 
[6] M. Sharma, J. Tiwari, U.R. Acharya, Automatic sleep-stage scoring in healthy and 
sleep disorder patients using optimal wavelet filter bank technique with eeg 
signals, International Journal of Environmental Research and Public Health 18 
(2021) 1–29. 
[7] M.M. Rahman, A.K. Sarkar, M.A. Hossain, M.S. Hossain, M.R. Islam, M.B. Hossain, 
J.M. Quinn, M.A. Moni, Recognition of human emotions using eeg signals: a 
review, Computers in Biology and Medicine 136 (2021) 104696. 
[8] H. Hinrikus, A. Suhhova, M. Bachmann, K. Aadamsoo, Ü. V˜ohma, J. Lass, V. Tuulik, 
Electroencephalographic spectral asymmetry index for detection of depression, 
Medical & biological engineering & computing 47 (12) (2009) 1291–1299. 
[9] V.A. Grin-Yatsenko, I. Baas, V.A. Ponomarev, J.D. Kropotov, Independent 
component approach to the analysis of eeg recordings at early stages of depressive 
disorders, Clinical Neurophysiology 121 (2010) 281–289. 
[10] J.L. Stewart, J.A. Coan, D.N. Towers, J.J. Allen, Resting and task-elicited prefrontal 
eeg alpha asymmetry in depression: support for the capability model, 
Psychophysiology 51 (2014) 446–455. 
[11] G.E. Bruder, J.W. Stewart, D. Hellerstein, J.E. Alvarenga, D. Alschuler, P. 
J. McGrath, Abnormal functional brain asymmetry in depression: evidence of 
biologic commonality between major depression and dysthymia, Psychiatry 
research 196 (2012) 250–254. 
[12] W. Heller, M.A. Etienne, G.A. Miller, Patterns of perceptual asymmetry in 
depression and anxiety: implications for neuropsychological models of emotion 
and psychopathology, Journal of abnormal psychology 104 (1995) 327–333. 
[13] S.D. Puthankattil, P.K. Joseph, Classification of eeg signals in normal and 
depression conditions by ann using rwe and signal entropy, Journal of Mechanics 
in Medicine and biology 12 (2012) 1240019. 
[14] A. Gaouda, M. Salama, M. Sultan, A. Chikhani, Power quality detection and 
classification using wavelet-multiresolution signal decomposition, IEEE 
Transactions on power delivery 14 (1999) 1469–1476. 
Fig. 15. Change in Accuracy with variation in values of m.  
Fig. 16. Change in Accuracy with variation in values of o.  
S. Soni et al.                                                                                                                                                                                                                                     
 Computers in Biology and Medicine 145 (2022) 105420
13
[15] M. Ahmadlou, H. Adeli, A. Adeli, Fractality analysis of frontal brain in major 
depressive disorder, International Journal of Psychophysiology 85 (2012) 
206–211. 
[16] M. Bachmann, J. Lass, A. Suhhova, H. Hinrikus, Spectral asymmetry and higuchi’s 
fractal dimension measures of depression electroencephalogram, Computational 
and mathematical methods in medicine 2013 (2013) 1–9. 
[17] T.Q.D. Khoa, V.Q. Ha, V.V. Toi, Higuchi fractal properties of onset epilepsy 
electroencephalogram, Computational and mathematical methods in medicine 
2012 (2012) 1–7. 
[18] B. Hosseinifard, M.H. Moradi, R. Rostami, Classifying depression patients and 
normal subjects using machine learning techniques and nonlinear features from 
eeg signal, Computer methods and programs in biomedicine 109 (2013) 339–345. 
[19] O. Faust, P.C.A. Ang, S.D. Puthankattil, P.K. Joseph, Depression diagnosis support 
system based on eeg signal entropies, Journal of mechanics in medicine and 
biology 14 (2014) 1450035. 
[20] U.R. Acharya, V.K. Sudarshan, H. Adeli, J. Santhosh, J.E. Koh, S.D. Puthankatti, 
A. Adeli, A novel depression diagnosis index using nonlinear features in eeg 
signals, European neurology 74 (2015) 79–83. 
[21] H. Cai, X. Sha, X. Han, S. Wei, B. Hu, Pervasive eeg diagnosis of depression using 
deep belief network with three-electrodes eeg collector, in: 2016 IEEE 
International Conference on Bioinformatics and Biomedicine (BIBM), IEEE, 2016, 
pp. 1239–1246. 
[22] W. Mumtaz, L. Xia, S.S.A. Ali, M.A.M. Yasin, M. Hussain, A.S. Malik, 
Electroencephalogram (eeg)-based computer-aided technique to diagnose major 
depressive disorder (mdd), Biomedical Signal Processing and Control 31 (2017) 
108–115. 
[23] H. Liu, H. Motoda, Computational Methods of Feature Selection, CRC Press, 2007, 
pp. 1–440. 
[24] S.-C. Liao, C.-T. Wu, H.-C. Huang, W.-T. Cheng, Y.-H. Liu, Major depression 
detection from eeg signals using kernel eigen-filter-bank common spatial patterns, 
Sensors 17 (2017) 1385. 
[25] M. Sharma, P. Achuth, D. Deb, S.D. Puthankattil, U.R. Acharya, An automated 
diagnosis of depression using three-channel bandwidth-duration localized wavelet 
filter bank with eeg signals, Cognitive Systems Research 52 (2018) 508–520. 
[26] H. Cai, J. Han, Y. Chen, X. Sha, Z. Wang, B. Hu, J. Yang, L. Feng, Z. Ding, Y. Chen, 
et al., A pervasive approach to eeg-based depression detection, Complexity 2018 
(2018), 5238028. 
[27] S. Byun, A.Y. Kim, E.H. Jang, S. Kim, K.W. Choi, H.Y. Yu, H.J. Jeon, Detection of 
major depressive disorder from linear and nonlinear heart rate variability features 
during mental task protocol, Computers in biology and medicine 112 (2019) 
103381. 
[28] H. Cai, Z. Qu, Z. Li, Y. Zhang, X. Hu, B. Hu, Feature-level fusion approaches based 
on multimodal eeg data for depression recognition, Information Fusion 59 (2020) 
127–138. 
[29] A. Grover, J. Leskovec, node2vec: scalable feature learning for networks, in: 
Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge 
Discovery and Data Mining, ACM, 2016, pp. 855–864. 
[30] Y. Wu, Y. Bian, X. Zhang, Remember where you came from: on the second-order 
random walk based proximity measures, Proceedings of the VLDB Endowment 10 
(2016) 13–24. 
[31] S. Chauhan, M. Singh, A.K. Aggarwal, Data science and data analytics: Artificial 
intelligence and machine learning integrated based approach, Data Science and 
Data Analytics: Opportunities and Challenges (2021) 1. 
[32] A. Kaur, A.P.S. Chauhan, A.K. Aggarwal, An automated slice sorting technique for 
multi-slice computed tomography liver cancer images using convolutional 
network, Expert Systems with Applications 186 (2021) 115686. 
[33] A. Kaur, A.P.S. Chauhan, A.K. Aggarwal, Machine learning based comparative 
analysis of methods for enhancer prediction in genomic data, in: 2019 2nd 
International Conference on Intelligent Communication and Computational 
Techniques (ICCT), IEEE, 2019, pp. 142–145. 
[34] A.P. Bradley, The use of the area under the roc curve in the evaluation of machine 
learning algorithms, Pattern recognition 30 (1997) 1145–1159. 
[35] H. Cai, Y. Gao, S. Sun, N. Li, F. Tian, H. Xiao, J. Li, Z. Yang, X. Li, Q. Zhao, et al., 
Modma Dataset: a Multi-Modal Open Dataset for Mental-Disorder Analysis, 09283, 
2002. arXiv preprint arXiv. 
[36] A. Seal, R. Bajpai, J. Agnihotri, A. Yazidi, E. Herrera-Viedma, O. Krejcar, Deprnet: a 
deep convolution neural network framework for detecting depression using eeg, 
IEEE Transactions on Instrumentation and Measurement 70 (2021) 1–13. 
[37] R. Thukral, A. Arora, A. Kumar, et al., Denoising of thermal images using deep 
neural network, in: Proceedings of International Conference on Recent Trends in 
Computing, Springer, 2022, pp. 827–833. 
[38] R. Thukral, A. Kumar, A. Arora, et al., Effect of different thresholding techniques 
for denoising of emg signals by using different wavelets, in: 2019 2nd International 
Conference on Intelligent Communication and Computational Techniques (ICCT), 
IEEE, 2019, pp. 161–165. 
[39] S.-I. Liu, Z.-T. Yeh, H.-C. Huang, F.-J. Sun, J.-J. Tjung, L.-C. Hwang, Y.-H. Shih, A. 
W.-C. Yeh, Validation of patient health questionnaire for depression screening 
among primary care patients in taiwan, Comprehensive psychiatry 52 (2011) 
96–101. 
[40] L. Van der Maaten, G. Hinton, Visualizing data using t-sne, Journal of machine 
learning research 9 (2008) 1–27. 
[41] B. Ay, O. Yildirim, M. Talo, U.B. Baloglu, G. Aydin, S.D. Puthankattil, U. 
R. Acharya, Automated depression detection using deep representation and 
sequence learning with eeg signals, Journal of medical systems 43 (7) (2019) 1–12. 
[42] U.R. Acharya, S.L. Oh, Y. Hagiwara, J.H. Tan, H. Adeli, D.P. Subha, Automated eeg- 
based screening of depression using deep convolutional neural network, Computer 
methods and programs in biomedicine 161 (2018) 103–113. 
[43] S. Zheng, C. Lei, T. Wang, C. Wu, J. Sun, H. Peng, Feature-level fusion for 
depression recognition based on fnirs data, in: 2020 IEEE International Conference 
on Bioinformatics and Biomedicine (BIBM), IEEE, 2020, pp. 2906–2913. 
S. Soni et al.                                                                                                                                                                                                                                     
",https://doi.org/10.1016/j.compbiomed.2022.105420,doc21,"Computers in Biology and Medicine 145 (2022) 105420 Available online 2 April 2022 0010-4825/© 2022 Elsevier Ltd. All rights reserved. Graphical representation learning-based approach for automatic classification of electroencephalogram signals in depression Surbhi Soni a, Ayan Seal a,*, Anis Yazidi b,d,c, Ondrej Krejcar e,f a PDPM Indian Institute of Information Technology, Design and Manufacturing, Jabalpur, 482005, India b Department of Computer Science, OsloMet – Oslo Metropolitan University, Oslo, Norway c Department of Plastic and Reconstructive Surgery, Oslo University Hospital, Oslo, Norway d Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway e Center for Basic and Applied Research, Faculty of Informatics and Management, University of Hradec Kralove, Hradecka 1249, Hradec Kralove, 50003, Czech Republic f Malaysia Japan International Institute of Technology, Universiti Teknologi Malaysia, Jalan Sultan Yahya Petra, 54100, Kuala Lumpur, Malaysia A R T I C L E I N F O Keywords: Node2vec Electroencephalography Graph-level fusion Feature-level fusion Decision-level fusion A B S T R A C T Depression is a major depressive disorder characterized by persistent sadness and a sense of worthlessness, as well as a loss of interest in pleasurable activities, which leads to a variety of physical and emotional problems. It is a worldwide illness that affects millions of people and should be detected at an early stage to prevent negative effects on an individual’s life. Electroencephalogram (EEG) is a non-invasive technique for detecting depression that analyses brain signals to determine the current mental state of depressed subjects. In this study, we propose a method for automatic feature extraction to detect depression by first constructing a graph from the dataset where the nodes represent the subjects in the dataset and where the edge weights obtained using the Euclidean distance reflect the relationship between them. The Node2vec algorithmic framework is then used to compute feature representations for nodes in a graph in the form of node embeddings ensuring that similar nodes in the graph remain near in the embedding. These node embeddings act as useful features which can be directly used by classification algorithms to determine whether a subject is depressed thus reducing the effort required for manual handcrafted feature extraction. To combine the features collected from the multiple channels of the EEG data, the method proposes three types of fusion methods: graph-level fusion, feature-level fusion, and decision-level fusion. The proposed method is tested on three publicly available datasets with 3, 20, and 128 channels, respectively, and compared to five state-of-the-art methods. The results show that the proposed method detects depression effectively with a peak accuracy of 0.933 in decision-level fusion, which is the highest among the state-of-the-art methods. 1. Introduction Depressive disorders are characterized by sadness, loss of interest or pleasure, disturbed sleep or appetite, a sense of guilt and hopelessness, poor concentration, and can even lead to suicide in its most severe form. According to the World Health Organization, 322 million people worldwide suffer from depression [1]. Thus, diagnosing at an early stage is critical to protect patients from the severe and irreversible conse­ quences of depression. It has three levels, namely mild, moderate, and acute. Doctors diagnose the same based on classification criteria such as the Diagnostic and Statistical Manual of Mental Disorders Fifth Edition, Beck Depression Inventory, which are a questionnaire containing a set of questions score of which determines the level of depression. Also, the interactive sessions between the patients and health practitioners play an imperative role in detecting depression. However, these sessions may not always produce the desired results because it is dependent on the practitioner’s knowledge and skill in dealing with depressive patients. Moreover, patients suffering from a mental disorder are hesitant to admit that they require treatment because they are afraid of being labeled mentally ill. As a result, clinical treatment is ineffective in assisting depressive patients in receiving proper treatment, resulting in further deterioration of the illness and its detrimental effect on an in­ dividual’s life. Alternative approaches to effectively detect and diagnose depression are required to overcome the drawbacks of clinical methods. The advancement of sensor technology and communication systems has resulted in the development of electronic devices that are critical in * Corresponding author. E-mail address: ayan@iiitdmj.ac.in (A. Seal). Contents lists available at ScienceDirect Computers in Biology and Medicine journal homepage: www.elsevier.com/locate/compbiomed Received 30 December 2021; Received in revised form 1 February 2022; Accepted 19 February 2022 Computers in Biology and Medicine 145 (2022) 105420 2 monitoring an individual’s health conditions. These devices are commonly employed to investigate the activity of the human brain in techniques such as electroencephalography (EEG), magnetoencepha­ lography, magnetic resonance imaging, and functional magnetic reso­ nance imaging. Out of these, EEG is a portable and non-invasive technique that uses electrodes attached to the scalp to evaluate the electrical activity of the brain. This electrical activity is represented on EEG recordings by a wavy line, which is then used by physicians and scientists to study brain functions and diagnose neurological disorders. The electrodes employed are generally useable and are labeled as F, P, O, and T, which represent the areas of the brain from which the signals are acquired, such as the frontal, parietal, occipital, and temporal lobes. The electrode in the midline of the brain is designated as z. EEG evaluates the functioning of the brain and is used for diagnosis of illness like epileptic seizure [2], Parkinson’s Disease [3], Schizo­ phrenia [4], Stress Detection [5] and Sleep Disorder [6]. The use of EEG signals in the detection of depression is a new area of study. It begins with the extraction of EEG signals using an electroencephalogram de­ vice, followed by pre-processing, which removes disturbances in EEG signals caused by environmental changes, commonly referred to as ar­ tifacts. Following the removal of artifacts, the important features of EEG signals are extracted and fed into the classification algorithms, that determine whether or not the subject is depressed. Because of nonlinear properties EEG data, extracting useful features from it is difficult. The features and behaviour of EEG signals cannot be clearly explained using time, frequency, or time-frequency analysis. As a result, it’s critical to locate stable features and create accurate models with high classification performance [7]. Hence the feature extraction procedure entails the manual extraction of handcrafted features, which is tedious and labor-intensive. The proposed method is based on an automated feature extraction process based on graphical representations, which overcomes the problem of manual feature extraction. 1.1. Motivation and contributions EEG processing entails signal processing and analysis, which begins with the extraction of useful features in the time, frequency, and time- frequency domains. This process takes a long time and a lot of human effort; additionally, there are no fixed global biomarker features for detecting depression. As a result, the work aims to reduce the manual effort required for feature extraction and propose an automatic method for detecting depressive patients using graphical representation learning. The contributions of this work are as follows: ● The proposed method aims to develop a predictive model that automatically extracts features from EEG signals using graph repre­ sentation learning followed by the classification of the depressed and healthy subjects using machine learning algorithms. ● The proposed method develops three novel approaches graph-level, feature-level, and decision-level data fusion techniques that provides a way to combine the features extracted from each channel of the dataset that are obtained after applying the Node2cec algorithm in order to obtain a greater predictive power. As far as these fusion techniques are concerned, they are mainly exploiting the Node2vec algorithmic framework to carry out the data fusion procedure. ● The Node2vec algorithmic framework is adopted that computes a vector representation of a node based on random walks in the graph. These vectors corresponding to each node acts as features and is fed into machine learning algorithms to classify depressed and healthy subjects. ● The proposed method is executed on three datasets consisting of 3 channels, 20 channels, and 128 channels respectively. It is then compared with five state-of-the-art methods using different evalua­ tion metrics, namely accuracy, sensitivity/recall, specificity, preci­ sion, and ROC curve. Empirical results illustrate that the decision- level-based proposed method outranks some existing approaches. The paper’s structure is as follows, Section II discusses a literature review of existing depression-related works. The proposed work is described in detail in Section III, which includes a detailed explanation of the Node2vec method. The results and discussions are presented in Section IV, followed by the conclusion and future scope in Section V. 2. Related work A substantial amount of research had been conducted in the field of depression detection using EEG signals. Hinrikus et al. [8] presented a new method for analyzing EEG signals based on the frequency spectrum, assuming that beta-band played an important role in the detection of depression. The Spectral Asymmetry Index (SASI) was exploited as a promising measure to detect depressed patients and was found positive in the depressed groups and negative in the healthy group. However, no statistically significant features related to hemispherical asymmetry had been observed. Grin-Yatsenko et al. [9] employed the Independent Component Analysis method to decompose raw EEG data extracted from multiple channels into separate components for each eye open and eye closed state. Every component’s and each subjects’s frequency band power spectra were computed. A comparison of the power spectrum in theta, alpha, and beta bands reported exceptionally high alpha power during resting state in depressed patients, which was contradicted by Stewart et al. [10], whose findings showed low alpha activity in all parts of the brain during the depression. Gerard E. Bruder et al. [11] used dichotic test demonstrations in which external stimuli such as Fusion words and complex tones were delivered and hemisphere Asymmetry [12] was computed to classify depressed and healthy subjects. It claimed that healthy men had greater hemispheric asymmetry than women in perceiving tones and words, whereas depressed patients showed no gender difference. Other measures, however, were required to further depict the gender differences in depression. Discrete Wavelet transform was employed by Puthankattil and Joseph [13] to decompose the EEG signal data extracted from 15 depressed and 15 healthy subjects into different frequency bands and Parseval’s method [14], was applied to calculate energy present at various decomposition levels. The two-layered feed-forward neural network with twenty neurons was adopted to classify the depressed and healthy subjects based on relative wave entropy and signal entropy features. However, it was a preliminary study that accepted a small number of features and a conventional al­ gorithm on a smaller dataset. Ahmadlou et al. [15] found the Higuchi Fractal Dimension of the left, right, and overall frontal brain beta sub-bands effective in distinguishing between depressed and healthy subjects when passed to the enhanced probabilistic neural network for classification. The research findings were preliminary because it experimented on a smaller dataset and additional data was required to draw definite conclusions. Bachmann et al. [16] in their findings used SASI and HFD to differentiate between depressive and healthy subjects and suggested that the HFD alone did not perform well in the frontal region. According to Khoa et al. [17], HFD served as a successful discriminator in detecting depressed subjects in the parietooccipital region and not in the frontal region as it is more sensitive to noise because of its high variability. Hosseinifard et al. [18] findings concluded that non-linear features such as Correlation Dimension, Higuchi Fractal Dimension, and Lyapunov exponent were more effective in detecting depression; however, combining both linear and non-linear features can improve accuracy even further. Faust [19] findings sug­ gested that the Probabilistic Neural Network was capable of dis­ tinguishing between depressed and healthy subjects based on non-linear features such as Sample Entropy, Approximate Entropy, Renyl’s En­ tropy, and Bispectral Entropy. However, the method used redundant features as the feature selection technique was not involved and high accuracy could have resulted from overfitting. Acharya et al. [20] extracted fifteen non-linear features and then ranked them using the t-test, and the features with the highest rank in both the left and right hemispheres were then combined to form the Depression Diagnostic S. Soni et al. Computers in Biology and Medicine 145 (2022) 105420 3 Index to effectively discriminate between the depressive and healthy groups. However, because there is no proof of the relationship of fea­ tures used as a combination in the index’s formulation, its use is ques­ tionable. Cai et al. [21] suggested a method in which EEG data was collected from three electrodes, namely Fp1, Fz, and Fp2 followed by its division into alpha, beta, gamma, and theta frequency bands. Twenty-seven linear and non-linear features were extracted from these frequency bands and fed into four classifiers, namely K-Nearest Neighbor (KNN), Support Vector Machine (SVM), Artificial Neural Network and, Deep Belief Neural Network (DBNN). The results indicated that the absolute power of the beta sub-band combined with the DBNN Classifier provided an accuracy of 78.24% in distinguishing between the depressed and healthy groups. However, there was a need to increase data collection to gradually improve accuracy. Mumtaz et al. [22] extracted features from the EEG dataset consisting of nineteen channels which included the powers of different frequency bands and alpha interhemispheric asymmetry. Receiver Operating Criterion (ROC) [23] was used to select the most significant features to avoid irrelevant and redundant features and the passed for classification. The findings sug­ gested that alpha interhemispheric asymmetry was the most promising characteristic when combined with an SVM Classifier. Liao et al. [24] developed a spectral-spatial feature extractor-based method that first filters raw multi-channel EEG signals into frequency bands and then transformed the original signals from each sub-band to an optimal feature vector space by reducing it into a lower-dimensional feature vector space. The resulting vector space provided the highest classifi­ cation accuracy with the SVM classifier to distinguish between the depressed and healthy subjects. Sharma et al. [25] decomposed raw EEG signal from three channels into seven wavelet sub-bands using three Channel Orthogonal Wavelet Filter Bank. The logarithmic norm feature was extracted from each wavelet sub-band and fed into the support vector machine to differentiate between the depressed and healthy subjects. Cai et al. [26] conducted a study on 213 subjects, out of which 92 were depressed and 121 were normal and collected their EEG signals through a pervasive three-electrode EEG collector. The signals were denoised using a Finite Impulse Response Filter, then features were extracted and classified into three categories: time-domain features, frequency domain features, and non-linear features. To select the most important features the Minimal-Redundancy-Maximum-Relevancy method was adopted, and the results indicated that Absolute power theta in combination with the KNN classifier produced the best the highest accuracy of 76.98% in differentiating between the two groups, which was higher than previous studies. Byun et al. [27] used a machine learning approach to classify healthy and depressed subjects using Heat Rate Variability demonstration to evaluate cardiac autonomic regula­ tion connection with depression. by extracting twenty HRV features—13 linear, five nonlinear, and two Poincar´e plot from electrocardiogram (ECG) recordings of 37 depressed and 41 healthy subjects. The results suggested that SVM classifier distinguished the two groups with 74% accuracy. Cai et al. [28] presented a multimodal approach by fusing features extracted from three-channel EEG signals recorded in response to different modalities of positive, negative, and neutral audio stimu­ lation. The extracted features combined with the KNN classifier yielded an accuracy of 86.98%. The studies mentioned above demonstrate the use of handcrafted features to detect depression that requires a lot of human effort. Our proposed method focuses on automated feature extraction using graphical representation hence reducing human effort in the feature extraction phase. 3. Methods and materials The primary goal of this research is to propose a computer-aided automatic method for detecting depression using a graphical approach to feature extraction, thereby avoiding the use of handcrafted features that require human effort. 3.1. Feature extraction using Node2vec A feature is a collection of variables that, when combined, best represent a larger set of data. Feature extraction is directly related to dimensionality reduction because it reduces the data set passed for training while accurately representing the original data set without sacrificing critical information. Node2vec [29] is an algorithmic framework that learns feature representation in the form of network nodes and is used for feature extraction from EEG data. It learns a node’s dense representation in such a way that when it is plotted in a low-dimensional space, the nodes near it in that space are also its neighbors in the actual formation structure. The Node2vec algorithm is divided into three steps. The first step is to generate a graph from the dataset, with nodes representing each subjects in the dataset and edges representing their Euclidean distance from one another. In the second step, for each node in a graph, second- order random walks are generated to form a sentence, which is a collection of node ids. A corpus, which is a collection of all sentences, is created. The third step is to generate node embedding, which is accomplished by passing the corpus to the skip-gram model, which treats each node id as a unique word/token in a dictionary to calculate the embedding vectors for each node, which are represented in a two- dimensional plane using the T-SNE algorithm, as shown in Fig. 1. These node embeddings serve as important features that will be used for classification in the future. Random walks can be thought of as a walker traversing the edges of a graph, deciding where to go next, and then moving on to the next step. The majority of existing random walk measures are based on the first-order Markov model, in which the next random walk step is determined solely by the current node. However, it is ineffective in many real-world applications, and experimental results show that second-order measures outperform their first-order counter­ parts in a variety of applications [30]. As a result, second-order random measures are used, which also consider the previously visited node and efficiently explore the various neighborhoods of a given node using hyper-parameters, which are as follows: ● Return parameter (m): The parameter controls the likelihood of the random walk returning to a previously visited node. The greater the value of m, the less likely it is that the random walk will return to a node. An m value less than one indicates that the random walk tends to return to a previously visited node in order to keep it close to the start node. ● Inout parameter (o): The parameter instructs the random walk to explore inward and outward from a specified source node. If o is less than one, a random walk will tend to stay close to the source node, demonstrating breadth first search behavior. As a result, the random walk includes nodes that are close to the source node, encouraging inward exploration. If o is greater than one, a random walk will tend to move away from the source node, demonstrating depth first search behavior to promote outward exploration. ● Embedding dimension (d): it denotes size of the embedding dimension. ● Length of a random walk (l): it denotes the number of nodes in a walk. ● Walks per node (r): it denotes the number of random walks for each node The steps involved in the Node2vec algorithm are enlisted below. 1. Construct an undirected and weighted complete graph G(V, E) from the EEG dataset, where V represents the set of nodes that depicts the subjects in the dataset and E is the set of weighted edges that reflect the distance between two nodes computed using euclidian distance. 2. Save the weights of all nodes to their neighbors, and calculate the transition probabilities between each node and its neighbors with the help of hyperparameters m and n using Eqs. (1) and (2), respectively. S. Soni et al. Computers in Biology and Medicine 145 (2022) 105420 4 πtx = αmo(u, x)⋅wtx (1) αmo(u, x) = ⎧ ⎨ ⎩ 1/m if dux = 0 1 if dux = 1 1/o if dux = 2 (2) where t and x are nodes Vt and Vx respectively and wt,x reflects the weight between the two nodes. Consider Fig. 2 where a random walk that has just visited edge (u, t) and now resides at node t. The walk must now decide what to do next, so it computes and analyzes the transition probabilities πtx on edges (t, x) leading from t. Here dux denotes the shortest path distance between nodes u and x. 3. Obtain random walks for a node u of fixed length l by generating nodes ci using Eq. (3). P(ci = x|ci−1 = t) = ⎧ ⎨ ⎩ πtx Z if (i, j)ϵE 0 otherwise (3) where ci denotes the ith node of the random walk starting from source node u and c(i−1) is the previously visited node, πtxj is the unnormalized transition probability between nodes t and x, and Z denotes the nor­ malizating factor which is a sum of all transition probabilities. 4. Train all the walk paths of each node using a skip-gram model and then obtain the node embeddings of dimension d which act as rele­ vant features. 3.2. Classification In this study, a 10-fold cross-validation technique is adopted to evaluate the performance of the proposed method, where the original dataset is randomly divided into ten equal-size subsamples [31]. A single subsample from the ten is kept as validation data for testing the method, while the remaining nine are used as training data. The cross-validation process is then performed ten times (the folds), with each of the ten subsamples serving as validation data exactly once. The evaluation metrics obtained from the 10 folds is then averaged (or otherwise combined) to estimate the performance of the proposed method. Here, six classifiers, namely Decision Tree (DT), KNN, XGBoost, SVM, Logistic Regression (LR), and Linear Discriminant Analysis (LDA), are adopted. These classifiers take feature vectors obtained from the validation set using the Node2vec algorithm separately and predict categories, namely depressed and healthy subjects. The classification algorithms along with their various parameters are listed in Table 1. 3.3. Evaluation metric Generally, evaluation metrics are employed to measure the quality of a classification model. There are many different types of evaluation metrics available to validate a classification model. In this work, we note, precision, sensitivity, specificity, f1-score and accuracy measures. Precision determines that out of all the depressed predicted, what per­ centage is truly depressed. Sensitivity also called as Recall tells us how many subjects in the diseased class are correctly classified. The ability of the method to reliably identify subjects without the ailment is known as specificity [32]. f1-score which is the harmonic mean of precision, and sensitivity [33]. Accuracy is determined by the capacity of the model to appropriately distinguish between depressed and healthy subjects. The precision, sensitivity, specificity, f1-score and accuracy measures are computed using Eqs. (4)–(9), respectively. Precision = TP TP + FP (4) Sensitivity = TP TP + FN (5) Fig. 1. Node2vec method of feature representation. Fig. 2. Illustration of the random walk procedure in Node2vec method. The walk just transitioned from u to t and is now evaluating its next step out of node t to the neighboring nodes x1, x2 and x3. Search biases are shown by edge labels. Table 1 Classification Algorithms with their Parameters. Classification_Algorithm Parameters KNN n_neighbors = 7, weight = ”uniform”, algorithm = ”kd_tree”, leaf_size = 30, metric = ”minkowski”, n_jobs = 1 DT criterion = ’gini’, splitter = ”best”, max_depth = ”None”, min_samples_split = 2, max_features = None XGBoost n_estimators = 100, booster = ”gbtree”, learning_rate = 0.1, subsample = 1.0, criterion = ”friedman_mse”, min_saples_split = 2 SVM kernel = ”linear”, degree = 3, gamma = ”scale”, shrinking = ”True”, tol = 1e-3, cache_size = 200, class_weight = ”balanced” LR penalty = 12, dual = ”false”, tol = 1e-4, fit_intercept = ”True”, intercept_scaling = 1, class_weight = ”balanced” LDA n_components = 1, solver = ”svd”, shrinkage = ”None”, priors = ”None”, tol = 1.0e-4, covariance_estimator = ”None” S. Soni et al. Computers in Biology and Medicine 145 (2022) 105420 5 Specificity = TN TN + FP (6) FPR = 1 −Specificity (7) F1 −score = 2 × Precision × Recall Precision + Recall (8) Accuracy = TP + TN TP + TN + FP + FN (9) where TP, TN, FP, and FN denote true-positive, true-negative, false- positive, and false-negative, respectively. In this study, the ROC curve is also used to graphically display a classifier’s performance with vary­ ing threshold settings [34]. It is a probability curve and area under curve (auc) represents the degree or measure of separability to distinguish between classes. The ROC curve is plotted with TP rate (TPR) on the y-axis and FP rate (FPR) on the x-axis. The higher the auc, the better the model distinguish between subjects with and without the disease. 3.4. Dataset description 3.4.1. Dataset 1 The dataset used in the experiment is borrowed from a Multi-modal Open Dataset for Mental-disorder Analysis (MODMA) [35] which is openly available for depression analysis. The EEG signals were collected using a three-electrode Pervasive EEG collector at a frequency of 250 Hz. The EEG signals of 55 subjects were captured, out of which 23 were suffering from depression and the rest 33 were healthy subjects. The signals were collected from the pre-frontal part of the brain by placing three electrodes on the scalp at locations, namely Fp1, Fpz, and Fp3 based on a 10–20 system of electrode placement. 3.4.2. Dataset 2 The second dataset considered in this paper is taken from paper [36] which consists of EEG data signals of 33 subjects for 9 min at a resting state, out of which 15 subjects were depressed and 18 are healthy. The EEG data were collected using 20 electrodes at a frequency of 512 Hz. During the recording 0.1-Hz, high-pass filter, 100-Hz low-pass filter, and 50-Hz notch filter was employed to remove low-frequency noise and irrelevant baseline noise from the recorded data. 3.4.3. Dataset 3 The third dataset is also borrowed from MODMA that consists of an EEG recording of 53 subjects, out of which 24 subjects were depressed patients, out of which 13 were males and 11 were females, and 29 subjects were healthy, out of which 20 were males and 9 were females. The EEG signals were recorded using 128-channel HydroCel Geodesic Sensor Net (Electrical Geodesics Inc., Oregon Eugene, USA) and Net Station acquisition software at a sampling frequency of 256-Hz. To maintain good contact the impedance of the electrodes was checked and kept below 50 Kilo Ohms. It should be noted that noise contained in EEG signals hinders increasing the classification accuracy of a machine learning algorithm to some extent, hence pre-processing step is required. Although many denoising techniques have been developed in previous studies [37,38], however the pre-processed versions of the raw datasets are already available publicly. Three such pre-processed datasets are considered for this study. Thus, no pre-processing step is required separately. The pre-processing steps widely used in the field of neuroscience permit to remove noise which is commonly known as artifact. There are mainly two types of artifacts: physiological and extra-physiological. Physio­ logical are mainly related to movement artifacts and blinking artifacts. Extra-physiological are related mainly to the equipment and interfer­ ence from the environment. However, how the pre-processing had been carried out is beyond the scope of the study. The interested readers are referred to Refs. [35,36] to know more about the pre-processing step. In addition, the subjects were subjected to a clinical test assisted by pro­ fessional psychologists to complete a preliminary judgment of depres­ sion by filling out a Patient Health Questionnaire (PHQ-9). The questionnaire consisted of 9 questions used for diagnosis, screening, and monitoring the severity of depression. It is based on Diagnostic and Statistical Manual of Mental Disorders, fourth edition (DSM-IV) criteria, with questions designed to detect symptoms of depression that have lasted at least two weeks. Based on it, a score known as the PHQ-9 score is assigned to each patient, which is employed to determine whether or not a subject is depressed. PHQ-9’s sensitivity and specificity for iden­ tifying depressed patients have been reported to be 86.0% percent and 91.1% percent, respectively [39]. 3.5. Fusion methods Node2vec is used to extract relevant features from a dataset that will best represent it in a reduced dimension, as previously discussed. Three different types of fusion methods have been proposed at the graph, feature and decision levels described as follows: 3.5.1. Graph-level fusion Graph-level fusion occurs immediately following the first step of graph construction as displayed in Fig. 3 (Appendix). In the first step, for each channel, a complete graph is created in which each node represents a subject in a dataset and the edge weight represents the euclidian dis­ tance between them. As a result, if the dataset contains n channels, namely C1, C2, C3 … Cn, then n graphs that is G1, G2, G3 … Gn are generated each of which contains p(p−1) 2 edges where p is the total number of subjects in the dataset. The graph-level fusion method works by concatenating the graphs G1, G2, G3 … Gn and then constructing the final graph where each edge is computed using Eq. (10). sq = ∑n i=1 wiq (10) Here, q denotes the total number of edges present in the graph and sq denotes a specific edge of the final graph. Consider if each of the com­ plete graphs G1, G2, G3 … Gn consists of four nodes then a total of six edges are generated then the concatenated final graph will also contain four nodes and six edges, namely s1, s2, s3, s4, s5 and s6 whose value is computed using Eq. (10). It then generates a second order random walk for each node in the final graph, resulting in the creation of a corpus trained by the skip-gram model to obtain the embedding for each node in a two-dimensional space using the t-SNE algorithm [40]. These node embeddings of size size n × d act as feature vectors and are then passed to the classification algorithms to distinguish between depressed and healthy subjects. 3.5.2. Feature-level fusion After the step of node embedding generation, the feature-level fusion is performed as shown in Fig. 4 (Appendix). After constructing n graphs, namely G1, G2, G3 … Gn from n different channels that is C1, C2, C3 … Cn, random walks for each node are generated to form a corpus, which is then trained by the skip-gram model to generate node embeddings for each channel, namely F1, F2, F3 … Fn, that act as feature vectors embedded in a two-dimensional space. The feature vectors generated by each channel are then combined to form the final set of feature vectors, which is called feature-level fusion. These feature vectors are of size n × d which are then fed into different classification algorithms, that cate­ gorize subjects as depressed or healthy. The size of d is taken to be 128. 3.5.3. Decision-level fusion Another type of feature combination method used at the output level is decision level fusion as displayed in Fig. 3. After constructing n graphs, namely G1, G2, G3 … Gn from n different channels that is C1, C2, C3 … Cn, random walks for each node are generated to form a corpus, which is S. Soni et al. Computers in Biology and Medicine 145 (2022) 105420 6 then trained by the skip-gram model to generate node embeddings for each channel, namely F1, F2, F3 … Fn, that act as feature vectors embedded in a two-dimensional space. These feature vectors of size size n × d are then passed to the classification algorithms to generate pre­ dictions P1, P2, P3 … Pn by dividing the feature vectors into training and testing. It compares the classifier’s prediction decision in classifying the depressed and healthy groups for each channel and then makes the decision to give the final predicted output based on the Majority func­ tion. It is the Boolean function that evaluates to false when half or more of the arguments are false and true otherwise, i.e. the function’s value equals the value of the majority of the inputs. We can use the (real- valued) formula to represent depressed groups as 1 and healthy groups as 0 as shown in Eq. (11). Fig. 3. Block diagram for decision-level fusion. S. Soni et al. Computers in Biology and Medicine 145 (2022) 105420 7 (p1….pn) = Majority(p1….pn) = ⌊1 2 + ( ∑n i=1pi ) − 1 2 n ⌋ (11) When the number of arguments n is even, the “1/2” in the formula breaks ties in favor of zeros otherwise the function breaks ties in favour of ones. 4. Experimental results and discussions 4.1. Experimental settings The Keras framework and Google Colab platform have been used for the implementation of the experiment in this study. Python 3.8.1 lan­ guage is employed for the implementation task using GPU RAM of 16 GB, System RAM of 15 GB, Intel(R) 2.30 GHz CPU, Tesla P100-PCIE Graphic Processor, and GDDR5X memory type. 4.2. Computational protocol The proposed method’s classification report is compared to three recent DL-based models and three machine learning approaches, ●AchLSTM: Automated depression detection using deep representa­ tion and sequence learning with EEG signals [41]. ● AchCNN: Automated EEG-based screening of depression using deep CNN [42]. ●DeprNet:A deep convolution neural network framework for detect­ ing depression using EEG [36]. ●CaiH-KNN1: A pervasive approach to EEG-based depression detec­ tion [26]. ●CaiH-KNN2:Feature-Level fusion approaches for depression recog­ nition based on multimodal EEG data [43]. ● CaiH-DBN Pervasive EEG diagnosis of depression using Deep Belief Network with three-electrodes EEG collector [21]. We provide meaningful names because the scholars have not used any names to refer for their works. These state-of-the-art methods are implemented on the above-said three datasets. The above state-of-the- art methods are implemented as they are in the presented papers. The detailed description of these are beyond the scope of this study. The interested readers can refer to Refs. [41,42]. [26,36,43], and [21] to know about these methods in detail. 4.3. Results Node2vec is a simple, scalable, and successful technique for learning low-dimensional embeddings for nodes in a graph. The first step to implement the node2vec algorithm is the generation of a graph from the dataset. where the nodes of the graph represent the subjects present in the dataset and the edges between them represent the euclidian distance between them. Since the EEG data is in the form of a NumPy array hence it is feasible to determine the euclidian distance between them. After the formation of the complete graph, the algorithm creates sentences from this graph which is a list of node ids. Hence a collection of all sentences called the corpus is generated using four parameters: l, r, m, and o. The value of d here is taken as 128. The values of the parameters taken in the experiment are reflected in Table 2. Finally, the corpus is fed to the skip- gram model which gives a set of feature vectors in a two-dimensional plane where the blue point reflects healthy subjects and red points represents the depressed subjects. Since dataset 1 includes 55 subjects hence, a complete graph with 55 nodes and 1540 edges is generated. Because the length of the random walks in our case is set to 10, 550 biased random walks are generated using the parameters m and n. The corpus of 550 random walks is then fed into the skip-gram model, which produces features in the form of node vectors of size 55 × 128 embedded in a two-dimensional plane. In the case of dataset 2, the complete graph consists of 33 nodes and 551 edges. Because each node generates ten random walks, a total of 330 random walks are generated and fed to the skip-gram model, which generates feature vectors of size 33 × 128 embedded in a two- dimensional plane. Similarly dataset 3 contains 53 subjects, with a complete graph of 53 nodes and 1431 edges. In this case, 530 biased random walks are generated and fed into the skip-gram model, which generates feature vectors of size 53 × 128 embedded in a two-dimensional plane. 4.3.1. Graph-level fusion results As previously stated, graph-level fusion is carried out by concate­ nating the graphs obtained from the n channels and then using the Node2vec algorithm to obtain the feature vectors from the concatenated graph. The obtained feature vectors are then fed into the classification algorithms, which classifies the depressed and healthy subjects. As a result, three, twenty, and one twenty-eight graphs will be produced from datasets 1, 2 and 3 respectively. In case of dataset 1, the edges of three graphs are concatenated to form a final graph, on which the Node2vec algorithm is applied to generate a final set of features. Similarly, in the dataset 2, the edges of twenty graphs are concatenated to generate a feature set, and in the dataset 3, the edges of one twenty-eight graphs are concatenated to generate a feature set. The classification algorithms is then applied over the feature set to distinguish the healthy and depressed subjects. In dataset 1, the result of the graph-level fusion is reported in Table 3. Among the five classification algorithms applied on the feature vectors which is obtained as a result of the Node2vec algorithm, the KNN classifier gives the highest accuracy of 0.785 in classifying the depressed and healthy subjects. Apart from the accuracy metric, the auc metric is also taken into consideration to determine the performance of the proposed algorithm in distinguishing between depressed and healthy subjects. The KNN al­ gorithm achieves the greatest auc of 0.875, which is the highest among all classifiers in dataset 1 as displayed in Fig. 4. Similarly, for dataset 2, out of the five classifiers, the KNN algorithm gives the highest accuracy of 0.928 in classifying depressed and healthy subjects as noted in Table 4. In dataset 2, the ROC curve is plotted and observed that the KNN algorithm provides the highest auc of 0.962 which is the highest among all the algorithms as shown in Fig. 5. In the dataset 3, on classifying the feature vectors that are obtained by applying Node2vec algorithm on the graph generated as a result of graph-level fusion when passed to five classification algorithms, the KNN algorithm achieves the highest accuracy of 0.857 among all the different classifiers as noted in Table 5. Table 2 Parameters table. Parameters Values No of random walks (r) 10 length of a random walk (l) 100 Return Parameter (m) 0.5 In out Parameter (o) 2.0 Table 3 Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 1 for graph- level fusion. Algorithm Precision Sensitivity Specificity F1-score Accuracy KNN 0.743 0.754 0.782 0.748 0.785 SVM 0.612 0.632 0.629 0.621 0.647 LR 0.723 0.750 0.672 0.734 0.688 LDA 0.675 0.720 0.687 0.624 0.705 XGBoost 0.613 0.637 0.625 0.624 0.647 DT 0.698 0.688 0.673 0.692 0.667 S. Soni et al. Computers in Biology and Medicine 145 (2022) 105420 8 In dataset 3, the ROC curve is plotted and observed that the KNN algorithm provides auc of 0.875 which is the highest among all the al­ gorithms as displayed in Fig. 6. 4.3.2. Feature-level fusion results As stated above in feature level fusion, the EEG signals extracted from different channels are passed individually to the Node2vec algo­ rithm which provides the feature vectors of each channel embedded in a two-dimensional plane, which is then combined and passed to the classification algorithms.In the case of dataset 1, the feature vectors are obtained by combining the features of three channels are then fed into classification algorithms to differentiate between the depressed and healthy subjects. The results show that KNN outperforms the classifi­ cation with the highest accuracy of 0.777 among the five algorithms used in the methodology as described in Table 6. The ROC curve is plotted for feature-level fusion in the case of dataset 1 using different machine learning algorithms KNN algorithm provides the highest auc of 0.742 among all the other classification al­ gorithms used in the proposed methodology as shown in Fig. 7. For the dataset 2, the feature vectors are obtained by combining the feature vectors generated from the twenty channels when passed to the Node2vec algorithm which are then fed to the classification algorithms. The results show that among the five algorithms used in the method­ ology, KNN performs better with the highest accuracy of 0.909, as re­ ported in Table 7. The ROC curve plotted for feature level fusion in the case of the dataset 2 using classification algorithms provides the highest auc of 0.944 in the case of the LR algorithm among all the other algorithms as Fig. 4. ROC curve of dataset 1 for graph-level fusion. Table 4 Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 2 for graph- level fusion. Algorithm Precision Sensitivity Specificity F1-score Accuracy KNN 0.912 0.903 0.923 0.907 0.928 SVM 0.866 0.870 0.910 0.867 0.866 LR 0.857 0/860 0.847 0.858 0.837 LDA 0.713 0.723 0.730 0.717 0.733 XGBoost 0.767 0.790 0.730 0.778 0.823 DT 0.663 0.686 0.678 0.674 0.666 Fig. 5. ROC curve dataset 2 for graph-level fusion. Table 5 Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 3 for graph- level fusion. Algorithm Precision Sensitivity Specificity F1-score Accuracy KNN 0.822 0.862 0.832 0.841 0.857 SVM 0.817 0.823 0.802 0.819 0.833 LR 0.634 0.656 0.602 0.644 0.625 LDA 0.677 0.687 0.632 0.681 0.668 XGBoost 0.666 0.682 0.622 0.673 0.666 DT 0.666 0.672 0.612 0.668 0.625 Fig. 6. ROC curve of dataset 3 for graph-level fusion. S. Soni et al. Computers in Biology and Medicine 145 (2022) 105420 9 displayed in Fig. 8. In the case of dataset 3, the feature vectors obtained by combining the feature vectors of one twenty-eight channels generated by passing the channels individually to the Node2vec algorithm are then passed to the classification algorithms to distinguish depressed and healthy sub­ jects. Out of the five classification algorithms, the KNN algorithm ach­ ieves the highest accuracy of 0.833 as described in Table 8. The ROC curve is plotted for feature-level fusion in the case of dataset 3. The KNN algorithm provides the highest auc of 0.944 among all the other algorithms, as shown in Fig. 9. 4.3.3. Decision-level fusion results As previously stated, decision-level fusion is similar to feature-level fusion with the exception of one additional step. The channels of the EEG dataset were individually passed to the Node2vec algorithm in this Table 6 Precision, Sensitivity, Specificity, f1-scor, and Accuracy in dataset 1 for feature- level fusion. Algorithm Precision Sensitivity Specificity F1-score Accuracy KNN 0.776 0.783 0.792 0.779 0.777 SVM 0.622 0.603 0.643 0.612 0.666 LR 0.678 0.665 0.703 0.671 0.683 LDA 0.613 0.673 0.653 0.641 0.636 XGBoost 0.556 0.543 0.579 0.549 0.555 DT 0.524 0.533 0.563 0.528 0.575 Fig. 7. ROC curve of dataset 1 for feature-level fusion. Table 7 Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 2 for feature-level fusion. Algorithm Precision Sensitivity Specificity F1-score Accuracy KNN 0.875 0.890 0.888 0.882 0.909 SVM 0.788 0.777 0.874 0.782 0.800 LR 0.822 0.833 0.876 0.827 0.908 LDA 0.755 0.733 0.789 0.743 0.802 XGBoost 0.843 0.822 0.868 0.832 0.900 DT 0.643 0.666 0.683 0.654 0.700 Fig. 8. ROC curve of dataset 2 for feature-level fusion. Table 8 Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 3 for feature-level fusion. Algorithm Precision Sensitivity Specificity F1-score Accuracy KNN 0.799 0.811 0.822 0.804 0.833 SVM 0.711 0.732 0.722 0.721 0.752 LR 0.698 0.703 0.702 0.700 0.714 LDA 0.673 0.693 0.687 0.682 0.704 XGBoost 0.587 0.607 0.623 0.596 0.636 DT 0.579 0.542 0.612 0.559 0.606 Fig. 9. ROC curve of dataset 3 for feature-level fusion. S. Soni et al. Computers in Biology and Medicine 145 (2022) 105420 10 fusion method, and the feature vectors obtained are passed to the clas­ sifiers for classification. The predictions obtained from the classifiers for each channel are then analyzed, and a final prediction based on the majority voting rule is obtained. The predictions obtained by the three channels when the feature vectors of each channel are passed to the classification algorithms in the case of dataset 1 are then analyzed and a final prediction decision is made. The KNN algorithm achieves the highest accuracy of 0.823 in classifying depressed and healthy groups using decision-level fusion among all five classification algorithms used in this methodology, as reported in Table 9. The ROC curve plotted in the case of the dataset 1 gave the highest auc of 0.875 with the KNN algorithm when compared to the other al­ gorithms as displayed in Fig. 10. In the case of dataset 2, the predictions that are obtained by the twenty channels when the feature vectors of each channel are passed to the classification algorithm are analyzed and a final prediction decision is taken. The highest accuracy of 0.933 is obtained with the KNN using the decision-level fusion among all the other five classification algo­ rithm used in this methodology as noted in Table 10. In the case of dataset 2, the ROC curve plotted gives the highest auc of 0.964 in the case of the KNN algorithm when compared to the other algorithms as displayed in Fig. 11. The predictions obtained in case of dataset 3 when the feature vec­ tors of each channel are passed to the classification algorithms were analyzed and a final prediction decision is made based on Majority voting rule. The KNN algorithm achieves the highest accuracy of 0.888 among all five classification algorithms used in this methodology, as described in Table 11. The ROC curve plotted in the case dataset 3 gives the highest auc of 0.875 with the KNN algorithm when compared to the other algorithms as shown in Fig. 12. 4.4. Comparative study The proposed method is compared three deep learning methods and three handcrafted feature methods on three datasets that are collected from three different sources. The aim of this work is to check how good the proposed method is over state-of-the-art methods. A comparative analysis to benchmark state-of-the-art methods for depression detection using EEG signals with respect to validation metrics, such as precision, recall, F1-score, and accuracy, is performed. However, the meta-data of these datasets, for example, the sample rate, data size, etc, are not considered, which deserve further study. The comparative study dem­ onstrates that the proposed method outperforms all other methods in terms of validation metrics in detecting depressed and healthy subjects as described in Table 12. 4.5. Empirical study The Node2vec algorithm generates feature vectors by performing biased random walks using four parameters m, o, l, and r. The value of these parameters is decided to be optimal by an experimental study performed on the datasets taking the different values of the parameters. Table 9 Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 1 for decision-level fusion. Algorithm Precision Sensitivity Specificity F1-score Accuracy KNN 0.777 0.818 0.789 0.796 0.823 SVM 0.727 0.723 0.666 0.724 0.714 LR 0.634 0.689 0.646 0.660 0.666 LDA 0.724 0.714 0.750 0.718 0.727 XGBoost 0.513 0.533 0.562 0.522 0.545 DT 0.688 0.673 0.697 0.680 0.683 Fig. 10. ROC curve of dataset 1 for decision-level fusion. Table 10 Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 2 for decision-level fusion. Algorithm Precision Sensitivity Specificity F1-score Accuracy KNN 0.895 0.915 0.923 0.904 0.933 SVM 0.865 0.859 0.908 0.861 0.900 LR 0.877 0.899 0.843 0.875 0.916 LDA 0.832 0.865 0.900 0.848 0.923 XGBoost 0.813 0.842 0.823 0.836 0.866 DT 0.708 0.710 0.702 0.708 0.733 Fig. 11. ROC curve of dataset 2 for decision-level fusion. S. Soni et al. Computers in Biology and Medicine 145 (2022) 105420 11 4.5.1. Varying r with constants m, o, and l The values of m, o, and l are kept constant as reported in Table 2, but different values of r are used, and the change in accuracy is observed. The values taken are 5, 10, 15, 20, and 25. It is discovered that the highest accuracy is obtained when the value of r is set to 10. The experiment is carried out on all three datasets, and the variation in ac­ curacy with change in r value is shown in Fig. 13. 4.5.2. Varying l with constants m, o, and r To observe the change in accuracy, the values of m, o, and r are kept constant as specified in Table 2, and different values of l are used. The values taken are 50, 100, 150, 200, 250, and 300. During the experi­ ment, it is discovered that the case of 100 yielded the highest accuracy. The experiment is carried out on all three datasets, and the variation in accuracy with change in l value is demonstrated in Fig. 14. 4.5.3. Varying m with constants l, o, and v The values of l, o, and r remains constant as noted in Table 2, while different values of m are used to observe the change in accuracy. The values chosen are 0.1, 0.3, 0.5, 0.7, 0.9, and 1.0. While experimenting, it is discovered that the case of 0.5 yielded the highest accuracy. The experiment is carried out on all three datasets, and the variation in ac­ curacy with change in m value is shown in Fig. 15. 4.5.4. Varying o with constants r, l, and m The values of r, l, and m are held constant as specified in Table 2, and the accuracy is measured for a variety of o values. The values of n during the experiment are 0.5, 1.0, 1.5, 2.0, and 2.5. It is discovered that when the value of o are set to 2.0, the highest accuracy is obtained. The experiment is carried out across all three datasets, and the variation in accuracy with change in o value is shown in Fig. 16. 4.6. Discussion We present a discussion on each of the methods implemented and Table 11 Precision, Sensitivity, Specificity, F1-score, and Accuracy in dataset 3 for decision-level fusion. Algorithm Precision Sensitivity Specificity F1-score Accuracy KNN 0.852 0.872 0.863 0.861 0.888 SVM 0.743 0.723 0.733 0.737 0.750 LR 0.788 0.803 0.792 0.795 0.818 LDA 0.743 0.827 0.803 0.782 0.833 XGBoost 0.666 0.653 0.627 0.659 0.666 DT 0.687 0.702 0.692 0.694 0.714 Fig. 12. ROC curve of dataset 3 for decision-level fusion. Table 12 Comparative study: The classification report of AchCNN, AchLSTM, DepreNet, CaiHH-KNN1, CaiH-KNN2, CaiH-DBN and proposed method for dataset 1, dataset 2 and dataset 3. Method Dataset 1 Dataset 2 Dataset 3 Precision Recall f1-score Accuracy Precision Recall f1-score Accuracy Precision Recall f1-score Accuracy AchCNN [42] 0.564 0. 612 0.587 0.635 0.581 0.639 0.610 0.681 0.702 0.713 0.707 0.732 AchLSTM [41] 0.607 0.643 0.624 0.678 0.613 0.913 0.734 0.744 0.744 0.733 0.738 0.753 DeprNet [36] 0.651 0.688 0.668 0.702 0.919 0.887 0.895 0.914 0.775 0.723 0.748 0.782 \CaiH-KNN1 [26] 0.666 0.633 0.649 0.684 0.527 0.655 0.588 0.723 0.688 0.697 0.692 0.703 CaiH-KNN2 [43] 0.668 0.704 0.685 0.713 0.667 0.735 0.699 0.724 0.688 0.701 0.694 0.723 \CaiH-DBN\} [21] 0.622 0.597 0.609 0.635 0,617 0.680 0.647 0.671 0.652 0.643 0.647. 0.662 Proposed Method 0.789 0.818 0.803 0.823 0.888 0.915 0.901 0.933 0.866 0.872 0.871 0.888 Fig. 13. Change in Accuracy with variation in values of r. Fig. 14. Change in Accuracy with variation in values of l. S. Soni et al. Computers in Biology and Medicine 145 (2022) 105420 12 analyzed in this paper. Relying solely on traditional approaches, such as questionnaires, might fail to detect depression. With the technological advances in brain signal analysis, human brain activities in the form of non-invasive EEG recordings can produce more reliable results. In this work, three fusion methods are proposed at three different levels. However, all the three above-said methods exploit Node2vec algo­ rithmic framework. This study evaluates the performance of the pro­ posed methods on the three publicly available pre-processed datasets consisting of 3, 20, and 128 channels, respectively, using different evaluation metrics. Out of them, the performance of the proposed method at the decision level is superior since it tries to combine the decisions of several channels to produce a single final decision using majority voting technique. The decision of each channel is the classifi­ cation conducted on the test dataset. However, the contribution of the individual channels of these datasets towards the performance of the method is not analyzed and will be carried out in near future. 5. Conclusion The study successfully uses the graph representation learning approach for automatically extracting features from each channel and applies three different types of fusion, namely a graph-level fusion, feature-level fusion, and decision-level fusion for analyzing EEG data and classifying healthy and depressed subjects. The proposed method can successfully distinguish the healthy and depressed subjects with the highest accuracy of 0.933, sensitivity of 0.916, specificity of 0.923, the precision of 0.895, f1-score of 0.904, and an auc of 0.966 with the KNN Algorithm in case of decision-level fusion that outperforms the other state-of-art methods. The proposed method’s accuracy is promising, but there is still potential for improvement. The method works by first constructing a graph from the dataset, in which the nodes represent the subjects in the dataset and where the edge weights obtained using the Euclidean distance reflect their relationship. The Node2vec algorithm is applied over the graph to create distinct features in the form of node embeddings, which are then fed to classification algorithms to classify the depressed and healthy subjects. Our next steps will focus on creating a sparse graph rather than a complete graph, which will aid in the extraction of more different characteristics and improve the model’s accuracy. Furthermore, due to the very complicated and informative graph structure, machine learning on graphs is know to be a difficult task. As a result, future research will concentrate on using graph con­ volutional networks (GCNs) to work directly on graphs, leveraging structural information and producing useful feature representations for nodes in the graph, which will help to improve the method’s accuracy in detecting depressed subjects. Declaration of competing interest The authors declare no conflict of interest. Acknowledgment This work is partially supported by the project IT4Neuro (degener­ ation), reg. nr. CZ.02.1.01/0.0/0.0/18 069/0010054 and by the project “Smart Solutions in Ubiquitous Computing Environments”, Grant Agency of Excellence, University of Hradec Kralove, Faculty of Infor­ matics and Management, Czech Republic (under ID: UHK-FIM-GE- 2022). Appendix A. Supplementary data Supplementary data to this article can be found online at org/10.1016/j.compbiomed.2022.105420. References [1] W.H. Organization, et al., Depression and other common mental disorders: global health estimates, Tech. rep. (2017) 1–24. [2] A. Shoeibi, N. Ghassemi, R. Alizadehsani, M. Rouhani, H. Hosseini-Nejad, A. Khosravi, M. Panahiazar, S. Nahavandi, A comprehensive comparison of handcrafted features and convolutional autoencoders for epileptic seizures detection in eeg signals, Expert Systems with Applications 163 (2021) 1–16. [3] S.K. Khare, V. Bajaj, U.R. Acharya, Detection of Parkinson’s disease using automated tunable q wavelet transform technique with eeg signals, Biocybernetics and Biomedical Engineering 41 (2021) 679–689. [4] M. Sharma, U.R. Acharya, Automated Detection of Schizophrenia Using Optimal Wavelet-Based Norm Features Extracted from Single-Channel Eeg, Cognitive Neurodynamics, 2021, pp. 1–14. [5] A. Asif, M. Majid, S.M. Anwar, Human stress classification using eeg signals in response to music tracks, Computers in biology and medicine 107 (2019) 182–196. [6] M. Sharma, J. Tiwari, U.R. Acharya, Automatic sleep-stage scoring in healthy and sleep disorder patients using optimal wavelet filter bank technique with eeg signals, International Journal of Environmental Research and Public Health 18 (2021) 1–29. [7] M.M. Rahman, A.K. Sarkar, M.A. Hossain, M.S. Hossain, M.R. Islam, M.B. Hossain, J.M. Quinn, M.A. Moni, Recognition of human emotions using eeg signals: a review, Computers in Biology and Medicine 136 (2021) 104696. [8] H. Hinrikus, A. Suhhova, M. Bachmann, K. Aadamsoo, Ü. V˜ohma, J. Lass, V. Tuulik, Electroencephalographic spectral asymmetry index for detection of depression, Medical & biological engineering & computing 47 (12) (2009) 1291–1299. [9] V.A. Grin-Yatsenko, I. Baas, V.A. Ponomarev, J.D. Kropotov, Independent component approach to the analysis of eeg recordings at early stages of depressive disorders, Clinical Neurophysiology 121 (2010) 281–289. [10] J.L. Stewart, J.A. Coan, D.N. Towers, J.J. Allen, Resting and task-elicited prefrontal eeg alpha asymmetry in depression: support for the capability model, Psychophysiology 51 (2014) 446–455. [11] G.E. Bruder, J.W. Stewart, D. Hellerstein, J.E. Alvarenga, D. Alschuler, P. J. McGrath, Abnormal functional brain asymmetry in depression: evidence of biologic commonality between major depression and dysthymia, Psychiatry research 196 (2012) 250–254. [12] W. Heller, M.A. Etienne, G.A. Miller, Patterns of perceptual asymmetry in depression and anxiety: implications for neuropsychological models of emotion and psychopathology, Journal of abnormal psychology 104 (1995) 327–333. [13] S.D. Puthankattil, P.K. Joseph, Classification of eeg signals in normal and depression conditions by ann using rwe and signal entropy, Journal of Mechanics in Medicine and biology 12 (2012) 1240019. [14] A. Gaouda, M. Salama, M. Sultan, A. Chikhani, Power quality detection and classification using wavelet-multiresolution signal decomposition, IEEE Transactions on power delivery 14 (1999) 1469–1476. Fig. 15. Change in Accuracy with variation in values of m. Fig. 16. Change in Accuracy with variation in values of o. S. Soni et al. Computers in Biology and Medicine 145 (2022) 105420 13 [15] M. Ahmadlou, H. Adeli, A. Adeli, Fractality analysis of frontal brain in major depressive disorder, International Journal of Psychophysiology 85 (2012) 206–211. [16] M. Bachmann, J. Lass, A. Suhhova, H. Hinrikus, Spectral asymmetry and higuchi’s fractal dimension measures of depression electroencephalogram, Computational and mathematical methods in medicine 2013 (2013) 1–9. [17] T.Q.D. Khoa, V.Q. Ha, V.V. Toi, Higuchi fractal properties of onset epilepsy electroencephalogram, Computational and mathematical methods in medicine 2012 (2012) 1–7. [18] B. Hosseinifard, M.H. Moradi, R. Rostami, Classifying depression patients and normal subjects using machine learning techniques and nonlinear features from eeg signal, Computer methods and programs in biomedicine 109 (2013) 339–345. [19] O. Faust, P.C.A. Ang, S.D. Puthankattil, P.K. Joseph, Depression diagnosis support system based on eeg signal entropies, Journal of mechanics in medicine and biology 14 (2014) 1450035. [20] U.R. Acharya, V.K. Sudarshan, H. Adeli, J. Santhosh, J.E. Koh, S.D. Puthankatti, A. Adeli, A novel depression diagnosis index using nonlinear features in eeg signals, European neurology 74 (2015) 79–83. [21] H. Cai, X. Sha, X. Han, S. Wei, B. Hu, Pervasive eeg diagnosis of depression using deep belief network with three-electrodes eeg collector, in: 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), IEEE, 2016, pp. 1239–1246. [22] W. Mumtaz, L. Xia, S.S.A. Ali, M.A.M. Yasin, M. Hussain, A.S. Malik, Electroencephalogram (eeg)-based computer-aided technique to diagnose major depressive disorder (mdd), Biomedical Signal Processing and Control 31 (2017) 108–115. [23] H. Liu, H. Motoda, Computational Methods of Feature Selection, CRC Press, 2007, pp. 1–440. [24] S.-C. Liao, C.-T. Wu, H.-C. Huang, W.-T. Cheng, Y.-H. Liu, Major depression detection from eeg signals using kernel eigen-filter-bank common spatial patterns, Sensors 17 (2017) 1385. [25] M. Sharma, P. Achuth, D. Deb, S.D. Puthankattil, U.R. Acharya, An automated diagnosis of depression using three-channel bandwidth-duration localized wavelet filter bank with eeg signals, Cognitive Systems Research 52 (2018) 508–520. [26] H. Cai, J. Han, Y. Chen, X. Sha, Z. Wang, B. Hu, J. Yang, L. Feng, Z. Ding, Y. Chen, et al., A pervasive approach to eeg-based depression detection, Complexity 2018 (2018), 5238028. [27] S. Byun, A.Y. Kim, E.H. Jang, S. Kim, K.W. Choi, H.Y. Yu, H.J. Jeon, Detection of major depressive disorder from linear and nonlinear heart rate variability features during mental task protocol, Computers in biology and medicine 112 (2019) 103381. [28] H. Cai, Z. Qu, Z. Li, Y. Zhang, X. Hu, B. Hu, Feature-level fusion approaches based on multimodal eeg data for depression recognition, Information Fusion 59 (2020) 127–138. [29] A. Grover, J. Leskovec, node2vec: scalable feature learning for networks, in: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM, 2016, pp. 855–864. [30] Y. Wu, Y. Bian, X. Zhang, Remember where you came from: on the second-order random walk based proximity measures, Proceedings of the VLDB Endowment 10 (2016) 13–24. [31] S. Chauhan, M. Singh, A.K. Aggarwal, Data science and data analytics: Artificial intelligence and machine learning integrated based approach, Data Science and Data Analytics: Opportunities and Challenges (2021) 1. [32] A. Kaur, A.P.S. Chauhan, A.K. Aggarwal, An automated slice sorting technique for multi-slice computed tomography liver cancer images using convolutional network, Expert Systems with Applications 186 (2021) 115686. [33] A. Kaur, A.P.S. Chauhan, A.K. Aggarwal, Machine learning based comparative analysis of methods for enhancer prediction in genomic data, in: 2019 2nd International Conference on Intelligent Communication and Computational Techniques (ICCT), IEEE, 2019, pp. 142–145. [34] A.P. Bradley, The use of the area under the roc curve in the evaluation of machine learning algorithms, Pattern recognition 30 (1997) 1145–1159. [35] H. Cai, Y. Gao, S. Sun, N. Li, F. Tian, H. Xiao, J. Li, Z. Yang, X. Li, Q. Zhao, et al., Modma Dataset: a Multi-Modal Open Dataset for Mental-Disorder Analysis, 09283, 2002. arXiv preprint arXiv. [36] A. Seal, R. Bajpai, J. Agnihotri, A. Yazidi, E. Herrera-Viedma, O. Krejcar, Deprnet: a deep convolution neural network framework for detecting depression using eeg, IEEE Transactions on Instrumentation and Measurement 70 (2021) 1–13. [37] R. Thukral, A. Arora, A. Kumar, et al., Denoising of thermal images using deep neural network, in: Proceedings of International Conference on Recent Trends in Computing, Springer, 2022, pp. 827–833. [38] R. Thukral, A. Kumar, A. Arora, et al., Effect of different thresholding techniques for denoising of emg signals by using different wavelets, in: 2019 2nd International Conference on Intelligent Communication and Computational Techniques (ICCT), IEEE, 2019, pp. 161–165. [39] S.-I. Liu, Z.-T. Yeh, H.-C. Huang, F.-J. Sun, J.-J. Tjung, L.-C. Hwang, Y.-H. Shih, A. W.-C. Yeh, Validation of patient health questionnaire for depression screening among primary care patients in taiwan, Comprehensive psychiatry 52 (2011) 96–101. [40] L. Van der Maaten, G. Hinton, Visualizing data using t-sne, Journal of machine learning research 9 (2008) 1–27. [41] B. Ay, O. Yildirim, M. Talo, U.B. Baloglu, G. Aydin, S.D. Puthankattil, U. R. Acharya, Automated depression detection using deep representation and sequence learning with eeg signals, Journal of medical systems 43 (7) (2019) 1–12. [42] U.R. Acharya, S.L. Oh, Y. Hagiwara, J.H. Tan, H. Adeli, D.P. Subha, Automated eeg- based screening of depression using deep convolutional neural network, Computer methods and programs in biomedicine 161 (2018) 103–113. [43] S. Zheng, C. Lei, T. Wang, C. Wu, J. Sun, H. Peng, Feature-level fusion for depression recognition based on fnirs data, in: 2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), IEEE, 2020, pp. 2906–2913. S. Soni et al."
A novel multi-scale based deep convolutional neural network for detecting COVID-19 from X-rays,Mohan Karnati and Ayan Seal and Geet Sahu and Anis Yazidi and Ondrej Krejcar,2022,,125,Applied Soft Computing,article,"Applied Soft Computing 125 (2022) 109109
Contents lists available at ScienceDirect
Applied Soft Computing
journal homepage: www.elsevier.com/locate/asoc
A novel multi-scale based deep convolutional neural network for
detecting COVID-19 from X-rays
Mohan Karnati a, Ayan Seal a,∗, Geet Sahu a, Anis Yazidi b,c,d, Ondrej Krejcar e,f
a Department of Computer Science and Engineering, PDPM Indian Institute of Information Technology Design & Manufacturing Jabalpur,
Jabalpur, Madhya Pradesh 482005, India
b Department of Computer Science, OsloMet – Oslo Metropolitan University, Oslo, 460167, Norway
c Department of Computer Science, Norwegian University of Science and Technology, Trondheim, 460167, Norway
d Department of Plastic and Reconstructive Surgery, Oslo University Hospital, Oslo, 460167, Norway
e Center for Basic and Applied Science, Faculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 500 03 Hradec
Kralove, Czech Republic
f Malaysia-Japan International Institute of Technology (MJIIT), Universiti Teknologi Malaysia, Jalan Sultan Yahya Petra, 54100 Kuala
Lumpur, Malaysia
a r t i c l e
i n f o
Article history:
Received 23 October 2021
Received in revised form 26 April 2022
Accepted 26 May 2022
Available online 6 June 2022
Keywords:
COVID-19
Chest X-ray
Deep neural network
Internet of things
a b s t r a c t
The COVID-19 pandemic has posed an unprecedented threat to the global public health system,
primarily infecting the airway epithelial cells in the respiratory tract. Chest X-ray (CXR) is widely
available, faster, and less expensive therefore it is preferred to monitor the lungs for COVID-19
diagnosis over other techniques such as molecular test, antigen test, antibody test, and chest computed
tomography (CT). As the pandemic continues to reveal the limitations of our current ecosystems,
researchers are coming together to share their knowledge and experience in order to develop new
systems to tackle it. In this work, an end-to-end IoT infrastructure is designed and built to diagnose
patients remotely in the case of a pandemic, limiting COVID-19 dissemination while also improving
measurement science. The proposed framework comprises six steps. In the last step, a model is
designed to interpret CXR images and intelligently measure the severity of COVID-19 lung infections
using a novel deep neural network (DNN). The proposed DNN employs multi-scale sampling filters
to extract reliable and noise-invariant features from a variety of image patches. Experiments are
conducted on five publicly available databases, including COVIDx, COVID-19 Radiography, COVID-
XRay-5K, COVID-19-CXR, and COVIDchestxray, with classification accuracies of 96.01%, 99.62%, 99.22%,
98.83%, and 100%, and testing times of 0.541, 0.692, 1.28, 0.461, and 0.202 s, respectively. The obtained
results show that the proposed model surpasses fourteen baseline techniques. As a result, the newly
developed model could be utilized to evaluate treatment efficacy, particularly in remote locations.
© 2022 Elsevier B.V. All rights reserved.
1. Introduction
COVID-19 was originally identified in China in December 2019
and has infected over a hundred million people around the world.
The World Health Organization (WHO) declared a pandemic on
March 11, 2020. In almost 74% of the cases, the infections are
either minor (18%) or severe symptoms (56%). However, the
remaining 26% vary from critical (20%) to an extreme symp-
toms (6%) [1]. As of today (28/05/2021), the world’s cumulative
number of COVID-19 infections is more than 169 million, and
the death toll overpasses 3.52 million, while 151 million cases
recovered completely. Moreover, the number of active instances
is 14.74 million, among which 14,648,154 events are in minor
∗Corresponding author.
E-mail address:
ayan@iiitdmj.ac.in (A. Seal).
condition, and 93,863 events are in serious condition [2]. Table 1
summarizes some major statistical parameters related to the
pandemic COVID-19 in several countries. The novel COVID-19
disease emerges with throat inflammation, fever, and respiratory
distress, then progresses to breathing difficulties. The infection
could cause the severe acute respiratory syndrome, pulmonary
hypertension, organ failure, and, ultimately, death of the pa-
tient [3]. Recent studies suggest that men are more likely to
get affected than women. In this perspective, men represent 60%
of the cases, and there were no reported substantial mortality
rates among children younger than nine years [4]. Furthermore,
COVID-19 infected patients must isolate themselves and adopt
appropriate preventive steps to safeguard healthy individuals,
thereby breaking the infection chain [4,5]. Historical data have
shown that the infection rate grows exponentially rather than
linearly if preventive measures are not utilized effectively, and
https://doi.org/10.1016/j.asoc.2022.109109
1568-4946/© 2022 Elsevier B.V. All rights reserved.
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
Table 1
Statistics on COVID-19 outbreaks.
Countries
Confirmed
Deaths
Recovered
USA
33,999,680
607,726
27,701,879
India
27,555,457
318,895
24,893,410
Brazil
16,342,162
456,753
14,786,292
Russia
5,044,459
120,406
4,661,234
UK
4,473,677
127,758
4,310,572
France
5,635,629
109,165
5,284,264
Turkey
5,220,549
46,970
5,070,815
Germany
3,673,969
88,689
3,461,700
Italy
4,205,970
125,793
3,826,984
in some cases, the pandemic may reach a tipping point beyond
which the infection rate becomes uncontrollable. In many circum-
stances, it would put a strain on the limited medical resources
available for diagnosis. COVID-19 is diagnosed using at least one
of the three methods listed below:
• RT-PCR: For antigen detection testing, [6,7] uses a nose
blood sample and a venous blood sample. In some countries,
such as India, these procedures necessitate contact between
patients and physicians, which might take anything from
a few hours to three days to receive results. Some studies
have found that the results of numerous RT-PCR tests per-
formed at different times for the same patient can differ,
resulting in a high false negative (FN) diagnostic rate [8].
Many researchers suggested combining the RT-PCR test with
additional clinical exams, such as computed tomography
(CT), to improve the accuracy of the diagnosis.
• CT scan: COVID-19 patients mostly become infected with
lung disease at an early stage of the disease. The most preva-
lent COVID-19 lung symptoms are consolidation, i.e. fluid
and bone accumulations in lung blood vessels that pre-
vent ground-glass opacity, gas exchange, and nodular shad-
owing. These symptoms are frequently present in the
middle and lower lung regions and can be used to dis-
tinguish between people infected with non-COVID-19 and
COVID-19 [9,10]. In comparison to RT-PCR, CT equipment
generates images for faster COVID-19 screening [11]. CT
scan-based measurement entails assessing 3D radiographic
imaging of the lungs from multiple perspectives. Manual
examination of COVID-19 from chest CT scans, on the other
hand, is a labor-intensive, and time-consuming procedure
since medical practitioners must find lesions slice-by-slice
from volumetric CT images.
• Chest X-ray (CXR): In comparison to CT, CXR equipment
is smaller and more portable. In hospitals, this type of re-
source is usually more accessible than RT-PCR and CT-scan.
Furthermore, because the CXR test lasts around 15 s per
subject [12], it is one of the most cost-effective pieces of
evaluation equipment.
In medical treatment, a reliable computer-aided diagnostic
system that analyzes CXR for precise, rapid screening and diag-
nosis of COVID-19 patients is required, reducing the workload
on the medical staff. However, such a diagnosis is difficult to
automate because CXR images of pneumonia exhibit similar types
of defects in the lung territories. Therefore, relying only on classi-
cal computer vision techniques which are based on hand-crafted
descriptors might be deemed to failure due to the difficulty to
handle the distinctive features of pneumonia targets.
1.1. Motivation and contribution
In recent years, tremendous progress has been made in mea-
surement science by applying deep neural networks (DNN) tech-
niques to computer vision applications such as salient object
detection [13,14], facial expression recognition [15,16], and de-
ception detection [17], thus DNN models have become the defacto-
standard nowadays. DNN has specialized in learning-rich images
with high-level discriminatory semantic characteristics automat-
ically, eliminating the need for hand-crafted descriptors. These
breakthroughs have revealed that deeper models can improve
results [16]. Thus, it is viable to train a DNN model to obtain
promising performance in COVID-19 screening and monitoring.
Moreover, technological advancement has enabled the manufac-
turing of low-cost portable computing devices for consumers.
Cellular devices have advanced in terms of technical capabil-
ities and processing power, and they have become a source
of information, interaction, and sharing. They are now almost
indispensable in our daily lives. Internet of Things (IoT) with
cellular devices have permitted a far wider range of uses, not
only for entertainment but also for the treatment and monitor-
ing of health requirements, environmental surveillance, home
automation, and many more [18]. Therefore, the motivation for
this study is twofold. Firstly, there is a lack of resources and
screening tools for identifying and monitoring COVID-19 patients,
and secondly, DNN has a great potential for fetching features
and accurately classifying images without any manual interven-
tion. This work introduces a framework that includes a novel
DNN enabled IoT service to intelligently measure the severity of
COVID-19 lung infections by analyzing CXR images. The proposed
DNN module consists of multi-scale sampling filters that allow
extracting more reliable and noise-invariant features at different
image patches. We have circumvent the shortcomings of the ex-
isting DNN models and achieve superior performance by carefully
designing the proposed DNN model-based multi-scale sampling.
All the experiments are implemented on five databases, namely
COVIDx (D1) [19], COVID-19 Radiography (D2) [20], COVID-XRay-
5K (D3) [21], COVID-19-CXR (D4) [22], and COVID-chestxray
(D5) [23]. The proposed framework is compared with fourteen
existing approaches by utilizing four well-known classification
metrics viz., F1-score, recall, precision, and accuracy. Empiri-
cal evidence manifests that the proposed method outranks all
the fourteen existing approaches. The integration of the pro-
posed algorithm with an IoT framework results in an efficient
and precise real-time online service for COVID-19 diagnosis. The
contributions of this study can be summarized as follows:
• A detection and monitoring tool for the diagnosis of COVID-
19 patients is introduced. This framework is instrumented
with an IoT system that helps to oversee both potential
and real cases. Thus, the newly developed equipment can
be employed to observe patients efficiently, especially in a
remote location.
• A novel DNN framework is designed for distinguishing non-
COVID-19 from COVID-19 classes using CXR images. The
use of X-ray simplifies the implementation of the proposed
method in real-world scenarios. When compared to other
testing procedures, X-rays are less expensive and take less
time.
• The proposed DNN consists of multi-scale filters. The
strength of multi-scale sampling filters to fetch robust and
noise invariant facets with distinguishing power is exploited.
We hypothesize that by integrating multi-scale feature ex-
traction, we can learn more resilient convolutional filters
since the scale of features varies substantially among dis-
tinct ground objects captured from several sensing devices.
Moreover, our proposed DNN is simple as it has fewer layers
and learning parameters.
• We give insights into the theoretical enhancement made
to
the
DNN
model
and
document
their
empowering
effect through experiments. The experimental results il-
lustrate that the computation cost is considerably lower
compared with some related approaches. This confirms that
our approach is more computationally efficient.
2
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
The organization of the current study is structured as follows: A
concise summary of a few notable previous approaches related
to COVID-19 classification is put forward in Section 2. Section 3
describes the proposed work in depth. The obtained outcomes
of the proposed model along with other baseline approaches are
reported in Section 4. At last, Section 5 concludes the current
study.
2. Related work
Some recent developments in diagnosis the COVID-19 utilizing
machine learning (ML) and deep learning (DL) techniques are
thoroughly described in this section.
In the field of medical imaging, DL techniques have classi-
cally discovered a large set of applications ranging from diabetic
retinopathy, histological examination, cardiac imaging, tumor de-
tection, to mention a few. An emerging application of DL is to
diagnose COVID-19 using CXR images, CT-scans [24], etc. Several
researchers have published a set of pre-print papers tackling the
problem of COVID-19 detection from CXR [19]. The reported re-
sults from the latter study document promising outcomes, how-
ever, they are based on small databases, which is far from the real
implementation. These solutions would need to be thoroughly
tested and improved before they could be put into use.
Typically, researchers rely on DL techniques to classify any
specific characteristics of COVID-19 patients from CXR images.
DL is known to be efficient in the detection of different lung-
related diseases based on chest radiography images. A plethora
of legacy studies applying ML and DL algorithms to analyze
the X-ray and CT images can be found in the literature [19,
25,26]. With the upsurge of the COVID-19, many recent pieces
of research have investigated the usefulness of radiological im-
ages for COVID-19 detection. In [19], Wang et al. presented a
COVID-Net for COVID-19 detection. Further, Hemdan et al. [26]
suggested an alternative approach named COVIDX-Net, consisting
of seven DNN variants to detect COVID-19 from CXR images.
However, these methods suffer from overfitting problem and
are hard to implement in real-time applications since it has a
larger network. To make it evident, the training and validation
losses obtained by these two methods are analyzed and it is
observed that the gap between training and validation losses is
greater. Ohata et al. [27] employed transfer learning to further
train various pre-trained DL models to fetch facets and accurately
predict COVID-19. Tabik et al. [28] suggested a COVID-SDNet,
which consists of several DNN networks for COVID-19 classifi-
cation. However, these methods are very time-consuming. Arias
et al. [29] presented an automatic detection of COVID-19 (AD-
COVID19) using DNN with a segmentation approach. In [30],
Wang et al. used a prior residual learning approach for classifying
COVID-19 robustly. However, it has a large number of param-
eters, hence it is hard to implement in real-time applications,
especially in health care for monitoring COVID-19 patients. Khan
et al. [22] utilized pre-trained XCeption architecture and further
trained it on CXR images of COVID-19 and other chest pneumonia
from two separate publicly accessible databases. Furthermore,
Jian et al. [25] presented a DL model that directly used pre-trained
models like ResNeXt, XCeption, and Inception-V3 for COVID-19
detection from CXR images. Similarly, Apostolopoulos et al. [31]
used a transfer learning approach with VGG-19 and MobileNet.
These methods, have a large number of parameters and require
complex computational resources to train. In [32], DarkCovid-
Net is presented for classification and detection of COVID-19.
In [33], five pre-trained models, namely ResNet50, ResNet101,
ResNet152, InceptionV3 and Inception-ResNetV2, are employed
for classifying COVID-19 effectively.
Some researchers have presented IoT-based diagnosis systems
that collect relevant sensor data and process it in the cloud. With
the advent of IoT, it has become a critical component of many
environmental monitoring and healthcare applications.
In [34], Nguyen provided a review of the artificial intelli-
gence (AI) methods used in COVID-19 analysis. These approaches
were divided into several categories, including the use of IoT.
Maghdid [35] explored that sensors on smartphones can be used
to acquire health information such as temperature. Rao and
Vazquez [36] investigated the utility of ML techniques on user
data gathered via a web-based survey obtained from smartphones
for quick COVID-19 screening. In [37], Allam and Jones suggested
a method to detect potential COVID-19 patients using images
from a thermal camera. Otoom et al. [38] presented an IoT-based
real-time detection, observation, and inspection of COVID-19
system using eight ML algorithms, namely k-nearest neighbor
(KNN), support vector machine (SVM), artificial neural network
(ANN), Naive Bayes, decision stump, decision table, one rule
(OneR), and zero rule (ZeroR). Zhang et al. [39] presented a
residual learning diagnosis detection (RLDD) system for COVID-19
classification. A residual block was used in this method to train a
DNN, which is quite large, therefore complex calculations are re-
quired. Furthermore, they presented an industrial IoT framework,
but no comprehensive definition of how or where it should be
implemented was provided. However, the performance of these
methods falls short on small databases.
3. Proposed method
This section offers a brief overview of the proposed DL-based
IoT service for evaluating CXR images and diagnosing COVID-19
effectively. Due to the reliance on classical ML approaches on hu-
man skill for feature creation, as well as DL advancements in the
domain of computer vision, we propose a DL model for automatic
feature engineering in this study. We will also demonstrate how
our DL-based algorithm can be linked to an IoT service to create
a complete diagnosis chain.
3.1. The IoT framework
Social distancing is a non-pharmaceutical method of preven-
tion. When we are forced to stay locked up in our homes, the
IoT revolution plays an important role in modern healthcare
systems in terms of professional, social, and economic prospects.
As a result, in the context of the current pandemic, IoT-enabled
applications can be used to reduce the potential spread of COVID-
19 through early and remote diagnosis. As a result, the present
study introduces an end-to-end IoT framework to help virtually
the patients in remote locations in the event of a pandemic. The
challenges associated with each layer of the proposed framework
are addressed, and design guidelines for dealing with them are
discussed. This sub-section describes the developed IoT-based
framework for observing and recognizing COVID-19 cases. This
framework can also be used to track how well-reported patients
respond to treatment and learn more about the COVID-19 disease.
The proposed IoT framework is shown in Fig. 1, consisting of six
steps labeled from 1–6. The doctor can upload a COVID-19 X-
ray image or a group of images to an internet application from
this screen. This method will extract information from images
and classify them as non-COVID-19 or COVID-19. The proposed
method extracts features from an image using the DNN model,
followed by a softmax classifier that uses the extracted features as
inputs to classify COVID-19. This method makes use of the LINDA,
which is available as a web service. It consists of a processing
flow that can (i) extract, (ii) train, (iii) predict, and (iv) store
the statistics and results obtained for COVID-19 recognition. All
computational processing for this IoT system is done in the cloud.
The server is housed at the Instituto Federal de Educaço, Ciência,
3
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
Fig. 1. Schematic illustration of the LINDA approach for IoT-based COVID-19 detection and classification in CXR images. (1) new images can be sent for training or
prediction using the same software. (2) users can define system parameters using a web application; (3) training results are displayed in plots and tables; and (4)
API prediction is in charge of image processing based on the parameters set in the web application, (5) medical analysis by the doctors, and, finally, (6) Diagnostic
process by the proposed DNN model.
Fig. 2. Diagram showing the processing steps starting from five X-ray databases,
extracting facets of the COVID-19 X-ray images based on DNN, and the
classification step with softmax classifiers.
e Tecnologia do Ceará. LINDA has recently gained popularity, and
it has been used to develop not only medical IoT services such as
stroke classification based on cerebral vascular accident images,
melanocytic lesion classification based on skin images [40,41], but
also machine condition monitoring [42].
When patients exhibit COVID-19-related symptoms, smart-
phones, computers, and other electronic devices are permitted
to transmit information and X-ray images to LINDA. A user can
perform a variety of operations in LINDA, including defining
the number of classes, configuring the extraction and classifier
characteristics, and changing the extractors and classifiers used.
LINDA also includes a graphical dashboard with metrics for eval-
uating the performance of the extractor and classifier. The IoT
system supports the Python programming language, the Post-
greSQL database, the TensorFlow, and Keras frameworks. The flow
of the developed LINDA-based IoT system is depicted in Fig. 2: the
first phase entails integrating the five X-ray image databases, as
well as the feature extraction and classification procedures.
The data flow of the LINDA system is depicted in detail in
Fig. 1. The information flow of the LINDA system will begin by
sending an image from a device, as shown in Fig. 1 by the number
1. A security hash code will also be sent to the system. The
system will then call the prediction API, which will select the
algorithms to use based on the secure hash. The required models
will be loaded into memory. If the system settings have not been
completed and some changes are required, the web application
(number 2) will be used to upload and categorize images. The
proposed DNN is deployed on this platform, and the algorithm
was trained on five databases. Section 3.2 contains a detailed de-
scription of DNN. To learn more about LINDA, interested readers
should visit [43]. The proposed method has three advantages:
• There is no need for face-to-face communication between
physicians and subjects, which reduces medical staff expo-
sure to infection.
• The proposed application diagnoses the X-ray image in less
than a second, allowing faster response in case of positive
cases.
• By virtue of enjoying a short development cycle, the pro-
posed IoT-based service can be easily upgraded at a minimal
cost without disrupting the service.
3.2. The proposed DNN architecture
In this study, we developed a multi-scale DNN system for
extracting and recognizing COVID-19 features from CXR images.
DNN automatically learns the various features from X-ray images
using different scales, and these facets are learned by training the
network over several iterations. In previous research, researchers
discovered that convolutional sampling on fixed scales frequently
limits a DNN’s ability to find local invariant patterns, whereas
multi-scale sampling allows a DNN to find more reliable and
noise-invariant features at different image patches. To address
this scope in the context of the current study, a variable filter size
(7 × 7, 5 × 5, 3 × 3) is used at various convolutional layers with
strides of 1 × 1. Before training the network, pre-processing is
performed on X-ray images as shown in Fig. 3. Fig. 4 displays the
architecture of the proposed DNN. The DNN extracts robust and
geometrically invariant patterns from different patches of X-ray.
The input to the DNN is gray-scale images. The proposed DNN
consists of 5 blocks. The first block contains 3 convolutional layers
with different filter banks and Block2 consisting of pooling layers,
which are stacked with Block1 convolutional layers as shown in
Fig. 4. The features obtained from the Block2 are concatenated
into a single feature vector. Later, three convolution operations
are applied with various filter banks (i.e. Block3) on concatenated
vector and combined all the features obtained from Block3, then,
they are stacked with a single convolutional layer consisting of
1 × 1 filter bank followed by max-pooling operation with filter
size 4 × 4. Finally, we find Block5 which is composed of two fully
connected (FC) layers and a softmax layer of sizes 256, 512, and
4
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
Fig. 3. Preprocessing stages for X-ray images. The preprocessing step includes the normalization of X-ray pixels between 0 and 1, image resize, and image
augmentation.
Fig. 4. Illustration of the phases of the proposed DNN framework for COVID-19 detection. First, the network is trained with labeled data. We input the images to
be tested into the network in the testing phase, compute the class probability (CP) of COVID-19 and non-COVID-19, and provide the diagnostic results.
2. Technically, the first four blocks (Block1, Block2, Block3, Block4)
are considered for feature extraction and the last block (Block5) is
employed for classifying COVID-19 using X-rays i.e. final mapping
to the output. Table 2 reports the comprehensive description of
each layer and its parameters.
Furthermore, filters 7 × 7, 5 × 5, and 3 × 3 are utilized to
capture the enriched contextual information. Moreover, the 1 × 1
filter is used as an identity function.
L1=f 1
1,p(size:7×7),b1
p(size:1×1),p=1,2,...,32
L2=f 1
1,q(size:5×5),b1
q(size:1×1),q=1,2,...,32
L3=f 1
1,r (size:3×3),b1
r (size:1×1),r=1,2,...,32
L4=f 2
p,x(size:7×7),b2
x (size:1×1),s=1,2,...,64
L5=f 2
q,y(size:5×5),b2
y(size:1×1),u=1,2,...,64
L6=f 2
r,z(size:3×3),b2
z (size:1×1),v=1,2,...,64
L7=f 3
c,w(size:1×1),b3w(size:1×1),w=1,2,.128
(1)
Smaller window sizes (i.e., 2 × 2) are used for the pooling layer
in the proposed method as the highest information loss occurs
due to the pooling layers. A max-pooling scheme is considered
in this work. The formal description of the model is defined
mathematically by Eq. (1). The filter initialization values f i
i,k is
selected at random from the distribution defined by the filter
size, input, and output number of the specific layer’s feature maps
where a uniform distribution with upper and lower bounds of ±k
is defined by U(±k). The mathematical formulation for uniform
distribution of filter initialization is shown in Eq. (2).
f 1
1,p∼U
(
±
√
32
(1+32)×7×7
)
,f 1
1,q∼U
(
±
√
32
(1+32)×5×5
)
f 1
1,r∼U
(
±
√
32
(1+32)×3×3
)
,f 2
p,x∼U
(
±
√
64
(1+64)×7×7
)
f 2
q,y∼U
(
±
√
64
(1+64)×5×5
)
,f 2
r,z∼U
(
±
√
64
(1+64)×3×3
)
f 2
c,w∼U
(
±
√
128
(1+128)×1×1
)
(2)
The total number parameters are the sum of the parameters of
each layer, where the number of parameters of each convolution
layer is (f × f × (wp + b)) × fo, where f is a filter bank size, p is
the input number of feature maps, and b is a bias i.e., 1 and fo is
the output number of feature maps. The representation of the ith
convolutional layer, Li is shown in Eq. (3). Where ∆(.) denotes
an activation function of a layer. Rectified linear unit (ReLU) is
an activation function adopted in this work, where fm ∈(1, fo),
fo defines the number of facets maps exist in the layer Li, e is
the number of input facets maps in previous layer i.e., Li−1
e
. a, b
denotes the coordinates of the feature maps, and ⋆indicates
convolution operation. Eq. (3) is further elaborated as shown in
5
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
Table 2
Demonstration of the network parameters employed in the proposed DNN architecture. Here, BN →batch
normalization.
R. NO
Layer
Type
Filter size
Stride
Padding
Activation
Output
1.
I
Input
–
–
–
–
128 × 128 × 1
2.
L1
Convolution
7 × 7
1
Same
ReLU
128 × 128 × 32
3.
L2
Convolution
5 × 5
1
Same
ReLU
128 × 128 × 32
4.
L3
Convolution
3 × 3
1
Same
ReLU
128 × 128 × 32
5.
M1
Max-pooling + BN
2 × 2
2
Valid
–
64 × 64 × 32
6.
M2
Max-pooling + BN
2 × 2
2
Valid
–
64 × 64 × 32
7.
M3
Max-pooling + BN
2 × 2
2
Valid
–
64 × 64 × 32
8.
C1
Concatenation
–
–
–
–
64 × 64 × 96
9.
L4
Convolution
7 × 7
1
Same
ReLU
64 × 64 × 64
10.
L5
Convolution
5 × 5
1
Same
ReLU
64 × 64 × 64
11.
L6
Convolution
3 × 3
1
Same
ReLU
64 × 64 × 64
12.
C2
Concatenation
–
–
–
–
64 × 64 × 192
13.
L7
Convolution
1 × 1
1
Valid
ReLU
64 × 64 × 64
14.
M4
Max-pooling + BN
4 × 4
4
Valid
–
16 × 16 × 64
15.
F
Flatten
–
–
–
–
16384 × 1
16.
FC1
Full-connection
–
–
–
ReLU
512 × 1
17.
FC2
Full-connection
–
–
–
ReLU
256 × 1
18.
CP
Class probabilities
–
–
–
Softmax
2 × 1
Eq. (4).
Li
fm =∆
(
Li−1
e
⋆f i
e,fm +bi
fm
)
,
(3)
Li
fm (a,b)=
∆
(
∑m
u=−m
∑m
v=−m Li−1
e
(a−u,b−v)·f i
e,fm (u,v)+bi
fm
)
(4)
The filter bank size of the layer Li is (2 × m + 1) × (2 × m + 1).
In the proposed model, the ‘‘same’’ padding is applied to keep
the size of the feature map constant. Max-pooling operation is
performed on the output of convolutional layer Li
fm with filter
bank of size 2 × 2. From each feature map, max-pooling measures
the utmost importance of each patch to highlight the primary
feature represented within the patch. Max-pooling also reduces
the number of parameters to make the model simple, In addition,
it provides feature maps that are invariant to translation, rotation,
and scale. As shown in Fig. 4, the input images of 128 × 128 pixels
are down-sampled by the max-pooling layer, resulting in filter
maps of various sizes after each layer of convolution in the Block2,
later concatenated, with C1 being the output obtained by the
max-pooling layer. Further, Block3 is stacked with C1, containing
variable sizes of filter banks for convolution operation. Followed
by concatenation operation, C2 is applied on outputs of Block3,
which is called Block4. The convolution operation with filter bank
of 1 × 1 is applied on output feature maps of Block4 followed by a
max-pooling operation, then all the feature maps are flattened to
a single vector of size 16384 × 1, where Wi and bi are the weight
and bias of the ith FC layer. The output of the second FC layer, FC2,
is further fed into the softmax layer. The softmax layer consists
of two neurons and produces a probability vector, ˆZ = [ ˆzc, ˆznc],
where, ˆzc is the prediction score of COVID-19 class and ˆznc of non-
COVID-19 class. The jth probability value is obtained by Eq. (5).
ˆZj =
eFCj
2
∑2
j=1 eFCj
2
, j = 1, 2.
(5)
3.2.1. Network training
The proposed network trains on X-ray images and computes
the probability of each class, CP. The weights of the proposed
network are initialized randomly with the help of uniform distri-
bution as shown in Eq. (2) and the adaptive momentum (Adam)
optimization technique employed to tune the hyperparameters
to minimize the loss between predicted class probabilities, ˆZ =
[ ˆzc, ˆ
znc] and actual class probabilities, Z = [zc, znc] of COVID-19.
The initial learning rate and weight decay are fixed as 0.00001 in
Adam. As a loss function for the classifier, we use cross-entropy.
Eq. (6) is employed to compute the cross-entropy.
ψ(Z, ˆZ) = −Z log ˆZ
= −[zc, znc] log[ ˆzc, ˆznc]
= −zc · log( ˆzc) −znc · log(ˆznc)
(6)
with the batch size S, the loss function is given in Eq. (7).
ψ(Z, ˆZ) = −
(
1
S
S
∑
i=1
zc · log ˆzc + (znc) · log(ˆznc)
)
,
(7)
where Z(= [z1, z2]) is one-hot encoding vector of the actual
labels. Batch size 16 is considered while training the proposed
DNN since the network can occupy less memory in the proposed
system.
4. Empirical evidence
This section delves into the specifics of the proposed DNN’s
implementation, as well as the database’s details, before conclud-
ing with the empirical findings.
4.1. Experimental setting
This sub-section describes the resources used for experiments.
For the training and testing of the proposed and existing models,
the Keras framework and Anaconda Python 3.6 package are con-
sidered in this study. The specifications of the working system
are NVIDIA Quadro P5000 graphics processor, 256-bit memory
interface, 16 GB GPU RAM, Cuda core-2560, GDDR5X memory,
and 288.5 GB/s bandwidth.
4.2. Experimental data
In this sub-section, we discuss about the databases and evalu-
ation procedure of the proposed DNN model for diagnosing the
COVID-19 is described. All the experiments are performed on
the five publicly available databases, namely D1 [19], D2 [20],
D3 [21], D4 [22], and D5 [23]. The statistical information of these
databases is reported in Table 3. When dealing with a database
containing a small number of images, overfitting or excessive
variance of ML algorithms is common. The overfitting problem
is addressed in this study by considering horizontal flip, random
6
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
Table 3
Statistical information according to the database and class.
Database
Before augmentation
Train
Validation
Test
COVID-19
non-COVID-19
COVID-19
non-COVID-19
COVID-19
non-COVID-19
D1
1299
3027
163
378
163
378
D2
960
1073
120
134
120
134
D3
148
2960
18
370
18
370
D4
256
355
32
45
32
45
D5
99
400
13
50
13
50
After augmentation
D1
5196
12108
163
378
163
378
D2
3840
4292
120
134
120
134
D3
592
11840
18
370
18
370
D4
1024
1420
32
45
32
45
D5
396
1600
13
50
13
50
rotation by 10 degrees, and zoom range 0.4 as image augmen-
tation strategies. Moreover, to maintain the consistency of the
proposed model, all the X-ray images of five databases are resized
into 128 × 128 and each database is divided into three groups:
train, validation, and test sets. For all of the investigations, a
k(=10)-fold cross-validation methodology is adopted to assess the
performance of the proposed method. In other words, out of ten
subsets, eight are employed for training, one is used for valida-
tion, and the remaining one is utilized for testing. The underfitting
and overfitting problems may solve by considering the 10-fold
cross-validation technique. Table 3 reports the number of X-ray
images employed in the train, validation, and test in the ratio
of 0.8, 0.1, and 0.1, respectively. The upper and lower part of
Table 3 denotes the number of samples before and after image
augmentation. Moreover, four well-known evaluation metrics,
namely accuracy, precision, recall, and F1-score are employed for
evaluation of the proposed DNN and comparative methods. The
detailed description of evaluation metrics is beyond the scope of
this study.
4.3. Results
In this sub-section, the empirical results of five databases
are discussed. The proposed DNN is evaluated on five databases,
namely D1, D2, D3, D4, and D5. Fig. 5 depicts the training proce-
dure for five datasets. As seen in Fig. 5, accuracy improved rapidly
during training until it reached an average of 10 to 20 iterations,
and then progressively increased. After multiple iterations, the
performance of the training and validation sets appeared to be
smooth and did not grow any further. Similarly, training and
validation losses decreased until it reached 10 to 20 epochs. The
training loss assesses how well the model fits the training data,
whereas the validation loss assesses how well the model fits new
data. We discovered that the proposed DNN can achieve nearly
100% accuracy in training and the best results in validation. The
training and validation losses of the proposed DNN are 0.1003,
0.1291 for D1, 0.0019, 0.0167 for D2, 0.0186, 0.01426 for D3,
0.0096, 0.0201 for D4, 0.0099, and 0.0213 for D5. As a result,
it is clear that the proposed DNN structure offers considerable
benefits in terms of COVID-19 identification.
To illustrate the robustness of the proposed DNN structure
on five databases, metrics such as precision, recall, F1-score are
measured, which is noted in Table 4. Furthermore, the accuracy
of the proposed method is compared with the fourteen existing
works on the five databases, and the results are noted in Table 4.
We can summarize the following:
• Table 4 clearly indicates that the proposed DNN framework
obtains an average detection F1-score, recall, and precision
of 96% on D1, 100% on the D2, 99% on D3, 99% on D4,
and 100% on D5 databases respectively. This indicates that
the proposed model learns well on X-ray images and it is
able to distinguish the features belonging to COVID-19 and
non-COVID-19.
• It is observed from Table 4 that the detection accuracy of
the proposed method is 96.01% on the D1, 99.61% on D2,
99.22% on D3, 98.83% on D4, and 100% on D5 databases
respectively, which is far better than the accuracies obtained
by the existing methods. Besides, the error rate incurred by
the proposed method on the testing set is 0.1391, 0.0057,
0.0996, 0.0178, and 0.0124 on D1, D2, D3, D4, and D5
databases, which is impressive enough in comparison with
the existing methods.
4.3.1. Comparative results
In this sub-section, our aim is to compare the performance
of fourteen baseline approaches such as XCeption net [25], In-
ception_V2 [44], SVM [38], Coronet [22], COVID-SDNet [28], AD-
COVID19 [29], transfer learning approach [27], Prior attention
network [30], VGG-19 [31], DarkCovidNet [32], ResNet50 [33],
RLDD [39] with the proposed method in the last experiment. The
short description of these approaches are discussed in Section 2
however, its detailed explanation is beyond the scope of this
work. In this study, all the models adopted for comparison are im-
plemented based on specifications as stated in the original papers.
Table 4 reports the average classification accuracies achieved by
these methods on five publicly available databases. Also notes the
values of precision, recall, and F1-score of these approaches.
Table 4 demonstrates that the proposed method is the best
and it happens due to the use of the proposed DNN to fetch more
reliable and noise-invariant facets at different image patches.
Using this approach, we design an end-to-end IoT-enabled DL
framework for fast and remote diagnosis which is our main
objective. The achieved accuracy of the proposed DNN on five
databases, namely D1, D2, D3, D4, and D5 are 96.01%, 99.61%,
99.22%, 98.83%, and 100%, respectively. Moreover, the measure-
ment of the running time is a significant aspect of analyzing
the proposed DNN. The training and testing time for implement-
ing the proposed DNN, as well as comparative approaches, are
detailed in Table 5. Normally, the training time of a DL model
relies on the size of the input, the size of the network, number
of folds, number of epochs, and other parameters. Moreover,
all the experiments are conducted in the same environment to
measure time efficiency. Table 5 clearly states that the proposed
DNN requires an average training and testing time across all
the databases. Moreover, a comparative analysis is employed to
examine the false negatives predicted by the existing methods
and the proposed DNN. False negatives refer to cases when a
person, who has the COVID-19 disease screens negative rather
7
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
Fig. 5. Training and loss curves on five database. (a), (c), (e), (g), and (i) represents accuracy curve on D1, D2, D3, D4, and D5, (b), (d), (f), and (h) indicates loss
curve on D1, D2, D3, D4, and D5.
Table 4
Analysis of state-of-the-art methods on test set of five databases using other metrics, namely accuracy, precision, recall, and F1-score in terms of%.
Ref. Method
Year D1
D2
D3
D4
D5
Accuracy Precision Recall F1-score Accuracy Precision Recall F1-score Accuracy Precision Recall F1-score Accuracy Precision Recall F1-score Accuracy Precision Recall F1-score
[25] XCeption net
2020 90.19
90
91
91
99.22
99
99
99
96.83
97
97
97
94.85
96
95
95
90.19
89
91
90
[19] COVID-Net
2020 94.90
96
94
95
93.05
95
93
94
91.12
91
91
91
79.89
81
80
79
90.33
91
89
90
[44] Inception_V2
2020 94.15
95
94
94
99.01
97
99
98
97.05
97
97
97
82.49
82
82
82
95.97
96
98
97
[38] SVM
2020 91.36
90
90
90
98.03
98
98
98
98.88
99
90
94
73.19
85
73
76
91.36
91
91
91
[22] Coronet
2020 92.03
92
92
92
99.50
99
99
99
98.01
98
99
98
85.00
85
85
85
92.03
92
92
92
[28] COVID-SDNet
2020 94.91
96
95
95
96.01
96
96
96
95.72
97
95
96
91.33
90
92
91
94.00
94
94
94
[29] AD-COVID19
2020 90.34
90
93
91
89.09
89
89
89
91.86
93
91
92
83.67
86
83
84
95.06
96
94
95
[27] Transfer learning
2020 88.86
89
89
89
98.02
98
98
98
93.75
96
92
94
89.33
90
89
89
97.73
97
97
97
[30] Prior attention
2020 90.06
92
90
91
91.99
92
92
92
96.58
98
96
97
87.63
88
86
87
93.00
93
93
93
[31] VGG19
2020 89.96
91
90
90
96.68
97
97
97
97.61
98
98
98
88.39
88
86
87
98.00
98
98
98
[32] DarkCovidNet
2020 88.31
88
88
88
95.37
95
95
95
98.08
98
98
98
93.18
92
94
93
95.01
95
95
95
[33] ResNet50
2021 92.05
92
92
92
97.34
97
97
97
98.32
98
98
98
94.11
96
95
94
98.86
99
99
99
[39] RLDD
2021 93.33
93
93
93
96.02
97
95
96
97.07
98
97
96
90.91
91
91
91
95.66
97
95
96
–
Proposed method –
96.01
96
96
96
99.61
100
99
100
99.22
99
99
99
98.83
98
99
99
100
100
100
100
Table 5
Execution time in seconds on five databases viz. D1, D2, D3, D4, and D5 by various methods.
Ref.
Method
Training time
Testing time for all the Images
D1
D2
D3
D4
D5
D1
D2
D3
D4
D5
[25]
XCeption net
495.0
480.0
270.0
330.0
316.13
5.0
16.0
10.0
3.01
2.0
[19]
COVID-Net
939.0
987.0
438.33
402.01
386.99
25.0
27.05
11.76
8.33
4.09
[44]
Inception_V2
4700.0
850.0
925.0
625.0
600.01
12.0
19.0
18.02
11.23
10.0
[38]
SVM
16.75
13.2675
19.62
17.34
15.091
2.3145
1.3167
2.891
1.8472
1.2710
[22]
Coronet
2488.0
2676.0
1336.0
1720.0
1201.09
86.0
42.0
51.0
36.701
24.42
[28]
COVID-SDNet
451.00
526.66
357.92
380.06
365.66
86.0
35.0
38.33
23.64
14.96
[29]
AD-COVID19
98.01
101.03
78.72
67.00
43.94
9.04
11.35
3.78
2.00
1.33
[27]
Transfer learning
92.98
17.63
19.09
5.092
4.66
3.014
3.63
1.302
1.001
0.78
[30]
Prior attention
245.33
260.04
201.33
166.66
102.11
67.27
30.98
23.02
19.00
13.109
[31]
VGG19
2205.0
2782.06
1618.0
1920.0
1386.0
6.0
8.2
7.01
5.11
3.03
[32]
DarkCovidNet
200.0
250.0
180.0
185.0
150.0
1.03
1.769
1.25
0.996
0.841
[33]
ResNet50
934.0
960.0
700.08
658.00
500.0
17.0
19.0
15.0
14.07
10.2
[39]
RLDD
104.65
99.09
84.68
58.88
38.01
11.09
4.330
3.810
3.002
1.109
–
Proposed method
95.4
96
66
20.9
12.3
0.541
0.692
1.28
0.461
0.202
than positive which is included in Fig. 6. In this regard, we wish
to mention that all the five databases are considered together
while computing false-negative cases. It is clear from Fig. 6 that
the proposed DNN has very few false negatives to existing state-
of-the-art methods. In addition to this, in this study, the number
of parameters involved and memory size (in MB) required for
an image are used to determine the complexity of the proposed
DNN. The proposed DNN’s complexity is compared to 12 current
state-of-the-art DL approaches and results are reported in Table 6.
Table 6 demonstrates that the number of parameters in the
8
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
Fig. 6. A comparative analysis on number of false negatives of existing approaches as well as the proposed DNN.
Table 6
Computational efficiency analysis of the proposed DNN with other DL approaches.
Ref.
Method
No. parameters (in millions (M))
Memory size (in MB)
[25]
XCeption net
29.2
38
[19]
COVID-Net
11.75
106
[44]
Inception_V2
55.9
296
[22]
Coronet
33.9
240
[28]
COVID-SDNet
40.3
386
[29]
AD-COVID19
89.1
820
[27]
Transfer learning
11.6
120
[30]
Prior attention
15.9
110
[31]
VGG19
20.5
385
[32]
DarkCovidNet
1.12
8
[33]
ResNet50
25.6
420
[39]
RLDD
26
160
–
Proposed method
9.04
94
proposed DNN is smaller than the number of parameters in nine-
teen state-of-the-art DL techniques, demonstrating the proposed
DNN’s simplicity. In comparison to existing DL techniques, the
memory size (in MB) required for an image is also smaller. It
could satisfy the needs of many real-time COVID-19 diagnosis
applications. After optimization in both time and space, the model
could be equipped with real-time edge devices, such as NVIDIA
TX2.
4.4. Robustness of the proposed DNN
In this sub-section, we conduct experiments to find the ro-
bustness of the proposed DNN. In basic terms, feature engineering
is the process of converting chest x-ray images into desirable
features using the proposed DNN in order to improve model
accuracy. To compare the performance of the proposed DNN
with some state-of-the-art approaches, accuracy, precision, re-
call, and F1-score are used, and the results are presented in
Table 4. The proposed DNN outperforms all state-of-the-art tech-
niques, as reported in Table 4. It means the proposed DNN does
the feature engineering task well in comparison to other state-
of-the-art methods. Nowadays, the values of these evaluation
measures are no longer sufficient to demonstrate how good a
DL model is. The t-SNE plots of the feature vectors obtained
by the proposed DNN along with state-of-the-art approaches on
five different databases are shown in Figs. 7, 8, 9, 10, and 11 in
order to illustrate the effectiveness of the proposed DNN model
over some of the existing methods. The features in a 2-D plot
are depicted using t-distributed stochastic neighbor embedding,
a dimensional reduction technique that allows us to perceive a
high-dimensional database in a low-dimensional environment.
Because such embedding incorporates categorization informa-
tion, it visualizes the learned proposed network’s most recent
embeddings. It is clear from Figs. 7, 8, 9, 10, and 11 that the pro-
posed DNN is the only method, which can extract distinguishable
features for five databases separately and forms well-separated
clusters when we are mapping them from higher-dimensional to
a two-dimensional plane. The t-SNE plots of a few of the existing
approaches are also well separated with a small margin on some
of the databases. Thus, the performances of these methods are not
always consistent. This experiment shows how efficient the pro-
posed method is. Furthermore, to show the proposed method’s
efficient feature learning capacity, the probability vector created
by the softmax layer is compared to a few existing DL techniques.
Initially, the five best state-of-the-art methods are selected based
on their accuracies [19,22,25,28,39]. We pick four CXR images
(two are from COVID-19 patients and two are from a healthy
person) randomly from the test sets. Then, the probability score
of each method along with the proposed approach to these four
images is estimated and displayed in Fig. 12. The label ‘0’ and ‘1’
in the graphs of Fig. 12 denote the probability of covid-19 infected
patients and healthy persons, respectively. The probability score
ranges between 0 to 1 and the ideal probability score of label ‘0’
and label ‘1’ for covid-19 infected patients is 1 and 0, respectively.
Similarly, it is vice versa for healthy people. It can be observed
from Fig. 12 that the proposed method predicts scores nearer
to ideal values for both covid-19 infected patients and healthy
persons. On the other hand, probability scores obtained by the
existing DNN based approaches for healthy persons and infected
patients are relatively far from the ideal values.
9
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
Fig. 7. Feature visualization on D1 database. Here, (a) shows the input feature map, (b)–(m) depicts the feature maps obtained from existing methods, and (n) shows
the feature map obtained from the proposed DNN.
Fig. 8. Feature visualization on D2 database. Here, (a) shows the input feature map, (b)–(m) depicts the feature maps obtained from existing methods, and (n) shows
the feature map obtained from the proposed DNN.
In addition to this, we observe that the proposed DNN is
evaluated using a 10-fold cross-validation procedure, in which
the original dataset is randomly divided into ten equal-size sub-
samples. Only one subsample of the ten is preserved as test data
for the algorithm, while the other nine are used for training and
validation. The folds are then used to repeat the cross-validation
process ten times, with each of the ten subsamples serving as
validation data exactly once. The performance of the proposed
DNN can then be estimated by averaging (or otherwise combin-
ing) the evaluation metrics acquired from the 10 folds. However,
the proposed DNN’s overall accuracy differs from the individual
accuracy of each fold. To identify the variance in the obtained
accuracies on each database, the standard deviation of accuracies
acquired in ten different folds is assessed, as illustrated in Fig. 13.
10
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
Fig. 9. Feature visualization on D3 database. Here, (a) shows the input feature map, (b)–(m) depicts the feature maps obtained from existing methods, and (n) shows
the feature map obtained from the proposed DNN.
Fig. 10. Feature visualization on D4 database. Here, (a) shows the input feature map, (b)–(m) depicts the feature maps obtained from existing methods, and (n)
shows the feature map obtained from the proposed DNN.
It is clear from Fig. 13 that the obtained low standard deviation on
a database implies that 10-fold accuracies tend to be extremely
close to the averaged accuracy of the proposed DNN.
4.5. Ablation study
To develop a DNN model from scratch for a particular prob-
lem is not an easy task especially when we are facing the data
scarcity problem with a database containing few images. An
ablation study is required to understand the contribution of each
module of the proposed DNN. Thus, an ablation study is con-
ducted to finalize the architecture of the proposed model in
such a way that it performs well with a test set. In accordance
with our experiments, the proposed DNN gives an accuracy of
96.01%, 99.61%, 99.22%, 98.83%, and 100% for the task of COVID-
19 classification of the X-ray images on D1, D2, D3, D4, and
11
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
Fig. 11. Feature visualization on D5 database. Here, (a) shows the input feature map, (b)–(m) depicts the feature maps obtained from existing methods, and (n)
shows the feature map obtained from the proposed DNN.
Table 7
The performance in terms of accuracy (%) on the test set of five databases with and without batch
normalization layers & variation of pooling layers and without pooling layers are noted.
The seventh experiment belongs to batch normalization
BN
D1
D2
D3
D4
D5
No
92.87
98.82
99.05
93.19
96.82
Yes
96.01
99.61
99.22
98.83
100
The eighth experiment belongs to pooling
Pooling
D1
D2
D3
D4
D5
Max
96.01
99.61
99.22
98.83
100
Average
94.46
99.21
99.16
90.01
100
No
88.01
97.64
94.44
89.38
96.82
D5 databases respectively. In this sub-section, the effect of the
performance of the proposed DNN is assessed by varying the
model parameters. In the first experiment, the behavior of the
DNN model for different activation functions is shown in Fig. 14.
Fig. 14 indicates that ReLU activation gives a better performance
than others. In the second experiment, the effect of the batch
normalization layer on the performance of the proposed DNN is
evaluated. The results of the second experiment are presented
in the upper part of Table 7. In the third experiment, the effect
of change in pooling layers on the performance of the proposed
DNN is assessed. The results of this study are presented in the
lower part of Table 7. The proposed DNN is divided into five
blocks, namely Block1, Block2, Block3, Block4, and Block5. We have
experimented i.e., the fourth experiment, to quantify the block-
wise performance of the proposed DNN. The results of the fourth
experiment are shown in Table 8.
From Table 8, we can observe that although increasing layers
containing blocks the proposed model gives better performance.
Moreover, we can observe from the last row of Table 8 is that
overfitting occurred after increasing more than 5 blocks. In ad-
dition, as seen in Fig. 15, there is a huge gap between training
and validation losses when increasing more than 5 blocks. So, the
model is overfitting.
Moreover, optimization plays a crucial role in the DL model
for updating the weights to reduce the losses of the DL model,
also called hyper-parameter tuning. There are many optimiza-
tion techniques available for parameter hyper-space search. Some
of the widely used optimization techniques for DL approaches
are stochastic gradient descent (SGD), adaptive gradient descent
(Adagrad), root mean square propagation (RMSprop), SGD with
momentum, and adaptive moment estimation (Adam). In the
fifth experiment, we have tested the aforementioned optimiza-
tion techniques. The performance analysis of various optimization
techniques is shown in Fig. 16. It can be observed from Fig. 16
that Adam optimization gave a better performance for COVID-19
classification from X-ray images. However, the proposed model
obtained a satisfactory performance for other optimization tech-
niques. Variations of different scales are examined by the sixth
experiment. Table 9, shows the performance of the proposed
DNN using different filter scales. To measure the importance of
the multi-scale approach, conducted a seventh experiment with
and without multi-scale blocks of the proposed DNN. The mea-
surement of the proposed DNN performance with and without
multi-scale is shown in Fig. 17.
12
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
Fig. 12. The comparative probability scores of the proposed DNN along with existing methods. (a), (c) represents the COVID-19 CXR images and (b), (d) indicates the
non-COVID-19 CXR images. Each row represents the probability scores of two classes. (e), (f), (g), (h) is of [25], (i), (j), (k), (l) is of [19], (m), (n), (o), (p) is for [22],
(q), (r), (s), (t) is for [28], (u), (v), (w), (x) is for [39], (y), (z), (aa), (ab) is for the proposed method.
Fig. 13. The performance (averaged accuracy ±standard deviation) of the proposed DNN on five databases.
It is clear from Fig. 17 that the performance of the proposed
DNN without multi-scale is not satisfactory. Thus, we can con-
clude that multi-scale features provide significant features to
distinguish COVID-19 from non-COVID-19.
It can be observed from Table 9 that the combination of 3 ×
3, 5 × 5, 7 × 7 scales gave better performance than other scales.
In addition, an experiment is conducted on varying learning rates.
Fig. 18, shows the performance varying while changing learning
13
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
Fig. 14. Variation of COVID-19 classification accuracies (%) obtained using different activation functions, where Selu →scaled exponential linear unit, Elu →
exponential linear unit, Tanh →hyperbolic tangent, ReLU →rectified linear unit.
Fig. 15. The training and validation losses incurred by the proposed DNN model after adding more layers to it on five databases. (a), (b), (c), (d), and (e) indicates
five databases, namely D1, D2, D3, D4, and D5. Here, B15 →Block1 + Block5, B125 →Block1 + Block2 + Block5, B1235 →Block1 + Block2 + Block3 + Block5, B12345
→Block1 + Block2 + Block3 + Block4 + Block5, B1234E5 →Block1 + Block2 + Block3 + Block4 + Extrablock + Block5.
Table 8
The performance in terms of accuracy (%) on the test set of five databases with varying blocks of
the proposed DNN (for example, Block1 + Block5, Block1 is for feature extraction and Block5 is for
classification).
Blocks
D1
D2
D3
D4
D5
Block1 + Block5
93.88
97.64
94.45
89.38
98.41
Block1 + Block2 + Block5
94.63
99.21
99.01
93.19
98.59
Block1 + Block2 + Block3 + Block5
94.91
99.21
99.22
94.16
96.82
Block1 + Block2 + Block3 + Block4 + Block5
96.01
99.61
99.22
98.83
100
Block1 + Block2 + Block3 + Block4 + ExtraBlock + Block5
74.63
73.09
78.43
65.89
84.21
14
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
Fig. 16. Variation of COVID-19 classification accuracies (%) obtained on the test set using different optimization techniques.
Fig. 17. The effect of the proposed DNN with and without multi-scale approach, where, WMS →With multi-scale and WOMS →Without multi-scale.
Table 9
The performance in terms of accuracy (%) on the test set of five databases with
varying filter scales of the proposed DNN.
Blocks
D1
D2
D3
D4
D5
11 × 11, 3 × 3, 5 × 5
95
98
71
86
100
11 × 11, 5 × 5, 7 × 7
94
97
94
82
100
11 × 11, 3 × 3, 7 × 7
82
98
95
80
100
9 × 9, 3 × 3, 5 × 5
95
98
94
84
100
9 × 9, 5 × 5, 7 × 7
85
96
94
86
95
9 × 9, 3 × 3, 7 × 7
92
97
89
83
100
1 × 1, 3 × 3, 5 × 5
92
98
98
90
98
1 × 1, 5 × 5, 7 × 7
91
98
98
84
98
1 × 1, 3 × 3, 7 × 7
91
98
97
85
76
3 × 3, 5 × 5, 7 × 7
96.01
99.61
99.22
98.83
100
Fig. 18. Evaluation of different learning rates on five databases.
rates. From Fig. 18, it is observed that the learning rate at 0.00001
obtained higher classification accuracy.
5. Conclusion
In this study, a DNN enabled IoT framework is introduced for
fast and accurate detection of COVID-19. Five databases viz., D1,
D2, D3, D4, and D5 are considered in this study to manifest the
efficiency of the proposed method over existing approaches. One
of the key benefits of integrating IoT into healthcare is reduc-
ing the exposition to contagion and automating the diagnosis,
thus making the medical staff more concentrated on patients.
Connected to this, the DNN framework is employed to fetch
more reliable and noise-invariant facets at various image patches.
The proposed method acquires an average recognition accuracy
15
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
of 96.01%, 99.61%, 99.22%, 98.83%, and 100% respectively. Ex-
perimental outcomes also manifest that the proposed method
outranks fourteen contemporary approaches by adopting the av-
erage time i.e., training and testing time. Compared to the existing
methods, the proposed model predicts very few FP’s and FN’s,
which is shown in Fig. 6. Furthermore, it is worth investigating to
deploy the proposed model in some real-life settings. The results
obtained in this study are very promising and this work can be
extended by considering multiple factors in the future. For future
work, we intend to enhance the diversity of the database by
adding new X-ray images of patients with COVID-19, as soon
as these images are available, and by including X-ray exams of
other lung-related diseases. Further, more efforts will be given to
exploring how to identify COVID-19 in the early stages and how
the prior attention mechanism can be employed in other medical
image analysis problems.
CRediT authorship contribution statement
Mohan Karnati: Conception and design of study, Acquisi-
tion of data, Analysis and/or interpretation of data, Drafting the
manuscript, Revising the manuscript critically for important in-
tellectual content, . Ayan Seal: Conception and design of study,
Acquisition of data, Analysis and/or interpretation of data, Draft-
ing the manuscript, Revising the manuscript critically for impor-
tant intellectual content. Geet Sahu: Conception and design of
study, Acquisition of data, Analysis and/or interpretation of data,
Drafting the manuscript, Revising the manuscript critically for im-
portant intellectual content. Anis Yazidi: Conception and design
of study, Acquisition of data, Analysis and/or interpretation of
data, Drafting the manuscript, Revising the manuscript critically
for important intellectual content. Ondrej Krejcar: Conception
and design of study, Acquisition of data, Analysis and/or interpre-
tation of data, Drafting the manuscript, Revising the manuscript
critically for important intellectual content.
Declaration of competing interest
The authors declare that they have no known competing finan-
cial interests or personal relationships that could have appeared
to influence the work reported in this paper.
Acknowledgments
This work is partially supported by the project ‘‘Smart So-
lutions in Ubiquitous Computing Environments’’’, Grant Agency
of Excellence, University of Hradec Kralove, Faculty of Informat-
ics and Management, Czech Republic (under ID: UHK-FIM-GE-
2022); and by the SPEV project ‘‘Smart Solutions in Ubiquitous
Computing Environments’’’, University of Hradec Kralove, Fac-
ulty of Informatics and Management, Czech Republic (under ID:
UHK-FIMSPEV-2022-2102). We are also grateful for support of
Ph.D. student Michal Dobrovolny in consultations of some imple-
mentation issues. All authors approved the final version of the
manuscript.
References
[1] Y.-H. Xu, J.-H. Dong, W.-M. An, X.-Y. Lv, X.-P. Yin, J.-Z. Zhang, L. Dong, X.
Ma, H.-J. Zhang, B.-L. Gao, Clinical and computed tomographic imaging fea-
tures of novel coronavirus pneumonia caused by SARS-CoV-2, J. Infection
80 (4) (2020) 394–400.
[2] worldometere,
Covid-19
coronavirus
pandemic,
2020,
URL
https://www.worldometers.info/coronavirus/?fbclid=
IwAR2UgycDn8i64zB71xUGm5svanZxQEI_U6IEEzgiNRtMnVLtBQtyKqPW_
e8.
[3] E. Mahase, Coronavirus: covid-19 has killed more people than SARS and
mers combined, despite lower case fatality rate, 2020.
[4] L. Yan, H.-T. Zhang, Y. Xiao, M. Wang, Y. Guo, C. Sun, X. Tang, L. Jing, S. Li,
M. Zhang, et al., Prediction of criticality in patients with severe Covid-19
infection using three clinical features: a machine learning-based prognostic
model with clinical data in wuhan, 2020, medRxiv.
[5] A.
Singh,
S.K.
Chandra,
M.K.
Bajpai,
Study
of
non-pharmacological
interventions on COVID-19 spread, 2020, medRxiv.
[6] W. Wang, Y. Xu, R. Gao, R. Lu, K. Han, G. Wu, W. Tan, Detection of
SARS-CoV-2 in different types of clinical specimens, JAMA 323 (18) (2020)
1843–1844.
[7] C. Vermeiren, X. Marchand-Senécal, E. Sheldrake, D. Bulir, M. Smieja, S.
Chong, J.D. Forbes, K. Katz, Comparison of copan eswab and floqswab
for COVID-19 PCR diagnosis: working around a supply shortage, J. Clin.
Microbiol. (2020).
[8] E. Prompetchara, C. Ketloy, T. Palaga, Immune responses in COVID-19 and
potential vaccines: Lessons learned from SARS and MERS epidemic, Asian.
Pac. J. Allergy Immunol. 38 (1) (2020) 1–9.
[9] Y. Fang, H. Zhang, J. Xie, et al., Sensitivity of chest ct for covid-19:
comparison to rt-pcr, Radiology 200432 (2020).
[10] Z. Ye, Y. Zhang, Y. Wang, Z. Huang, B. Song, Chest CT manifestations of
new coronavirus disease 2019 (COVID-19): a pictorial review, Eur. Radiol.
(2020) 1–9.
[11] B. Wang, S. Jin, Q. Yan, H. Xu, C. Luo, L. Wei, W. Zhao, X. Hou, W. Ma, Z.
Xu, et al., AI-assisted CT imaging analysis for COVID-19 screening: Building
and deploying a medical AI system, Appl. Soft Comput. 98 (2021) 106897.
[12] H.Y.F. Wong, H.Y.S. Lam, A.H.-T. Fong, S.T. Leung, T.W.-Y. Chin, C.S.Y. Lo,
M.M.-S. Lui, J.C.Y. Lee, K.W.-H. Chiu, T.W.-H. Chung, et al., Frequency
and distribution of chest radiographic findings in patients positive for
COVID-19, Radiology 296 (2) (2020) E72–E78.
[13] A.K. Gupta, A. Seal, P. Khanna, A. Yazidi, O. Krejcar, Gated contextual
features for salient object detection, IEEE Trans. Instrum. Measur., 1–13.
[14] A.K. Gupta, A. Seal, P. Khanna, E. Herrera-Viedma, O. Krejcar, Almnet:
Adjacent layer driven multiscale features for salient object detection, IEEE
Trans. Instrum. Meas. 70 (2021) 1–14, http://dx.doi.org/10.1109/TIM.2021.
3108503.
[15] K. Mohan, A. Seal, O. Krejcar, A. Yazidi, FER-net: facial expression
recognition using deep neural net, Neural Comput. Appl., 1–12.
[16] K. Mohan, A. Seal, O. Krejcar, A. Yazidi, Facial expression recognition
using local gravitational force descriptor-based deep convolution neural
networks, IEEE Trans. Instrum. Meas. 70 (2020) 1–12.
[17] M. Karnati, A. Seal, A. Yazidi, O. Krejcar, Lienet: A deep convolution neural
networks framework for detecting deception, IEEE Trans. Cogn. Dev. Syst.
(2021).
[18] I. Yaqoob, E. Ahmed, I.A.T. Hashem, A.I.A. Ahmed, A. Gani, M. Imran,
M. Guizani, Internet of things architecture: Recent advances, taxonomy,
requirements, and open challenges, IEEE Wirel. Commun. 24 (3) (2017)
10–16.
[19] L. Wang, Z.Q. Lin, A. Wong, Covid-net: A tailored deep convolutional neural
network design for detection of covid-19 cases from chest x-ray images,
Sci. Rep. 10 (1) (2020) 1–12.
[20] T. Rahman, COVID-19 radiography database, 2020, URL https://www.
kaggle.com/tawsifurrahman/covid19-radiography-database.
[21] S. Minaee, R. Kafieh, M. Sonka, S. Yazdani, G.J. Soufi, Deep-covid: Predicting
covid-19 from chest x-ray images using deep transfer learning, Med. Image
Anal. 65 (2020) 101794.
[22] A.I. Khan, J.L. Shah, M.M. Bhat, Coronet: A deep neural network for
detection and diagnosis of COVID-19 from chest x-ray images, Comput.
Methods Programs Biomed. (2020) 105581.
[23] C. Li, M. Wang, G. Wu, K. Rana, N. Charoenkitkarn, J. Chan, COVID19 chest
X-ray classification with simple convolutional neural network, in: CSBio’20:
Proceedings of the Eleventh International Conference on Computational
Systems-Biology and Bioinformatics, 2020, pp. 97–100.
[24] Q. Yan, B. Wang, D. Gong, C. Luo, W. Zhao, J. Shen, J. Ai, Q. Shi, Y. Zhang,
S. Jin, et al., Covid-19 chest CT image segmentation network by multi-
scale fusion and enhancement operations, IEEE Trans. Big Data 7 (1) (2021)
13–24.
[25] R. Jain, M. Gupta, S. Taneja, D.J. Hemanth, Deep learning based detection
and analysis of COVID-19 on chest X-ray images, Appl. Intell. (2020) 1–11.
[26] E.E.-D. Hemdan, M.A. Shouman, M.E. Karar, Covidx-net: A framework of
deep learning classifiers to diagnose covid-19 in x-ray images, 2020, arXiv
preprint arXiv:2003.11055.
[27] E.F. Ohata, G.M. Bezerra, J.V.S. das Chagas, A.V.L. Neto, A.B. Albuquerque,
V.H.C. de Albuquerque, P.P. Reboucas Filho, Automatic detection of COVID-
19 infection using chest X-ray images through transfer learning, IEEE/CAA
J. Autom. Sin. 8 (1) (2020) 239–248.
[28] S. Tabik, A. Gómez-Ríos, J.L. Martín-Rodríguez, I. Sevillano-García, M. Rey-
Area, D. Charte, E. Guirado, J.-L. Suárez, J. Luengo, M. Valero-González, et
al., Covidgr dataset and COVID-sdnet methodology for predicting COVID-19
based on chest X-ray images, IEEE J. Biomed. Health Inf. 24 (12) (2020)
3595–3605.
16
 M. Karnati, A. Seal, G. Sahu et al.
Applied Soft Computing 125 (2022) 109109
[29] J.D. Arias-Londoño, J.A. Gomez-Garcia, L. Moro-Velázquez, J.I. Godino-
Llorente, Artificial intelligence applied to chest X-ray images for the
automatic detection of COVID-19. a thoughtful evaluation approach, IEEE
Access 8 (2020) 226811–226827.
[30] J. Wang, Y. Bao, Y. Wen, H. Lu, H. Luo, Y. Xiang, X. Li, C. Liu, D. Qian, Prior-
attention residual learning for more discriminative COVID-19 screening in
CT images, IEEE Trans. Med. Imaging 39 (8) (2020) 2572–2583.
[31] I.D. Apostolopoulos, T.A. Mpesiana, Covid-19: automatic detection from x-
ray images utilizing transfer learning with convolutional neural networks,
Phys. Eng. Sci. Med. (2020) 1.
[32] T. Ozturk, M. Talo, E.A. Yildirim, U.B. Baloglu, O. Yildirim, U.R. Acharya,
Automated detection of COVID-19 cases using deep neural networks with
X-ray images, Comput. Biol. Med. 121 (2020) 103792.
[33] A. Narin, C. Kaya, Z. Pamuk, Automatic detection of coronavirus disease
(covid-19) using x-ray images and deep convolutional neural networks,
Pattern Anal. Appl. 24 (3) (2021) 1207–1220.
[34] T.T.
Nguyen,
Artificial
intelligence
in
the
battle
against
coronavirus
(COVID-19): a survey and future research directions, 10, 2020, Preprint.
[35] H.S. Maghdid, K.Z. Ghafoor, A.S. Sadiq, K. Curran, K. Rabie, A novel ai-
enabled framework to diagnose coronavirus covid 19 using smartphone
embedded sensors: Design study, 2020, arXiv preprint arXiv:2003.07434.
[36] A.S.S. Rao, J.A. Vazquez, Identification of COVID-19 can be quicker through
artificial intelligence framework using a mobile phone–based survey when
cities and towns are under quarantine, Infect. Control Hosp. Epidemiol. 41
(7) (2020) 826–830.
[37] Z. Allam, D.S. Jones, On the coronavirus (COVID-19) outbreak and the
smart city network: universal data sharing standards coupled with artificial
intelligence (AI) to benefit urban health monitoring and management, in:
Healthcare, Vol. 8, (1) Multidisciplinary Digital Publishing Institute, 2020,
p. 46.
[38] M. Otoom, N. Otoum, M.A. Alzubaidi, Y. Etoom, R. Banihani, An IoT-based
framework for early identification and monitoring of COVID-19 cases,
Biomed. Signal Process. Control 62 (2020) 102149.
[39] M. Zhang, R. Chu, C. Dong, J. Wei, W. Lu, N. Xiong, Rldd: An advanced
residual learning diagnosis detection system for COVID-19 in iIoT, IEEE
Trans. Ind. Inf. (2021).
[40] C.M. Dourado, S.P.P. Da Silva, R.V.M. Da Nóbrega, P.P. Rebouças Filho,
K. Muhammad, V.H.C. De Albuquerque, An open IoHT-based deep learn-
ing framework for online medical image recognition, IEEE J. Sel. Areas
Commun. 39 (2) (2020) 541–548.
[41] D.D.A. Rodrigues, R.F. Ivo, S.C. Satapathy, S. Wang, J. Hemanth, P.P.
Reboucas Filho, A new approach for classification skin lesion based on
transfer learning, deep learning, and IoT system, Pattern Recognit. Lett.
136 (2020) 8–15.
[42] Q. Hu, E.F. Ohata, F.H. Silva, G.L. Ramalho, T. Han, P.P. Reboucas Filho, A
new online approach for classification of pumps vibration patterns based
on intelligent IoT system, Measurement 151 (2020) 107138.
[43] C.M. Dourado Jr., S.P.P. da Silva, R.V.M. da Nobrega, A.C.d.S. Barros, P.P.
Reboucas Filho, V.H.C. de Albuquerque, Deep learning IoT system for online
stroke detection in skull computed tomography images, Comput. Netw.
152 (2019) 25–39.
[44] D. Dansana, R. Kumar, A. Bhattacharjee, D.J. Hemanth, D. Gupta, A. Khanna,
O. Castillo, Early diagnosis of COVID-19-affected patients based on X-ray
and computed tomography images using deep learning algorithm, Soft
Comput. (2020) 1–9.
17
",https://doi.org/10.1016/j.asoc.2022.109109,doc19,"Applied Soft Computing 125 (2022) 109109 Contents lists available at ScienceDirect Applied Soft Computing journal homepage: www.elsevier.com/locate/asoc A novel multi-scale based deep convolutional neural network for detecting COVID-19 from X-rays Mohan Karnati a, Ayan Seal a,∗, Geet Sahu a, Anis Yazidi b,c,d, Ondrej Krejcar e,f a Department of Computer Science and Engineering, PDPM Indian Institute of Information Technology Design & Manufacturing Jabalpur, Jabalpur, Madhya Pradesh 482005, India b Department of Computer Science, OsloMet – Oslo Metropolitan University, Oslo, 460167, Norway c Department of Computer Science, Norwegian University of Science and Technology, Trondheim, 460167, Norway d Department of Plastic and Reconstructive Surgery, Oslo University Hospital, Oslo, 460167, Norway e Center for Basic and Applied Science, Faculty of Informatics and Management, University of Hradec Kralove, Rokitanskeho 62, 500 03 Hradec Kralove, Czech Republic f Malaysia-Japan International Institute of Technology (MJIIT), Universiti Teknologi Malaysia, Jalan Sultan Yahya Petra, 54100 Kuala Lumpur, Malaysia a r t i c l e i n f o Article history: Received 23 October 2021 Received in revised form 26 April 2022 Accepted 26 May 2022 Available online 6 June 2022 Keywords: COVID-19 Chest X-ray Deep neural network Internet of things a b s t r a c t The COVID-19 pandemic has posed an unprecedented threat to the global public health system, primarily infecting the airway epithelial cells in the respiratory tract. Chest X-ray (CXR) is widely available, faster, and less expensive therefore it is preferred to monitor the lungs for COVID-19 diagnosis over other techniques such as molecular test, antigen test, antibody test, and chest computed tomography (CT). As the pandemic continues to reveal the limitations of our current ecosystems, researchers are coming together to share their knowledge and experience in order to develop new systems to tackle it. In this work, an end-to-end IoT infrastructure is designed and built to diagnose patients remotely in the case of a pandemic, limiting COVID-19 dissemination while also improving measurement science. The proposed framework comprises six steps. In the last step, a model is designed to interpret CXR images and intelligently measure the severity of COVID-19 lung infections using a novel deep neural network (DNN). The proposed DNN employs multi-scale sampling filters to extract reliable and noise-invariant features from a variety of image patches. Experiments are conducted on five publicly available databases, including COVIDx, COVID-19 Radiography, COVID- XRay-5K, COVID-19-CXR, and COVIDchestxray, with classification accuracies of 96.01%, 99.62%, 99.22%, 98.83%, and 100%, and testing times of 0.541, 0.692, 1.28, 0.461, and 0.202 s, respectively. The obtained results show that the proposed model surpasses fourteen baseline techniques. As a result, the newly developed model could be utilized to evaluate treatment efficacy, particularly in remote locations. © 2022 Elsevier B.V. All rights reserved. 1. Introduction COVID-19 was originally identified in China in December 2019 and has infected over a hundred million people around the world. The World Health Organization (WHO) declared a pandemic on March 11, 2020. In almost 74% of the cases, the infections are either minor (18%) or severe symptoms (56%). However, the remaining 26% vary from critical (20%) to an extreme symp- toms (6%) [1]. As of today (28/05/2021), the world’s cumulative number of COVID-19 infections is more than 169 million, and the death toll overpasses 3.52 million, while 151 million cases recovered completely. Moreover, the number of active instances is 14.74 million, among which 14,648,154 events are in minor ∗Corresponding author. E-mail address: ayan@iiitdmj.ac.in (A. Seal). condition, and 93,863 events are in serious condition [2]. Table 1 summarizes some major statistical parameters related to the pandemic COVID-19 in several countries. The novel COVID-19 disease emerges with throat inflammation, fever, and respiratory distress, then progresses to breathing difficulties. The infection could cause the severe acute respiratory syndrome, pulmonary hypertension, organ failure, and, ultimately, death of the pa- tient [3]. Recent studies suggest that men are more likely to get affected than women. In this perspective, men represent 60% of the cases, and there were no reported substantial mortality rates among children younger than nine years [4]. Furthermore, COVID-19 infected patients must isolate themselves and adopt appropriate preventive steps to safeguard healthy individuals, thereby breaking the infection chain [4,5]. Historical data have shown that the infection rate grows exponentially rather than linearly if preventive measures are not utilized effectively, and 1568-4946/© 2022 Elsevier B.V. All rights reserved. M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 Table 1 Statistics on COVID-19 outbreaks. Countries Confirmed Deaths Recovered USA 33,999,680 607,726 27,701,879 India 27,555,457 318,895 24,893,410 Brazil 16,342,162 456,753 14,786,292 Russia 5,044,459 120,406 4,661,234 UK 4,473,677 127,758 4,310,572 France 5,635,629 109,165 5,284,264 Turkey 5,220,549 46,970 5,070,815 Germany 3,673,969 88,689 3,461,700 Italy 4,205,970 125,793 3,826,984 in some cases, the pandemic may reach a tipping point beyond which the infection rate becomes uncontrollable. In many circum- stances, it would put a strain on the limited medical resources available for diagnosis. COVID-19 is diagnosed using at least one of the three methods listed below: • RT-PCR: For antigen detection testing, [6,7] uses a nose blood sample and a venous blood sample. In some countries, such as India, these procedures necessitate contact between patients and physicians, which might take anything from a few hours to three days to receive results. Some studies have found that the results of numerous RT-PCR tests per- formed at different times for the same patient can differ, resulting in a high false negative (FN) diagnostic rate [8]. Many researchers suggested combining the RT-PCR test with additional clinical exams, such as computed tomography (CT), to improve the accuracy of the diagnosis. • CT scan: COVID-19 patients mostly become infected with lung disease at an early stage of the disease. The most preva- lent COVID-19 lung symptoms are consolidation, i.e. fluid and bone accumulations in lung blood vessels that pre- vent ground-glass opacity, gas exchange, and nodular shad- owing. These symptoms are frequently present in the middle and lower lung regions and can be used to dis- tinguish between people infected with non-COVID-19 and COVID-19 [9,10]. In comparison to RT-PCR, CT equipment generates images for faster COVID-19 screening [11]. CT scan-based measurement entails assessing 3D radiographic imaging of the lungs from multiple perspectives. Manual examination of COVID-19 from chest CT scans, on the other hand, is a labor-intensive, and time-consuming procedure since medical practitioners must find lesions slice-by-slice from volumetric CT images. • Chest X-ray (CXR): In comparison to CT, CXR equipment is smaller and more portable. In hospitals, this type of re- source is usually more accessible than RT-PCR and CT-scan. Furthermore, because the CXR test lasts around 15 s per subject [12], it is one of the most cost-effective pieces of evaluation equipment. In medical treatment, a reliable computer-aided diagnostic system that analyzes CXR for precise, rapid screening and diag- nosis of COVID-19 patients is required, reducing the workload on the medical staff. However, such a diagnosis is difficult to automate because CXR images of pneumonia exhibit similar types of defects in the lung territories. Therefore, relying only on classi- cal computer vision techniques which are based on hand-crafted descriptors might be deemed to failure due to the difficulty to handle the distinctive features of pneumonia targets. 1.1. Motivation and contribution In recent years, tremendous progress has been made in mea- surement science by applying deep neural networks (DNN) tech- niques to computer vision applications such as salient object detection [13,14], facial expression recognition [15,16], and de- ception detection [17], thus DNN models have become the defacto- standard nowadays. DNN has specialized in learning-rich images with high-level discriminatory semantic characteristics automat- ically, eliminating the need for hand-crafted descriptors. These breakthroughs have revealed that deeper models can improve results [16]. Thus, it is viable to train a DNN model to obtain promising performance in COVID-19 screening and monitoring. Moreover, technological advancement has enabled the manufac- turing of low-cost portable computing devices for consumers. Cellular devices have advanced in terms of technical capabil- ities and processing power, and they have become a source of information, interaction, and sharing. They are now almost indispensable in our daily lives. Internet of Things (IoT) with cellular devices have permitted a far wider range of uses, not only for entertainment but also for the treatment and monitor- ing of health requirements, environmental surveillance, home automation, and many more [18]. Therefore, the motivation for this study is twofold. Firstly, there is a lack of resources and screening tools for identifying and monitoring COVID-19 patients, and secondly, DNN has a great potential for fetching features and accurately classifying images without any manual interven- tion. This work introduces a framework that includes a novel DNN enabled IoT service to intelligently measure the severity of COVID-19 lung infections by analyzing CXR images. The proposed DNN module consists of multi-scale sampling filters that allow extracting more reliable and noise-invariant features at different image patches. We have circumvent the shortcomings of the ex- isting DNN models and achieve superior performance by carefully designing the proposed DNN model-based multi-scale sampling. All the experiments are implemented on five databases, namely COVIDx (D1) [19], COVID-19 Radiography (D2) [20], COVID-XRay- 5K (D3) [21], COVID-19-CXR (D4) [22], and COVID-chestxray (D5) [23]. The proposed framework is compared with fourteen existing approaches by utilizing four well-known classification metrics viz., F1-score, recall, precision, and accuracy. Empiri- cal evidence manifests that the proposed method outranks all the fourteen existing approaches. The integration of the pro- posed algorithm with an IoT framework results in an efficient and precise real-time online service for COVID-19 diagnosis. The contributions of this study can be summarized as follows: • A detection and monitoring tool for the diagnosis of COVID- 19 patients is introduced. This framework is instrumented with an IoT system that helps to oversee both potential and real cases. Thus, the newly developed equipment can be employed to observe patients efficiently, especially in a remote location. • A novel DNN framework is designed for distinguishing non- COVID-19 from COVID-19 classes using CXR images. The use of X-ray simplifies the implementation of the proposed method in real-world scenarios. When compared to other testing procedures, X-rays are less expensive and take less time. • The proposed DNN consists of multi-scale filters. The strength of multi-scale sampling filters to fetch robust and noise invariant facets with distinguishing power is exploited. We hypothesize that by integrating multi-scale feature ex- traction, we can learn more resilient convolutional filters since the scale of features varies substantially among dis- tinct ground objects captured from several sensing devices. Moreover, our proposed DNN is simple as it has fewer layers and learning parameters. • We give insights into the theoretical enhancement made to the DNN model and document their empowering effect through experiments. The experimental results il- lustrate that the computation cost is considerably lower compared with some related approaches. This confirms that our approach is more computationally efficient. 2 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 The organization of the current study is structured as follows: A concise summary of a few notable previous approaches related to COVID-19 classification is put forward in Section 2. Section 3 describes the proposed work in depth. The obtained outcomes of the proposed model along with other baseline approaches are reported in Section 4. At last, Section 5 concludes the current study. 2. Related work Some recent developments in diagnosis the COVID-19 utilizing machine learning (ML) and deep learning (DL) techniques are thoroughly described in this section. In the field of medical imaging, DL techniques have classi- cally discovered a large set of applications ranging from diabetic retinopathy, histological examination, cardiac imaging, tumor de- tection, to mention a few. An emerging application of DL is to diagnose COVID-19 using CXR images, CT-scans [24], etc. Several researchers have published a set of pre-print papers tackling the problem of COVID-19 detection from CXR [19]. The reported re- sults from the latter study document promising outcomes, how- ever, they are based on small databases, which is far from the real implementation. These solutions would need to be thoroughly tested and improved before they could be put into use. Typically, researchers rely on DL techniques to classify any specific characteristics of COVID-19 patients from CXR images. DL is known to be efficient in the detection of different lung- related diseases based on chest radiography images. A plethora of legacy studies applying ML and DL algorithms to analyze the X-ray and CT images can be found in the literature [19, 25,26]. With the upsurge of the COVID-19, many recent pieces of research have investigated the usefulness of radiological im- ages for COVID-19 detection. In [19], Wang et al. presented a COVID-Net for COVID-19 detection. Further, Hemdan et al. [26] suggested an alternative approach named COVIDX-Net, consisting of seven DNN variants to detect COVID-19 from CXR images. However, these methods suffer from overfitting problem and are hard to implement in real-time applications since it has a larger network. To make it evident, the training and validation losses obtained by these two methods are analyzed and it is observed that the gap between training and validation losses is greater. Ohata et al. [27] employed transfer learning to further train various pre-trained DL models to fetch facets and accurately predict COVID-19. Tabik et al. [28] suggested a COVID-SDNet, which consists of several DNN networks for COVID-19 classifi- cation. However, these methods are very time-consuming. Arias et al. [29] presented an automatic detection of COVID-19 (AD- COVID19) using DNN with a segmentation approach. In [30], Wang et al. used a prior residual learning approach for classifying COVID-19 robustly. However, it has a large number of param- eters, hence it is hard to implement in real-time applications, especially in health care for monitoring COVID-19 patients. Khan et al. [22] utilized pre-trained XCeption architecture and further trained it on CXR images of COVID-19 and other chest pneumonia from two separate publicly accessible databases. Furthermore, Jian et al. [25] presented a DL model that directly used pre-trained models like ResNeXt, XCeption, and Inception-V3 for COVID-19 detection from CXR images. Similarly, Apostolopoulos et al. [31] used a transfer learning approach with VGG-19 and MobileNet. These methods, have a large number of parameters and require complex computational resources to train. In [32], DarkCovid- Net is presented for classification and detection of COVID-19. In [33], five pre-trained models, namely ResNet50, ResNet101, ResNet152, InceptionV3 and Inception-ResNetV2, are employed for classifying COVID-19 effectively. Some researchers have presented IoT-based diagnosis systems that collect relevant sensor data and process it in the cloud. With the advent of IoT, it has become a critical component of many environmental monitoring and healthcare applications. In [34], Nguyen provided a review of the artificial intelli- gence (AI) methods used in COVID-19 analysis. These approaches were divided into several categories, including the use of IoT. Maghdid [35] explored that sensors on smartphones can be used to acquire health information such as temperature. Rao and Vazquez [36] investigated the utility of ML techniques on user data gathered via a web-based survey obtained from smartphones for quick COVID-19 screening. In [37], Allam and Jones suggested a method to detect potential COVID-19 patients using images from a thermal camera. Otoom et al. [38] presented an IoT-based real-time detection, observation, and inspection of COVID-19 system using eight ML algorithms, namely k-nearest neighbor (KNN), support vector machine (SVM), artificial neural network (ANN), Naive Bayes, decision stump, decision table, one rule (OneR), and zero rule (ZeroR). Zhang et al. [39] presented a residual learning diagnosis detection (RLDD) system for COVID-19 classification. A residual block was used in this method to train a DNN, which is quite large, therefore complex calculations are re- quired. Furthermore, they presented an industrial IoT framework, but no comprehensive definition of how or where it should be implemented was provided. However, the performance of these methods falls short on small databases. 3. Proposed method This section offers a brief overview of the proposed DL-based IoT service for evaluating CXR images and diagnosing COVID-19 effectively. Due to the reliance on classical ML approaches on hu- man skill for feature creation, as well as DL advancements in the domain of computer vision, we propose a DL model for automatic feature engineering in this study. We will also demonstrate how our DL-based algorithm can be linked to an IoT service to create a complete diagnosis chain. 3.1. The IoT framework Social distancing is a non-pharmaceutical method of preven- tion. When we are forced to stay locked up in our homes, the IoT revolution plays an important role in modern healthcare systems in terms of professional, social, and economic prospects. As a result, in the context of the current pandemic, IoT-enabled applications can be used to reduce the potential spread of COVID- 19 through early and remote diagnosis. As a result, the present study introduces an end-to-end IoT framework to help virtually the patients in remote locations in the event of a pandemic. The challenges associated with each layer of the proposed framework are addressed, and design guidelines for dealing with them are discussed. This sub-section describes the developed IoT-based framework for observing and recognizing COVID-19 cases. This framework can also be used to track how well-reported patients respond to treatment and learn more about the COVID-19 disease. The proposed IoT framework is shown in Fig. 1, consisting of six steps labeled from 1–6. The doctor can upload a COVID-19 X- ray image or a group of images to an internet application from this screen. This method will extract information from images and classify them as non-COVID-19 or COVID-19. The proposed method extracts features from an image using the DNN model, followed by a softmax classifier that uses the extracted features as inputs to classify COVID-19. This method makes use of the LINDA, which is available as a web service. It consists of a processing flow that can (i) extract, (ii) train, (iii) predict, and (iv) store the statistics and results obtained for COVID-19 recognition. All computational processing for this IoT system is done in the cloud. The server is housed at the Instituto Federal de Educaço, Ciência, 3 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 Fig. 1. Schematic illustration of the LINDA approach for IoT-based COVID-19 detection and classification in CXR images. (1) new images can be sent for training or prediction using the same software. (2) users can define system parameters using a web application; (3) training results are displayed in plots and tables; and (4) API prediction is in charge of image processing based on the parameters set in the web application, (5) medical analysis by the doctors, and, finally, (6) Diagnostic process by the proposed DNN model. Fig. 2. Diagram showing the processing steps starting from five X-ray databases, extracting facets of the COVID-19 X-ray images based on DNN, and the classification step with softmax classifiers. e Tecnologia do Ceará. LINDA has recently gained popularity, and it has been used to develop not only medical IoT services such as stroke classification based on cerebral vascular accident images, melanocytic lesion classification based on skin images [40,41], but also machine condition monitoring [42]. When patients exhibit COVID-19-related symptoms, smart- phones, computers, and other electronic devices are permitted to transmit information and X-ray images to LINDA. A user can perform a variety of operations in LINDA, including defining the number of classes, configuring the extraction and classifier characteristics, and changing the extractors and classifiers used. LINDA also includes a graphical dashboard with metrics for eval- uating the performance of the extractor and classifier. The IoT system supports the Python programming language, the Post- greSQL database, the TensorFlow, and Keras frameworks. The flow of the developed LINDA-based IoT system is depicted in Fig. 2: the first phase entails integrating the five X-ray image databases, as well as the feature extraction and classification procedures. The data flow of the LINDA system is depicted in detail in Fig. 1. The information flow of the LINDA system will begin by sending an image from a device, as shown in Fig. 1 by the number 1. A security hash code will also be sent to the system. The system will then call the prediction API, which will select the algorithms to use based on the secure hash. The required models will be loaded into memory. If the system settings have not been completed and some changes are required, the web application (number 2) will be used to upload and categorize images. The proposed DNN is deployed on this platform, and the algorithm was trained on five databases. Section 3.2 contains a detailed de- scription of DNN. To learn more about LINDA, interested readers should visit [43]. The proposed method has three advantages: • There is no need for face-to-face communication between physicians and subjects, which reduces medical staff expo- sure to infection. • The proposed application diagnoses the X-ray image in less than a second, allowing faster response in case of positive cases. • By virtue of enjoying a short development cycle, the pro- posed IoT-based service can be easily upgraded at a minimal cost without disrupting the service. 3.2. The proposed DNN architecture In this study, we developed a multi-scale DNN system for extracting and recognizing COVID-19 features from CXR images. DNN automatically learns the various features from X-ray images using different scales, and these facets are learned by training the network over several iterations. In previous research, researchers discovered that convolutional sampling on fixed scales frequently limits a DNN’s ability to find local invariant patterns, whereas multi-scale sampling allows a DNN to find more reliable and noise-invariant features at different image patches. To address this scope in the context of the current study, a variable filter size (7 × 7, 5 × 5, 3 × 3) is used at various convolutional layers with strides of 1 × 1. Before training the network, pre-processing is performed on X-ray images as shown in Fig. 3. Fig. 4 displays the architecture of the proposed DNN. The DNN extracts robust and geometrically invariant patterns from different patches of X-ray. The input to the DNN is gray-scale images. The proposed DNN consists of 5 blocks. The first block contains 3 convolutional layers with different filter banks and Block2 consisting of pooling layers, which are stacked with Block1 convolutional layers as shown in Fig. 4. The features obtained from the Block2 are concatenated into a single feature vector. Later, three convolution operations are applied with various filter banks (i.e. Block3) on concatenated vector and combined all the features obtained from Block3, then, they are stacked with a single convolutional layer consisting of 1 × 1 filter bank followed by max-pooling operation with filter size 4 × 4. Finally, we find Block5 which is composed of two fully connected (FC) layers and a softmax layer of sizes 256, 512, and 4 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 Fig. 3. Preprocessing stages for X-ray images. The preprocessing step includes the normalization of X-ray pixels between 0 and 1, image resize, and image augmentation. Fig. 4. Illustration of the phases of the proposed DNN framework for COVID-19 detection. First, the network is trained with labeled data. We input the images to be tested into the network in the testing phase, compute the class probability (CP) of COVID-19 and non-COVID-19, and provide the diagnostic results. 2. Technically, the first four blocks (Block1, Block2, Block3, Block4) are considered for feature extraction and the last block (Block5) is employed for classifying COVID-19 using X-rays i.e. final mapping to the output. Table 2 reports the comprehensive description of each layer and its parameters. Furthermore, filters 7 × 7, 5 × 5, and 3 × 3 are utilized to capture the enriched contextual information. Moreover, the 1 × 1 filter is used as an identity function. L1=f 1 1,p(size:7×7),b1 p(size:1×1),p=1,2,...,32 L2=f 1 1,q(size:5×5),b1 q(size:1×1),q=1,2,...,32 L3=f 1 1,r (size:3×3),b1 r (size:1×1),r=1,2,...,32 L4=f 2 p,x(size:7×7),b2 x (size:1×1),s=1,2,...,64 L5=f 2 q,y(size:5×5),b2 y(size:1×1),u=1,2,...,64 L6=f 2 r,z(size:3×3),b2 z (size:1×1),v=1,2,...,64 L7=f 3 c,w(size:1×1),b3w(size:1×1),w=1,2,.128 (1) Smaller window sizes (i.e., 2 × 2) are used for the pooling layer in the proposed method as the highest information loss occurs due to the pooling layers. A max-pooling scheme is considered in this work. The formal description of the model is defined mathematically by Eq. (1). The filter initialization values f i i,k is selected at random from the distribution defined by the filter size, input, and output number of the specific layer’s feature maps where a uniform distribution with upper and lower bounds of ±k is defined by U(±k). The mathematical formulation for uniform distribution of filter initialization is shown in Eq. (2). f 1 1,p∼U ( ± √ 32 (1+32)×7×7 ) ,f 1 1,q∼U ( ± √ 32 (1+32)×5×5 ) f 1 1,r∼U ( ± √ 32 (1+32)×3×3 ) ,f 2 p,x∼U ( ± √ 64 (1+64)×7×7 ) f 2 q,y∼U ( ± √ 64 (1+64)×5×5 ) ,f 2 r,z∼U ( ± √ 64 (1+64)×3×3 ) f 2 c,w∼U ( ± √ 128 (1+128)×1×1 ) (2) The total number parameters are the sum of the parameters of each layer, where the number of parameters of each convolution layer is (f × f × (wp + b)) × fo, where f is a filter bank size, p is the input number of feature maps, and b is a bias i.e., 1 and fo is the output number of feature maps. The representation of the ith convolutional layer, Li is shown in Eq. (3). Where ∆(.) denotes an activation function of a layer. Rectified linear unit (ReLU) is an activation function adopted in this work, where fm ∈(1, fo), fo defines the number of facets maps exist in the layer Li, e is the number of input facets maps in previous layer i.e., Li−1 e . a, b denotes the coordinates of the feature maps, and ⋆indicates convolution operation. Eq. (3) is further elaborated as shown in 5 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 Table 2 Demonstration of the network parameters employed in the proposed DNN architecture. Here, BN →batch normalization. R. NO Layer Type Filter size Stride Padding Activation Output 1. I Input – – – – 128 × 128 × 1 2. L1 Convolution 7 × 7 1 Same ReLU 128 × 128 × 32 3. L2 Convolution 5 × 5 1 Same ReLU 128 × 128 × 32 4. L3 Convolution 3 × 3 1 Same ReLU 128 × 128 × 32 5. M1 Max-pooling + BN 2 × 2 2 Valid – 64 × 64 × 32 6. M2 Max-pooling + BN 2 × 2 2 Valid – 64 × 64 × 32 7. M3 Max-pooling + BN 2 × 2 2 Valid – 64 × 64 × 32 8. C1 Concatenation – – – – 64 × 64 × 96 9. L4 Convolution 7 × 7 1 Same ReLU 64 × 64 × 64 10. L5 Convolution 5 × 5 1 Same ReLU 64 × 64 × 64 11. L6 Convolution 3 × 3 1 Same ReLU 64 × 64 × 64 12. C2 Concatenation – – – – 64 × 64 × 192 13. L7 Convolution 1 × 1 1 Valid ReLU 64 × 64 × 64 14. M4 Max-pooling + BN 4 × 4 4 Valid – 16 × 16 × 64 15. F Flatten – – – – 16384 × 1 16. FC1 Full-connection – – – ReLU 512 × 1 17. FC2 Full-connection – – – ReLU 256 × 1 18. CP Class probabilities – – – Softmax 2 × 1 Eq. (4). Li fm =∆ ( Li−1 e ⋆f i e,fm +bi fm ) , (3) Li fm (a,b)= ∆ ( ∑m u=−m ∑m v=−m Li−1 e (a−u,b−v)·f i e,fm (u,v)+bi fm ) (4) The filter bank size of the layer Li is (2 × m + 1) × (2 × m + 1). In the proposed model, the ‘‘same’’ padding is applied to keep the size of the feature map constant. Max-pooling operation is performed on the output of convolutional layer Li fm with filter bank of size 2 × 2. From each feature map, max-pooling measures the utmost importance of each patch to highlight the primary feature represented within the patch. Max-pooling also reduces the number of parameters to make the model simple, In addition, it provides feature maps that are invariant to translation, rotation, and scale. As shown in Fig. 4, the input images of 128 × 128 pixels are down-sampled by the max-pooling layer, resulting in filter maps of various sizes after each layer of convolution in the Block2, later concatenated, with C1 being the output obtained by the max-pooling layer. Further, Block3 is stacked with C1, containing variable sizes of filter banks for convolution operation. Followed by concatenation operation, C2 is applied on outputs of Block3, which is called Block4. The convolution operation with filter bank of 1 × 1 is applied on output feature maps of Block4 followed by a max-pooling operation, then all the feature maps are flattened to a single vector of size 16384 × 1, where Wi and bi are the weight and bias of the ith FC layer. The output of the second FC layer, FC2, is further fed into the softmax layer. The softmax layer consists of two neurons and produces a probability vector, ˆZ = [ ˆzc, ˆznc], where, ˆzc is the prediction score of COVID-19 class and ˆznc of non- COVID-19 class. The jth probability value is obtained by Eq. (5). ˆZj = eFCj 2 ∑2 j=1 eFCj 2 , j = 1, 2. (5) 3.2.1. Network training The proposed network trains on X-ray images and computes the probability of each class, CP. The weights of the proposed network are initialized randomly with the help of uniform distri- bution as shown in Eq. (2) and the adaptive momentum (Adam) optimization technique employed to tune the hyperparameters to minimize the loss between predicted class probabilities, ˆZ = [ ˆzc, ˆ znc] and actual class probabilities, Z = [zc, znc] of COVID-19. The initial learning rate and weight decay are fixed as 0.00001 in Adam. As a loss function for the classifier, we use cross-entropy. Eq. (6) is employed to compute the cross-entropy. ψ(Z, ˆZ) = −Z log ˆZ = −[zc, znc] log[ ˆzc, ˆznc] = −zc · log( ˆzc) −znc · log(ˆznc) (6) with the batch size S, the loss function is given in Eq. (7). ψ(Z, ˆZ) = − ( 1 S S ∑ i=1 zc · log ˆzc + (znc) · log(ˆznc) ) , (7) where Z(= [z1, z2]) is one-hot encoding vector of the actual labels. Batch size 16 is considered while training the proposed DNN since the network can occupy less memory in the proposed system. 4. Empirical evidence This section delves into the specifics of the proposed DNN’s implementation, as well as the database’s details, before conclud- ing with the empirical findings. 4.1. Experimental setting This sub-section describes the resources used for experiments. For the training and testing of the proposed and existing models, the Keras framework and Anaconda Python 3.6 package are con- sidered in this study. The specifications of the working system are NVIDIA Quadro P5000 graphics processor, 256-bit memory interface, 16 GB GPU RAM, Cuda core-2560, GDDR5X memory, and 288.5 GB/s bandwidth. 4.2. Experimental data In this sub-section, we discuss about the databases and evalu- ation procedure of the proposed DNN model for diagnosing the COVID-19 is described. All the experiments are performed on the five publicly available databases, namely D1 [19], D2 [20], D3 [21], D4 [22], and D5 [23]. The statistical information of these databases is reported in Table 3. When dealing with a database containing a small number of images, overfitting or excessive variance of ML algorithms is common. The overfitting problem is addressed in this study by considering horizontal flip, random 6 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 Table 3 Statistical information according to the database and class. Database Before augmentation Train Validation Test COVID-19 non-COVID-19 COVID-19 non-COVID-19 COVID-19 non-COVID-19 D1 1299 3027 163 378 163 378 D2 960 1073 120 134 120 134 D3 148 2960 18 370 18 370 D4 256 355 32 45 32 45 D5 99 400 13 50 13 50 After augmentation D1 5196 12108 163 378 163 378 D2 3840 4292 120 134 120 134 D3 592 11840 18 370 18 370 D4 1024 1420 32 45 32 45 D5 396 1600 13 50 13 50 rotation by 10 degrees, and zoom range 0.4 as image augmen- tation strategies. Moreover, to maintain the consistency of the proposed model, all the X-ray images of five databases are resized into 128 × 128 and each database is divided into three groups: train, validation, and test sets. For all of the investigations, a k(=10)-fold cross-validation methodology is adopted to assess the performance of the proposed method. In other words, out of ten subsets, eight are employed for training, one is used for valida- tion, and the remaining one is utilized for testing. The underfitting and overfitting problems may solve by considering the 10-fold cross-validation technique. Table 3 reports the number of X-ray images employed in the train, validation, and test in the ratio of 0.8, 0.1, and 0.1, respectively. The upper and lower part of Table 3 denotes the number of samples before and after image augmentation. Moreover, four well-known evaluation metrics, namely accuracy, precision, recall, and F1-score are employed for evaluation of the proposed DNN and comparative methods. The detailed description of evaluation metrics is beyond the scope of this study. 4.3. Results In this sub-section, the empirical results of five databases are discussed. The proposed DNN is evaluated on five databases, namely D1, D2, D3, D4, and D5. Fig. 5 depicts the training proce- dure for five datasets. As seen in Fig. 5, accuracy improved rapidly during training until it reached an average of 10 to 20 iterations, and then progressively increased. After multiple iterations, the performance of the training and validation sets appeared to be smooth and did not grow any further. Similarly, training and validation losses decreased until it reached 10 to 20 epochs. The training loss assesses how well the model fits the training data, whereas the validation loss assesses how well the model fits new data. We discovered that the proposed DNN can achieve nearly 100% accuracy in training and the best results in validation. The training and validation losses of the proposed DNN are 0.1003, 0.1291 for D1, 0.0019, 0.0167 for D2, 0.0186, 0.01426 for D3, 0.0096, 0.0201 for D4, 0.0099, and 0.0213 for D5. As a result, it is clear that the proposed DNN structure offers considerable benefits in terms of COVID-19 identification. To illustrate the robustness of the proposed DNN structure on five databases, metrics such as precision, recall, F1-score are measured, which is noted in Table 4. Furthermore, the accuracy of the proposed method is compared with the fourteen existing works on the five databases, and the results are noted in Table 4. We can summarize the following: • Table 4 clearly indicates that the proposed DNN framework obtains an average detection F1-score, recall, and precision of 96% on D1, 100% on the D2, 99% on D3, 99% on D4, and 100% on D5 databases respectively. This indicates that the proposed model learns well on X-ray images and it is able to distinguish the features belonging to COVID-19 and non-COVID-19. • It is observed from Table 4 that the detection accuracy of the proposed method is 96.01% on the D1, 99.61% on D2, 99.22% on D3, 98.83% on D4, and 100% on D5 databases respectively, which is far better than the accuracies obtained by the existing methods. Besides, the error rate incurred by the proposed method on the testing set is 0.1391, 0.0057, 0.0996, 0.0178, and 0.0124 on D1, D2, D3, D4, and D5 databases, which is impressive enough in comparison with the existing methods. 4.3.1. Comparative results In this sub-section, our aim is to compare the performance of fourteen baseline approaches such as XCeption net [25], In- ception_V2 [44], SVM [38], Coronet [22], COVID-SDNet [28], AD- COVID19 [29], transfer learning approach [27], Prior attention network [30], VGG-19 [31], DarkCovidNet [32], ResNet50 [33], RLDD [39] with the proposed method in the last experiment. The short description of these approaches are discussed in Section 2 however, its detailed explanation is beyond the scope of this work. In this study, all the models adopted for comparison are im- plemented based on specifications as stated in the original papers. Table 4 reports the average classification accuracies achieved by these methods on five publicly available databases. Also notes the values of precision, recall, and F1-score of these approaches. Table 4 demonstrates that the proposed method is the best and it happens due to the use of the proposed DNN to fetch more reliable and noise-invariant facets at different image patches. Using this approach, we design an end-to-end IoT-enabled DL framework for fast and remote diagnosis which is our main objective. The achieved accuracy of the proposed DNN on five databases, namely D1, D2, D3, D4, and D5 are 96.01%, 99.61%, 99.22%, 98.83%, and 100%, respectively. Moreover, the measure- ment of the running time is a significant aspect of analyzing the proposed DNN. The training and testing time for implement- ing the proposed DNN, as well as comparative approaches, are detailed in Table 5. Normally, the training time of a DL model relies on the size of the input, the size of the network, number of folds, number of epochs, and other parameters. Moreover, all the experiments are conducted in the same environment to measure time efficiency. Table 5 clearly states that the proposed DNN requires an average training and testing time across all the databases. Moreover, a comparative analysis is employed to examine the false negatives predicted by the existing methods and the proposed DNN. False negatives refer to cases when a person, who has the COVID-19 disease screens negative rather 7 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 Fig. 5. Training and loss curves on five database. (a), (c), (e), (g), and (i) represents accuracy curve on D1, D2, D3, D4, and D5, (b), (d), (f), and (h) indicates loss curve on D1, D2, D3, D4, and D5. Table 4 Analysis of state-of-the-art methods on test set of five databases using other metrics, namely accuracy, precision, recall, and F1-score in terms of%. Ref. Method Year D1 D2 D3 D4 D5 Accuracy Precision Recall F1-score Accuracy Precision Recall F1-score Accuracy Precision Recall F1-score Accuracy Precision Recall F1-score Accuracy Precision Recall F1-score [25] XCeption net 2020 90.19 90 91 91 99.22 99 99 99 96.83 97 97 97 94.85 96 95 95 90.19 89 91 90 [19] COVID-Net 2020 94.90 96 94 95 93.05 95 93 94 91.12 91 91 91 79.89 81 80 79 90.33 91 89 90 [44] Inception_V2 2020 94.15 95 94 94 99.01 97 99 98 97.05 97 97 97 82.49 82 82 82 95.97 96 98 97 [38] SVM 2020 91.36 90 90 90 98.03 98 98 98 98.88 99 90 94 73.19 85 73 76 91.36 91 91 91 [22] Coronet 2020 92.03 92 92 92 99.50 99 99 99 98.01 98 99 98 85.00 85 85 85 92.03 92 92 92 [28] COVID-SDNet 2020 94.91 96 95 95 96.01 96 96 96 95.72 97 95 96 91.33 90 92 91 94.00 94 94 94 [29] AD-COVID19 2020 90.34 90 93 91 89.09 89 89 89 91.86 93 91 92 83.67 86 83 84 95.06 96 94 95 [27] Transfer learning 2020 88.86 89 89 89 98.02 98 98 98 93.75 96 92 94 89.33 90 89 89 97.73 97 97 97 [30] Prior attention 2020 90.06 92 90 91 91.99 92 92 92 96.58 98 96 97 87.63 88 86 87 93.00 93 93 93 [31] VGG19 2020 89.96 91 90 90 96.68 97 97 97 97.61 98 98 98 88.39 88 86 87 98.00 98 98 98 [32] DarkCovidNet 2020 88.31 88 88 88 95.37 95 95 95 98.08 98 98 98 93.18 92 94 93 95.01 95 95 95 [33] ResNet50 2021 92.05 92 92 92 97.34 97 97 97 98.32 98 98 98 94.11 96 95 94 98.86 99 99 99 [39] RLDD 2021 93.33 93 93 93 96.02 97 95 96 97.07 98 97 96 90.91 91 91 91 95.66 97 95 96 – Proposed method – 96.01 96 96 96 99.61 100 99 100 99.22 99 99 99 98.83 98 99 99 100 100 100 100 Table 5 Execution time in seconds on five databases viz. D1, D2, D3, D4, and D5 by various methods. Ref. Method Training time Testing time for all the Images D1 D2 D3 D4 D5 D1 D2 D3 D4 D5 [25] XCeption net 495.0 480.0 270.0 330.0 316.13 5.0 16.0 10.0 3.01 2.0 [19] COVID-Net 939.0 987.0 438.33 402.01 386.99 25.0 27.05 11.76 8.33 4.09 [44] Inception_V2 4700.0 850.0 925.0 625.0 600.01 12.0 19.0 18.02 11.23 10.0 [38] SVM 16.75 13.2675 19.62 17.34 15.091 2.3145 1.3167 2.891 1.8472 1.2710 [22] Coronet 2488.0 2676.0 1336.0 1720.0 1201.09 86.0 42.0 51.0 36.701 24.42 [28] COVID-SDNet 451.00 526.66 357.92 380.06 365.66 86.0 35.0 38.33 23.64 14.96 [29] AD-COVID19 98.01 101.03 78.72 67.00 43.94 9.04 11.35 3.78 2.00 1.33 [27] Transfer learning 92.98 17.63 19.09 5.092 4.66 3.014 3.63 1.302 1.001 0.78 [30] Prior attention 245.33 260.04 201.33 166.66 102.11 67.27 30.98 23.02 19.00 13.109 [31] VGG19 2205.0 2782.06 1618.0 1920.0 1386.0 6.0 8.2 7.01 5.11 3.03 [32] DarkCovidNet 200.0 250.0 180.0 185.0 150.0 1.03 1.769 1.25 0.996 0.841 [33] ResNet50 934.0 960.0 700.08 658.00 500.0 17.0 19.0 15.0 14.07 10.2 [39] RLDD 104.65 99.09 84.68 58.88 38.01 11.09 4.330 3.810 3.002 1.109 – Proposed method 95.4 96 66 20.9 12.3 0.541 0.692 1.28 0.461 0.202 than positive which is included in Fig. 6. In this regard, we wish to mention that all the five databases are considered together while computing false-negative cases. It is clear from Fig. 6 that the proposed DNN has very few false negatives to existing state- of-the-art methods. In addition to this, in this study, the number of parameters involved and memory size (in MB) required for an image are used to determine the complexity of the proposed DNN. The proposed DNN’s complexity is compared to 12 current state-of-the-art DL approaches and results are reported in Table 6. Table 6 demonstrates that the number of parameters in the 8 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 Fig. 6. A comparative analysis on number of false negatives of existing approaches as well as the proposed DNN. Table 6 Computational efficiency analysis of the proposed DNN with other DL approaches. Ref. Method No. parameters (in millions (M)) Memory size (in MB) [25] XCeption net 29.2 38 [19] COVID-Net 11.75 106 [44] Inception_V2 55.9 296 [22] Coronet 33.9 240 [28] COVID-SDNet 40.3 386 [29] AD-COVID19 89.1 820 [27] Transfer learning 11.6 120 [30] Prior attention 15.9 110 [31] VGG19 20.5 385 [32] DarkCovidNet 1.12 8 [33] ResNet50 25.6 420 [39] RLDD 26 160 – Proposed method 9.04 94 proposed DNN is smaller than the number of parameters in nine- teen state-of-the-art DL techniques, demonstrating the proposed DNN’s simplicity. In comparison to existing DL techniques, the memory size (in MB) required for an image is also smaller. It could satisfy the needs of many real-time COVID-19 diagnosis applications. After optimization in both time and space, the model could be equipped with real-time edge devices, such as NVIDIA TX2. 4.4. Robustness of the proposed DNN In this sub-section, we conduct experiments to find the ro- bustness of the proposed DNN. In basic terms, feature engineering is the process of converting chest x-ray images into desirable features using the proposed DNN in order to improve model accuracy. To compare the performance of the proposed DNN with some state-of-the-art approaches, accuracy, precision, re- call, and F1-score are used, and the results are presented in Table 4. The proposed DNN outperforms all state-of-the-art tech- niques, as reported in Table 4. It means the proposed DNN does the feature engineering task well in comparison to other state- of-the-art methods. Nowadays, the values of these evaluation measures are no longer sufficient to demonstrate how good a DL model is. The t-SNE plots of the feature vectors obtained by the proposed DNN along with state-of-the-art approaches on five different databases are shown in Figs. 7, 8, 9, 10, and 11 in order to illustrate the effectiveness of the proposed DNN model over some of the existing methods. The features in a 2-D plot are depicted using t-distributed stochastic neighbor embedding, a dimensional reduction technique that allows us to perceive a high-dimensional database in a low-dimensional environment. Because such embedding incorporates categorization informa- tion, it visualizes the learned proposed network’s most recent embeddings. It is clear from Figs. 7, 8, 9, 10, and 11 that the pro- posed DNN is the only method, which can extract distinguishable features for five databases separately and forms well-separated clusters when we are mapping them from higher-dimensional to a two-dimensional plane. The t-SNE plots of a few of the existing approaches are also well separated with a small margin on some of the databases. Thus, the performances of these methods are not always consistent. This experiment shows how efficient the pro- posed method is. Furthermore, to show the proposed method’s efficient feature learning capacity, the probability vector created by the softmax layer is compared to a few existing DL techniques. Initially, the five best state-of-the-art methods are selected based on their accuracies [19,22,25,28,39]. We pick four CXR images (two are from COVID-19 patients and two are from a healthy person) randomly from the test sets. Then, the probability score of each method along with the proposed approach to these four images is estimated and displayed in Fig. 12. The label ‘0’ and ‘1’ in the graphs of Fig. 12 denote the probability of covid-19 infected patients and healthy persons, respectively. The probability score ranges between 0 to 1 and the ideal probability score of label ‘0’ and label ‘1’ for covid-19 infected patients is 1 and 0, respectively. Similarly, it is vice versa for healthy people. It can be observed from Fig. 12 that the proposed method predicts scores nearer to ideal values for both covid-19 infected patients and healthy persons. On the other hand, probability scores obtained by the existing DNN based approaches for healthy persons and infected patients are relatively far from the ideal values. 9 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 Fig. 7. Feature visualization on D1 database. Here, (a) shows the input feature map, (b)–(m) depicts the feature maps obtained from existing methods, and (n) shows the feature map obtained from the proposed DNN. Fig. 8. Feature visualization on D2 database. Here, (a) shows the input feature map, (b)–(m) depicts the feature maps obtained from existing methods, and (n) shows the feature map obtained from the proposed DNN. In addition to this, we observe that the proposed DNN is evaluated using a 10-fold cross-validation procedure, in which the original dataset is randomly divided into ten equal-size sub- samples. Only one subsample of the ten is preserved as test data for the algorithm, while the other nine are used for training and validation. The folds are then used to repeat the cross-validation process ten times, with each of the ten subsamples serving as validation data exactly once. The performance of the proposed DNN can then be estimated by averaging (or otherwise combin- ing) the evaluation metrics acquired from the 10 folds. However, the proposed DNN’s overall accuracy differs from the individual accuracy of each fold. To identify the variance in the obtained accuracies on each database, the standard deviation of accuracies acquired in ten different folds is assessed, as illustrated in Fig. 13. 10 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 Fig. 9. Feature visualization on D3 database. Here, (a) shows the input feature map, (b)–(m) depicts the feature maps obtained from existing methods, and (n) shows the feature map obtained from the proposed DNN. Fig. 10. Feature visualization on D4 database. Here, (a) shows the input feature map, (b)–(m) depicts the feature maps obtained from existing methods, and (n) shows the feature map obtained from the proposed DNN. It is clear from Fig. 13 that the obtained low standard deviation on a database implies that 10-fold accuracies tend to be extremely close to the averaged accuracy of the proposed DNN. 4.5. Ablation study To develop a DNN model from scratch for a particular prob- lem is not an easy task especially when we are facing the data scarcity problem with a database containing few images. An ablation study is required to understand the contribution of each module of the proposed DNN. Thus, an ablation study is con- ducted to finalize the architecture of the proposed model in such a way that it performs well with a test set. In accordance with our experiments, the proposed DNN gives an accuracy of 96.01%, 99.61%, 99.22%, 98.83%, and 100% for the task of COVID- 19 classification of the X-ray images on D1, D2, D3, D4, and 11 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 Fig. 11. Feature visualization on D5 database. Here, (a) shows the input feature map, (b)–(m) depicts the feature maps obtained from existing methods, and (n) shows the feature map obtained from the proposed DNN. Table 7 The performance in terms of accuracy (%) on the test set of five databases with and without batch normalization layers & variation of pooling layers and without pooling layers are noted. The seventh experiment belongs to batch normalization BN D1 D2 D3 D4 D5 No 92.87 98.82 99.05 93.19 96.82 Yes 96.01 99.61 99.22 98.83 100 The eighth experiment belongs to pooling Pooling D1 D2 D3 D4 D5 Max 96.01 99.61 99.22 98.83 100 Average 94.46 99.21 99.16 90.01 100 No 88.01 97.64 94.44 89.38 96.82 D5 databases respectively. In this sub-section, the effect of the performance of the proposed DNN is assessed by varying the model parameters. In the first experiment, the behavior of the DNN model for different activation functions is shown in Fig. 14. Fig. 14 indicates that ReLU activation gives a better performance than others. In the second experiment, the effect of the batch normalization layer on the performance of the proposed DNN is evaluated. The results of the second experiment are presented in the upper part of Table 7. In the third experiment, the effect of change in pooling layers on the performance of the proposed DNN is assessed. The results of this study are presented in the lower part of Table 7. The proposed DNN is divided into five blocks, namely Block1, Block2, Block3, Block4, and Block5. We have experimented i.e., the fourth experiment, to quantify the block- wise performance of the proposed DNN. The results of the fourth experiment are shown in Table 8. From Table 8, we can observe that although increasing layers containing blocks the proposed model gives better performance. Moreover, we can observe from the last row of Table 8 is that overfitting occurred after increasing more than 5 blocks. In ad- dition, as seen in Fig. 15, there is a huge gap between training and validation losses when increasing more than 5 blocks. So, the model is overfitting. Moreover, optimization plays a crucial role in the DL model for updating the weights to reduce the losses of the DL model, also called hyper-parameter tuning. There are many optimiza- tion techniques available for parameter hyper-space search. Some of the widely used optimization techniques for DL approaches are stochastic gradient descent (SGD), adaptive gradient descent (Adagrad), root mean square propagation (RMSprop), SGD with momentum, and adaptive moment estimation (Adam). In the fifth experiment, we have tested the aforementioned optimiza- tion techniques. The performance analysis of various optimization techniques is shown in Fig. 16. It can be observed from Fig. 16 that Adam optimization gave a better performance for COVID-19 classification from X-ray images. However, the proposed model obtained a satisfactory performance for other optimization tech- niques. Variations of different scales are examined by the sixth experiment. Table 9, shows the performance of the proposed DNN using different filter scales. To measure the importance of the multi-scale approach, conducted a seventh experiment with and without multi-scale blocks of the proposed DNN. The mea- surement of the proposed DNN performance with and without multi-scale is shown in Fig. 17. 12 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 Fig. 12. The comparative probability scores of the proposed DNN along with existing methods. (a), (c) represents the COVID-19 CXR images and (b), (d) indicates the non-COVID-19 CXR images. Each row represents the probability scores of two classes. (e), (f), (g), (h) is of [25], (i), (j), (k), (l) is of [19], (m), (n), (o), (p) is for [22], (q), (r), (s), (t) is for [28], (u), (v), (w), (x) is for [39], (y), (z), (aa), (ab) is for the proposed method. Fig. 13. The performance (averaged accuracy ±standard deviation) of the proposed DNN on five databases. It is clear from Fig. 17 that the performance of the proposed DNN without multi-scale is not satisfactory. Thus, we can con- clude that multi-scale features provide significant features to distinguish COVID-19 from non-COVID-19. It can be observed from Table 9 that the combination of 3 × 3, 5 × 5, 7 × 7 scales gave better performance than other scales. In addition, an experiment is conducted on varying learning rates. Fig. 18, shows the performance varying while changing learning 13 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 Fig. 14. Variation of COVID-19 classification accuracies (%) obtained using different activation functions, where Selu →scaled exponential linear unit, Elu → exponential linear unit, Tanh →hyperbolic tangent, ReLU →rectified linear unit. Fig. 15. The training and validation losses incurred by the proposed DNN model after adding more layers to it on five databases. (a), (b), (c), (d), and (e) indicates five databases, namely D1, D2, D3, D4, and D5. Here, B15 →Block1 + Block5, B125 →Block1 + Block2 + Block5, B1235 →Block1 + Block2 + Block3 + Block5, B12345 →Block1 + Block2 + Block3 + Block4 + Block5, B1234E5 →Block1 + Block2 + Block3 + Block4 + Extrablock + Block5. Table 8 The performance in terms of accuracy (%) on the test set of five databases with varying blocks of the proposed DNN (for example, Block1 + Block5, Block1 is for feature extraction and Block5 is for classification). Blocks D1 D2 D3 D4 D5 Block1 + Block5 93.88 97.64 94.45 89.38 98.41 Block1 + Block2 + Block5 94.63 99.21 99.01 93.19 98.59 Block1 + Block2 + Block3 + Block5 94.91 99.21 99.22 94.16 96.82 Block1 + Block2 + Block3 + Block4 + Block5 96.01 99.61 99.22 98.83 100 Block1 + Block2 + Block3 + Block4 + ExtraBlock + Block5 74.63 73.09 78.43 65.89 84.21 14 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 Fig. 16. Variation of COVID-19 classification accuracies (%) obtained on the test set using different optimization techniques. Fig. 17. The effect of the proposed DNN with and without multi-scale approach, where, WMS →With multi-scale and WOMS →Without multi-scale. Table 9 The performance in terms of accuracy (%) on the test set of five databases with varying filter scales of the proposed DNN. Blocks D1 D2 D3 D4 D5 11 × 11, 3 × 3, 5 × 5 95 98 71 86 100 11 × 11, 5 × 5, 7 × 7 94 97 94 82 100 11 × 11, 3 × 3, 7 × 7 82 98 95 80 100 9 × 9, 3 × 3, 5 × 5 95 98 94 84 100 9 × 9, 5 × 5, 7 × 7 85 96 94 86 95 9 × 9, 3 × 3, 7 × 7 92 97 89 83 100 1 × 1, 3 × 3, 5 × 5 92 98 98 90 98 1 × 1, 5 × 5, 7 × 7 91 98 98 84 98 1 × 1, 3 × 3, 7 × 7 91 98 97 85 76 3 × 3, 5 × 5, 7 × 7 96.01 99.61 99.22 98.83 100 Fig. 18. Evaluation of different learning rates on five databases. rates. From Fig. 18, it is observed that the learning rate at 0.00001 obtained higher classification accuracy. 5. Conclusion In this study, a DNN enabled IoT framework is introduced for fast and accurate detection of COVID-19. Five databases viz., D1, D2, D3, D4, and D5 are considered in this study to manifest the efficiency of the proposed method over existing approaches. One of the key benefits of integrating IoT into healthcare is reduc- ing the exposition to contagion and automating the diagnosis, thus making the medical staff more concentrated on patients. Connected to this, the DNN framework is employed to fetch more reliable and noise-invariant facets at various image patches. The proposed method acquires an average recognition accuracy 15 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 of 96.01%, 99.61%, 99.22%, 98.83%, and 100% respectively. Ex- perimental outcomes also manifest that the proposed method outranks fourteen contemporary approaches by adopting the av- erage time i.e., training and testing time. Compared to the existing methods, the proposed model predicts very few FP’s and FN’s, which is shown in Fig. 6. Furthermore, it is worth investigating to deploy the proposed model in some real-life settings. The results obtained in this study are very promising and this work can be extended by considering multiple factors in the future. For future work, we intend to enhance the diversity of the database by adding new X-ray images of patients with COVID-19, as soon as these images are available, and by including X-ray exams of other lung-related diseases. Further, more efforts will be given to exploring how to identify COVID-19 in the early stages and how the prior attention mechanism can be employed in other medical image analysis problems. CRediT authorship contribution statement Mohan Karnati: Conception and design of study, Acquisi- tion of data, Analysis and/or interpretation of data, Drafting the manuscript, Revising the manuscript critically for important in- tellectual content, . Ayan Seal: Conception and design of study, Acquisition of data, Analysis and/or interpretation of data, Draft- ing the manuscript, Revising the manuscript critically for impor- tant intellectual content. Geet Sahu: Conception and design of study, Acquisition of data, Analysis and/or interpretation of data, Drafting the manuscript, Revising the manuscript critically for im- portant intellectual content. Anis Yazidi: Conception and design of study, Acquisition of data, Analysis and/or interpretation of data, Drafting the manuscript, Revising the manuscript critically for important intellectual content. Ondrej Krejcar: Conception and design of study, Acquisition of data, Analysis and/or interpre- tation of data, Drafting the manuscript, Revising the manuscript critically for important intellectual content. Declaration of competing interest The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper. Acknowledgments This work is partially supported by the project ‘‘Smart So- lutions in Ubiquitous Computing Environments’’’, Grant Agency of Excellence, University of Hradec Kralove, Faculty of Informat- ics and Management, Czech Republic (under ID: UHK-FIM-GE- 2022); and by the SPEV project ‘‘Smart Solutions in Ubiquitous Computing Environments’’’, University of Hradec Kralove, Fac- ulty of Informatics and Management, Czech Republic (under ID: UHK-FIMSPEV-2022-2102). We are also grateful for support of Ph.D. student Michal Dobrovolny in consultations of some imple- mentation issues. All authors approved the final version of the manuscript. References [1] Y.-H. Xu, J.-H. Dong, W.-M. An, X.-Y. Lv, X.-P. Yin, J.-Z. Zhang, L. Dong, X. Ma, H.-J. Zhang, B.-L. Gao, Clinical and computed tomographic imaging fea- tures of novel coronavirus pneumonia caused by SARS-CoV-2, J. Infection 80 (4) (2020) 394–400. [2] worldometere, Covid-19 coronavirus pandemic, 2020, URL IwAR2UgycDn8i64zB71xUGm5svanZxQEI_U6IEEzgiNRtMnVLtBQtyKqPW_ e8. [3] E. Mahase, Coronavirus: covid-19 has killed more people than SARS and mers combined, despite lower case fatality rate, 2020. [4] L. Yan, H.-T. Zhang, Y. Xiao, M. Wang, Y. Guo, C. Sun, X. Tang, L. Jing, S. Li, M. Zhang, et al., Prediction of criticality in patients with severe Covid-19 infection using three clinical features: a machine learning-based prognostic model with clinical data in wuhan, 2020, medRxiv. [5] A. Singh, S.K. Chandra, M.K. Bajpai, Study of non-pharmacological interventions on COVID-19 spread, 2020, medRxiv. [6] W. Wang, Y. Xu, R. Gao, R. Lu, K. Han, G. Wu, W. Tan, Detection of SARS-CoV-2 in different types of clinical specimens, JAMA 323 (18) (2020) 1843–1844. [7] C. Vermeiren, X. Marchand-Senécal, E. Sheldrake, D. Bulir, M. Smieja, S. Chong, J.D. Forbes, K. Katz, Comparison of copan eswab and floqswab for COVID-19 PCR diagnosis: working around a supply shortage, J. Clin. Microbiol. (2020). [8] E. Prompetchara, C. Ketloy, T. Palaga, Immune responses in COVID-19 and potential vaccines: Lessons learned from SARS and MERS epidemic, Asian. Pac. J. Allergy Immunol. 38 (1) (2020) 1–9. [9] Y. Fang, H. Zhang, J. Xie, et al., Sensitivity of chest ct for covid-19: comparison to rt-pcr, Radiology 200432 (2020). [10] Z. Ye, Y. Zhang, Y. Wang, Z. Huang, B. Song, Chest CT manifestations of new coronavirus disease 2019 (COVID-19): a pictorial review, Eur. Radiol. (2020) 1–9. [11] B. Wang, S. Jin, Q. Yan, H. Xu, C. Luo, L. Wei, W. Zhao, X. Hou, W. Ma, Z. Xu, et al., AI-assisted CT imaging analysis for COVID-19 screening: Building and deploying a medical AI system, Appl. Soft Comput. 98 (2021) 106897. [12] H.Y.F. Wong, H.Y.S. Lam, A.H.-T. Fong, S.T. Leung, T.W.-Y. Chin, C.S.Y. Lo, M.M.-S. Lui, J.C.Y. Lee, K.W.-H. Chiu, T.W.-H. Chung, et al., Frequency and distribution of chest radiographic findings in patients positive for COVID-19, Radiology 296 (2) (2020) E72–E78. [13] A.K. Gupta, A. Seal, P. Khanna, A. Yazidi, O. Krejcar, Gated contextual features for salient object detection, IEEE Trans. Instrum. Measur., 1–13. [14] A.K. Gupta, A. Seal, P. Khanna, E. Herrera-Viedma, O. Krejcar, Almnet: Adjacent layer driven multiscale features for salient object detection, IEEE Trans. Instrum. Meas. 70 (2021) 1–14, 3108503. [15] K. Mohan, A. Seal, O. Krejcar, A. Yazidi, FER-net: facial expression recognition using deep neural net, Neural Comput. Appl., 1–12. [16] K. Mohan, A. Seal, O. Krejcar, A. Yazidi, Facial expression recognition using local gravitational force descriptor-based deep convolution neural networks, IEEE Trans. Instrum. Meas. 70 (2020) 1–12. [17] M. Karnati, A. Seal, A. Yazidi, O. Krejcar, Lienet: A deep convolution neural networks framework for detecting deception, IEEE Trans. Cogn. Dev. Syst. (2021). [18] I. Yaqoob, E. Ahmed, I.A.T. Hashem, A.I.A. Ahmed, A. Gani, M. Imran, M. Guizani, Internet of things architecture: Recent advances, taxonomy, requirements, and open challenges, IEEE Wirel. Commun. 24 (3) (2017) 10–16. [19] L. Wang, Z.Q. Lin, A. Wong, Covid-net: A tailored deep convolutional neural network design for detection of covid-19 cases from chest x-ray images, Sci. Rep. 10 (1) (2020) 1–12. [20] T. Rahman, COVID-19 radiography database, 2020, URL kaggle.com/tawsifurrahman/covid19-radiography-database. [21] S. Minaee, R. Kafieh, M. Sonka, S. Yazdani, G.J. Soufi, Deep-covid: Predicting covid-19 from chest x-ray images using deep transfer learning, Med. Image Anal. 65 (2020) 101794. [22] A.I. Khan, J.L. Shah, M.M. Bhat, Coronet: A deep neural network for detection and diagnosis of COVID-19 from chest x-ray images, Comput. Methods Programs Biomed. (2020) 105581. [23] C. Li, M. Wang, G. Wu, K. Rana, N. Charoenkitkarn, J. Chan, COVID19 chest X-ray classification with simple convolutional neural network, in: CSBio’20: Proceedings of the Eleventh International Conference on Computational Systems-Biology and Bioinformatics, 2020, pp. 97–100. [24] Q. Yan, B. Wang, D. Gong, C. Luo, W. Zhao, J. Shen, J. Ai, Q. Shi, Y. Zhang, S. Jin, et al., Covid-19 chest CT image segmentation network by multi- scale fusion and enhancement operations, IEEE Trans. Big Data 7 (1) (2021) 13–24. [25] R. Jain, M. Gupta, S. Taneja, D.J. Hemanth, Deep learning based detection and analysis of COVID-19 on chest X-ray images, Appl. Intell. (2020) 1–11. [26] E.E.-D. Hemdan, M.A. Shouman, M.E. Karar, Covidx-net: A framework of deep learning classifiers to diagnose covid-19 in x-ray images, 2020, arXiv preprint arXiv:2003.11055. [27] E.F. Ohata, G.M. Bezerra, J.V.S. das Chagas, A.V.L. Neto, A.B. Albuquerque, V.H.C. de Albuquerque, P.P. Reboucas Filho, Automatic detection of COVID- 19 infection using chest X-ray images through transfer learning, IEEE/CAA J. Autom. Sin. 8 (1) (2020) 239–248. [28] S. Tabik, A. Gómez-Ríos, J.L. Martín-Rodríguez, I. Sevillano-García, M. Rey- Area, D. Charte, E. Guirado, J.-L. Suárez, J. Luengo, M. Valero-González, et al., Covidgr dataset and COVID-sdnet methodology for predicting COVID-19 based on chest X-ray images, IEEE J. Biomed. Health Inf. 24 (12) (2020) 3595–3605. 16 M. Karnati, A. Seal, G. Sahu et al. Applied Soft Computing 125 (2022) 109109 [29] J.D. Arias-Londoño, J.A. Gomez-Garcia, L. Moro-Velázquez, J.I. Godino- Llorente, Artificial intelligence applied to chest X-ray images for the automatic detection of COVID-19. a thoughtful evaluation approach, IEEE Access 8 (2020) 226811–226827. [30] J. Wang, Y. Bao, Y. Wen, H. Lu, H. Luo, Y. Xiang, X. Li, C. Liu, D. Qian, Prior- attention residual learning for more discriminative COVID-19 screening in CT images, IEEE Trans. Med. Imaging 39 (8) (2020) 2572–2583. [31] I.D. Apostolopoulos, T.A. Mpesiana, Covid-19: automatic detection from x- ray images utilizing transfer learning with convolutional neural networks, Phys. Eng. Sci. Med. (2020) 1. [32] T. Ozturk, M. Talo, E.A. Yildirim, U.B. Baloglu, O. Yildirim, U.R. Acharya, Automated detection of COVID-19 cases using deep neural networks with X-ray images, Comput. Biol. Med. 121 (2020) 103792. [33] A. Narin, C. Kaya, Z. Pamuk, Automatic detection of coronavirus disease (covid-19) using x-ray images and deep convolutional neural networks, Pattern Anal. Appl. 24 (3) (2021) 1207–1220. [34] T.T. Nguyen, Artificial intelligence in the battle against coronavirus (COVID-19): a survey and future research directions, 10, 2020, Preprint. [35] H.S. Maghdid, K.Z. Ghafoor, A.S. Sadiq, K. Curran, K. Rabie, A novel ai- enabled framework to diagnose coronavirus covid 19 using smartphone embedded sensors: Design study, 2020, arXiv preprint arXiv:2003.07434. [36] A.S.S. Rao, J.A. Vazquez, Identification of COVID-19 can be quicker through artificial intelligence framework using a mobile phone–based survey when cities and towns are under quarantine, Infect. Control Hosp. Epidemiol. 41 (7) (2020) 826–830. [37] Z. Allam, D.S. Jones, On the coronavirus (COVID-19) outbreak and the smart city network: universal data sharing standards coupled with artificial intelligence (AI) to benefit urban health monitoring and management, in: Healthcare, Vol. 8, (1) Multidisciplinary Digital Publishing Institute, 2020, p. 46. [38] M. Otoom, N. Otoum, M.A. Alzubaidi, Y. Etoom, R. Banihani, An IoT-based framework for early identification and monitoring of COVID-19 cases, Biomed. Signal Process. Control 62 (2020) 102149. [39] M. Zhang, R. Chu, C. Dong, J. Wei, W. Lu, N. Xiong, Rldd: An advanced residual learning diagnosis detection system for COVID-19 in iIoT, IEEE Trans. Ind. Inf. (2021). [40] C.M. Dourado, S.P.P. Da Silva, R.V.M. Da Nóbrega, P.P. Rebouças Filho, K. Muhammad, V.H.C. De Albuquerque, An open IoHT-based deep learn- ing framework for online medical image recognition, IEEE J. Sel. Areas Commun. 39 (2) (2020) 541–548. [41] D.D.A. Rodrigues, R.F. Ivo, S.C. Satapathy, S. Wang, J. Hemanth, P.P. Reboucas Filho, A new approach for classification skin lesion based on transfer learning, deep learning, and IoT system, Pattern Recognit. Lett. 136 (2020) 8–15. [42] Q. Hu, E.F. Ohata, F.H. Silva, G.L. Ramalho, T. Han, P.P. Reboucas Filho, A new online approach for classification of pumps vibration patterns based on intelligent IoT system, Measurement 151 (2020) 107138. [43] C.M. Dourado Jr., S.P.P. da Silva, R.V.M. da Nobrega, A.C.d.S. Barros, P.P. Reboucas Filho, V.H.C. de Albuquerque, Deep learning IoT system for online stroke detection in skull computed tomography images, Comput. Netw. 152 (2019) 25–39. [44] D. Dansana, R. Kumar, A. Bhattacharjee, D.J. Hemanth, D. Gupta, A. Khanna, O. Castillo, Early diagnosis of COVID-19-affected patients based on X-ray and computed tomography images using deep learning algorithm, Soft Comput. (2020) 1–9. 17"
Hadoop MapReduce scheduling paradigms,"Johannessen, Roger and Yazidi, Anis and Boning Feng",2017,,,,inproceedings,"2017 the 2nd IEEE International Conference on Cloud Computing and Big Data Analysis 
Hadoop MapReduce Scheduling Paradigms 
Roger Johannessen, Anis Yazidi, Boning Feng 
Department of Computer Science 
Oslo and Akershus University College of Applied Sciences 
Oslo, Norway 
e-mail: anis.yazidi@hioa.no.boning.feng@hioa.no 
Abstract-Apache Hadoop is one of the most prominent and 
early technologies for handling big data. Different scheduling 
algorithms within the framework of Apache Hadoop were 
developed in the last decade. In this paper, we attempt to 
provide 
a 
comprehensive 
overview 
over 
the 
different 
paradigms for scheduling in Apache Hadoop. The surveyed 
approaches fall under different categories, namely, Deadline 
prioritization, Resource prioritization, Job size prioritization, 
Hybrid approaches and recent trends for improvements upon 
default schedulers. 
Keywords-Apache 
Hadoop; 
MapReduce; 
scheduling 
paradigms 
I. 
INTRODUCTION 
Bollier stated, ""Big websites can generate terabytes of 
raw log data every day. The sheer size of its data set has 
led 
to 
the 
emergence 
of 
new 
cloud 
infrastructures, 
characterized by 
the 
ability 
to scale 
to 
thousands 
of 
nodes, fault tolerance and relaxed consistency"" [1]. From 
2005 to 2020, the digital universe is expected to grow 
dramatically by a factor of 300, from 130 exabytes to 40 
trillion gigabytes, i.e. more than 5,200 gigabytes per person 
in 2020. Moreover, the digital universe is expected to 
double every two years [2]. A big part of the growth is a 
defining trait of our current technology landscape -
the 
Internet of Things, quickly evolving into: ""The Internet of 
Everything"" 
[3]. 
The 
benefits 
of 
""all 
interconnected"" 
devices is immense in tenns of potentially huge increase 
in quality of life. In the same time, it brings along the 
challenge of handling extreme amounts of data. Devices 
generate nowadays vast amounts logging data, but also 
functional data such as media streams that are key to the 
sole purpose of the device. Data is becoming the world's 
new natural resource [4]. The challenges represented by 
big data handling can be divided into three groups: 
• 
Velocity 
• 
Volume 
• 
Variety 
Hadoop possesses a sophisticated set of methods that 
handle the above challenges elegantly through the use of: 
• 
Hadoop Common (a set of utilities and libraries) 
• 
The file system called HDFS (Hadoop File System) 
• 
YARN (Yet Another Resource Negotiator) 
• 
MapReduce (a framework for distributing tasks and 
parallel processing) 
978-1-5090-4499-3/17/$31.00 ©20 17 IEEE 
175 
II. 
RELATED WORK 
In this section, we will survey some promIsmg new 
scheduling algorithms, as well as some highly-cited and well 
established ones. We have categorized those scheduling 
algorithms by the type of the scheduling priority. 
A. 
Deadline Prioritization 
(1) 
Deadline 
Constraint 
Scheduler: 
Prioritizing 
deadline in a Hadoop clusters is done by predicting the 
completion time of jobs/tasks and then allocating them to 
nodes capable of processing them within a time limit where 
the data is actually useful. The research reported in [5] was 
motivated by the fact that FIFO, the default scheduling 
algorithm of Hadoop clusters, has some visible drawbacks 
due to its rigid prioritization scheme. The paper explores real 
time cluster scheduling based on user specified deadlines. 
The authors give a preliminary evaluation of their algorithm 
reckoned as Deadline Constraint Scheduler, which is a 
scheduler that simply ignores new tasks that cannot be 
processed 
within 
their 
deadline. 
This 
is 
achieved 
by 
calculating the deadline and comparing it to the execution 
time. The latter approach performs well in a homogeneous 
cluster, but is invalidated in a heterogeneous cluster where 
execution times might vary across nodes. In this case, the 
algorithm relaxes some of its parameters so that to allow 
processing times to be decoupled from the slowest node. 
However, this might lead to under-utilization of certain 
nodes in the cluster. The authors concede that they will 
address this issue in future work. To calculate schedulability, 
the work calculates the minimum amount of map tasks to get 
a job done, and compares it to the maximum amount of 
reduce tasks. If there is less available reduce slots than the 
maximum amount of possible reduce tasks in the job, the 
task is dropped. Experimental results show greater task 
efficiency during MapReduce phases [5]. 
(2) Cloud Least Laxity First: In another approach 
introduced in the paper entitled ""A Deadline Scheduler for 
Jobs in Distributed Systems"" [6], the authors propose an 
interesting deadline scheduler for Hadoop called Cloud Least 
Laxity First (CLLF), that orders tasks based on laxity (time 
left over to deadline, after task is [mished). They argue that 
by using this technique one can reduce the amount of nodes 
needed while maintaining total execution time at acceptable 
levels. This was proven by comparing the algorithm to Time 
Shared 
and 
Space 
Shared 
scheduling 
in 
a 
controlled 
environment. The devised scheduler handles soft deadlines 
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore.  Restrictions apply. 
 by introducing a penalty tenn as a function of the lateness 
(lateness defmed as completion time minus deadline). The 
authors describe a system in which each worker node uses a 
FIFO-queue and notifies the master as soon as it has an idle 
processor. The master has the role of hosting the CLLF­
algorithm and allocating tasks. As the authors themselves 
describe it: ""The general idea of the algorithm is to sort the 
cloudlets by laxities (the fust has the lowest one). Giving this 
sorted list, the algorithm takes the fust element of this list 
and looks for a host that locally have the data of the cloudlet 
and which also have at least one free slot. If one matching 
host is found, the task is ran on it; otherwise, the algorithm 
restarts the same procedure using the second element of the 
list"" [6]. As in the case of the algorithm reported in [5] which 
falls in this category, this algorithm 
[6] is limited to 
homogeneous environments. In line with goal of reducing 
the amount of virtual nodes needed for job executions, the 
work [6] shows a considerable decrease in missed deadlines 
compared to Time Shared and Space Shared algorithms, thus, 
increasing the disparity in effectiveness of the latter two 
algorithms. 
B. 
Resource Prioritization 
(1) Coupling Scheduler: 
Algorithms 
delving 
into 
resource allocation and optimization of utilization of worker 
nodes are perhaps the most investigated topic within the field 
of MapReduce. As processing and handling of data is getting 
more and more centralized, virtualized Hadoop clusters seem 
to be the future of MapReduce and has emerged as enabler 
for business ventures through the cloud. In [7], it was argued 
that the widely used Fair Scheduler has a starvation problem 
involving the Map and Reduce operations. The paper focuses 
on coupling the two progresses, instead of treating them 
separately. The authors [7] also performed a performance 
comparison, 
proving 
that Coupling 
Scheduler 
performs 
better than Fair Scheduler in handling tasks with varying 
map service times. The main effect this has on resource 
usage is that reducers are gradually launched as more and 
more maps are completed, instead of allocating a quantity of 
reducers based on predicted need, i.e. as seen in [5]. The 
benefits is that there is virtually no under-utilization of 
resources in the cluster, making the approach [5] energy 
efficient. However, Coupling Scheduler ignores job sizes and 
can therefore be inefficient when processing jobs with large 
map service times. This is due to the coupling nature of 
""sticky processor sharing"" [7], where a map task gradually 
gets the amount of reducers it needs, disregarding task 
completion time, potentially allowing huge tasks to complete 
before allocating resources to smaller tasks [7]. 
(2) Triple-Queue Scheduler and MR-predict: While [7] 
preemptively couples mappers and reducers regardless of 
task 
size, 
the 
authors 
behind 
the 
paper 
""A Dynamic 
MapReduce Scheduler for Heterogeneous Workloads"" [8] 
have devised a prediction method called MR-predict to 
detect workloads in real time. MR-predict focuses on 
optimizing the utilization and balance between I/O-bound vs 
CPU-bound applications, which is not a concern in legacy 
Hadoop MapReduce. Based on MR-Predict, which classifies 
a type of workload, they propose Triple-Queue Scheduler to 
176 
serve tasks based on the predicted workload. The standard 
First Come First Served strategy would not be able to handle 
scheduling different task types, as it has a single queue. With 
the Triple-Queue Scheduler the authors solve this issue by 
paralleling queues, and delivering I/O bound tasks to nodes 
with I/O resources to spare, while at the same time serving 
CPU bound tasks to fitting nodes. MR-predict checks the 
history of a job to predict the future tasks, and from there 
describe the workload type. If a new job is received with no 
previous history, the job is sent to a waiting queue within 
Triple-Queue Scheduler, where the scheduler will assign one 
map task of that job to every TaskTracker whenever it has 
idle slots. When the map tasks finish, MR-predict calculates 
the MTCT (Map Task Completed Time), MID (Map Input 
Data) and MOD (Map Output Data) based on the data 
gathered from these tasks. The type of workload then gets 
determined, and the job is moved into either an I/O-Bound 
queue, or a CPU-Bound queue. Furthermore, the scheduler 
monitors tasks assigned to queues, checking if MTCT 
increases. If MTCT increase passes the threshold of 140%, 
the scheduler determines that the task was assigned to the 
wrong queue, and moves the task to an alternative queue. 
The tests were run on a native Hadoop cluster, running 
TeraSort, GrepCount and WordCount. The authors observed 
a 20% increase in resource utilization and an impressive 30% 
increase in throughput. This is naturally only meant for 
heterogeneous workloads, as there would be little use to 
predict a homogeneous job flow. The algorithm is also 
exclusively useful in a homogeneous environment [8]. 
(3) Workload Characteristic and Resource Aware 
Scheduler: In this paper, the authors propose WCRA­
scheduling 
of 
Hadoop 
clusters 
[9]. 
WCRA-scheduling 
checks the CPU, RAM and I/O-load on the nodes fust. 
Afterwards, all the tasks are sorted based on Estimated 
Completion Time then scheduled on the most fitting nodes. 
The work bears some similarity to [8], but also embraces 
RAM as an important parameter, ensuring that more than 
25% of the primary memory is always available before 
scheduling a job. The authors argue that ""is critical in case of 
CPU and Disk I/O bound tasks"" [9]. It was found that 
""compute node works significantly if it has the available 
physical memory greater than 25%. Tasks are assigned to the 
node if the memory availability is greater than 25%"" [9]. 
WRCA-scheduling has the benefit of being specifically 
designed to handle heterogeneous clusters. In a similar 
manner to [8], WRCA works by fust completing a set of 
sample tasks for a new job in order to determine predicted 
type of workload, and then classifies the job as either CPU­
bound or I/O-bound. Compared to [8], more extensive testing 
with more jobs were reported, albeit on a smaller cluster 
environment, and actually reached the same amount of 
increase in throughput (30%) when compared to FIFO, Fair­
scheduler and Capacity scheduler. 
(4) Adaptive resource allocation schedulers: 
By 
defmition, an adaptive resource allocation scheduler adapts 
to the capabilities and performance of each node in the 
cluster individually. In [10], the authors argued that legacy 
resource-aware schedulers give nodes a fixed amount of 
resources for each job, 
potentially causing over/under-
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore.  Restrictions apply. 
 utilization of resources, in contrast to their devised scheduler 
[10] which dynamically adapts its resource allocation over 
the course of the job. Based on the estimated amount of tasks 
that can be processed concurrently on each node, the devised 
algorithm shrinks/extends the amount of resources over the 
run time. This algorithm is also designed to optimize a 
heterogeneous cluster as in [8]. Instead of predicting tasks 
and queueing the workloads, the authors propose a strategy 
where the worker nodes and their ""available/lack resources 
(CPU and memory) are monitored, and based on this, the 
scheduler will extend/shrink the capacity of the TaskTracker 
by increasing/decreasing the number of map/reduce slots of 
the TaskTracker"" 
[10]. The approach was tested using 
different benchmarks including TeraSort, PiEstimator and 
WordCound, in a similar manner to the main stream of 
papers in this category. According to the experimental 
fmdings, 
it 
was 
observed an 
average 
increase of 
the 
completion time of all tasks by around 30%. As in the case 
of [6], this approach also yields an increased effectiveness 
with reduced nodes/slots in the cluster, compared to native 
algorithms like FIFO and Fair-scheduler [10]. 
e. 
Job Size 
(1) Size-Based Scheduling: As was remarked in a series 
of papers such as in [7], ignoring the job size might halt 
throughput in cluster, although it is very resource-effective. 
Weighing job-size first should then logically considerably 
increase throughput in the cluster and is claimed to achieve 
""near-optimal system response times"" [11]. The hard part 
about designing an algorithm focused on size is that it has to 
prioritize jobs/tasks with the shortest remaining completion 
time to be effective. This can lead to bigger tasks starving to 
get resources. The authors introduce HFSP (Size-based 
Scheduling for Hadoop) [11], a scheduler that lets Hadoop 
determine job size during execution in real time. They claim 
that 
their 
approach 
""satisfies 
both 
the 
interactivity 
requirements of small jobs and the performance requirements 
of large jobs, which can thus coexist in a cluster without 
requiring manual setups and complex tuning"" [11]. To be 
able to schedule tasks with short completion times without 
forcing starvation of larger tasks, the author implement a 
common aging policy, where the cost of a task in the queue 
gets gradually decremented as it waits for resources. They 
call 
the 
technique 
""Shortest 
Remaining 
Virtual 
Time 
(SRVT)"" [11]. SRVT results in a slight increase in average 
throughput time, at the benefit of virtually eliminating errors 
and starvation in the queue. By applying a size-based 
scheduling 
algorithm, 
the 
authors 
also 
argue 
that 
the 
scheduler has significantly reduced overhead, as its only 
concern is the direct size of the job, and no additional 
calculations are necessary. As seen in [9] and [8], this 
scheduler determines size by running a small set of sample 
tasks from a job. The approach [11] is endowed with a 
preemptive estimation module that sets a coarse size value 
for the job before the samples are processed, which gets 
gradually refmed as samples are completed. The authors 
have measured the perfonnance of their approach in a 
benchmarking suite, and found a significant decrease in 
system response times. Contrary to 
[6] and [10], this 
177 
effectiveness disparity increased in larger jobs and larger 
clusters [12]. 
(2) LsPS (Leveraging size Patterns Scheduler): The 
work reported in [11] proposes an algorithm that specializes 
in handling bursty workloads in a multi-user environment, by 
tuning resource shares among users, and even the scheduling 
algorithm for each user, based on job size. The authors have 
tested their algorithm both in a controlled environment and 
in a production cluster: Amazon EC2, and observed reduced 
MapReduce job response times. The job tracker calculates 
how many slots and resources each user should have based 
on the history of task completion, and predicted completion 
time based on job size. Every time a task is finished, the 
statistics of that particular user are updated. Based on all this 
data, the Job Tracker continually sorts users instead of tasks, 
making sure to let the most efficient users get the most slots, 
without starving other users. This is done by granting a slot 
share ratio to the users that is inversely proportional to their 
job average sizes. In the case of new users entering the 
cluster 
have 
no 
history 
for 
determining 
average job 
size/completion time, predefined job profIles are added to the 
scheduler, and assigned to users based on a couple of user­
defmed criteria. The authors have chosen a FIFO-algorithm 
as a fallback, in case of tasks getting the same cost and 
confusing LsPS, making sure that the first task submitted 
simply is processed. The experimental results show huge 
promise in enterprise environments, with multiple users, 
heterogeneous clusters and heterogeneous workloads. For 
smaller clusters and predictable workloads however, the 
overhead cost might be too high [11]. 
D. Improving Native Hadoop 
(1) 
Fair 
and 
Efficient 
Slot 
Configuration 
and 
Scheduling: In many cases, enterprises just want to use 
Hadoop for parallel big data processing out-of-the-box, 
without much configuration by experts. This frequently leads 
to using native Hadoop schedulers which may be inefficient. 
The team behind FRESH (FaiR and Efficient Slot scheduling 
for Hadoop) [13] argue that Hadoop is far too complex to 
tweak 
for 
many 
users. 
They 
propose 
FRESH 
that 
dynamically configures slots and assign tasks to achieve 
optimal performance from a cluster. They introduce two 
different algorithms, one which statically assigns slots for 
each job submitted, and one that dynamically alters the 
amounts of slots for a job during run time. The static 
algorithm calculates optimal amounts of slots for each job, 
allocates slots for nodes, and then hands the jobs over to Fair 
Scheduler to server tasks to the nodes. The dynamic 
algorithm takes the whole process without help for Fair 
Scheduler, and acts as both back end slot allocator and task 
server for nodes, dynamically monitoring each node and 
making sure all tasks are processed with optimal fairness. 
The authors present their own novel definition of fairness, 
named 
overall 
fairness 
with 
an 
algorithm 
that 
more 
accurately disperses resources between jobs. The reported 
tests show a significant improvement, especially with the 
dynamic slot allocation, increasing makespan by up to 30% 
compared to Fair scheduler across all types of workloads 
[13]. 
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore.  Restrictions apply. 
 (2) Chronos: Instead of creating a totally new ""default"" 
scheduler from scratch, a different approach for enhancing 
the native Hadoop scheduler is proposed by the authors of 
Chronos: 
Failure-A ware 
Scheduling 
in 
Shared 
Hadoop 
Clusters [14]. The authors argue that the performance of 
Hadoop systems in part depends on how failures are handled. 
Hadoop handles failures by re-executing all the tasks of the 
failed machines. In this case, the machines need to wait for 
resources to execute recovery tasks. They argue that the fact 
that this is black-boxed from Hadoop schedulers (not visible 
or configurable for schedulers) may hinder the schedulers 
from optimizing the workflow according to the scheduling 
goal efficiently, and thus significantly reducing performance 
of the cluster. In order to counter this problem, the authors 
introduce Chronos, a failure-aware scheduling strategy that 
preemptively allocates resources to nodes with task failures, 
and also considers data locality for optimized performance. 
Chronos 
is 
an 
optional 
component 
independent 
from 
schedulers, and works together with the scheduler of a users 
choice (like native Hadoop - FIFO or Fair). Chronos works 
basically by listening to heartbeats from Hadoop. Upon a 
failure, Chronos queries the Job Tracker for the nodes that 
has task failures. Chronos then attempts to ""inject"" the 
recovery tasks into the front of the task queue, based on an 
algorithm working 
together with the scheduler goal to 
determine priorities of tasks. When it finds an appropriate 
slot, it then allocates resources away from less important 
tasks in the queue and on to the recovering node. The latter 
strategy allows the failed slots to preemptively be freed, 
instead of waiting in starvation for recovery resources. The 
authors tested Chronos in combination with FIFO and Fair­
scheduler and experienced a reduction in job completion 
times by up to an astonishing percentage of 55%. 
E. 
Hybrid Approach 
(1) Resource and Deadline-aware Job Scheduling: As 
aforementioned, there is a vast variety of interesting and 
effective scheduling algorithms with different prioritization, 
and different drawbacks. In general term, hybrid approaches 
aspire to combine one or more different approaches so that to 
distill the best of their combination [15]. In [15], the authors 
introduce a hybrid algorithm that takes both task deadlines 
and a predicted future resource availability into account 
when allocating tasks. To achieve this they apply a receding 
horizon control algorithm in combination with a self-learning 
model that learns to predict an estimate of future resource 
availability and job completion times. They do this by 
introducing control intervals in which actual resources and 
job sizes and predicted resources and job sizes are calculated, 
and 
based 
on 
this 
they 
optimize 
the 
schedule 
while 
evaluating 
deadlines. 
This 
is 
especially 
useful 
in 
an 
environment 
where 
resources 
are 
dynamic 
and 
heterogeneous, as resources can be added or taken away 
during run time, and the controls will catch the updates and 
optimize for it. Tested in a controlled environment against 
Fair Scheduler, the authors were able to reduce the penalty of 
deadline misses by 36%, and against Earliest Deadline First 
scheduler they show a reduced penalty of 10% [15]. 
178 
(2) Classification and Optimization based Scheduler: 
A truly hybrid solution is introduced in [16]. The authors 
analyze the performance of widely used schedulers like FIFO 
and Fair Share Scheduler, and an algorithm reckoned as 
COSHH (Classification and Optimization based Scheduler 
for 
Heterogeneous 
Hadoop) 
scheduler. 
Based 
on 
the 
performances of these algorithms, the paper introduces a 
hybrid solution where all three algorithms are used in the 
same cluster based on different system loads. ""When the 
system is underloaded, and the number of free slots is greater 
than the number of waiting tasks, the scheduler switches to 
the FIFO algorithm. Here, the simple FIFO algorithm can 
improve 
the 
average 
completion 
time 
with 
minimum 
scheduling overhead. However, as the system load increases 
such that the available number of slots is less than the 
number of waiting tasks, the hybrid scheduler selects the Fair 
Sharing algorithm. When the load increases such that the 
system is overloaded, and the number of waiting tasks in job 
queues is quickly increasing, the Fair Sharing algorithm can 
greatly increase the average completion time. Therefore, the 
scheduler switches to the COSHH algorithm which improves 
the average completion time, while avoiding considerable 
degradation 
in 
the 
fairness 
metric"" 
[16]. 
The 
hybrid 
scheduler chooses the best scheduling algorithm for different 
scales of jobs and resources to address average completion 
time and fairness [16]. The results of the experiments are 
thoroughly documented, showing that the approach works, in 
numerous cases cutting scheduling and completion-time by 
half [16]. 
III. 
CONCLUSION 
After reviewing a number of related works on Hadoop 
scheduling, the conclusion that stands out is the potential for 
improvement in the default Hadoop scheduling algorithms. 
Almost all the surveyed schedulers in this paper have 
advantages 
in 
terms 
of 
fairness 
and 
completion 
time 
compared 
to 
the 
default 
Hadoop 
scheduling 
policy. 
Interestingly, FRESH [13] and COSHH-hybrid [16] have the 
potential to become a native part of Hadoop, replacing FIFO 
and Fair sharing, as well as Chronos [14] which holds a lot 
of promise while still needing further testing. When it comes 
to large enterprise environments, LsPS [11] represents a 
promising 
approach 
as 
it 
delivered 
unprecedented 
performance and user control in a scalable and dynamic 
cluster, vastly improving upon default schedulers. 
REFERENCES 
[I] 
Bollier, D., & Firestone, C. M. (2010). The promise and peril of big 
data (p. 1). Washington, DC: Aspen Institute, Communications and 
Society Program. 
[2] 
Gantz, J., & Reinsel, D. (2012). The digital universe in 2020: Big 
data, bigger digital shadows, and biggest growth in the far east. 
IDC iView: IDC Analyze the future, 2007, 1-16, 
[3] 
Richards, N. M., & King, 1. H. (2013). Three paradoxes of big 
data. 
[4] 
Huang, G., He, J., Chi, C. H., Zhou, w., & Zhang, Y. (2015, 
June). A Data as a Product Model for Future Consumption of Big 
Stream Data in Clouds. In 2015 IEEE International Conference on 
Services Computing (SCC), (pp. 256-263). IEEE. 
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore.  Restrictions apply. 
 [5] 
Kc, K., & Anyanwu, K. (2010, November). Scheduling hadoop 
jobs to meet deadlines. In 2010 IEEE Second International 
Conference 
on 
Cloud 
Computing 
Technology 
and 
Science 
(CloudCom) (pp. 388-392). IEEE. 
[6] 
Perret, Q., Charlemagne, G., Sotiriadis, S., & Bessis, N. (2013, 
March). A deadline scheduler for jobs in distributed systems. In 2013 
27th International Conference on Advanced Information Networking 
and Applications Workshops (WAINA) (pp. 757-764). IEEE. 
[7] 
Tan, J., Meng, X., & Zhang, L. (2012, March). Performance 
analysis 
of 
coupling 
scheduler 
for 
mapreduce/hadoop. 
In 
INFOCOM, 2012 Proceedings IEEE (pp. 2586-2590). IEEE. 
[8] 
Tian, c., Zhou, H., He, Y., & Zha, L. (2009, August). A dynamic 
mapreduce scheduler for heterogeneous workloads. In 2009 Eighth 
International Conference on Grid and Cooperative Computing (pp. 
218-224). IEEE. 
[9] 
Divya, M., & Annappa, B. (2015, July). Workload characteristics 
and resource 
aware Hadoop scheduler. In 2015 IEEE 2nd 
International Conference on Recent Trends in Information Systems 
(ReTIS) (pp. 163-168). IEEE. 
[10] Elkholy, A. M., & Sail am, E. A. (2014, December). Self adaptive Hadoop 
scheduler 
for 
heterogeneous resources. 
In 2014 9th 
International 
Conference on Computer Engineering & Systems (lCCES) (pp. 427-432). 
IEEE 
179 
[II] Yao, Y., Tai, J., Sheng, B., & Mi, N. (2015). LsPS: A Job Size­
Based Scheduler for Efficient Task Assignments in Hadoop. IEEE 
Transactions on Cloud Computing, 3(4), 411-424. 
[12] Pastorelli, M., Barbuzzi, A., Carra, D., Dell' Amico, M., 
& 
Michiardi, P. (2013, October). HFSP: size-based scheduling for 
Hadoop. In 2013 IEEE International Conference on Big Data (pp. 
51-59). IEEE. 
[13] Wang, J., Yao, Y., Mao, Y., Sheng, B., & Mi, N. (2014, June). 
Fresh: Fair and efficient slot configuration and scheduling for 
hadoop clusters. In 2014 IEEE 7th International Conference on 
Cloud Computing (pp. 761-768). IEEE. ISO 690 
[14] Yildiz, 0., Ibrahim, S., Phuong, T. A., & Antoniu, G. (2015, 
October). Chronos: Failure-aware scheduling in shared hadoop 
clusters. In 2015 IEEE International Conference on Big Data (Big 
Data) (pp. 313-318). IEEE. 
[15] Cheng, D., Rao, J., Jiang, C., & Zhou, X. (2015, May). Resource 
and deadline-aware job scheduling in dynamic hadoop clusters. In 
2015 IEEE International Parallel and Distributed Processing 
Symposium (IPDPS) (pp. 956-965). IEEE. 
[16] Rasooli, A., & Down, D. G. (2012, November). A hybrid scheduling 
approach for scalable heterogeneous hadoop systems. In High 
Performance Computing, Networking, Storage and Analysis (SCC), 
2012 SC Companion: (pp. 1284-1291). IEEE. 
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore.  Restrictions apply. 
",10.1109/ICCCBDA.2017.7951906,doc31,"2017 the 2nd IEEE International Conference on Cloud Computing and Big Data Analysis Hadoop MapReduce Scheduling Paradigms Roger Johannessen, Anis Yazidi, Boning Feng Department of Computer Science Oslo and Akershus University College of Applied Sciences Oslo, Norway e-mail: anis.yazidi@hioa.no.boning.feng@hioa.no Abstract-Apache Hadoop is one of the most prominent and early technologies for handling big data. Different scheduling algorithms within the framework of Apache Hadoop were developed in the last decade. In this paper, we attempt to provide a comprehensive overview over the different paradigms for scheduling in Apache Hadoop. The surveyed approaches fall under different categories, namely, Deadline prioritization, Resource prioritization, Job size prioritization, Hybrid approaches and recent trends for improvements upon default schedulers. Keywords-Apache Hadoop; MapReduce; scheduling paradigms I. INTRODUCTION Bollier stated, ""Big websites can generate terabytes of raw log data every day. The sheer size of its data set has led to the emergence of new cloud infrastructures, characterized by the ability to scale to thousands of nodes, fault tolerance and relaxed consistency"" [1]. From 2005 to 2020, the digital universe is expected to grow dramatically by a factor of 300, from 130 exabytes to 40 trillion gigabytes, i.e. more than 5,200 gigabytes per person in 2020. Moreover, the digital universe is expected to double every two years [2]. A big part of the growth is a defining trait of our current technology landscape - the Internet of Things, quickly evolving into: ""The Internet of Everything"" [3]. The benefits of ""all interconnected"" devices is immense in tenns of potentially huge increase in quality of life. In the same time, it brings along the challenge of handling extreme amounts of data. Devices generate nowadays vast amounts logging data, but also functional data such as media streams that are key to the sole purpose of the device. Data is becoming the world's new natural resource [4]. The challenges represented by big data handling can be divided into three groups: • Velocity • Volume • Variety Hadoop possesses a sophisticated set of methods that handle the above challenges elegantly through the use of: • Hadoop Common (a set of utilities and libraries) • The file system called HDFS (Hadoop File System) • YARN (Yet Another Resource Negotiator) • MapReduce (a framework for distributing tasks and parallel processing) 978-1-5090-4499-3/17/$31.00 ©20 17 IEEE 175 II. RELATED WORK In this section, we will survey some promIsmg new scheduling algorithms, as well as some highly-cited and well established ones. We have categorized those scheduling algorithms by the type of the scheduling priority. A. Deadline Prioritization (1) Deadline Constraint Scheduler: Prioritizing deadline in a Hadoop clusters is done by predicting the completion time of jobs/tasks and then allocating them to nodes capable of processing them within a time limit where the data is actually useful. The research reported in [5] was motivated by the fact that FIFO, the default scheduling algorithm of Hadoop clusters, has some visible drawbacks due to its rigid prioritization scheme. The paper explores real time cluster scheduling based on user specified deadlines. The authors give a preliminary evaluation of their algorithm reckoned as Deadline Constraint Scheduler, which is a scheduler that simply ignores new tasks that cannot be processed within their deadline. This is achieved by calculating the deadline and comparing it to the execution time. The latter approach performs well in a homogeneous cluster, but is invalidated in a heterogeneous cluster where execution times might vary across nodes. In this case, the algorithm relaxes some of its parameters so that to allow processing times to be decoupled from the slowest node. However, this might lead to under-utilization of certain nodes in the cluster. The authors concede that they will address this issue in future work. To calculate schedulability, the work calculates the minimum amount of map tasks to get a job done, and compares it to the maximum amount of reduce tasks. If there is less available reduce slots than the maximum amount of possible reduce tasks in the job, the task is dropped. Experimental results show greater task efficiency during MapReduce phases [5]. (2) Cloud Least Laxity First: In another approach introduced in the paper entitled ""A Deadline Scheduler for Jobs in Distributed Systems"" [6], the authors propose an interesting deadline scheduler for Hadoop called Cloud Least Laxity First (CLLF), that orders tasks based on laxity (time left over to deadline, after task is [mished). They argue that by using this technique one can reduce the amount of nodes needed while maintaining total execution time at acceptable levels. This was proven by comparing the algorithm to Time Shared and Space Shared scheduling in a controlled environment. The devised scheduler handles soft deadlines Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore. Restrictions apply. by introducing a penalty tenn as a function of the lateness (lateness defmed as completion time minus deadline). The authors describe a system in which each worker node uses a FIFO-queue and notifies the master as soon as it has an idle processor. The master has the role of hosting the CLLF­ algorithm and allocating tasks. As the authors themselves describe it: ""The general idea of the algorithm is to sort the cloudlets by laxities (the fust has the lowest one). Giving this sorted list, the algorithm takes the fust element of this list and looks for a host that locally have the data of the cloudlet and which also have at least one free slot. If one matching host is found, the task is ran on it; otherwise, the algorithm restarts the same procedure using the second element of the list"" [6]. As in the case of the algorithm reported in [5] which falls in this category, this algorithm [6] is limited to homogeneous environments. In line with goal of reducing the amount of virtual nodes needed for job executions, the work [6] shows a considerable decrease in missed deadlines compared to Time Shared and Space Shared algorithms, thus, increasing the disparity in effectiveness of the latter two algorithms. B. Resource Prioritization (1) Coupling Scheduler: Algorithms delving into resource allocation and optimization of utilization of worker nodes are perhaps the most investigated topic within the field of MapReduce. As processing and handling of data is getting more and more centralized, virtualized Hadoop clusters seem to be the future of MapReduce and has emerged as enabler for business ventures through the cloud. In [7], it was argued that the widely used Fair Scheduler has a starvation problem involving the Map and Reduce operations. The paper focuses on coupling the two progresses, instead of treating them separately. The authors [7] also performed a performance comparison, proving that Coupling Scheduler performs better than Fair Scheduler in handling tasks with varying map service times. The main effect this has on resource usage is that reducers are gradually launched as more and more maps are completed, instead of allocating a quantity of reducers based on predicted need, i.e. as seen in [5]. The benefits is that there is virtually no under-utilization of resources in the cluster, making the approach [5] energy efficient. However, Coupling Scheduler ignores job sizes and can therefore be inefficient when processing jobs with large map service times. This is due to the coupling nature of ""sticky processor sharing"" [7], where a map task gradually gets the amount of reducers it needs, disregarding task completion time, potentially allowing huge tasks to complete before allocating resources to smaller tasks [7]. (2) Triple-Queue Scheduler and MR-predict: While [7] preemptively couples mappers and reducers regardless of task size, the authors behind the paper ""A Dynamic MapReduce Scheduler for Heterogeneous Workloads"" [8] have devised a prediction method called MR-predict to detect workloads in real time. MR-predict focuses on optimizing the utilization and balance between I/O-bound vs CPU-bound applications, which is not a concern in legacy Hadoop MapReduce. Based on MR-Predict, which classifies a type of workload, they propose Triple-Queue Scheduler to 176 serve tasks based on the predicted workload. The standard First Come First Served strategy would not be able to handle scheduling different task types, as it has a single queue. With the Triple-Queue Scheduler the authors solve this issue by paralleling queues, and delivering I/O bound tasks to nodes with I/O resources to spare, while at the same time serving CPU bound tasks to fitting nodes. MR-predict checks the history of a job to predict the future tasks, and from there describe the workload type. If a new job is received with no previous history, the job is sent to a waiting queue within Triple-Queue Scheduler, where the scheduler will assign one map task of that job to every TaskTracker whenever it has idle slots. When the map tasks finish, MR-predict calculates the MTCT (Map Task Completed Time), MID (Map Input Data) and MOD (Map Output Data) based on the data gathered from these tasks. The type of workload then gets determined, and the job is moved into either an I/O-Bound queue, or a CPU-Bound queue. Furthermore, the scheduler monitors tasks assigned to queues, checking if MTCT increases. If MTCT increase passes the threshold of 140%, the scheduler determines that the task was assigned to the wrong queue, and moves the task to an alternative queue. The tests were run on a native Hadoop cluster, running TeraSort, GrepCount and WordCount. The authors observed a 20% increase in resource utilization and an impressive 30% increase in throughput. This is naturally only meant for heterogeneous workloads, as there would be little use to predict a homogeneous job flow. The algorithm is also exclusively useful in a homogeneous environment [8]. (3) Workload Characteristic and Resource Aware Scheduler: In this paper, the authors propose WCRA­ scheduling of Hadoop clusters [9]. WCRA-scheduling checks the CPU, RAM and I/O-load on the nodes fust. Afterwards, all the tasks are sorted based on Estimated Completion Time then scheduled on the most fitting nodes. The work bears some similarity to [8], but also embraces RAM as an important parameter, ensuring that more than 25% of the primary memory is always available before scheduling a job. The authors argue that ""is critical in case of CPU and Disk I/O bound tasks"" [9]. It was found that ""compute node works significantly if it has the available physical memory greater than 25%. Tasks are assigned to the node if the memory availability is greater than 25%"" [9]. WRCA-scheduling has the benefit of being specifically designed to handle heterogeneous clusters. In a similar manner to [8], WRCA works by fust completing a set of sample tasks for a new job in order to determine predicted type of workload, and then classifies the job as either CPU­ bound or I/O-bound. Compared to [8], more extensive testing with more jobs were reported, albeit on a smaller cluster environment, and actually reached the same amount of increase in throughput (30%) when compared to FIFO, Fair­ scheduler and Capacity scheduler. (4) Adaptive resource allocation schedulers: By defmition, an adaptive resource allocation scheduler adapts to the capabilities and performance of each node in the cluster individually. In [10], the authors argued that legacy resource-aware schedulers give nodes a fixed amount of resources for each job, potentially causing over/under- Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore. Restrictions apply. utilization of resources, in contrast to their devised scheduler [10] which dynamically adapts its resource allocation over the course of the job. Based on the estimated amount of tasks that can be processed concurrently on each node, the devised algorithm shrinks/extends the amount of resources over the run time. This algorithm is also designed to optimize a heterogeneous cluster as in [8]. Instead of predicting tasks and queueing the workloads, the authors propose a strategy where the worker nodes and their ""available/lack resources (CPU and memory) are monitored, and based on this, the scheduler will extend/shrink the capacity of the TaskTracker by increasing/decreasing the number of map/reduce slots of the TaskTracker"" [10]. The approach was tested using different benchmarks including TeraSort, PiEstimator and WordCound, in a similar manner to the main stream of papers in this category. According to the experimental fmdings, it was observed an average increase of the completion time of all tasks by around 30%. As in the case of [6], this approach also yields an increased effectiveness with reduced nodes/slots in the cluster, compared to native algorithms like FIFO and Fair-scheduler [10]. e. Job Size (1) Size-Based Scheduling: As was remarked in a series of papers such as in [7], ignoring the job size might halt throughput in cluster, although it is very resource-effective. Weighing job-size first should then logically considerably increase throughput in the cluster and is claimed to achieve ""near-optimal system response times"" [11]. The hard part about designing an algorithm focused on size is that it has to prioritize jobs/tasks with the shortest remaining completion time to be effective. This can lead to bigger tasks starving to get resources. The authors introduce HFSP (Size-based Scheduling for Hadoop) [11], a scheduler that lets Hadoop determine job size during execution in real time. They claim that their approach ""satisfies both the interactivity requirements of small jobs and the performance requirements of large jobs, which can thus coexist in a cluster without requiring manual setups and complex tuning"" [11]. To be able to schedule tasks with short completion times without forcing starvation of larger tasks, the author implement a common aging policy, where the cost of a task in the queue gets gradually decremented as it waits for resources. They call the technique ""Shortest Remaining Virtual Time (SRVT)"" [11]. SRVT results in a slight increase in average throughput time, at the benefit of virtually eliminating errors and starvation in the queue. By applying a size-based scheduling algorithm, the authors also argue that the scheduler has significantly reduced overhead, as its only concern is the direct size of the job, and no additional calculations are necessary. As seen in [9] and [8], this scheduler determines size by running a small set of sample tasks from a job. The approach [11] is endowed with a preemptive estimation module that sets a coarse size value for the job before the samples are processed, which gets gradually refmed as samples are completed. The authors have measured the perfonnance of their approach in a benchmarking suite, and found a significant decrease in system response times. Contrary to [6] and [10], this 177 effectiveness disparity increased in larger jobs and larger clusters [12]. (2) LsPS (Leveraging size Patterns Scheduler): The work reported in [11] proposes an algorithm that specializes in handling bursty workloads in a multi-user environment, by tuning resource shares among users, and even the scheduling algorithm for each user, based on job size. The authors have tested their algorithm both in a controlled environment and in a production cluster: Amazon EC2, and observed reduced MapReduce job response times. The job tracker calculates how many slots and resources each user should have based on the history of task completion, and predicted completion time based on job size. Every time a task is finished, the statistics of that particular user are updated. Based on all this data, the Job Tracker continually sorts users instead of tasks, making sure to let the most efficient users get the most slots, without starving other users. This is done by granting a slot share ratio to the users that is inversely proportional to their job average sizes. In the case of new users entering the cluster have no history for determining average job size/completion time, predefined job profIles are added to the scheduler, and assigned to users based on a couple of user­ defmed criteria. The authors have chosen a FIFO-algorithm as a fallback, in case of tasks getting the same cost and confusing LsPS, making sure that the first task submitted simply is processed. The experimental results show huge promise in enterprise environments, with multiple users, heterogeneous clusters and heterogeneous workloads. For smaller clusters and predictable workloads however, the overhead cost might be too high [11]. D. Improving Native Hadoop (1) Fair and Efficient Slot Configuration and Scheduling: In many cases, enterprises just want to use Hadoop for parallel big data processing out-of-the-box, without much configuration by experts. This frequently leads to using native Hadoop schedulers which may be inefficient. The team behind FRESH (FaiR and Efficient Slot scheduling for Hadoop) [13] argue that Hadoop is far too complex to tweak for many users. They propose FRESH that dynamically configures slots and assign tasks to achieve optimal performance from a cluster. They introduce two different algorithms, one which statically assigns slots for each job submitted, and one that dynamically alters the amounts of slots for a job during run time. The static algorithm calculates optimal amounts of slots for each job, allocates slots for nodes, and then hands the jobs over to Fair Scheduler to server tasks to the nodes. The dynamic algorithm takes the whole process without help for Fair Scheduler, and acts as both back end slot allocator and task server for nodes, dynamically monitoring each node and making sure all tasks are processed with optimal fairness. The authors present their own novel definition of fairness, named overall fairness with an algorithm that more accurately disperses resources between jobs. The reported tests show a significant improvement, especially with the dynamic slot allocation, increasing makespan by up to 30% compared to Fair scheduler across all types of workloads [13]. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore. Restrictions apply. (2) Chronos: Instead of creating a totally new ""default"" scheduler from scratch, a different approach for enhancing the native Hadoop scheduler is proposed by the authors of Chronos: Failure-A ware Scheduling in Shared Hadoop Clusters [14]. The authors argue that the performance of Hadoop systems in part depends on how failures are handled. Hadoop handles failures by re-executing all the tasks of the failed machines. In this case, the machines need to wait for resources to execute recovery tasks. They argue that the fact that this is black-boxed from Hadoop schedulers (not visible or configurable for schedulers) may hinder the schedulers from optimizing the workflow according to the scheduling goal efficiently, and thus significantly reducing performance of the cluster. In order to counter this problem, the authors introduce Chronos, a failure-aware scheduling strategy that preemptively allocates resources to nodes with task failures, and also considers data locality for optimized performance. Chronos is an optional component independent from schedulers, and works together with the scheduler of a users choice (like native Hadoop - FIFO or Fair). Chronos works basically by listening to heartbeats from Hadoop. Upon a failure, Chronos queries the Job Tracker for the nodes that has task failures. Chronos then attempts to ""inject"" the recovery tasks into the front of the task queue, based on an algorithm working together with the scheduler goal to determine priorities of tasks. When it finds an appropriate slot, it then allocates resources away from less important tasks in the queue and on to the recovering node. The latter strategy allows the failed slots to preemptively be freed, instead of waiting in starvation for recovery resources. The authors tested Chronos in combination with FIFO and Fair­ scheduler and experienced a reduction in job completion times by up to an astonishing percentage of 55%. E. Hybrid Approach (1) Resource and Deadline-aware Job Scheduling: As aforementioned, there is a vast variety of interesting and effective scheduling algorithms with different prioritization, and different drawbacks. In general term, hybrid approaches aspire to combine one or more different approaches so that to distill the best of their combination [15]. In [15], the authors introduce a hybrid algorithm that takes both task deadlines and a predicted future resource availability into account when allocating tasks. To achieve this they apply a receding horizon control algorithm in combination with a self-learning model that learns to predict an estimate of future resource availability and job completion times. They do this by introducing control intervals in which actual resources and job sizes and predicted resources and job sizes are calculated, and based on this they optimize the schedule while evaluating deadlines. This is especially useful in an environment where resources are dynamic and heterogeneous, as resources can be added or taken away during run time, and the controls will catch the updates and optimize for it. Tested in a controlled environment against Fair Scheduler, the authors were able to reduce the penalty of deadline misses by 36%, and against Earliest Deadline First scheduler they show a reduced penalty of 10% [15]. 178 (2) Classification and Optimization based Scheduler: A truly hybrid solution is introduced in [16]. The authors analyze the performance of widely used schedulers like FIFO and Fair Share Scheduler, and an algorithm reckoned as COSHH (Classification and Optimization based Scheduler for Heterogeneous Hadoop) scheduler. Based on the performances of these algorithms, the paper introduces a hybrid solution where all three algorithms are used in the same cluster based on different system loads. ""When the system is underloaded, and the number of free slots is greater than the number of waiting tasks, the scheduler switches to the FIFO algorithm. Here, the simple FIFO algorithm can improve the average completion time with minimum scheduling overhead. However, as the system load increases such that the available number of slots is less than the number of waiting tasks, the hybrid scheduler selects the Fair Sharing algorithm. When the load increases such that the system is overloaded, and the number of waiting tasks in job queues is quickly increasing, the Fair Sharing algorithm can greatly increase the average completion time. Therefore, the scheduler switches to the COSHH algorithm which improves the average completion time, while avoiding considerable degradation in the fairness metric"" [16]. The hybrid scheduler chooses the best scheduling algorithm for different scales of jobs and resources to address average completion time and fairness [16]. The results of the experiments are thoroughly documented, showing that the approach works, in numerous cases cutting scheduling and completion-time by half [16]. III. CONCLUSION After reviewing a number of related works on Hadoop scheduling, the conclusion that stands out is the potential for improvement in the default Hadoop scheduling algorithms. Almost all the surveyed schedulers in this paper have advantages in terms of fairness and completion time compared to the default Hadoop scheduling policy. Interestingly, FRESH [13] and COSHH-hybrid [16] have the potential to become a native part of Hadoop, replacing FIFO and Fair sharing, as well as Chronos [14] which holds a lot of promise while still needing further testing. When it comes to large enterprise environments, LsPS [11] represents a promising approach as it delivered unprecedented performance and user control in a scalable and dynamic cluster, vastly improving upon default schedulers. REFERENCES [I] Bollier, D., & Firestone, C. M. (2010). The promise and peril of big data (p. 1). Washington, DC: Aspen Institute, Communications and Society Program. [2] Gantz, J., & Reinsel, D. (2012). The digital universe in 2020: Big data, bigger digital shadows, and biggest growth in the far east. IDC iView: IDC Analyze the future, 2007, 1-16, [3] Richards, N. M., & King, 1. H. (2013). Three paradoxes of big data. [4] Huang, G., He, J., Chi, C. H., Zhou, w., & Zhang, Y. (2015, June). A Data as a Product Model for Future Consumption of Big Stream Data in Clouds. In 2015 IEEE International Conference on Services Computing (SCC), (pp. 256-263). IEEE. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore. Restrictions apply. [5] Kc, K., & Anyanwu, K. (2010, November). Scheduling hadoop jobs to meet deadlines. In 2010 IEEE Second International Conference on Cloud Computing Technology and Science (CloudCom) (pp. 388-392). IEEE. [6] Perret, Q., Charlemagne, G., Sotiriadis, S., & Bessis, N. (2013, March). A deadline scheduler for jobs in distributed systems. In 2013 27th International Conference on Advanced Information Networking and Applications Workshops (WAINA) (pp. 757-764). IEEE. [7] Tan, J., Meng, X., & Zhang, L. (2012, March). Performance analysis of coupling scheduler for mapreduce/hadoop. In INFOCOM, 2012 Proceedings IEEE (pp. 2586-2590). IEEE. [8] Tian, c., Zhou, H., He, Y., & Zha, L. (2009, August). A dynamic mapreduce scheduler for heterogeneous workloads. In 2009 Eighth International Conference on Grid and Cooperative Computing (pp. 218-224). IEEE. [9] Divya, M., & Annappa, B. (2015, July). Workload characteristics and resource aware Hadoop scheduler. In 2015 IEEE 2nd International Conference on Recent Trends in Information Systems (ReTIS) (pp. 163-168). IEEE. [10] Elkholy, A. M., & Sail am, E. A. (2014, December). Self adaptive Hadoop scheduler for heterogeneous resources. In 2014 9th International Conference on Computer Engineering & Systems (lCCES) (pp. 427-432). IEEE 179 [II] Yao, Y., Tai, J., Sheng, B., & Mi, N. (2015). LsPS: A Job Size­ Based Scheduler for Efficient Task Assignments in Hadoop. IEEE Transactions on Cloud Computing, 3(4), 411-424. [12] Pastorelli, M., Barbuzzi, A., Carra, D., Dell' Amico, M., & Michiardi, P. (2013, October). HFSP: size-based scheduling for Hadoop. In 2013 IEEE International Conference on Big Data (pp. 51-59). IEEE. [13] Wang, J., Yao, Y., Mao, Y., Sheng, B., & Mi, N. (2014, June). Fresh: Fair and efficient slot configuration and scheduling for hadoop clusters. In 2014 IEEE 7th International Conference on Cloud Computing (pp. 761-768). IEEE. ISO 690 [14] Yildiz, 0., Ibrahim, S., Phuong, T. A., & Antoniu, G. (2015, October). Chronos: Failure-aware scheduling in shared hadoop clusters. In 2015 IEEE International Conference on Big Data (Big Data) (pp. 313-318). IEEE. [15] Cheng, D., Rao, J., Jiang, C., & Zhou, X. (2015, May). Resource and deadline-aware job scheduling in dynamic hadoop clusters. In 2015 IEEE International Parallel and Distributed Processing Symposium (IPDPS) (pp. 956-965). IEEE. [16] Rasooli, A., & Down, D. G. (2012, November). A hybrid scheduling approach for scalable heterogeneous hadoop systems. In High Performance Computing, Networking, Storage and Analysis (SCC), 2012 SC Companion: (pp. 1284-1291). IEEE. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore. Restrictions apply."
Modern AI versus century-old mathematical models: How far can we go with generative adversarial networks to reproduce stochastic processes?,Pedro Lencastre and Marit Gjersdal and Leonardo Rydin Gorjão and Anis Yazidi and Pedro G. Lind,2023,,453,Physica D: Nonlinear Phenomena,article,"Physica D 453 (2023) 133831
Contents lists available at ScienceDirect
Physica D
journal homepage: www.elsevier.com/locate/physd
Modern AI versus century-old mathematical models: How far can we
go with generative adversarial networks to reproduce stochastic
processes?
Pedro Lencastre a,b,c, Marit Gjersdal a, Leonardo Rydin Gorjão d, Anis Yazidi a,b,c,
Pedro G. Lind a,b,c,∗
a Department of Computer Science, OsloMet – Oslo Metropolitan University, P.O. Box 4 St. Olavs plass, N-0130, Oslo, Norway
b OsloMet Artificial Intelligence lab, OsloMet, Pilestredet 52, N-0166, Oslo, Norway
c NordSTAR - Nordic Center for Sustainable and Trustworthy AI Research, Pilestredet 52, N-0166, Oslo, Norway
d Faculty of Science and Technology, Norwegian University of Life Sciences, 1432, Ås, Norway
a r t i c l e
i n f o
Article history:
Received 5 December 2022
Received in revised form 26 April 2023
Accepted 21 June 2023
Available online 28 June 2023
Communicated by R. Kuske
Keywords:
Generative Adversarial Networks
GANs
Markov models
Time-series prediction
Eye-tracking data
a b s t r a c t
The usage of generative adversarial networks (GAN)s for synthetic time-series data generation has
been gaining popularity in recent years with applications from finance to music composition and
processing of textual content. However, beyond their reported success, few comparisons exist with
other artificial intelligence (AI) methods or standard mathematical models. Here, we test GANs
performance, comparing them with a well-known mathematical model, namely a Markov chain. We
implement comparative metrics based on one- and two-point statistics to evaluate the performance of
each method. We find that, similarly to other AI approaches, GANs struggle to capture rare events and
cross-feature relations and are unable to create synthetic faithful data. GANs are relatively successful in
replicating the auto-correlation function, but they still lag significantly behind simple Markov chains.
We also provide a qualitative explanation for this limitation of AI approaches.
© 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license
(http://creativecommons.org/licenses/by/4.0/).
1. Introduction
With the improvements in computation capabilities and the
increasing accessibility of large amounts of data, non-parametric
models of time-series have become increasingly popular. It is
easy to understand why that is the case: non-parametric models
have an almost universal application without the laborious task
of understanding and reducing the problem to a core of funda-
mental quantities to describe a system, often with inaccurate but
necessary simplifications.
In this context, artificial neural networks (ANNs) based al-
gorithms are used, e.g. to predict wind speeds [1], wind power
output [2], air quality [3], the evolution of the price financial
assets [4], the rate of infections during a pandemic outbreak [5]
or the number of patients arriving at a hospital’s emergency
services [6].
While it is obvious that being able to predict the future of
statistical quantities is useful, these methods can further be used
in data augmentation when the original data is insufficient, or,
∗Corresponding author at: Department of Computer Science, OsloMet – Oslo
Metropolitan University, P.O. Box 4 St. Olavs plass, N-0130, Oslo, Norway.
E-mail address:
pedro.lind@oslomet.no (P.G. Lind).
e.g. in the medical domain, to produce anonymised data that can
be shared without strict ethical constraints.
Among these methods, one of the most popular is generative
adversarial networks (GANs) [7], which, after their success in
faithfully creating realistic images, have recently become popular
in time-series replication [8]. GANs consider two ‘‘coupled’’ ANNs
playing a zero-sum game. The first ANN is called ‘‘generator’’
and creates synthetic data with the objective to ‘‘fool’’ the sec-
ond ANN. This latter ANN is called ‘‘discriminator’’ and tries to
distinguish if a particular set of data is synthetic or not.
GANs have been applied to biomedical signal data, where
they have been used to model the time-evolution of data from
electrocardiogram, electroencephalogram, electromyography and
photoplethysmography [9]. GANs have also been used in natu-
ral language processing [10], generating music [11,12], predict-
ing pedestrian trajectory [13] and in predicting the evolution
of financial assets [14]. In the realm of biomedical signal data,
one type of time-series with several potential applications is
eye-tracking data, which can be used to determine personality
traits [15], drug consumption habits [16,17], as well as diagnosing
attention-deficit hyperactivity disorder [18,19] and autism [20].
In this paper, we will test the performance of GANs in re-
producing stochastic trajectories and compare them with some
https://doi.org/10.1016/j.physd.2023.133831
0167-2789/© 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
 P. Lencastre, M. Gjersdal, L.R. Gorjão et al.
Physica D 453 (2023) 133831
Fig. 1. Representation of a GAN: the generator tries to create data as faithfully
as possible, while the discriminator attempts at distinguishing real data from
that produced by the generator.
benchmarks from stochastic modelling. Eye-tracking data are par-
ticularly appropriate to evaluate GANs’ performance for two rea-
sons. Firstly, eye-tracking data reflect a broad panoply of foot-
prints flagging particular health states and features of human
behaviour. Secondly, they have very large kurtosis, i.e. they are
prone to extreme events, typically due to fast gaze relocations
in-between two areas of interest. These extreme events lead
to heavy-tailed distribution and ANN-based methods have been
shown to struggle to capture these distributions’ tails.
Thus, within the family of non-parametric models, we com-
pare GANs’ performance with that of Markov models, which are
a benchmark to describe stochastic time series [21]. Similarly
to AI methods, Markov models can be used to replicate a given
set of data without the knowledge of the underlying process.
When compared to its AI counterparts, Markov models have some
advantages: they can provide a unique time-continuous descrip-
tion of the system, or, alternatively, assert that a given process
is not time-homogeneous (stationary) or time-continuous [22].
Furthermore, in a Markov model each parameter of the model has
a straightforward meaning and thus an inspection of the model
can give us information about the system, something that does
not generally happen for ANN-based methods.
We start in Section 2 by describing the technical details in
the implementation of different GAN architecture and Markov
chains. In Section 3 we describe the data that will be used to
test GANs and Markov models. Besides eye-tracking data we
will consider synthetic data. Section 4 focuses on comparing the
results obtained when using GANs and Markov chains for both
synthetic and empirical data and finally, Section 5 concludes the
manuscript.
2. Algorithms and methods
2.1. GANs architectures
GANs are a subset of AI algorithms following the structure
represented in Fig. 1. The generator is initialised with a random
noise vector z0 as input from which a time-series is generated.
This time-series is then analysed by the discriminator, which will
get either real data x or data generated by the generator, z, and
will try to distinguish between both.
These two networks are trained together in a min–max game
fashion [23]. The discriminator is trained to maximise its cor-
rect labelling of the input as real or fake, while the generator
Table 1
The generator and the discriminator used in each of the GAN architectures
addressed in this paper, cf. Fig. 1.
GAN
Generator
Discriminator
RCGAN
LSTM
LSTM
TimeGAN
bidirect. LSTM
bidirect. LSTM
SigCWGAN
AR-FNN
C-Sig-W1
RCWGAN
AR-FNN
AR-FNN
tries to minimise it and tries to ‘‘fool’’ the discriminator. Ideally,
this simultaneous adversarial training will eventually lead to the
generator learning to create outputs that mimic the statistical
properties of the original data: as the discriminator gets more
accurate so must the generator in order to fool it.
Mathematically, a GAN implementation considers the follow-
ing objective function
L(G(z), D(x)) = Ex∼ρx [log D(x)]
+ Ez∼ρZ [log (1 −D(G(z)))] ,
(1)
where D(x) ∈[0, 1] is the discriminator-assigned probability of
x being a real data point. Thus, Ex∼ρx [log D(x)] is the expected
fraction of correct guesses by the discriminator about real data
series x, among all trials in which the discriminator is evaluating
real data. In this context, G is the function characterising the
generator which maps an input noise series z into a series G(z).
See Fig. 1. Therefore, 1 −D(G(z)) represents the probability the
discriminator assigns of G(z) correctly being labelled as generated
data. The probability distributions of the real data series x, of the
input noise z and of the generated series G(z) are represented as
ρx, ρz and ρG, respectively.
The task of the generator is to bring the probability distribu-
tion ρG of the generated series G(z) as close as possible to the
distribution ρx of real data series x, such that both terms on the
right-hand side are decreased. Simultaneously, the discriminator
will try to maximise both expected values, one by maximising
D(x), and the other by minimising D(G(z)). Therefore, having
defined the objective function in Eq. (1), the optimisation scheme
which trains the GAN model solves the min–max problem
min
G
max
D
L(G(z), D(x)) .
(2)
Within the general GAN framework, several architectures are
possible with different types of ANNs as generators and dis-
criminators. In this paper, we consider a selection of different
architectures, indicated in Table 1 together with the specific types
of generators and discriminators. Details on how to train GAN
architectures are given in Appendix B.
2.1.1. Recurrent conditional GAN
Recurrent conditional GAN (RCGAN) was one of the first time-
series GAN models introduced [24], as a model for replicating
multi-valued time-series of medical data, namely the evolution
of the health state of patients in emergency care, with the moti-
vation to both predict the patient outcomes and generate faithful
synthetic data unconstrained from privacy concerns.
As the name suggests, it uses recurrent neural networks for
the generator and discriminator with Long Short-Term Memory
(LSTM) cells [25].
2.1.2. TimeGAN
TimeGAN was introduced in 2019 with the aim to outperform
several state-of-the-art GANs [26], presenting concrete examples
from stock market and energy consumption data. TimeGAN com-
bines a classical GAN architecture with an autoencoder a type of
ANN composed of two networks, one that ‘‘encodes’’ a series into
2
 P. Lencastre, M. Gjersdal, L.R. Gorjão et al.
Physica D 453 (2023) 133831
symbols and another one that ‘‘decodes’’ the symbols back into
a series [27]. TimeGAN consists of four networks. In the classical
GAN part of the algorithm, a recurrent neural network (RNN) is
used as a generator and a bidirectional LSTM as a discriminator.
Instead of giving the discriminator the original real data as input
to classify it as real or fake, it is given the encoded vector of the
real data, after being processed by an autoencoder.
TimeGAN uses three loss functions to control the training:
Reconstruction loss; supervised loss; and unsupervised loss. The
reconstruction loss is calculated using the output of the decoder
and is used to calculate the gradients for the encoder and the
decoder. The unsupervised loss is based on the discriminator’s
output and, similarly to the min–max loss function of the original
GAN Eq. (1), is used for calculating the generator and discrimina-
tors gradients. Finally, the supervised loss is calculated based on
both the generator’s output and the encoder’s output of the real
data, and is used for calculating the gradients of the generator and
the encoder. Some authors implement TimeGAN with the GAN
part only without the autoencoder part of the algorithm [28]. We
here follow that implementation.
2.1.3. SigCWGAN and RCWGAN
The Conditional Sign-Wasserstein GAN (SigCWGAN) was de-
signed with the purpose to capture temporal dependencies in
multi-dimensional time-series data while being able to correctly
model the tail of its underlying distribution [28]. To capture
this, a new metric is introduced, namely the so-called Signature
Wasserstein-1 (C-Sig-W1), which serves as the discriminator of
the GAN. The usage of this metric is supposed to be not only
more robust but also computationally less expensive to train
than a typical ANN. For further mathematical details about the
discriminator the interested reader should consult Ref. [28].
In this architecture, the authors introduce as a generator a
three-layer feed-forward neural network residual connections
and parametric ReLUs as activation functions, which determines
if the output of a neuron activates the next neuron or not.
The authors call this ANN, Autoregressive Feed-Forward Neural
Network (AR-FNN). The generator has the main aim to capture
auto-regressive processes and thus be able to capture the time-
dependency of the process. More details can be found in the
appendix of the original paper [28].
The authors of SigCWGAN also implemented a GAN where
both the generator and discriminator are RNNs with the afore-
mentioned AR-FNN cells. This architecture is called Recurrent
Conditional Wasserstein GAN (RCWGAN). In this paper, we will
consider this architecture.
The original author’s pytorch implementation of the all previ-
ously mentioned GAN algorithms can be found in Github [29].
2.2. Markov-chain models for reproducing time-series
Markov models were introduced in 1906 [30] with the general
aim to model conditional probabilities and thus being able to
provide a description of the time-evolution of a stochastic pro-
cess. They were implemented firstly in an effort to estimate the
probability of finding a vowel in a text, based on the knowledge
of the previous letter [21].
By definition, a time-series Xt is said to follow a Markov
process if it fulfils the Markov property:
Pr(Xt=j = ˆxj | Xt=j−1 = ˆxj−1, . . . , Xt=0 = ˆx0) =
Pr(Xt=j = ˆxj | Xt=j−1 = ˆxj−1) ,
(3)
for all positive integers j, where capital letters mean stochastic
variables at different time steps and lowercase letters are the re-
spective values of those variables. Successive values are measured
at constant time intervals ∆t.
The Markov condition implies that, at all times, any prediction
on the future of time series Xt depends only on the current state
of the system and not on past states. For that reason, Markov pro-
cesses are often said to be ‘‘memoryless’’. The Markov property is
a simplification that, in the strict sense, does not apply to most
natural systems, but it is very convenient because by computing
the conditional probability Pr(Xt=j = ˆxj | Xt=j−1 = ˆxj−1) we
can describe the full time-evolution of the system, i.e. two-point
statistics contains all the information about the process. More
details on how to generate a Markov process in this way are given
in Appendix C.
3. Data and evaluation metrics
3.1. Synthetic data
The first set of data analysed in this paper is a synthetically
generated Vector Auto-Regressive (VAR) process. In one dimen-
sion, a VAR(p) process assumes that the observable at the present
time t is defined from its values in the previous p observations
apart a small random noise. In our case, the observable is the
velocity of the eye-gaze, which means that we consider spa-
tial increments of the positions in both x and y direction. For
increments (∆X) the VAR (p) model reads
∆Xt =
p
∑
n=1
φn∆Xt−n + ξt(σ) ,
(4)
where ξ is normally distributed random number with zero mean
and σ standard deviation. Consequently, in a VAR(p) process,
apart from Gaussian fluctuations, the future increments are de-
fined through a linear combination of the last p increments.
Again, the time labelling is done indicating the number of ele-
mentary constant time intervals ∆t. Here we take ∆t = 1 and
generate around 85 thousand points (the same number as the
empirical eye-tracking dataset we use), given the initial condition
∆X0 = 0
In what follows, we consider a VAR(1) process, meaning that
future increments are determined by a random number and the
increment immediately preceding it. We consider, however, a
VAR(1) process on a two-dimensional plane (X and Y), with some
correlation between ∆X and ∆Y, given by σXY . Our process is thus
defined by the system of equations
∆Xt = φX∆Xt−1 + ξ
(X)
t
(σX, σXY ) ,
∆Yt = φY∆Yt−1 + ξ
(Y)
t
(σY, σYX) ,
(5)
where ξ
(X)
t
(σX, σXY ) represents the stochastic fluctuations in the
X-dimension, with zero mean, standard deviation σX and a cor-
relation σXY with the stochastic fluctuations in the Y-dimension.
We will consider a process purely isotropic, i.e. σX = σY ≡σ and
φX = φY ≡φ.
The VAR(1) process is one of the most simple synthetic time-
series that are correlated in time. It is, by construction, a Markov
process, allowing us to test the accuracy of our implemented
model, and, for φ
>
0, it is suitable to test the commonly
mentioned limitation of NN and GAN algorithms in modelling the
tails of a distribution. In Fig. 2 (top) a two-dimensional VAR(1)
process is represented, with σ = 1, φ = 0.8 and σXY = 0.8, with
an inset showing the respective scatter plot of the increments in
both X- and Y-directions. From this inset, we observe that indeed
∆X and ∆Y are positively correlated, with a clear propensity of
the values to lay on the main diagonal. Furthermore, we observe
that values on the extremes of ∆X (corr. ∆Y) tend to follow also
extreme values of ∆X (corr. ∆Y), thus illustrating the positive
auto-correlation of both coordinates (φ = 0.8). In this paper we
will use three types of VAR processes, namely with the values of
p = 1, 2 and 3.
3
 P. Lencastre, M. Gjersdal, L.R. Gorjão et al.
Physica D 453 (2023) 133831
Fig. 2. Top: Representation of a trajectory of two dimensional VAR(1) process
(left) and its corresponding increments (right). This time-series was synthetically
generated with positive auto-correlation φ = 0.8 and positive feature correlation
σXY = 0.8. Thus, values are distributed mainly on the diagonal corresponding to
the first and third quadrants. Bottom: Representation of a gaze trajectory (left)
and its corresponding increments (right). This series was empirically estimated
with a modern eye-tracker. Typically, gaze positions are concentrated on a
limited area which is alternated with fast relocation trajectories.
3.2. Eye-tracking data
The eye-tracking data was collected at Oslo Metropolitan Uni-
versity with the Eye-link Duo, a state-of-the-art equipment with a
maximum frequency of 2000 Hz and a precision of 0.1 degrees of
visual angle. Here we have downsampled our data to a frequency
of 200 Hz and blinks have been removed, yielding around 85
thousand data-points. Units of X and Y are presented in pixels
of the viewing screen and eye-tracking data was extracted while
the participant was engaged in trying to find pre-selected targets.
For this purpose, images from the book Where’s Wally? were
used. Eight pictures were used, each one for two minutes. It is
very unlikely that two minutes are enough to find all the pre-
selected targets in a large image and the experiment was set up
this way to make sure that a participant is kept engaged through-
out the experiment. The data was collected following all ethical
requirements approved by the Norwegian Center for Research
Data (Norsk senter for forskningsdata), with the application with
Reference Number 176347.
In Fig. 2 (bottom) we see an illustration of a gaze trajectory,
with, in the inset, its corresponding increments. As described in
the literature, we observe periods where the eyes are fixated
around a point (called fixations) and periods of relocations (called
saccades). Indeed we observe some extreme velocity events and
the velocity time-series presents an excess kurtosis of κ ∼50.
The presence of extreme events is a welcomed feature of gaze
trajectories that makes them particularly suitable to study the
performance of ANN based methods. It has been widely reported
that ANN-based methods struggle to capture extreme events [2]
with some models analysed here explicitly stating their ability
to overcome this limitation in replicating the tails of a distri-
bution [28]. Real data used to assess ANN performance has a
considerably small kurtosis, 5 < κ < 15, and thus includes
Fig. 3. Illustration of some of the relevant quantities to describe gaze tra-
jectories, namely gaze velocity, gaze direction (θ) and the angle between
two consecutive gaze relocations (ϕ). Here, the two steps ⃗r1 and ⃗r2 occurred
within constant time-lags ∆t. Consequently, the velocity magnitude is given by,
e.g. ∥⃗v1∥= ∥⃗r1∥/∆t.
much less extreme events. There are two important examples of
non-Markov behaviour. One is the so-called inhibition of return
(IoR) [31], a known mechanism by which, for some time, the
human gaze avoids visiting the same area after it has recently
left it. The other is screen confinement, by which eye-tracker
gaze trajectories are restricted to a screen area, and which intro-
duces non-trivial long-range dependencies on the series of gaze
velocities.
Three quantities are important to describe gaze trajectories:
the velocity magnitude, ∥v∥, the angle, θ, of a given velocity with
the horizontal axis, and the angle, ϕ, between two consecutive
measurements. All three quantities are illustrated in Fig. 3. In
what follows we will access the performance of a model by
its ability to replicate the distribution of these three quantities,
together with the time evolution of the velocity magnitude ∥v∥.
3.3. Evaluation metrics
The question of which metrics are preferable in evaluating the
performance of a GAN is open to debate [32–34]: most research
on the topic is focused on GANs’ applications to images.
In Ref. [24] the authors assess the similarity between a sample
of synthetically generated data and an empirical original sample,
by employing a metric called maximum mean discrepancy. With
it, the average fluctuations of the values in both synthetic and
empirical samples are compared with the difference between
samples. The authors also introduce a scheme called train-on-
synthetic-test-on-real (TSTR). It requires labels for the generated
data, as well as a supervised learning model that is able to classify
well the original data when trained with it. Then, the synthetic
generated data is first used to train the classifier, and finally, the
classifier is tested with real data. If it is able to correctly label that
data, it means that synthetic fully anonymous data is suited to
create models with real-world predictive power. In Ref. [26] the
authors use a statistical method for visualising high-dimensional
data in a two-dimensional map, called t-distributed stochastic
neighbour embedding. This method enables one to visualise the
distribution of the data. To study the preservation of correlations
between different dimensions of the data, principal component
analysis is used. While the profile of auto-correlations is not
directly assessed, the authors compare conditional probability
4
 P. Lencastre, M. Gjersdal, L.R. Gorjão et al.
Physica D 453 (2023) 133831
Table 2
Moments of the probability distribution function of |v| for each dataset and the corresponding Markov/GAN generated data. We see that, when it comes to modelling
the distribution of |v|, the Markov model is relatively successful. GAN models, however, consistently underestimate the values of the moments of the distribution. In
particular, GAN models have difficulty capturing long tails of the distribution, as can be seen by the reduced values of the kurtosis. The only exception is TimeGAN
for the VAR(2) dataset, but notice that, in this case, the value of the standard deviation is largely underestimated. The difficulty in replicating the moments of the
|v|-distribution is even more pronounced in the empirical case of gaze trajectories which is significantly more complex than a VAR process.
Mean
Standard deviation
Skewness
Excess of kurtosis
VAR(1)
Data
2.0
1.27
1.1
1.39
Markov
2.00 ± 10−2
1.30 ± 10−2
1.10 ± 3 · 10−2
1.4 ± 10−1
RC
1.00 ± 4 · 10−2
6.8 · 10−1 ± 5 · 10−2
1.2 ± 2 · 10−1
2 ± 1
Time
1.10 ± 2 · 10−2
7.1 · 10−1 ± 1 · 10−2
7.8 · 10−1 ± 6 · 10−2
3 · 10−1 ± 2 · 10−1
SIGCW
1.20 ± 2 · 10−2
7.2 · 10−1 ± 2 · 10−2
1.00 ± 7 · 10−2
1.0 ± 3 · 10−1
RCW
1.40 ± 3 · 10−2
8.7 · 10−1 ± 2 · 10−2
9.3 · 10−1 ± 7 · 10−2
8 · 10−1 ± 3 · 10−1
VAR(2)
Data
1.5
1.0
1.0
1.2
Markov
1.500 ± 4 · 10−3
9.80 · 10−1 ± 3 · 10−3
1.10 ± 10−2
1.20 ± 5 · 10−2
RC
8.9 · 10−1 ± 2 · 10−2
5.1 · 10−1 ± 1 · 10−2
7.2 · 10−1 ± 6 · 10−2
6 · 10−1 ± 2 · 10−1
Time
2.80 ± 4 · 10−2
1.8 · 10−1 ± 10−2
5.0 ± 10−1
3.00 ± 9 · 10−2
SIGCW
1.100 ± 7 · 10−3
8.40 · 10−1 ± 6 · 10−3
1.00 ± 2 · 10−2
8.7 · 10−1 ± 7 · 10−2
RCW
(Diverges)
(Diverges)
(Diverges)
(Diverges)
VAR(3)
Data
2.1
1.4
1.1
1.2
Markov
2.200 ± 9 · 10−3
1.400 ± 8 · 10−3
1.00 ± 1 · 10−2
1.20 ± 7 · 10−2
RC
1.80 ± 10−2
4.4o · 10−1 ± 9 · 10−3
−5 · 10−1 ± 5
5 · 10−1 ± 10−1
Time
(Diverges)
(Diverges)
(Diverges)
(Diverges)
SIGCW
1.00 ± 10−2
7.10 · 10−1 ± 8 · 10−3
1.10 ± 3 · 10−2
1 ± 10−1
RCW
(Diverges)
(Diverges)
(Diverges)
(Diverges)
Eye-Gaze
Data
3.2
6.2
5.8
4.1 · 10+1
Markov
3.3 ± 10−1
6.2 ± 3 · 10−1
5.8 ± 2 · 10−1
4.1 · 10+1 ± 3
RC
4.20 · 10−1 ± 5 · 10−3
2.90 · 10−1 ± 5 · 10−3
1.50 ± 8 · 10−2
2.9 ± 5 · 10−1
Time
3.70 · 10−1 ± 4 · 10−3
2.20 · 10−1 ± 3 · 10−3
1.20 ± 8 · 10−2
2.4 ± 6 · 10−1
SIGCW
1.200 ± 7 · 10−3
7.70 · 10−1 ± 7 · 10−3
1.30 ± 4 · 10−2
2.6 ± 3 · 10−1
RCW
4.50 · 10−1 ± 9 · 10−3
3.7 · 10−1 ± 10−2
2.0 ± 2 · 10−1
6 ± 1
distributions as an indicative measure of the ability to capture
time dependencies and make predictions about the future of
the series. Finally, in Ref. [28], the authors check the probability
density and auto-correlation functions, using the L1-distance. In
multidimensional data, this metric is also used to evaluate differ-
ences in feature correlation. The TSTR scheme is also used by the
authors to evaluate performance.
In broad terms, one usually wants to check two aspects of the
generated data: (i) if the generated distribution is similar to the
original data and (ii) if the time-dependency and its possible long
time-correlations reproduce those of real data. To estimate how
well an algorithm replicates the distribution of the original data,
we evaluate the distributions of the velocity magnitude ∥v∥and
each angle, θ and ϕ (see Fig. 3).
In order to compare the similarity between distributions, we
will use the Jensen–Shannon (JS) divergence, which is a sym-
metrised version of the Kullback–Leibler (KL) divergence, fulfill-
ing the properties of a distance, in this case, between distribu-
tions. The KL divergence is defined by
DKL(ρemp||ρsyn) =
∫
ρemp log
(ρemp
ρsyn
)
.
(6)
With this definition, JS divergence is defined as
DJS(ρemp||ρsyn) = 1
2
(
DKL(ρemp||¯ρ) + DKL(ρsyn||¯ρ))
,
(7)
where ¯ρ =
1
2(ρemp + ρsyn). The KL divergence is perhaps the
most common measure to quantify the similarity between dis-
tributions, since minimising the KL divergence leads to a maxi-
mum likelihood estimation. The JS divergence remains this im-
portant feature and, additionally, has a symmetric property, i.e.
DJS(ρemp||ρsyn) = DJS(ρsyn||ρemp), which in the present case is
more intuitive: while the generator tries to approximate the syn-
thetic distributions to the empirical ones, the discriminators try
to distinguish the empirical distributions from those generated by
the generator.
When it comes to quantifying how well the time-dependency
is replicated, we evaluate the auto-correlation of the velocity
magnitude ∥v∥. The auto-correlation is defined as the Pearson
correlation for each spatial coordinate, namely (for X)
γX(tlag) =
E [
(X(t) −X)(X(t −tlag) −X)]
E [
(X(t) −X)(X(t) −X)]
,
(8)
where X is the average of the variable (spatial coordinates) and
tlag is the time-lag for which the auto-correlation is computed
and E[x] symbolises the expected value of a stochastic variable x.
Notice that, while gaze trajectories are not stationary stochastic
processes, both the AI models as well as the Markov model create
time-homogeneous trajectories. In that sense, γX (and γY sep-
arately) evaluates the model’s ability to replicate the ‘‘average’’
dynamics of a given time-series.
To assess how well an algorithm replicates the auto-correlation
function of each one of these three quantities we will consider the
L2-distance. The L2-distance between two functions femp(x), fsyn(x)
is given by
d(femp, fsyn) =
(∫∞
−∞
(femp(x) −fsyn(x))2dx
) 1
2
.
(9)
4. Comparative analysis
The results of this paper are shown in Fig. 4 – together with
additional simulation in Appendix A, namely Figs. 6 and 7 –
and in Fig. 5, with the results to reproduce eye-gaze trajecto-
ries. Table 2 shows the expected value and the uncertainty of
the first four moments of the distribution of |v|-values, namely
mean, variance, skewness and kurtosis, for each case of original
data (synthetic, VAR-processes and empirical eye-gaze trajecto-
ries, and the corresponding Markov- and GAN-generated data.
Table 3 shows the similarity between empirical and modelled
data. For the distribution of each one of the three quantities
characterising eye-gaze trajectories (cf.
Fig. 3) we indicate the
5
 P. Lencastre, M. Gjersdal, L.R. Gorjão et al.
Physica D 453 (2023) 133831
Fig. 4. Results for reproducing the VAR(1) process with a Markov model and time-series GANs. On the first and second rows, the distribution and auto-correlation
function of ∥v∥are plotted. On the last two rows, the distributions of the angles θ and ϕ are shown.
Table 3
Algorithms’ performance in replicating a VAR process (top) and gaze trajectories (bottom) according to the metrics defined in Eqs. (9) and (7). Firstly, the accuracy
in replicating the distribution (first column) and auto-correlation (second column) function of ∥v∥are calculated. The distance between the empirical and synthetic
distributions of the angles θ and ϕ are shown in the third and fourth columns respectively. It is possible to see that AI algorithms significantly fail in replicating
any distribution of either ∥v∥, θ or ϕ. In what the auto-correlation of ∥v∥are concerned, SigCWGAN comes close to a Markov process. With the distribution of θ
and ϕ so poorly replicated, however, it is difficult to assume that it correctly captures the time-evolution of the process.
Dist. |v| [DJS]
Aut.corr. |v| [d(femp, fsyn)]
Dist. θ [DJS]
Dist. ϕ [DJS]
VAR(1)
Markov
6 · 10−3 ± 2 · 10−3
7 · 10−2 ± 1 · 10−2
6 · 10−2 ± 10−2
1.4 · 10−1 ± 2 · 10−2
RCGAN
3.4 ± 4 · 10−1
7 · 10−1 ± 3 · 10−1
3.1 ± 6 · 10−1
1.2 ± 10−1
TimeGAN
2.8 ± 10−1
3.7 · 10−1 ± 4 · 10−2
4.7 ± 3 · 10−1
1.5 ± 10−1
SigCWGAN
2.5 ± 10−1
1.3 · 10−1 ± 4 · 10−2
6 · 10−1 ± 10−1
3.2 · 10−1 ± 4 · 10−2
RCWGAN
1.0 ± 10−1
3.0 · 10−1 ± 3 · 10−2
6.8 ± 3 · 10−1
2.1 ± 2 · 10−1
VAR(2)
Markov
3.5 · 10−3 ± 8 · 10−4
2.20 · 10−1 ± 6 · 10−3
2.8 · 10−2 ± 4 · 10−3
4.5 · 10−2 ± 5 · 10−3
RCGAN
2.7 ± 2 · 10−1
1.6 ± 10−1
9.8 ± 3 · 10−1
1.7 ± 2 · 10−1
TimeGAN
2.80 ± 4 · 10−2
1.8 · 10−1 ± 10−2
5.00 ± 2 · 10−2
3.00 ± 8 · 10−2
SigCWGAN
9.3 · 10−1 ± 4 · 10−2
4 · 10−2 ± 10−2
101 ± 10−1
9.2 ± 10−1
RCWGAN
(Diverges)
(Diverges)
(Diverges)
(Diverges)
VAR(3)
Markov
3.1 · 10−3 ± 8 · 10−4
9.2 · 10−1 ± 10−2
2.9 · 10−2 ± 4 · 10−3
8.9 · 10−2 ± 8 · 10−3
RCGAN
5.2 ± 10−1
1.30 ± 7 · 10−2
4 · 101 ± 1
1.20 · 101 ± 3 · 10−1
TimeGAN
(Diverges)
(Diverges)
(Diverges)
(Diverges)
SigCWGAN
4.2 ± 10−1
1.8 · 10−1 ± 5 · 10−2
1.60 · 101 ± 2 · 10−1
3.0 ± 2 · 10−1
RCWGAN
(Diverges)
(Diverges)
(Diverges)
(Diverges)
Eye-Gaze
Markov
1.6 · 10−2 ± 3 · 10−3
3.2 · 10−1 ± 7 · 10−2
3.3 · 10−1 ± 2 · 10−2
4.6 · 10−2 ± 6 · 10−3
RCGAN
2.600 ± 3 · 10−3
6.7 · 10−1 ± 10−2
1.1 ± 10−1
5 · 10−2 ± 6 · 10−2
TimeGAN
2.600 ± 3 · 10−3
1.100 ± 5 · 10−3
1.2 ± 10−1
4.2 · 10−1 ± 5 · 10−2
SigCWGAN
1.60 ± 2 · 10−2
4.3 · 10−1 ± 2 · 10−2
9.3 · 10−1 ± 4 · 10−2
1.20 · 101 ± 10−1
RCWGAN
2.6 ± 4 · 10−1
8.90 · 10−1 ± 8 · 10−3
2.2 ± 2 · 10−1
5.1 ± 2 · 10−1
numerical value of the Jensen–Shannon divergence between both
distributions (cf. Eq. (7)), while for the auto-correlation function
of the velocity magnitude we use the L2-distance (cf. Eq. (9)).
For each algorithm, 100 time-series were generated, each with
85 thousand data points, the same number of data points as the
original time-series.
6
 P. Lencastre, M. Gjersdal, L.R. Gorjão et al.
Physica D 453 (2023) 133831
Fig. 5. Results for reproducing eye-gaze trajectories with a Markov model and time-series GANs. In the first column, the first 600 points of a trajectory are represented.
In the second column and third columns, the distribution and auto-correlation function of ∥v∥are plotted. On the last two rows, the distributions of the angles θ
and ϕ are shown.
4.1. Replicating synthetic data
Starting with the results for the VAR(1) process (Fig. 4), we
observe that the distribution of (absolute value of) velocity in-
crements has no heavy tails (first column). Even so, GAN models
consistently fail to capture the large values of the distribution.
They all perform at the same level, and, when compare with the
Markov chain model, the performance is two to three orders of
magnitude worse (cf. 3). Still, the RCWGAN architecture shows
better results.
As for the auto-correlation functions (second column), we see
also that again the Markov model performs better than any GAN
architecture. Here, the SigCWGAN seems to retrieve the best
results, followed by RCWGAN. Such a fact can be explained by
the choice of the generator for these architectures, namely an
AR-FNN, which is usually built with the stated aim to capture
auto-correlations [28]. Still, contrary to what one would expect,
even though these two GAN architectures are relatively good
at estimating the (positively valued) auto-correlation function,
they fail in simulating the large values of the velocity increment
distribution. We see in Fig. 4 that the AI models tested here fail to
correctly model the larger values of the VAR increments’ distribu-
tions, even though their excess kurtosis is insignificant. This hap-
pens even when GANs can correctly replicate the auto-correlation
function.
The distribution of the angle θ is also best grasped by the
Markov model. Again, SIGCWGAN comes close but significantly
worse than the Markov model, followed by the RCGAN architec-
ture. RCWGAN shows significant overestimation bias, while in the
case of TimeGAN, the distribution of θ is concentrated on 45◦
and 135◦. For the distribution of the angle ϕ, all algorithms work
relatively well. SigCWGAN and the Markov model work at the
same level, with Markov performing better, but the results for the
SigCWGAN lying within the margin of error. These results are in
line with the ones published in Ref. [28] on the same data, with
SigCWGAN performing slightly worse and the other GAN models
performing slightly better.
Notice that VAR(1) processes are Markov processes by con-
struction, so it is not surprising that a Markov process reproduces
so well this process. However, similar results are obtained for
VAR processes of higher dimension. In Appendix A we show the
results for VAR(p) processes with p = 2 and p = 3, and there
again one observes that Markov processes surpass all the set of
GANs architectures. Moreover, as will be discussed in the next
subsection, for the eye-gaze trajectories, the results do not differ
much from this.
4.2. Replicating empirical data
For empirical data, examples of empirical eye-gaze trajecto-
ries, as well as the respective modelled trajectories with the
different models, are shown in the first column of Fig. 5.
The distribution of the velocity increment (second column)
shows again no heavy tails. However, while the Markov model’s
distribution fits again considerably well with the empirical distri-
bution, the GAN model’s inability to capture the extreme values is
even stronger than for VAR processes. SigCWGAN works slightly
better than the other architectures.
As for the auto-correlation function, since we do not expect
gaze trajectories to obey the Markov condition, it is normal to
7
 P. Lencastre, M. Gjersdal, L.R. Gorjão et al.
Physica D 453 (2023) 133831
Fig. 6. Results for reproducing the VAR(2) process with a Markov model and time-series GANs. For comparison with Fig. 4.
expect a deviation between both functions. The SigCWGAN ar-
chitecture comes close to the Markov model in modelling the
auto-correlation function, while the other architectures are only
able to partially capture the positive auto-correlations of the
process.
The distribution of angle θ is also well grasped by the Markov
model. In particular, the Markov model is able to capture the pref-
erential directions around the 0◦, 90◦, 180◦, 270◦. It is however
unable to capture the finer details of this metric, smoothing some
of the other picks in the distribution. It is possible that larger
samples (trajectories) or a different choice of the kernel when
computing the numerical distribution would lead to a better
resolution. GANs, however, cannot capture this distribution at all.
They replicate some of the fluctuations, but with significant biases
and miss the preferential angles. For the distribution of the angle
ϕ, again, the Markov model works better than any GAN. However,
TimeGAN and RCWGAN are able to capture some distribution
around the 180◦value. We see that even though SigCWGAN
somewhat replicates the auto-correlation function, it does not
capture the distribution of ϕ. Indeed, this time-series must be
one rare example that has an angle between two increments
around 180◦but that, at the same time, has a positive auto-
correlation function. It is possible that not being able to replicate
the larger values of the distribution, in order to capture the
positive value auto-correlation function, this algorithm tends to
create trajectories in the same direction.
5. Discussion and conclusions
From the comparative analysis in the previous section, we
conclude the Markov model outperforms all GAN architectures
considered in this paper. Within the set of GAN architectures, it
is possible to see that the SigCWGAN outperforms the rest of the
GANS and that it performs at the level of a Markov implementa-
tion when it comes to the distribution of ϕ, but slightly worse for
the distribution of θ. The other GANs perform relatively worse
and do not come statistically close to the efficacy of a Markov
process, particularly when it comes to the distribution of θ.
The fact that one specific GAN architecture can reproduce
some of the statistics at the same level as a Markov process is
good news for the AI community since it opens the door to their
application to more complex processes. However, we provide
evidence that simple Markov models are significantly better at
modelling the distribution of the process and are themselves not
as complex (black-box-like) as an AI method. Indeed, GAN im-
plementations typically use a number of parameters two orders
of magnitude larger than Markov models. Moreover, by simply
computing a Markov transition matrix one might be able to assert
other important features of the natural process (trajectory), e.g. if
it is time-continuous or stationary [22].
Such drawbacks of GANs seem to be present in processes with
a negligible excess kurtosis, such as VAR(p) processes, as well
as 200 Hz free-viewing eye-gaze trajectory, which have typically
a very large excess kurtosis. Thus, while we do not claim that
non-parametric Markov models always outperform AI algorithms,
we show that, when non-parametric models are needed, the
implicit assumption of the universal preference of AI methods
is not justified. This is done by showing that old-fashion math-
ematical models outperform their AI counterparts both in a very
simple synthetic time-series and in a highly complex empirical
one. We thus recommend caution when employing AI to predict
time-series without comparing them with simpler methods that
humans can easily explain.
8
 P. Lencastre, M. Gjersdal, L.R. Gorjão et al.
Physica D 453 (2023) 133831
Fig. 7. Results for reproducing the VAR(3) process with a Markov model and time-series GANs. For comparison with Figs. 4 and 6.
The evidence uncovered in this paper can be now extended in
different ways. On one hand, while the GAN models considered
here are some of the most used in AI approaches and the pro-
cesses consider cover both Gaussian and non-Gaussian features,
other GAN architectures and datasets could be considered. In
particular, emphasis should be given to architectures aimed at
capturing the extreme values of a distribution, as has been the
case of SigCWGAN and TimeGAN. Datasets covering other types
of processes could also help to a systematic approach to exploring
the limits of our findings, namely including jump-diffusion [35]
noise and intermittent processes [36].
On the other hand, extensions of the Markov model used
here could be investigated, namely models with a Markov length
longer than one time lag. Finally, a hybrid approach could be
to use a GAN to model the residuals of a Markov process or
train GANs to generate Markov matrices (eventually in more
dimensions).
We have compared our training with that of previous works
on the same data [28] and, in most cases, found very similar
training statistics and outcomes when training on the same data.
The GANs tested here are conditional GANs, meaning that they
use the previous points to calculate the following points. Thus,
the number of points used in calculating the next set of points
(typically represented a ‘‘p’’ in the literature). A systematic search
of the optimal value of this parameter was performed and the
value of p = 3 was chosen. Other aspects, such as the size of the
network and the batch size were also optimised after comparing
the outcomes of several trials.
All in all, despite the claims of GAN’s ability to capture the
overall time-evolution of a stochastic process this is not verified
in complex time-series. Even in algorithms which, according to
the authors, were able to capture extreme values of the data,
this limitation is quite significant, with the GAN architectures not
being able to capture the full spectrum of the auto-correlation
function. At face value, the inability of AI methods to outper-
form a conceptually simple mathematical process is surprising.
When these methods are presented, their successes are high-
lighted and further applications of these methods focus only
on the case where they are successful. Nonetheless, they are
constrained by the central limit theorem: the typical distribution
of the GAN-generated data is the normal distribution. One possi-
bility to overcome this would be to re-design the standard GAN
architectures, enabling them to include noise inputs distributed
according to α-stable distributions.
Declaration of competing interest
The authors declare that there are no interest to be stated.
Data availability
The authors do not have permission to share data.
Acknowledgements
The authors thank Oslo Metropolitan University for partial
financial support, through the Nordic Center for Sustainable and
Trustworthy AI Research (NordSTAR).
Appendix A. Results for replicating VAR(2) and VAR(3) pro-
cesses
While gaze trajectories have a non-Markov behaviour it is also
interesting to apply our methodology to synthetic processes that,
9
 P. Lencastre, M. Gjersdal, L.R. Gorjão et al.
Physica D 453 (2023) 133831
contrarily to the VAR(1) process, are also, by definition, non-
Markov. These are the VAR(p = 2) processes and the VAR(p =
3) processes as defined in Eq. (4).
In the VAR(2) process we have used φ1 = 0.5 and φ2 = 0.4
and in the VAR(3) process we have used φ1 = 0.3, φ2 = 0.3 and
φ3 = 0.3. The correlation coefficient the two spacial dimensions
was kept at 0.8 and, just like before, for each case we have created
85 thousand points time-series with a sampling time ∆t = 1.
Results can be observer in Table 3 and in Figs. 6 and 7.
In this case, we observed that some GAN-generated time-
series diverged to infinity. This was the case for the RCWGAN in
the VAR(2) case and for the RCWGAN and TimeGAN in the VAR(3)
process. We found a similar behaviour with other choices of φ
with RCGAN diverging at times too. SigCWGAN was not observed
to diverge for convergent time-series. Changing the number of
epochs in training or the learning rate did not seem to signifi-
cantly affect some GANs, producing divergent series. Indeed, we
observe that SigCWGAN typically replicates the auto-correlation
function of the VAR(2) and VAR(3) at an accuracy similar to the
case of VAR(1). As expected, this is not the case for a Markov
process.
However, given that the ANN that is used in the SigCWGAN
(the AR-FNN) is explicitly built with the purpose of mimicking the
auto-correlation function of the data and that this architecture
fails to capture the distribution of ϕ, it is reasonable to assume
that the algorithm is unable to replicate many significant aspects
of the temporal dynamics of the process.
When it comes to the distribution of the increments of a
process, we see that, similarly to VAR(1) processes and gaze
trajectories, GANs underestimate its moments, specially in the
standard deviation. We also see that GANs fail in reproducing the
distribution of θ showing that they do not accurately represent
the relationship between the two spacial dimensions.
In conclusion, for the case of VAR(2) and VAR(3) we see
that one aspect of the temporal dynamics of the process (the
auto-correlation function) is better replicated by one GAN, the
SigCWGAN, while the other (the distribution of ϕ) is still far from
the results produced by the Markov model. Moreover, GANs still
fail to replicate the distribution of the increments and to capture
correctly the relationship between the two spacial dimensions
of the problem, which can be evaluated by the distribution of
θ. Thus, even in the case of a simple synthetic data where the
Markov hypothesis is not present, the advantages of GANs are still
limited.
Appendix B. About the training of GANs
Training GANs is a challenging task since this is often not
a stable process, where each epoch is better than the previous
one, and where some pitfalls exist [8]. Two problems are usual,
namely the vanishing gradients and the mode collapse. In the first
one, the discriminator becomes so successful that neither the
discriminator nor the generator is able to have any learning with
successive epochs. In mode collapse the generator is able to fool
the discriminator with just small different modes ignoring all the
others, thus producing time-series that are all very similar among
themselves. To solve this, one is typically advised to choose
carefully the learning rate of both networks.
In our implementation, we have indeed found that training a
GAN for a longer period did not necessarily lead to better results.
Moreover, we experienced some instances of mode collapse when
trying to model real-time series and had to carefully calibrate
learning rates. We found that training the GANs for around 200
epochs would decrease the train and testing error while also
avoiding the pitfall of mode collapse. The weights of the ANNs
were updated using the Adam optimiser [37].
Appendix C. Implementation of the Markov-chain model
In a Markov model, we can generate a time-series by comput-
ing Pr(Xt=n+1 = xn+1 | Xt=n = xn). We estimate this quantity
empirically with the help of a Gaussian estimation kernel K as
follows:
Pr(Xt=n+1 = xn+1 | Xt=n = xn) =
Pr(Xt=n+1 = xn+1, Xt=n = xn)
Pr(Xt=n = xn)
,
(C.1)
with
Pr(Xt=n+1 = xn+1, Xt=n = xn) =
1
( ˆN −1)2h2
ˆN−1
∑
i=1
K
(
xn+1 −ˆxi+1
h
)
K
(
xn −ˆxi
h
)
,
(C.2)
Pr(Xt=n = xn) =
1
h( ˆN −1)
ˆN−1
∑
i=1
K
(
xn −ˆxi
h
)
,
(C.3)
where
K
(
xn −ˆxi
h
)
=
1
√
2π
exp
(
−1
2
(
xn −ˆxi
h
)2)
,
(C.4)
and h represents the bandwidth of the Gaussian estimation kernel
K and it is calculated following Silverman’s rule [38]:
h =
(
4 ˆσ 5
3 ˆN −3
) 1
5
≈1.06 ˆσ ( ˆN −1)−1/5 ,
(C.5)
where ˆσ is the standard deviation of ˆx1 . . . ˆxn and ˆN the number
of data points in our sample.
When analysing empirical data, Pr(Xt=n+1
|
Xt=n) can be
represented as a matrix T of dimension Ns ×Ns with entries given
by
Ti,j = Pr
(
Xt=n+1 ⊂[ki, ki+1) | Xt=n ⊂[kj, kj+1)
)
,
(C.6)
with i, j ∈N, i, j ⊂[0, Ns] and km > kn ⇔m > n. Thus,
if we observer the state Xt=n ⊂[kj, kj+1) we can calculate the
probability of observing Xt=n+1 ⊂[ki, ki+1). When generating a
new time-series, if it is found that Xt=n+1 ⊂[ki, ki+1), we assign
a value to Xt=n+1 from the uniform distribution in the interval
[ki, ki+1).
The accuracy of this method depends on three major factors:
Firstly, on the validity of the Markov condition (3); Secondly, on
the number of states Ns, which is constrained by computational
time (scaling approximately with N4
s for a two-dimensional pro-
cess); Thirdly, accuracy is also affected by the amount of data
in our sample ˆN, which impacts the bandwidth calculus h: the
larger ˆN is, the smaller is the resulting value of h thus increasing
the spatial resolution of the model. An implementation of this
algorithm using python and numpy can be found in Github [39].
References
[1] A. Flores, H. Tito-Chura, V. Yana-Mamani, Wind speed time series pre-
diction with deep learning and data augmentation, in: Proceedings of
SAI Intelligent Systems Conference, Springer, 2021, pp. 330–343, http:
//dx.doi.org/10.1007/978-3-030-82193-7_22.
[2] P.G. Lind, L. Vera-Tudela, M. Wächter, M. Kühn, J. Peinke, Normal behaviour
models for wind turbine vibrations: Comparison of neural networks and
a stochastic approach, Energies 10 (12) (2017) 1944, http://dx.doi.org/10.
3390/en10121944.
[3] A. Russo, F. Raischel, P. Lind, Air quality prediction using optimal neural
networks with stochastic variables, Atmos. Environ. 79 (2013) 822–830,
http://dx.doi.org/10.1016/j.atmosenv.2013.07.072.
10
 P. Lencastre, M. Gjersdal, L.R. Gorjão et al.
Physica D 453 (2023) 133831
[4] J. Cao, Z. Li, J. Li, Financial time series forecasting model based on
CEEMDAN and LSTM, Phys. A 519 (2019) 127–139, http://dx.doi.org/10.
1016/j.physa.2018.11.061.
[5] P. Wang, X. Zheng, G. Ai, D. Liu, B. Zhu, Time series prediction for the
epidemic trends of COVID-19 using the improved LSTM deep learning
method: Case studies in Russia, Peru and Iran, Chaos Solitons Fractals 140
(2020) 110214, http://dx.doi.org/10.1016/j.chaos.2020.110214.
[6] F. Harrou, A. Dairi, F. Kadri, Y. Sun, Forecasting emergency department
overcrowding: A deep learning framework, Chaos Solitons Fractals 139
(2020) 110247, http://dx.doi.org/10.1016/j.chaos.2020.110247.
[7] I.J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S.
Ozair, A. Courville, Y. Bengio, Generative adversarial networks, 2014, http:
//dx.doi.org/10.48550/arXiv.1406.2661, arXiv preprint arXiv:1406.2661.
[8] E. Brophy, Z. Wang, Q. She, T. Ward, Generative adversarial networks
in time series: A survey and taxonomy, 2021, http://dx.doi.org/10.48550/
arXiv.2107.11098, arXiv preprint arXiv:2107.11098.
[9] D. Hazra, Y.-C. Byun, SynSigGAN: Generative adversarial networks for
synthetic biomedical signal generation, Biology 9 (12) (2020) 441, http:
//dx.doi.org/10.3390/biology9120441.
[10] L. Yu, W. Zhang, J. Wang, Y. Yu, Seqgan: Sequence generative adversarial
nets with policy gradient, in: Proceedings of the AAAI Conference on Artifi-
cial Intelligence, Vol. 31, 2017, p. 1, URL https://www.aaai.org/Conferences/
AAAI/2017/PreliminaryPapers/12-Yu-L-14344.pdf.
[11] O. Mogren, C-RNN-GAN: Continuous recurrent neural networks with ad-
versarial training, 2016, http://dx.doi.org/10.48550/arXiv.1611.09904, arXiv
preprint arXiv:1611.09904.
[12] H.-W. Dong, W.-Y. Hsiao, L.-C. Yang, Y.-H. Yang, Musegan: Multi-track
sequential generative adversarial networks for symbolic music genera-
tion and accompaniment, in: Thirty-Second AAAI Conference on Artificial
Intelligence, 2018, p. 1, URL https://salu133445.github.io/musegan/pdf/
musegan-aaai2018-paper.pdf.
[13] Z. Lv, X. Huang, W. Cao, An improved GAN with transformers for pedestrian
trajectory prediction models, Int. J. Intell. Syst. 37 (8) (2021) 4417–4436,
http://dx.doi.org/10.1002/int.22724.
[14] M. Wiese, R. Knobloch, R. Korn, P. Kretschmer, Quant GANs: Deep gen-
eration of financial time series, Quant. Finance 20 (9) (2020) 1419–1440,
http://dx.doi.org/10.1080/14697688.2020.1730426.
[15] S. Berkovsky, R. Taib, I. Koprinska, E. Wang, Y. Zeng, J. Li, S. Kleitman,
Detecting personality traits using eye-tracking data, in: Proceedings of the
2019 CHI Conference on Human Factors in Computing Systems, 2019, pp.
1–12, http://dx.doi.org/10.1145/3290605.3300451.
[16] M. Steffens, B. Becker, C. Neumann, A. Kasparbauer, I. Meyhöfer, B. Weber,
M. Mehta, R. Hurlemann, U. Ettinger, Effects of ketamine on brain function
during smooth pursuit eye movements, Hum. Brain Mapp. 37 (11) (2016)
4047–4060, http://dx.doi.org/10.1002/hbm.23294.
[17] P.M. Grace, T. Stanford, M. Gentgall, P.E. Rolan, Utility of saccadic
eye movement analysis as an objective biomarker to detect the seda-
tive interaction between opioids and sleep deprivation in opioid-naive
and
opioid-tolerant
populations,
J.
Psychopharmacol.
24
(11)
(2010)
1631–1640, http://dx.doi.org/10.1177/0269881109352704.
[18] H. Chauhan, A. Prasad, J. Shukla, Engagement analysis of ADHD students
using visual cues from eye tracker, in: Companion Publication of the
2020 International Conference on Multimodal Interaction, 2020, pp. 27–31,
http://dx.doi.org/10.1145/3395035.3425256.
[19] A. Lev, Y. Braw, T. Elbaum, M. Wagner, Y. Rassovsky, Eye tracking
during a continuous performance test: Utility for assessing ADHD pa-
tients, J. Atten. Disord. 26 (2) (2022) 245–255, http://dx.doi.org/10.1177/
1087054720972786.
[20] T. Wadhera, D. Kakkar, Eye tracker: An assistive tool in diagnosis of autism
spectrum disorder, in: Emerging Trends in the Diagnosis and Intervention
of Neurodevelopmental Disorders, IGI Global, 2019, pp. 125–152, http:
//dx.doi.org/10.4018/978-1-5225-7004-2.ch007.
[21] B. Hayes, et al., First links in the Markov chain, Am. Sci. 101 (2) (2013)
252, http://dx.doi.org/10.1511/2013.101.92.
[22] P. Lencastre, F. Raischel, T. Rogers, P. Lind, From empirical data to time-
inhomogeneous continuous Markov processes, Phys. Rev. E 93 (3) (2016)
032135, http://dx.doi.org/10.1103/PhysRevE.93.032135.
[23] R. Huang, B. Xu, D. Schuurmans, C. Szepesvári, Learning with a strong
adversary, 2015, http://dx.doi.org/10.48550/arXiv.1511.03034.
[24] S.L. Hyland, C. Esteban, G. Rätsch, Real-valued (medical) time series
generation with recurrent conditional GANs, 2017, http://dx.doi.org/10.
48550/arXiv.1706.02633, arXiv preprint arXiv:1706.02633.
[25] S. Hochreiter, J. Schmidhuber, Long short-term memory, Neural Comput.
9 (8) (1997) 1735–1780, http://dx.doi.org/10.1162/neco.1997.9.8.1735.
[26] J. Yoon, D. Jarrett, M. Van der Schaar, Time-series generative adversarial
networks, Adv. Neural Inf. Process. Syst. 32 (2019) URL http://papers.
neurips.cc/paper/8789-time-series-generative-adversarial-networks.pdf.
[27] D.P. Kingma, M. Welling, et al., An introduction to variational autoencoders,
Found. Trends Mach. Learn. 12 (4) (2019) 307–392, http://dx.doi.org/10.
1561/2200000056.
[28] H. Ni, L. Szpruch, M. Wiese, S. Liao, B. Xiao, Conditional sig-Wasserstein
GANs for time series generation, 2020, http://dx.doi.org/10.48550/arXiv.
2006.05421, arXiv preprint arXiv:2006.05421.
[29] H.
Ni,
L.
Szpruch,
M.
Wiese,
S.
Liao,
B.
Xiao,
Conditional-Sig-
Wasserstein-GANs, 2020, URL https://github.com/SigCGANs/Conditional-
Sig-Wasserstein-GANs.
[30] A.A. Markov, Extension of the law of large numbers to dependent
quantities, Izv. Fiz.-Matem. Obsch. Kazan Univ. (2nd Ser.) 15 (1) (1906)
135–156.
[31] R.M. Klein, W.J. MacInnes, Inhibition of return is a foraging facilitator in
visual search, Psychol. Sci. 10 (4) (1999) 346–352, http://dx.doi.org/10.
1111/1467-9280.00166.
[32] A. Borji, Pros and cons of GAN evaluation measures, Comput. Vis. Image
Underst. 179 (2019) 41–65, http://dx.doi.org/10.1016/j.cviu.2018.10.009.
[33] A. Borji, Pros and cons of GAN evaluation measures: New developments,
Comput. Vis. Image Underst. 215 (2022) 103329, http://dx.doi.org/10.1016/
j.cviu.2021.103329.
[34] K. Shmelkov, C. Schmid, K. Alahari, How good is my GAN? in: Proceed-
ings of the European Conference on Computer Vision (ECCV), 2018, pp.
213–229, http://dx.doi.org/10.1007/978-3-030-01216-8_14.
[35] L. Rydin Gorjão, D. Witthaut, P.G. Lind, JumpDiff: Non-parametric numer-
ical estimation of jump-diffusion processes, J. Stat. Softw. 15 (2023) 1–22,
http://dx.doi.org/10.18637/jss.v105.i04.
[36] P. Lencastre, S. Denysov, A. Yazidi, P.G. Lind, Uncovering Lévy flights and
intermittent processes from empirical time series: a theoretical framework
to classify, 2023, in prepartion.
[37] D.P. Kingma, J. Ba, Adam: A method for stochastic optimization, 2014, http:
//dx.doi.org/10.48550/arXiv.1412.6980, arXiv preprint arXiv:1412.6980.
[38] B.W. Silverman, Density Estimation for Statistics and Data Analysis, first
ed., Routledge, New York, 1998, http://dx.doi.org/10.1201/9781315140919.
[39] P. Lencastre, Markov model, 2023, URL https://github.com/134f/Physica-D-
Markov-model.
11
",https://doi.org/10.1016/j.physd.2023.133831,doc25,"Physica D 453 (2023) 133831 Contents lists available at ScienceDirect Physica D journal homepage: www.elsevier.com/locate/physd Modern AI versus century-old mathematical models: How far can we go with generative adversarial networks to reproduce stochastic processes? Pedro Lencastre a,b,c, Marit Gjersdal a, Leonardo Rydin Gorjão d, Anis Yazidi a,b,c, Pedro G. Lind a,b,c,∗ a Department of Computer Science, OsloMet – Oslo Metropolitan University, P.O. Box 4 St. Olavs plass, N-0130, Oslo, Norway b OsloMet Artificial Intelligence lab, OsloMet, Pilestredet 52, N-0166, Oslo, Norway c NordSTAR - Nordic Center for Sustainable and Trustworthy AI Research, Pilestredet 52, N-0166, Oslo, Norway d Faculty of Science and Technology, Norwegian University of Life Sciences, 1432, Ås, Norway a r t i c l e i n f o Article history: Received 5 December 2022 Received in revised form 26 April 2023 Accepted 21 June 2023 Available online 28 June 2023 Communicated by R. Kuske Keywords: Generative Adversarial Networks GANs Markov models Time-series prediction Eye-tracking data a b s t r a c t The usage of generative adversarial networks (GAN)s for synthetic time-series data generation has been gaining popularity in recent years with applications from finance to music composition and processing of textual content. However, beyond their reported success, few comparisons exist with other artificial intelligence (AI) methods or standard mathematical models. Here, we test GANs performance, comparing them with a well-known mathematical model, namely a Markov chain. We implement comparative metrics based on one- and two-point statistics to evaluate the performance of each method. We find that, similarly to other AI approaches, GANs struggle to capture rare events and cross-feature relations and are unable to create synthetic faithful data. GANs are relatively successful in replicating the auto-correlation function, but they still lag significantly behind simple Markov chains. We also provide a qualitative explanation for this limitation of AI approaches. ( 1. Introduction With the improvements in computation capabilities and the increasing accessibility of large amounts of data, non-parametric models of time-series have become increasingly popular. It is easy to understand why that is the case: non-parametric models have an almost universal application without the laborious task of understanding and reducing the problem to a core of funda- mental quantities to describe a system, often with inaccurate but necessary simplifications. In this context, artificial neural networks (ANNs) based al- gorithms are used, e.g. to predict wind speeds [1], wind power output [2], air quality [3], the evolution of the price financial assets [4], the rate of infections during a pandemic outbreak [5] or the number of patients arriving at a hospital’s emergency services [6]. While it is obvious that being able to predict the future of statistical quantities is useful, these methods can further be used in data augmentation when the original data is insufficient, or, ∗Corresponding author at: Department of Computer Science, OsloMet – Oslo Metropolitan University, P.O. Box 4 St. Olavs plass, N-0130, Oslo, Norway. E-mail address: pedro.lind@oslomet.no (P.G. Lind). e.g. in the medical domain, to produce anonymised data that can be shared without strict ethical constraints. Among these methods, one of the most popular is generative adversarial networks (GANs) [7], which, after their success in faithfully creating realistic images, have recently become popular in time-series replication [8]. GANs consider two ‘‘coupled’’ ANNs playing a zero-sum game. The first ANN is called ‘‘generator’’ and creates synthetic data with the objective to ‘‘fool’’ the sec- ond ANN. This latter ANN is called ‘‘discriminator’’ and tries to distinguish if a particular set of data is synthetic or not. GANs have been applied to biomedical signal data, where they have been used to model the time-evolution of data from electrocardiogram, electroencephalogram, electromyography and photoplethysmography [9]. GANs have also been used in natu- ral language processing [10], generating music [11,12], predict- ing pedestrian trajectory [13] and in predicting the evolution of financial assets [14]. In the realm of biomedical signal data, one type of time-series with several potential applications is eye-tracking data, which can be used to determine personality traits [15], drug consumption habits [16,17], as well as diagnosing attention-deficit hyperactivity disorder [18,19] and autism [20]. In this paper, we will test the performance of GANs in re- producing stochastic trajectories and compare them with some 0167-2789/ P. Lencastre, M. Gjersdal, L.R. Gorjão et al. Physica D 453 (2023) 133831 Fig. 1. Representation of a GAN: the generator tries to create data as faithfully as possible, while the discriminator attempts at distinguishing real data from that produced by the generator. benchmarks from stochastic modelling. Eye-tracking data are par- ticularly appropriate to evaluate GANs’ performance for two rea- sons. Firstly, eye-tracking data reflect a broad panoply of foot- prints flagging particular health states and features of human behaviour. Secondly, they have very large kurtosis, i.e. they are prone to extreme events, typically due to fast gaze relocations in-between two areas of interest. These extreme events lead to heavy-tailed distribution and ANN-based methods have been shown to struggle to capture these distributions’ tails. Thus, within the family of non-parametric models, we com- pare GANs’ performance with that of Markov models, which are a benchmark to describe stochastic time series [21]. Similarly to AI methods, Markov models can be used to replicate a given set of data without the knowledge of the underlying process. When compared to its AI counterparts, Markov models have some advantages: they can provide a unique time-continuous descrip- tion of the system, or, alternatively, assert that a given process is not time-homogeneous (stationary) or time-continuous [22]. Furthermore, in a Markov model each parameter of the model has a straightforward meaning and thus an inspection of the model can give us information about the system, something that does not generally happen for ANN-based methods. We start in Section 2 by describing the technical details in the implementation of different GAN architecture and Markov chains. In Section 3 we describe the data that will be used to test GANs and Markov models. Besides eye-tracking data we will consider synthetic data. Section 4 focuses on comparing the results obtained when using GANs and Markov chains for both synthetic and empirical data and finally, Section 5 concludes the manuscript. 2. Algorithms and methods 2.1. GANs architectures GANs are a subset of AI algorithms following the structure represented in Fig. 1. The generator is initialised with a random noise vector z0 as input from which a time-series is generated. This time-series is then analysed by the discriminator, which will get either real data x or data generated by the generator, z, and will try to distinguish between both. These two networks are trained together in a min–max game fashion [23]. The discriminator is trained to maximise its cor- rect labelling of the input as real or fake, while the generator Table 1 The generator and the discriminator used in each of the GAN architectures addressed in this paper, cf. Fig. 1. GAN Generator Discriminator RCGAN LSTM LSTM TimeGAN bidirect. LSTM bidirect. LSTM SigCWGAN AR-FNN C-Sig-W1 RCWGAN AR-FNN AR-FNN tries to minimise it and tries to ‘‘fool’’ the discriminator. Ideally, this simultaneous adversarial training will eventually lead to the generator learning to create outputs that mimic the statistical properties of the original data: as the discriminator gets more accurate so must the generator in order to fool it. Mathematically, a GAN implementation considers the follow- ing objective function L(G(z), D(x)) = Ex∼ρx [log D(x)] + Ez∼ρZ [log (1 −D(G(z)))] , (1) where D(x) ∈[0, 1] is the discriminator-assigned probability of x being a real data point. Thus, Ex∼ρx [log D(x)] is the expected fraction of correct guesses by the discriminator about real data series x, among all trials in which the discriminator is evaluating real data. In this context, G is the function characterising the generator which maps an input noise series z into a series G(z). See Fig. 1. Therefore, 1 −D(G(z)) represents the probability the discriminator assigns of G(z) correctly being labelled as generated data. The probability distributions of the real data series x, of the input noise z and of the generated series G(z) are represented as ρx, ρz and ρG, respectively. The task of the generator is to bring the probability distribu- tion ρG of the generated series G(z) as close as possible to the distribution ρx of real data series x, such that both terms on the right-hand side are decreased. Simultaneously, the discriminator will try to maximise both expected values, one by maximising D(x), and the other by minimising D(G(z)). Therefore, having defined the objective function in Eq. (1), the optimisation scheme which trains the GAN model solves the min–max problem min G max D L(G(z), D(x)) . (2) Within the general GAN framework, several architectures are possible with different types of ANNs as generators and dis- criminators. In this paper, we consider a selection of different architectures, indicated in Table 1 together with the specific types of generators and discriminators. Details on how to train GAN architectures are given in Appendix B. 2.1.1. Recurrent conditional GAN Recurrent conditional GAN (RCGAN) was one of the first time- series GAN models introduced [24], as a model for replicating multi-valued time-series of medical data, namely the evolution of the health state of patients in emergency care, with the moti- vation to both predict the patient outcomes and generate faithful synthetic data unconstrained from privacy concerns. As the name suggests, it uses recurrent neural networks for the generator and discriminator with Long Short-Term Memory (LSTM) cells [25]. 2.1.2. TimeGAN TimeGAN was introduced in 2019 with the aim to outperform several state-of-the-art GANs [26], presenting concrete examples from stock market and energy consumption data. TimeGAN com- bines a classical GAN architecture with an autoencoder a type of ANN composed of two networks, one that ‘‘encodes’’ a series into 2 P. Lencastre, M. Gjersdal, L.R. Gorjão et al. Physica D 453 (2023) 133831 symbols and another one that ‘‘decodes’’ the symbols back into a series [27]. TimeGAN consists of four networks. In the classical GAN part of the algorithm, a recurrent neural network (RNN) is used as a generator and a bidirectional LSTM as a discriminator. Instead of giving the discriminator the original real data as input to classify it as real or fake, it is given the encoded vector of the real data, after being processed by an autoencoder. TimeGAN uses three loss functions to control the training: Reconstruction loss; supervised loss; and unsupervised loss. The reconstruction loss is calculated using the output of the decoder and is used to calculate the gradients for the encoder and the decoder. The unsupervised loss is based on the discriminator’s output and, similarly to the min–max loss function of the original GAN Eq. (1), is used for calculating the generator and discrimina- tors gradients. Finally, the supervised loss is calculated based on both the generator’s output and the encoder’s output of the real data, and is used for calculating the gradients of the generator and the encoder. Some authors implement TimeGAN with the GAN part only without the autoencoder part of the algorithm [28]. We here follow that implementation. 2.1.3. SigCWGAN and RCWGAN The Conditional Sign-Wasserstein GAN (SigCWGAN) was de- signed with the purpose to capture temporal dependencies in multi-dimensional time-series data while being able to correctly model the tail of its underlying distribution [28]. To capture this, a new metric is introduced, namely the so-called Signature Wasserstein-1 (C-Sig-W1), which serves as the discriminator of the GAN. The usage of this metric is supposed to be not only more robust but also computationally less expensive to train than a typical ANN. For further mathematical details about the discriminator the interested reader should consult Ref. [28]. In this architecture, the authors introduce as a generator a three-layer feed-forward neural network residual connections and parametric ReLUs as activation functions, which determines if the output of a neuron activates the next neuron or not. The authors call this ANN, Autoregressive Feed-Forward Neural Network (AR-FNN). The generator has the main aim to capture auto-regressive processes and thus be able to capture the time- dependency of the process. More details can be found in the appendix of the original paper [28]. The authors of SigCWGAN also implemented a GAN where both the generator and discriminator are RNNs with the afore- mentioned AR-FNN cells. This architecture is called Recurrent Conditional Wasserstein GAN (RCWGAN). In this paper, we will consider this architecture. The original author’s pytorch implementation of the all previ- ously mentioned GAN algorithms can be found in Github [29]. 2.2. Markov-chain models for reproducing time-series Markov models were introduced in 1906 [30] with the general aim to model conditional probabilities and thus being able to provide a description of the time-evolution of a stochastic pro- cess. They were implemented firstly in an effort to estimate the probability of finding a vowel in a text, based on the knowledge of the previous letter [21]. By definition, a time-series Xt is said to follow a Markov process if it fulfils the Markov property: Pr(Xt=j = ˆxj | Xt=j−1 = ˆxj−1, . . . , Xt=0 = ˆx0) = Pr(Xt=j = ˆxj | Xt=j−1 = ˆxj−1) , (3) for all positive integers j, where capital letters mean stochastic variables at different time steps and lowercase letters are the re- spective values of those variables. Successive values are measured at constant time intervals ∆t. The Markov condition implies that, at all times, any prediction on the future of time series Xt depends only on the current state of the system and not on past states. For that reason, Markov pro- cesses are often said to be ‘‘memoryless’’. The Markov property is a simplification that, in the strict sense, does not apply to most natural systems, but it is very convenient because by computing the conditional probability Pr(Xt=j = ˆxj | Xt=j−1 = ˆxj−1) we can describe the full time-evolution of the system, i.e. two-point statistics contains all the information about the process. More details on how to generate a Markov process in this way are given in Appendix C. 3. Data and evaluation metrics 3.1. Synthetic data The first set of data analysed in this paper is a synthetically generated Vector Auto-Regressive (VAR) process. In one dimen- sion, a VAR(p) process assumes that the observable at the present time t is defined from its values in the previous p observations apart a small random noise. In our case, the observable is the velocity of the eye-gaze, which means that we consider spa- tial increments of the positions in both x and y direction. For increments (∆X) the VAR (p) model reads ∆Xt = p ∑ n=1 φn∆Xt−n + ξt(σ) , (4) where ξ is normally distributed random number with zero mean and σ standard deviation. Consequently, in a VAR(p) process, apart from Gaussian fluctuations, the future increments are de- fined through a linear combination of the last p increments. Again, the time labelling is done indicating the number of ele- mentary constant time intervals ∆t. Here we take ∆t = 1 and generate around 85 thousand points (the same number as the empirical eye-tracking dataset we use), given the initial condition ∆X0 = 0 In what follows, we consider a VAR(1) process, meaning that future increments are determined by a random number and the increment immediately preceding it. We consider, however, a VAR(1) process on a two-dimensional plane (X and Y), with some correlation between ∆X and ∆Y, given by σXY . Our process is thus defined by the system of equations ∆Xt = φX∆Xt−1 + ξ (X) t (σX, σXY ) , ∆Yt = φY∆Yt−1 + ξ (Y) t (σY, σYX) , (5) where ξ (X) t (σX, σXY ) represents the stochastic fluctuations in the X-dimension, with zero mean, standard deviation σX and a cor- relation σXY with the stochastic fluctuations in the Y-dimension. We will consider a process purely isotropic, i.e. σX = σY ≡σ and φX = φY ≡φ. The VAR(1) process is one of the most simple synthetic time- series that are correlated in time. It is, by construction, a Markov process, allowing us to test the accuracy of our implemented model, and, for φ > 0, it is suitable to test the commonly mentioned limitation of NN and GAN algorithms in modelling the tails of a distribution. In Fig. 2 (top) a two-dimensional VAR(1) process is represented, with σ = 1, φ = 0.8 and σXY = 0.8, with an inset showing the respective scatter plot of the increments in both X- and Y-directions. From this inset, we observe that indeed ∆X and ∆Y are positively correlated, with a clear propensity of the values to lay on the main diagonal. Furthermore, we observe that values on the extremes of ∆X (corr. ∆Y) tend to follow also extreme values of ∆X (corr. ∆Y), thus illustrating the positive auto-correlation of both coordinates (φ = 0.8). In this paper we will use three types of VAR processes, namely with the values of p = 1, 2 and 3. 3 P. Lencastre, M. Gjersdal, L.R. Gorjão et al. Physica D 453 (2023) 133831 Fig. 2. Top: Representation of a trajectory of two dimensional VAR(1) process (left) and its corresponding increments (right). This time-series was synthetically generated with positive auto-correlation φ = 0.8 and positive feature correlation σXY = 0.8. Thus, values are distributed mainly on the diagonal corresponding to the first and third quadrants. Bottom: Representation of a gaze trajectory (left) and its corresponding increments (right). This series was empirically estimated with a modern eye-tracker. Typically, gaze positions are concentrated on a limited area which is alternated with fast relocation trajectories. 3.2. Eye-tracking data The eye-tracking data was collected at Oslo Metropolitan Uni- versity with the Eye-link Duo, a state-of-the-art equipment with a maximum frequency of 2000 Hz and a precision of 0.1 degrees of visual angle. Here we have downsampled our data to a frequency of 200 Hz and blinks have been removed, yielding around 85 thousand data-points. Units of X and Y are presented in pixels of the viewing screen and eye-tracking data was extracted while the participant was engaged in trying to find pre-selected targets. For this purpose, images from the book Where’s Wally? were used. Eight pictures were used, each one for two minutes. It is very unlikely that two minutes are enough to find all the pre- selected targets in a large image and the experiment was set up this way to make sure that a participant is kept engaged through- out the experiment. The data was collected following all ethical requirements approved by the Norwegian Center for Research Data (Norsk senter for forskningsdata), with the application with Reference Number 176347. In Fig. 2 (bottom) we see an illustration of a gaze trajectory, with, in the inset, its corresponding increments. As described in the literature, we observe periods where the eyes are fixated around a point (called fixations) and periods of relocations (called saccades). Indeed we observe some extreme velocity events and the velocity time-series presents an excess kurtosis of κ ∼50. The presence of extreme events is a welcomed feature of gaze trajectories that makes them particularly suitable to study the performance of ANN based methods. It has been widely reported that ANN-based methods struggle to capture extreme events [2] with some models analysed here explicitly stating their ability to overcome this limitation in replicating the tails of a distri- bution [28]. Real data used to assess ANN performance has a considerably small kurtosis, 5 < κ < 15, and thus includes Fig. 3. Illustration of some of the relevant quantities to describe gaze tra- jectories, namely gaze velocity, gaze direction (θ) and the angle between two consecutive gaze relocations (ϕ). Here, the two steps ⃗r1 and ⃗r2 occurred within constant time-lags ∆t. Consequently, the velocity magnitude is given by, e.g. ∥⃗v1∥= ∥⃗r1∥/∆t. much less extreme events. There are two important examples of non-Markov behaviour. One is the so-called inhibition of return (IoR) [31], a known mechanism by which, for some time, the human gaze avoids visiting the same area after it has recently left it. The other is screen confinement, by which eye-tracker gaze trajectories are restricted to a screen area, and which intro- duces non-trivial long-range dependencies on the series of gaze velocities. Three quantities are important to describe gaze trajectories: the velocity magnitude, ∥v∥, the angle, θ, of a given velocity with the horizontal axis, and the angle, ϕ, between two consecutive measurements. All three quantities are illustrated in Fig. 3. In what follows we will access the performance of a model by its ability to replicate the distribution of these three quantities, together with the time evolution of the velocity magnitude ∥v∥. 3.3. Evaluation metrics The question of which metrics are preferable in evaluating the performance of a GAN is open to debate [32–34]: most research on the topic is focused on GANs’ applications to images. In Ref. [24] the authors assess the similarity between a sample of synthetically generated data and an empirical original sample, by employing a metric called maximum mean discrepancy. With it, the average fluctuations of the values in both synthetic and empirical samples are compared with the difference between samples. The authors also introduce a scheme called train-on- synthetic-test-on-real (TSTR). It requires labels for the generated data, as well as a supervised learning model that is able to classify well the original data when trained with it. Then, the synthetic generated data is first used to train the classifier, and finally, the classifier is tested with real data. If it is able to correctly label that data, it means that synthetic fully anonymous data is suited to create models with real-world predictive power. In Ref. [26] the authors use a statistical method for visualising high-dimensional data in a two-dimensional map, called t-distributed stochastic neighbour embedding. This method enables one to visualise the distribution of the data. To study the preservation of correlations between different dimensions of the data, principal component analysis is used. While the profile of auto-correlations is not directly assessed, the authors compare conditional probability 4 P. Lencastre, M. Gjersdal, L.R. Gorjão et al. Physica D 453 (2023) 133831 Table 2 Moments of the probability distribution function of |v| for each dataset and the corresponding Markov/GAN generated data. We see that, when it comes to modelling the distribution of |v|, the Markov model is relatively successful. GAN models, however, consistently underestimate the values of the moments of the distribution. In particular, GAN models have difficulty capturing long tails of the distribution, as can be seen by the reduced values of the kurtosis. The only exception is TimeGAN for the VAR(2) dataset, but notice that, in this case, the value of the standard deviation is largely underestimated. The difficulty in replicating the moments of the |v|-distribution is even more pronounced in the empirical case of gaze trajectories which is significantly more complex than a VAR process. Mean Standard deviation Skewness Excess of kurtosis VAR(1) Data 2.0 1.27 1.1 1.39 Markov 2.00 ± 10−2 1.30 ± 10−2 1.10 ± 3 · 10−2 1.4 ± 10−1 RC 1.00 ± 4 · 10−2 6.8 · 10−1 ± 5 · 10−2 1.2 ± 2 · 10−1 2 ± 1 Time 1.10 ± 2 · 10−2 7.1 · 10−1 ± 1 · 10−2 7.8 · 10−1 ± 6 · 10−2 3 · 10−1 ± 2 · 10−1 SIGCW 1.20 ± 2 · 10−2 7.2 · 10−1 ± 2 · 10−2 1.00 ± 7 · 10−2 1.0 ± 3 · 10−1 RCW 1.40 ± 3 · 10−2 8.7 · 10−1 ± 2 · 10−2 9.3 · 10−1 ± 7 · 10−2 8 · 10−1 ± 3 · 10−1 VAR(2) Data 1.5 1.0 1.0 1.2 Markov 1.500 ± 4 · 10−3 9.80 · 10−1 ± 3 · 10−3 1.10 ± 10−2 1.20 ± 5 · 10−2 RC 8.9 · 10−1 ± 2 · 10−2 5.1 · 10−1 ± 1 · 10−2 7.2 · 10−1 ± 6 · 10−2 6 · 10−1 ± 2 · 10−1 Time 2.80 ± 4 · 10−2 1.8 · 10−1 ± 10−2 5.0 ± 10−1 3.00 ± 9 · 10−2 SIGCW 1.100 ± 7 · 10−3 8.40 · 10−1 ± 6 · 10−3 1.00 ± 2 · 10−2 8.7 · 10−1 ± 7 · 10−2 RCW (Diverges) (Diverges) (Diverges) (Diverges) VAR(3) Data 2.1 1.4 1.1 1.2 Markov 2.200 ± 9 · 10−3 1.400 ± 8 · 10−3 1.00 ± 1 · 10−2 1.20 ± 7 · 10−2 RC 1.80 ± 10−2 4.4o · 10−1 ± 9 · 10−3 −5 · 10−1 ± 5 5 · 10−1 ± 10−1 Time (Diverges) (Diverges) (Diverges) (Diverges) SIGCW 1.00 ± 10−2 7.10 · 10−1 ± 8 · 10−3 1.10 ± 3 · 10−2 1 ± 10−1 RCW (Diverges) (Diverges) (Diverges) (Diverges) Eye-Gaze Data 3.2 6.2 5.8 4.1 · 10+1 Markov 3.3 ± 10−1 6.2 ± 3 · 10−1 5.8 ± 2 · 10−1 4.1 · 10+1 ± 3 RC 4.20 · 10−1 ± 5 · 10−3 2.90 · 10−1 ± 5 · 10−3 1.50 ± 8 · 10−2 2.9 ± 5 · 10−1 Time 3.70 · 10−1 ± 4 · 10−3 2.20 · 10−1 ± 3 · 10−3 1.20 ± 8 · 10−2 2.4 ± 6 · 10−1 SIGCW 1.200 ± 7 · 10−3 7.70 · 10−1 ± 7 · 10−3 1.30 ± 4 · 10−2 2.6 ± 3 · 10−1 RCW 4.50 · 10−1 ± 9 · 10−3 3.7 · 10−1 ± 10−2 2.0 ± 2 · 10−1 6 ± 1 distributions as an indicative measure of the ability to capture time dependencies and make predictions about the future of the series. Finally, in Ref. [28], the authors check the probability density and auto-correlation functions, using the L1-distance. In multidimensional data, this metric is also used to evaluate differ- ences in feature correlation. The TSTR scheme is also used by the authors to evaluate performance. In broad terms, one usually wants to check two aspects of the generated data: (i) if the generated distribution is similar to the original data and (ii) if the time-dependency and its possible long time-correlations reproduce those of real data. To estimate how well an algorithm replicates the distribution of the original data, we evaluate the distributions of the velocity magnitude ∥v∥and each angle, θ and ϕ (see Fig. 3). In order to compare the similarity between distributions, we will use the Jensen–Shannon (JS) divergence, which is a sym- metrised version of the Kullback–Leibler (KL) divergence, fulfill- ing the properties of a distance, in this case, between distribu- tions. The KL divergence is defined by DKL(ρemp||ρsyn) = ∫ ρemp log (ρemp ρsyn ) . (6) With this definition, JS divergence is defined as DJS(ρemp||ρsyn) = 1 2 ( DKL(ρemp||¯ρ) + DKL(ρsyn||¯ρ)) , (7) where ¯ρ = 1 2(ρemp + ρsyn). The KL divergence is perhaps the most common measure to quantify the similarity between dis- tributions, since minimising the KL divergence leads to a maxi- mum likelihood estimation. The JS divergence remains this im- portant feature and, additionally, has a symmetric property, i.e. DJS(ρemp||ρsyn) = DJS(ρsyn||ρemp), which in the present case is more intuitive: while the generator tries to approximate the syn- thetic distributions to the empirical ones, the discriminators try to distinguish the empirical distributions from those generated by the generator. When it comes to quantifying how well the time-dependency is replicated, we evaluate the auto-correlation of the velocity magnitude ∥v∥. The auto-correlation is defined as the Pearson correlation for each spatial coordinate, namely (for X) γX(tlag) = E [ (X(t) −X)(X(t −tlag) −X)] E [ (X(t) −X)(X(t) −X)] , (8) where X is the average of the variable (spatial coordinates) and tlag is the time-lag for which the auto-correlation is computed and E[x] symbolises the expected value of a stochastic variable x. Notice that, while gaze trajectories are not stationary stochastic processes, both the AI models as well as the Markov model create time-homogeneous trajectories. In that sense, γX (and γY sep- arately) evaluates the model’s ability to replicate the ‘‘average’’ dynamics of a given time-series. To assess how well an algorithm replicates the auto-correlation function of each one of these three quantities we will consider the L2-distance. The L2-distance between two functions femp(x), fsyn(x) is given by d(femp, fsyn) = (∫∞ −∞ (femp(x) −fsyn(x))2dx ) 1 2 . (9) 4. Comparative analysis The results of this paper are shown in Fig. 4 – together with additional simulation in Appendix A, namely Figs. 6 and 7 – and in Fig. 5, with the results to reproduce eye-gaze trajecto- ries. Table 2 shows the expected value and the uncertainty of the first four moments of the distribution of |v|-values, namely mean, variance, skewness and kurtosis, for each case of original data (synthetic, VAR-processes and empirical eye-gaze trajecto- ries, and the corresponding Markov- and GAN-generated data. Table 3 shows the similarity between empirical and modelled data. For the distribution of each one of the three quantities characterising eye-gaze trajectories (cf. Fig. 3) we indicate the 5 P. Lencastre, M. Gjersdal, L.R. Gorjão et al. Physica D 453 (2023) 133831 Fig. 4. Results for reproducing the VAR(1) process with a Markov model and time-series GANs. On the first and second rows, the distribution and auto-correlation function of ∥v∥are plotted. On the last two rows, the distributions of the angles θ and ϕ are shown. Table 3 Algorithms’ performance in replicating a VAR process (top) and gaze trajectories (bottom) according to the metrics defined in Eqs. (9) and (7). Firstly, the accuracy in replicating the distribution (first column) and auto-correlation (second column) function of ∥v∥are calculated. The distance between the empirical and synthetic distributions of the angles θ and ϕ are shown in the third and fourth columns respectively. It is possible to see that AI algorithms significantly fail in replicating any distribution of either ∥v∥, θ or ϕ. In what the auto-correlation of ∥v∥are concerned, SigCWGAN comes close to a Markov process. With the distribution of θ and ϕ so poorly replicated, however, it is difficult to assume that it correctly captures the time-evolution of the process. Dist. |v| [DJS] Aut.corr. |v| [d(femp, fsyn)] Dist. θ [DJS] Dist. ϕ [DJS] VAR(1) Markov 6 · 10−3 ± 2 · 10−3 7 · 10−2 ± 1 · 10−2 6 · 10−2 ± 10−2 1.4 · 10−1 ± 2 · 10−2 RCGAN 3.4 ± 4 · 10−1 7 · 10−1 ± 3 · 10−1 3.1 ± 6 · 10−1 1.2 ± 10−1 TimeGAN 2.8 ± 10−1 3.7 · 10−1 ± 4 · 10−2 4.7 ± 3 · 10−1 1.5 ± 10−1 SigCWGAN 2.5 ± 10−1 1.3 · 10−1 ± 4 · 10−2 6 · 10−1 ± 10−1 3.2 · 10−1 ± 4 · 10−2 RCWGAN 1.0 ± 10−1 3.0 · 10−1 ± 3 · 10−2 6.8 ± 3 · 10−1 2.1 ± 2 · 10−1 VAR(2) Markov 3.5 · 10−3 ± 8 · 10−4 2.20 · 10−1 ± 6 · 10−3 2.8 · 10−2 ± 4 · 10−3 4.5 · 10−2 ± 5 · 10−3 RCGAN 2.7 ± 2 · 10−1 1.6 ± 10−1 9.8 ± 3 · 10−1 1.7 ± 2 · 10−1 TimeGAN 2.80 ± 4 · 10−2 1.8 · 10−1 ± 10−2 5.00 ± 2 · 10−2 3.00 ± 8 · 10−2 SigCWGAN 9.3 · 10−1 ± 4 · 10−2 4 · 10−2 ± 10−2 101 ± 10−1 9.2 ± 10−1 RCWGAN (Diverges) (Diverges) (Diverges) (Diverges) VAR(3) Markov 3.1 · 10−3 ± 8 · 10−4 9.2 · 10−1 ± 10−2 2.9 · 10−2 ± 4 · 10−3 8.9 · 10−2 ± 8 · 10−3 RCGAN 5.2 ± 10−1 1.30 ± 7 · 10−2 4 · 101 ± 1 1.20 · 101 ± 3 · 10−1 TimeGAN (Diverges) (Diverges) (Diverges) (Diverges) SigCWGAN 4.2 ± 10−1 1.8 · 10−1 ± 5 · 10−2 1.60 · 101 ± 2 · 10−1 3.0 ± 2 · 10−1 RCWGAN (Diverges) (Diverges) (Diverges) (Diverges) Eye-Gaze Markov 1.6 · 10−2 ± 3 · 10−3 3.2 · 10−1 ± 7 · 10−2 3.3 · 10−1 ± 2 · 10−2 4.6 · 10−2 ± 6 · 10−3 RCGAN 2.600 ± 3 · 10−3 6.7 · 10−1 ± 10−2 1.1 ± 10−1 5 · 10−2 ± 6 · 10−2 TimeGAN 2.600 ± 3 · 10−3 1.100 ± 5 · 10−3 1.2 ± 10−1 4.2 · 10−1 ± 5 · 10−2 SigCWGAN 1.60 ± 2 · 10−2 4.3 · 10−1 ± 2 · 10−2 9.3 · 10−1 ± 4 · 10−2 1.20 · 101 ± 10−1 RCWGAN 2.6 ± 4 · 10−1 8.90 · 10−1 ± 8 · 10−3 2.2 ± 2 · 10−1 5.1 ± 2 · 10−1 numerical value of the Jensen–Shannon divergence between both distributions (cf. Eq. (7)), while for the auto-correlation function of the velocity magnitude we use the L2-distance (cf. Eq. (9)). For each algorithm, 100 time-series were generated, each with 85 thousand data points, the same number of data points as the original time-series. 6 P. Lencastre, M. Gjersdal, L.R. Gorjão et al. Physica D 453 (2023) 133831 Fig. 5. Results for reproducing eye-gaze trajectories with a Markov model and time-series GANs. In the first column, the first 600 points of a trajectory are represented. In the second column and third columns, the distribution and auto-correlation function of ∥v∥are plotted. On the last two rows, the distributions of the angles θ and ϕ are shown. 4.1. Replicating synthetic data Starting with the results for the VAR(1) process (Fig. 4), we observe that the distribution of (absolute value of) velocity in- crements has no heavy tails (first column). Even so, GAN models consistently fail to capture the large values of the distribution. They all perform at the same level, and, when compare with the Markov chain model, the performance is two to three orders of magnitude worse (cf. 3). Still, the RCWGAN architecture shows better results. As for the auto-correlation functions (second column), we see also that again the Markov model performs better than any GAN architecture. Here, the SigCWGAN seems to retrieve the best results, followed by RCWGAN. Such a fact can be explained by the choice of the generator for these architectures, namely an AR-FNN, which is usually built with the stated aim to capture auto-correlations [28]. Still, contrary to what one would expect, even though these two GAN architectures are relatively good at estimating the (positively valued) auto-correlation function, they fail in simulating the large values of the velocity increment distribution. We see in Fig. 4 that the AI models tested here fail to correctly model the larger values of the VAR increments’ distribu- tions, even though their excess kurtosis is insignificant. This hap- pens even when GANs can correctly replicate the auto-correlation function. The distribution of the angle θ is also best grasped by the Markov model. Again, SIGCWGAN comes close but significantly worse than the Markov model, followed by the RCGAN architec- ture. RCWGAN shows significant overestimation bias, while in the case of TimeGAN, the distribution of θ is concentrated on 45◦ and 135◦. For the distribution of the angle ϕ, all algorithms work relatively well. SigCWGAN and the Markov model work at the same level, with Markov performing better, but the results for the SigCWGAN lying within the margin of error. These results are in line with the ones published in Ref. [28] on the same data, with SigCWGAN performing slightly worse and the other GAN models performing slightly better. Notice that VAR(1) processes are Markov processes by con- struction, so it is not surprising that a Markov process reproduces so well this process. However, similar results are obtained for VAR processes of higher dimension. In Appendix A we show the results for VAR(p) processes with p = 2 and p = 3, and there again one observes that Markov processes surpass all the set of GANs architectures. Moreover, as will be discussed in the next subsection, for the eye-gaze trajectories, the results do not differ much from this. 4.2. Replicating empirical data For empirical data, examples of empirical eye-gaze trajecto- ries, as well as the respective modelled trajectories with the different models, are shown in the first column of Fig. 5. The distribution of the velocity increment (second column) shows again no heavy tails. However, while the Markov model’s distribution fits again considerably well with the empirical distri- bution, the GAN model’s inability to capture the extreme values is even stronger than for VAR processes. SigCWGAN works slightly better than the other architectures. As for the auto-correlation function, since we do not expect gaze trajectories to obey the Markov condition, it is normal to 7 P. Lencastre, M. Gjersdal, L.R. Gorjão et al. Physica D 453 (2023) 133831 Fig. 6. Results for reproducing the VAR(2) process with a Markov model and time-series GANs. For comparison with Fig. 4. expect a deviation between both functions. The SigCWGAN ar- chitecture comes close to the Markov model in modelling the auto-correlation function, while the other architectures are only able to partially capture the positive auto-correlations of the process. The distribution of angle θ is also well grasped by the Markov model. In particular, the Markov model is able to capture the pref- erential directions around the 0◦, 90◦, 180◦, 270◦. It is however unable to capture the finer details of this metric, smoothing some of the other picks in the distribution. It is possible that larger samples (trajectories) or a different choice of the kernel when computing the numerical distribution would lead to a better resolution. GANs, however, cannot capture this distribution at all. They replicate some of the fluctuations, but with significant biases and miss the preferential angles. For the distribution of the angle ϕ, again, the Markov model works better than any GAN. However, TimeGAN and RCWGAN are able to capture some distribution around the 180◦value. We see that even though SigCWGAN somewhat replicates the auto-correlation function, it does not capture the distribution of ϕ. Indeed, this time-series must be one rare example that has an angle between two increments around 180◦but that, at the same time, has a positive auto- correlation function. It is possible that not being able to replicate the larger values of the distribution, in order to capture the positive value auto-correlation function, this algorithm tends to create trajectories in the same direction. 5. Discussion and conclusions From the comparative analysis in the previous section, we conclude the Markov model outperforms all GAN architectures considered in this paper. Within the set of GAN architectures, it is possible to see that the SigCWGAN outperforms the rest of the GANS and that it performs at the level of a Markov implementa- tion when it comes to the distribution of ϕ, but slightly worse for the distribution of θ. The other GANs perform relatively worse and do not come statistically close to the efficacy of a Markov process, particularly when it comes to the distribution of θ. The fact that one specific GAN architecture can reproduce some of the statistics at the same level as a Markov process is good news for the AI community since it opens the door to their application to more complex processes. However, we provide evidence that simple Markov models are significantly better at modelling the distribution of the process and are themselves not as complex (black-box-like) as an AI method. Indeed, GAN im- plementations typically use a number of parameters two orders of magnitude larger than Markov models. Moreover, by simply computing a Markov transition matrix one might be able to assert other important features of the natural process (trajectory), e.g. if it is time-continuous or stationary [22]. Such drawbacks of GANs seem to be present in processes with a negligible excess kurtosis, such as VAR(p) processes, as well as 200 Hz free-viewing eye-gaze trajectory, which have typically a very large excess kurtosis. Thus, while we do not claim that non-parametric Markov models always outperform AI algorithms, we show that, when non-parametric models are needed, the implicit assumption of the universal preference of AI methods is not justified. This is done by showing that old-fashion math- ematical models outperform their AI counterparts both in a very simple synthetic time-series and in a highly complex empirical one. We thus recommend caution when employing AI to predict time-series without comparing them with simpler methods that humans can easily explain. 8 P. Lencastre, M. Gjersdal, L.R. Gorjão et al. Physica D 453 (2023) 133831 Fig. 7. Results for reproducing the VAR(3) process with a Markov model and time-series GANs. For comparison with Figs. 4 and 6. The evidence uncovered in this paper can be now extended in different ways. On one hand, while the GAN models considered here are some of the most used in AI approaches and the pro- cesses consider cover both Gaussian and non-Gaussian features, other GAN architectures and datasets could be considered. In particular, emphasis should be given to architectures aimed at capturing the extreme values of a distribution, as has been the case of SigCWGAN and TimeGAN. Datasets covering other types of processes could also help to a systematic approach to exploring the limits of our findings, namely including jump-diffusion [35] noise and intermittent processes [36]. On the other hand, extensions of the Markov model used here could be investigated, namely models with a Markov length longer than one time lag. Finally, a hybrid approach could be to use a GAN to model the residuals of a Markov process or train GANs to generate Markov matrices (eventually in more dimensions). We have compared our training with that of previous works on the same data [28] and, in most cases, found very similar training statistics and outcomes when training on the same data. The GANs tested here are conditional GANs, meaning that they use the previous points to calculate the following points. Thus, the number of points used in calculating the next set of points (typically represented a ‘‘p’’ in the literature). A systematic search of the optimal value of this parameter was performed and the value of p = 3 was chosen. Other aspects, such as the size of the network and the batch size were also optimised after comparing the outcomes of several trials. All in all, despite the claims of GAN’s ability to capture the overall time-evolution of a stochastic process this is not verified in complex time-series. Even in algorithms which, according to the authors, were able to capture extreme values of the data, this limitation is quite significant, with the GAN architectures not being able to capture the full spectrum of the auto-correlation function. At face value, the inability of AI methods to outper- form a conceptually simple mathematical process is surprising. When these methods are presented, their successes are high- lighted and further applications of these methods focus only on the case where they are successful. Nonetheless, they are constrained by the central limit theorem: the typical distribution of the GAN-generated data is the normal distribution. One possi- bility to overcome this would be to re-design the standard GAN architectures, enabling them to include noise inputs distributed according to α-stable distributions. Declaration of competing interest The authors declare that there are no interest to be stated. Data availability The authors do not have permission to share data. Acknowledgements The authors thank Oslo Metropolitan University for partial financial support, through the Nordic Center for Sustainable and Trustworthy AI Research (NordSTAR). Appendix A. Results for replicating VAR(2) and VAR(3) pro- cesses While gaze trajectories have a non-Markov behaviour it is also interesting to apply our methodology to synthetic processes that, 9 P. Lencastre, M. Gjersdal, L.R. Gorjão et al. Physica D 453 (2023) 133831 contrarily to the VAR(1) process, are also, by definition, non- Markov. These are the VAR(p = 2) processes and the VAR(p = 3) processes as defined in Eq. (4). In the VAR(2) process we have used φ1 = 0.5 and φ2 = 0.4 and in the VAR(3) process we have used φ1 = 0.3, φ2 = 0.3 and φ3 = 0.3. The correlation coefficient the two spacial dimensions was kept at 0.8 and, just like before, for each case we have created 85 thousand points time-series with a sampling time ∆t = 1. Results can be observer in Table 3 and in Figs. 6 and 7. In this case, we observed that some GAN-generated time- series diverged to infinity. This was the case for the RCWGAN in the VAR(2) case and for the RCWGAN and TimeGAN in the VAR(3) process. We found a similar behaviour with other choices of φ with RCGAN diverging at times too. SigCWGAN was not observed to diverge for convergent time-series. Changing the number of epochs in training or the learning rate did not seem to signifi- cantly affect some GANs, producing divergent series. Indeed, we observe that SigCWGAN typically replicates the auto-correlation function of the VAR(2) and VAR(3) at an accuracy similar to the case of VAR(1). As expected, this is not the case for a Markov process. However, given that the ANN that is used in the SigCWGAN (the AR-FNN) is explicitly built with the purpose of mimicking the auto-correlation function of the data and that this architecture fails to capture the distribution of ϕ, it is reasonable to assume that the algorithm is unable to replicate many significant aspects of the temporal dynamics of the process. When it comes to the distribution of the increments of a process, we see that, similarly to VAR(1) processes and gaze trajectories, GANs underestimate its moments, specially in the standard deviation. We also see that GANs fail in reproducing the distribution of θ showing that they do not accurately represent the relationship between the two spacial dimensions. In conclusion, for the case of VAR(2) and VAR(3) we see that one aspect of the temporal dynamics of the process (the auto-correlation function) is better replicated by one GAN, the SigCWGAN, while the other (the distribution of ϕ) is still far from the results produced by the Markov model. Moreover, GANs still fail to replicate the distribution of the increments and to capture correctly the relationship between the two spacial dimensions of the problem, which can be evaluated by the distribution of θ. Thus, even in the case of a simple synthetic data where the Markov hypothesis is not present, the advantages of GANs are still limited. Appendix B. About the training of GANs Training GANs is a challenging task since this is often not a stable process, where each epoch is better than the previous one, and where some pitfalls exist [8]. Two problems are usual, namely the vanishing gradients and the mode collapse. In the first one, the discriminator becomes so successful that neither the discriminator nor the generator is able to have any learning with successive epochs. In mode collapse the generator is able to fool the discriminator with just small different modes ignoring all the others, thus producing time-series that are all very similar among themselves. To solve this, one is typically advised to choose carefully the learning rate of both networks. In our implementation, we have indeed found that training a GAN for a longer period did not necessarily lead to better results. Moreover, we experienced some instances of mode collapse when trying to model real-time series and had to carefully calibrate learning rates. We found that training the GANs for around 200 epochs would decrease the train and testing error while also avoiding the pitfall of mode collapse. The weights of the ANNs were updated using the Adam optimiser [37]. Appendix C. Implementation of the Markov-chain model In a Markov model, we can generate a time-series by comput- ing Pr(Xt=n+1 = xn+1 | Xt=n = xn). We estimate this quantity empirically with the help of a Gaussian estimation kernel K as follows: Pr(Xt=n+1 = xn+1 | Xt=n = xn) = Pr(Xt=n+1 = xn+1, Xt=n = xn) Pr(Xt=n = xn) , (C.1) with Pr(Xt=n+1 = xn+1, Xt=n = xn) = 1 ( ˆN −1)2h2 ˆN−1 ∑ i=1 K ( xn+1 −ˆxi+1 h ) K ( xn −ˆxi h ) , (C.2) Pr(Xt=n = xn) = 1 h( ˆN −1) ˆN−1 ∑ i=1 K ( xn −ˆxi h ) , (C.3) where K ( xn −ˆxi h ) = 1 √ 2π exp ( −1 2 ( xn −ˆxi h )2) , (C.4) and h represents the bandwidth of the Gaussian estimation kernel K and it is calculated following Silverman’s rule [38]: h = ( 4 ˆσ 5 3 ˆN −3 ) 1 5 ≈1.06 ˆσ ( ˆN −1)−1/5 , (C.5) where ˆσ is the standard deviation of ˆx1 . . . ˆxn and ˆN the number of data points in our sample. When analysing empirical data, Pr(Xt=n+1 | Xt=n) can be represented as a matrix T of dimension Ns ×Ns with entries given by Ti,j = Pr ( Xt=n+1 ⊂[ki, ki+1) | Xt=n ⊂[kj, kj+1) ) , (C.6) with i, j ∈N, i, j ⊂[0, Ns] and km > kn ⇔m > n. Thus, if we observer the state Xt=n ⊂[kj, kj+1) we can calculate the probability of observing Xt=n+1 ⊂[ki, ki+1). When generating a new time-series, if it is found that Xt=n+1 ⊂[ki, ki+1), we assign a value to Xt=n+1 from the uniform distribution in the interval [ki, ki+1). The accuracy of this method depends on three major factors: Firstly, on the validity of the Markov condition (3); Secondly, on the number of states Ns, which is constrained by computational time (scaling approximately with N4 s for a two-dimensional pro- cess); Thirdly, accuracy is also affected by the amount of data in our sample ˆN, which impacts the bandwidth calculus h: the larger ˆN is, the smaller is the resulting value of h thus increasing the spatial resolution of the model. An implementation of this algorithm using python and numpy can be found in Github [39]. References [1] A. Flores, H. Tito-Chura, V. Yana-Mamani, Wind speed time series pre- diction with deep learning and data augmentation, in: Proceedings of SAI Intelligent Systems Conference, Springer, 2021, pp. 330–343, http: //dx.doi.org/10.1007/978-3-030-82193-7_22. [2] P.G. Lind, L. Vera-Tudela, M. Wächter, M. Kühn, J. Peinke, Normal behaviour models for wind turbine vibrations: Comparison of neural networks and a stochastic approach, Energies 10 (12) (2017) 1944, 3390/en10121944. [3] A. Russo, F. Raischel, P. Lind, Air quality prediction using optimal neural networks with stochastic variables, Atmos. Environ. 79 (2013) 822–830, 10 P. Lencastre, M. Gjersdal, L.R. Gorjão et al. Physica D 453 (2023) 133831 [4] J. Cao, Z. Li, J. Li, Financial time series forecasting model based on CEEMDAN and LSTM, Phys. A 519 (2019) 127–139, 1016/j.physa.2018.11.061. [5] P. Wang, X. Zheng, G. Ai, D. Liu, B. Zhu, Time series prediction for the epidemic trends of COVID-19 using the improved LSTM deep learning method: Case studies in Russia, Peru and Iran, Chaos Solitons Fractals 140 (2020) 110214, [6] F. Harrou, A. Dairi, F. Kadri, Y. Sun, Forecasting emergency department overcrowding: A deep learning framework, Chaos Solitons Fractals 139 (2020) 110247, [7] I.J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, Y. Bengio, Generative adversarial networks, 2014, http: //dx.doi.org/10.48550/arXiv.1406.2661, arXiv preprint arXiv:1406.2661. [8] E. Brophy, Z. Wang, Q. She, T. Ward, Generative adversarial networks in time series: A survey and taxonomy, 2021, arXiv.2107.11098, arXiv preprint arXiv:2107.11098. [9] D. Hazra, Y.-C. Byun, SynSigGAN: Generative adversarial networks for synthetic biomedical signal generation, Biology 9 (12) (2020) 441, http: //dx.doi.org/10.3390/biology9120441. [10] L. Yu, W. Zhang, J. Wang, Y. Yu, Seqgan: Sequence generative adversarial nets with policy gradient, in: Proceedings of the AAAI Conference on Artifi- cial Intelligence, Vol. 31, 2017, p. 1, URL AAAI/2017/PreliminaryPapers/12-Yu-L-14344.pdf. [11] O. Mogren, C-RNN-GAN: Continuous recurrent neural networks with ad- versarial training, 2016, arXiv preprint arXiv:1611.09904. [12] H.-W. Dong, W.-Y. Hsiao, L.-C. Yang, Y.-H. Yang, Musegan: Multi-track sequential generative adversarial networks for symbolic music genera- tion and accompaniment, in: Thirty-Second AAAI Conference on Artificial Intelligence, 2018, p. 1, URL musegan-aaai2018-paper.pdf. [13] Z. Lv, X. Huang, W. Cao, An improved GAN with transformers for pedestrian trajectory prediction models, Int. J. Intell. Syst. 37 (8) (2021) 4417–4436, [14] M. Wiese, R. Knobloch, R. Korn, P. Kretschmer, Quant GANs: Deep gen- eration of financial time series, Quant. Finance 20 (9) (2020) 1419–1440, [15] S. Berkovsky, R. Taib, I. Koprinska, E. Wang, Y. Zeng, J. Li, S. Kleitman, Detecting personality traits using eye-tracking data, in: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, 2019, pp. 1–12, [16] M. Steffens, B. Becker, C. Neumann, A. Kasparbauer, I. Meyhöfer, B. Weber, M. Mehta, R. Hurlemann, U. Ettinger, Effects of ketamine on brain function during smooth pursuit eye movements, Hum. Brain Mapp. 37 (11) (2016) 4047–4060, [17] P.M. Grace, T. Stanford, M. Gentgall, P.E. Rolan, Utility of saccadic eye movement analysis as an objective biomarker to detect the seda- tive interaction between opioids and sleep deprivation in opioid-naive and opioid-tolerant populations, J. Psychopharmacol. 24 (11) (2010) 1631–1640, [18] H. Chauhan, A. Prasad, J. Shukla, Engagement analysis of ADHD students using visual cues from eye tracker, in: Companion Publication of the 2020 International Conference on Multimodal Interaction, 2020, pp. 27–31, [19] A. Lev, Y. Braw, T. Elbaum, M. Wagner, Y. Rassovsky, Eye tracking during a continuous performance test: Utility for assessing ADHD pa- tients, J. Atten. Disord. 26 (2) (2022) 245–255, 1087054720972786. [20] T. Wadhera, D. Kakkar, Eye tracker: An assistive tool in diagnosis of autism spectrum disorder, in: Emerging Trends in the Diagnosis and Intervention of Neurodevelopmental Disorders, IGI Global, 2019, pp. 125–152, http: //dx.doi.org/10.4018/978-1-5225-7004-2.ch007. [21] B. Hayes, et al., First links in the Markov chain, Am. Sci. 101 (2) (2013) 252, [22] P. Lencastre, F. Raischel, T. Rogers, P. Lind, From empirical data to time- inhomogeneous continuous Markov processes, Phys. Rev. E 93 (3) (2016) 032135, [23] R. Huang, B. Xu, D. Schuurmans, C. Szepesvári, Learning with a strong adversary, 2015, [24] S.L. Hyland, C. Esteban, G. Rätsch, Real-valued (medical) time series generation with recurrent conditional GANs, 2017, 48550/arXiv.1706.02633, arXiv preprint arXiv:1706.02633. [25] S. Hochreiter, J. Schmidhuber, Long short-term memory, Neural Comput. 9 (8) (1997) 1735–1780, [26] J. Yoon, D. Jarrett, M. Van der Schaar, Time-series generative adversarial networks, Adv. Neural Inf. Process. Syst. 32 (2019) URL neurips.cc/paper/8789-time-series-generative-adversarial-networks.pdf. [27] D.P. Kingma, M. Welling, et al., An introduction to variational autoencoders, Found. Trends Mach. Learn. 12 (4) (2019) 307–392, 1561/2200000056. [28] H. Ni, L. Szpruch, M. Wiese, S. Liao, B. Xiao, Conditional sig-Wasserstein GANs for time series generation, 2020, 2006.05421, arXiv preprint arXiv:2006.05421. [29] H. Ni, L. Szpruch, M. Wiese, S. Liao, B. Xiao, Conditional-Sig- Wasserstein-GANs, 2020, URL Sig-Wasserstein-GANs. [30] A.A. Markov, Extension of the law of large numbers to dependent quantities, Izv. Fiz.-Matem. Obsch. Kazan Univ. (2nd Ser.) 15 (1) (1906) 135–156. [31] R.M. Klein, W.J. MacInnes, Inhibition of return is a foraging facilitator in visual search, Psychol. Sci. 10 (4) (1999) 346–352, 1111/1467-9280.00166. [32] A. Borji, Pros and cons of GAN evaluation measures, Comput. Vis. Image Underst. 179 (2019) 41–65, [33] A. Borji, Pros and cons of GAN evaluation measures: New developments, Comput. Vis. Image Underst. 215 (2022) 103329, j.cviu.2021.103329. [34] K. Shmelkov, C. Schmid, K. Alahari, How good is my GAN? in: Proceed- ings of the European Conference on Computer Vision (ECCV), 2018, pp. 213–229, [35] L. Rydin Gorjão, D. Witthaut, P.G. Lind, JumpDiff: Non-parametric numer- ical estimation of jump-diffusion processes, J. Stat. Softw. 15 (2023) 1–22, [36] P. Lencastre, S. Denysov, A. Yazidi, P.G. Lind, Uncovering Lévy flights and intermittent processes from empirical time series: a theoretical framework to classify, 2023, in prepartion. [37] D.P. Kingma, J. Ba, Adam: A method for stochastic optimization, 2014, http: //dx.doi.org/10.48550/arXiv.1412.6980, arXiv preprint arXiv:1412.6980. [38] B.W. Silverman, Density Estimation for Statistics and Data Analysis, first ed., Routledge, New York, 1998, [39] P. Lencastre, Markov model, 2023, URL Markov-model. 11"
An Intelligent Collaborative Image-Sensing System for Disease Detection,"Djenouri, Youcef and Belhadi, Asma and Yazidi, Anis and Srivastava, Gautam and Chatterjee, Pushpita and Lin, Jerry Chun-Wei",2023,2.0,23,IEEE Sensors Journal,article,"IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023
947
An Intelligent Collaborative Image-Sensing
System for Disease Detection
Youcef Djenouri
, Asma Belhadi, Anis Yazidi
, Gautam Srivastava
, Senior Member, IEEE,
Pushpita Chatterjee
, and Jerry Chun-Wei Lin
, Senior Member, IEEE
Abstract—With the growth of smart medical devices and
applications in smart hospitals, home care facilities, nursing,
and the Internet of Medical Things (IoMT) are becoming more
ubiquitous. It uses smart medical devices and cloud comput-
ing services, and basic Internet of Things (IoT) technology,
to detect key body indicators, monitor health situations, and
generate multivariate data to provide just-in-time healthcare
services. In this article, we present a novel collaborative
disease detection system based on IoMT amalgamated with
captured image data. The system can be based on intelligent
agents, where every agent explores the interaction between
different medical data obtained by smart sensor devicesusing reinforcementlearning as well as targets to detectdiseases.
The agents then collaborate to make a reliable conclusion about the detected diseases. Intensive experiments were
conducted using medical data. The results show the importance of using intelligent agents for disease detection in
healthcare decision-making. Moreover, collaboration increases the detection rate, with numerical results showing the
superiority of the proposed framework compared with baseline solutions for disease detection.
Index Terms— Communicable disease, correlation, multiagent system (MAS), smart sensor data.
I. INTRODUCTION
S
MART healthcare is a framework that leverages wear-
able devices, the Internet of Medical Things (IoMT),
powerful machine learning algorithms, and wireless commu-
nication technology to connect people, resources, and orga-
nizations as well as then intelligently manage and respond
Manuscript received 21 April 2022; revised 9 July 2022; accepted
13 August 2022. Date of publication 2 September 2022; date of current
version 12 January 2023. The associate editor coordinating the review
of this article and approving it for publication was Dr. Hari P. Gupta.
(Corresponding author: Jerry Chun-Wei Lin.)
Youcef Djenouri is with SINTEF Digital, 0610 Oslo, Norway (e-mail:
youcef.djenouri@sintef.no).
Asma Belhadi is with the School of Economics, Innovation and
Technology, Kristiania University College, 0107 Oslo, Norway (e-mail:
asma.belhadi@kristiania.no).
Anis Yazidi is with the Department of Computer Science, OsloMet-Oslo
Metropolitan University, 0167 Oslo, Norway, also with the Department of
Neurosurgery, Oslo University Hospital, 0450 Oslo, Norway, and also with
the Department of Computer Science, Norwegian University of Science
and Technology, 7491 Trondheim, Norway (e-mail: anisy@oslomet.no).
Gautam Srivastava is with the Department of Math and Computer
Science, Brandon University, Brandon, MB R7A 6A9, Canada, also with
Research Centre for Interneural Computing, China Medical University,
Taichung 404, Taiwan, and also with the Department of Computer
Science and Math, Lebanese American University, Beirut 1102, Lebanon
(e-mail: SRIVASTAVAG@brandonu.ca).
Pushpita Chatterjee is with the Department of Computer Science, Ten-
nessee State University, Nashville, TN 37209 USA (e-mail: pushpita.c@
ieee.org).
Jerry Chun-Wei Lin is with the Department of Computer Sci-
ence, Electrical Engineering and Mathematical Sciences, Western Nor-
way University of Applied Sciences, 5063 Bergen, Norway (e-mail:
jerrylin@ieee.org).
Digital Object Identiﬁer 10.1109/JSEN.2022.3202437
to healthcare needs [1], [2]. Medical sensors, often referred
to as IoMT, are a critical component of smart healthcare.
IoMT may be able to be driving today’s smart healthcare
by leveraging cutting-edge technologies, such as artiﬁcial
intelligence (AI), cloud computing, coupled with the emer-
gent sixth generation (6G) mobile networks. The increasing
use of IoMT devices, as well as data-driven apps, may
be able to be contributing to positive effects ranging from
improved user-health attitudes and early disease detection to
higher-quality care and a more cost-effective smart healthcare
ecosystem.
It may be expected that the integration of the Internet of
the Things (IoT) with medical devices in a smart healthcare
system will increase the quality and the efﬁciency of services
for patients, especially for patients with chronic diseases who
need continuous care. With the support of Internet communica-
tions, IoMT enables continuous monitoring of important phys-
iological functions in, otherwise, healthy individuals, so that
diseases may be able to be detected, and appropriate action
may be able to be taken immediately. This may be able to be
particularly important during pandemics, such as the recent
Coronavirus-disease pandemic that raged globally [3], [4],
where taking into account our advanced and technologically
advanced healthcare systems, which tend to include both
medical personnel with support systems, saw themselves under
an absurd amount of stress [5]. The demand for a remote,
autonomous, and ubiquitous IoMT architecture may be able
to be greater than ever [6].
1558-1748 © 2022 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 948
IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023
The integration of smart sensors and controls within the
Internet also has turned any and all “so-called” cyber-physical
systems (CPSs) into IoMT, which has recently emerged as
one of the main driving forces behind the fourth industrial
revolution nicknamed Industry 4.0 [7]. In these directions,
healthcare itself may be able to be also undergoing a digital
revolution through the integration of smart devices. On the
other hand, the number of IoMT devices is expected to
increase signiﬁcantly over the next few years. Furthermore,
the heterogeneity of the various IoMT components (network
interfaces, data format, data semantics, and communication
protocols) will lead to difﬁculties in interoperability and data
protection [7]. In this regard, a ubiquitous, and collaborative
health platform for all smart devices must be adaptable enough
to accommodate all these concepts.
A. Motivation
Technologies based on AI are very promising in this regard
and in medical applications in general [8], [9]. These include
techniques, such as multiagent systems (MASs), networks
that incorporate deep learning (DL), and advanced computa-
tional techniques, such as evolutionary computation (EC) or
other well-known ones. DL is a well-known branch of AI
that can involve the creation of complicated but complete
models with a high number of layers and a large number
of hyperparameters. These models are not only capable of
learning from large amounts of data, but they can also
directly extract important aspects from these huge amounts of
data. Medical data analysis, especially disease detection, is a
fascinating area of DL [10], [11], [12], [13]. For example,
Coronavirus-disease pandemic samples were used to build
an intelligent model to calculate infection rates [10]. The
latter work uses both supervised and unsupervised learning
methods, resulting in a 40% increase in detection speed.
Transfer learning was used to evaluate pathogen frames and
validate Coronavirus-disease pandemic instances with typical
virus-based pneumonia [11]. The result highlights the value of
using intelligent approaches for Coronavirus-disease pandemic
diagnosis.
We may be able to also observe examples that have been
substantially explored in the newer, fresh ﬁeld of distributed
DL [14], [15], [16], [17], [18] by studying various types of DL
models that are well established in medicine as well as disease
detection. The identiﬁcation of illnesses is the primary objec-
tive of these technologies, particularly the distributed ones.
This will assist medical professionals in making decisions that
are acceptable and fair within the realm of medicine. The
intricacy of the data is the single most critical barrier that
makes disease detection more difﬁcult than it would otherwise
be. Indeed, diseases may be able to have different forms and
manifestations that are difﬁcult to detect. We are researching
the possibility of developing a comprehensive framework
that makes use of DL to get beyond these disadvantages
and MASs.
The large number of hyperparameters provided by DL
models is another signiﬁcant obstacle to the disease detection
process. The random selection of these values leads to a
signiﬁcant decrease in the overall performance during the
learning phase. Moreover, the process of setting the para-
meters for such frameworks takes a long time, and there
is no guarantee of satisfactory convergence. The effective-
ness of EC in tackling complicated problems [19], [20] has
led this research to tune the parameters of the proposed
framework.
B. Contributions
To the best of our knowledge, this is the ﬁrst paper to take
an in-depth look at combining MASs, EC, and DL for disease
detection. Below is a list of the major contributions.
1) We provide an collaborative system for disease detec-
tion (ALMOST), a new paradigm that uses DL, MAS,
and EC to identify diseases. To learn from medical
training data and different diseases, each and every
agent uses its DL architecture. Each iteration of the
architecture establishes communication between agents
to share information and reduce the error learning rate.
2) We
show
how
many
convolutional
neural
net-
works (CNNs) may be able to work together to process
large amounts of data in the medical domain. Several
optimizations, such as batch normalization and dropout
algorithms, ensure that the CNN processes medical data
with great accuracy.
3) To intelligently explore the conﬁguration space of dif-
ferent hyper parameter values, we propose a new evo-
lutionary computational technique based on a genetic
behavior. This approach improves the convergence of
ALMOST in predicting diseases from medical data.
4) Extensive testing was conducted to demonstrate the
applicability
of
ALMOST.
The
ﬁndings
demon-
strated that the ALMOST performs better than other
well-known illness identiﬁcation algorithms in terms of
the quality of the information and also in terms of
computation time when training large medical data.
From here on, this article is arranged as follows. Section II
provides an in-depth examination of related studies on disease
detection. Section III provides a comprehensive understanding
of the ALMOST methodology. A performance evaluation
of ALMOST is shown in Section IV. Section V discusses
the major consequences of using ALMOST on medical data
and the prospects for the future of the research. Section VI
concludes this article.
II. LITERATURE REVIEW
A. AI-Based Solutions
Pattern mining [21], [22], [23] is one of the approaches
to derive and reveal the potential relationships of the items
in the databases. Nawaz et al. [24] investigated the use of
pattern mining in the analysis of medical diseases. The set of
Coronavirus-disease pandemic patient data is converted into a
set of transactions, where each and every patient is represented
by a transaction, and each Coronavirus-disease pandemic-
based information related to the patient is represented by an
item. A pattern mining algorithm is then applied to the set
of transactions to extract relevant patterns. The latter was
used to identify diseases based on the correlation between
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 DJENOURI et al.: INTELLIGENT COLLABORATIVE IMAGE-SENSING SYSTEM FOR DISEASE DETECTION
949
medical data features. Wang et al. [10] automated the process
of image assessment by exploring the segmentation as well
as classiﬁcation of DL-based architectures. Thus, we may be
able to achieve a reasonable estimate of the always illusory
Coronavirus-disease pandemic infection rate. Wang et al. [11]
found viral pneumonia from more than 1000 images of
pathogens. The experiments showed a clear beneﬁt of using
intelligent methods for disease diagnosis. Yan et al. [25] used
a topological approach to analyze nonlinear dynamics to exam-
ine gait complexity ﬂuctuations in Parkinson’s disease patients
to detect the Freezing-of-Gait episode. The 3-D acceleration
data from eight individuals with symptoms are used to extract
relevant features from the acceleration signals using topo-
logical analysis of the reconstructed process. Jain et al. [26]
demonstrated the performances of using Inception-V3 for
Coronavirus-disease pandemic disease identiﬁcation through
data enrichment. Sedik et al. [27] demonstrated the efﬁciency
of using CNN in Coronavirus-disease pandemic identiﬁca-
tion. This article also demonstrated the importance of multi-
modal data, in which the authors collected medical data from
multiple sources, including tomographic and X-ray images.
Manoj et al. [28] took a look at an incentive-based system,
where the Coronavirus pandemic could be better planned for
using an incentive system using block chain. In this solution,
governments globally can prepare and plan better strategies
for ﬁghting the virus using the availability of data from
both a geographic point of view but also qualitative data
around the disease. By being able to have more accurate
and better data around the pandemic, and have it available
in a decentralized fashion being managed by block chain,
will allow a faster response time to virus outbreaks in the
future.
B. Hybrid-Based Solutions
Chae et al. [29] predicted infectious diseases by success-
fully exploring long-term short-term memory with autoregres-
sive moving average. The proposed model is improved by
the ensemble learning mechanism. Therefore, more sources
of information were collected and extracted from social net-
works. Ahuja et al. [30] implemented four DL architectures
(ResNet18, ResNet50, ResNet101, and SqueezeNet) to capture
Coronavirus-disease pandemic from medical lung CT-scan
data. The models are pretrained using a large collection of
images from different domains. The transfer learning mech-
anism is used to learn the Coronavirus-disease pandemic
cases from the medical data. Wong et al. [31] analyzed the
effect of data-driven solutions for infectious diseases. They
explored the combination of various data management as well
as AI techniques to help healthcare professionals mitigate
the risk of disease detection and enable better diagnosis in
a smart healthcare environment. Hirano et al. [32] classiﬁed
the various diseases using the model for use in DL. The
classiﬁcation models developed are based on three types of
medical images: photographic images, X-ray chest images, and
retinopathy images. Three applications are then investigated,
including skin cancer, transmissible diabetics, and pneumonia.
Transfer learning with the adversarial neural network has been
implemented. The transfer learning mechanism allows the
model developed from various medical sources to be trained,
and the adversarial network, which may be able to handle both
non-targeted and targeted attacks and identify fake medical
images. Jamshidi et al. [33] process multiple sources of med-
ical data by exploring generative adversarial networks, extreme
learning, and long-term short-term memory. This combination
not only enables the handling of heterogeneous medical data
but also increases the disease detection rate. Singh et al. [34]
worked on developing a hybrid model based on both decom-
positions and DL for disease detection. Segments are created
by applying the k-means algorithm to medical data. These
segments are then fed into the CNN to predict diseases based
on the original medical images. Shalbaf et al. [35] imple-
mented 15 pre-trained DL models to automatically identify
the Coronavirus-disease pandemic. These models are based on
three well-known classiﬁcation-based architectures, including
Inception, ResNet, and DenseNet. Ensemble learning is then
explored to merge the results obtained from these models using
the majority voting strategy.
III. ALMOST: AN COLLABORATIVE SYSTEM
FOR DISEASE DETECTION
A. Principle
We begin by explaining the most important aspects of
ALMOST. ALMOST is a combination of many intelligent
strategies for solving disease detection problems. The CNN
is used for disease diagnosis. To correctly execute ALMOST
in a distributed environment where each agent can beneﬁt from
the environment through the reinforcement learning paradigm,
the use of an MAS is investigated. Since DL requires setting
a large number of parameters, up to a million for some
architectures, EC is used to determine the best settings for real-
time processing. The components of ALMOST are discussed
in the next parts.
B. Learning Phase
The learning phase is done with the help of CNNs [36].
CNN is a common type of deep architecture in computer
vision applications, such as object detection and identiﬁcation.
In recent years, the adaptability of this method has helped
both time series and text data. CNN is based on the concept
of extracting features from matrix data using convolutional
ﬁlters. Convolutional ﬁlters create a new image by applying
a series of weights to the matrix data of each pixel in the
image. As a result, a new image is generated. In addition, well-
known operators for DL models, such as batch normalization
and dropout, are used during training to increase the accuracy
of the proposed framework. This was achieved using the
dropout method. Batch normalization is one of the factors
that help the network to converge faster, while the dropout
method acts as a regulator that prevents the network from
overﬁtting. These two methods are necessary for the network
to achieve high accuracy. Below is a complete description of
these components.
1) Batch Normalization: To efﬁciently train a large number
of layers, we used the batch normalization technique in
all steps of the training phase. With only a few epochs,
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 950
IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023
the learning process may be able to converge better.
Batch normalization is performed after each and every
convolutional layer in the CNN.
2) Dropout: It is a technique that allows you to avoid over
adaptation during training. In each and every phase,
the outputs of the neurons in the hidden layers are
randomly skipped. Propagating a deep network with a
constrained number of weights may be thought of as a
straightforward method for bringing about convergence
of predictions during the inference phase.
C. Multiagents Systems
The MAS is used to learn the different diseases in the
training phase. The agents collaborate using the reinforcement
learning process. Consider the tuple ⟨A, S, U, R⟩, an MAS is
deﬁned by A. There are Aagents in total, and for the purposes
of this discussion, each of them is treated as if it were an
independent Markov decision process. A ﬁnite collection of
environmental states is represented by the variable S, a set
of actions by the variable U, and a reward function by the
variable R. The methods presented in A describe not only how
each agent should behave given the current situation, but also
how it should decide on the appropriate actions. For instance,
in the process of disease detection, the mission of each agent is
to identify the most effective tactic that maximizes the value
of the target objective function, which may be the number
of diseases that are accurately identiﬁed. We will discuss the
many parts that make up the MAS that we have designed by
the sections as follows.
1) Environment: The environment may be thought of as
a collection of databases that hold a massive quantity
of data that were gathered by various intelligent sensor
devices. As a result, the environment is able to create
certain conditions for training the agents and determine
the optimal actions.
2) State: The next action of each and every agent is deter-
mined by the decisions made in earlier phases. The state
of each agent is, thus, composed of two distinct parts:
the data being processed and a collection of actions
completed in the past. When calculating the size of the
state space S, the number of observations contained in
the database is taken into account.
3) Action: It is the assignment of each and every obser-
vation in the database’s decision-making behavior. For
instance, a detection task is the assignment of each and
every disease category.
4) Reward: It is essential to decide on an acceptable reward
function. It makes it possible for each agent in A to
have a more fruitful learning experience. Using data that
included ground truths, we crafted a reward in response
to the behaviors of the agent.
Therefore, the ﬁrst thing each agent does is to perform
a scan of the data collected by the ith intelligent sensor.
This is denoted by the notation Ai. It then computes the
ﬁrst observation of the ith intelligent sensor, and all future
observations of that sensor. The ground truth for the ﬁrst
observation is used in the creation of a reward function speciﬁc
to that choice. This approach is repeated for each of the ith
smart sensor observations. As a result, a set of local options,
denoted LDi, is generated for each agent Ai. The agents then
learn from the local decisions {LDi} to optimally ﬁnd the
global decision. This learning is realized through the process
of reinforcement learning, where the best agents that have a
high score for their local decisions receive a reward.
D. Hyperparameters Optimization
To achieve optimal performance, we apply an evolutionary-
based technique to optimize hyperparameters. The adaptation
of the genetic algorithm is proposed due to its known balance
of intensiﬁcation and diversiﬁcation. A complete description
of the proposed algorithm is given for solving our hyper
parameter optimization problem.
Let HP = {HP1, HP2, . . . , HPr} be the set of hyperpa-
rameters, where r is the number of hyperparameters in the
evolved ALMOST. Each HPi represents a set of the possible
values of the hyperparameter in question. The conﬁguration
space C is then deﬁned by the set of all possible conﬁgurations,
where each and every conﬁguration is a vector. The possible
values of all hyperparameters belong to HP. When it comes
to hyperparameter optimization, our methodology focuses on
determining the ideal conﬁguration that provides the highest
level of accuracy. The conﬁguration space is deﬁned by the
total number of possible hyper parameter values, as given in
|C| =
r
i=1
|HPi|.
(1)
Because of the vastness of the conﬁguration space, ﬁnding
the ideal solutions requires considerable computational effort.
Consider the epoch parameter, which has a max value of
1000, the error rate, which has a max value of 100, as well
as the number of agents in the evolved model, which has
a max value of 100; then, the search space will include
ten million conﬁgurations, so it is not possible to apply
exhaustive search methods in this case. To solve this challenge,
evolutionary computational methods are used. Below are the
main components of our solution.
1) Population Initialization: We are trying to distribute |P|,
which is the initial population, noted P. This initial population
should be uniformly distributed in the conﬁguration space C.
Proper examination of each and every of the numerous alter-
native conﬁgurations that tend to cover most locations within
C may be able to then be performed using this uniform
distribution technique. We must ﬁrst create the population,
taking diversity into account.
This process begins with the random generation of an indi-
vidual represented by a single C conﬁguration. It is possible
that after starting with this individual, we can generate more
|P|−1, assuming that each newly formed individual is differ-
ent from the previously generated individuals. We could use
a distance measure between two successive conﬁgurations to
evaluate dissimilarity based on the individuals formed in those
conﬁgurations. This would be done based on the individuals
generated in those conﬁgurations. The original population,
denoted by the variable P, should, in turn, be able to maximize
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 DJENOURI et al.: INTELLIGENT COLLABORATIVE IMAGE-SENSING SYSTEM FOR DISEASE DETECTION
951
the diversiﬁcation function shown in
Diversify(P) =
|P|

i=1
|P|

j=1
Distance(Ci, C j)
(2)
where Distance(Ci, C j) is the distance between the conﬁgura-
tions of the ith and the jth individuals, respectively.
2) Crossover: To produce new offspring, each and every of
the two individuals in the current population goes through the
following steps.
1) We start at 1 and work our way up to r, creating a
random sequence of crossing points. At each of these
points, we divide the intersection into its left and right
halves, respectively.
2) Both the left-hand side of the original, which is copied
to the left-hand side of the ﬁrst descendant, and the
right-hand side of the original, which is copied to the
right-hand side of the second descendant, are descen-
dants of each other.
3) The right-hand side of the second person is inherited
by the ﬁrst generation, while the left-hand side of the
second individual is inherited by the second generation.
3) Mutation: Mutation facilitates the search for diversity.
We use a strategy in which the value of a single parameter
is randomly varied in every single one of the conﬁgurations
currently in use. The mutation point is chosen randomly and
can have a value between 1 and r, depending on the method.
At each iteration, the value of the mutation point is changed
in the descendants generated by the crossover operator.
4) Fitness Function: Identifying diseases with the highest
possible degree of precision is the goal of the ALMOST
framework. Therefore, to assign points to individuals within
populations, we use the following function:
Fitness(Ci) = DetectionALMOST(Ci).
(3)
Note that the following hold.
1) Ci
is a representation of the conﬁguration of the
ith individual in the population.
2) DetectionALMOST(Ci) indicates the ratio for disease
detection using the developed ALMOST based on the Ci.
Based on these actions, we presented the following method
for optimizing hyperparameter values. In the beginning, the
initial population size, deﬁned as |P|, is randomly gener-
ated. Then, each and every individual is constructed using
population initialization. Then, mutation, and crossover with
mutation and crossover rates (Mr and Cr), is used to generate
conﬁgurations from C. To keep the population size constant,
each individual is evaluated against the ﬁtness function, focus-
ing on maintaining the highest quality |P| individuals. All
others are now deleted. This procedure is then continued
endlessly until the max number of iterations (IMAX) is
reached.
E. Description
Algorithm 1 shows the pseudocode of ALMOST for each
and every agent. The process begins by building the model for
use in DL represented by the CNN with batch normalization
and dropout layers (from lines 4 to 5). The batches of data
Algorithm 1 ALMOST Pseudocode for Each Agent
1: Input: I = {I1, I2, . . . , Im}: the set of m images collected
from sensors.
2: Output: model: The trained model to detect the disease;
DD: the set of the disease detected from I.
3: model ←C N N();
4: model ←model ∪BatchNormalization();
5: model ←model ∪Dropout()
6: Batches ←CreatingBatches(D);
7: Hyper_Param ←G A( f it(model, Batches));
8: DD ←In f erence(Inew, model, Hyper_Param);
9: return < model, DD >.
are created from the input images I in line 6. Then, the
genetic algorithm is applied to optimize the hyperparameters
of the model for use in DL by performing the training phase
on the created batches (line 7). The inference phase is then
run on the trained model to identify the disease of the new
image (line 8). The output of the algorithm is the set of
detected diseases DD and the trained disease detection model
(line 11).
IV. PERFORMANCE EVALUATION
Extensive testing was performed on known medical datasets
speciﬁcally designed for disease detection applications to
validate the use of the proposed ALMOST framework. Exper-
iments were conducted using a desktop computer equipped
with 16 GB of primary memory and an Intel Core i7 processor
for optimal performance. PythonTorch was used for the actual
implementation of each algorithm. We used the Kvasir [37]
medical database to validate the applicability of ALMOST in
disease detection, for disease data for the human digestive
system. The aim is to automate the detection of endoscopic
ﬁndings in the esophagus, stomach, intestines, and rectum. It is
available in two versions. The ﬁrst version, called Kvasir (v1),
consists of 4000 images grouped into eight classes showing
anatomical landmarks, pathological ﬁndings, or endoscopic
procedures. The second version, called Kvasir (v2), expands
on the ﬁrst version and consists of 8000 images with the same
number of classes.
A. Parameter Setting
In ALMOST, several parameters need to be optimized,
including the number of agents, the number of generations, the
crossover and mutation rates, and the population size. Choos-
ing optimal values for these parameters is critical for better
performance of the ALMOST framework. In this experiment,
we analyze the behavior of ALMOST at different values for
the number of agents, number of generations, crossover rate,
and the mutation rate. We varied the number of agents from
2 to 20, the number of generations and population size from
10 to 100, and the crossover rate and mutation rate from
0.01 to 0.99. The behavior of ALMOST may be able to be
summarized as follows.
1) Number of Agents: The experiments showed that when
we vary the number of agents from 2 to 20, the accuracy
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 952
IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023
TABLE I
SUMMARY OF PARAMETER SETTING OF ALMOST
TABLE II
ALMOST VERSUS DISEASE DETECTION SOLUTIONS
of ALMOST increases until ﬁve agents for Kvasir (V1)
and eight agents for Kvasir (V2) where stabilization of
the accuracy is observed.
2) Number Generations: The experiments showed that
when we vary the number of generations from 10 to 100,
the accuracy of ALMOST increases until 45 generations
for Kvasir (V1), and 58 generations for Kvasir (V2)
where stabilization of the accuracy is observed.
3) Population Size: The experiments showed that when we
vary the population size from 10 to 100, the accuracy of
ALMOST increases until 85 individuals for Kvasir (V1),
and 93 individuals for Kvasir (V2) where stabilization
of the accuracy is observed.
4) Crossover Rate: The experiments showed that when we
vary the crossover from 0.01 to 0.99, the accuracy of
ALMOST increases until 0.35 for Kvasir (V1), as well
as 0.47 for Kvasir (V2) where stabilization of the
accuracy is observed.
5) Mutation Rate: The experiments showed when we
vary the mutation from 0.01 to 0.99, the accuracy of
ALMOST increases until 0.53 for Kvasir (V1), as well
as 0.61 for Kvasir (V2) where the stabilization of the
accuracy is observed.
Table I gives the optimal values of the parameters used in
ALMOST for both Kvasir (v1) and Kvasir (v2). The next
experiments aim to validate the usefulness of the proposed
ALMOST framework for disease detection. To reach this
conclusion, an intensive analysis was performed by comparing
ALMOST with the baseline solutions InceptionResNet [34]
and DenseNet [35]). The detailed results with a full explana-
tion are shown below.
B. Quality of Outputs
Table II shows the quality of results from ALMOST and
the baseline solutions: InceptionResNet, DenseNet on Kvasir
(V1), and Kvasir (V2). We varied the percentage of images
used for training from 1000 to 4000 for Kvasir (V1) and
from 1000 to 8000 images for Kvasir (V2). We then calculate
Fig. 1.
ALMOST versus advanced disease detection solutions with
different numbers of error loss values (0.10, 0.08, 0.05, 0.02, and 0.01).
the quality of the results represented by the F1 and accu-
racy formulas. The results show the superiority of ALMOST
compared with the baseline solutions for all scenarios. Thus,
the accuracy of ALMOST is 0.96 when all the data from
Kvasir (V2) are processed, while the accuracy of the two
solutions is less than 0.80 when the same data are trained.
This great performance is due to the efﬁcient components
of ALMOST represented by the DL solution and the MASs,
and the accurate way of the hyperoptimization process. Fig. 2
shows a case study of ALMOST. The ﬁrst three images are
considered as esophagitis disease, and the second three images
are considered as polyps disease, where the last three images
are considered as ulcerative colitis disease.
C. ALMOST for Large-Scale Data
In the next experiment, we will examine the scalability of
ALMOST compared with the baseline solutions when it comes
to processing large amounts of data. For comparison, we will
use Xception [38] and SqueezeNet [39]. These algorithms
have proven their usefulness in a variety of different contexts,
including training huge datasets. Different training scenarios
with different data sizes of Kvasir (v1) and Kvasir (v2) are
run. Data duplication is generated by multiplying Kvasir (v1)
and Kvasir (v2) multiple times (1000, 10000, and 100000).
For each and every redundant sample, changes are generated
using a generative adversarial network. We varied the error
loss to be optimized from 0.10 to 0.01, and the results are
given in Fig. 1. From these results, we may be able to see the
clear superiority of ALMOST over the other two solutions in
terms of training time. This performance may be able to be
explained by the fact that ALMOST is optimized DL where
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 DJENOURI et al.: INTELLIGENT COLLABORATIVE IMAGE-SENSING SYSTEM FOR DISEASE DETECTION
953
Fig. 2.
Case study of ALMOST: the ﬁrst three images are considered as esophagitis disease, and the second three images are considered as
polyps disease, where the last three images are considered as ulcerative colitis disease.
the collaboration between the different agents accelerates the
training process.
V. DISCUSSION AND FUTURE DIRECTION
The primary beneﬁts of applying ALMOST to disease
detection data are presented in this section. We also make
some recommendations for how to improve the ALMOST
framework.
1) The effective combination of intelligent technologies in
the form of DL, MASs, and metaheuristics leads to
a high level of precision. For real-time medical data
management and disease detection, runtime performance
is still a challenge. The development of hybrid systems
that combine evolutionary and exact approaches [40]
to improve the performance of ALMOST could be an
interesting avenue.
2) The proposed methodology provides better results than
previous approaches. It would extremely fascinating to
study the results of ALMOST for other smart healthcare
applications, such as brain tumor detection [41], as well
as surgery [42].
3) Output interpretation is a challenge in ALMOST.
It relies on black-box models that do not implicitly
explain the process of output interpretation. Health-
care practitioners need to understand how the given
output is produced to trust it. This problem is being
addressed by the emerging discipline of explainable
AI (XAI). We intend to incorporate XAI approaches
into ALMOST. This will allow for a more accurate
interpretation of the results from ALMOST.
VI. CONCLUSION
In this article, an intelligent collaborative system for dis-
ease detection is proposed. It studied the different interac-
tions between the medical data using intelligent agents with
an efﬁcient reinforcement learning mechanism. This enables
signiﬁcant determination of various diseases in healthcare
systems. The proposed system was tested on different medical
datasets. The initial results showed the usefulness of using
intelligent agents for healthcare diagnosis. The numerical
results can be seen to also clearly visualize the strength of our
proposed framework when directly compared with baseline
methodologies when focusing on the rate of disease detection.
REFERENCES
[1] R. Yadav et al., “Smart healthcare: RL-based task ofﬂoading scheme
for edge-enable sensor networks,” IEEE Sensors J., vol. 21, no. 22,
pp. 24910–24918, Nov. 2021.
[2] L. Babangida, T. Perumal, N. Mustapha, and R. Yaakob, “Internet of
Things (IoT) based activity recognition strategies in smart homes: A
review,” IEEE Sensors J., vol. 22, no. 9, pp. 8327–8336, May 2022.
[3] Y. Han and H. Yang, “The transmission and diagnosis of 2019 novel
coronavirus infection disease (COVID-19): A Chinese perspective,”
J. Med. Virol., vol. 92, no. 6, pp. 639–644, 2020.
[4] J. He, Y. Guo, R. Mao, and J. Zhang, “Proportion of asymptomatic
coronavirus disease 2019: A systematic review and meta-analysis,”
J. Med. Virol., vol. 93, no. 2, pp. 820–830, 2021.
[5] E. J. Emanuel et al., “Fair allocation of scarce medical resources in
the time of COVID-19,” New England J. Med., vol. 382, no. 21,
pp. 2049–2055, May 2020.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 954
IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023
[6] T. Yang, M. Gentile, C.-F. Shen, and C.-M. Cheng, “Combining point-
of-care diagnostics and internet of medical things (IoMT) to combat the
COVID-19 pandemic,” Diagnostics, vol. 10, no. 4, p. 224, Apr. 2020.
[7] L. M. Camarinha-Matos, R. Fornasiero, and H. Afsarmanesh, “Collabo-
rative networks as a core enabler of industry 4.0,” in Collaboration in a
Data-Rich World (PRO-VE) (IFIP Advances in Information and Commu-
nication Technology), vol. 506, L. Camarinha-Matos, H. Afsarmanesh,
and R. Fornasiero, Eds. Cham, Switzerland: Springer, 2017, doi:
10.1007/978-3-319-65151-4_1.
[8] S. Pouyanfar et al., “A survey on deep learning: Algorithms, tech-
niques, and applications,” ACM Comput. Surv., vol. 51, no. 5, pp. 1–36,
Sep. 2018.
[9] A. Sharma et al., “Multi-agent system applications to ﬁght COVID-19
pandemic,” Apollo Med., vol. 17, no. 5, p. 41, 2020.
[10] B. Wang et al., “AI-assisted CT imaging analysis for COVID-19
screening: Building and deploying a medical AI system,” Appl. Soft
Comput., vol. 98, Jan. 2021, Art. no. 106897.
[11] S. Wang et al., “A deep learning algorithm using CT images to screen for
corona virus disease (COVID-19),” Eur. Radiol., vol. 31, pp. 6096–6104,
Feb. 2021.
[12] D. M. Khan, K. Masroor, M. F. M. Jailani, N. Yahya, M. Z. Yusoff, and
S. M. Khan, “Development of wavelet coherence EEG as a biomarker
for diagnosis of major depressive disorder,” IEEE Sensors J., vol. 22,
no. 5, pp. 4315–4325, Mar. 2022.
[13] R. Wang et al., “A standalone and portable microﬂuidic imaging detec-
tion system with embedded computing for point-of-care diagnostics,”
IEEE Sensors J., vol. 22, no. 6, pp. 6116–6123, Mar. 2022.
[14] N. Balachandar, K. Chang, J. Kalpathy-Cramer, and D. L. Rubin,
“Accounting for data variability in multi-institutional distributed deep
learning for medical imaging,” J. Amer. Med. Inform. Assoc., vol. 27,
no. 5, pp. 700–708, May 2020.
[15] S. S. Roy, K. Samanta, S. Modak, S. Chatterjee, and R. Bose, “Cross
spectrum aided deep feature extraction based neuromuscular disease
detection framework,” IEEE Sensors Lett., vol. 4, no. 6, pp. 1–4,
Jun. 2020.
[16] H. Ku, W. Susilo, Y. Zhang, W. Liu, and M. Zhang, “Privacy-
preserving federated learning in medical diagnosis with homomorphic
re-encryption,” Comput. Standards Interfaces, vol. 80, Mar. 2022,
Art. no. 103583.
[17] X. Xu, H. Tian, X. Zhang, L. Qi, Q. He, and W. Dou, “DisCOV: Dis-
tributed COVID-19 detection on X-ray images with edge-cloud collab-
oration,” IEEE Trans. Services Comput., vol. 15, no. 3, pp. 1206–1219,
May 2022.
[18] R. Dwivedi, S. Dey, C. Chakraborty, and S. Tiwari, “Grape disease
detection network based on multi-task learning and attention features,”
IEEE Sensors J., vol. 21, no. 16, pp. 17573–17580, Aug. 2021.
[19] U. Ahmed, J. C.-W. Lin, G. Srivastava, R. Yasin, and Y. Djenouri,
“An evolutionary model to mine high expected utility patterns from
uncertain databases,” IEEE Trans. Emerg. Topics Comput. Intell., vol. 5,
no. 1, pp. 19–28, Feb. 2021.
[20] P. Srinivas and R. Katarya, “HyOPTXg: OPTUNA hyper-parameter
optimization framework for predicting cardiovascular disease using
XGBoost,” Biomed. Signal Process. Control, vol. 73, Mar. 2022,
Art. no. 103456.
[21] C.-W. Lin, T.-P. Hong, G.-C. Lan, J.-W. Han, and W.-Y. Lin, “Incre-
mentally mining high utility patterns based on pre-large concept,” Appl.
Intell., vol. 40, no. 2, pp. 343–357, Mar. 2014.
[22] J. C.-W. Lin, W. Gan, P. Fournier-Viger, T.-P. Hong, and J. Zhan,
“Efﬁcient mining of high-utility itemsets using multiple minimum utility
thresholds,” Knowl.-Based Syst., vol. 113, pp. 100–115, Dec. 2016.
[23] W. Gan, J. C.-W. Lin, J. Zhang, P. Fournier-Viger, H.-C. Chao, and
P. S. Yu, “Fast utility mining on sequence data,” IEEE Trans. Cybern.,
vol. 51, no. 2, pp. 487–500, Feb. 2021.
[24] M.
S.
Nawaz,
P.
Fournier-Viger,
A.
Shojaee,
and
H.
Fujita,
“Using artiﬁcial intelligence techniques for COVID-19 genome analy-
sis,”
Int.
J.
Speech
Technol.,
vol.
51,
no.
5,
pp. 3086–3103,
May 2021.
[25] Y. Yan et al., “Topological descriptors of gait nonlinear dynamics
toward freezing-of-gait episodes recognition in Parkinson’s disease,”
IEEE Sensors J., vol. 22, no. 5, pp. 4294–4304, Mar. 2022.
[26] R. Jain, M. Gupta, S. Taneja, and D. J. Hemanth, “Deep learning based
detection and analysis of COVID-19 on chest X-ray images,” Appl.
Intell., vol. 51, pp. 1690–1700, Oct. 22021.
[27] A. Sedik, M. Hammad, F. E. Abd El-Samie, B. B. Gupta, and
A. A. Abd El-Latif, “Efﬁcient deep learning approach for augmented
detection of Coronavirus disease,” Neural Comput. Appl., vol. 34,
pp. 11423–11440, Jan. 2021.
[28] M. Manoj, G. Srivastava, S. R. K. Somayaji, T. R. Gadekallu,
P. K. R. Maddikunta, and S. Bhattacharya, “An incentive based
approach
for
COVID-19
planning
using
blockchain
technology,”
in Proc. IEEE Globecom
Workshops (GC Wkshps), Dec. 2020,
pp. 1–6.
[29] S. Chae, S. Kwon, and D. Lee, “Predicting infectious disease using deep
learning and big data,” Int. J. Environ. Res. Public Health, vol. 15, no. 8,
p. 1596, Jul. 2018.
[30] S. Ahuja, B. K. Panigrahi, N. Dey, V. Rajinikanth, and T. K. Gandhi,
“Deep transfer learning-based automated detection of COVID-19 from
lung CT scan slices,” Appl. Intell., vol. 51, no. 1, pp. 571–585,
2021.
[31] Z. S. Y. Wong, J. Zhou, and Q. Zhang, “Artiﬁcial intelligence for
infectious disease big data analytics,” Infection, Disease Health, vol. 24,
no. 1, pp. 44–48, Feb. 2019.
[32] H. Hirano, A. Minagi, and K. Takemoto, “Universal adversarial attacks
on deep neural networks for medical image classiﬁcation,” BMC Med.
Imag., vol. 21, no. 1, pp. 1–13, Dec. 2021.
[33] M. Jamshidi et al., “Artiﬁcial intelligence and COVID-19: Deep learn-
ing approaches for diagnosis and treatment,” IEEE Access, vol. 8,
pp. 109581–109595, 2020.
[34] P. Singh, A. Verma, and J. S. R. Alex, “Disease and pest infection
detection in coconut tree through deep learning techniques,” Comput.
Electron. Agricult., vol. 182, Mar. 2021, Art. no. 105986.
[35] P. Gifani, A. Shalbaf, and M. Vafaeezadeh, “Automated detection of
COVID-19 using ensemble of transfer learning with deep convolutional
neural network based on CT scans,” Int. J. Comput. Assist. Radiol.
Surgery, vol. 16, no. 1, pp. 115–123, Jan. 2021.
[36] D. Moolchandani, A. Kumar, and S. R. Sarangi, “Accelerating CNN
inference on ASICs: A survey,” J. Syst. Archit., vol. 113, Feb. 2021,
Art. no. 101887.
[37] K. Pogorelov et al., “Kvasir: A multi-class image dataset for computer
aided gastrointestinal disease detection,” in Proc. 8th ACM Multimedia
Syst. Conf., 2017, pp. 164–169.
[38] F. Chollet, “Xception: Deep learning with depthwise separable convo-
lutions,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR),
Jul. 2017, pp. 1251–1258.
[39] F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally,
and K. Keutzer, “SqueezeNet: AlexNet-level accuracy with 50x fewer
parameters and <0.5 MB model size,” 2016, arXiv:1602.07360.
[40] Y. Djenouri and M. Comuzzi, “Combining Apriori heuristic and bio-
inspired algorithms for solving the frequent itemsets mining problem,”
Inf. Sci., vol. 420, pp. 1–15, Dec. 2017.
[41] M. Wo´zniak, J. Siłka, and M. Wieczorek, “Deep neural network correla-
tion learning mechanism for CT brain tumor detection,” Neural Comput.
Appl., vol. 1, pp. 1–16, Mar. 2021, doi: 10.1007/s00521-021-05841-x.
[42] P. N. Ramkumar et al., “Clinical and research medical applications
of artiﬁcial intelligence,” Arthroscopy: J. Arthroscopic Related Surg.,
vol. 37, no. 5, pp. 1694–1697, 2021.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
",10.1109/JSEN.2022.3202437,doc24,"IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023 947 An Intelligent Collaborative Image-Sensing System for Disease Detection Youcef Djenouri , Asma Belhadi, Anis Yazidi , Gautam Srivastava , Senior Member, IEEE, Pushpita Chatterjee , and Jerry Chun-Wei Lin , Senior Member, IEEE Abstract—With the growth of smart medical devices and applications in smart hospitals, home care facilities, nursing, and the Internet of Medical Things (IoMT) are becoming more ubiquitous. It uses smart medical devices and cloud comput- ing services, and basic Internet of Things (IoT) technology, to detect key body indicators, monitor health situations, and generate multivariate data to provide just-in-time healthcare services. In this article, we present a novel collaborative disease detection system based on IoMT amalgamated with captured image data. The system can be based on intelligent agents, where every agent explores the interaction between different medical data obtained by smart sensor devicesusing reinforcementlearning as well as targets to detectdiseases. The agents then collaborate to make a reliable conclusion about the detected diseases. Intensive experiments were conducted using medical data. The results show the importance of using intelligent agents for disease detection in healthcare decision-making. Moreover, collaboration increases the detection rate, with numerical results showing the superiority of the proposed framework compared with baseline solutions for disease detection. Index Terms— Communicable disease, correlation, multiagent system (MAS), smart sensor data. I. INTRODUCTION S MART healthcare is a framework that leverages wear- able devices, the Internet of Medical Things (IoMT), powerful machine learning algorithms, and wireless commu- nication technology to connect people, resources, and orga- nizations as well as then intelligently manage and respond Manuscript received 21 April 2022; revised 9 July 2022; accepted 13 August 2022. Date of publication 2 September 2022; date of current version 12 January 2023. The associate editor coordinating the review of this article and approving it for publication was Dr. Hari P. Gupta. (Corresponding author: Jerry Chun-Wei Lin.) Youcef Djenouri is with SINTEF Digital, 0610 Oslo, Norway (e-mail: youcef.djenouri@sintef.no). Asma Belhadi is with the School of Economics, Innovation and Technology, Kristiania University College, 0107 Oslo, Norway (e-mail: asma.belhadi@kristiania.no). Anis Yazidi is with the Department of Computer Science, OsloMet-Oslo Metropolitan University, 0167 Oslo, Norway, also with the Department of Neurosurgery, Oslo University Hospital, 0450 Oslo, Norway, and also with the Department of Computer Science, Norwegian University of Science and Technology, 7491 Trondheim, Norway (e-mail: anisy@oslomet.no). Gautam Srivastava is with the Department of Math and Computer Science, Brandon University, Brandon, MB R7A 6A9, Canada, also with Research Centre for Interneural Computing, China Medical University, Taichung 404, Taiwan, and also with the Department of Computer Science and Math, Lebanese American University, Beirut 1102, Lebanon (e-mail: SRIVASTAVAG@brandonu.ca). Pushpita Chatterjee is with the Department of Computer Science, Ten- nessee State University, Nashville, TN 37209 USA (e-mail: pushpita.c@ ieee.org). Jerry Chun-Wei Lin is with the Department of Computer Sci- ence, Electrical Engineering and Mathematical Sciences, Western Nor- way University of Applied Sciences, 5063 Bergen, Norway (e-mail: jerrylin@ieee.org). Digital Object Identiﬁer 10.1109/JSEN.2022.3202437 to healthcare needs [1], [2]. Medical sensors, often referred to as IoMT, are a critical component of smart healthcare. IoMT may be able to be driving today’s smart healthcare by leveraging cutting-edge technologies, such as artiﬁcial intelligence (AI), cloud computing, coupled with the emer- gent sixth generation (6G) mobile networks. The increasing use of IoMT devices, as well as data-driven apps, may be able to be contributing to positive effects ranging from improved user-health attitudes and early disease detection to higher-quality care and a more cost-effective smart healthcare ecosystem. It may be expected that the integration of the Internet of the Things (IoT) with medical devices in a smart healthcare system will increase the quality and the efﬁciency of services for patients, especially for patients with chronic diseases who need continuous care. With the support of Internet communica- tions, IoMT enables continuous monitoring of important phys- iological functions in, otherwise, healthy individuals, so that diseases may be able to be detected, and appropriate action may be able to be taken immediately. This may be able to be particularly important during pandemics, such as the recent Coronavirus-disease pandemic that raged globally [3], [4], where taking into account our advanced and technologically advanced healthcare systems, which tend to include both medical personnel with support systems, saw themselves under an absurd amount of stress [5]. The demand for a remote, autonomous, and ubiquitous IoMT architecture may be able to be greater than ever [6]. 1558-1748 © 2022 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. 948 IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023 The integration of smart sensors and controls within the Internet also has turned any and all “so-called” cyber-physical systems (CPSs) into IoMT, which has recently emerged as one of the main driving forces behind the fourth industrial revolution nicknamed Industry 4.0 [7]. In these directions, healthcare itself may be able to be also undergoing a digital revolution through the integration of smart devices. On the other hand, the number of IoMT devices is expected to increase signiﬁcantly over the next few years. Furthermore, the heterogeneity of the various IoMT components (network interfaces, data format, data semantics, and communication protocols) will lead to difﬁculties in interoperability and data protection [7]. In this regard, a ubiquitous, and collaborative health platform for all smart devices must be adaptable enough to accommodate all these concepts. A. Motivation Technologies based on AI are very promising in this regard and in medical applications in general [8], [9]. These include techniques, such as multiagent systems (MASs), networks that incorporate deep learning (DL), and advanced computa- tional techniques, such as evolutionary computation (EC) or other well-known ones. DL is a well-known branch of AI that can involve the creation of complicated but complete models with a high number of layers and a large number of hyperparameters. These models are not only capable of learning from large amounts of data, but they can also directly extract important aspects from these huge amounts of data. Medical data analysis, especially disease detection, is a fascinating area of DL [10], [11], [12], [13]. For example, Coronavirus-disease pandemic samples were used to build an intelligent model to calculate infection rates [10]. The latter work uses both supervised and unsupervised learning methods, resulting in a 40% increase in detection speed. Transfer learning was used to evaluate pathogen frames and validate Coronavirus-disease pandemic instances with typical virus-based pneumonia [11]. The result highlights the value of using intelligent approaches for Coronavirus-disease pandemic diagnosis. We may be able to also observe examples that have been substantially explored in the newer, fresh ﬁeld of distributed DL [14], [15], [16], [17], [18] by studying various types of DL models that are well established in medicine as well as disease detection. The identiﬁcation of illnesses is the primary objec- tive of these technologies, particularly the distributed ones. This will assist medical professionals in making decisions that are acceptable and fair within the realm of medicine. The intricacy of the data is the single most critical barrier that makes disease detection more difﬁcult than it would otherwise be. Indeed, diseases may be able to have different forms and manifestations that are difﬁcult to detect. We are researching the possibility of developing a comprehensive framework that makes use of DL to get beyond these disadvantages and MASs. The large number of hyperparameters provided by DL models is another signiﬁcant obstacle to the disease detection process. The random selection of these values leads to a signiﬁcant decrease in the overall performance during the learning phase. Moreover, the process of setting the para- meters for such frameworks takes a long time, and there is no guarantee of satisfactory convergence. The effective- ness of EC in tackling complicated problems [19], [20] has led this research to tune the parameters of the proposed framework. B. Contributions To the best of our knowledge, this is the ﬁrst paper to take an in-depth look at combining MASs, EC, and DL for disease detection. Below is a list of the major contributions. 1) We provide an collaborative system for disease detec- tion (ALMOST), a new paradigm that uses DL, MAS, and EC to identify diseases. To learn from medical training data and different diseases, each and every agent uses its DL architecture. Each iteration of the architecture establishes communication between agents to share information and reduce the error learning rate. 2) We show how many convolutional neural net- works (CNNs) may be able to work together to process large amounts of data in the medical domain. Several optimizations, such as batch normalization and dropout algorithms, ensure that the CNN processes medical data with great accuracy. 3) To intelligently explore the conﬁguration space of dif- ferent hyper parameter values, we propose a new evo- lutionary computational technique based on a genetic behavior. This approach improves the convergence of ALMOST in predicting diseases from medical data. 4) Extensive testing was conducted to demonstrate the applicability of ALMOST. The ﬁndings demon- strated that the ALMOST performs better than other well-known illness identiﬁcation algorithms in terms of the quality of the information and also in terms of computation time when training large medical data. From here on, this article is arranged as follows. Section II provides an in-depth examination of related studies on disease detection. Section III provides a comprehensive understanding of the ALMOST methodology. A performance evaluation of ALMOST is shown in Section IV. Section V discusses the major consequences of using ALMOST on medical data and the prospects for the future of the research. Section VI concludes this article. II. LITERATURE REVIEW A. AI-Based Solutions Pattern mining [21], [22], [23] is one of the approaches to derive and reveal the potential relationships of the items in the databases. Nawaz et al. [24] investigated the use of pattern mining in the analysis of medical diseases. The set of Coronavirus-disease pandemic patient data is converted into a set of transactions, where each and every patient is represented by a transaction, and each Coronavirus-disease pandemic- based information related to the patient is represented by an item. A pattern mining algorithm is then applied to the set of transactions to extract relevant patterns. The latter was used to identify diseases based on the correlation between Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. DJENOURI et al.: INTELLIGENT COLLABORATIVE IMAGE-SENSING SYSTEM FOR DISEASE DETECTION 949 medical data features. Wang et al. [10] automated the process of image assessment by exploring the segmentation as well as classiﬁcation of DL-based architectures. Thus, we may be able to achieve a reasonable estimate of the always illusory Coronavirus-disease pandemic infection rate. Wang et al. [11] found viral pneumonia from more than 1000 images of pathogens. The experiments showed a clear beneﬁt of using intelligent methods for disease diagnosis. Yan et al. [25] used a topological approach to analyze nonlinear dynamics to exam- ine gait complexity ﬂuctuations in Parkinson’s disease patients to detect the Freezing-of-Gait episode. The 3-D acceleration data from eight individuals with symptoms are used to extract relevant features from the acceleration signals using topo- logical analysis of the reconstructed process. Jain et al. [26] demonstrated the performances of using Inception-V3 for Coronavirus-disease pandemic disease identiﬁcation through data enrichment. Sedik et al. [27] demonstrated the efﬁciency of using CNN in Coronavirus-disease pandemic identiﬁca- tion. This article also demonstrated the importance of multi- modal data, in which the authors collected medical data from multiple sources, including tomographic and X-ray images. Manoj et al. [28] took a look at an incentive-based system, where the Coronavirus pandemic could be better planned for using an incentive system using block chain. In this solution, governments globally can prepare and plan better strategies for ﬁghting the virus using the availability of data from both a geographic point of view but also qualitative data around the disease. By being able to have more accurate and better data around the pandemic, and have it available in a decentralized fashion being managed by block chain, will allow a faster response time to virus outbreaks in the future. B. Hybrid-Based Solutions Chae et al. [29] predicted infectious diseases by success- fully exploring long-term short-term memory with autoregres- sive moving average. The proposed model is improved by the ensemble learning mechanism. Therefore, more sources of information were collected and extracted from social net- works. Ahuja et al. [30] implemented four DL architectures (ResNet18, ResNet50, ResNet101, and SqueezeNet) to capture Coronavirus-disease pandemic from medical lung CT-scan data. The models are pretrained using a large collection of images from different domains. The transfer learning mech- anism is used to learn the Coronavirus-disease pandemic cases from the medical data. Wong et al. [31] analyzed the effect of data-driven solutions for infectious diseases. They explored the combination of various data management as well as AI techniques to help healthcare professionals mitigate the risk of disease detection and enable better diagnosis in a smart healthcare environment. Hirano et al. [32] classiﬁed the various diseases using the model for use in DL. The classiﬁcation models developed are based on three types of medical images: photographic images, X-ray chest images, and retinopathy images. Three applications are then investigated, including skin cancer, transmissible diabetics, and pneumonia. Transfer learning with the adversarial neural network has been implemented. The transfer learning mechanism allows the model developed from various medical sources to be trained, and the adversarial network, which may be able to handle both non-targeted and targeted attacks and identify fake medical images. Jamshidi et al. [33] process multiple sources of med- ical data by exploring generative adversarial networks, extreme learning, and long-term short-term memory. This combination not only enables the handling of heterogeneous medical data but also increases the disease detection rate. Singh et al. [34] worked on developing a hybrid model based on both decom- positions and DL for disease detection. Segments are created by applying the k-means algorithm to medical data. These segments are then fed into the CNN to predict diseases based on the original medical images. Shalbaf et al. [35] imple- mented 15 pre-trained DL models to automatically identify the Coronavirus-disease pandemic. These models are based on three well-known classiﬁcation-based architectures, including Inception, ResNet, and DenseNet. Ensemble learning is then explored to merge the results obtained from these models using the majority voting strategy. III. ALMOST: AN COLLABORATIVE SYSTEM FOR DISEASE DETECTION A. Principle We begin by explaining the most important aspects of ALMOST. ALMOST is a combination of many intelligent strategies for solving disease detection problems. The CNN is used for disease diagnosis. To correctly execute ALMOST in a distributed environment where each agent can beneﬁt from the environment through the reinforcement learning paradigm, the use of an MAS is investigated. Since DL requires setting a large number of parameters, up to a million for some architectures, EC is used to determine the best settings for real- time processing. The components of ALMOST are discussed in the next parts. B. Learning Phase The learning phase is done with the help of CNNs [36]. CNN is a common type of deep architecture in computer vision applications, such as object detection and identiﬁcation. In recent years, the adaptability of this method has helped both time series and text data. CNN is based on the concept of extracting features from matrix data using convolutional ﬁlters. Convolutional ﬁlters create a new image by applying a series of weights to the matrix data of each pixel in the image. As a result, a new image is generated. In addition, well- known operators for DL models, such as batch normalization and dropout, are used during training to increase the accuracy of the proposed framework. This was achieved using the dropout method. Batch normalization is one of the factors that help the network to converge faster, while the dropout method acts as a regulator that prevents the network from overﬁtting. These two methods are necessary for the network to achieve high accuracy. Below is a complete description of these components. 1) Batch Normalization: To efﬁciently train a large number of layers, we used the batch normalization technique in all steps of the training phase. With only a few epochs, Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. 950 IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023 the learning process may be able to converge better. Batch normalization is performed after each and every convolutional layer in the CNN. 2) Dropout: It is a technique that allows you to avoid over adaptation during training. In each and every phase, the outputs of the neurons in the hidden layers are randomly skipped. Propagating a deep network with a constrained number of weights may be thought of as a straightforward method for bringing about convergence of predictions during the inference phase. C. Multiagents Systems The MAS is used to learn the different diseases in the training phase. The agents collaborate using the reinforcement learning process. Consider the tuple ⟨A, S, U, R⟩, an MAS is deﬁned by A. There are Aagents in total, and for the purposes of this discussion, each of them is treated as if it were an independent Markov decision process. A ﬁnite collection of environmental states is represented by the variable S, a set of actions by the variable U, and a reward function by the variable R. The methods presented in A describe not only how each agent should behave given the current situation, but also how it should decide on the appropriate actions. For instance, in the process of disease detection, the mission of each agent is to identify the most effective tactic that maximizes the value of the target objective function, which may be the number of diseases that are accurately identiﬁed. We will discuss the many parts that make up the MAS that we have designed by the sections as follows. 1) Environment: The environment may be thought of as a collection of databases that hold a massive quantity of data that were gathered by various intelligent sensor devices. As a result, the environment is able to create certain conditions for training the agents and determine the optimal actions. 2) State: The next action of each and every agent is deter- mined by the decisions made in earlier phases. The state of each agent is, thus, composed of two distinct parts: the data being processed and a collection of actions completed in the past. When calculating the size of the state space S, the number of observations contained in the database is taken into account. 3) Action: It is the assignment of each and every obser- vation in the database’s decision-making behavior. For instance, a detection task is the assignment of each and every disease category. 4) Reward: It is essential to decide on an acceptable reward function. It makes it possible for each agent in A to have a more fruitful learning experience. Using data that included ground truths, we crafted a reward in response to the behaviors of the agent. Therefore, the ﬁrst thing each agent does is to perform a scan of the data collected by the ith intelligent sensor. This is denoted by the notation Ai. It then computes the ﬁrst observation of the ith intelligent sensor, and all future observations of that sensor. The ground truth for the ﬁrst observation is used in the creation of a reward function speciﬁc to that choice. This approach is repeated for each of the ith smart sensor observations. As a result, a set of local options, denoted LDi, is generated for each agent Ai. The agents then learn from the local decisions {LDi} to optimally ﬁnd the global decision. This learning is realized through the process of reinforcement learning, where the best agents that have a high score for their local decisions receive a reward. D. Hyperparameters Optimization To achieve optimal performance, we apply an evolutionary- based technique to optimize hyperparameters. The adaptation of the genetic algorithm is proposed due to its known balance of intensiﬁcation and diversiﬁcation. A complete description of the proposed algorithm is given for solving our hyper parameter optimization problem. Let HP = {HP1, HP2, . . . , HPr} be the set of hyperpa- rameters, where r is the number of hyperparameters in the evolved ALMOST. Each HPi represents a set of the possible values of the hyperparameter in question. The conﬁguration space C is then deﬁned by the set of all possible conﬁgurations, where each and every conﬁguration is a vector. The possible values of all hyperparameters belong to HP. When it comes to hyperparameter optimization, our methodology focuses on determining the ideal conﬁguration that provides the highest level of accuracy. The conﬁguration space is deﬁned by the total number of possible hyper parameter values, as given in |C| = r i=1 |HPi|. (1) Because of the vastness of the conﬁguration space, ﬁnding the ideal solutions requires considerable computational effort. Consider the epoch parameter, which has a max value of 1000, the error rate, which has a max value of 100, as well as the number of agents in the evolved model, which has a max value of 100; then, the search space will include ten million conﬁgurations, so it is not possible to apply exhaustive search methods in this case. To solve this challenge, evolutionary computational methods are used. Below are the main components of our solution. 1) Population Initialization: We are trying to distribute |P|, which is the initial population, noted P. This initial population should be uniformly distributed in the conﬁguration space C. Proper examination of each and every of the numerous alter- native conﬁgurations that tend to cover most locations within C may be able to then be performed using this uniform distribution technique. We must ﬁrst create the population, taking diversity into account. This process begins with the random generation of an indi- vidual represented by a single C conﬁguration. It is possible that after starting with this individual, we can generate more |P|−1, assuming that each newly formed individual is differ- ent from the previously generated individuals. We could use a distance measure between two successive conﬁgurations to evaluate dissimilarity based on the individuals formed in those conﬁgurations. This would be done based on the individuals generated in those conﬁgurations. The original population, denoted by the variable P, should, in turn, be able to maximize Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. DJENOURI et al.: INTELLIGENT COLLABORATIVE IMAGE-SENSING SYSTEM FOR DISEASE DETECTION 951 the diversiﬁcation function shown in Diversify(P) = |P|  i=1 |P|  j=1 Distance(Ci, C j) (2) where Distance(Ci, C j) is the distance between the conﬁgura- tions of the ith and the jth individuals, respectively. 2) Crossover: To produce new offspring, each and every of the two individuals in the current population goes through the following steps. 1) We start at 1 and work our way up to r, creating a random sequence of crossing points. At each of these points, we divide the intersection into its left and right halves, respectively. 2) Both the left-hand side of the original, which is copied to the left-hand side of the ﬁrst descendant, and the right-hand side of the original, which is copied to the right-hand side of the second descendant, are descen- dants of each other. 3) The right-hand side of the second person is inherited by the ﬁrst generation, while the left-hand side of the second individual is inherited by the second generation. 3) Mutation: Mutation facilitates the search for diversity. We use a strategy in which the value of a single parameter is randomly varied in every single one of the conﬁgurations currently in use. The mutation point is chosen randomly and can have a value between 1 and r, depending on the method. At each iteration, the value of the mutation point is changed in the descendants generated by the crossover operator. 4) Fitness Function: Identifying diseases with the highest possible degree of precision is the goal of the ALMOST framework. Therefore, to assign points to individuals within populations, we use the following function: Fitness(Ci) = DetectionALMOST(Ci). (3) Note that the following hold. 1) Ci is a representation of the conﬁguration of the ith individual in the population. 2) DetectionALMOST(Ci) indicates the ratio for disease detection using the developed ALMOST based on the Ci. Based on these actions, we presented the following method for optimizing hyperparameter values. In the beginning, the initial population size, deﬁned as |P|, is randomly gener- ated. Then, each and every individual is constructed using population initialization. Then, mutation, and crossover with mutation and crossover rates (Mr and Cr), is used to generate conﬁgurations from C. To keep the population size constant, each individual is evaluated against the ﬁtness function, focus- ing on maintaining the highest quality |P| individuals. All others are now deleted. This procedure is then continued endlessly until the max number of iterations (IMAX) is reached. E. Description Algorithm 1 shows the pseudocode of ALMOST for each and every agent. The process begins by building the model for use in DL represented by the CNN with batch normalization and dropout layers (from lines 4 to 5). The batches of data Algorithm 1 ALMOST Pseudocode for Each Agent 1: Input: I = {I1, I2, . . . , Im}: the set of m images collected from sensors. 2: Output: model: The trained model to detect the disease; DD: the set of the disease detected from I. 3: model ←C N N(); 4: model ←model ∪BatchNormalization(); 5: model ←model ∪Dropout() 6: Batches ←CreatingBatches(D); 7: Hyper_Param ←G A( f it(model, Batches)); 8: DD ←In f erence(Inew, model, Hyper_Param); 9: return < model, DD >. are created from the input images I in line 6. Then, the genetic algorithm is applied to optimize the hyperparameters of the model for use in DL by performing the training phase on the created batches (line 7). The inference phase is then run on the trained model to identify the disease of the new image (line 8). The output of the algorithm is the set of detected diseases DD and the trained disease detection model (line 11). IV. PERFORMANCE EVALUATION Extensive testing was performed on known medical datasets speciﬁcally designed for disease detection applications to validate the use of the proposed ALMOST framework. Exper- iments were conducted using a desktop computer equipped with 16 GB of primary memory and an Intel Core i7 processor for optimal performance. PythonTorch was used for the actual implementation of each algorithm. We used the Kvasir [37] medical database to validate the applicability of ALMOST in disease detection, for disease data for the human digestive system. The aim is to automate the detection of endoscopic ﬁndings in the esophagus, stomach, intestines, and rectum. It is available in two versions. The ﬁrst version, called Kvasir (v1), consists of 4000 images grouped into eight classes showing anatomical landmarks, pathological ﬁndings, or endoscopic procedures. The second version, called Kvasir (v2), expands on the ﬁrst version and consists of 8000 images with the same number of classes. A. Parameter Setting In ALMOST, several parameters need to be optimized, including the number of agents, the number of generations, the crossover and mutation rates, and the population size. Choos- ing optimal values for these parameters is critical for better performance of the ALMOST framework. In this experiment, we analyze the behavior of ALMOST at different values for the number of agents, number of generations, crossover rate, and the mutation rate. We varied the number of agents from 2 to 20, the number of generations and population size from 10 to 100, and the crossover rate and mutation rate from 0.01 to 0.99. The behavior of ALMOST may be able to be summarized as follows. 1) Number of Agents: The experiments showed that when we vary the number of agents from 2 to 20, the accuracy Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. 952 IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023 TABLE I SUMMARY OF PARAMETER SETTING OF ALMOST TABLE II ALMOST VERSUS DISEASE DETECTION SOLUTIONS of ALMOST increases until ﬁve agents for Kvasir (V1) and eight agents for Kvasir (V2) where stabilization of the accuracy is observed. 2) Number Generations: The experiments showed that when we vary the number of generations from 10 to 100, the accuracy of ALMOST increases until 45 generations for Kvasir (V1), and 58 generations for Kvasir (V2) where stabilization of the accuracy is observed. 3) Population Size: The experiments showed that when we vary the population size from 10 to 100, the accuracy of ALMOST increases until 85 individuals for Kvasir (V1), and 93 individuals for Kvasir (V2) where stabilization of the accuracy is observed. 4) Crossover Rate: The experiments showed that when we vary the crossover from 0.01 to 0.99, the accuracy of ALMOST increases until 0.35 for Kvasir (V1), as well as 0.47 for Kvasir (V2) where stabilization of the accuracy is observed. 5) Mutation Rate: The experiments showed when we vary the mutation from 0.01 to 0.99, the accuracy of ALMOST increases until 0.53 for Kvasir (V1), as well as 0.61 for Kvasir (V2) where the stabilization of the accuracy is observed. Table I gives the optimal values of the parameters used in ALMOST for both Kvasir (v1) and Kvasir (v2). The next experiments aim to validate the usefulness of the proposed ALMOST framework for disease detection. To reach this conclusion, an intensive analysis was performed by comparing ALMOST with the baseline solutions InceptionResNet [34] and DenseNet [35]). The detailed results with a full explana- tion are shown below. B. Quality of Outputs Table II shows the quality of results from ALMOST and the baseline solutions: InceptionResNet, DenseNet on Kvasir (V1), and Kvasir (V2). We varied the percentage of images used for training from 1000 to 4000 for Kvasir (V1) and from 1000 to 8000 images for Kvasir (V2). We then calculate Fig. 1. ALMOST versus advanced disease detection solutions with different numbers of error loss values (0.10, 0.08, 0.05, 0.02, and 0.01). the quality of the results represented by the F1 and accu- racy formulas. The results show the superiority of ALMOST compared with the baseline solutions for all scenarios. Thus, the accuracy of ALMOST is 0.96 when all the data from Kvasir (V2) are processed, while the accuracy of the two solutions is less than 0.80 when the same data are trained. This great performance is due to the efﬁcient components of ALMOST represented by the DL solution and the MASs, and the accurate way of the hyperoptimization process. Fig. 2 shows a case study of ALMOST. The ﬁrst three images are considered as esophagitis disease, and the second three images are considered as polyps disease, where the last three images are considered as ulcerative colitis disease. C. ALMOST for Large-Scale Data In the next experiment, we will examine the scalability of ALMOST compared with the baseline solutions when it comes to processing large amounts of data. For comparison, we will use Xception [38] and SqueezeNet [39]. These algorithms have proven their usefulness in a variety of different contexts, including training huge datasets. Different training scenarios with different data sizes of Kvasir (v1) and Kvasir (v2) are run. Data duplication is generated by multiplying Kvasir (v1) and Kvasir (v2) multiple times (1000, 10000, and 100000). For each and every redundant sample, changes are generated using a generative adversarial network. We varied the error loss to be optimized from 0.10 to 0.01, and the results are given in Fig. 1. From these results, we may be able to see the clear superiority of ALMOST over the other two solutions in terms of training time. This performance may be able to be explained by the fact that ALMOST is optimized DL where Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. DJENOURI et al.: INTELLIGENT COLLABORATIVE IMAGE-SENSING SYSTEM FOR DISEASE DETECTION 953 Fig. 2. Case study of ALMOST: the ﬁrst three images are considered as esophagitis disease, and the second three images are considered as polyps disease, where the last three images are considered as ulcerative colitis disease. the collaboration between the different agents accelerates the training process. V. DISCUSSION AND FUTURE DIRECTION The primary beneﬁts of applying ALMOST to disease detection data are presented in this section. We also make some recommendations for how to improve the ALMOST framework. 1) The effective combination of intelligent technologies in the form of DL, MASs, and metaheuristics leads to a high level of precision. For real-time medical data management and disease detection, runtime performance is still a challenge. The development of hybrid systems that combine evolutionary and exact approaches [40] to improve the performance of ALMOST could be an interesting avenue. 2) The proposed methodology provides better results than previous approaches. It would extremely fascinating to study the results of ALMOST for other smart healthcare applications, such as brain tumor detection [41], as well as surgery [42]. 3) Output interpretation is a challenge in ALMOST. It relies on black-box models that do not implicitly explain the process of output interpretation. Health- care practitioners need to understand how the given output is produced to trust it. This problem is being addressed by the emerging discipline of explainable AI (XAI). We intend to incorporate XAI approaches into ALMOST. This will allow for a more accurate interpretation of the results from ALMOST. VI. CONCLUSION In this article, an intelligent collaborative system for dis- ease detection is proposed. It studied the different interac- tions between the medical data using intelligent agents with an efﬁcient reinforcement learning mechanism. This enables signiﬁcant determination of various diseases in healthcare systems. The proposed system was tested on different medical datasets. The initial results showed the usefulness of using intelligent agents for healthcare diagnosis. The numerical results can be seen to also clearly visualize the strength of our proposed framework when directly compared with baseline methodologies when focusing on the rate of disease detection. REFERENCES [1] R. Yadav et al., “Smart healthcare: RL-based task ofﬂoading scheme for edge-enable sensor networks,” IEEE Sensors J., vol. 21, no. 22, pp. 24910–24918, Nov. 2021. [2] L. Babangida, T. Perumal, N. Mustapha, and R. Yaakob, “Internet of Things (IoT) based activity recognition strategies in smart homes: A review,” IEEE Sensors J., vol. 22, no. 9, pp. 8327–8336, May 2022. [3] Y. Han and H. Yang, “The transmission and diagnosis of 2019 novel coronavirus infection disease (COVID-19): A Chinese perspective,” J. Med. Virol., vol. 92, no. 6, pp. 639–644, 2020. [4] J. He, Y. Guo, R. Mao, and J. Zhang, “Proportion of asymptomatic coronavirus disease 2019: A systematic review and meta-analysis,” J. Med. Virol., vol. 93, no. 2, pp. 820–830, 2021. [5] E. J. Emanuel et al., “Fair allocation of scarce medical resources in the time of COVID-19,” New England J. Med., vol. 382, no. 21, pp. 2049–2055, May 2020. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. 954 IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023 [6] T. Yang, M. Gentile, C.-F. Shen, and C.-M. Cheng, “Combining point- of-care diagnostics and internet of medical things (IoMT) to combat the COVID-19 pandemic,” Diagnostics, vol. 10, no. 4, p. 224, Apr. 2020. [7] L. M. Camarinha-Matos, R. Fornasiero, and H. Afsarmanesh, “Collabo- rative networks as a core enabler of industry 4.0,” in Collaboration in a Data-Rich World (PRO-VE) (IFIP Advances in Information and Commu- nication Technology), vol. 506, L. Camarinha-Matos, H. Afsarmanesh, and R. Fornasiero, Eds. Cham, Switzerland: Springer, 2017, doi: 10.1007/978-3-319-65151-4_1. [8] S. Pouyanfar et al., “A survey on deep learning: Algorithms, tech- niques, and applications,” ACM Comput. Surv., vol. 51, no. 5, pp. 1–36, Sep. 2018. [9] A. Sharma et al., “Multi-agent system applications to ﬁght COVID-19 pandemic,” Apollo Med., vol. 17, no. 5, p. 41, 2020. [10] B. Wang et al., “AI-assisted CT imaging analysis for COVID-19 screening: Building and deploying a medical AI system,” Appl. Soft Comput., vol. 98, Jan. 2021, Art. no. 106897. [11] S. Wang et al., “A deep learning algorithm using CT images to screen for corona virus disease (COVID-19),” Eur. Radiol., vol. 31, pp. 6096–6104, Feb. 2021. [12] D. M. Khan, K. Masroor, M. F. M. Jailani, N. Yahya, M. Z. Yusoff, and S. M. Khan, “Development of wavelet coherence EEG as a biomarker for diagnosis of major depressive disorder,” IEEE Sensors J., vol. 22, no. 5, pp. 4315–4325, Mar. 2022. [13] R. Wang et al., “A standalone and portable microﬂuidic imaging detec- tion system with embedded computing for point-of-care diagnostics,” IEEE Sensors J., vol. 22, no. 6, pp. 6116–6123, Mar. 2022. [14] N. Balachandar, K. Chang, J. Kalpathy-Cramer, and D. L. Rubin, “Accounting for data variability in multi-institutional distributed deep learning for medical imaging,” J. Amer. Med. Inform. Assoc., vol. 27, no. 5, pp. 700–708, May 2020. [15] S. S. Roy, K. Samanta, S. Modak, S. Chatterjee, and R. Bose, “Cross spectrum aided deep feature extraction based neuromuscular disease detection framework,” IEEE Sensors Lett., vol. 4, no. 6, pp. 1–4, Jun. 2020. [16] H. Ku, W. Susilo, Y. Zhang, W. Liu, and M. Zhang, “Privacy- preserving federated learning in medical diagnosis with homomorphic re-encryption,” Comput. Standards Interfaces, vol. 80, Mar. 2022, Art. no. 103583. [17] X. Xu, H. Tian, X. Zhang, L. Qi, Q. He, and W. Dou, “DisCOV: Dis- tributed COVID-19 detection on X-ray images with edge-cloud collab- oration,” IEEE Trans. Services Comput., vol. 15, no. 3, pp. 1206–1219, May 2022. [18] R. Dwivedi, S. Dey, C. Chakraborty, and S. Tiwari, “Grape disease detection network based on multi-task learning and attention features,” IEEE Sensors J., vol. 21, no. 16, pp. 17573–17580, Aug. 2021. [19] U. Ahmed, J. C.-W. Lin, G. Srivastava, R. Yasin, and Y. Djenouri, “An evolutionary model to mine high expected utility patterns from uncertain databases,” IEEE Trans. Emerg. Topics Comput. Intell., vol. 5, no. 1, pp. 19–28, Feb. 2021. [20] P. Srinivas and R. Katarya, “HyOPTXg: OPTUNA hyper-parameter optimization framework for predicting cardiovascular disease using XGBoost,” Biomed. Signal Process. Control, vol. 73, Mar. 2022, Art. no. 103456. [21] C.-W. Lin, T.-P. Hong, G.-C. Lan, J.-W. Han, and W.-Y. Lin, “Incre- mentally mining high utility patterns based on pre-large concept,” Appl. Intell., vol. 40, no. 2, pp. 343–357, Mar. 2014. [22] J. C.-W. Lin, W. Gan, P. Fournier-Viger, T.-P. Hong, and J. Zhan, “Efﬁcient mining of high-utility itemsets using multiple minimum utility thresholds,” Knowl.-Based Syst., vol. 113, pp. 100–115, Dec. 2016. [23] W. Gan, J. C.-W. Lin, J. Zhang, P. Fournier-Viger, H.-C. Chao, and P. S. Yu, “Fast utility mining on sequence data,” IEEE Trans. Cybern., vol. 51, no. 2, pp. 487–500, Feb. 2021. [24] M. S. Nawaz, P. Fournier-Viger, A. Shojaee, and H. Fujita, “Using artiﬁcial intelligence techniques for COVID-19 genome analy- sis,” Int. J. Speech Technol., vol. 51, no. 5, pp. 3086–3103, May 2021. [25] Y. Yan et al., “Topological descriptors of gait nonlinear dynamics toward freezing-of-gait episodes recognition in Parkinson’s disease,” IEEE Sensors J., vol. 22, no. 5, pp. 4294–4304, Mar. 2022. [26] R. Jain, M. Gupta, S. Taneja, and D. J. Hemanth, “Deep learning based detection and analysis of COVID-19 on chest X-ray images,” Appl. Intell., vol. 51, pp. 1690–1700, Oct. 22021. [27] A. Sedik, M. Hammad, F. E. Abd El-Samie, B. B. Gupta, and A. A. Abd El-Latif, “Efﬁcient deep learning approach for augmented detection of Coronavirus disease,” Neural Comput. Appl., vol. 34, pp. 11423–11440, Jan. 2021. [28] M. Manoj, G. Srivastava, S. R. K. Somayaji, T. R. Gadekallu, P. K. R. Maddikunta, and S. Bhattacharya, “An incentive based approach for COVID-19 planning using blockchain technology,” in Proc. IEEE Globecom Workshops (GC Wkshps), Dec. 2020, pp. 1–6. [29] S. Chae, S. Kwon, and D. Lee, “Predicting infectious disease using deep learning and big data,” Int. J. Environ. Res. Public Health, vol. 15, no. 8, p. 1596, Jul. 2018. [30] S. Ahuja, B. K. Panigrahi, N. Dey, V. Rajinikanth, and T. K. Gandhi, “Deep transfer learning-based automated detection of COVID-19 from lung CT scan slices,” Appl. Intell., vol. 51, no. 1, pp. 571–585, 2021. [31] Z. S. Y. Wong, J. Zhou, and Q. Zhang, “Artiﬁcial intelligence for infectious disease big data analytics,” Infection, Disease Health, vol. 24, no. 1, pp. 44–48, Feb. 2019. [32] H. Hirano, A. Minagi, and K. Takemoto, “Universal adversarial attacks on deep neural networks for medical image classiﬁcation,” BMC Med. Imag., vol. 21, no. 1, pp. 1–13, Dec. 2021. [33] M. Jamshidi et al., “Artiﬁcial intelligence and COVID-19: Deep learn- ing approaches for diagnosis and treatment,” IEEE Access, vol. 8, pp. 109581–109595, 2020. [34] P. Singh, A. Verma, and J. S. R. Alex, “Disease and pest infection detection in coconut tree through deep learning techniques,” Comput. Electron. Agricult., vol. 182, Mar. 2021, Art. no. 105986. [35] P. Gifani, A. Shalbaf, and M. Vafaeezadeh, “Automated detection of COVID-19 using ensemble of transfer learning with deep convolutional neural network based on CT scans,” Int. J. Comput. Assist. Radiol. Surgery, vol. 16, no. 1, pp. 115–123, Jan. 2021. [36] D. Moolchandani, A. Kumar, and S. R. Sarangi, “Accelerating CNN inference on ASICs: A survey,” J. Syst. Archit., vol. 113, Feb. 2021, Art. no. 101887. [37] K. Pogorelov et al., “Kvasir: A multi-class image dataset for computer aided gastrointestinal disease detection,” in Proc. 8th ACM Multimedia Syst. Conf., 2017, pp. 164–169. [38] F. Chollet, “Xception: Deep learning with depthwise separable convo- lutions,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jul. 2017, pp. 1251–1258. [39] F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally, and K. Keutzer, “SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5 MB model size,” 2016, arXiv:1602.07360. [40] Y. Djenouri and M. Comuzzi, “Combining Apriori heuristic and bio- inspired algorithms for solving the frequent itemsets mining problem,” Inf. Sci., vol. 420, pp. 1–15, Dec. 2017. [41] M. Wo´zniak, J. Siłka, and M. Wieczorek, “Deep neural network correla- tion learning mechanism for CT brain tumor detection,” Neural Comput. Appl., vol. 1, pp. 1–16, Mar. 2021, doi: 10.1007/s00521-021-05841-x. [42] P. N. Ramkumar et al., “Clinical and research medical applications of artiﬁcial intelligence,” Arthroscopy: J. Arthroscopic Related Surg., vol. 37, no. 5, pp. 1694–1697, 2021. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply."
Solving Two-Person Zero-Sum Stochastic Games With Incomplete Information Using Learning Automata With Artificial Barriers,"Yazidi, Anis and Silvestre, Daniel and Oommen, B. John",2023,2.0,34,IEEE Transactions on Neural Networks and Learning Systems,article,"650
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023
Solving Two-Person Zero-Sum Stochastic Games
With Incomplete Information Using Learning
Automata With Artiﬁcial Barriers
Anis Yazidi
, Senior Member, IEEE, Daniel Silvestre
, and B. John Oommen
, Life Fellow, IEEE
Abstract—Learning automata (LA) with artiﬁcially absorbing
barriers was a completely new horizon of research in the 1980s
(Oommen, 1986). These new machines yielded properties that
were previously unknown. More recently, absorbing barriers
have been introduced in continuous estimator algorithms so
that the proofs could follow a martingale property, as opposed
to monotonicity (Zhang et al., 2014), (Zhang et al., 2015).
However, the applications of LA with artiﬁcial barriers are almost
nonexistent. In that regard, this article is pioneering in that it
provides effective and accurate solutions to an extremely complex
application domain, namely that of solving two-person zero-sum
stochastic games that are provided with incomplete information.
LA have been previously used (Sastry et al., 1994) to design
algorithms capable of converging to the game’s Nash equilibrium
under limited information. Those algorithms have focused on
the case where the saddle point of the game exists in a pure
strategy. However, the majority of the LA algorithms used for
games are absorbing in the probability simplex space, and thus,
they converge to an exclusive choice of a single action. These
LA are thus unable to converge to other mixed Nash equilibria
when the game possesses no saddle point for a pure strategy.
The pioneering contribution of this article is that we propose
an LA solution that is able to converge to an optimal mixed
Nash equilibrium even though there may be no saddle point
when a pure strategy is invoked. The scheme, being of the linear
reward-inaction (L R−I) paradigm, is in and of itself, absorbing.
However, by incorporating artiﬁcial barriers, we prevent it
from being “stuck” or getting absorbed in pure strategies.
Unlike the linear reward-ϵpenalty (L R−ϵ P) scheme proposed by
Lakshmivarahan and Narendra almost four decades ago, our
new scheme achieves the same goal with much less parameter
tuning and in a more elegant manner. This article includes
Manuscript received 2 October 2020; revised 16 February 2021; accepted
18 May 2021. Date of publication 4 August 2021; date of current ver-
sion 6 February 2023. The work of Daniel Silvestre was supported in
part by the Portuguese Fundação para a Ciência e a Tecnologia (FCT)
through the Institute for Systems and Robotics (ISR), Laboratory for Robot-
ics and Engineering Systems (LARSyS), under Project UIDB/50009/2020,
through FirePuma Project under Grant PCIF/MPG/0156/2019, and through
COPELABS, University Lusófona, under Project UIDB/04111/2020. The
work of B. John Oommen was supported in part by the Natural Sciences
and Engineering Research Council of Canada (NSERC) and in part by the
Natural Sciences and Engineering Council of Canada. (Corresponding author:
B. John Oommen.)
Anis Yazidi is with the Department of Computer Science, Oslo Metropolitan
University, 0190 Oslo, Norway (e-mail: anis.yazidi@oslomet.no).
Daniel Silvestre is with Dynamical Systems and Ocean Robotics Laboratory
(DSOR), Department of Electrical and Computer Engineering, Lusófona Uni-
versity, 1749-024 Lisbon, Portugal, and also with the Institute for Systems and
Robotics, Instituto Superior Técnico, University of Lisbon, 1049-001 Lisbon,
Portugal (e-mail: dsilvestre@isr.tecnico.ulisboa.pt).
B. John Oommen is with the School of Computer Science, Carleton Univer-
sity, Ottawa, ON K1S 5B6, Canada, and also with the Department of IKT, Uni-
versity of Agder, 4879 Grimstad, Norway (e-mail: oommen@scs.carleton.ca).
Color versions of one or more ﬁgures in this article are available at
https://doi.org/10.1109/TNNLS.2021.3099095.
Digital Object Identiﬁer 10.1109/TNNLS.2021.3099095
the nontrial proofs of the theoretical results characterizing our
scheme and also contains experimental veriﬁcation that conﬁrms
our theoretical ﬁndings.
Index Terms—Games with incomplete information, learning
automata (LA), LA with artiﬁcial barriers.
I. INTRODUCTION
T
HE term learning automata (LA) denotes a whole subﬁeld
of research within adaptive systems with several books
being dedicated to its study [2], [5], [6], [12], [14]. The work
on LA dates to the Soviet Union in the 1960s when the
mathematical giant Tsetlin et al. [15] devised the so-called
Tsetlin machine that is a learning mechanism with ﬁnite mem-
ory. Tsetlin’s learning machines were demonstrated to give
birth to self-organizing behavior through collective learning.
In his work, Tsetlin pioneered the Goore game, which is a
distributed coordination game with limited feedback that has
many practical applications, as shown by Tung and Kleinrock
[16]. The early works in the ﬁeld of LA, such as the Tsetlin
machine, fall under the family of ﬁxed structure LA. The
mainstream of current LA research concerns the family of
variable structure LA (VSLA) which, loosely speaking, differs
from ﬁxed structure LA in the fact that they operate with
a probability vector that is updated dynamically over time.
In ﬁxed structure LA, the choice is governed by a transition
matrix whose transitions do not depend on time and that
describes how the internal states of the LA are updated based
on the environment’s feedback. The term LA was coined for
the ﬁrst time by Narendra and Thathachar [6].
Markovian Representations of LA: LA can also be charac-
terized by their Markovian representations. They thus fall into
one of two families, being either ergodic or those that possess
absorbing barriers [8]. Such a characterization is crucial to
the tenets of this article. Absorbing automata have underlying
Markov chains that get absorbed or locked into a barrier
state. Sometimes, this can occur even after a relatively small,
ﬁnite number of iterations. The classic references [2], [5],
[6], [12], [14] report numerous LA families that contain such
absorbing barriers. On the other hand, as these same references
explain, the literature has also reported scores of ergodic
automata, which converge in distribution. In these cases,
the asymptotic distribution of the action probability vector
converges to a value that is independent of its initial vector.
Absorbing LA are usually designed to operate in stationary
environments. As opposed to these, ergodic LA are preferred
for nonstationary environments, namely those that possess
2162-237X © 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION
651
time-dependent reward probabilities. These characterizations,
and their corresponding implications for game playing, will
be explained presently.
Continuous or Discretized VSLA: VSLA can also be char-
acterized as being continuous or discretized. This depends on
the values that the action probabilities can take. Continuous
LA allow the action probabilities to assume any value in the
interval [0, 1]. Such algorithms have a relatively slow rate of
convergence. The problem with continuous LA is that they
approach a goal but never reach there. This was mitigated in
the 1980s by introducing the concept of discretization, where
if an action probability was close enough to zero or unity,
it could jump to that endpoint in a single step. This also ren-
dered the LA to have a faster convergence because one could
increase their speeds of convergence by incorporating this
phenomenon [3], [4], [9]. This is implemented by constraining
the action selection probability to be one of a ﬁnite number of
values in the interval [0, 1]. By incorporating discretization,
almost all of the reported VSLA of the continuous type have
also been discretized [9], [10], [19].
LA With Artiﬁcially Absorbing Barriers: LA with artiﬁ-
cially introduced absorbing barriers were a novelty in the
1980s. These yielded machines, which had properties that
were previously unknown. This was due to the fact that a
discretized machine, even though it was ergodic, could be
rendered absorbing by forcing the machine to stay at one of the
absorbing barriers [8]. Ironically, this simple step introduced
families of new LA, with properties that were previously
unknown. For example, ADLR−P and ADLI−P are absorbing
versions of their corresponding ergodic counterparts but have
been proven to be ϵ-optimal in all random environments. This
phenomenon, of including artiﬁcially absorbing barriers, has
been recently applied to the family of pursuit LA [18].
Estimator LA With Artiﬁcial Barriers: The concept of
introducing absorbing barriers is also central to the proofs
of estimator algorithms. For three decades, these pursuit
algorithms were “proven” to be ϵ-optimal by virtue of the
monotonicity property. However, recently, these proofs have
been shown to be ﬂawed. To remedy this, absorbing barriers
have been introduced in continuous estimator algorithms so
that the proofs could follow a martingale property, as opposed
to monotonicity. Consequently, Zhang et al. [18]–[20] have
shown that one can invoke this weaker property, namely,
the martingale property, by artiﬁcially providing such an
absorbing barrier. Thus, whenever an action probability is
close enough to unity, the LA is forced to jump to this
absorbing barrier.
Applications of LA: LA have boasted scores of applica-
tions. These include theoretical problems, such as the graph
partitioning problem. They have been used in controlling intel-
ligent vehicles. When it concerns neural networks and hidden
Markov models, Meybodi et al. have used them in adapting
the former, and others have applied them in training the latter.
Network call admission, trafﬁc control, and quality-of-service
routing have been resolved using LA, while others have also
found applications in tackling problems involving network and
communications issues. Apart from these, the entire ﬁeld of
LA and stochastic learning has had a myriad of applications
listed in the reference books [2], [5], [6], [14]. In the interest
of the page-limit constraints, the citations to these applications
are not included. However, they can be easily found by
executing a simple search, and many are included in the above
benchmark references.
Game Playing With LA: While artiﬁcially introduced barri-
ers have been shown to have powerful theoretical and design
implications, the applications of them are few. This is where
this article ﬁnds its place—it presents one such application.
LA have also been used to resolve stochastic games with
incomplete information. This article pioneers a merge of the
above two issues. First of all, we present a mechanism by
which LA can be augmented with artiﬁcial barriers, but unlike
the state of the art, these barriers are nonabsorbing. We then
proceed to use these to play zero-sum games with incomplete
information. Games of this type were studied four decades ago
for scenarios when the game matrix had a saddle point using
traditional L R−I and L R−P LA [13]. Our results generalize
those when the game does not possess the Nash equilibrium.
Rather, we propose the nontrivial use of LA with artiﬁcial
nonabsorbing barriers to resolve such games. This article
contains the theoretical results and those from simulations
using the corresponding benchmark games.
Landscape of Our Present Work: In this article, we pro-
pose an algorithm addressing zero-sum games, which can be
generalized to nonzero-sum games in a manner similar to the
principle by which the method in [1] was generalized in [17].
In the latter, Xing and Chandramouli [17] proved that the linear
reward−ϵpenalty (L R−ϵP) algorithm, devised in [1], is able to
work in nonzero-sum games. Thus, without further elaborating
on this,1 our results are generalizable to nonzero-sum games.
Since the game is zero-sum, the outcomes are either a
loss for player A, with reward −1, and the corresponding
win for player B with value +1, or the converse for the
case of a win for player A. We emphasize that this is a
limited information game where each player is unaware of
both the mixed strategy and the selected action of the other
player. The available information to each player is whether its
action resulted in a win or a loss. The reader should note that
either/both players might not even be aware of the existence
of another player and be working with the assumption that
he is playing against nature, as in the classical multiarmed
bandit algorithms. However, if both players learn using our
algorithm based on the assumption that they are operating
in an adversarial environment, we show that they will both
converge to the desired equilibrium. Our proposed scheme has
players adjusting their strategy whenever it obtains a “win”
for that round. This conforms to the linear reward-inaction
(L R−I) paradigm, described in detail, presently. It is thus,
unarguably, radically different from the mechanism proposed
by Lakshmivarahan and Narendra [1], where the probability
updates are performed upon receiving both reward and penalty
responses, which thus renders changes to occur at every time
instant.
1Some preliminary unpublished work is being conducted for extending this
work to nonzero-sum games.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 652
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023
Objective and Contribution of This Article: Based on the
above discussion, one can summarize the objective of this
article as to study the behavior of a nonabsorbing barrier-based
L R−I mechanism in a stochastic zero-sum game played by two
players A and B, with two actions each, as earlier done in [1].
Each player uses an LA to decide his strategy, where the only
received feedback from the environment is the reward of the
joint actions of both players. The game is played iteratively
and the players are able to revise their mixed strategies.
Applications of the Proposed Method: Learning within the
context of games has a natural application in the realm of
game theory. However, in the context of multiagent systems
(MASs), this has been shown to be suitable for the cooperative
control of robotic systems [21]. In such a design, it is assumed
that the mission can be fully described as a potential game,
where the utility function measures how well the nodes in
the network are complying with the objectives. Nevertheless,
having robots converging to pure strategies means that the
network designer is favoring exploitation and disregarding
exploration. If the environment changes and causes a different
payoff matrix, the agent would be locked into repeatedly
playing the same strategy. Moreover, this assumes that the
utility must be known and deterministic. Therefore, instead of
designing application-speciﬁc algorithms, the proposed learn-
ing algorithm can be used to address problems in cooperative
control such as the so-called “rendezvous” problem for a ﬂeet
of robots [26], [27], the desynchronization of the use of a
shared medium [22], [23], and a consensus algorithm to have
the agents agree on a common value [24] or to solve distributed
computation such as the PageRank [25], by only considering
the current stochastic payoff.
It is also pertinent to mention that the mechanism that we
propose here can be used by the agents to learn how to act if
the payoff corresponds to how successful they are in following
the objectives of the “mission.” Much can be said about this,
but we terminate these discussions here in the interest of
brevity and due to space limitations. However, with respect
to future research, it is wise to mention that the question
of whether they can be applied to synchronization, as in the
analysis of the family of so-called “Fireﬂy” algorithms, is yet
open.
A. Notation Used
Most of the notations that we use are well established from
the theory of matrices and in the ﬁeld of LA [2], [6], and
stating them would trivialize this article. However, we mention
that apart from the well-established notations used in these
areas, we will use the notation that the conditional expectation
of some variable v with respect to w is written as E[v|w] and
the partial derivative of a variable v(t) with respect to time t
is denoted by (∂v(t)/∂t).
II. GAME MODEL
To initiate discussions, we formalize the game model that
is being investigated. Let P(t)
=
p1(t) p2(t)⊺denote
the mixed strategy of player A at time instant t, where
p1(t) accounts for the probability of adopting strategy 1
and, conversely, p2(t) stands for the probability of adopting
strategy 2. Thus, P(t) describes the distribution over the
strategies of player A. Similarly, we can deﬁne the mixed
strategy of player B at time t as Q(t) =
q1(t) q2(t)⊺.
The extension to more than two actions per player is
straightforward following the method analogous to what was
used by Papavassilopoulos [11], which extended the work of
Lakshmivarahan and Narendra [1].
Let αA(t) ∈{1, 2} be the action chosen by player A at time
instant t and αB(t) ∈{1, 2} be the one chosen by player B,
following the probability distributions P(t) and Q(t), respec-
tively. The pair (αA(t), αB(t)) constitutes the joint action at
time t and is pure strategy. Speciﬁcally, if (αA(t), αB(t)) =
(i, j), the probability of gain for player A is determined by di j,
as formalized in [1]. We thus construct a matrix with the set
of probabilities D = [di j], 1 ≤i ≤2, which is the so-called
payoff matrix associated with the game.
The matrix D is given by
D =
d11
d12
d21
d22

(1)
where all the entries are probabilities.
Clearly, the actual game matrix G is given by gi j = 2 di j−1,
with entries in the interval [−1, 1]. Without loss of generality,
player A corresponds to the row player, whereas B is the
column player. Furthermore, when referring to a “gain,” we
are seeing this from the perspective of player A.
In zero-sum games, Nash equilibria are equivalently called
the “saddle points” for the game. Since the outcome for a given
joint action is stochastic, the game is the stochastic form of a
zero-sum game. The “zero-sum” property implies that at any
time t, there is only one winning player.2
In the interest of completeness, we present the original
scheme proposed in [1] based on the L R−ϵP rule. It uses two
parameters θR and θP as the learning rates associated with
the reward and penalty responses, respectively. When player
A gains at time instant t by playing action i, he updates his
mixed strategy as
pi(t + 1) = pi(t) + θR(1 −pi(t))
ps(t + 1) = ps(t) −θP ps(t)
for
s ̸= i.
However, if player A loses after using action i, his mixed
strategy is updated by the following:
pi(t + 1) = pi(t) −θP pi(t)
ps(t + 1) = ps(t) + θR(1 −ps(t))
for s ̸= i.
The exact update mechanism for player B is obtained by
replacing the corresponding p(t) by q(t) and by recalling that
a gain for A maps onto a loss scenario for player B. We now
introduce our novel solution that is proposed to learn a new
mixed strategy.
2The results inferred from this article can be extended to nonzero-sum
games. However, for the sake of simplicity, we only consider the case of
zero-sum games.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION
653
III. LA ALGORITHM BASED ON L R−I WITH
ARTIFICIAL BARRIERS
A. Nonabsorbing Artiﬁcial Barriers
We have earlier seen that an ergodic LA can be made
absorbing by artiﬁcially rendering the end states to become
absorbing. This was brieﬂy addressed above. However, what
has not been discussed in the literature is a strategy by which a
scheme which is, in and of itself, absorbing, can be rendered to
be ergodic. In other words, the LA are allowed to move within
the probability simplex by utilizing an absorbing scheme.
However, when it enters an absorbing barrier, the scheme
is forced to go back into the simplex in order to render it
to be ergodic. No such scheme has ever been reported in
the literature, and the advantage of having such a scheme
is that one does not get locked into a suboptimal absorbing
barrier. Rather, we can permit it to move around so that it can
migrate stochastically toward an optimal mixed strategy. This
is, precisely, what we shall do.
B. Nonabsorbing Game Playing
We now present our strategic LA-based game algorithm
together with a formal analysis that demonstrates the conver-
gence to the saddle points of the game even if the saddle point
corresponds to a mixed Nash equilibrium. Our LA solution is
based on the L R−I scheme, but as alluded to earlier, it has
been modiﬁed in order to nontrivially provide nonabsorbing
barriers. The proof of convergence is based on Norman’s
theory for learning processes characterized by small learning
steps [6], [7].
Considering that pmax denotes an artiﬁcial barrier, we use
the notation that pmin = 1 −pmax. We further constrain
the probability for each action by restricting it, by design,
to belong to the interval [pmin, pmax] if p1(0) and q1(0) are
initially chosen to belong to the same interval. If the outcome
from the environment is a gain at a time t for action i ∈{1, 2},
the update rule is given by
pi(t + 1) = pi(t) + θ(pmax −pi(t))
ps(t + 1) = ps(t) + θ(pmin −ps(t)) for s ̸= i.
(2)
The reader will observe that this update mechanism is
identical to the well-established linear schemes, except that
pmin and pmax replace the values zero and unity, respectively.
When the player receives a loss, the probabilities are not
updated, which translates into
pi(t + 1) = pi(t)
ps(t + 1) = ps(t) for s ̸= i.
(3)
The update rules for the mixed strategy q(t +1) are deﬁned
in a similar fashion by recalling the dichotomy that whenever
player A gains, it corresponds to a loss for player B and vice
versa. Analogous to the L R−I paradigm, mixed strategies are
not changed in the case of a loss.
We now proceed to analyze the convergence properties of
the proposed algorithm. To aid in the analysis, we identify the
Nash equilibrium of the game by the pair (popt, qopt). To render
the presentation to be less cumbersome, we divide the analysis
into two cases.
1) Case 1 [Only One Mixed Nash Equilibrium Case (No
Saddle Point in Pure Strategies)]: The ﬁrst case depicts the
situation where no saddle point exists in pure strategies.
In other words, the only Nash equilibrium is a mixed one.
Based on the fundamentals of game theory, the optimal mixed
strategies can be easily shown to be the following:
popt = d22 −d21
L
,
qopt = d22 −d12
L
where L = (d11+d22)−(d12+d21). Without loss of generality,
we assume that
d11 > max{d12, d21}
and d22 > max {d12, d21}.
(4)
Notice that the above inequalities are not restrictive,
as games not satisfying them can be mapped in a symmetric
manner by reindexing the actions of the players and/or the
indices of the players.
2) Case 2 (There Is a Saddle Point in Pure Strategies): The
case where the game matrix has saddle points in pure strategies
corresponds to either: 1) d11 > d12, d12 < d21, d21 > d22, and
d22 < d11 or 2) in the symmetric case, where d11 < d12,
d12 > d21, d21 < d22, and d22 > d11.
Since the other cases can be proven in identical manners,
in the interest of brevity, we consider only the case where
d21 < d11 < d12.
(5)
In this case, popt = 1 and qopt = 1. The other subcases
within Case 2 can be obtained by reindexing the actions of
the players and/or the indices of the players, as in Case 1.
Let the vector X(t) =
p1(t) q1(t)⊺. We introduce the
notation that X(t) = X(t + 1) −X(t). We also represent
the conditional expected value operator by E[·|·]. Using these,
we claim the next theorem.
Theorem 1: Consider a zero-sum game with a payoff matrix
as in (1) and a learning algorithm deﬁned by (2) and (3)
for both players A and B, with learning rate θ. Then,
E[X(t)|X(t)] = θW(x), and for every ϵ
> 0, there
exists a unique stationary point X∗=
p∗
1 q∗
1
⊺satisfying the
following conditions.
1) W(X∗) = 0.
2) |X∗−Xopt| < ϵ.
Proof:
Let us ﬁrst compute the conditional expected
value3 of the increment X(t)
E[X(t)|X(t)] = E[X(t + 1) −X(t)|X(t)]
=
 E[p1(t + 1) −p1(t)|X(t)]
E[q1(t + 1) −q1(t)|X(t)])

= θ
W1(X(t))
W2(X(t))

= θW(X(t))
where the above format is possible since all possible updates
share the form X(t) = θW(t), for some W(t), as given
in (2).
3Computing the “expected value of the increment” is a standard procedure
in the theory of LA. This is because the increment, in and of itself, is a random
variable, which is sometimes positive and sometimes negative. Quantifying the
latter is not possible due to the randomness of the updating rule. However,
the conditional expected value of the increment can be determined, whence
(by invoking the “Law of the Unconscious Statistician”), one can determine
the expected value of the increment itself.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 654
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023
For ease of notation, we drop the dependence on t with
the implicit assumption that all occurrences of X, p1, and q1
represent X(t), p1(t), and q1(t), respectively. W1(x) is then
W1(X)
= p1q1d11(pmax −p1) + p1(1 −q1)d12(pmax −p1)
+(1 −p1)q1d21(pmin −p1)
+(1 −p1)(1 −q1)d22(pmin −p1)
= p1[q1d11 + (1 −q1)d12](pmax −p1)
+(1 −p1)[q1d21 + (1 −q1)d22](pmin −p1)
= p1(pmax −p1)D A
1 (q1) + (1 −p1)(pmin −p1)D A
2 (q1)
(6)
where
D A
1 (q1) = q1d11 + (1 −q1)d12
(7)
D A
2 (q1) = q1d21 + (1 −q1)d22.
(8)
By replacing pmax = 1 −pmin and rearranging the expres-
sion, we get
W1(X) = p1(1 −p1)D A
1 (q1) −p1 pminD A
1 (q1)
+(1 −p1)pminD A
2 (q1) −p1(1 −p1)D A
2 (q1)
= p1(1 −p1)

D A
1 (q1) −D A
2 (q1)

−pmin

p1 D A
1 (q1) −(1 −p1)D A
2 (q1)

.
Similarly, we can get
W2(X)
= q1 p1(1 −d11)(pmax −q1)
+q1(1 −p1)(1 −d12)(pmax −q1)
+(1 −q1)p1(1 −d21)(pmin −q1)
+(1 −q1)(1 −p1)(1 −d22)(pmin −q1)
= q1[p1(1 −d11) + (1 −p1)(1 −d12)](pmax −q1)
+(1 −q1)[p1(1 −d21) + (1 −p1)(1 −d22)](pmin −q1)
= q1(pmax −q1)

1 −DB
1 (p1)

+(1 −q1)(pmin −q1)
1 −DB
2 (p1)

(9)
where
DB
1 (p1) = p1d11 + (1 −p1)d21
(10)
DB
2 (p1) = p1d12 + (1 −p1)d22.
(11)
By replacing pmax = 1 −pmin and rearranging the expres-
sion, we get
W2(X)
= q1(1 −q1)
 1 −DB
1 (p1)
 −q1 pmin
 1 −DB
1 (p1)
+(1 −q1)pmin
 
1 −DB
2 (p1) −q1(1 −q1)
 
1 −DB
2 (p1)
 
= −q1(1 −q1)

DB
1 (p1) −DB
2 (p1)

+pmin

−q1
 
1 −DB
1 (p1)
 
+ (1 −q1)
 
1 −DB
2 (p1)
 
= −q1(1 −q1)

DB
1 (p1) −DB
2 (p1)

+pmin
q1DB
1 (p1) −(1 −q1)DB
2 (p1) + (1 −2q1)
.
(12)
We need to address the two identiﬁed cases. Consider
Case 1), where there is only a single mixed equilibrium.
According to (4), we get
D A
12(q1) = D A
1 (q1) −D A
2 (q1)
= (d12 −d22) + Lq1.
(13)
Given that L > 0, since d11 > d12 and d22 > d21, D A
12(q1)
is an increasing function of q1 and
⎧
⎪⎨
⎪⎩
D A
12(q1) < 0, if q1 < qopt
D A
12(q1) = 0, if q1 = qopt
D A
12(q1) > 0, if q1 > qopt.
(14)
For a given q1, W1(X) is quadratic in p1. Also, we have
W1
 0
q1

= pminD A
2 (q1) > 0
W1
 1
q1

= −pminD A
1 (q1) < 0.
(15)
Since W1(X) is quadratic with a negative second derivative
with respect to p1 and the inequalities in (15) are strict,
it admits a single root p1 for p1 ∈[0, 1]. Moreover, we have
W1(X) = 0 for some p1 such that
⎧
⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎩
p1 < 1
2, if q1 < qopt
p1 = 1
2, if q1 = qopt
p1 > 1
2, if q1 > qopt.
(16)
Using a similar argument, we can see that there exists a
single solution for each p1, and as pmin →0, we conclude
that W1(X) = 0 whenever p1 ∈{0, popt, 1}. Arguing in a
similar manner, we see that W2(X) = 0 when
X ∈
0
0

,
0
1

,
1
0

,
popt
qopt

.
Thus, there exists a small enough value for pmin such that
X∗= [p∗, q∗]⊺satisﬁes W2(X∗) = 0, proving Case 1).
In the proof of Case 1), we have utilized the fact that for
small enough pmin, the learning algorithm admits a stationary
point and also identiﬁed the corresponding possible values for
this point. It is thus always possible to select a small enough
pmin > 0 such that X∗approaches Xopt, concluding the proof
for Case 1).
Case 2) can be derived in a similar manner, and the details
are omitted to avoid repetition.
□
In the next theorem, we show that the expected value of
X(t) has a negative deﬁnite gradient.
Theorem 2: The
matrix
of
partial
derivatives,
((∂W(X∗))/∂x), is negative deﬁnite.
Proof: We start the proof by writing the explicit format
for
∂W(X)
∂X
=
⎡
⎢⎢⎣
∂W1(X)
∂p1
∂W1(X)
∂q1
∂W2(X)
∂p1
∂W2(X)
∂q1
⎤
⎥⎥⎦
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION
655
and then computing each of the entries as follows:
∂W1(X)
∂p1
= (1 −2p1)
 
D A
1 (q1) −D A
2 (q1)
 
−pmin
 
D A
1 (q1) + D A
2 (q1)
 
= (1 −2p1)D A
12(q1)
−pmin
 D A
1 (q1) + D A
2 (q1)
 
∂W1(X)
∂q1
= p1(1 −p1)L −pmin(p1(d11 −d12)
+(1 −p1)(d22 −d21))
∂W2(X)
∂p1
= −q1(1 −q1)L + pmin((q1(d11 −d21)
−(1 −q1)(d12 −d22))
∂W2(X)
∂q1
= −(1 −2q1)
 
DB
1 (p1) −DB
2 (p1)
 
+pmin
 
DB
1 (p1) + DB
2 (p1) −2
 
.
As seen in Theorem 1, for a small enough value for pmin,
we can ignore the terms that are weighted by pmin, and we
will thus have ((∂W(X∗))/∂X) ≈((∂W(Xopt))/∂X). We now
subdivide the analysis in the two cases identiﬁed as above,
which are equivalent to the following.
1) Case 1: No saddle point in pure strategies.
2) Case 2: There is a saddle point in pure strategies.
3) Case 1 (No Saddle Point in Pure Strategies): In this case,
we have
D A
1
 
qopt
 
= D A
2
 
qopt
 
and DB
1
 
popt
 
= DB
2
 
popt
 
which makes
∂W1
 
Xopt
 
∂p1
= −2pminD A
1
 
qopt
 
.
(17)
Similarly, we can compute
∂W1
 
Xopt
 
∂q1
= (1 −2pmin)popt
 1 −popt
 L.
(18)
The entry ((∂W2(Xopt))/∂p1) can be simpliﬁed to
∂W2
 Xopt
 
∂p1
= −(1 −2pmin)qopt
 
1 −qopt
 
L
(19)
and
∂W2
 
Xopt
 
∂q1
= −2pmin
 
1 −DB
1
 
popt
  
(20)
resulting in (21), as shown at the bottom of the page.
The matrix given in (21) satisﬁes
det

∂W
 
Xopt
 
∂x

> 0 , trace

∂W
 
Xopt
 
∂x

< 0
(22)
which implies that the 2 × 2 matrix is negative deﬁnite.
4) Case 2 (There Is a Saddle Point in Pure Strategies):
In Theorem 1, Case 2 reduces to considering qopt = 1 and
popt = 1.
Computing the entries of the matrix for this case yields
∂W1
 
Xopt
 
∂p1
= −(d11 −d21) −pmin(d11 + d21)
(23)
and
∂W1
 
Xopt
 
∂q1
= −pmin(d11 −d12).
(24)
The entry ((∂W2(Xopt))/∂p1) can be simpliﬁed to
∂W2
 
Xopt
 
∂p1
= pmin(d11 −d21)
(25)
and
∂W2
 
Xopt
 
∂q1
= (d11 −d12) −pmin(2 −d11 −d12)
(26)
resulting in (27), as shown at the bottom of the next page.
The matrix in (27) satisﬁes
det

∂W
 
Xopt
 
∂X

> 0 , trace

∂W
 
Xopt
 
∂X

< 0
(28)
for a sufﬁciently small value of pmin, which again implies that
the 2 × 2 matrix is negative deﬁnite.
□
Theorem 3: Let V be the von Neumann value of the game
given by matrix D. Let p(t) = [p1, p2] and q(t) = [q1, q2].
For a sufﬁciently small pmin approaching 0, η(t) converges to
V as θ →0 where
η(t) ≜Ep(t)
DEqT (t)
.
(29)
Proof: The proof of these results requires a classic result
due to Norman [7], given in the Appendix, in the interest of
completeness.
The convergence of
E(p1(t)) E(q1(t))
to
p∗
opt q∗
opt

is
a consequence of this theorem. Interestingly enough, this
theorem is a classical fundamental result that has been used
to prove many of the convergence results in LA. It has, for
example, been used by the seminal paper by Lakshmivarahan
and Narendra [1] to derive similar convergence properties of
the L R−ϵP, applicable for the same game settings as ours.
Indeed, it is easy to verify that Assumptions (1)–(6) required
for Norman’s result are satisﬁed. Thus, by further invoking
Theorem 1 and Theorem 2, the result follows.
□
We conclude this section by mentioning that like all LA
algorithms, the computational complexity of our scheme is
linear in the size of the action probability vector. This is
because, at the most, all the action probabilities are updated
at every time instant.
For the beneﬁt of future researchers, we believe that it
will be proﬁtable to record the hurdles we encountered in
∂W
 
Xopt
 
∂X
=

−2pminD A
1
 
qopt
 
(1 −2pmin)popt
 
1 −popt
 
L
−(1 −2pmin)qopt
 
1 −qopt
 
L
−2pmin
 
1 −DB
1
 
popt
  

.
(21)
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 656
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023
this research. The breakthrough came when we were able
to devise/design LA systems that possessed no-absorbing
barriers. In other words, it involved the concept of forcing the
LA back into the probability space when it was close enough to
the absorbing barriers. This was a phenomenon that we had not
earlier seen in the literature. The consequent problem was the
analysis. The underlying Markov process could not be easily
analyzed using the properties of absorbing chains. Neither
could it be trivially modeled as an ergodic chain converging
to an equilibrium distribution. The analysis that we presented
here came as a “brain wave,” and once the building blocks
were established, everything naturally seemed to fall in place.
These few sentences, requested by an anonymous referee,
should clarify the difﬁculties encountered in this research,
in order to show that the present research is pioneering and
this is not a trivial extension of existing methodologies.
IV. SIMULATIONS
In this section, we present simulations to conﬁrm the
abovementioned theoretical properties of the proposed learning
algorithm. In the interest of maintaining benchmarks, we adopt
the same examples as those reported in [1]. Also, by using
different instances of the payoff matrix D, we are able to
experimentally cover the two cases referred to in Section III.
Again, we refer to those cases as Cases 1 and 2, as done in [1].
A. Convergence in Case 1
We consider an instance of the game where only one mixed
Nash equilibrium exists, i.e., there is no saddle point in pure
strategies. We adopt the same game matrix D as in [1] given
by
D =
 0.6
0.2
0.35
0.9

(30)
which admits popt = 0.5789 and qopt = 0.7368.
In order to eliminate the Monte Carlo error, we ran our
scheme for 5 × 106 iterations and report the error in Table I
for different values of pmax and θ as the difference between
Xopt and the mean over time of X(t) after convergence.4
An important remark is that the error decreases as pmax
approaches 1 (i.e., when pmin →0). Please observe that in
this case, we have particularly chosen to not let pmax be unity.
If we allow it to be precisely unity, it would mean that we
would not require an
artiﬁcial barrier close to unity (for
example, between 0.990 and 0.999 as in Table I). In fact, for
pmax = 0.999 and θ = 0.001, the method achieves an error of
2.1621 × 10−3, and further reducing θ = 0.0001 leads to an
error of 1.6820 × 10−3.
To better visualize the scheme, Fig. 1 shows the evolution
over time of the mixed strategies for both players (given by
4The mean is taken over the last 10% of the total number of iterations.
TABLE I
ERROR FOR DIFFERENT VALUES OF θ AND pMAX WHEN pOPT = 0.5789 AND
qOPT = 0.7368 FOR THE GAME SPECIFIED BY THE D MATRIX GIVEN
BY (30). THE POINT THAT YOU HAVE RAISED IS PERTINENT
Fig. 1.
Time evolution of [p1(t), q1(t)]⊺for the same settings as in Fig. 2.
X(t)) for an ensemble of 1000 runs using θ = 0.01 and
pmax = 0.999.
The trajectory of the ensemble allows us to perceive the
mean evolution of the mixed strategies. The spiral pattern is
caused by one of the players adapting to the strategy being
used by the other before the former learns by overcorrecting
its strategy. The procedure is continued leading to smaller
corrections until the players reach the Nash equilibrium.
The abovementioned behavior can also be visualized
in Fig. 2 that presents the trajectory for a single experiment
with pmax = 0.99 and θ = 0.00001 over 3 × 107 steps. The
described oscillatory behavior is attenuated as the players play
for more iterations. The reader should particularly observe
that a larger value of θ will cause more steady-state error
(as speciﬁed in Theorem 1), but it will also perturb this
behavior as the nodes take larger updates whenever they win.
On the other hand, further decreasing θ results in a smaller
error of the stationary point of the method but also decreases
the convergence speed. This well-established inherent tradeoff
between the steady-state error and rate of convergence can be
better visualized by comparing Fig. 1 with θ = 0.001 against
Fig. 3 for a smaller value of θ = 10−5.
∂W
 
Xopt
 
∂X
=
−(d11 −d21) −pmin(d11 + d21)
−pmin(d11 −d12)
pmin(d11 −d21)
(d11 −d12) −pmin(2 −d11 −d12)

.
(27)
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION
657
Fig. 2.
Trajectory of X(t) for the case of the D matrix given by (30) with
popt = 0.5789 and qopt = 0.7368 and using pmax = 0.99 and θ = 0.00001.
Fig. 3.
Time evolution of X(t) where popt = 0.5789 and qopt = 0.7368
using pmax = 0.99 and θ = 0.00001.
Fig. 4.
Trajectory of X(t) for the case of the D matrix given by (30) and
using an absorbing barrier pmax = 1 and θ = 0.00001.
Furthermore, in order to clearly emphasize the necessity of
using an artiﬁcial barrier, we have speciﬁcally repeated the
same experiment except that we have included an absorbing
barrier instead, i.e., set pmax = 1. The result is shown in Fig. 4.
In this case, we expect that the scheme enters an absorbing
barrier. Since it is impossible for the human eye to detect
whether or not we entered an absorbing barrier by merely
examining the graph, we also manually checked the log of
TABLE II
ERROR FOR DIFFERENT VALUES OF θ AND pMAX FOR D1
TABLE III
ERROR FOR DIFFERENT VALUES OF θ AND pMAX FOR D2
the experiment and veriﬁed that the probabilities became
exactly unity after around 6798000 iterations. Although the
theoretical convergence should have occurred in the limit and
not after a ﬁnite number of iterations, the machine limited
accuracy rounded the probabilities to unity after this juncture.
B. Pure Equilibrium
In order to assess the performance of the proposed learning
algorithm on cases with a pure equilibrium, we consider two
instances of games falling in the category of Case 2 with
popt = 1 and qopt = 1. The payoff matrices D1 and D2 for the
two games are given by
D1 =
 0.6
0.8
0.35
0.9

D2 =
0.7
0.9
0.6
0.8

.
We ﬁrst show the convergence errors of our method for both
games D1 and D2 in Tables II and III, respectively. As in the
previous simulation for Case 1, the errors are on the order
to 10−3 for larger values of pmax. However, given that our
algorithm uses artiﬁcial barriers to prevent absorbing states,
the error is lower bounded by pmin. A similar issue is present
in game D2. We have also included this simulation since it is
a more challenging game to learn with our method for a larger
steady-state error, even for very small values of θ.
In Fig. 5, we depict the time evolution of the two compo-
nents of the vector X(t) using the proposed algorithm for an
ensemble of 1000 runs. In the case of having a pure Nash
equilibrium, there is no oscillatory behavior as when a player
assigns more probability to an action since the other player
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 658
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023
Fig. 5.
(a) Evolution over time of X(t) for θ = 0.01 and Pmax = 0.999 when
applied to game with payoffs D1. (b) Zoomed version around the steady-state
value.
Fig. 6.
(a) Evolution over time of X(t) for θ = 0.01 and Pmax = 0.999 when
applied to game with payoffs D2. (b) Zoomed version around the steady-state
value.
reinforces the strategy. However, Fig. 5(a) could lead make
one believe that the LA method has converged to a pure
strategy. Fig. 5(b) zooms around the point where the strategies
have converged to showcase that their maximum value is
limited by pmax, as per the design of our updating rule. This
mechanism is particularly favorable to prevent players from
converging to absorbing states for games with time-varying
payoff matrices. However, the study of such a scenario is left
for future research, namely that of determining how to design
pmax and θ that represent a good tradeoff between learning the
game and adapting to a change in the payoffs.
Game D2 presents a harder challenge for our method as
we can see from its larger steady-state error. Fig. 6 shows the
time evolution of the probabilities for each player when the
algorithm is applied to D2 with θ = 0.01, Pmax = 0.999 and
for an ensemble with 1000 runs.
The main remark regarding the results presented in Fig. 6(a)
is that the convergence is much slower when compared to
game D1. This behavior is governed by the fact that the entries
in matrix D2 are closer to each other, unlike in D1 where there
is a clear disadvantage for player A when selecting action 2.
There will, thus, be much fewer updates for player A where
it increases the probability of action 2 in game D1—which is
not pertinent in game D2. Fig. 6(b) further emphasizes this
remark by displaying a zoom, depicting a sharper change in
the probabilities in comparison with the smooth behavior in
game D1.
C. Comparisons With Related Works
Now that we have explained our new techniques and estab-
lished its theoretical basis, we continue this discussion with a
brief comparison with some of the prior art.5
First of all, one possible alternative when the payoff matrix
is known can be to consider the problem as that of designing
a local controller for each of the agents. One alternative is
to explore the results in [28] and further investigated in [29].
However, this is only possible when D is known, which is not
the scenario that we have assumed in this article.
It is not out of place to review some of the relevant works
in game theory that are not necessarily solved using LA.
However, in the interest of space and brevity, we will not aim
at submitting an extensive review of the ﬁeld of game theory.
Rather, we shall cite some pertinent works inasmuch as our
main contribution in this article centers on advancing the ﬁeld
of LA-based solutions and, more speciﬁcally, those dealing
with the special case of games with “incomplete information.”
There are different variants of zero-sum stochastic games in
the literature. Flesch et al. [30] have proven the general result
that every positive zero-sum stochastic game with countable
state and action spaces admits a value if at least one player
has a ﬁnite action space. A similar value-existence result
was obtained for a zero-sum stochastic game [31] with a
continuous-time Markov chain, where the players have also
the possibility of stopping the game. Ziliotto [32] considered
weighted-average stochastic games, that is, stochastic games
where Player 1 maximizes (in expectation) a ﬁxed weighted
average of the sequence of rewards. A so-called pumping
algorithm was proposed in [33] for two-person zero-sum
undiscounted stochastic games. Other approaches map the
game onto a dynamic programming problem and solve it based
on Bellman’s optimal principle using concepts from the theory
of optimal control [34].
The research on game theoretical learning with incomplete
information [13] is scarce in the literature. Incomplete infor-
mation is a taxonomy used within the ﬁeld of LA games to
denote the case where the players do not observe the action of
the opponent players and where each player does not know his
own payoff function but only observes outcomes in the form
of a reward or a penalty. The informed reader would observe
that the games we deal with in this article fall under this class
of games characterized by such incomplete information.
The case of incomplete information is not usually treated
by the mainstream of literature in game theory. Indeed,
5We are thankful to the anonymous referee who requested this comprehen-
sive section. It signiﬁcantly adds to the quality of this article.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION
659
the main game learning algorithms available in the literature,
such as ﬁctitious play [35], best response dynamics, and
gradient-based learning approaches, deal with the complete
knowledge case, where the players know their own payoff
function and observe the history of the choices of other
players. Fictitious play is one of the few algorithms that can
converge to a mixed strategy equilibrium by maintaining var-
ious frequency-based beliefs over the action of the opponent
players, and using those beliefs, for deciding the next action to
be played. However, the ﬁctitious play algorithm cannot solve
our settings of incomplete information.
When it comes to games with incomplete information,
different algorithms have been suggested, which are based
on the Bush–Mosteller learning paradigm. Notable examples
include the ones reported in [36]–[39]. All those algorithms
share a similar structure to our proposed LA, in particular, and
to VSLA in general, in the sense, that the action probabilities
are updated iteratively based on feedback and using some
learning parameter. In this context, one should note that many
LA models can be seen as extensions of Bush–Mosteller
learning. However, the difference with our work is the fact that
all the aforementioned algorithms have absorbing barriers. The
theoretical analyses of the convergence to pure equilibria for
this family of algorithms rely usually on the theory replicator
dynamics.
Another family of methods that can operate with limited
information includes the Erev–Roth algorithm [40] and the
Arthur algorithm [41], which in turn can be seen as a
variant of the Erev–Roth algorithm. The Erev–Roth algo-
rithm is alternatively called the Erev–Roth payoff matching
algorithm and relies on updating the so-called “propensity”
for each action, which is, loosely speaking, the cumulative
payoff for that action. Thereafter, each action is played in a
manner proportional to its corresponding relative propensity.
The Erev–Roth algorithm is one of the few examples of
limited-information game learning approaches that converge
to unique mixed strategy equilibria. However, the Erev–Roth
algorithm requires storing the entire history of rewards and
penalties for each action. Furthermore, we have not been able
to locate any research study that reports the analysis of the
Erev–Roth algorithm for the case of our stochastic zero-sum
game. We therefore opted to implement it for our game.
Experimental results (not reported here, in the interest of not
distracting from the main contribution of this article) show
that it neither converges to the desired equilibrium nor does it
possess consistent convergence results.
D. Real-Life Application Scenarios
One referee had requested a brief explanation of a complex
environment, or different scenarios in a game, by which we
could utilize our newly proposed solution. We agree that
providing an insightful discussion could be insightful for
interested readers and active researchers. This, of course, can
be open-ended, but to satisfy the referee, we present the
following brief example.
Our learning algorithm admits potential applications in
many security games as well as in communication problems.
The intersection between game theory and security is an
emerging ﬁeld of research. Algorithms that can converge to
mixed equilibria are of great interest to the security community
because mixed equilibria are usually preferred over pure ones.
In fact, randomization gives less predictive ability to the
attacker to guess the deployed strategy of the defender [42].
For instance, let us take a repetitive game involving a jammer
and a transmitter, which, in turn, constitute our players [43].
The jammer aims to disturb and block communication between
a transmitter and its associated receiver. The transmitter can
choose the channel over which his message is communicated,
while the jammer chooses a channel to attack. We suppose
that the outcome is stochastic depending on the choice of the
attacker (jammer) and defender (transmitter) and the stochastic
characteristics of the channel. Both the jammer and transmitter
can observe whether the attack was successful or not, and
for instance, this common observation can be due to the
receiver acknowledging the correct reception of the message
over a wireless channel that both the attacker and jammer can
overhear. Thus, the game is stochastic zero-sum.
V. CONCLUSION
The theoretical applications LA with artiﬁcially absorbing
barriers have been reported since the 1980s [8] and, more
recently, in Estimator LA [18]–[20]. This article pioneers the
study of LA with artiﬁcial nonabsorbing barriers. LA have
been previously used [13] to design algorithms capable of
converging to the game’s Nash equilibrium under limited
information. The majority of the LA algorithms used for
games are absorbing in the probability simplex space, and they
converge to an exclusive choice of a single action. These LA
are, thus, unable to converge to other mixed Nash equilibria
when the game possesses no saddle point for a pure strategy.
As opposed to these, we propose an LA solution that is able to
converge to an optimal mixed Nash equilibrium even though
there may be no saddle point when a pure strategy is invoked.
The scheme is inherently of the absorbing L R−I paradigm.
However, by introducing reﬂecting barriers, we prevent it from
being “stuck” or getting absorbed in pure strategies. Unlike the
linear reward-ϵpenalty (L R−ϵP) scheme proposed in [1], our
new scheme achieves the same goal with much less parameter
tuning and in a more elegant manner.
As far as know, our method is only the second reported
algorithm in the literature capable of ﬁnding mixed strategies
whenever no saddle point exists for pure strategies. If a
saddle point exists for pure strategies, the scheme converges
to a near-optimal solution close to the pure strategies in the
probability simplex. This article includes the nontrial proofs
of the theoretical results characterizing the convergence and
stability of the algorithm. These are presented and illustrated
through simulations for benchmark games presented in the
literature.
With regard to future work, we believe that it will be
useful in real-life applications that can be modeled using such
game-like behavior.
APPENDIX
NORMAN THEOREM
Theorem 4: Let X(t) be a stationary Markov process
dependent on a constant parameter θ ∈[0, 1]. Each X(t) ∈I,
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 660
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023
where I is a subset of the real line. Let X(t) = X(t + 1) −
X(t). The following are assumed to hold.
1) I is compact.
2) E[X(t)|X(t) = y] = θw(y) + O
 
θ2 
.
3) V ar[X(t)|X(t) = y] = θ2 s(y) + o
 
θ2 
.
4) EX(t)3|X(t) = y = O θ3 . where supy∈I
 O θk /
θk 
< ∞for K = 2, 3 and supy∈I
 
o
 
θ2 
/θ2 
→0 as
θ →0.
5) w(y) has a Lipschitz derivative in I.
6) s(y) is Lipschitz I.
If Assumptions (1)–(6) hold, w(y) has a unique root y∗in
I and (dw/dy)

y=y∗≤0; then, the following conditions hold.
1) var[X(t)|X(0) = x] = 0(θ) uniformly for all x ∈I
and t ≥0. For any x ∈I, the differential equation
(dy(τ)/dτ) = w(y(t)) has a unique solution y(τ) =
y(τ, x) with y(0) = x and E[δX(t)|X(0) = x] =
y(tθ) + O(θ) uniformly for all x ∈I and t ≥0.
2)
 
(X(t) −y(tθ))/
√
θ
 
has a normal distribution with
zero mean and ﬁnite variance as θ →0 and tθ →∞.
ACKNOWLEDGMENT
The authors are very grateful for the feedback from the
anonymous Referees of the original submission. Their input
signiﬁcantly improved the quality of this ﬁnal version.
REFERENCES
[1] S. Lakshmivarahan and K. S. Narendra, “Learning algorithms for two-
person zero-sum stochastic games with incomplete information: A
uniﬁed approach,” SIAM J. Control Optim., vol. 20, no. 4, pp. 541–552,
1982.
[2] S. Lakshmivarahan, Learning Algorithms Theory and Applications:
Theory and Applications. New York, NY, USA: Springer, 2012.
[3] J. K. Lanctot and B. J. Oommen, “On discretizing estimator-based
learning algorithms,” IEEE Trans. Syst., Man, Cybern., B, Cybern.,
vol. 2, pp. 1417–1422, 1991.
[4] J. K. Lanctot and B. J. Oommen, “Discretized estimator learn-
ing automata,” IEEE Trans. Syst., Man, Cybern., vol. 22, no. 6,
pp. 1473–1483, Nov./Dec. 1992.
[5] K. Najim and A. S. Poznyak, Learning Automata: Theory and Applica-
tions. Amsterdam, The Netherlands: Elsevier, 2014.
[6] K. S. Narendra and M. A. Thathachar, Learning Automata: An Intro-
duction. North Chelmsford, MA, USA: Courier Corporation, 2012.
[7] M. F. Norman, Markov Processes and Learning Models, vol. 84.
New York, NY, USA: Academic, 1972.
[8] B. Johnoommen, “Absorbing and ergodic discretized two-action learning
automata,” IEEE Trans. Syst., Man, Cybern., vol. 16, no. 2, pp. 282–293,
Mar. 1986.
[9] B. J. Oommen and J. K. Lanctot, “Discretized pursuit learning
automata,” IEEE Trans. Syst., Man, Cybern., vol. 20, no. 4, pp. 931–938,
Jul./Aug. 1990.
[10] B. J. Oommen and M. Agache, “Continuous and discretized pursuit
learning schemes: Various algorithms and their comparison,” IEEE
Trans. Syst., Man, Cybern., B (Cybern.), vol. 31, no. 3, pp. 277–287,
Jun. 2001.
[11] G. P. Papavassilopoulos, “Learning algorithms for repeated bimatrix
Nash games with incomplete information,” J. Optim. Theory Appl.,
vol. 62, no. 3, pp. 467–488, 1989.
[12] A. Rezvanian, A. M. Saghiri, S. M. Vahidipour, M. Esnaashari, and
M. R. Meybodi, Recent Advances in Learning Automata, vol. 754.
New York, NY, USA: Springer, 2018.
[13] P. S. Sastry, V. V. Phansalkar, and M. A. L. Thathachar, “Decentralized
learning of Nash equilibria in multi-person stochastic games with
incomplete information,” IEEE Trans. Syst., Man Cybern., vol. 24, no. 5,
pp. 769–777, May 1994.
[14] M. A. L. Thathachar and P. S. Sastry, Networks of Learning Automata:
Techniques for Online Stochastic Optimization. Boston, MA, USA:
Kluwer, 2003.
[15] M. L. Tsetlin et al., Automaton Theory and Modeling of Biological
Systems. New York, NY, USA: Academic, 1973.
[16] B. Tung and L. Kleinrock, “Using ﬁnite state automata to produce self-
optimization and self-control,” IEEE Trans. Parallel Distrib. Syst., vol. 7,
no. 4, pp. 439–448, Apr. 1996.
[17] Y. Xing and R. Chandramouli, “Stochastic learning solution for distrib-
uted discrete power control game in wireless data networks,” IEEE/ACM
Trans. Netw., vol. 16, no. 4, pp. 932–944, Aug. 2008.
[18] X. Zhang, O. C. Granmo, B. J. Oommen, and L. Jiao, “A formal proof
of the ε-optimality of absorbing continuous pursuit algorithms using
the theory of regular functions,” Appl. Intell., vol. 41, pp. 974–985,
May 2014.
[19] X. Zhang, B. J. Oommen, O. C. Granmo, and L. Jiao, “A formal proof of
the ε-optimality of discretized pursuit algorithms,” Appl. Intell., vol. 44,
pp. 282–294, 2016, doi: 10.1007/s10489-015-0670-1.
[20] X. Zhang, B. J. Oommen, and O. C. Granmo, “The design of absorb-
ing Bayesian pursuit algorithms and the formal analyses of their ε-
optimality,” Pattern Anal. Appl., vol. 20, no. 3, pp. 797–808, 2015.
[21] J. R. Marden, G. Arslan, and J. S. Shamma, “Cooperative control and
potential games,” IEEE Trans. Syst., Man, Cybern. B. Cybern., vol. 39,
no. 6, pp. 1393–1407, Dec. 2009, doi: 10.1109/TSMCB.2009.2017273.
[22] D. Silvestre, J. P. Hespanha, and C. Silvestre, “Resilient desyn-
chronization for decentralized medium access control,” IEEE Con-
trol
Syst.
Lett.,
vol.
5,
no.
3,
pp. 803–808,
Jul.
2021,
doi:
10.1109/LCSYS.2020.3005819.
[23] D. Silvestre, J. Hespanha, and C. Silvestre, “Desynchronization for
decentralized medium access control based on gauss-seidel iterations,”
in Proc. Amer. Control Conf. (ACC), Jul. 2019, pp. 4049–4054, doi:
10.23919/ACC.2019.8814471.
[24] D. Silvestre, J. P. Hespanha, and C. Silvestre, “Broadcast and gossip
stochastic average consensus algorithms in directed topologies,” IEEE
Trans. Control Netw. Syst., vol. 6, no. 2, pp. 474–486, Jun. 2019, doi:
10.1109/TCNS.2018.2839341.
[25] D. Silvestre, J. Hespanha, and C. Silvestre, “A PageRank algorithm
based on asynchronous gauss-seidel iterations,” in Proc. Annu. Amer.
Control Conf. (ACC), Milwaukee, WI, USA, Jun. 2018, pp. 484–489,
doi: 10.23919/ACC.2018.8431212.
[26] R. Ribeiro, D. Silvestre, and C. Silvestre, “A rendezvous algorithm
for multi-agent systems in disconnected network topologies,” in Proc.
28th Medit. Conf. Control Autom. (MED), Sep. 2020, pp. 592–597, doi:
10.1109/MED48518.2020.9183093.
[27] R. Ribeiro, D. Silvestre, and C. Silvestre, “Decentralized control for
multi-agent missions based on ﬂocking rules,” CONTROLO ( Lec-
ture Notes in Electrical Engineering), vol. 695, J. A. Gonçalves,
M. Braz-César, and J. P. Coelho, Eds. Cham, Switzerland: Springer,
2021, pp. 445–454, doi: 10.1007/978-3-030-58653-9_43.
[28] Y. Wu and R. Lu, “Output synchronization and L2-gain analysis for
network systems,” IEEE Trans. Syst., Man, Cybern., Syst., vol. 48,
no. 12, pp. 2105–2114, Dec. 2018, doi: 10.1109/TSMC.2017.2754544.
[29] Y. Wu, A. Isidori, R. Lu, and H. K. Khalil, “Performance recovery
of dynamic feedback-linearization methods for multivariable nonlinear
systems,” IEEE Trans. Autom. Control, vol. 65, no. 4, pp. 1365–1380,
Apr. 2020, doi: 10.1109/TAC.2019.2924176.
[30] J. Flesch, A. Predtetchinski, and W. Sudderth, “Positive zero-sum
stochastic games with countable state and action spaces,” Appl. Math.
Optim., vol. 82, pp. 499–516, Nov. 2018.
[31] C. Pal and S. Saha, “Continuous-time zero-sum stochastic game with
stopping and control,” Operations Res. Lett., vol. 48, no. 6, pp. 715–719,
Nov. 2020.
[32] B. Ziliotto, “A tauberian theorem for nonexpansive operators and appli-
cations to zero-sum stochastic games,” Math. Operations Res., vol. 41,
no. 4, pp. 1522–1534, Nov. 2016.
[33] E. Boros, K. Elbassioni, V. Gurvich, and K. Makino, “A potential
reduction algorithm for two-person zero-sum mean payoff stochastic
games,” Dyn. Games Appl., vol. 8, no. 1, pp. 22–41, Mar. 2018.
[34] K. Du, R. Song, Q. Wei, and B. Zhao, “A solution of two-person zero
sum differential games with incomplete state information,” in Advances
in Neural Networks—ISNN 2019 (Lecture Notes in Computer Science),
vol. 11554, H. Lu, H. Tang, and Z. Wang, Eds. Cham, Switzerland:
Springer, 2019, doi: 10.1007/978-3-030-22796-8_46.
[35] J. Hofbauer and W. H. Sandholm, “On the global convergence of
stochastic ﬁctitious play,” Econometrica, vol. 70, no. 6, pp. 2265–2294,
Nov. 2002.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION
661
[36] T. Börgers and R. Sarin, “Learning through reinforcement and replicator
dynamics,” J. Econ. Theory, vol. 77, no. 1, pp. 1–14, Nov. 1997.
[37] L. R. Izquierdo, S. S. Izquierdo, N. M. Gotts, and J. G. Polhill, “Tran-
sient and asymptotic dynamics of reinforcement learning in games,”
Games Econ. Behav., vol. 61, no. 2, pp. 259–276, Nov. 2007.
[38] A. S. Poznyak and K. Najim, “Bush-Mosteller learning for a zero-sum
repeated game with random pay-offs,” Int. J. Syst. Sci., vol. 32, no. 10,
pp. 1251–1260, 2001.
[39] Q. Zhu, H. Tembine, and T. Basar, “Heterogeneous learning in zero-
sum stochastic games with incomplete information,” in Proc. 49th IEEE
Conf. Decis. Control (CDC), Dec. 2010, pp. 219–224.
[40] I. Erev and A. E. Roth, “Multi-agent learning and the descriptive value
of simple models,” Artif. Intell., vol. 171, no. 7, pp. 423–428, May 2007.
[41] W. B. Arthur, “On designing economic agents that behave like human
agents,” J. Evol. Econ., vol. 3, no. 1, pp. 1–22, Mar. 1993.
[42] M. H. Manshaei, Q. Zhu, T. Alpcan, T. Bac¸sar, and J.-P. Hubaux, “Game
theory meets network security and privacy,” ACM Comput. Surv., vol. 45,
no. 3, pp. 1–39, Jun. 2013.
[43] V. Vadori, M. Scalabrin, A. V. Guglielmi, and L. Badia, “Jamming in
underwater sensor networks as a Bayesian zero-sum game with position
uncertainty,” in Proc. IEEE Global Commun. Conf. (GLOBECOM),
Dec. 2014, pp. 1–6.
Anis Yazidi (Senior Member, IEEE) received the
M.Sc. and Ph.D. degrees from the University of
Agder, Grimstad,
Norway, in 2008 and 2012,
respectively.
He was a Researcher with Teknova AS, Grimstad.
From 2014 to 2019, he was an Associate Pro-
fessor with the Department of Computer Science,
Oslo Metropolitan University, Oslo, Norway. He is
currently a Full Professor with the Department of
Computer Science, where he is leading the research
group in applied artiﬁcial intelligence. He is also
a Professor II with the Norwegian University of Science and Technol-
ogy (NTNU), Trondheim, Norway. His current research interests include
machine learning, learning automata, stochastic optimization, and autonomous
computing.
Daniel
Silvestre
received the B.Sc. degree in
computer networks
from the Instituto Superior
Técnico (IST), Lisbon, Portugal, in 2008, and the
M.Sc. degree in advanced computing and the Ph.D.
degree (Hons.) in electrical and computer engineer-
ing from Imperial College London, London, U.K.,
in 2009 and 2017, respectively.
He was a Visiting Scholar at the University of
California at Santa Barbara, Santa Barbara, CA,
USA. He is currently with the Institute for Systems
and Robotics, IST. He holds a research assistant
appointment with the University of Macau, Macau. His research interests span
the ﬁelds of fault detection and isolation, distributed systems, network control
systems, computer networks, set-valued estimation and control methods, and
randomized algorithms.
B. John Oommen (Life Fellow, IEEE) was born
in India, in 1953. He received the Bachelor of
Technology degree in electrical engineering from
IIT Madras, Chennai, India, in 1975, the Master
of Engineering degree from the Indian Institute of
Science, Bengaluru, India, in 1977, and the Master
of Science degree and the Ph.D. degree in electrical
engineering from Purdue University, West Lafayette,
IN, USA, in 1979 and 1982, respectively.
He has been teaching at the School of Computer
Science, Carleton University, Ottawa, ON, Canada,
since 1981. He was elevated to be a Chancellor’s Professor at Carleton
University in 2006. He has published more than 485 refereed publications,
many of which have been award-winning.
Dr. Oommen was nominated as a fellow of the Institute of Electrical and
Electronic Engineers (IEEE) for research in a subﬁeld of artiﬁcial intelligence,
namely in learning automata in 2003. He was also nominated as a fellow of the
International Association of Pattern Recognition (IAPR) in August 2006 for
contributions to fundamental and applied problems in syntactic and statis-
tical pattern recognition. He
received the Carleton University’s Research
Achievement Award four times, in 1995, 2001, 2007, and 2015. At IIT
Madras and the Indian Institute of Science, he received the medal for being
the Best Graduating Student. He has served on the Editorial Board of the
IEEE TRANSACTIONS ON SYSTEMS, MAN AND CYBERNETICS and Pattern
Recognition.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
",10.1109/TNNLS.2021.3099095,doc30,"650 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023 Solving Two-Person Zero-Sum Stochastic Games With Incomplete Information Using Learning Automata With Artiﬁcial Barriers Anis Yazidi , Senior Member, IEEE, Daniel Silvestre , and B. John Oommen , Life Fellow, IEEE Abstract—Learning automata (LA) with artiﬁcially absorbing barriers was a completely new horizon of research in the 1980s (Oommen, 1986). These new machines yielded properties that were previously unknown. More recently, absorbing barriers have been introduced in continuous estimator algorithms so that the proofs could follow a martingale property, as opposed to monotonicity (Zhang et al., 2014), (Zhang et al., 2015). However, the applications of LA with artiﬁcial barriers are almost nonexistent. In that regard, this article is pioneering in that it provides effective and accurate solutions to an extremely complex application domain, namely that of solving two-person zero-sum stochastic games that are provided with incomplete information. LA have been previously used (Sastry et al., 1994) to design algorithms capable of converging to the game’s Nash equilibrium under limited information. Those algorithms have focused on the case where the saddle point of the game exists in a pure strategy. However, the majority of the LA algorithms used for games are absorbing in the probability simplex space, and thus, they converge to an exclusive choice of a single action. These LA are thus unable to converge to other mixed Nash equilibria when the game possesses no saddle point for a pure strategy. The pioneering contribution of this article is that we propose an LA solution that is able to converge to an optimal mixed Nash equilibrium even though there may be no saddle point when a pure strategy is invoked. The scheme, being of the linear reward-inaction (L R−I) paradigm, is in and of itself, absorbing. However, by incorporating artiﬁcial barriers, we prevent it from being “stuck” or getting absorbed in pure strategies. Unlike the linear reward-ϵpenalty (L R−ϵ P) scheme proposed by Lakshmivarahan and Narendra almost four decades ago, our new scheme achieves the same goal with much less parameter tuning and in a more elegant manner. This article includes Manuscript received 2 October 2020; revised 16 February 2021; accepted 18 May 2021. Date of publication 4 August 2021; date of current ver- sion 6 February 2023. The work of Daniel Silvestre was supported in part by the Portuguese Fundação para a Ciência e a Tecnologia (FCT) through the Institute for Systems and Robotics (ISR), Laboratory for Robot- ics and Engineering Systems (LARSyS), under Project UIDB/50009/2020, through FirePuma Project under Grant PCIF/MPG/0156/2019, and through COPELABS, University Lusófona, under Project UIDB/04111/2020. The work of B. John Oommen was supported in part by the Natural Sciences and Engineering Research Council of Canada (NSERC) and in part by the Natural Sciences and Engineering Council of Canada. (Corresponding author: B. John Oommen.) Anis Yazidi is with the Department of Computer Science, Oslo Metropolitan University, 0190 Oslo, Norway (e-mail: anis.yazidi@oslomet.no). Daniel Silvestre is with Dynamical Systems and Ocean Robotics Laboratory (DSOR), Department of Electrical and Computer Engineering, Lusófona Uni- versity, 1749-024 Lisbon, Portugal, and also with the Institute for Systems and Robotics, Instituto Superior Técnico, University of Lisbon, 1049-001 Lisbon, Portugal (e-mail: dsilvestre@isr.tecnico.ulisboa.pt). B. John Oommen is with the School of Computer Science, Carleton Univer- sity, Ottawa, ON K1S 5B6, Canada, and also with the Department of IKT, Uni- versity of Agder, 4879 Grimstad, Norway (e-mail: oommen@scs.carleton.ca). Color versions of one or more ﬁgures in this article are available at Digital Object Identiﬁer 10.1109/TNNLS.2021.3099095 the nontrial proofs of the theoretical results characterizing our scheme and also contains experimental veriﬁcation that conﬁrms our theoretical ﬁndings. Index Terms—Games with incomplete information, learning automata (LA), LA with artiﬁcial barriers. I. INTRODUCTION T HE term learning automata (LA) denotes a whole subﬁeld of research within adaptive systems with several books being dedicated to its study [2], [5], [6], [12], [14]. The work on LA dates to the Soviet Union in the 1960s when the mathematical giant Tsetlin et al. [15] devised the so-called Tsetlin machine that is a learning mechanism with ﬁnite mem- ory. Tsetlin’s learning machines were demonstrated to give birth to self-organizing behavior through collective learning. In his work, Tsetlin pioneered the Goore game, which is a distributed coordination game with limited feedback that has many practical applications, as shown by Tung and Kleinrock [16]. The early works in the ﬁeld of LA, such as the Tsetlin machine, fall under the family of ﬁxed structure LA. The mainstream of current LA research concerns the family of variable structure LA (VSLA) which, loosely speaking, differs from ﬁxed structure LA in the fact that they operate with a probability vector that is updated dynamically over time. In ﬁxed structure LA, the choice is governed by a transition matrix whose transitions do not depend on time and that describes how the internal states of the LA are updated based on the environment’s feedback. The term LA was coined for the ﬁrst time by Narendra and Thathachar [6]. Markovian Representations of LA: LA can also be charac- terized by their Markovian representations. They thus fall into one of two families, being either ergodic or those that possess absorbing barriers [8]. Such a characterization is crucial to the tenets of this article. Absorbing automata have underlying Markov chains that get absorbed or locked into a barrier state. Sometimes, this can occur even after a relatively small, ﬁnite number of iterations. The classic references [2], [5], [6], [12], [14] report numerous LA families that contain such absorbing barriers. On the other hand, as these same references explain, the literature has also reported scores of ergodic automata, which converge in distribution. In these cases, the asymptotic distribution of the action probability vector converges to a value that is independent of its initial vector. Absorbing LA are usually designed to operate in stationary environments. As opposed to these, ergodic LA are preferred for nonstationary environments, namely those that possess 2162-237X © 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION 651 time-dependent reward probabilities. These characterizations, and their corresponding implications for game playing, will be explained presently. Continuous or Discretized VSLA: VSLA can also be char- acterized as being continuous or discretized. This depends on the values that the action probabilities can take. Continuous LA allow the action probabilities to assume any value in the interval [0, 1]. Such algorithms have a relatively slow rate of convergence. The problem with continuous LA is that they approach a goal but never reach there. This was mitigated in the 1980s by introducing the concept of discretization, where if an action probability was close enough to zero or unity, it could jump to that endpoint in a single step. This also ren- dered the LA to have a faster convergence because one could increase their speeds of convergence by incorporating this phenomenon [3], [4], [9]. This is implemented by constraining the action selection probability to be one of a ﬁnite number of values in the interval [0, 1]. By incorporating discretization, almost all of the reported VSLA of the continuous type have also been discretized [9], [10], [19]. LA With Artiﬁcially Absorbing Barriers: LA with artiﬁ- cially introduced absorbing barriers were a novelty in the 1980s. These yielded machines, which had properties that were previously unknown. This was due to the fact that a discretized machine, even though it was ergodic, could be rendered absorbing by forcing the machine to stay at one of the absorbing barriers [8]. Ironically, this simple step introduced families of new LA, with properties that were previously unknown. For example, ADLR−P and ADLI−P are absorbing versions of their corresponding ergodic counterparts but have been proven to be ϵ-optimal in all random environments. This phenomenon, of including artiﬁcially absorbing barriers, has been recently applied to the family of pursuit LA [18]. Estimator LA With Artiﬁcial Barriers: The concept of introducing absorbing barriers is also central to the proofs of estimator algorithms. For three decades, these pursuit algorithms were “proven” to be ϵ-optimal by virtue of the monotonicity property. However, recently, these proofs have been shown to be ﬂawed. To remedy this, absorbing barriers have been introduced in continuous estimator algorithms so that the proofs could follow a martingale property, as opposed to monotonicity. Consequently, Zhang et al. [18]–[20] have shown that one can invoke this weaker property, namely, the martingale property, by artiﬁcially providing such an absorbing barrier. Thus, whenever an action probability is close enough to unity, the LA is forced to jump to this absorbing barrier. Applications of LA: LA have boasted scores of applica- tions. These include theoretical problems, such as the graph partitioning problem. They have been used in controlling intel- ligent vehicles. When it concerns neural networks and hidden Markov models, Meybodi et al. have used them in adapting the former, and others have applied them in training the latter. Network call admission, trafﬁc control, and quality-of-service routing have been resolved using LA, while others have also found applications in tackling problems involving network and communications issues. Apart from these, the entire ﬁeld of LA and stochastic learning has had a myriad of applications listed in the reference books [2], [5], [6], [14]. In the interest of the page-limit constraints, the citations to these applications are not included. However, they can be easily found by executing a simple search, and many are included in the above benchmark references. Game Playing With LA: While artiﬁcially introduced barri- ers have been shown to have powerful theoretical and design implications, the applications of them are few. This is where this article ﬁnds its place—it presents one such application. LA have also been used to resolve stochastic games with incomplete information. This article pioneers a merge of the above two issues. First of all, we present a mechanism by which LA can be augmented with artiﬁcial barriers, but unlike the state of the art, these barriers are nonabsorbing. We then proceed to use these to play zero-sum games with incomplete information. Games of this type were studied four decades ago for scenarios when the game matrix had a saddle point using traditional L R−I and L R−P LA [13]. Our results generalize those when the game does not possess the Nash equilibrium. Rather, we propose the nontrivial use of LA with artiﬁcial nonabsorbing barriers to resolve such games. This article contains the theoretical results and those from simulations using the corresponding benchmark games. Landscape of Our Present Work: In this article, we pro- pose an algorithm addressing zero-sum games, which can be generalized to nonzero-sum games in a manner similar to the principle by which the method in [1] was generalized in [17]. In the latter, Xing and Chandramouli [17] proved that the linear reward−ϵpenalty (L R−ϵP) algorithm, devised in [1], is able to work in nonzero-sum games. Thus, without further elaborating on this,1 our results are generalizable to nonzero-sum games. Since the game is zero-sum, the outcomes are either a loss for player A, with reward −1, and the corresponding win for player B with value +1, or the converse for the case of a win for player A. We emphasize that this is a limited information game where each player is unaware of both the mixed strategy and the selected action of the other player. The available information to each player is whether its action resulted in a win or a loss. The reader should note that either/both players might not even be aware of the existence of another player and be working with the assumption that he is playing against nature, as in the classical multiarmed bandit algorithms. However, if both players learn using our algorithm based on the assumption that they are operating in an adversarial environment, we show that they will both converge to the desired equilibrium. Our proposed scheme has players adjusting their strategy whenever it obtains a “win” for that round. This conforms to the linear reward-inaction (L R−I) paradigm, described in detail, presently. It is thus, unarguably, radically different from the mechanism proposed by Lakshmivarahan and Narendra [1], where the probability updates are performed upon receiving both reward and penalty responses, which thus renders changes to occur at every time instant. 1Some preliminary unpublished work is being conducted for extending this work to nonzero-sum games. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. 652 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023 Objective and Contribution of This Article: Based on the above discussion, one can summarize the objective of this article as to study the behavior of a nonabsorbing barrier-based L R−I mechanism in a stochastic zero-sum game played by two players A and B, with two actions each, as earlier done in [1]. Each player uses an LA to decide his strategy, where the only received feedback from the environment is the reward of the joint actions of both players. The game is played iteratively and the players are able to revise their mixed strategies. Applications of the Proposed Method: Learning within the context of games has a natural application in the realm of game theory. However, in the context of multiagent systems (MASs), this has been shown to be suitable for the cooperative control of robotic systems [21]. In such a design, it is assumed that the mission can be fully described as a potential game, where the utility function measures how well the nodes in the network are complying with the objectives. Nevertheless, having robots converging to pure strategies means that the network designer is favoring exploitation and disregarding exploration. If the environment changes and causes a different payoff matrix, the agent would be locked into repeatedly playing the same strategy. Moreover, this assumes that the utility must be known and deterministic. Therefore, instead of designing application-speciﬁc algorithms, the proposed learn- ing algorithm can be used to address problems in cooperative control such as the so-called “rendezvous” problem for a ﬂeet of robots [26], [27], the desynchronization of the use of a shared medium [22], [23], and a consensus algorithm to have the agents agree on a common value [24] or to solve distributed computation such as the PageRank [25], by only considering the current stochastic payoff. It is also pertinent to mention that the mechanism that we propose here can be used by the agents to learn how to act if the payoff corresponds to how successful they are in following the objectives of the “mission.” Much can be said about this, but we terminate these discussions here in the interest of brevity and due to space limitations. However, with respect to future research, it is wise to mention that the question of whether they can be applied to synchronization, as in the analysis of the family of so-called “Fireﬂy” algorithms, is yet open. A. Notation Used Most of the notations that we use are well established from the theory of matrices and in the ﬁeld of LA [2], [6], and stating them would trivialize this article. However, we mention that apart from the well-established notations used in these areas, we will use the notation that the conditional expectation of some variable v with respect to w is written as E[v|w] and the partial derivative of a variable v(t) with respect to time t is denoted by (∂v(t)/∂t). II. GAME MODEL To initiate discussions, we formalize the game model that is being investigated. Let P(t) = p1(t) p2(t)⊺denote the mixed strategy of player A at time instant t, where p1(t) accounts for the probability of adopting strategy 1 and, conversely, p2(t) stands for the probability of adopting strategy 2. Thus, P(t) describes the distribution over the strategies of player A. Similarly, we can deﬁne the mixed strategy of player B at time t as Q(t) = q1(t) q2(t)⊺. The extension to more than two actions per player is straightforward following the method analogous to what was used by Papavassilopoulos [11], which extended the work of Lakshmivarahan and Narendra [1]. Let αA(t) ∈{1, 2} be the action chosen by player A at time instant t and αB(t) ∈{1, 2} be the one chosen by player B, following the probability distributions P(t) and Q(t), respec- tively. The pair (αA(t), αB(t)) constitutes the joint action at time t and is pure strategy. Speciﬁcally, if (αA(t), αB(t)) = (i, j), the probability of gain for player A is determined by di j, as formalized in [1]. We thus construct a matrix with the set of probabilities D = [di j], 1 ≤i ≤2, which is the so-called payoff matrix associated with the game. The matrix D is given by D = d11 d12 d21 d22  (1) where all the entries are probabilities. Clearly, the actual game matrix G is given by gi j = 2 di j−1, with entries in the interval [−1, 1]. Without loss of generality, player A corresponds to the row player, whereas B is the column player. Furthermore, when referring to a “gain,” we are seeing this from the perspective of player A. In zero-sum games, Nash equilibria are equivalently called the “saddle points” for the game. Since the outcome for a given joint action is stochastic, the game is the stochastic form of a zero-sum game. The “zero-sum” property implies that at any time t, there is only one winning player.2 In the interest of completeness, we present the original scheme proposed in [1] based on the L R−ϵP rule. It uses two parameters θR and θP as the learning rates associated with the reward and penalty responses, respectively. When player A gains at time instant t by playing action i, he updates his mixed strategy as pi(t + 1) = pi(t) + θR(1 −pi(t)) ps(t + 1) = ps(t) −θP ps(t) for s ̸= i. However, if player A loses after using action i, his mixed strategy is updated by the following: pi(t + 1) = pi(t) −θP pi(t) ps(t + 1) = ps(t) + θR(1 −ps(t)) for s ̸= i. The exact update mechanism for player B is obtained by replacing the corresponding p(t) by q(t) and by recalling that a gain for A maps onto a loss scenario for player B. We now introduce our novel solution that is proposed to learn a new mixed strategy. 2The results inferred from this article can be extended to nonzero-sum games. However, for the sake of simplicity, we only consider the case of zero-sum games. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION 653 III. LA ALGORITHM BASED ON L R−I WITH ARTIFICIAL BARRIERS A. Nonabsorbing Artiﬁcial Barriers We have earlier seen that an ergodic LA can be made absorbing by artiﬁcially rendering the end states to become absorbing. This was brieﬂy addressed above. However, what has not been discussed in the literature is a strategy by which a scheme which is, in and of itself, absorbing, can be rendered to be ergodic. In other words, the LA are allowed to move within the probability simplex by utilizing an absorbing scheme. However, when it enters an absorbing barrier, the scheme is forced to go back into the simplex in order to render it to be ergodic. No such scheme has ever been reported in the literature, and the advantage of having such a scheme is that one does not get locked into a suboptimal absorbing barrier. Rather, we can permit it to move around so that it can migrate stochastically toward an optimal mixed strategy. This is, precisely, what we shall do. B. Nonabsorbing Game Playing We now present our strategic LA-based game algorithm together with a formal analysis that demonstrates the conver- gence to the saddle points of the game even if the saddle point corresponds to a mixed Nash equilibrium. Our LA solution is based on the L R−I scheme, but as alluded to earlier, it has been modiﬁed in order to nontrivially provide nonabsorbing barriers. The proof of convergence is based on Norman’s theory for learning processes characterized by small learning steps [6], [7]. Considering that pmax denotes an artiﬁcial barrier, we use the notation that pmin = 1 −pmax. We further constrain the probability for each action by restricting it, by design, to belong to the interval [pmin, pmax] if p1(0) and q1(0) are initially chosen to belong to the same interval. If the outcome from the environment is a gain at a time t for action i ∈{1, 2}, the update rule is given by pi(t + 1) = pi(t) + θ(pmax −pi(t)) ps(t + 1) = ps(t) + θ(pmin −ps(t)) for s ̸= i. (2) The reader will observe that this update mechanism is identical to the well-established linear schemes, except that pmin and pmax replace the values zero and unity, respectively. When the player receives a loss, the probabilities are not updated, which translates into pi(t + 1) = pi(t) ps(t + 1) = ps(t) for s ̸= i. (3) The update rules for the mixed strategy q(t +1) are deﬁned in a similar fashion by recalling the dichotomy that whenever player A gains, it corresponds to a loss for player B and vice versa. Analogous to the L R−I paradigm, mixed strategies are not changed in the case of a loss. We now proceed to analyze the convergence properties of the proposed algorithm. To aid in the analysis, we identify the Nash equilibrium of the game by the pair (popt, qopt). To render the presentation to be less cumbersome, we divide the analysis into two cases. 1) Case 1 [Only One Mixed Nash Equilibrium Case (No Saddle Point in Pure Strategies)]: The ﬁrst case depicts the situation where no saddle point exists in pure strategies. In other words, the only Nash equilibrium is a mixed one. Based on the fundamentals of game theory, the optimal mixed strategies can be easily shown to be the following: popt = d22 −d21 L , qopt = d22 −d12 L where L = (d11+d22)−(d12+d21). Without loss of generality, we assume that d11 > max{d12, d21} and d22 > max {d12, d21}. (4) Notice that the above inequalities are not restrictive, as games not satisfying them can be mapped in a symmetric manner by reindexing the actions of the players and/or the indices of the players. 2) Case 2 (There Is a Saddle Point in Pure Strategies): The case where the game matrix has saddle points in pure strategies corresponds to either: 1) d11 > d12, d12 < d21, d21 > d22, and d22 < d11 or 2) in the symmetric case, where d11 < d12, d12 > d21, d21 < d22, and d22 > d11. Since the other cases can be proven in identical manners, in the interest of brevity, we consider only the case where d21 < d11 < d12. (5) In this case, popt = 1 and qopt = 1. The other subcases within Case 2 can be obtained by reindexing the actions of the players and/or the indices of the players, as in Case 1. Let the vector X(t) = p1(t) q1(t)⊺. We introduce the notation that X(t) = X(t + 1) −X(t). We also represent the conditional expected value operator by E[·|·]. Using these, we claim the next theorem. Theorem 1: Consider a zero-sum game with a payoff matrix as in (1) and a learning algorithm deﬁned by (2) and (3) for both players A and B, with learning rate θ. Then, E[X(t)|X(t)] = θW(x), and for every ϵ > 0, there exists a unique stationary point X∗= p∗ 1 q∗ 1 ⊺satisfying the following conditions. 1) W(X∗) = 0. 2) |X∗−Xopt| < ϵ. Proof: Let us ﬁrst compute the conditional expected value3 of the increment X(t) E[X(t)|X(t)] = E[X(t + 1) −X(t)|X(t)] =  E[p1(t + 1) −p1(t)|X(t)] E[q1(t + 1) −q1(t)|X(t)])  = θ W1(X(t)) W2(X(t))  = θW(X(t)) where the above format is possible since all possible updates share the form X(t) = θW(t), for some W(t), as given in (2). 3Computing the “expected value of the increment” is a standard procedure in the theory of LA. This is because the increment, in and of itself, is a random variable, which is sometimes positive and sometimes negative. Quantifying the latter is not possible due to the randomness of the updating rule. However, the conditional expected value of the increment can be determined, whence (by invoking the “Law of the Unconscious Statistician”), one can determine the expected value of the increment itself. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. 654 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023 For ease of notation, we drop the dependence on t with the implicit assumption that all occurrences of X, p1, and q1 represent X(t), p1(t), and q1(t), respectively. W1(x) is then W1(X) = p1q1d11(pmax −p1) + p1(1 −q1)d12(pmax −p1) +(1 −p1)q1d21(pmin −p1) +(1 −p1)(1 −q1)d22(pmin −p1) = p1[q1d11 + (1 −q1)d12](pmax −p1) +(1 −p1)[q1d21 + (1 −q1)d22](pmin −p1) = p1(pmax −p1)D A 1 (q1) + (1 −p1)(pmin −p1)D A 2 (q1) (6) where D A 1 (q1) = q1d11 + (1 −q1)d12 (7) D A 2 (q1) = q1d21 + (1 −q1)d22. (8) By replacing pmax = 1 −pmin and rearranging the expres- sion, we get W1(X) = p1(1 −p1)D A 1 (q1) −p1 pminD A 1 (q1) +(1 −p1)pminD A 2 (q1) −p1(1 −p1)D A 2 (q1) = p1(1 −p1)  D A 1 (q1) −D A 2 (q1)  −pmin  p1 D A 1 (q1) −(1 −p1)D A 2 (q1)  . Similarly, we can get W2(X) = q1 p1(1 −d11)(pmax −q1) +q1(1 −p1)(1 −d12)(pmax −q1) +(1 −q1)p1(1 −d21)(pmin −q1) +(1 −q1)(1 −p1)(1 −d22)(pmin −q1) = q1[p1(1 −d11) + (1 −p1)(1 −d12)](pmax −q1) +(1 −q1)[p1(1 −d21) + (1 −p1)(1 −d22)](pmin −q1) = q1(pmax −q1)  1 −DB 1 (p1)  +(1 −q1)(pmin −q1) 1 −DB 2 (p1)  (9) where DB 1 (p1) = p1d11 + (1 −p1)d21 (10) DB 2 (p1) = p1d12 + (1 −p1)d22. (11) By replacing pmax = 1 −pmin and rearranging the expres- sion, we get W2(X) = q1(1 −q1) 1 −DB 1 (p1) −q1 pmin 1 −DB 1 (p1) +(1 −q1)pmin 1 −DB 2 (p1) −q1(1 −q1) 1 −DB 2 (p1) = −q1(1 −q1)  DB 1 (p1) −DB 2 (p1)  +pmin  −q1 1 −DB 1 (p1) + (1 −q1) 1 −DB 2 (p1)  = −q1(1 −q1)  DB 1 (p1) −DB 2 (p1)  +pmin q1DB 1 (p1) −(1 −q1)DB 2 (p1) + (1 −2q1) . (12) We need to address the two identiﬁed cases. Consider Case 1), where there is only a single mixed equilibrium. According to (4), we get D A 12(q1) = D A 1 (q1) −D A 2 (q1) = (d12 −d22) + Lq1. (13) Given that L > 0, since d11 > d12 and d22 > d21, D A 12(q1) is an increasing function of q1 and ⎧ ⎪⎨ ⎪⎩ D A 12(q1) < 0, if q1 < qopt D A 12(q1) = 0, if q1 = qopt D A 12(q1) > 0, if q1 > qopt. (14) For a given q1, W1(X) is quadratic in p1. Also, we have W1  0 q1  = pminD A 2 (q1) > 0 W1  1 q1  = −pminD A 1 (q1) < 0. (15) Since W1(X) is quadratic with a negative second derivative with respect to p1 and the inequalities in (15) are strict, it admits a single root p1 for p1 ∈[0, 1]. Moreover, we have W1(X) = 0 for some p1 such that ⎧ ⎪⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎪⎩ p1 < 1 2, if q1 < qopt p1 = 1 2, if q1 = qopt p1 > 1 2, if q1 > qopt. (16) Using a similar argument, we can see that there exists a single solution for each p1, and as pmin →0, we conclude that W1(X) = 0 whenever p1 ∈{0, popt, 1}. Arguing in a similar manner, we see that W2(X) = 0 when X ∈ 0 0  , 0 1  , 1 0  , popt qopt  . Thus, there exists a small enough value for pmin such that X∗= [p∗, q∗]⊺satisﬁes W2(X∗) = 0, proving Case 1). In the proof of Case 1), we have utilized the fact that for small enough pmin, the learning algorithm admits a stationary point and also identiﬁed the corresponding possible values for this point. It is thus always possible to select a small enough pmin > 0 such that X∗approaches Xopt, concluding the proof for Case 1). Case 2) can be derived in a similar manner, and the details are omitted to avoid repetition. □ In the next theorem, we show that the expected value of X(t) has a negative deﬁnite gradient. Theorem 2: The matrix of partial derivatives, ((∂W(X∗))/∂x), is negative deﬁnite. Proof: We start the proof by writing the explicit format for ∂W(X) ∂X = ⎡ ⎢⎢⎣ ∂W1(X) ∂p1 ∂W1(X) ∂q1 ∂W2(X) ∂p1 ∂W2(X) ∂q1 ⎤ ⎥⎥⎦ Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION 655 and then computing each of the entries as follows: ∂W1(X) ∂p1 = (1 −2p1) D A 1 (q1) −D A 2 (q1) −pmin D A 1 (q1) + D A 2 (q1) = (1 −2p1)D A 12(q1) −pmin D A 1 (q1) + D A 2 (q1) ∂W1(X) ∂q1 = p1(1 −p1)L −pmin(p1(d11 −d12) +(1 −p1)(d22 −d21)) ∂W2(X) ∂p1 = −q1(1 −q1)L + pmin((q1(d11 −d21) −(1 −q1)(d12 −d22)) ∂W2(X) ∂q1 = −(1 −2q1) DB 1 (p1) −DB 2 (p1) +pmin DB 1 (p1) + DB 2 (p1) −2 . As seen in Theorem 1, for a small enough value for pmin, we can ignore the terms that are weighted by pmin, and we will thus have ((∂W(X∗))/∂X) ≈((∂W(Xopt))/∂X). We now subdivide the analysis in the two cases identiﬁed as above, which are equivalent to the following. 1) Case 1: No saddle point in pure strategies. 2) Case 2: There is a saddle point in pure strategies. 3) Case 1 (No Saddle Point in Pure Strategies): In this case, we have D A 1 qopt = D A 2 qopt and DB 1 popt = DB 2 popt which makes ∂W1 Xopt ∂p1 = −2pminD A 1 qopt . (17) Similarly, we can compute ∂W1 Xopt ∂q1 = (1 −2pmin)popt 1 −popt L. (18) The entry ((∂W2(Xopt))/∂p1) can be simpliﬁed to ∂W2 Xopt ∂p1 = −(1 −2pmin)qopt 1 −qopt L (19) and ∂W2 Xopt ∂q1 = −2pmin 1 −DB 1 popt (20) resulting in (21), as shown at the bottom of the page. The matrix given in (21) satisﬁes det  ∂W Xopt ∂x  > 0 , trace  ∂W Xopt ∂x  < 0 (22) which implies that the 2 × 2 matrix is negative deﬁnite. 4) Case 2 (There Is a Saddle Point in Pure Strategies): In Theorem 1, Case 2 reduces to considering qopt = 1 and popt = 1. Computing the entries of the matrix for this case yields ∂W1 Xopt ∂p1 = −(d11 −d21) −pmin(d11 + d21) (23) and ∂W1 Xopt ∂q1 = −pmin(d11 −d12). (24) The entry ((∂W2(Xopt))/∂p1) can be simpliﬁed to ∂W2 Xopt ∂p1 = pmin(d11 −d21) (25) and ∂W2 Xopt ∂q1 = (d11 −d12) −pmin(2 −d11 −d12) (26) resulting in (27), as shown at the bottom of the next page. The matrix in (27) satisﬁes det  ∂W Xopt ∂X  > 0 , trace  ∂W Xopt ∂X  < 0 (28) for a sufﬁciently small value of pmin, which again implies that the 2 × 2 matrix is negative deﬁnite. □ Theorem 3: Let V be the von Neumann value of the game given by matrix D. Let p(t) = [p1, p2] and q(t) = [q1, q2]. For a sufﬁciently small pmin approaching 0, η(t) converges to V as θ →0 where η(t) ≜Ep(t) DEqT (t) . (29) Proof: The proof of these results requires a classic result due to Norman [7], given in the Appendix, in the interest of completeness. The convergence of E(p1(t)) E(q1(t)) to p∗ opt q∗ opt  is a consequence of this theorem. Interestingly enough, this theorem is a classical fundamental result that has been used to prove many of the convergence results in LA. It has, for example, been used by the seminal paper by Lakshmivarahan and Narendra [1] to derive similar convergence properties of the L R−ϵP, applicable for the same game settings as ours. Indeed, it is easy to verify that Assumptions (1)–(6) required for Norman’s result are satisﬁed. Thus, by further invoking Theorem 1 and Theorem 2, the result follows. □ We conclude this section by mentioning that like all LA algorithms, the computational complexity of our scheme is linear in the size of the action probability vector. This is because, at the most, all the action probabilities are updated at every time instant. For the beneﬁt of future researchers, we believe that it will be proﬁtable to record the hurdles we encountered in ∂W Xopt ∂X =  −2pminD A 1 qopt (1 −2pmin)popt 1 −popt L −(1 −2pmin)qopt 1 −qopt L −2pmin 1 −DB 1 popt  . (21) Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. 656 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023 this research. The breakthrough came when we were able to devise/design LA systems that possessed no-absorbing barriers. In other words, it involved the concept of forcing the LA back into the probability space when it was close enough to the absorbing barriers. This was a phenomenon that we had not earlier seen in the literature. The consequent problem was the analysis. The underlying Markov process could not be easily analyzed using the properties of absorbing chains. Neither could it be trivially modeled as an ergodic chain converging to an equilibrium distribution. The analysis that we presented here came as a “brain wave,” and once the building blocks were established, everything naturally seemed to fall in place. These few sentences, requested by an anonymous referee, should clarify the difﬁculties encountered in this research, in order to show that the present research is pioneering and this is not a trivial extension of existing methodologies. IV. SIMULATIONS In this section, we present simulations to conﬁrm the abovementioned theoretical properties of the proposed learning algorithm. In the interest of maintaining benchmarks, we adopt the same examples as those reported in [1]. Also, by using different instances of the payoff matrix D, we are able to experimentally cover the two cases referred to in Section III. Again, we refer to those cases as Cases 1 and 2, as done in [1]. A. Convergence in Case 1 We consider an instance of the game where only one mixed Nash equilibrium exists, i.e., there is no saddle point in pure strategies. We adopt the same game matrix D as in [1] given by D =  0.6 0.2 0.35 0.9  (30) which admits popt = 0.5789 and qopt = 0.7368. In order to eliminate the Monte Carlo error, we ran our scheme for 5 × 106 iterations and report the error in Table I for different values of pmax and θ as the difference between Xopt and the mean over time of X(t) after convergence.4 An important remark is that the error decreases as pmax approaches 1 (i.e., when pmin →0). Please observe that in this case, we have particularly chosen to not let pmax be unity. If we allow it to be precisely unity, it would mean that we would not require an artiﬁcial barrier close to unity (for example, between 0.990 and 0.999 as in Table I). In fact, for pmax = 0.999 and θ = 0.001, the method achieves an error of 2.1621 × 10−3, and further reducing θ = 0.0001 leads to an error of 1.6820 × 10−3. To better visualize the scheme, Fig. 1 shows the evolution over time of the mixed strategies for both players (given by 4The mean is taken over the last 10% of the total number of iterations. TABLE I ERROR FOR DIFFERENT VALUES OF θ AND pMAX WHEN pOPT = 0.5789 AND qOPT = 0.7368 FOR THE GAME SPECIFIED BY THE D MATRIX GIVEN BY (30). THE POINT THAT YOU HAVE RAISED IS PERTINENT Fig. 1. Time evolution of [p1(t), q1(t)]⊺for the same settings as in Fig. 2. X(t)) for an ensemble of 1000 runs using θ = 0.01 and pmax = 0.999. The trajectory of the ensemble allows us to perceive the mean evolution of the mixed strategies. The spiral pattern is caused by one of the players adapting to the strategy being used by the other before the former learns by overcorrecting its strategy. The procedure is continued leading to smaller corrections until the players reach the Nash equilibrium. The abovementioned behavior can also be visualized in Fig. 2 that presents the trajectory for a single experiment with pmax = 0.99 and θ = 0.00001 over 3 × 107 steps. The described oscillatory behavior is attenuated as the players play for more iterations. The reader should particularly observe that a larger value of θ will cause more steady-state error (as speciﬁed in Theorem 1), but it will also perturb this behavior as the nodes take larger updates whenever they win. On the other hand, further decreasing θ results in a smaller error of the stationary point of the method but also decreases the convergence speed. This well-established inherent tradeoff between the steady-state error and rate of convergence can be better visualized by comparing Fig. 1 with θ = 0.001 against Fig. 3 for a smaller value of θ = 10−5. ∂W Xopt ∂X = −(d11 −d21) −pmin(d11 + d21) −pmin(d11 −d12) pmin(d11 −d21) (d11 −d12) −pmin(2 −d11 −d12)  . (27) Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION 657 Fig. 2. Trajectory of X(t) for the case of the D matrix given by (30) with popt = 0.5789 and qopt = 0.7368 and using pmax = 0.99 and θ = 0.00001. Fig. 3. Time evolution of X(t) where popt = 0.5789 and qopt = 0.7368 using pmax = 0.99 and θ = 0.00001. Fig. 4. Trajectory of X(t) for the case of the D matrix given by (30) and using an absorbing barrier pmax = 1 and θ = 0.00001. Furthermore, in order to clearly emphasize the necessity of using an artiﬁcial barrier, we have speciﬁcally repeated the same experiment except that we have included an absorbing barrier instead, i.e., set pmax = 1. The result is shown in Fig. 4. In this case, we expect that the scheme enters an absorbing barrier. Since it is impossible for the human eye to detect whether or not we entered an absorbing barrier by merely examining the graph, we also manually checked the log of TABLE II ERROR FOR DIFFERENT VALUES OF θ AND pMAX FOR D1 TABLE III ERROR FOR DIFFERENT VALUES OF θ AND pMAX FOR D2 the experiment and veriﬁed that the probabilities became exactly unity after around 6798000 iterations. Although the theoretical convergence should have occurred in the limit and not after a ﬁnite number of iterations, the machine limited accuracy rounded the probabilities to unity after this juncture. B. Pure Equilibrium In order to assess the performance of the proposed learning algorithm on cases with a pure equilibrium, we consider two instances of games falling in the category of Case 2 with popt = 1 and qopt = 1. The payoff matrices D1 and D2 for the two games are given by D1 =  0.6 0.8 0.35 0.9  D2 = 0.7 0.9 0.6 0.8  . We ﬁrst show the convergence errors of our method for both games D1 and D2 in Tables II and III, respectively. As in the previous simulation for Case 1, the errors are on the order to 10−3 for larger values of pmax. However, given that our algorithm uses artiﬁcial barriers to prevent absorbing states, the error is lower bounded by pmin. A similar issue is present in game D2. We have also included this simulation since it is a more challenging game to learn with our method for a larger steady-state error, even for very small values of θ. In Fig. 5, we depict the time evolution of the two compo- nents of the vector X(t) using the proposed algorithm for an ensemble of 1000 runs. In the case of having a pure Nash equilibrium, there is no oscillatory behavior as when a player assigns more probability to an action since the other player Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. 658 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023 Fig. 5. (a) Evolution over time of X(t) for θ = 0.01 and Pmax = 0.999 when applied to game with payoffs D1. (b) Zoomed version around the steady-state value. Fig. 6. (a) Evolution over time of X(t) for θ = 0.01 and Pmax = 0.999 when applied to game with payoffs D2. (b) Zoomed version around the steady-state value. reinforces the strategy. However, Fig. 5(a) could lead make one believe that the LA method has converged to a pure strategy. Fig. 5(b) zooms around the point where the strategies have converged to showcase that their maximum value is limited by pmax, as per the design of our updating rule. This mechanism is particularly favorable to prevent players from converging to absorbing states for games with time-varying payoff matrices. However, the study of such a scenario is left for future research, namely that of determining how to design pmax and θ that represent a good tradeoff between learning the game and adapting to a change in the payoffs. Game D2 presents a harder challenge for our method as we can see from its larger steady-state error. Fig. 6 shows the time evolution of the probabilities for each player when the algorithm is applied to D2 with θ = 0.01, Pmax = 0.999 and for an ensemble with 1000 runs. The main remark regarding the results presented in Fig. 6(a) is that the convergence is much slower when compared to game D1. This behavior is governed by the fact that the entries in matrix D2 are closer to each other, unlike in D1 where there is a clear disadvantage for player A when selecting action 2. There will, thus, be much fewer updates for player A where it increases the probability of action 2 in game D1—which is not pertinent in game D2. Fig. 6(b) further emphasizes this remark by displaying a zoom, depicting a sharper change in the probabilities in comparison with the smooth behavior in game D1. C. Comparisons With Related Works Now that we have explained our new techniques and estab- lished its theoretical basis, we continue this discussion with a brief comparison with some of the prior art.5 First of all, one possible alternative when the payoff matrix is known can be to consider the problem as that of designing a local controller for each of the agents. One alternative is to explore the results in [28] and further investigated in [29]. However, this is only possible when D is known, which is not the scenario that we have assumed in this article. It is not out of place to review some of the relevant works in game theory that are not necessarily solved using LA. However, in the interest of space and brevity, we will not aim at submitting an extensive review of the ﬁeld of game theory. Rather, we shall cite some pertinent works inasmuch as our main contribution in this article centers on advancing the ﬁeld of LA-based solutions and, more speciﬁcally, those dealing with the special case of games with “incomplete information.” There are different variants of zero-sum stochastic games in the literature. Flesch et al. [30] have proven the general result that every positive zero-sum stochastic game with countable state and action spaces admits a value if at least one player has a ﬁnite action space. A similar value-existence result was obtained for a zero-sum stochastic game [31] with a continuous-time Markov chain, where the players have also the possibility of stopping the game. Ziliotto [32] considered weighted-average stochastic games, that is, stochastic games where Player 1 maximizes (in expectation) a ﬁxed weighted average of the sequence of rewards. A so-called pumping algorithm was proposed in [33] for two-person zero-sum undiscounted stochastic games. Other approaches map the game onto a dynamic programming problem and solve it based on Bellman’s optimal principle using concepts from the theory of optimal control [34]. The research on game theoretical learning with incomplete information [13] is scarce in the literature. Incomplete infor- mation is a taxonomy used within the ﬁeld of LA games to denote the case where the players do not observe the action of the opponent players and where each player does not know his own payoff function but only observes outcomes in the form of a reward or a penalty. The informed reader would observe that the games we deal with in this article fall under this class of games characterized by such incomplete information. The case of incomplete information is not usually treated by the mainstream of literature in game theory. Indeed, 5We are thankful to the anonymous referee who requested this comprehen- sive section. It signiﬁcantly adds to the quality of this article. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION 659 the main game learning algorithms available in the literature, such as ﬁctitious play [35], best response dynamics, and gradient-based learning approaches, deal with the complete knowledge case, where the players know their own payoff function and observe the history of the choices of other players. Fictitious play is one of the few algorithms that can converge to a mixed strategy equilibrium by maintaining var- ious frequency-based beliefs over the action of the opponent players, and using those beliefs, for deciding the next action to be played. However, the ﬁctitious play algorithm cannot solve our settings of incomplete information. When it comes to games with incomplete information, different algorithms have been suggested, which are based on the Bush–Mosteller learning paradigm. Notable examples include the ones reported in [36]–[39]. All those algorithms share a similar structure to our proposed LA, in particular, and to VSLA in general, in the sense, that the action probabilities are updated iteratively based on feedback and using some learning parameter. In this context, one should note that many LA models can be seen as extensions of Bush–Mosteller learning. However, the difference with our work is the fact that all the aforementioned algorithms have absorbing barriers. The theoretical analyses of the convergence to pure equilibria for this family of algorithms rely usually on the theory replicator dynamics. Another family of methods that can operate with limited information includes the Erev–Roth algorithm [40] and the Arthur algorithm [41], which in turn can be seen as a variant of the Erev–Roth algorithm. The Erev–Roth algo- rithm is alternatively called the Erev–Roth payoff matching algorithm and relies on updating the so-called “propensity” for each action, which is, loosely speaking, the cumulative payoff for that action. Thereafter, each action is played in a manner proportional to its corresponding relative propensity. The Erev–Roth algorithm is one of the few examples of limited-information game learning approaches that converge to unique mixed strategy equilibria. However, the Erev–Roth algorithm requires storing the entire history of rewards and penalties for each action. Furthermore, we have not been able to locate any research study that reports the analysis of the Erev–Roth algorithm for the case of our stochastic zero-sum game. We therefore opted to implement it for our game. Experimental results (not reported here, in the interest of not distracting from the main contribution of this article) show that it neither converges to the desired equilibrium nor does it possess consistent convergence results. D. Real-Life Application Scenarios One referee had requested a brief explanation of a complex environment, or different scenarios in a game, by which we could utilize our newly proposed solution. We agree that providing an insightful discussion could be insightful for interested readers and active researchers. This, of course, can be open-ended, but to satisfy the referee, we present the following brief example. Our learning algorithm admits potential applications in many security games as well as in communication problems. The intersection between game theory and security is an emerging ﬁeld of research. Algorithms that can converge to mixed equilibria are of great interest to the security community because mixed equilibria are usually preferred over pure ones. In fact, randomization gives less predictive ability to the attacker to guess the deployed strategy of the defender [42]. For instance, let us take a repetitive game involving a jammer and a transmitter, which, in turn, constitute our players [43]. The jammer aims to disturb and block communication between a transmitter and its associated receiver. The transmitter can choose the channel over which his message is communicated, while the jammer chooses a channel to attack. We suppose that the outcome is stochastic depending on the choice of the attacker (jammer) and defender (transmitter) and the stochastic characteristics of the channel. Both the jammer and transmitter can observe whether the attack was successful or not, and for instance, this common observation can be due to the receiver acknowledging the correct reception of the message over a wireless channel that both the attacker and jammer can overhear. Thus, the game is stochastic zero-sum. V. CONCLUSION The theoretical applications LA with artiﬁcially absorbing barriers have been reported since the 1980s [8] and, more recently, in Estimator LA [18]–[20]. This article pioneers the study of LA with artiﬁcial nonabsorbing barriers. LA have been previously used [13] to design algorithms capable of converging to the game’s Nash equilibrium under limited information. The majority of the LA algorithms used for games are absorbing in the probability simplex space, and they converge to an exclusive choice of a single action. These LA are, thus, unable to converge to other mixed Nash equilibria when the game possesses no saddle point for a pure strategy. As opposed to these, we propose an LA solution that is able to converge to an optimal mixed Nash equilibrium even though there may be no saddle point when a pure strategy is invoked. The scheme is inherently of the absorbing L R−I paradigm. However, by introducing reﬂecting barriers, we prevent it from being “stuck” or getting absorbed in pure strategies. Unlike the linear reward-ϵpenalty (L R−ϵP) scheme proposed in [1], our new scheme achieves the same goal with much less parameter tuning and in a more elegant manner. As far as know, our method is only the second reported algorithm in the literature capable of ﬁnding mixed strategies whenever no saddle point exists for pure strategies. If a saddle point exists for pure strategies, the scheme converges to a near-optimal solution close to the pure strategies in the probability simplex. This article includes the nontrial proofs of the theoretical results characterizing the convergence and stability of the algorithm. These are presented and illustrated through simulations for benchmark games presented in the literature. With regard to future work, we believe that it will be useful in real-life applications that can be modeled using such game-like behavior. APPENDIX NORMAN THEOREM Theorem 4: Let X(t) be a stationary Markov process dependent on a constant parameter θ ∈[0, 1]. Each X(t) ∈I, Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. 660 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023 where I is a subset of the real line. Let X(t) = X(t + 1) − X(t). The following are assumed to hold. 1) I is compact. 2) E[X(t)|X(t) = y] = θw(y) + O θ2 . 3) V ar[X(t)|X(t) = y] = θ2 s(y) + o θ2 . 4) EX(t)3|X(t) = y = O θ3 . where supy∈I O θk / θk < ∞for K = 2, 3 and supy∈I o θ2 /θ2 →0 as θ →0. 5) w(y) has a Lipschitz derivative in I. 6) s(y) is Lipschitz I. If Assumptions (1)–(6) hold, w(y) has a unique root y∗in I and (dw/dy)  y=y∗≤0; then, the following conditions hold. 1) var[X(t)|X(0) = x] = 0(θ) uniformly for all x ∈I and t ≥0. For any x ∈I, the differential equation (dy(τ)/dτ) = w(y(t)) has a unique solution y(τ) = y(τ, x) with y(0) = x and E[δX(t)|X(0) = x] = y(tθ) + O(θ) uniformly for all x ∈I and t ≥0. 2) (X(t) −y(tθ))/ √ θ has a normal distribution with zero mean and ﬁnite variance as θ →0 and tθ →∞. ACKNOWLEDGMENT The authors are very grateful for the feedback from the anonymous Referees of the original submission. Their input signiﬁcantly improved the quality of this ﬁnal version. REFERENCES [1] S. Lakshmivarahan and K. S. Narendra, “Learning algorithms for two- person zero-sum stochastic games with incomplete information: A uniﬁed approach,” SIAM J. Control Optim., vol. 20, no. 4, pp. 541–552, 1982. [2] S. Lakshmivarahan, Learning Algorithms Theory and Applications: Theory and Applications. New York, NY, USA: Springer, 2012. [3] J. K. Lanctot and B. J. Oommen, “On discretizing estimator-based learning algorithms,” IEEE Trans. Syst., Man, Cybern., B, Cybern., vol. 2, pp. 1417–1422, 1991. [4] J. K. Lanctot and B. J. Oommen, “Discretized estimator learn- ing automata,” IEEE Trans. Syst., Man, Cybern., vol. 22, no. 6, pp. 1473–1483, Nov./Dec. 1992. [5] K. Najim and A. S. Poznyak, Learning Automata: Theory and Applica- tions. Amsterdam, The Netherlands: Elsevier, 2014. [6] K. S. Narendra and M. A. Thathachar, Learning Automata: An Intro- duction. North Chelmsford, MA, USA: Courier Corporation, 2012. [7] M. F. Norman, Markov Processes and Learning Models, vol. 84. New York, NY, USA: Academic, 1972. [8] B. Johnoommen, “Absorbing and ergodic discretized two-action learning automata,” IEEE Trans. Syst., Man, Cybern., vol. 16, no. 2, pp. 282–293, Mar. 1986. [9] B. J. Oommen and J. K. Lanctot, “Discretized pursuit learning automata,” IEEE Trans. Syst., Man, Cybern., vol. 20, no. 4, pp. 931–938, Jul./Aug. 1990. [10] B. J. Oommen and M. Agache, “Continuous and discretized pursuit learning schemes: Various algorithms and their comparison,” IEEE Trans. Syst., Man, Cybern., B (Cybern.), vol. 31, no. 3, pp. 277–287, Jun. 2001. [11] G. P. Papavassilopoulos, “Learning algorithms for repeated bimatrix Nash games with incomplete information,” J. Optim. Theory Appl., vol. 62, no. 3, pp. 467–488, 1989. [12] A. Rezvanian, A. M. Saghiri, S. M. Vahidipour, M. Esnaashari, and M. R. Meybodi, Recent Advances in Learning Automata, vol. 754. New York, NY, USA: Springer, 2018. [13] P. S. Sastry, V. V. Phansalkar, and M. A. L. Thathachar, “Decentralized learning of Nash equilibria in multi-person stochastic games with incomplete information,” IEEE Trans. Syst., Man Cybern., vol. 24, no. 5, pp. 769–777, May 1994. [14] M. A. L. Thathachar and P. S. Sastry, Networks of Learning Automata: Techniques for Online Stochastic Optimization. Boston, MA, USA: Kluwer, 2003. [15] M. L. Tsetlin et al., Automaton Theory and Modeling of Biological Systems. New York, NY, USA: Academic, 1973. [16] B. Tung and L. Kleinrock, “Using ﬁnite state automata to produce self- optimization and self-control,” IEEE Trans. Parallel Distrib. Syst., vol. 7, no. 4, pp. 439–448, Apr. 1996. [17] Y. Xing and R. Chandramouli, “Stochastic learning solution for distrib- uted discrete power control game in wireless data networks,” IEEE/ACM Trans. Netw., vol. 16, no. 4, pp. 932–944, Aug. 2008. [18] X. Zhang, O. C. Granmo, B. J. Oommen, and L. Jiao, “A formal proof of the ε-optimality of absorbing continuous pursuit algorithms using the theory of regular functions,” Appl. Intell., vol. 41, pp. 974–985, May 2014. [19] X. Zhang, B. J. Oommen, O. C. Granmo, and L. Jiao, “A formal proof of the ε-optimality of discretized pursuit algorithms,” Appl. Intell., vol. 44, pp. 282–294, 2016, doi: 10.1007/s10489-015-0670-1. [20] X. Zhang, B. J. Oommen, and O. C. Granmo, “The design of absorb- ing Bayesian pursuit algorithms and the formal analyses of their ε- optimality,” Pattern Anal. Appl., vol. 20, no. 3, pp. 797–808, 2015. [21] J. R. Marden, G. Arslan, and J. S. Shamma, “Cooperative control and potential games,” IEEE Trans. Syst., Man, Cybern. B. Cybern., vol. 39, no. 6, pp. 1393–1407, Dec. 2009, doi: 10.1109/TSMCB.2009.2017273. [22] D. Silvestre, J. P. Hespanha, and C. Silvestre, “Resilient desyn- chronization for decentralized medium access control,” IEEE Con- trol Syst. Lett., vol. 5, no. 3, pp. 803–808, Jul. 2021, doi: 10.1109/LCSYS.2020.3005819. [23] D. Silvestre, J. Hespanha, and C. Silvestre, “Desynchronization for decentralized medium access control based on gauss-seidel iterations,” in Proc. Amer. Control Conf. (ACC), Jul. 2019, pp. 4049–4054, doi: 10.23919/ACC.2019.8814471. [24] D. Silvestre, J. P. Hespanha, and C. Silvestre, “Broadcast and gossip stochastic average consensus algorithms in directed topologies,” IEEE Trans. Control Netw. Syst., vol. 6, no. 2, pp. 474–486, Jun. 2019, doi: 10.1109/TCNS.2018.2839341. [25] D. Silvestre, J. Hespanha, and C. Silvestre, “A PageRank algorithm based on asynchronous gauss-seidel iterations,” in Proc. Annu. Amer. Control Conf. (ACC), Milwaukee, WI, USA, Jun. 2018, pp. 484–489, doi: 10.23919/ACC.2018.8431212. [26] R. Ribeiro, D. Silvestre, and C. Silvestre, “A rendezvous algorithm for multi-agent systems in disconnected network topologies,” in Proc. 28th Medit. Conf. Control Autom. (MED), Sep. 2020, pp. 592–597, doi: 10.1109/MED48518.2020.9183093. [27] R. Ribeiro, D. Silvestre, and C. Silvestre, “Decentralized control for multi-agent missions based on ﬂocking rules,” CONTROLO ( Lec- ture Notes in Electrical Engineering), vol. 695, J. A. Gonçalves, M. Braz-César, and J. P. Coelho, Eds. Cham, Switzerland: Springer, 2021, pp. 445–454, doi: 10.1007/978-3-030-58653-9_43. [28] Y. Wu and R. Lu, “Output synchronization and L2-gain analysis for network systems,” IEEE Trans. Syst., Man, Cybern., Syst., vol. 48, no. 12, pp. 2105–2114, Dec. 2018, doi: 10.1109/TSMC.2017.2754544. [29] Y. Wu, A. Isidori, R. Lu, and H. K. Khalil, “Performance recovery of dynamic feedback-linearization methods for multivariable nonlinear systems,” IEEE Trans. Autom. Control, vol. 65, no. 4, pp. 1365–1380, Apr. 2020, doi: 10.1109/TAC.2019.2924176. [30] J. Flesch, A. Predtetchinski, and W. Sudderth, “Positive zero-sum stochastic games with countable state and action spaces,” Appl. Math. Optim., vol. 82, pp. 499–516, Nov. 2018. [31] C. Pal and S. Saha, “Continuous-time zero-sum stochastic game with stopping and control,” Operations Res. Lett., vol. 48, no. 6, pp. 715–719, Nov. 2020. [32] B. Ziliotto, “A tauberian theorem for nonexpansive operators and appli- cations to zero-sum stochastic games,” Math. Operations Res., vol. 41, no. 4, pp. 1522–1534, Nov. 2016. [33] E. Boros, K. Elbassioni, V. Gurvich, and K. Makino, “A potential reduction algorithm for two-person zero-sum mean payoff stochastic games,” Dyn. Games Appl., vol. 8, no. 1, pp. 22–41, Mar. 2018. [34] K. Du, R. Song, Q. Wei, and B. Zhao, “A solution of two-person zero sum differential games with incomplete state information,” in Advances in Neural Networks—ISNN 2019 (Lecture Notes in Computer Science), vol. 11554, H. Lu, H. Tang, and Z. Wang, Eds. Cham, Switzerland: Springer, 2019, doi: 10.1007/978-3-030-22796-8_46. [35] J. Hofbauer and W. H. Sandholm, “On the global convergence of stochastic ﬁctitious play,” Econometrica, vol. 70, no. 6, pp. 2265–2294, Nov. 2002. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION 661 [36] T. Börgers and R. Sarin, “Learning through reinforcement and replicator dynamics,” J. Econ. Theory, vol. 77, no. 1, pp. 1–14, Nov. 1997. [37] L. R. Izquierdo, S. S. Izquierdo, N. M. Gotts, and J. G. Polhill, “Tran- sient and asymptotic dynamics of reinforcement learning in games,” Games Econ. Behav., vol. 61, no. 2, pp. 259–276, Nov. 2007. [38] A. S. Poznyak and K. Najim, “Bush-Mosteller learning for a zero-sum repeated game with random pay-offs,” Int. J. Syst. Sci., vol. 32, no. 10, pp. 1251–1260, 2001. [39] Q. Zhu, H. Tembine, and T. Basar, “Heterogeneous learning in zero- sum stochastic games with incomplete information,” in Proc. 49th IEEE Conf. Decis. Control (CDC), Dec. 2010, pp. 219–224. [40] I. Erev and A. E. Roth, “Multi-agent learning and the descriptive value of simple models,” Artif. Intell., vol. 171, no. 7, pp. 423–428, May 2007. [41] W. B. Arthur, “On designing economic agents that behave like human agents,” J. Evol. Econ., vol. 3, no. 1, pp. 1–22, Mar. 1993. [42] M. H. Manshaei, Q. Zhu, T. Alpcan, T. Bac¸sar, and J.-P. Hubaux, “Game theory meets network security and privacy,” ACM Comput. Surv., vol. 45, no. 3, pp. 1–39, Jun. 2013. [43] V. Vadori, M. Scalabrin, A. V. Guglielmi, and L. Badia, “Jamming in underwater sensor networks as a Bayesian zero-sum game with position uncertainty,” in Proc. IEEE Global Commun. Conf. (GLOBECOM), Dec. 2014, pp. 1–6. Anis Yazidi (Senior Member, IEEE) received the M.Sc. and Ph.D. degrees from the University of Agder, Grimstad, Norway, in 2008 and 2012, respectively. He was a Researcher with Teknova AS, Grimstad. From 2014 to 2019, he was an Associate Pro- fessor with the Department of Computer Science, Oslo Metropolitan University, Oslo, Norway. He is currently a Full Professor with the Department of Computer Science, where he is leading the research group in applied artiﬁcial intelligence. He is also a Professor II with the Norwegian University of Science and Technol- ogy (NTNU), Trondheim, Norway. His current research interests include machine learning, learning automata, stochastic optimization, and autonomous computing. Daniel Silvestre received the B.Sc. degree in computer networks from the Instituto Superior Técnico (IST), Lisbon, Portugal, in 2008, and the M.Sc. degree in advanced computing and the Ph.D. degree (Hons.) in electrical and computer engineer- ing from Imperial College London, London, U.K., in 2009 and 2017, respectively. He was a Visiting Scholar at the University of California at Santa Barbara, Santa Barbara, CA, USA. He is currently with the Institute for Systems and Robotics, IST. He holds a research assistant appointment with the University of Macau, Macau. His research interests span the ﬁelds of fault detection and isolation, distributed systems, network control systems, computer networks, set-valued estimation and control methods, and randomized algorithms. B. John Oommen (Life Fellow, IEEE) was born in India, in 1953. He received the Bachelor of Technology degree in electrical engineering from IIT Madras, Chennai, India, in 1975, the Master of Engineering degree from the Indian Institute of Science, Bengaluru, India, in 1977, and the Master of Science degree and the Ph.D. degree in electrical engineering from Purdue University, West Lafayette, IN, USA, in 1979 and 1982, respectively. He has been teaching at the School of Computer Science, Carleton University, Ottawa, ON, Canada, since 1981. He was elevated to be a Chancellor’s Professor at Carleton University in 2006. He has published more than 485 refereed publications, many of which have been award-winning. Dr. Oommen was nominated as a fellow of the Institute of Electrical and Electronic Engineers (IEEE) for research in a subﬁeld of artiﬁcial intelligence, namely in learning automata in 2003. He was also nominated as a fellow of the International Association of Pattern Recognition (IAPR) in August 2006 for contributions to fundamental and applied problems in syntactic and statis- tical pattern recognition. He received the Carleton University’s Research Achievement Award four times, in 1995, 2001, 2007, and 2015. At IIT Madras and the Indian Institute of Science, he received the medal for being the Best Graduating Student. He has served on the Editorial Board of the IEEE TRANSACTIONS ON SYSTEMS, MAN AND CYBERNETICS and Pattern Recognition. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply."
Artificial intelligence in dry eye disease,Andrea M. Storås and Inga Strümke and Michael A. Riegler and Jakob Grauslund and Hugo L. Hammer and Anis Yazidi and Pål Halvorsen and Kjell G. Gundersen and Tor P. Utheim and Catherine J. Jackson,2022,,23,The Ocular Surface,article,"The Ocular Surface 23 (2022) 74–86
Available online 27 November 2021
1542-0124/© 2021 Elsevier Inc. All rights reserved.
Review Article 
Artificial intelligence in dry eye disease 
Andrea M. Storås a,e,*, Inga Strümke a, Michael A. Riegler a, Jakob Grauslund b,c,d, 
Hugo L. Hammer a,e, Anis Yazidi e, Pål Halvorsen a,e, Kjell G. Gundersen h, Tor P. Utheim e,f,g, 
Catherine J. Jackson h 
a SimulaMet, Oslo, Norway 
b Department of Ophthalmology, Odense University Hospital, Odense, Denmark 
c Department of Clinical Research, University of Southern Denmark, Odense, Denmark 
d Department of Ophthalmology, Vestfold University Trust, Tønsberg, Norway 
e Department of Computer Science, Oslo Metropolitan University, Norway 
f Department of Medical Biochemistry, Oslo University Hospital, Norway 
g Department of Ophthalmology, Oslo University Hospital, Norway 
h Ifocus, Haugesund, Norway   
A R T I C L E  I N F O   
Keywords: 
Dry eye disease 
Artificial intelligence 
Machine learning 
A B S T R A C T   
Dry eye disease (DED) has a prevalence of between 5 and 50%, depending on the diagnostic criteria used and 
population under study. However, it remains one of the most underdiagnosed and undertreated conditions in 
ophthalmology. Many tests used in the diagnosis of DED rely on an experienced observer for image interpre­
tation, which may be considered subjective and result in variation in diagnosis. Since artificial intelligence (AI) 
systems are capable of advanced problem solving, use of such techniques could lead to more objective diagnosis. 
Although the term ‘AI’ is commonly used, recent success in its applications to medicine is mainly due to ad­
vancements in the sub-field of machine learning, which has been used to automatically classify images and 
predict medical outcomes. Powerful machine learning techniques have been harnessed to understand nuances in 
patient data and medical images, aiming for consistent diagnosis and stratification of disease severity. This is the 
first literature review on the use of AI in DED. We provide a brief introduction to AI, report its current use in DED 
research and its potential for application in the clinic. Our review found that AI has been employed in a wide 
range of DED clinical tests and research applications, primarily for interpretation of interferometry, slit-lamp and 
meibography images. While initial results are promising, much work is still needed on model development, 
clinical testing and standardisation.   
1. Introduction 
Dry eye disease (DED) is one of the most common eye diseases 
worldwide, with a prevalence of between 5 and 50%, depending on the 
diagnostic criteria used and study population [1]. Yet, although symp­
toms stemming from DED are reported as the most common reason to 
seek medical eye care [1], it is considered one of the most under­
diagnosed and undertreated conditions in ophthalmology [2]. Symp­
toms of DED include eye irritation, photophobia and fluctuating vision. 
The condition can be painful and might result in lasting damage to the 
cornea through irritation of the ocular surface. Epidemiological studies 
indicate that DED is most prevalent in women [3] and increases with age 
[1]. However, the incidence of DED is likely to increase in all age groups 
in coming years due to longer screen time and more prevalent use of 
contact lenses, which are both risk factors [4]. Other risk factors include 
diabetes mellitus [5] and exposure to air-pollution [6]. DED can have a 
substantial effect on the quality of life, and may impose significant direct 
and indirect public health costs as well as personal economic burden due 
to reduced work productivity. 
DED is divided into two subtypes defined by the underlying mech­
anism of the disease: (i) aqueous deficient DED, where tear production 
from the lacrimal gland is insufficient and (ii) evaporative DED (the 
most common form), which is typically caused by dysfunctional mei­
bomian glands in the eyelids. Meibomian glands are responsible for 
supplying meibum, which is a concentrated substance that normally 
covers the surface of the cornea to form a protective superficial lipid 
* Corresponding author. SimulaMet, Oslo, Norway. 
E-mail address: andrea@simula.no (A.M. Storås).  
Contents lists available at ScienceDirect 
The Ocular Surface 
journal homepage: www.elsevier.com/locate/jtos 
https://doi.org/10.1016/j.jtos.2021.11.004 
Received 9 July 2021; Received in revised form 8 November 2021; Accepted 9 November 2021   
 The Ocular Surface 23 (2022) 74–86
75
layer that guards against evaporation of the underlying tear film. The 
ability to reliably distinguish between aqueous deficient and evapora­
tive DED, their respective severity levels and mixed aqueous/evapora­
tive forms is important in deciding the ideal modality of treatment. A 
fast and accurate diagnosis relieves patient discomfort and also spares 
them unnecessary expense and exposure to potential side effects asso­
ciated with some treatments. A tailor made treatment plan can yield 
improved treatment response and maximize health provider efficiency. 
The main clinical signs of DED are decreased tear volume, more rapid 
break-up of the tear film (fluorescein tear break-up time (TBUT)) and 
microwounds of the ocular surface [7]. In the healthy eye, the tear film 
naturally ‘breaks up’ after 10 s and the protective tear film is reformed 
with blinking. Available diagnostic tests often do not correlate with the 
severity of clinical symptoms reported by the patient. No single clinical 
test is considered definitive in the diagnosis of DED [1]. Therefore, 
multiple tests are typically used in combination and supplemented by 
information gathered on patient symptoms, recorded through ques­
tionnaires. These tests demand a significant amount of time and re­
sources at the clinic. Tests for determining the physical parameters of 
tears include TBUT, the Schirmer’s test, tear osmolarity and tear 
meniscus height. Other useful tests in DED diagnosis include ocular 
surface staining, corneal sensibility, interblink frequency, corneal sur­
face topography, interferometry, aberrometry and imaging techniques 
such as meibography and in vivo confocal microscopy (IVCM), as well as 
visual function tests. 
Artificial intelligence (AI) was defined in 1955 as “the science and 
engineering of making intelligent ma-chines” [8], where intelligence is 
the “ability to achieve goals in a wide range of environments” [9]. 
Within AI, machine learning denotes a class of algorithms capable of 
learning from data rather than being programmed with explicit rules. AI, 
and particularly machine learning, is increasingly becoming an integral 
part of health care systems. The sub-field of machine learning known as 
deep learning uses deep artificial neural networks, and has gained 
increased attention in recent years, especially for its image and text 
recognition abilities. In the field of ophthalmology, deep learning has so 
far mainly been used in the analysis of data from the retina to segment 
regions of interest in images, automate diagnosis and predict disease 
outcomes [10]. For instance, the combination of deep learning and op­
tical coherence tomography (OCT) technologies has allowed reliable 
detection of retinal diseases and improved diagnosis [11]. Machine 
learning also has potential for use in the diagnosis and treatment of 
anterior segment diseases, such as DED and has already found its way 
into the field with methods such as presented by Ciezar et al. [12]. Many 
of the tests used for DED diagnosis and follow-up rely on the experience 
of the observer for interpretation of images, which may be considered 
subjective [13]. AI tools can be used to interpret images automatically 
and objectively, saving time and providing consistency in diagnosis. 
Several reviews have been published that discuss the application of 
AI in eye disease, including screening for diabetic retinopathy [14], 
detection of age-related macular degeneration [15] and diagnosis of 
retinopathy of prematurity [16]. We are, however, not aware of any 
review on AI in DED. In this article, we therefore provide a critical re­
view of the use of AI systems developed within the field of DED, discuss 
their current use and highlight future work. 
2. Artificial intelligence 
AI is informational technology capable of performing activities that 
require intelligence. It has gained substantial popularity within the field 
of medicine due to its ability to solve ubiquitous medical problems, such 
as classification of skin cancer [17], prediction of hypoxemia during 
surgeries [18], identification of diabetic retinopathy [19] and prediction 
of risk for future need of keratoplasty [20]. Machine learning is a 
sub-field of AI encompassing algorithms capable of learning from data, 
without being explicitly programmed. All AI systems used in the studies 
included in this review, fall within the class of machine learning. The 
process by which a machine learning algorithm learns from data is 
referred to as training. The outcome of the training process is a machine 
learning model, and the model’s output is referred to as predictions. 
Different learning algorithms are categorised according to the type of 
data they use, and referred to as supervised, unsupervised and rein­
forcement learning. The latter is excluded from this review, as none of 
the studies use it, while the two former are introduced in this section. A 
complete overview of the algorithms encountered in the reviewed 
studies is provided in Fig. 1, sorted according to the categories described 
below. 
2.1. Supervised learning 
Supervised learning denotes the learning process of an algorithm 
using labelled data, meaning data that contains the target value for each 
data instance, e.g., tear film lipid layer category. The learning process 
involves extracting patterns linking the input variables and the target 
outcome. The performance of the resulting model is evaluated by letting 
it predict on a previously unseen data set, and comparing the predictions 
to the true data labels. See Section 2.5 for a brief discussion of evaluation 
metrics. Supervised learning algorithms can perform regression and 
classification, where regression involves predicting a numerical value 
for a data instance, and classification involves assigning data instances 
to predefined categories. Fig. 1 contains an overview of supervised 
learning algorithms encountered in the reviewed studies. 
2.2. Unsupervised learning 
Unsupervised learning denotes the training process of an algorithm 
using unlabelled data, i.e., data not containing target values. The task of 
the learning algorithm is to find patterns or data groupings by con­
structing a compact representation of the data. This type of machine 
learning is commonly used for grouping observations together, detecting 
relationships between input variables, and for dimensionality reduction. 
As unsupervised learning data contains no labels, a measure of model 
performance depends on considerations outside the data [see 21, chap. 
14], e.g., how the task would have been solved by someone in the real 
world. For clustering algorithms, similarity or dissimilarity measures 
such as the distance between cluster points can be used to measure 
performance, but whether this is relevant depends on the task [22]. 
Unsupervised algorithms encountered in the reviewed studies can be 
divided into those performing clustering and those used for dimen­
sionality reduction, see Fig. 1 for an overview. 
2.3. Artificial neural networks and deep learning 
Artificial neural networks are loosely inspired by the neurological 
networks in the biological brain, and consist of artificial neurons 
organised in layers. How the layers are organised within the network is 
referred to as its architecture. Artificial neural networks have one input 
layer, responsible for passing the data to the network, and one or more 
hidden layers. Networks with more than one hidden layer are called 
deep neural networks. The final layer is the output layer, providing the 
output of the entire network. Deep learning is a sub-field of machine 
learning involving training deep neural networks, which can be done 
both in a supervised and unsupervised manner. We encounter several 
deep architectures in the reviewed studies. The two more advanced 
types are convolutional neural networks (CNNs) and generative adver­
sarial networks (GANs). CNN denotes the commonly used architecture 
for image analysis and object detection problems, named for having so- 
called convolutional layers that act as filters identifying relevant fea­
tures in images. CNNs have gained popularity recently and all of the 
reviewed studies that apply CNNs were published in 2019 or later. 
Advanced deep learning techniques will most likely replace the estab­
lished image analysis methods. This trend has been observed within 
other medical fields such as gastrointestinal diseases and radiology [23, 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
76
24]. A GAN is a combination of two neural networks: A generator and a 
discriminator competing against each other. The goal of the generator is 
to produce fake data similar to a set of real data. The discriminator re­
ceives both real data and the fake data from the generator, and its goal is 
to discriminate the two. GANs can among other things be used to 
generate synthetic medical data, alleviating privacy concerns [25]. 
2.4. Workflow for model development and validation 
The data used for developing machine learning models is ideally 
divided into three independent parts: A training set, a validation set and 
a test set. The training set is used to tune the model, the validation set to 
evaluate performance during training, and the test set to evaluate the 
final model. A more advanced form of training and validation, is k-fold 
cross-validation. Here, the data is split into k parts, of which one part is 
set aside for validation, while the model is trained on the remaining 
data. This is repeated k times, and each time a different part of the data is 
used for validation. The model performance can be calculated as the 
average performance for the k different models [see 21, chap. 7]. It is 
considered good practice to not use the test data during model devel­
opment and vice versa, the model should not be tuned further once it has 
been evaluated on the test data [see 21, chap.7]. In cases of class 
imbalance, i.e., unequal number of instances from the different classes, 
there is a risk of developing a model that favors the prevalent class. If the 
data is stratified for training and testing, this might not be captured 
during testing. Class imbalance is common in medical data sets, as there 
are for instance usually more healthy than ill people in the population 
[26]. Whether to choose a class distribution that represents the popu­
lation, a balanced or some other distribution depends on the objective. 
Various performance scores should regardless always be used to provide 
a full picture of the model’s performance. 
2.5. Performance scores 
In order to assess how well a machine learning model performs, its 
performance can be assigned a score. In supervised learning, this is 
based on the model’s output compared to the desired output. Here, we 
introduce scores used most frequently in the reviewed studies. Their 
definitions as well as the remaining scores used are provided in Ap­
pendix A.1. A commonly used performance score in classification is 
accuracy, Equation (A.3), which denotes the proportion of correctly 
predicted instances. Its use is inappropriate in cases of strong class 
imbalance, as it can reach high values if the model always predicts the 
prevalent class. The sensitivity, also known as recall, Equation (A.4), 
denotes the true positive rate. If the goal is to detect all positive in­
stances, a high sensitivity indicates success. The precision, Equation 
(A.5), denotes the positive predictive value. The specificity, Equation 
(A.6), denotes the true negative rate, and is the negative class version of 
the sensitivity. The F1 score, Equation (A.7), is the harmonic mean be­
tween the sensitivity and the precision. It is not symmetric between the 
classes, meaning it is dependent on which class is defined as positive. 
Image segmentation involves partitioning the pixels in an image into 
segments [27]. This can for example be used to place all pixels repre­
senting the pupil into the same segment while pixels representing the iris 
are placed in another segment. The identified segments can then be 
compared to manual annotations. Performance scores used include the 
Average Pompeiu-Hausdorff distance, (A.17), the Jaccard index and the 
support, all described in Appendix A.1. 
2.6. AI regulation 
Approved AI devices will be a major part of the medical service 
landscape in the future. Currently, many countries are actively working 
on releasing AI regulations for healthcare, including the European Union 
(EU), the United States, China, South Korea and Japan. On April 21, 
2021, the EU released a proposal for a regulatory framework for AI [28]. 
The US Food and Drug Administration (FDA) is also working on AI 
legislation for healthcare [29]. 
In the framework proposed by the EU, AI systems are divided into the 
four categories low risk, minimal risk, high risk and unacceptable risk 
[28]. AI systems that fall into the high risk category are expected to be 
subject to strict requirements, including data governance, technical 
documentation, transparency and provision of information to users, 
human oversight, robustness and cyber security, and accuracy. It is 
highly likely that medical devices using AI will end up in the high risk 
category. Looking at the legislation proposals [28,29] from an AI 
research perspective, it is clear that explainable AI, transparency, un­
certainty assessment, robustness against adversarial attacks, high qual­
ity of data sets, proper performance assessment, continuous 
post-deployment monitoring, human oversight and interaction be­
tween AI systems and humans, will be major research topics for the 
development of AI in healthcare. 
3. Methods 
3.1. Search methods 
A systematic literature search was performed in PubMed and Embase 
in the period between March 20 and May 21, 2021. The goal was to 
retrieve as many studies as possible applying machine learning to DED 
related data. The following keywords were used: All combinations of 
“dry eye” and “meibomian gland dysfunction” with “artificial intelli­
gence”, “machine learning”, “computer vision”, “image recognition”, 
“bayesian network”, “decision tree”, “neural network”, “image based 
Fig. 1. An overview of the machine learning algorithms used in the reviewed studies.  
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
77
analysis”, “gradient boosting”, “gradient boosting machine” and “auto­
matic detection”. In addition, searches for “ocular surface” combined 
with both “artificial intelligence” and “machine learning” were made. 
See also an overview of the search terms and combinations in Fig. 2. No 
time period limitations were applied for any of the searches. 
3.2. Selection criteria 
The studies to include in the review had to be available in English in 
full-text. Studies not investigating the medical aspects of DED were 
excluded (e.g., other ocular diseases and cost analyses of DED). More­
over, the studies had to describe the use of a machine learning model in 
order to be considered. Reviews were not considered. The studies were 
selected in a three-step process. One review author screened the titles on 
the basis of the inclusion criteria. The full-texts were then retrieved and 
studied for relevance. The search gave 640 studies in total, of which 111 
were regarded as relevant according to the selection criteria. After 
removing duplicates, 45 studies were left. The three-step process is 
shown in Fig. 3a. 
4. Artificial intelligence in dry eye disease 
4.1. Summary of the studies 
Most studies were published in recent years, especially after 2014, 
see Fig. 3b. An overview of the studies is provided in Tables 1-4 for the 
clinical, biochemical and demographical studies, respectively. Infor­
mation on the data used in each study is shown in Table 5. We grouped 
studies according to the type of clinical test or type of study: TBUT, 
interferometry and slit-lamp images, IVCM, meibography, tear osmo­
larity, proteomics analysis, OCT, population surveys and other clinical 
tests. We found most studies employed machine learning for interpre­
tation of interferometry, slit-lamp and meibography images. 
4.2. Fluorescein tear break-up time 
Shorter break-up time indicates an unstable tear film and higher 
probability of DED. Machine learning has been employed to detect dry 
areas in TBUT videos and estimate TBUT [13,59,60,65]. Use of the 
Levenberg-Marquardt algorithm to detect dry areas achieved an accu­
racy of 91% compared to assessments by an optometrist [13]. Applica­
tion of Markov random fields to label pixels based on degree of dryness 
was used to estimate TBUT resulting in an average difference of 2.34 s 
compared to clinician assessments [65]. Polynomial functions have also 
been used to determine dry areas, where threshold values were 
fine-tuned before estimation of TBUT [59]. This method resulted in 
more than 90% of the videos deviating by less than ±2.5 s compared to 
analyses done by four experts on videos not used for training [60]. Taken 
together, these studies indicate that TBUT values obtained using auto­
matic methods are within an acceptable range compared to experts. 
However, we only found four studies, all of them including a small 
number of subjects. Further studies are needed to verify the findings and 
to test models on external data. 
4.3. Interferometry and slit-lamp images 
Interferometry is a useful tool that gives a snapshot of the status of 
the tear film lipid layer, which can be used to aid diagnosis of DED. 
Machine learning systems have been applied to interferometry and slit- 
lamp images for lipid layer classification based on morphological 
properties [36,37,54,56,57,61,62], estimation of the lipid layer thick­
ness [38,52], diagnosis of DED [49,51], determination of ocular redness 
[63] and estimation of tear meniscus height [31,50]. 
Diagnosis of DED can be based on the following morphological 
properties: open meshwork, closed mesh-work, wave, amorphous and 
color fringe [76]. Most studies used these properties to automatically 
classify interferometer lipid layer images using machine learning. Garcia 
et al. used a K-nearest neighbors model trained to classify images 
resulting in an accuracy of 86.2% [62]. Remeseiro et al. explored various 
support vector machine (SVM) models for use in final classification [56, 
57,61]. In one of the studies, the same data was used for training and 
testing, which is not ideal [57]. Another study did not report the data 
their system was trained on [56]. Peteiro et al. evaluated images using 
five different machine learning models [54]. In this study, the amor­
phous property was not included as one of possible classifications, as 
opposed to the other studies. A simple neural network achieved the 
overall best performance with an accuracy of 96%. However, because 
leave-one-out cross validation was applied, the model may have over­
fitted on the training data [21]. da Cruz et al. compared six different 
machine learning models and found that the random forest was the best 
classifier, regardless of the pre-processing steps used [36,37]. The 
highest performance was achieved by application of Ripley’s K function 
in the image pre-processing phase, and Greedy Stepwise technique used 
simultaneously with the machine learning models for feature selection 
[37]. Since all models were evaluated with cross validation, the system 
should be externally evaluated on new images before being considered 
Fig. 2. Search term combinations used in the literature search. Three of the studies found in the searches including “ocular surface” were also found among the 
studies in the searches including “dry eye”. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
78
for routine use in the clinic. 
Hwang et al. investigated whether tear film lipid layer thickness can 
be used to distinguish meibomian gland dysfunction (MGD) severity 
groups [52]. Machine learning was used to estimate the thickness from 
Lipiscanner and slit-lamp videos with promising results. Images were 
pre-processed and the flood-fill algo-rithm and canny edge detection 
were applied to locate and extract the iris from the pupil. A significant 
difference between two MGD severity groups was detected, suggesting 
that the technique could be used for the evaluation of MGD. Keratograph 
images can also be used to determine tear film lipid layer thickness. 
Comparison of two different image analysis methods using a generalized 
linear model showed that there was a high correlation between the two 
techniques [38]. The authors concluded that the simple technique was 
sufficient for evaluation of tear film lipid layer thickness. However, only 
28 subjects were included in the study. 
The use of fractal dimension estimation techniques was investigated 
for feature extraction from interferometer videos for diagnosis of DED 
[51]. The technique was found to be fast and had an area under the 
receiver operating characteristic curve (AUC) value of 0.786, compared 
to a value of 0.824 for an established method (See Appendix A.1 and 
Figure A.4a for a description of the receiver operating characteristic 
curve). Tear film lipid interferometer images were analysed using an 
SVM [49]. Extracted features from the images were passed to the SVM 
model, which classified the images as either healthy, aqueous-deficient 
DED, or evaporative DED. The agreement between the model and a 
trained ophthalmologist was high, with a reported Kappa value of 0.82. 
The model performed best when detecting aqueous-deficient DED. 
Ocular redness is an important indicator of dry eyes. Only one of the 
reviewed studies described an auto-mated system for evaluation of 
ocular redness associated with DED [63]. Slit-lamp images were ac­
quired from 26 subjects with a history of DED. Features representing the 
ocular redness intensity and horizontal vascular component were 
extracted with a Sobel operator. A multiple linear regression model was 
trained to predict ocular redness based on the extracted features. The 
system achieved an accuracy of 100%. The authors suggested that an 
objective system like this could replace subjective gradings by clinicians 
in multicentered clinical studies. 
The tear meniscus contains 75-90% of the aqueous tear volume [77]. 
Consequently, the tear meniscus height can be used as a quantitative 
indicator for DED caused by aqueous deficiency. When connected 
component labelling was applied to slit-lamp images, the Pearson’s 
correlation between the predicted meniscus heights and an established 
software methodology (ImageJ [78]) was high, ranging between 0.626 
and 0.847 [50]. The machine learning system was found to be more 
accurate than four experienced ophthalmologists. The tear meniscus 
height can also be estimated from keratography images using a CNN 
[31]. The automatic machine learning system achieved an accuracy of 
82.5% and was found to be more effective and consistent than a 
well-trained clinician working with limited time. 
Many of the studies apply SVM as their type of machine learning 
model without testing how other machine learning models perform. 
However, three of the studies tested several types of models and found 
that SVM did not perform the best [36,37,54]. It is difficult to compare 
the studies due to different applications and evaluation metrics. Despite 
promising results, most of the studies [36-38,50-52,54,57,61-63] did not 
evaluate their systems on external data. The systems should be tested on 
independent data before they can be considered for clinical application. 
Moreover, some studies were small [38,63] or pilots [31,50], and the 
suggested models should be tested on a larger number of subjects. 
4.4. In vivo confocal microscopy 
IVCM is a valuable non-invasive tool used to examine the corneal 
nerves and other features of the cornea [79]. IVCM images were used in 
a small study to assess characteristics of the corneal subbasal nerve 
plexus for diagnosis of DED [44]. Application of random forest and a 
deep neural network [45] gave promising results with an AUC value of 
0.828 for detecting DED [44]. IVCM images of corneal nerves can also be 
analysed by machine learning models to estimate the length of the nerve 
fiber [43]. Authors used a CNN with a U-net architecture that had been 
pre-trained on more than 5, 000 IVCM images of corneal nerves. The 
model showed that nerve fiber length was significantly longer after 
intense pulsed light treatment in MGD patients, which agreed with 
manual annotations from an experienced investigator with an AUC 
value of 0.96 and a sensitivity of 0.96. High-resolution IVCM images 
were also used to detect obstructive MGD [40]. Combinations of nine 
different CNNs were trained and tested on the images using 5-fold cross 
validation. Classification by the models was compared to diagnosis 
made by three eyelid specialists. The best performance was achieved 
when four different models were combined, with high sensitivity, 
specificity and AUC values, see Table 1. These promising results suggest 
that CNNs can be useful for detection and evaluation of MGD. Deep 
learning methods such as CNNs have the advantage that feature 
extraction from the images prior to analysis is not required as this is 
performed automatically by the model. 
IVCM images have been investigated for changes in immune cells 
across different severities of DED for diagnostic purposes [30]. A 
generalized linear model showed significant differences in dendritic cell 
density and morphology between DED patients and healthy individuals, 
but not between the different DED subgroups, see Table 1. While results 
using machine learning to interpret IVCM images are promising, larger 
clinical studies are needed to validate findings before clinical use can be 
considered. 
4.5. Meibography 
The meibomian glands are responsible for producing meibum, 
important for protecting the tear fluid from evaporation. Reduced 
Fig. 3. (a) Illustration of the three steps in the study selection process and number of studies (N) included in each step, and (b) the number of studies published over 
time, counting the studies included in this review. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
79
Table 1 
Overview of the reviewed studies using clinical investigations, part 1 of 2.  
Study 
Objective 
N 
Clinical Tests 
Type of Data 
Type of Algorithm 
Performance Score(s) 
Aggarwal S 
et al. (2021) 
[30] 
DED mechanism, 
effect of therapy 
199 
Subjective symptoms, Schirmer’s 
test with anasthesia, TBUT, vital 
staining of cornea and 
conjunctiva, laser IVCM images, 
subbasal layer of cornea: DC 
density and morphology 
Images of cornea 
GLM, MLR 
GLM: p-values < 0.05 for DC 
density and number of DCs, MLR: 
p-values < 0.05 between DC 
density and CFS, number of DCs 
and CFS, DC size and CFS, DC 
density and conjunctival staining, 
number of DCs and TBUT, 
corresponding beta-coefficients =
0.20, −0.23, 0.36, 0.24 and −0.18 
Deng X et al. 
(2021) [31] 
Estimate tear 
meniscus height 
217 
Oculus Keratograph 
Tear meniscus 
images 
CNN (U-net) 
Accuracy = 82.5%, sensitivity =
0.899, precision = 0.911, F1 score 
= 0.901 
Elsawy A et al. 
(2021) [32] 
Diagnose DED 
547 
AS-OCT 
Ocular surface 
images 
Pretrained CNN 
(VGG19) 
AUCROC = 0.99 (model 1) and 
0.98 (model 2), AUCPRC = 0.96 
(model 1) and 0.94 (model 2), F1 
score = 0.90 (model 1) and 0.86 
(model 2)* 
Khan ZK et al. 
(2021) [33] 
Detect MGD 
112 
Meibomian gland 3D IR-images, 
lower and upper eyelid 
Meibomian gland 
images 
GAN 
F1 score = 0.825, P-HD = 4.611, 
aggregated JI = 0.664, r = 0.962 
(clincian1) and 0.968 (clinician2), 
p-values < 0.001, mean difference 
= 0.96 (clincian1) and 0.95 
(clincian2) 
Xiao P et al. 
(2021) [34] 
Detect MGD 
15 
(images) 
Oculus Keratograph 
IR meibography 
images 
Prewitt operator, 
Graham scan algorithm, 
fragmentation algorithm 
and SA (used 
sequentially) 
Gland area: KI = 0.94, FPR =
6.02%, FNR = 6.43%. Gland 
segmentation: KI = 0.87, FPR =
4.35%, FNR = 18.61%* 
Yeh C-H et al. 
(2021) [35] 
Detect MGD 
706 
(images) 
Oculus Keratograph 
IR meibography 
images 
Nonparametric instance 
discrimination, 
pretrained CNN 
(ImageNet), hierarchical 
clustering 
Accuracy: meiboscore grading =
80.9%, 2-class classification =
85.2%, 3-class classification =
81.3%, 4-class classification =
80.8%* 
da Cruz LB 
et al. (2020) 
[36] 
Classify tear film 
patterns 
106 
(images) 
Doane interferometer 
Tear film lipid layer 
images 
SVM, RF, RT, Naive 
Bayes, DNN, simple NN 
RF: accuracy = 97.54%, SD =
0.51%, F1 score = 0.97, KI = 0.96, 
AUCROC = 0.99*** 
da Cruz LB 
et al. (2020) 
[37] 
Classify tear film 
patterns 
106 
(images) 
Doane interferometer 
Tear film lipid layer 
images 
SVM, RF, RT, Naive 
Bayes, DNN, simple NN 
RF: accuracy = 99.622%, SD =
0.843%, F1 score = 0.996, KI =
0.995, AUCROC = 0.999*** 
Fu P-I et al. 
(2020) [38] 
Compare 2 methods 
28 
Oculus Keratograph 
Tear film lipid layer 
images (with and 
without 
preprocessing) 
GLM 
beta-coefficients = 0.6, 10 
Fujimoto K 
et al. (2020) 
[39] 
Compare 2 methods 
195 
Pentacam vs AS-OCT 
CCT, TCT, thinnest 
point of cornea 
Multivariable regression 
Severe DED: beta-coefficients =
7.029 (CCT) and 6.958 (TCT), p- 
values = 0.002 (CCT) and 0.049 
(TCT), 95% CI = 2.528-11.530 
(CCT) and 0.037-13.879 (TCT) 
Maruoka S 
et al. (2020) 
[40] 
Detect MGD 
221 
IVCM 
Meibomian gland 
images 
Combinations of 9 CNNs 
Single CNN: AUROC = 0.966, 
sensitivity = 0.942, specificity =
0.821, ensemble CNNs: AUROC =
0.981, sensitivity = 0.921, 
specificity = 0.988 
Prabhu SM 
et al. (2020) 
[41] 
Quantify and detect 
MGD 
400 
(images) 
Oculus Keratograph, digital 
camera 
Meibomian gland 
images 
CNN (U-net) 
p-values > 0.005 between model 
output and clinical experts 
Stegmann H 
et al. (2020) 
[42] 
Detect tear 
meniscus in images 
10 
Optical coherence tomography 
Tear meniscus 
images 
2 CNNs 
Meniscus localization: JI =
0.7885, sensitivity = 0.9999, 
meniscus segmentation best CNN: 
accuracy = 0.9995, sensitivity =
0.9636, specificity = 0.9998, JI =
0.9324, F1 score = 0.9644, 
support = 0.0071*, *** 
Wei S et al. 
(2020) [43] 
DED mechanism, 
effect of therapy 
53 
Corneal IVCM with anesthesia 
Images of cornea 
Pretrained CNN (U-net) 
AUROC = 0.96, sensitivity = 96% 
Giannaccare G 
et al. (2019) 
[44] 
Subbasal nerve 
plexus 
characteristics for 
diagnosing DED 
69 
IVCM 
Images of subbasal 
nerve plexus 
Earlier developed 
method involving RF 
and NN[45,46] 
Nan 
Abbreviations: N = number of subjects; DED = dry eye disease; IVCM = in vivo confocal microscopy; DC = dendritic cell; GLM = generalized linear model; MLR =
multiple linear regression; CFS = corneal fluorescein score; AS-OCT = anterior segment optical coherence tomography; CNN = convolutional neural network; AUROC 
= area under reciever operating characteristic curve; AUPRC = area under precision-recall curve; MGD = meibomian gland dysfunction; GAN = generative adversarial 
network; P-HD = average Pompeiu-Hausdorff distance; JI = Jaccard index; KI = Kappa index; CTRL = healthy; FPR = false positive rate; FNR = false negative rate; 
SVM = support vector machine; RF = random forest; RT = random tree; DNN = deep neural network; SD = standard deviation; CCT = central corneal thickness; TCT =
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
80
secretion of meibum due to a reduced number of functional meibomian 
glands and/or obstruction of the ducts is a major cause of evaporative 
DED and MGD. Meibography is a common technique for diagnosing 
MGD [80]. Classification of meibomian glands using meibography is 
routine for experienced experts, but this is not the case for all clinicians. 
Moreover, automatic methods can be faster than human assessment. 
Meibography images may require several pre-processing steps before 
they can be classified. One study trained an SVM on extracted features 
from the images [64]. Pre-processing included the dilation, flood-fill, 
skeletonization and pruning algorithms. The model achieved a sensi­
tivity of 0.979 and specificity of 0.961. However, in contrast to all other 
image analysis methods, this method is not completely automatic as the 
images need to be manipulated manually before they are passed on to 
the system. 
A combination of Otsu’s method and the skeletonization and 
watershed algorithms was useful in auto-matically quantifying meibo­
mian glands [55]. This method was faster than an ophthalmologist and 
achieved a sensitivity and specificity of 0.993 and 0.975, respectively. 
Another automatic method applied B´ezier curve fitting as part of the 
analysis [53]. The reported sensitivity was 1.0, while the specificity was 
0.98. Xiao et al. sequentially applied a Prewitt operator, Graham scan, 
fragmentation and skeletonization algorithms for image analysis to 
quantify meibomian glands [34]. The agreement between the model 
results and two ophthalmologists was high with Kappa values larger 
than 0.8 and low false positive rates (< 0.06). The false negative rate 
was 0.19, suggesting that some glands were missed by the method. A 
considerable weakness of this study was that only 15 images were used 
for model development, and consequently it might not work well on 
unseen data. Another study automatically graded MGD severity using a 
Sobel operator, polynomial functions, fragmentation algorithm and 
Otsu’s method [47]. While the method was found to be faster, the results 
were significantly different from clinician assessments. 
Deep learning approaches were used by four studies evaluating 
meibomian gland features [33,35,41,48]. These systems are fully auto­
mated and apply some of the latest technologies within image analysis. 
Wang et al. used four different CNNs to determine meibomian gland 
atrophy [48]. The CNNs were trained to identify meibomian gland 
drop-out areas and estimate the percentage atrophy in a set of images. 
Comparison of model predictions with experienced clinicians indicated 
that the best CNN (ResNet50 architecture) was superior. Yeh et al. 
developed a method to evaluate meibomian gland atrophy by extracting 
features from meibography images with a special type of unsupervised 
CNN before application of a K-nearest neighbors model to allocate a 
meiboscore [35]. The system achieved an accuracy of 80.9%, out­
performing annotations by the clinical team. Moreover, hierarchical 
clustering of the extracted features from the CNN could show relation­
ships between meibography images. Another study used a CNN to 
automatically assess meibomian gland characteristics [41]. Images from 
two different devices collected from various hospitals were used to train 
and evaluate the CNN. This is an example of uncommonly good practice, 
as most medical AI systems are developed and evaluated on data from 
only one device and/or hospital. The only study to use a GAN archi­
tecture tested it on infrared 3D images of meibomian glands in order to 
evaluate MGD [33]. Comparing the model output with true labels, the 
performance scores were better than for state of the art segmentation 
methods. The Pearson correlations between the new automated method 
and two clinicians were 0.962 and 0.968. 
Four of the studies did not evaluate their proposed systems on 
external data [34,47,53,55]. Since the number of images used for model 
development was limited, the models can have overfit, and external 
evaluations should be performed to test how well the systems generalize 
to new data. 
4.6. Tear osmolarity 
Tear osmolarity is a measure of tear concentration, and high values 
can indicate dry eyes. Cartes et al. [67] investigated use of machine 
learning to detect DED based on this test. Four different machine 
learning models were compared. Noise was added to osmolarity mea­
surements during the training phase, while original data without noise 
was used for final evaluation. The logistic regression model achieved 
85% accuracy. However, since the models were trained and tested on the 
same data, the reported score is most likely not representative for how 
well the model generalizes to new data. 
4.7. Proteomic analysis 
Proteomic analysis describes the qualitative and quantitative 
composition of proteins present in a sample. Grus et al. compared tear 
proteins in individuals with diabetic DED, non-diabetic DED and healthy 
controls for discrimination between the groups [72]. The authors used 
discriminant analysis and principal component analysis combined with 
k-means clustering. Both models achieved low accuracies when pre­
dicting all three categories. However, classification into DED and 
non-DED achieved accuracies of 72% and 71% for discriminant analysis 
and k-means clustering, respectively. In another study by the same 
group, tear proteins analysed using deep learning discriminated subjects 
as healthy or having DED with an accuracy of 89% [71]. An accuracy of 
71% was achieved using discriminant analysis. A combination of 
discriminant analysis for detecting the most important proteins and a 
deep neural network for classification was also investigated [70]. High 
accuracy, sensitivity and specificity were reported. Discriminant anal­
ysis was also used by Gonzalez et al. in analysis of the tear proteome 
[69]. The most important proteins were selected to train an artificial 
neural network to classify tear samples as aqueous-deficient DED, MGD 
or healthy. The model gave an overall accuracy of 89.3%. Principal 
component analysis yielded good separation of healthy controls, 
aqueous-deficient DED and MGD data-points, indicating that the pro­
teins were good candidates for classification of the three conditions. This 
system achieved the highest accuracy of all the reviewed proteomic 
studies. Considered together, the results from the four studies [69-72] 
suggest that neural networks applied alone or together with other 
techniques perform better than discriminant analysis for detecting 
DED-related protein patterns in the tear proteome. 
Jung et al. used a network model based on modularity analysis to 
describe the tear proteome with respect to immunological and inflam­
matory responses related to DED [68]. In this study, patterns in tears and 
lacrimal fluid were investigated in patients with DED. Since only 10 
subjects were included, the study should be performed on a larger cohort 
of patients to verify the results. 
4.8. Optical coherence tomography 
Thickening of the corneal epithelium can be a sign of abnormalities 
in the cornea. Moreover, corneal thickness could potentially be a marker 
for DED. Kanellopoulos et al. developed a linear regression model to 
look for possible correlations between corneal thickness metrics 
measured using anterior segment optical coherence tomography (AS- 
OCT) and DED [58]. However, neither the model predictions nor per­
formance were reported, making it difficult to assess the usefulness of 
thinnest corneal thickness; r = Pearson’s correlation coefficient; Nan = not available; NN = neural network; RMSE = root mean squared error; CI = confidence interval; 
TBUT = fluorescein tear break-up time; PA = pruning algorithm; SA = skeletonization algorithm; FFA = Flood-fill algorithm; * = standard deviations not included in 
table; ** = 95% confidence intervals not included in table; *** = metrics are calculated as the average of 5 repetitions; **** = metrics are calculated as the average of 
10 repetitions; ***** = metrics are calculated as the average from 10-fold crossvalidation; § = metrics are calculated as the average from 6-fold crossvalidation; §§ =
metrics are calculated as the average of 100 models. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
81
Table 2 
Overview of the reviewed studies using clinical investigations, part 2 of 2.  
Study 
Objective 
N 
Clinical Tests 
Type of Data 
Type of Algorithm 
Performance Score(s) 
Llorens-Quintana 
C et al. (2019) 
[47] 
Evaluate 
meibomian 
gland atrophy 
149 
Oculus Keratograph 
Meibography 
images 
Sobel operator, polynomial 
function, fragmentation 
algorithm, Otsu’s method 
(used sequentially) 
p-values < 0.05 between automatic 
method and clinicians 
Wang J et al. 
(2019) [48] 
Evaluate 
meibomian 
gland atrophy 
706 
(images) 
Oculus Keratograph 
Meibography 
images 
4 CNNs 
Meiboscore grading: accuracy = 95.6%, 
eyelid detection: accuracy = 97.6%, JI =
0.955, atrophy detection: accuracy =
95.4%, JI = 0.667, RMSE = 0.067 
(average across 4 meiboscores) 
Yabusaki K 
(2019) [49] 
Diagnose DED 
138 
(images) 
Tear interferometer 
Tear film lipid 
layer images 
SVM 
KI = 0.820, CTRL: F1 score = 0.845, SD 
= 0.067, aqueous-deficient DED: F1 
score = 0.981, SD = 0.023, evaporative 
DED: F1 score = 0.815, SD = 0.095**** 
Yang J et al. 
(2019) [50] 
Estimate tear 
meniscus 
height for DED 
69 
Slit-lamp images with 
fluorescence staining 
Ocular surface 
images 
Connected component 
labelling 
Mean: p-value < 0.01 (×16 and ×40 
magnification), r = 0.626 (×16) and 
0.711 (×40), max: p-value < 0.001 (×16 
and ×40), r = 0.645 (×16) and 0.847 
(×40) 
Szyperski PD 
(2018) [51] 
Diagnose DED 
110 
Interferometry 
Videos from lateral 
shearing 
interferometry 
4 different fractal 
dimension estimators, 
linear regression 
Best estimator: AUROC = 0.786 
Hwang H et al. 
(2017) [52] 
Estimate tear 
film lipid layer 
thickness 
34 
Lipiscanner 1.0, slit-lamp 
microscope 
Tear film lipid 
layer videos 
Flood-fill algorithm, Canny 
edge detection 
p-value < 0.01 between all MGD groups 
Koprowski R et al. 
(2017) [53] 
Detect MGD 
57 
Oculus Keratograph 
Meibography 
images 
Riesz pyramid (?), Bezier 
curve (used sequentially) 
Accuracy = 99.08%, sensitivity = 1, 
specificity = 0.98 
Peteiro-Barral D 
et al. (2017) 
[54] 
Classify tear 
film patterns 
105 
(images) 
Tearscope plus images 
Tear film lipid 
layer images 
SVM, Decision tree, Naive 
Bayes, simple NN, Fisher¬
¥s linear discriminant 
NN: accuracy = 96%, sensitivity = 92%, 
specificity = 97%, precision = 92%, F1 
score = 0.93, AUCROC = 0.95 
Koprowski et al. 
(2016) [55] 
Detect MGD 
86 
Oculus Keratograph 
Meibography 
images 
Otsu’s method, SA, 
watershed algorithm (used 
sequentially) 
Sensitivity = 0.993, specificity = 0.975 
Remeseiro B et al. 
(2016) [56] 
Classify tear 
film patterns 
128 
(images) 
Tearscope-plus images 
Tear film lipid 
layer images 
SVM 
Accuracy = 96.09%, precision =
92.00%, sensitivity = 89.66%, 
specificity = 97.98%, F1 score =
91.23%, processing time = 0.07 s 
Remeseiro B et al. 
(2016) [57] 
Classify tear 
film patterns 
50 
(images) 
Tearscope-plus images 
Tear film lipid 
layer images 
SVM 
Accuracy = 90.89%, sensitivity =
83.54%, precision = 97.95%, specificity 
= 86.75% 
Kanellopoulos AJ 
et al. (2014) 
[58] 
Diagnose DED 
70 
Fourier-domain AS-OCT 
system: corneal and 
corneal epithelial 
thickness maps 
Corneal 
examination 
Linear regression 
(correlation between DED 
and thickness) 
Nan 
Ramos L et al. 
(2014) [59] 
Estimate TBUT 
18 
(videos) 
Videos from TBUT (slit- 
lamp) 
TBUT videos 
Polynomial function 
Specificity = 89% (parameter b) and 
82% (parameter e), specificity = 84% 
and 80% 
Ramos L et al. 
(2014) [60] 
Estimate TBUT 
18 
(videos) 
Videos from TBUT (slit- 
lamp) 
TBUT videos 
Polynomial function 
Accuracy = ""more than 90%"" 
Remeseiro et al. 
(2014) [61] 
Classify tear 
film patterns 
511 
(images) 
Tearscope-plus images 
Tear film lipid 
layer images 
Markov random field, SVM 
(used sequentially) 
Accuracy = 97.14%, accuracy (noisy 
data) = 92.61%***** 
García-Resúa C 
et al. (2013) 
[62] 
Classify tear 
film patterns 
105 
Tearscope-plus images 
Tear film lipid 
layer images 
K-nearest neighbors 
Cram´er’s V = 0.9, r = 0.94, p-value <
0.001, accuracy = 86.2% §
Rodriquez JD 
(2013) [63] 
Evaluate ocular 
redness 
26 
Slit-lamp, digital camera 
Images of 
conjunctiva 
Sobel operator, MLR (used 
sequentially) 
Accuracy = 100%, r = 0.76, concordance 
correlation = 0.76 (compared to 5 
investigators)* 
Koh YW et al. 
(2012) [64] 
Detect MGD 
55 
Slit-lamp biomicroscope, 
upper eye lid 
IR meibography 
images 
PA, SA, FFA, SVM (used 
sequentially) 
Specificity = 96.1%, SD = 0.4%, 
sensitivity = 97.9%, SD = 0.6% §§
Yedidya T et al. 
(2009) [65] 
Estimate TBUT 
22 
(videos) 
Video from TBUT 
TBUT videos 
Markov random field 
Mean difference in TBUT = 2.34s 
Yedidya T et al. 
(2007) [13] 
Detect dry 
areas 
8 
(videos) 
Video from TBUT 
TBUT videos 
Levenberg-Marquardt 
Accuracy = 91% (84-96%), SD = 4% 
Mathers WD et al. 
(2004) [66] 
Investigate DED 
513 
Schirmer’s test, 
meibomian gland drop- 
out, lipid viscosity and 
volume, tear evaporation 
Clinical test results 
Hierarchical clustering, 
decision tree 
Nan 
Abbreviations: N = number of subjects; DED = dry eye disease; IVCM = in vivo confocal microscopy; DC = dendritic cell; GLM = generalized linear model; MLR =
multiple linear regression; CFS = corneal fluorescein score; AS-OCT = anterior segment optical coherence tomography; CNN = convolutional neural network; AUROC 
= area under reciever operating characteristic curve; AUPRC = area under precision-recall curve; MGD = meibomian gland dysfunction; GAN = generative adversarial 
network; P-HD = average Pompeiu-Hausdorff distance; JI = Jaccard index; KI = Kappa index; CTRL = healthy; FPR = false positive rate; FNR = false negative rate; 
SVM = support vector machine; RF = random forest; RT = random tree; DNN = deep neural network; SD = standard deviation; CCT = central corneal thickness; TCT =
thinnest corneal thickness; r = Pearson’s correlation coefficient; Nan = not available; NN = neural network; RMSE = root mean squared error; CI = confidence interval; 
TBUT = fluorescein tear break-up time; PA = pruning algorithm; SA = skeletonization algorithm; FFA = Flood-fill algorithm; * = standard deviations not included in 
table; ** = 95% confidence intervals not included in table; *** = metrics are calculated as the average of 5 repetitions; **** = metrics are calculated as the average of 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
82
the study. The type of instrument used to determine the corneal thick­
ness was found to affect the results [39]. Measurements from AS-OCT 
and Pentacam were compared and multivariable regression was used 
to detect differences between the two techniques regarding the 
measured central corneal thickness and the thinnest corneal thickness. 
Individuals with mild DED, severe DED and healthy subjects were 
examined. The two techniques gave significantly different results in 
terms of the resulting β-coefficients in the multivariable regression 
model for individuals with severe DED. Images from clinical examina­
tions with AS-OCT were used to diagnose DED [32]. A pretrained VGG19 
CNN [81] was fine-tuned using separate images for training and vali­
dation. Two similar CNN models were developed, and evaluation was 
performed on an external test set. Both achieved impressively high 
performance scores. The AUC values were 0.99 and 0.98. This is one out 
of two studies in this review that used an independent test sets after 
model development. Such practice is essential for a realistic impression 
of how well the model generalizes to new data not used during model 
development. The good performance is likely linked to the large 
amounts of training data (29, 000 images), which is essential for deep 
learning methods. Most of the re-viewed studies use significantly smaller 
data sets, which constitutes a disadvantage. Stegmann et al. analysed 
OCT images from healthy subjects for automatic detection of the lower 
tear meniscus [42]. Two different CNNs were trained and evaluated 
using 5-fold cross validation. The tear menisci detected by the models 
were compared to evaluations from an experienced grader. The best 
CNN achieved an average accuracy of 99.95%, sensitivity of 0.9636 and 
specificity of 0.9998. The system is promising regarding fast and accu­
rate segmentation of OCT images. However, more images from different 
OCT systems, including non-healthy subjects, should be used to verify 
and improve the analysis. 
The two studies [42,81] showed that CNNs could be an appropriate 
tool for image analysis. CNNs are likely to increase in popularity within 
10 repetitions; ***** = metrics are calculated as the average from 10-fold crossvalidation; § = metrics are calculated as the average from 6-fold crossvalidation; §§ =
metrics are calculated as the average of 100 models. 
Table 3 
Overview of the reviewed studies using biochemical investigations.  
Study 
Objective 
N 
Clinical Tests 
Type of Data 
Type of Algorithm 
Performance Score(s) 
Cartes C 
et al. 
(2019) 
[67] 
Diagnose DED 
40 
Tear-Lab Osmometer 
Tear osmolarity 
measurements 
LR, Naive Bayes, SVM, RF 
LR: accuracy = 85% 
Jung JH 
et al. 
(2017) 
[68] 
Detect 
protein 
patterns in 
DED 
10 
Pooled tear and lacrimal fluid, 
analysed with LC-MS, trypsin 
digestion, RP-LC fractionation 
Proteins in tears 
and lacrimal fluid 
""Network model"" based on 
betweenness centrality 
Nan 
Gonzalez N 
(2014) [69 
Diagnose DED 
93 
Peptide/protein analysis: gel 
electrophoresis (SDS-PAGE) 
Peptides and 
proteins in tears 
Discriminant analysis, 
principal component analysis, 
NN 
Accuracy = 89.3%, CTRL: sensitivity = 0.99, 
specificity = 0.96, MGD: sensitivity = 0.85, 
specificity = 0.96, aqueous-deficient DED: 
sensitivity = 0.83, specificity = 0.93* 
Grus FH 
et al. 
(2005) 
[70] 
Diagnose DED 
159 
Schirmer’s test with 
anesthesia, tears analysed by 
LC-MS 
Proteins in tears 
Discriminant analysis, DNN 
(used sequentially) 
AUROC = 0.93, sensitivity and specificity =
‘‘approx. 90% each’’ 
Grus FH 
et al. 
(1999) 
[71] 
Diagnose DED 
60 
Protein analysis: gel 
electrophoresis (SDS-PAGE) 
Proteins in tears 
DNN, discriminant analysis 
DNN: accuracy = 89%, discriminant analysis: 
accuracy = 71% 
Grus FH 
et al. 
(1998) 
[72] 
Diagnose DED 
119 
Protein analysis: gel 
electrophoresis (SDS-PAGE) 
Proteins in tears 
Principal component analysis, 
K-means clustering (used 
sequentially), discriminant 
analysis 
K-means: accuracy = 71% (DED vs CTRL) and 
42% (DED, diabetes-DED, CTRL), 
discriminant analysis: accuracy = 72% (DED 
vs CTRL) and 43% (DED, diabetes-DED, CTRL) 
Abbreviations: N = number of subjects; DED = dry eye disease; LR = logistic regression; SVM = support vector machine; RF = random forest; AUROC = area under 
reciever operating characteristic curve; MGD = meibomian gland dysfunction; CTRL = healthy; DNN = deep neural network; Nan = not available; NN = neural 
network; LC-MS = liquid chromatography mass spectometry; RP-LC = reverse-phase liquid chromatography; SDS-PAGE = sodium dodecyl sulphate-polyacrylamide 
gel electrophoresis; OSDI = ocular surface disease index; * = metrics are calculated as the average of 10 repetitions. 
Table 4 
Overview of the reviewed studies using demographical investigations.  
Study 
Objective 
N 
Clinical Tests 
Type of Data 
Type of Algorithm 
Performance Score(s) 
Choi HR 
et al. 
(2020) 
[73] 
Investigate DED and 
dyslipidemia 
association 
2272 
OSDI score, health 
examination, 
questionnaire 
Population studies, Korea 
GLM, LR 
Nan 
Nam SM 
et al. 
(2020) 
[74] 
Detect risk factors for 
DED 
4391 
Health examination, 
health survey, nutrition 
survey 
National health survey, Korea 
Decision tree, Lasso, 
LR (used sequentially) 
AUROC = 0.70, 95% CI = 0.61- 
0.78, specificity = 68%, 
sensitivity = 66% 
Kaido M 
et al. 
(2015) 
[75] 
Diagnose DED 
369 
Blink frequency, visual 
maintenance ratio, 
questionnaire 
Functional VA measurement and 
questionnaire, Japanese visual 
display terminal workers 
Discriminant analysis 
Sensitivity = 93.1%, 
specificity = 43.7%, precision 
= 83.8%, NPV = 80.8% 
Abbreviations: N = number of subjects; DED = dry eye disease; GLM = generalized linear model; AUROC = area under reciever operating characteristic curve; Nan =
not available; CI = confidence interval; LR = logistic regression; OSDI = ocular surface disease index; VA = visual acuity; NPV = negative predictive value. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
83
the field of DED due to promising results for solving image related tasks, 
including feature extraction. 
4.9. Other clinical tests 
Machine learning models were used to analyse results from a variety 
of clinical tests to expand understanding of the DED process [66]. The 
study included subjects with DED and healthy subjects. Subjective cutoff 
values from clinical tests were used to assign subjects to the DED class. 
Hierarchical clustering and a decision tree were applied sequentially to 
group the subjects based on their clinical test results. The resulting 
groups were compared to the original groups. Because the analysis was 
based on objective measurements, it could be used to develop more 
objective diagnostic criteria. This could lead to earlier detection and 
more effective treatment of DED. 
Table 5 
Overview of the data applied for the analyses.  
Study 
Type of 
Input 
Data 
Training 
Dataset 
Testing 
Dataset 
Reference Standard 
Clinical Investigations 
Aggarwal S et al. 
(2021) [30] 
Tabular 
349 
Nan 
Nan (clinical test 
results, subjective 
report) 
Deng X et al. 
(2021) [31] 
Images 
253 
(images) 
232 
(images) 
Senior clinician 
Elsawy A et al. 
(2021) [32 
Images 
29172 
(train), 
7293 (val) 
23760 
Certified cornea 
specialist 
Khan ZK et al. 
(2021) [33] 
Images 
90 
22 
Clinician 
Xiao P et al. 
(2021) [34] 
Images 
15 
Nan 
2 ophthalmologists 
Yeh C-H et al. 
(2021) [35] 
Images 
398 
(train), 99 
(val) 
209 
Trained clinician 
da Cruz LB et al. 
(2020) [36] 
Tabular 
106 (10- 
fold CV) 
Nan 
Optometrist 
da Cruz LB et al. 
(2020) [37] 
Tabular 
106 (10- 
fold CV) 
Nan 
Optometrist 
Fu P-I et al. 
(2020) [38] 
Tabular 
28 
Nan 
Nan (clinical test 
results, subjective 
report) 
Fujimoto K et al. 
(2020) [39] 
Tabular 
195 
Nan 
Nan (kerato- 
conjunctival staining 
for ac{DED}) 
Maruoka S et al. 
(2020) [40] 
Images 
221 (5- 
fold CV) 
Nan 
3 eyelid specialists 
Prabhu SM et al. 
(2020) [41] 
Images 
600 
200 
Clinical experts 
Stegmann H 
et al. (2020) 
[42] 
Images 
6658 
(images) 
(5-fold 
CV) 
Nan 
Experienced 
investigator 
Wei S et al. 
(2020) [43] 
Images 
5000* 
53 (3-5 
per 
patient) 
Experienced 
investigator 
Giannaccare G 
et al. (2019) 
[44] 
Tabular 
Nan 
69 
Experienced 
investigator ~ cite 
{Chen2017ACCMed} 
Llorens- 
Quintana C 
et al. (2019) 
[47] 
Images 
149 
Nan 
Clinicians 
Wang J et al. 
(2019) [48] 
Images 
398 
(train) 99 
(val) 
209 
Experienced clinician 
Yabusaki K 
(2019) [49] 
Tabular 
93** 
45** 
Skilled 
ophthalmologist 
Yang J et al. 
(2019) [50] 
Images 
520 
Nan 
ImageJ software 
Szyperski PD 
(2018) [51] 
Tabular 
110 
Nan 
Nan 
Hwang H et al. 
(2017) [52] 
Frames 
34 
Nan 
Meibomian gland 
expert 
Koprowski R 
et al. (2017) 
[53] 
Images 
228 
(images) 
Nan 
Specialized clinicians 
Peteiro-Barral D 
et al. (2017) 
[54] 
Tabular 
105 (LOO 
CV) 
Nan 
Experts 
Koprowski et al. 
(2016) [55]  
Images 
172 
(images) 
Nan 
Ophthalmology expert 
Remeseiro B 
et al. (2016) 
[56] 
Tabular 
Nan 
128 
Optometrists 
Remeseiro B 
et al. (2016) 
[57] 
Tabular 
Sampled 
from test 
set 
50 
4 optometrists 
Tabular 
140 
Nan 
Ophthalmologist  
Table 5 (continued) 
Study 
Type of 
Input 
Data 
Training 
Dataset 
Testing 
Dataset 
Reference Standard 
Kanellopoulos 
AJ et al. 
(2014) [58] 
Ramos L et al. 
(2014) [59] 
Videos 
18 
Nan 
2/4 experts 
Ramos L et al. 
(2014) [60] 
Videos 
12 
6 
4 experts 
Remeseiro et al. 
(2014) [61] 
Tabular 
511 (10- 
fold CV) 
Nan 
Experts 
García-Resúa C 
et al. (2013) 
[62] 
Tabular 
105 (6- 
fold CV) 
Nan 
Experienced 
investigator 
Rodriquez JD 
(2013) [63] 
Tabular 
99 
(images) 
Nan 
5 trained investigators 
Koh YW et al. 
(2012) [64] 
Tabular 
28*** 
27*** 
Experts 
Yedidya T et al. 
(2009) [65] 
Videos 
22 
Nan 
Clinician 
Yedidya T et al. 
(2007) [13] 
Frames 
8**** 
Nan 
Optometrist (evaluated 
3 of the 8 patients) 
Mathers WD 
et al. (2004) 
[66] 
Tabular 
513 (10- 
fold CV) 
Nan 
Nan (clinical test 
results) 
Biochemical Investigations 
Cartes C et al. 
(2019) [67] 
Tabular 
40 (noise 
added) 
40 (no 
noise) 
Nan (clinical test 
results, subjective 
report) 
Jung JH et al. 
(2017) [68] 
Tabular 
10 
Nan 
Ophthalmologist 
Gonzalez N 
(2014) [69] 
Tabular 
70% of 
93** 
30% of 
93** 
Nan (clinical tests) 
Grus FH et al. 
(2005) [70] 
Tabular 
50% of 
159 
50% of 
159 
Nan (clinical test 
results, subjective 
report) 
Grus FH et al. 
(1999) [71] 
Tabular 
30 
30 
Nan (clinical test 
results, subjective 
report) 
Grus FH et al. 
(1998) [72] 
Tabular 
119 
§
Nan (clinical test 
results, subjective 
report) 
Demographical Investigations 
Choi HR et al. 
(2020) [73] 
Tabular 
2272 
Nan 
Nan (subjective report) 
Nam SM et al. 
(2020) [74] 
Tabular 
80% of 
4391 
20% of 
4391 
Ophthalmologist 
Kaido M et al. 
(2015) [75] 
Tabular 
369 
Nan 
Dry eye specialists 
Abbreviations: Nan = not available; val = validation; CV = crossvalidation; DED 
= dry eye disease; LOO = leave one out; * = pretraining images; ** = randomly 
selected samples, process repeated 10 times; *** = randomly selected samples, 
process repeated 100 times; **** = 3-5 sequences of video per patient; § = For 
multivariate analysis model, but the number of samples was not mentioned. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
84
4.10. Population surveys 
Population surveys can provide valuable insight regarding the 
prevalence of DED and help detect risk factors for developing the dis­
ease. Japanese visual terminal display workers were surveyed with the 
objective of detecting DED [75]. Dry eye exam data and subjective re­
ports were used for diagnosis. This was passed to a discriminant analysis 
model. When compared to diagnosis by a dry eye specialist, the model 
showed a high sensitivity of 0.931, but low specificity of 0.437. This is a 
very low specificity, but is not necessarily bad if the aim is to detect as 
many cases of DED as possible and there is less concern about misclas­
sification of healthy individuals. Data from a national health survey 
were analysed in order to detect risk factors for DED [74]. Here, in­
dividuals were regarded as having DED if they had been diagnosed by an 
ophthalmologist, and were experiencing dryness. Feature modifications 
were performed by a decision tree, and the most important features were 
selected using lasso. β-coefficients from a logistic regression trained on 
the most important features were used to rank the features. Women, 
individuals who had received refractive surgery and those with 
depression were detected as having the highest risk for developing DED. 
Even though the models in the study were trained on data from more 
than 3500 participants, the reported performance scores were among 
the poorest in this review with a sensitivity of 0.66 and a specificity of 
0.68. A possible reason could be that the selected features were not ideal 
for detecting DED. However, the detected risk factors have previously 
been shown to be associated with DED [3,82,83]. The findings suggest 
that the data quality from population surveys might not be as high as in 
other types of studies, which could lead to misinterpretation by the 
machine learning model. 
The association between DED and dyslipidemia was investigated by 
combining data from two population surveys in Korea in Ref. [73]. A 
generalized linear model was used to investigate linear characteristics 
between features and the severity of DED. The model showed significant 
increase in age, blood pressure and prevalence of hypercholesterolemia 
over the range from no DED to severe DED. Evaluation of the association 
between dyslipidemia and DED using linear regression showed that the 
odds ratio for men with dyslipidemia was higher than 1 compared to 
men without dyslipidemia. This association was not found in women. 
The study results suggest a positive association between DED and dys­
lipidemia in men, but not in women. 
4.11. Future perspectives 
In order to benchmark existing and future models, we advocate that 
the field of DED should have a common, centralized and openly avail­
able data set for testing and evaluation. The data should be fully 
representative for the relevant clinical tests. In order to ensure that 
models are applicable to all populations of patients, medical institutions, 
and types of equipment around the world, they must be evaluated on 
data from different demographic groups of patients across several clinics 
and, if relevant, from different medical devices. Moreover, the test data 
set should not be available for model development, but only for final 
evaluation. A common standard on these processes will increase the 
reproducibility and comparability of studies. Standardized collection 
and handling of clinical data and samples would also facilitate com­
parisons between different instruments and clinics [84]. In addition, a 
cross hospitals/centers data set would solve important challenges of 
applying AI in clinical practice, such as metrics not reflecting clinical 
applicability, difficulties in comparing algorithms, and under­
specification. These have all been identified as being among the main 
obstacles for adoption of any medical AI system in clinical practice [85, 
86]. 
A possible challenge regarding implementation in the clinic is that 
hospitals do not necessarily use the same data platforms, which might 
prevent widespread use of machine learning systems. Consequently, 
solutions for implementing digital applications across hospitals should 
be considered. 
Model explanations are important in order to understand why a 
complex machine learning model produces a certain prediction. For 
healthcare providers to trust the systems and decide to use them in the 
clinic, the systems should provide understandable and sound explana­
tions of the decision-making process. Moreover, they could assist clini­
cians when making medical decisions [18]. When developing new 
machine learning systems within DED, effort should be made to present 
the workings of the resulting models and their predictions in an easy to 
interpret fashion. 
5. Conclusions 
We observed a large variation in the type of clinical tests and the type 
of data used in the reviewed studies. This is also true regarding the 
extent of pre-processing applied to the data before passing it to the 
machine learning models. The studies analysing images can be divided 
into those applying deep learning techniques directly on the images, and 
those performing extensive pre-processing and feature extraction before 
the data is passed to the machine learning model in a tabular format. The 
number of studies belonging to the first group has increased significantly 
over the past 3 years. As deep learning techniques become more estab­
lished, these will probably replace more traditional image pre- 
processing and feature extraction techniques. 
We noted that there was a lack of consensus regarding how best to 
perform model development, including evaluation. This made it difficult 
to estimate how well some models will perform in the clinic and with 
new patients, and also to compare the different models. Comparison was 
further complicated by the use of different types of performance scores. 
In addition there was no culture of data and code sharing, which makes 
reproducibility of the results impossible. For the future, focus should be 
put on establishing data and code sharing as a standard procedure. 
In conclusion, the results from the different studies’ machine 
learning models are promising, although much work is still needed on 
model development, clinical testing and standardisation. AI has a high 
potential for use in many different applications related to DED, 
including automatic detection and classification of DED, investigation of 
the etiology and risk factors for DED, and in the detection of potential 
biomarkers. Effort should be made to create common guidelines for the 
model development process, especially regarding model evaluation. 
Prospective testing is recommended in order to evaluate whether pro­
posed models can improve the diagnostics of DED, and the health and 
quality of life of patients with DED. 
Declaration of competing interest 
The authors report no conflicts of interest. 
Appendix A. Supplementary data 
Supplementary data to this article can be found online at https://doi. 
org/10.1016/j.jtos.2021.11.004. 
References 
[1] Stapleton F, Alves M, Bunya VY, Jalbert I, Lekhanont K, Malet F, Na K-S, 
Schaumberg D, Uchino M, Vehof J, et al. TFOS DEWS II epidemiology report. Ocul 
Surf 2017;15(3):334–65. https://doi.org/10.1016/j.jtos.2017.05.003. 
[2] Geerling G, Tauber J, Baudouin C, Goto E, Matsumoto Y, O’Brien T, Rolando M, 
Tsubota K, Nichols KK. The international workshop on meibomian gland 
dysfunction: report of the subcommittee on management and treatment of 
meibomian gland dysfunction. Investig Ophthalmol Vis Sci 2011;52(4):2050–64. 
https://doi.org/10.1167/iovs.10-6997g. 
[3] Matossian C, McDonald M, Donaldson KE, Nichols KK, MacIver S, Gupta PK. Dry 
eye disease: consideration for women’s health. J Wom Health 2019;28(4):502–14. 
dx.d oi.org/10.1089/jwh.2018.7041. 
[4] Nichols JJ, Ziegler C, Mitchell GL, Nichols KK. Self-reported dry eye disease across 
refractive modalities. Investig Ophthalmol Vis Sci 2005;46(6):1911–4. https://doi. 
org/10.1167/iovs.04-1294. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
85
[5] Zhang X, Zhao L, Deng S, Sun X, Wang N. Dry eye syndrome in patients with 
diabetes mellitus: prevalence, etiology, and clinical characteristics. J Ophthalmol 
2016. https://doi.org/10.1155/2016/8201053. 2016. 
[6] Mandell JT, Idarraga M, Kumar N, Galor A. Impact of air pollution and weather on 
dry eye. J Clin Med 2020;9(11). https://doi.org/10.3390/jcm9113740. 
https://www.mdpi.com/2077-0383/9/11/3740. 
[7] Willcox MD, Argüeso P, Georgiev GA, Holopainen JM, Laurie GW, Millar TJ, 
Papas EB, Rolland JP, Schmidt TA, Stahl U, et al. TFOS DEWS II tear film report. 
Ocul Surf 2017;15(3):366–403. https://doi.org/10.1016/j.jtos.2017.03.006. 
[8] McCarthy J, Minsky ML, Rochester N, Shannon CE. A proposal for the Dartmouth 
summer research project on Artificial Intelligence, august 31, 1955. AI Mag 2006; 
27(4). https://doi.org/10.1609/aimag.v27i4.1904. 12-12. 
[9] Legg S, Hutter M. Universal intelligence: a definition of machine intelligence. 
Minds Mach 2007;17(4):391–444. https://doi.org/10.1007/s11023-007-9079-x. 
[10] Schmidt-Erfurth U, Sadeghipour A, Gerendas BS, Waldstein SM, Bogunovi´c H. 
Artificial Intelli- gence in retina. Prog Retin Eye Res 2018;67:1–29. https://doi. 
org/10.1016/j.preteyeres.2018.07.004. 
[11] De Fauw J, Ledsam JR, Romera-Paredes B, Nikolov S, Tomasev N, Blackwell S, 
Askham H, Glorot X, O’Donoghue B, Visentin D, et al. Clinically applicable deep 
learning for diagnosis and referral in retinal disease. Nat Med 2018;24(9):1342–50. 
https://doi.org/10.1038/s41591-018-0107-6. 
[12] Cię˙zar K, Pochylski M. 2D fourier transform for global analysis and classification of 
meibomian gland images. Ocul Surf 2020;18(4):865–70. https://doi.org/10.1016/ 
j.jtos.2020.09.005. https://www.sciencedirect.com/science/article/pii/S1542012 
420301452. 
[13] Yedidya T, Hartley R, Guillon J-P, Kanagasingam Y. Automatic dry eye detection. 
In: International conference on medical image computing and computer-assisted 
intervention. Springer; 2007. p. 792–9. https://doi.org/10.1007/978-3-540- 
75757-3_96. 
[14] Nielsen KB, Lautrup ML, Andersen JK, Savarimuthu TR, Grauslund J. Deep 
learning-based algorithms in screening of diabetic retinopathy: a systematic review 
of diagnostic performance. Ophthalmol Retina 2019;3(4):294–304. https://doi. 
org/10.1016/j.oret.2018.10.014. 
[15] Pead E, Megaw R, Cameron J, Fleming A, Dhillon B, Trucco E, MacGillivray T. 
Automated detection of age-related macular degeneration in color fundus 
photography: a systematic review. Surv Ophthalmol 2019;64(4):498–511. https:// 
doi.org/10.1016/j.survophthal.2019.02.003. https://www.sciencedirect.com/sci 
ence/article/pii/S0039625718302078. 
[16] Gensure RH, Chiang MF, Campbell JP. Artificial Intelligence for retinopathy of 
prematurity. Curr Opin Ophthalmol 2020;31(5):312–7. https://doi.org/10.1097/ 
ICU.0 000000000000680. 
[17] Esteva A, Kuprel B, Novoa RA, Ko J, Swetter SM, Blau HM, Thrun S. Dermatologist- 
level classification of skin cancer with deep neural networks. Nature (London) 
2017;542:115–8. https://doi.org/10.1038/nature21056. 
[18] Lundberg SM, Nair B, Vavilala MS, Horibe M, Eisses MJ, Adams T, Liston DE, 
Low DK-W, Newman S-F, Kim J, Lee S-I. Explainable machine-learning predictions 
for the prevention of hypoxaemia during surgery. Nat Biomed Eng 2018;2:749–60. 
https://doi.org/10.1038/s41551-018-0304-0. 
[19] Gulshan V, Peng L, Coram M, Stumpe MC, Wu D, Narayanaswamy A, 
Venugopalan S, Widner K, Madams T, Cuadros J, Kim R, Raman R, Nelson PC, 
Mega JL, Webster DR. Development and validation of a deep learning algorithm for 
detection of diabetic retinopathy in retinal fundus pho- tographs. J Am Med Assoc 
2016;316(22):2402–10. https://doi.org/10.1001/jama.2016.17216. 
[20] Yousefi S, Takahashi H, Hayashi T, Tampo H, Inoda S, Arai Y, Tabuchi H, Asbell P. 
Predicting the likelihood of need for future keratoplasty intervention using 
artificial intelligence. Ocul Surf 2020;18(2):320–5. https://doi.org/10.1016/j. 
jtos.2020.02.008. https://www.sciencedirect.com/science/article/pii/S1542012 
420300276. 
[21] Hastie T, Tibshirani R, Friedman J. The elements of statistical learning: data 
mining, inference, and prediction. Springer Science & Business Media; 2009. 
https://doi.org/10.1111/j.1467-985X. 2010.00646_6.x. 
[22] Palacio-Ni˜no J-O, Berzal F. Evaluation metrics for unsupervised learning 
algorithms. 2019, 05667. arXiv: 1905. 
[23] Le Berre C, Sandborn WJ, Aridhi S, Devignes M-D, Fournier L, Smaïl-Tabbone M, 
Danese S, Peyrin-Biroulet L. Application of artificial intelligence to 
gastroenterology and hepatology. Gastroenterology 2020;158(1):76–94. https:// 
doi.org/10.1053/j.gastro.2019.08.058. 
[24] Thrall JH, Li X, Li Q, Cruz C, Do S, Dreyer K, Brink J. Artificial intelligence and 
machine learning in radiology: opportunities, challenges, pitfalls, and criteria for 
success. J Am Coll Radiol 2018;15(3):504–8. https://doi.org/10.1016/j. 
jacr.2017.12.026. 
[25] Thambawita VL, Strümke I, Hicks S, Riegler MA, Halvorsen P, Parasa S. Data 
augmentation using generative adversarial networks for creating realistic artificial 
colon polyp images: validation study by endoscopists. Gastrointest Endosc 2021;93 
(6):AB190. 
[26] Gianfrancesco MA, Tamang S, Yazdany J, Schmajuk G. Potential biases in machine 
learning al- gorithms using electronic health record data. JAMA Int Med 2018;178 
(11):1544–7. https://10.1001/jamainternmed.2018.3763. 
[27] G´eron A. Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: 
concepts, tools, and techniques to build intelligent systems. O’Reilly Media; 2019. 
[28] European Commission. Proposal for a regulation laying down harmonised rules on 
Artificial Intelligence. 4, https://digital-strategy.ec.europa.eu/en/library/propo 
sal-regulation-laying-down-harmonised-rules-artificial-intelligence; 2021. 
[29] U.S. Food & Drug Administration. Artificial intelligence and machine learning (AI/ 
ML) software as a medical device (SaMD) action plan. 2021. 1, https://www.fda. 
gov/medical-devices/software-medical-device-samd/artificial-intelligence-and 
-machine-learning-software-medical-device. 
[30] Aggarwal S, Kheirkhah A, Cavalcanti BM, Cruzat A, Jamali A, Hamrah P. 
Correlation of corneal immune cell changes with clinical severity in dry eye 
disease: an in vivo confocal microscopy study. Ocul Surf 2021;19:183–9. https:// 
doi.org/10.1016/j.jtos.2020.05.012. https://www.sciencedirect.com/science/ 
article/pii/S1542012420300963. 
[31] Deng X, Tian L, Liu Z, Zhou Y, Jie Y. A deep learning approach for the 
quantification of lower tear meniscus height. Biomed Signal Process Control 2021; 
68:102655. https://doi.org/10.1016/j.bspc.2021.102655. https://www.sciencedi 
rect.com/science/article/pii/S1746809421002524. 
[32] Elsawy A, Eleiwa T, Chase C, Ozcan E, Tolba M, Feuer W, Abdel-Mottaleb M, Abou 
Shousha M. Multidisease deep learning neural network for the diagnosis of corneal 
diseases. Am J Ophthalmol 2021;226:252–61. https://doi.org/10.1016/j. 
ajo.2021.01.018. https://www.sciencedirect.com/science/article/pii/S0002939 
421000398. 
[33] Khan ZK, Umar AI, Shirazi SH, Rasheed A, Qadir A, Gul S. Image based analysis of 
meibomian gland dysfunction using conditional generative adversarial neural 
network. BMJ Open Ophthalmol 2021;6(1). https://doi.org/10.1136/bmjophth- 
2020-000436. arXiv:https://bmjophth.bmj.com/content/6/1/e000436.full.pdf, 
https://bmjophth.bmj.com/content/6/1/e000436. 
[34] Xiao P, Luo Z, Deng Y, Wang G, Yuan J. An automated and multiparametric 
algorithm for objective analysis of meibography images. Quant Imag Med Surg 
2021;11(4):1586–99. https://doi.org/10.21037/qims-20-611. 
[35] Yeh C-H, Yu SX, Lin MC. Meibography phenotyping and classification from 
unsupervised discrim- inative feature learning. Transl Vis Sci Technol 2021;10(2). 
https://doi.org/10.1167/tvst.10.2.4. 4-4. arXiv:arvojournals.org/arvo/content 
\_public/journal/tvst/938516/i2164-2591-10-2-4\_16125 19083.80616.pdf. 
[36] da Cruz LB, Souza JC, de Sousa JA, Santos AM, de Paiva AC, de Almeida JDS, 
Silva AC, Junior GB, Gattass M. Interferometer eye image classification for dry eye 
categorization using phylogenetic diversity indexes for texture analysis. Comput 
Methods Progr Biomed 2020;188:105269. https://doi.org/10.1016/j. 
cmpb.2019.105269. https://www.sciencedirect.com/science/article/pii/S0 
169260719310995. 
[37] da Cruz LB, Souza JC, de Paiva AC, de Almeida JDS, Junior GB, Aires KRT, 
Silva AC, Gattass M. Tear film classification in interferometry eye images using 
phylogenetic diversity indexes and ripley’s k function. IEE J Biomed Health Inf 
2020;24(12):3491–8. https://doi.org/10.1109/JBHI.2020.3026940. 
[38] Fu P-I, Fang P-C, Ho R-W, Chao T-L, Cho W-H, Lai H-Y, Hsiao Y-T, Kuo M-T. 
Determina- tion of tear lipid film thickness based on a reflected placido disk tear 
film analyzer. Diagnostics 2020;10(6). https://doi.org/10.3390/ 
diagnostics10060353. https://www.mdpi.com/2075-4418/10/6/353. 
[39] Fujimoto K, Inomata T, Okumura Y, Iwata N, Fujio K, Eguchi A, Nagino K, 
Shokirova H, Kara- sawa M, Murakami A. Comparison of corneal thickness in 
patients with dry eye disease using the pentacam rotating scheimpflug camera and 
anterior segment optical coherence tomography. PLoS One 2020;15(2):e0228567. 
https://doi.org/10.1371/journal.pone.0228567. 
[40] Maruoka S, Tabuchi H, Nagasato D, Masumoto H, Chikama T, Kawai A, Oishi N, 
Maruyama T, Kato Y, Hayashi T, Katakami C. Deep neural network-based method 
for detecting obstructive meibomian gland dysfunction with in vivo laser confocal 
microscopy. Cornea 2020;39(6):720–5. https://doi.org/10.1097/ 
ICO.0000000000002279. 
[41] Prabhu SM, Chakiat A, S S, Vunnava KP, Shetty R. Deep learning segmentation and 
quantification of meibomian glands. Biomed Signal Process Control 2020;57: 
101776. https://doi.org/10.1016/j.bspc.2019.101776. https://www.sciencedirec 
t.com/science/article/pii/S174680941930357X. 
[42] Stegmann H, Werkmeister RM, Pfister M, Garh¨ofer G, Schmetterer L, dos 
Santos VA. Deep learn- ing segmentation for optical coherence tomography 
measurements of the lower tear meniscus. Biomed Opt Express 2020;11(3): 
1539–54. https://doi.org/10.1364/BOE.386228. http://www.osapublishing. 
org/boe/abstract.cfm?URI=boe-11-3-1539. 
[43] Wei S, Ren X, Wang Y, Chou Y, Li X. Therapeutic effect of intense pulsed light (ipl) 
combined with meibomian gland expression (mgx) on meibomian gland 
dysfunction (mgd). J Ophthalmol 2020;2020. https://doi.org/10.1155/2020/ 
3684963. 
[44] Giannaccare G, Pellegrini M, Sebastiani S, Moscardelli F, Versura P, Campos EC. In 
vivo confo- cal microscopy morphometric analysis of corneal subbasal nerve plexus 
in dry eye disease using newly developed fully automated system. Graefe’s Arch 
Clin Exp Ophthalmol 2019;257(3):583–9. https://doi-org.ezproxy.uio.no/10.1 
007/s00417-018-04225-7. 
[45] Chen X, Graham J, Dabbah MA, Petropoulos IN, Tavakoli M, Malik RA. An 
automatic tool for quantification of nerve fibers in corneal confocal microscopy 
images. IEEE (Inst Electr Electron Eng) Trans Biomed Eng 2017;64(4):786–94. 
https://doi.org/10.1109/TBME.2016.2573642. 
[46] Dabbah M, Graham J, Petropoulos I, Tavakoli M, Malik R. Automatic analysis of 
diabetic peripheral neuropathy using multi-scale quantitative morphology of nerve 
fibres in corneal confocal microscopy imaging. Med Image Anal 2011;15(5): 
738–47. https://doi.org/10.1016/j.media.20 11.05.016. https://www.sciencedi 
rect.com/science/article/pii/S1361841511000806. 
[47] Llorens-Quintana C, Rico-Del-Viejo L, Syga P, Madrid-Costa D, Iskander DR. 
A novel automated approach for infrared-based assessment of meibomian gland 
morphology. Transl Vis Sci Technol 2019;8(4). https://doi.org/10.1167/ 
tvst.8.4.17. 17-17. 
[48] Wang J, Yeh TN, Chakraborty R, Yu SX, Lin MC. A deep learning approach for 
meibomian gland atrophy evaluation in meibography images. Transl Vis Sci 
Technol 2019;8(6). https://doi.org/10.1167/tvst.8.6.37. 37-37. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
86
[49] Yabusaki K, Arita R, Yamauchi T. Automated classification of dry eye type 
analyzing interference fringe color images of tear film using machine learning 
techniques. Model Artif Intell Ophthalmol 2019;2(3):28–35. https://doi.org/ 
10.35119/maio.v2i3.90. 
[50] Yang J, Zhu X, Liu Y, Jiang X, Fu J, Ren X, Li K, Qiu W, Li X, Yao J. TMIS: a new 
image-based software application for the measurement of tear meniscus height. 
Acta Ophthalmol 2019;97(7):e973–80. https://doi.org/10.1111/aos.14107. 
https://onlinelibrary.wiley.com/doi/abs/10.1111/aos.14107. 
[51] Szyperski PD. Comparative study on fractal analysis of interferometry images with 
application to tear film surface quality assessment. Appl Opt 2018;57(16):4491–8. 
https://doi.org/10.1364/AO.57.004491. 
[52] Hwang H, Jeon H-J, Yow KC, Hwang HS, Chung E. Image-based quantitative 
analysis of tear film lipid layer thickness for meibomian gland evaluation. Biomed 
Eng Online 2017;16(1):1–15. https://doi.org/10.1186/s12938-017-0426-8. 
[53] Koprowski R, Tian L, Olczyk P. A clinical utility assessment of the automatic 
measurement method of the quality of meibomian glands. Biomed Eng Online 
2017;16(82):1–13. https://doi.org/10.1186/s12938-017-0373-4. 
[54] Peteiro-Barral D, Remeseiro B, M´endez R, Penedo MG. Evaluation of an automatic 
dry eye test using mcdm methods and rank correlation. Med Biol Eng Comput 
2017;55(4):527–36. https://doi.org/10.1007/s11517-016-1534-5. 
[55] Koprowski R, Wilczy´nski S, Olczyk P, Nowi´nska A, Węglarz B, Wylęgała E. 
A quantitative method for assessing the quality of meibomian glands. Comput Biol 
Med 2016;75:130–8. https://doi.org/10.1016/j.compbiomed.2016.06.001. 
https://www.sciencedirect.com/science/article/pii/S0010482516301391. 
[56] Remeseiro B, Barreira N, García-Resúa C, Lira M, Gir´aldez MJ, Yebra-Pimentel E, 
Penedo MG. ideas: a web-based system for dry eye assessment. Comput Methods 
Progr Biomed 2016;130:186–97. https://doi.org/10.1016/j.cmpb.2016.02.015. 
https://www.sciencedirect.com/science/article/pii/S0169260715301644. 
[57] Remeseiro B, Mosquera A, Penedo MG. CASDES: a computer-aided system to 
support dry eye diagnosis based on tear film maps. IEE J Biomed Health Inf 2016; 
20(3):936–43. https://doi.org/10.1109/JBHI.2015.2419316. 
[58] Kanellopoulos AJ, Asimellis G. In vivo 3-dimensional corneal epithelial thickness 
mapping as an indicator of dry eye: preliminary clinical assessment. Am J 
Ophthalmol 2014;157(1):63–8. https://doi.org/10.1016/j.ajo.2013.08.025. e2, 
https://www.sciencedirect.com/science/article/pii/S0002939413005850. 
[59] Ramos L, Barreira N, Pena-Verdeal H, Gir´aldez M. Automatic assessment of tear 
film break-up dynamics. Stud Health Technol Inf 2014;207:173–82. https://doi. 
org/10.3233/978-1-61499-474-9-173. 
[60] Ramos L, Barreira N, Mosquera A, Penedo M, Yebra-Pimentel E, García-Resúa C. 
Analysis of parameters for the automatic computation of the tear film break-up 
time test based on cclru standards. Comput Methods Progr Biomed 2014;113(3): 
715–24. https://doi.org/10.1016/j.cmpb.2013.12.003. https://www.sciencedirec 
t.com/science/article/pii/S0169260713003921. 
[61] Remeseiro B, Bolon-Canedo V, Peteiro-Barral D, Alonso-Betanzos A, Guijarro- 
Berdi˜nas B, Mos- quera A, Penedo MG, S´anchez-Maro˜no N. A methodology for 
improving tear film lipid layer classi- fication. IEE J Biomed Health Inf 2014;18(4): 
1485–93. https://doi.org/10.1109/JBHI.2013.2294732. 
[62] García-Resúa C, Fern´andez MJG, Penedo MFG, Calvo D, Penas M, Yebra- 
Pimentel E. New software application for clarifying tear film lipid layer patterns. 
Cornea 2013;32(4):538–46. https://doi.org/10.1097/ICO.0b013e31824d0d04. 
[63] Rodriguez JD, Johnston PR, Ousler GW, Smith LM, Abelson MB. Automated 
grading system for evaluation of ocular redness associated with dry eye. Clin 
Ophthalmol 2013;7:1197–204. https://doi.org/10.2147/OPTH.S39703. 
[64] Koh YW, Celik T, Lee HK, Petznick A, Tong LH. Detection of meibomian glands and 
classification of meibography images. J Biomed Opt 2012;17(8):086008. https:// 
doi.org/10.1117/1.JBO.17.8.086008. 
[65] Yedidya T, Carr P, Hartley R, Guillon J-P. Enforcing monotonic temporal evolution 
in dry eye images. In: International conference on medical image computing and 
computer-assisted intervention. Springer; 2009. p. 976–84. https://doi.org/ 
10.1007/978-3-642-04271-3_118. 
[66] Mathers WD, Choi D. Cluster analysis of patients with ocular surface disease, 
blepharitis, and dry eye. Arch Ophthalmol 2004;122(11):1700–4. https://doi.org/ 
10.1001/archo pht.122.11.1700. https://jamanetwork.com/journals/jamaophtha 
lmology/articlepdf/416676/eeb30021.pdf. 
[67] Cartes C, L´opez D, Salinas D, Segovia C, Ahumada C, P´erez N, Valenzuela F, 
Lanza N, Solís RL, Perez V, et al. Dry eye is matched by increased intrasubject 
variability in tear osmolarity as confirmed by machine learning approach. Arch Soc 
Esp Oftalmol 2019;94(7):337–42. https://doi.org/10.1016/j.oftal.2019.03.007. 
[68] Jung JH, Ji YW, Hwang HS, Oh JW, Kim HC, Lee HK, Kim KP. Proteomic analysis 
of human lacrimal and tear fluid in dry eye disease. Sci Rep 2017;7(1):1–11. 
https://doi.org/10.1038/s41598-017-13817-y. 
[69] Gonz´alez N, Iloro I, Soria J, Duran JA, Santamaría A, Elortza F, Su´arez T. Human 
tear pep- tide/protein profiling study of ocular surface diseases by spe-maldi-tof 
mass spectrometry analyses. EuPA Open Proteomics 2014;3:206–15. https://doi. 
org/10.1016/j.euprot.2014.02.016. https://www.sciencedirect.com/science/artic 
le/pii/S221296851400021X. 
[70] Grus FH, Podust VN, Bruns K, Lackner K, Fu S, Dalmasso EA, Wirthlin A, Pfeiffer N. 
SELDI- TOF-MS proteinchip array profiling of tears from patients with dry eye. 
Investig Ophthalmol Vis Sci 2005;46(3):863–76. https://doi.org/10.1167/iovs.04- 
0448. 
[71] Grus F-H, Augustin AJ. Analysis of tear protein patterns by a neural network as a 
diagnostical tool for the detection of dry eyes, ELECTROPHORESIS. Int J 1999;20 
(4-5):875–80. https://doi.org/10.1002/(SICI)1522-2683(19990101)20:4/5<875:: 
AID-ELPS875> 3.0.CO;2-V. 
[72] Grus F, Augustin A, Evangelou N, Toth-Sagi K. Analysis of tear-protein patterns as a 
diagnostic tool for the detection of dry eyes. Eur J Ophthalmol 1998;8(2):90–7. 
https://doi.org/10.1177/112067219800800207. 
[73] Choi HR, Lee JH, Lee HK, Song JS, Kim HC. Association between dyslipidemia and 
dry eye syndrome among the Korean middle-aged population. Cornea 2020;39(2): 
161–7. https://doi.org/10.1097/ICO.0000000000002133. 
[74] Nam SM, Peterson TA, Butte AJ, Seo KY, Han HW. Explanatory model of dry eye 
disease using health and nutrition examinations: machine learning and network- 
based factor analysis from a national survey. JMIR Med Inf 2020;8(2):e16153. 
https://doi.org/10.2196/16153. http://medinform.jmir.org/2020/2/e16153/. 
[75] Kaido M, Kawashima M, Yokoi N, Fukui M, Ichihashi Y, Kato H, Yamatsuji M, 
Nishida M, Fukagawa K, Kinoshita S, Tsubota K. Advanced dry eye screening for 
visual display terminal workers using functional visual acuity measurement: the 
moriguchi study. Br J Ophthalmol 2015;99(11):1488–92. https://doi.org/ 
10.1136/bjophthalmol-2015-306640. 
[76] Gullion J-PC. Tear film structure of the contact lens wearer. Ph.D. thesis. London: 
City University; 1990. 
[77] Holly FJ. Physical chemistry of the normal and disordered tear film. Trans 
Ophthalmol Soc U K 1985;104(Pt 4):374–80. 
[78] Rasband W. Imagej. http://imagej.nih.gov/ij/. 
[79] Cruzat M, Andrea, Qazi M, Yureeda, Hamrah M, Pedram. In vivo confocal 
microscopy of corneal nerves in health and disease. Ocul Surf 2016;15(1):15–47. 
https://doi.org/10.1016/j.jtos.2016.09.004. 
[80] Villani E, Marelli L, Dellavalle A, Serafino M, Nucci P. Latest evidences on 
meibomian gland dysfunction diagnosis and management. Ocul Surf 2020;18(4): 
871–92. https://doi.org/10.1016/j.jtos.2020.09.001. https://www.sciencedirect. 
com/science/article/pii/S1542012420301415. 
[81] Krizhevsky A, Sutskever I, Hinton GE. Imagenet classification with deep 
convolutional neural net- works. Commun ACM 2017;60(6):84–90. https://doi. 
org/10.1145/3065386. 
[82] Dartt DA. Dysfunctional neural regulation of lacrimal gland secretion and its role in 
the pathogenesis of dry eye syndromes. Ocul Surf 2004;2(2):76–91. https://doi. 
org/10.1016/S1542- 0124(12)70146-5. 
[83] Wan K, Chen L, Young A. Depression and anxiety in dry eye disease: a systematic 
review and meta- analysis. Eye 2016;30:1558–67. https://doi.org/10.1038/ 
eye.2016.186. 
[84] Ambaw YA, Timbadia DP, Raida M, Torta F, Wenk MR, Tong L. Profile of tear lipid 
mediator as a biomarker of inflammation for meibomian gland dysfunction and 
ocular surface diseases: standard operating procedures. The Ocular Surface; 2020. 
https://doi.org/10.1016/j.jtos.2020.09.0 08. https://www.sciencedirect.com/sci 
ence/article/pii/S1542012420301488. 
[85] D’Amour A, Heller K, Moldovan D, Adlam B, Alipanahi B, Beutel A, Chen C, 
Deaton J, Eisen- stein J, Hoffman MD, et al. Underspecification presents challenges 
for credibility in modern machine learning. arXiv preprint arXiv:2011.03395. 
2020. 
[86] Kelly CJ, Karthikesalingam A, Suleyman M, Corrado G, King D. Key challenges for 
delivering clinical impact with artificial intelligence. BMC Med 2019;17(1):1–9. 
A.M. Storås et al.                                                                                                                                                                                                                               
",https://doi.org/10.1016/j.jtos.2021.11.004,doc18,"The Ocular Surface 23 (2022) 74–86 Available online 27 November 2021 1542-0124/© 2021 Elsevier Inc. All rights reserved. Review Article Artificial intelligence in dry eye disease Andrea M. Storås a,e,*, Inga Strümke a, Michael A. Riegler a, Jakob Grauslund b,c,d, Hugo L. Hammer a,e, Anis Yazidi e, Pål Halvorsen a,e, Kjell G. Gundersen h, Tor P. Utheim e,f,g, Catherine J. Jackson h a SimulaMet, Oslo, Norway b Department of Ophthalmology, Odense University Hospital, Odense, Denmark c Department of Clinical Research, University of Southern Denmark, Odense, Denmark d Department of Ophthalmology, Vestfold University Trust, Tønsberg, Norway e Department of Computer Science, Oslo Metropolitan University, Norway f Department of Medical Biochemistry, Oslo University Hospital, Norway g Department of Ophthalmology, Oslo University Hospital, Norway h Ifocus, Haugesund, Norway A R T I C L E I N F O Keywords: Dry eye disease Artificial intelligence Machine learning A B S T R A C T Dry eye disease (DED) has a prevalence of between 5 and 50%, depending on the diagnostic criteria used and population under study. However, it remains one of the most underdiagnosed and undertreated conditions in ophthalmology. Many tests used in the diagnosis of DED rely on an experienced observer for image interpre­ tation, which may be considered subjective and result in variation in diagnosis. Since artificial intelligence (AI) systems are capable of advanced problem solving, use of such techniques could lead to more objective diagnosis. Although the term ‘AI’ is commonly used, recent success in its applications to medicine is mainly due to ad­ vancements in the sub-field of machine learning, which has been used to automatically classify images and predict medical outcomes. Powerful machine learning techniques have been harnessed to understand nuances in patient data and medical images, aiming for consistent diagnosis and stratification of disease severity. This is the first literature review on the use of AI in DED. We provide a brief introduction to AI, report its current use in DED research and its potential for application in the clinic. Our review found that AI has been employed in a wide range of DED clinical tests and research applications, primarily for interpretation of interferometry, slit-lamp and meibography images. While initial results are promising, much work is still needed on model development, clinical testing and standardisation. 1. Introduction Dry eye disease (DED) is one of the most common eye diseases worldwide, with a prevalence of between 5 and 50%, depending on the diagnostic criteria used and study population [1]. Yet, although symp­ toms stemming from DED are reported as the most common reason to seek medical eye care [1], it is considered one of the most under­ diagnosed and undertreated conditions in ophthalmology [2]. Symp­ toms of DED include eye irritation, photophobia and fluctuating vision. The condition can be painful and might result in lasting damage to the cornea through irritation of the ocular surface. Epidemiological studies indicate that DED is most prevalent in women [3] and increases with age [1]. However, the incidence of DED is likely to increase in all age groups in coming years due to longer screen time and more prevalent use of contact lenses, which are both risk factors [4]. Other risk factors include diabetes mellitus [5] and exposure to air-pollution [6]. DED can have a substantial effect on the quality of life, and may impose significant direct and indirect public health costs as well as personal economic burden due to reduced work productivity. DED is divided into two subtypes defined by the underlying mech­ anism of the disease: (i) aqueous deficient DED, where tear production from the lacrimal gland is insufficient and (ii) evaporative DED (the most common form), which is typically caused by dysfunctional mei­ bomian glands in the eyelids. Meibomian glands are responsible for supplying meibum, which is a concentrated substance that normally covers the surface of the cornea to form a protective superficial lipid * Corresponding author. SimulaMet, Oslo, Norway. E-mail address: andrea@simula.no (A.M. Storås). Contents lists available at ScienceDirect The Ocular Surface journal homepage: www.elsevier.com/locate/jtos Received 9 July 2021; Received in revised form 8 November 2021; Accepted 9 November 2021 The Ocular Surface 23 (2022) 74–86 75 layer that guards against evaporation of the underlying tear film. The ability to reliably distinguish between aqueous deficient and evapora­ tive DED, their respective severity levels and mixed aqueous/evapora­ tive forms is important in deciding the ideal modality of treatment. A fast and accurate diagnosis relieves patient discomfort and also spares them unnecessary expense and exposure to potential side effects asso­ ciated with some treatments. A tailor made treatment plan can yield improved treatment response and maximize health provider efficiency. The main clinical signs of DED are decreased tear volume, more rapid break-up of the tear film (fluorescein tear break-up time (TBUT)) and microwounds of the ocular surface [7]. In the healthy eye, the tear film naturally ‘breaks up’ after 10 s and the protective tear film is reformed with blinking. Available diagnostic tests often do not correlate with the severity of clinical symptoms reported by the patient. No single clinical test is considered definitive in the diagnosis of DED [1]. Therefore, multiple tests are typically used in combination and supplemented by information gathered on patient symptoms, recorded through ques­ tionnaires. These tests demand a significant amount of time and re­ sources at the clinic. Tests for determining the physical parameters of tears include TBUT, the Schirmer’s test, tear osmolarity and tear meniscus height. Other useful tests in DED diagnosis include ocular surface staining, corneal sensibility, interblink frequency, corneal sur­ face topography, interferometry, aberrometry and imaging techniques such as meibography and in vivo confocal microscopy (IVCM), as well as visual function tests. Artificial intelligence (AI) was defined in 1955 as “the science and engineering of making intelligent ma-chines” [8], where intelligence is the “ability to achieve goals in a wide range of environments” [9]. Within AI, machine learning denotes a class of algorithms capable of learning from data rather than being programmed with explicit rules. AI, and particularly machine learning, is increasingly becoming an integral part of health care systems. The sub-field of machine learning known as deep learning uses deep artificial neural networks, and has gained increased attention in recent years, especially for its image and text recognition abilities. In the field of ophthalmology, deep learning has so far mainly been used in the analysis of data from the retina to segment regions of interest in images, automate diagnosis and predict disease outcomes [10]. For instance, the combination of deep learning and op­ tical coherence tomography (OCT) technologies has allowed reliable detection of retinal diseases and improved diagnosis [11]. Machine learning also has potential for use in the diagnosis and treatment of anterior segment diseases, such as DED and has already found its way into the field with methods such as presented by Ciezar et al. [12]. Many of the tests used for DED diagnosis and follow-up rely on the experience of the observer for interpretation of images, which may be considered subjective [13]. AI tools can be used to interpret images automatically and objectively, saving time and providing consistency in diagnosis. Several reviews have been published that discuss the application of AI in eye disease, including screening for diabetic retinopathy [14], detection of age-related macular degeneration [15] and diagnosis of retinopathy of prematurity [16]. We are, however, not aware of any review on AI in DED. In this article, we therefore provide a critical re­ view of the use of AI systems developed within the field of DED, discuss their current use and highlight future work. 2. Artificial intelligence AI is informational technology capable of performing activities that require intelligence. It has gained substantial popularity within the field of medicine due to its ability to solve ubiquitous medical problems, such as classification of skin cancer [17], prediction of hypoxemia during surgeries [18], identification of diabetic retinopathy [19] and prediction of risk for future need of keratoplasty [20]. Machine learning is a sub-field of AI encompassing algorithms capable of learning from data, without being explicitly programmed. All AI systems used in the studies included in this review, fall within the class of machine learning. The process by which a machine learning algorithm learns from data is referred to as training. The outcome of the training process is a machine learning model, and the model’s output is referred to as predictions. Different learning algorithms are categorised according to the type of data they use, and referred to as supervised, unsupervised and rein­ forcement learning. The latter is excluded from this review, as none of the studies use it, while the two former are introduced in this section. A complete overview of the algorithms encountered in the reviewed studies is provided in Fig. 1, sorted according to the categories described below. 2.1. Supervised learning Supervised learning denotes the learning process of an algorithm using labelled data, meaning data that contains the target value for each data instance, e.g., tear film lipid layer category. The learning process involves extracting patterns linking the input variables and the target outcome. The performance of the resulting model is evaluated by letting it predict on a previously unseen data set, and comparing the predictions to the true data labels. See Section 2.5 for a brief discussion of evaluation metrics. Supervised learning algorithms can perform regression and classification, where regression involves predicting a numerical value for a data instance, and classification involves assigning data instances to predefined categories. Fig. 1 contains an overview of supervised learning algorithms encountered in the reviewed studies. 2.2. Unsupervised learning Unsupervised learning denotes the training process of an algorithm using unlabelled data, i.e., data not containing target values. The task of the learning algorithm is to find patterns or data groupings by con­ structing a compact representation of the data. This type of machine learning is commonly used for grouping observations together, detecting relationships between input variables, and for dimensionality reduction. As unsupervised learning data contains no labels, a measure of model performance depends on considerations outside the data [see 21, chap. 14], e.g., how the task would have been solved by someone in the real world. For clustering algorithms, similarity or dissimilarity measures such as the distance between cluster points can be used to measure performance, but whether this is relevant depends on the task [22]. Unsupervised algorithms encountered in the reviewed studies can be divided into those performing clustering and those used for dimen­ sionality reduction, see Fig. 1 for an overview. 2.3. Artificial neural networks and deep learning Artificial neural networks are loosely inspired by the neurological networks in the biological brain, and consist of artificial neurons organised in layers. How the layers are organised within the network is referred to as its architecture. Artificial neural networks have one input layer, responsible for passing the data to the network, and one or more hidden layers. Networks with more than one hidden layer are called deep neural networks. The final layer is the output layer, providing the output of the entire network. Deep learning is a sub-field of machine learning involving training deep neural networks, which can be done both in a supervised and unsupervised manner. We encounter several deep architectures in the reviewed studies. The two more advanced types are convolutional neural networks (CNNs) and generative adver­ sarial networks (GANs). CNN denotes the commonly used architecture for image analysis and object detection problems, named for having so- called convolutional layers that act as filters identifying relevant fea­ tures in images. CNNs have gained popularity recently and all of the reviewed studies that apply CNNs were published in 2019 or later. Advanced deep learning techniques will most likely replace the estab­ lished image analysis methods. This trend has been observed within other medical fields such as gastrointestinal diseases and radiology [23, A.M. Storås et al. The Ocular Surface 23 (2022) 74–86 76 24]. A GAN is a combination of two neural networks: A generator and a discriminator competing against each other. The goal of the generator is to produce fake data similar to a set of real data. The discriminator re­ ceives both real data and the fake data from the generator, and its goal is to discriminate the two. GANs can among other things be used to generate synthetic medical data, alleviating privacy concerns [25]. 2.4. Workflow for model development and validation The data used for developing machine learning models is ideally divided into three independent parts: A training set, a validation set and a test set. The training set is used to tune the model, the validation set to evaluate performance during training, and the test set to evaluate the final model. A more advanced form of training and validation, is k-fold cross-validation. Here, the data is split into k parts, of which one part is set aside for validation, while the model is trained on the remaining data. This is repeated k times, and each time a different part of the data is used for validation. The model performance can be calculated as the average performance for the k different models [see 21, chap. 7]. It is considered good practice to not use the test data during model devel­ opment and vice versa, the model should not be tuned further once it has been evaluated on the test data [see 21, chap.7]. In cases of class imbalance, i.e., unequal number of instances from the different classes, there is a risk of developing a model that favors the prevalent class. If the data is stratified for training and testing, this might not be captured during testing. Class imbalance is common in medical data sets, as there are for instance usually more healthy than ill people in the population [26]. Whether to choose a class distribution that represents the popu­ lation, a balanced or some other distribution depends on the objective. Various performance scores should regardless always be used to provide a full picture of the model’s performance. 2.5. Performance scores In order to assess how well a machine learning model performs, its performance can be assigned a score. In supervised learning, this is based on the model’s output compared to the desired output. Here, we introduce scores used most frequently in the reviewed studies. Their definitions as well as the remaining scores used are provided in Ap­ pendix A.1. A commonly used performance score in classification is accuracy, Equation (A.3), which denotes the proportion of correctly predicted instances. Its use is inappropriate in cases of strong class imbalance, as it can reach high values if the model always predicts the prevalent class. The sensitivity, also known as recall, Equation (A.4), denotes the true positive rate. If the goal is to detect all positive in­ stances, a high sensitivity indicates success. The precision, Equation (A.5), denotes the positive predictive value. The specificity, Equation (A.6), denotes the true negative rate, and is the negative class version of the sensitivity. The F1 score, Equation (A.7), is the harmonic mean be­ tween the sensitivity and the precision. It is not symmetric between the classes, meaning it is dependent on which class is defined as positive. Image segmentation involves partitioning the pixels in an image into segments [27]. This can for example be used to place all pixels repre­ senting the pupil into the same segment while pixels representing the iris are placed in another segment. The identified segments can then be compared to manual annotations. Performance scores used include the Average Pompeiu-Hausdorff distance, (A.17), the Jaccard index and the support, all described in Appendix A.1. 2.6. AI regulation Approved AI devices will be a major part of the medical service landscape in the future. Currently, many countries are actively working on releasing AI regulations for healthcare, including the European Union (EU), the United States, China, South Korea and Japan. On April 21, 2021, the EU released a proposal for a regulatory framework for AI [28]. The US Food and Drug Administration (FDA) is also working on AI legislation for healthcare [29]. In the framework proposed by the EU, AI systems are divided into the four categories low risk, minimal risk, high risk and unacceptable risk [28]. AI systems that fall into the high risk category are expected to be subject to strict requirements, including data governance, technical documentation, transparency and provision of information to users, human oversight, robustness and cyber security, and accuracy. It is highly likely that medical devices using AI will end up in the high risk category. Looking at the legislation proposals [28,29] from an AI research perspective, it is clear that explainable AI, transparency, un­ certainty assessment, robustness against adversarial attacks, high qual­ ity of data sets, proper performance assessment, continuous post-deployment monitoring, human oversight and interaction be­ tween AI systems and humans, will be major research topics for the development of AI in healthcare. 3. Methods 3.1. Search methods A systematic literature search was performed in PubMed and Embase in the period between March 20 and May 21, 2021. The goal was to retrieve as many studies as possible applying machine learning to DED related data. The following keywords were used: All combinations of “dry eye” and “meibomian gland dysfunction” with “artificial intelli­ gence”, “machine learning”, “computer vision”, “image recognition”, “bayesian network”, “decision tree”, “neural network”, “image based Fig. 1. An overview of the machine learning algorithms used in the reviewed studies. A.M. Storås et al. The Ocular Surface 23 (2022) 74–86 77 analysis”, “gradient boosting”, “gradient boosting machine” and “auto­ matic detection”. In addition, searches for “ocular surface” combined with both “artificial intelligence” and “machine learning” were made. See also an overview of the search terms and combinations in Fig. 2. No time period limitations were applied for any of the searches. 3.2. Selection criteria The studies to include in the review had to be available in English in full-text. Studies not investigating the medical aspects of DED were excluded (e.g., other ocular diseases and cost analyses of DED). More­ over, the studies had to describe the use of a machine learning model in order to be considered. Reviews were not considered. The studies were selected in a three-step process. One review author screened the titles on the basis of the inclusion criteria. The full-texts were then retrieved and studied for relevance. The search gave 640 studies in total, of which 111 were regarded as relevant according to the selection criteria. After removing duplicates, 45 studies were left. The three-step process is shown in Fig. 3a. 4. Artificial intelligence in dry eye disease 4.1. Summary of the studies Most studies were published in recent years, especially after 2014, see Fig. 3b. An overview of the studies is provided in Tables 1-4 for the clinical, biochemical and demographical studies, respectively. Infor­ mation on the data used in each study is shown in Table 5. We grouped studies according to the type of clinical test or type of study: TBUT, interferometry and slit-lamp images, IVCM, meibography, tear osmo­ larity, proteomics analysis, OCT, population surveys and other clinical tests. We found most studies employed machine learning for interpre­ tation of interferometry, slit-lamp and meibography images. 4.2. Fluorescein tear break-up time Shorter break-up time indicates an unstable tear film and higher probability of DED. Machine learning has been employed to detect dry areas in TBUT videos and estimate TBUT [13,59,60,65]. Use of the Levenberg-Marquardt algorithm to detect dry areas achieved an accu­ racy of 91% compared to assessments by an optometrist [13]. Applica­ tion of Markov random fields to label pixels based on degree of dryness was used to estimate TBUT resulting in an average difference of 2.34 s compared to clinician assessments [65]. Polynomial functions have also been used to determine dry areas, where threshold values were fine-tuned before estimation of TBUT [59]. This method resulted in more than 90% of the videos deviating by less than ±2.5 s compared to analyses done by four experts on videos not used for training [60]. Taken together, these studies indicate that TBUT values obtained using auto­ matic methods are within an acceptable range compared to experts. However, we only found four studies, all of them including a small number of subjects. Further studies are needed to verify the findings and to test models on external data. 4.3. Interferometry and slit-lamp images Interferometry is a useful tool that gives a snapshot of the status of the tear film lipid layer, which can be used to aid diagnosis of DED. Machine learning systems have been applied to interferometry and slit- lamp images for lipid layer classification based on morphological properties [36,37,54,56,57,61,62], estimation of the lipid layer thick­ ness [38,52], diagnosis of DED [49,51], determination of ocular redness [63] and estimation of tear meniscus height [31,50]. Diagnosis of DED can be based on the following morphological properties: open meshwork, closed mesh-work, wave, amorphous and color fringe [76]. Most studies used these properties to automatically classify interferometer lipid layer images using machine learning. Garcia et al. used a K-nearest neighbors model trained to classify images resulting in an accuracy of 86.2% [62]. Remeseiro et al. explored various support vector machine (SVM) models for use in final classification [56, 57,61]. In one of the studies, the same data was used for training and testing, which is not ideal [57]. Another study did not report the data their system was trained on [56]. Peteiro et al. evaluated images using five different machine learning models [54]. In this study, the amor­ phous property was not included as one of possible classifications, as opposed to the other studies. A simple neural network achieved the overall best performance with an accuracy of 96%. However, because leave-one-out cross validation was applied, the model may have over­ fitted on the training data [21]. da Cruz et al. compared six different machine learning models and found that the random forest was the best classifier, regardless of the pre-processing steps used [36,37]. The highest performance was achieved by application of Ripley’s K function in the image pre-processing phase, and Greedy Stepwise technique used simultaneously with the machine learning models for feature selection [37]. Since all models were evaluated with cross validation, the system should be externally evaluated on new images before being considered Fig. 2. Search term combinations used in the literature search. Three of the studies found in the searches including “ocular surface” were also found among the studies in the searches including “dry eye”. A.M. Storås et al. The Ocular Surface 23 (2022) 74–86 78 for routine use in the clinic. Hwang et al. investigated whether tear film lipid layer thickness can be used to distinguish meibomian gland dysfunction (MGD) severity groups [52]. Machine learning was used to estimate the thickness from Lipiscanner and slit-lamp videos with promising results. Images were pre-processed and the flood-fill algo-rithm and canny edge detection were applied to locate and extract the iris from the pupil. A significant difference between two MGD severity groups was detected, suggesting that the technique could be used for the evaluation of MGD. Keratograph images can also be used to determine tear film lipid layer thickness. Comparison of two different image analysis methods using a generalized linear model showed that there was a high correlation between the two techniques [38]. The authors concluded that the simple technique was sufficient for evaluation of tear film lipid layer thickness. However, only 28 subjects were included in the study. The use of fractal dimension estimation techniques was investigated for feature extraction from interferometer videos for diagnosis of DED [51]. The technique was found to be fast and had an area under the receiver operating characteristic curve (AUC) value of 0.786, compared to a value of 0.824 for an established method (See Appendix A.1 and Figure A.4a for a description of the receiver operating characteristic curve). Tear film lipid interferometer images were analysed using an SVM [49]. Extracted features from the images were passed to the SVM model, which classified the images as either healthy, aqueous-deficient DED, or evaporative DED. The agreement between the model and a trained ophthalmologist was high, with a reported Kappa value of 0.82. The model performed best when detecting aqueous-deficient DED. Ocular redness is an important indicator of dry eyes. Only one of the reviewed studies described an auto-mated system for evaluation of ocular redness associated with DED [63]. Slit-lamp images were ac­ quired from 26 subjects with a history of DED. Features representing the ocular redness intensity and horizontal vascular component were extracted with a Sobel operator. A multiple linear regression model was trained to predict ocular redness based on the extracted features. The system achieved an accuracy of 100%. The authors suggested that an objective system like this could replace subjective gradings by clinicians in multicentered clinical studies. The tear meniscus contains 75-90% of the aqueous tear volume [77]. Consequently, the tear meniscus height can be used as a quantitative indicator for DED caused by aqueous deficiency. When connected component labelling was applied to slit-lamp images, the Pearson’s correlation between the predicted meniscus heights and an established software methodology (ImageJ [78]) was high, ranging between 0.626 and 0.847 [50]. The machine learning system was found to be more accurate than four experienced ophthalmologists. The tear meniscus height can also be estimated from keratography images using a CNN [31]. The automatic machine learning system achieved an accuracy of 82.5% and was found to be more effective and consistent than a well-trained clinician working with limited time. Many of the studies apply SVM as their type of machine learning model without testing how other machine learning models perform. However, three of the studies tested several types of models and found that SVM did not perform the best [36,37,54]. It is difficult to compare the studies due to different applications and evaluation metrics. Despite promising results, most of the studies [36-38,50-52,54,57,61-63] did not evaluate their systems on external data. The systems should be tested on independent data before they can be considered for clinical application. Moreover, some studies were small [38,63] or pilots [31,50], and the suggested models should be tested on a larger number of subjects. 4.4. In vivo confocal microscopy IVCM is a valuable non-invasive tool used to examine the corneal nerves and other features of the cornea [79]. IVCM images were used in a small study to assess characteristics of the corneal subbasal nerve plexus for diagnosis of DED [44]. Application of random forest and a deep neural network [45] gave promising results with an AUC value of 0.828 for detecting DED [44]. IVCM images of corneal nerves can also be analysed by machine learning models to estimate the length of the nerve fiber [43]. Authors used a CNN with a U-net architecture that had been pre-trained on more than 5, 000 IVCM images of corneal nerves. The model showed that nerve fiber length was significantly longer after intense pulsed light treatment in MGD patients, which agreed with manual annotations from an experienced investigator with an AUC value of 0.96 and a sensitivity of 0.96. High-resolution IVCM images were also used to detect obstructive MGD [40]. Combinations of nine different CNNs were trained and tested on the images using 5-fold cross validation. Classification by the models was compared to diagnosis made by three eyelid specialists. The best performance was achieved when four different models were combined, with high sensitivity, specificity and AUC values, see Table 1. These promising results suggest that CNNs can be useful for detection and evaluation of MGD. Deep learning methods such as CNNs have the advantage that feature extraction from the images prior to analysis is not required as this is performed automatically by the model. IVCM images have been investigated for changes in immune cells across different severities of DED for diagnostic purposes [30]. A generalized linear model showed significant differences in dendritic cell density and morphology between DED patients and healthy individuals, but not between the different DED subgroups, see Table 1. While results using machine learning to interpret IVCM images are promising, larger clinical studies are needed to validate findings before clinical use can be considered. 4.5. Meibography The meibomian glands are responsible for producing meibum, important for protecting the tear fluid from evaporation. Reduced Fig. 3. (a) Illustration of the three steps in the study selection process and number of studies (N) included in each step, and (b) the number of studies published over time, counting the studies included in this review. A.M. Storås et al. The Ocular Surface 23 (2022) 74–86 79 Table 1 Overview of the reviewed studies using clinical investigations, part 1 of 2. Study Objective N Clinical Tests Type of Data Type of Algorithm Performance Score(s) Aggarwal S et al. (2021) [30] DED mechanism, effect of therapy 199 Subjective symptoms, Schirmer’s test with anasthesia, TBUT, vital staining of cornea and conjunctiva, laser IVCM images, subbasal layer of cornea: DC density and morphology Images of cornea GLM, MLR GLM: p-values < 0.05 for DC density and number of DCs, MLR: p-values < 0.05 between DC density and CFS, number of DCs and CFS, DC size and CFS, DC density and conjunctival staining, number of DCs and TBUT, corresponding beta-coefficients = 0.20, −0.23, 0.36, 0.24 and −0.18 Deng X et al. (2021) [31] Estimate tear meniscus height 217 Oculus Keratograph Tear meniscus images CNN (U-net) Accuracy = 82.5%, sensitivity = 0.899, precision = 0.911, F1 score = 0.901 Elsawy A et al. (2021) [32] Diagnose DED 547 AS-OCT Ocular surface images Pretrained CNN (VGG19) AUCROC = 0.99 (model 1) and 0.98 (model 2), AUCPRC = 0.96 (model 1) and 0.94 (model 2), F1 score = 0.90 (model 1) and 0.86 (model 2)* Khan ZK et al. (2021) [33] Detect MGD 112 Meibomian gland 3D IR-images, lower and upper eyelid Meibomian gland images GAN F1 score = 0.825, P-HD = 4.611, aggregated JI = 0.664, r = 0.962 (clincian1) and 0.968 (clinician2), p-values < 0.001, mean difference = 0.96 (clincian1) and 0.95 (clincian2) Xiao P et al. (2021) [34] Detect MGD 15 (images) Oculus Keratograph IR meibography images Prewitt operator, Graham scan algorithm, fragmentation algorithm and SA (used sequentially) Gland area: KI = 0.94, FPR = 6.02%, FNR = 6.43%. Gland segmentation: KI = 0.87, FPR = 4.35%, FNR = 18.61%* Yeh C-H et al. (2021) [35] Detect MGD 706 (images) Oculus Keratograph IR meibography images Nonparametric instance discrimination, pretrained CNN (ImageNet), hierarchical clustering Accuracy: meiboscore grading = 80.9%, 2-class classification = 85.2%, 3-class classification = 81.3%, 4-class classification = 80.8%* da Cruz LB et al. (2020) [36] Classify tear film patterns 106 (images) Doane interferometer Tear film lipid layer images SVM, RF, RT, Naive Bayes, DNN, simple NN RF: accuracy = 97.54%, SD = 0.51%, F1 score = 0.97, KI = 0.96, AUCROC = 0.99*** da Cruz LB et al. (2020) [37] Classify tear film patterns 106 (images) Doane interferometer Tear film lipid layer images SVM, RF, RT, Naive Bayes, DNN, simple NN RF: accuracy = 99.622%, SD = 0.843%, F1 score = 0.996, KI = 0.995, AUCROC = 0.999*** Fu P-I et al. (2020) [38] Compare 2 methods 28 Oculus Keratograph Tear film lipid layer images (with and without preprocessing) GLM beta-coefficients = 0.6, 10 Fujimoto K et al. (2020) [39] Compare 2 methods 195 Pentacam vs AS-OCT CCT, TCT, thinnest point of cornea Multivariable regression Severe DED: beta-coefficients = 7.029 (CCT) and 6.958 (TCT), p- values = 0.002 (CCT) and 0.049 (TCT), 95% CI = 2.528-11.530 (CCT) and 0.037-13.879 (TCT) Maruoka S et al. (2020) [40] Detect MGD 221 IVCM Meibomian gland images Combinations of 9 CNNs Single CNN: AUROC = 0.966, sensitivity = 0.942, specificity = 0.821, ensemble CNNs: AUROC = 0.981, sensitivity = 0.921, specificity = 0.988 Prabhu SM et al. (2020) [41] Quantify and detect MGD 400 (images) Oculus Keratograph, digital camera Meibomian gland images CNN (U-net) p-values > 0.005 between model output and clinical experts Stegmann H et al. (2020) [42] Detect tear meniscus in images 10 Optical coherence tomography Tear meniscus images 2 CNNs Meniscus localization: JI = 0.7885, sensitivity = 0.9999, meniscus segmentation best CNN: accuracy = 0.9995, sensitivity = 0.9636, specificity = 0.9998, JI = 0.9324, F1 score = 0.9644, support = 0.0071*, *** Wei S et al. (2020) [43] DED mechanism, effect of therapy 53 Corneal IVCM with anesthesia Images of cornea Pretrained CNN (U-net) AUROC = 0.96, sensitivity = 96% Giannaccare G et al. (2019) [44] Subbasal nerve plexus characteristics for diagnosing DED 69 IVCM Images of subbasal nerve plexus Earlier developed method involving RF and NN[45,46] Nan Abbreviations: N = number of subjects; DED = dry eye disease; IVCM = in vivo confocal microscopy; DC = dendritic cell; GLM = generalized linear model; MLR = multiple linear regression; CFS = corneal fluorescein score; AS-OCT = anterior segment optical coherence tomography; CNN = convolutional neural network; AUROC = area under reciever operating characteristic curve; AUPRC = area under precision-recall curve; MGD = meibomian gland dysfunction; GAN = generative adversarial network; P-HD = average Pompeiu-Hausdorff distance; JI = Jaccard index; KI = Kappa index; CTRL = healthy; FPR = false positive rate; FNR = false negative rate; SVM = support vector machine; RF = random forest; RT = random tree; DNN = deep neural network; SD = standard deviation; CCT = central corneal thickness; TCT = A.M. Storås et al. The Ocular Surface 23 (2022) 74–86 80 secretion of meibum due to a reduced number of functional meibomian glands and/or obstruction of the ducts is a major cause of evaporative DED and MGD. Meibography is a common technique for diagnosing MGD [80]. Classification of meibomian glands using meibography is routine for experienced experts, but this is not the case for all clinicians. Moreover, automatic methods can be faster than human assessment. Meibography images may require several pre-processing steps before they can be classified. One study trained an SVM on extracted features from the images [64]. Pre-processing included the dilation, flood-fill, skeletonization and pruning algorithms. The model achieved a sensi­ tivity of 0.979 and specificity of 0.961. However, in contrast to all other image analysis methods, this method is not completely automatic as the images need to be manipulated manually before they are passed on to the system. A combination of Otsu’s method and the skeletonization and watershed algorithms was useful in auto-matically quantifying meibo­ mian glands [55]. This method was faster than an ophthalmologist and achieved a sensitivity and specificity of 0.993 and 0.975, respectively. Another automatic method applied B´ezier curve fitting as part of the analysis [53]. The reported sensitivity was 1.0, while the specificity was 0.98. Xiao et al. sequentially applied a Prewitt operator, Graham scan, fragmentation and skeletonization algorithms for image analysis to quantify meibomian glands [34]. The agreement between the model results and two ophthalmologists was high with Kappa values larger than 0.8 and low false positive rates (< 0.06). The false negative rate was 0.19, suggesting that some glands were missed by the method. A considerable weakness of this study was that only 15 images were used for model development, and consequently it might not work well on unseen data. Another study automatically graded MGD severity using a Sobel operator, polynomial functions, fragmentation algorithm and Otsu’s method [47]. While the method was found to be faster, the results were significantly different from clinician assessments. Deep learning approaches were used by four studies evaluating meibomian gland features [33,35,41,48]. These systems are fully auto­ mated and apply some of the latest technologies within image analysis. Wang et al. used four different CNNs to determine meibomian gland atrophy [48]. The CNNs were trained to identify meibomian gland drop-out areas and estimate the percentage atrophy in a set of images. Comparison of model predictions with experienced clinicians indicated that the best CNN (ResNet50 architecture) was superior. Yeh et al. developed a method to evaluate meibomian gland atrophy by extracting features from meibography images with a special type of unsupervised CNN before application of a K-nearest neighbors model to allocate a meiboscore [35]. The system achieved an accuracy of 80.9%, out­ performing annotations by the clinical team. Moreover, hierarchical clustering of the extracted features from the CNN could show relation­ ships between meibography images. Another study used a CNN to automatically assess meibomian gland characteristics [41]. Images from two different devices collected from various hospitals were used to train and evaluate the CNN. This is an example of uncommonly good practice, as most medical AI systems are developed and evaluated on data from only one device and/or hospital. The only study to use a GAN archi­ tecture tested it on infrared 3D images of meibomian glands in order to evaluate MGD [33]. Comparing the model output with true labels, the performance scores were better than for state of the art segmentation methods. The Pearson correlations between the new automated method and two clinicians were 0.962 and 0.968. Four of the studies did not evaluate their proposed systems on external data [34,47,53,55]. Since the number of images used for model development was limited, the models can have overfit, and external evaluations should be performed to test how well the systems generalize to new data. 4.6. Tear osmolarity Tear osmolarity is a measure of tear concentration, and high values can indicate dry eyes. Cartes et al. [67] investigated use of machine learning to detect DED based on this test. Four different machine learning models were compared. Noise was added to osmolarity mea­ surements during the training phase, while original data without noise was used for final evaluation. The logistic regression model achieved 85% accuracy. However, since the models were trained and tested on the same data, the reported score is most likely not representative for how well the model generalizes to new data. 4.7. Proteomic analysis Proteomic analysis describes the qualitative and quantitative composition of proteins present in a sample. Grus et al. compared tear proteins in individuals with diabetic DED, non-diabetic DED and healthy controls for discrimination between the groups [72]. The authors used discriminant analysis and principal component analysis combined with k-means clustering. Both models achieved low accuracies when pre­ dicting all three categories. However, classification into DED and non-DED achieved accuracies of 72% and 71% for discriminant analysis and k-means clustering, respectively. In another study by the same group, tear proteins analysed using deep learning discriminated subjects as healthy or having DED with an accuracy of 89% [71]. An accuracy of 71% was achieved using discriminant analysis. A combination of discriminant analysis for detecting the most important proteins and a deep neural network for classification was also investigated [70]. High accuracy, sensitivity and specificity were reported. Discriminant anal­ ysis was also used by Gonzalez et al. in analysis of the tear proteome [69]. The most important proteins were selected to train an artificial neural network to classify tear samples as aqueous-deficient DED, MGD or healthy. The model gave an overall accuracy of 89.3%. Principal component analysis yielded good separation of healthy controls, aqueous-deficient DED and MGD data-points, indicating that the pro­ teins were good candidates for classification of the three conditions. This system achieved the highest accuracy of all the reviewed proteomic studies. Considered together, the results from the four studies [69-72] suggest that neural networks applied alone or together with other techniques perform better than discriminant analysis for detecting DED-related protein patterns in the tear proteome. Jung et al. used a network model based on modularity analysis to describe the tear proteome with respect to immunological and inflam­ matory responses related to DED [68]. In this study, patterns in tears and lacrimal fluid were investigated in patients with DED. Since only 10 subjects were included, the study should be performed on a larger cohort of patients to verify the results. 4.8. Optical coherence tomography Thickening of the corneal epithelium can be a sign of abnormalities in the cornea. Moreover, corneal thickness could potentially be a marker for DED. Kanellopoulos et al. developed a linear regression model to look for possible correlations between corneal thickness metrics measured using anterior segment optical coherence tomography (AS- OCT) and DED [58]. However, neither the model predictions nor per­ formance were reported, making it difficult to assess the usefulness of thinnest corneal thickness; r = Pearson’s correlation coefficient; Nan = not available; NN = neural network; RMSE = root mean squared error; CI = confidence interval; TBUT = fluorescein tear break-up time; PA = pruning algorithm; SA = skeletonization algorithm; FFA = Flood-fill algorithm; * = standard deviations not included in table; ** = 95% confidence intervals not included in table; *** = metrics are calculated as the average of 5 repetitions; **** = metrics are calculated as the average of 10 repetitions; ***** = metrics are calculated as the average from 10-fold crossvalidation; § = metrics are calculated as the average from 6-fold crossvalidation; §§ = metrics are calculated as the average of 100 models. A.M. Storås et al. The Ocular Surface 23 (2022) 74–86 81 Table 2 Overview of the reviewed studies using clinical investigations, part 2 of 2. Study Objective N Clinical Tests Type of Data Type of Algorithm Performance Score(s) Llorens-Quintana C et al. (2019) [47] Evaluate meibomian gland atrophy 149 Oculus Keratograph Meibography images Sobel operator, polynomial function, fragmentation algorithm, Otsu’s method (used sequentially) p-values < 0.05 between automatic method and clinicians Wang J et al. (2019) [48] Evaluate meibomian gland atrophy 706 (images) Oculus Keratograph Meibography images 4 CNNs Meiboscore grading: accuracy = 95.6%, eyelid detection: accuracy = 97.6%, JI = 0.955, atrophy detection: accuracy = 95.4%, JI = 0.667, RMSE = 0.067 (average across 4 meiboscores) Yabusaki K (2019) [49] Diagnose DED 138 (images) Tear interferometer Tear film lipid layer images SVM KI = 0.820, CTRL: F1 score = 0.845, SD = 0.067, aqueous-deficient DED: F1 score = 0.981, SD = 0.023, evaporative DED: F1 score = 0.815, SD = 0.095**** Yang J et al. (2019) [50] Estimate tear meniscus height for DED 69 Slit-lamp images with fluorescence staining Ocular surface images Connected component labelling Mean: p-value < 0.01 (×16 and ×40 magnification), r = 0.626 (×16) and 0.711 (×40), max: p-value < 0.001 (×16 and ×40), r = 0.645 (×16) and 0.847 (×40) Szyperski PD (2018) [51] Diagnose DED 110 Interferometry Videos from lateral shearing interferometry 4 different fractal dimension estimators, linear regression Best estimator: AUROC = 0.786 Hwang H et al. (2017) [52] Estimate tear film lipid layer thickness 34 Lipiscanner 1.0, slit-lamp microscope Tear film lipid layer videos Flood-fill algorithm, Canny edge detection p-value < 0.01 between all MGD groups Koprowski R et al. (2017) [53] Detect MGD 57 Oculus Keratograph Meibography images Riesz pyramid (?), Bezier curve (used sequentially) Accuracy = 99.08%, sensitivity = 1, specificity = 0.98 Peteiro-Barral D et al. (2017) [54] Classify tear film patterns 105 (images) Tearscope plus images Tear film lipid layer images SVM, Decision tree, Naive Bayes, simple NN, Fisher¬ ¥s linear discriminant NN: accuracy = 96%, sensitivity = 92%, specificity = 97%, precision = 92%, F1 score = 0.93, AUCROC = 0.95 Koprowski et al. (2016) [55] Detect MGD 86 Oculus Keratograph Meibography images Otsu’s method, SA, watershed algorithm (used sequentially) Sensitivity = 0.993, specificity = 0.975 Remeseiro B et al. (2016) [56] Classify tear film patterns 128 (images) Tearscope-plus images Tear film lipid layer images SVM Accuracy = 96.09%, precision = 92.00%, sensitivity = 89.66%, specificity = 97.98%, F1 score = 91.23%, processing time = 0.07 s Remeseiro B et al. (2016) [57] Classify tear film patterns 50 (images) Tearscope-plus images Tear film lipid layer images SVM Accuracy = 90.89%, sensitivity = 83.54%, precision = 97.95%, specificity = 86.75% Kanellopoulos AJ et al. (2014) [58] Diagnose DED 70 Fourier-domain AS-OCT system: corneal and corneal epithelial thickness maps Corneal examination Linear regression (correlation between DED and thickness) Nan Ramos L et al. (2014) [59] Estimate TBUT 18 (videos) Videos from TBUT (slit- lamp) TBUT videos Polynomial function Specificity = 89% (parameter b) and 82% (parameter e), specificity = 84% and 80% Ramos L et al. (2014) [60] Estimate TBUT 18 (videos) Videos from TBUT (slit- lamp) TBUT videos Polynomial function Accuracy = ""more than 90%"" Remeseiro et al. (2014) [61] Classify tear film patterns 511 (images) Tearscope-plus images Tear film lipid layer images Markov random field, SVM (used sequentially) Accuracy = 97.14%, accuracy (noisy data) = 92.61%***** García-Resúa C et al. (2013) [62] Classify tear film patterns 105 Tearscope-plus images Tear film lipid layer images K-nearest neighbors Cram´er’s V = 0.9, r = 0.94, p-value < 0.001, accuracy = 86.2% § Rodriquez JD (2013) [63] Evaluate ocular redness 26 Slit-lamp, digital camera Images of conjunctiva Sobel operator, MLR (used sequentially) Accuracy = 100%, r = 0.76, concordance correlation = 0.76 (compared to 5 investigators)* Koh YW et al. (2012) [64] Detect MGD 55 Slit-lamp biomicroscope, upper eye lid IR meibography images PA, SA, FFA, SVM (used sequentially) Specificity = 96.1%, SD = 0.4%, sensitivity = 97.9%, SD = 0.6% §§ Yedidya T et al. (2009) [65] Estimate TBUT 22 (videos) Video from TBUT TBUT videos Markov random field Mean difference in TBUT = 2.34s Yedidya T et al. (2007) [13] Detect dry areas 8 (videos) Video from TBUT TBUT videos Levenberg-Marquardt Accuracy = 91% (84-96%), SD = 4% Mathers WD et al. (2004) [66] Investigate DED 513 Schirmer’s test, meibomian gland drop- out, lipid viscosity and volume, tear evaporation Clinical test results Hierarchical clustering, decision tree Nan Abbreviations: N = number of subjects; DED = dry eye disease; IVCM = in vivo confocal microscopy; DC = dendritic cell; GLM = generalized linear model; MLR = multiple linear regression; CFS = corneal fluorescein score; AS-OCT = anterior segment optical coherence tomography; CNN = convolutional neural network; AUROC = area under reciever operating characteristic curve; AUPRC = area under precision-recall curve; MGD = meibomian gland dysfunction; GAN = generative adversarial network; P-HD = average Pompeiu-Hausdorff distance; JI = Jaccard index; KI = Kappa index; CTRL = healthy; FPR = false positive rate; FNR = false negative rate; SVM = support vector machine; RF = random forest; RT = random tree; DNN = deep neural network; SD = standard deviation; CCT = central corneal thickness; TCT = thinnest corneal thickness; r = Pearson’s correlation coefficient; Nan = not available; NN = neural network; RMSE = root mean squared error; CI = confidence interval; TBUT = fluorescein tear break-up time; PA = pruning algorithm; SA = skeletonization algorithm; FFA = Flood-fill algorithm; * = standard deviations not included in table; ** = 95% confidence intervals not included in table; *** = metrics are calculated as the average of 5 repetitions; **** = metrics are calculated as the average of A.M. Storås et al. The Ocular Surface 23 (2022) 74–86 82 the study. The type of instrument used to determine the corneal thick­ ness was found to affect the results [39]. Measurements from AS-OCT and Pentacam were compared and multivariable regression was used to detect differences between the two techniques regarding the measured central corneal thickness and the thinnest corneal thickness. Individuals with mild DED, severe DED and healthy subjects were examined. The two techniques gave significantly different results in terms of the resulting β-coefficients in the multivariable regression model for individuals with severe DED. Images from clinical examina­ tions with AS-OCT were used to diagnose DED [32]. A pretrained VGG19 CNN [81] was fine-tuned using separate images for training and vali­ dation. Two similar CNN models were developed, and evaluation was performed on an external test set. Both achieved impressively high performance scores. The AUC values were 0.99 and 0.98. This is one out of two studies in this review that used an independent test sets after model development. Such practice is essential for a realistic impression of how well the model generalizes to new data not used during model development. The good performance is likely linked to the large amounts of training data (29, 000 images), which is essential for deep learning methods. Most of the re-viewed studies use significantly smaller data sets, which constitutes a disadvantage. Stegmann et al. analysed OCT images from healthy subjects for automatic detection of the lower tear meniscus [42]. Two different CNNs were trained and evaluated using 5-fold cross validation. The tear menisci detected by the models were compared to evaluations from an experienced grader. The best CNN achieved an average accuracy of 99.95%, sensitivity of 0.9636 and specificity of 0.9998. The system is promising regarding fast and accu­ rate segmentation of OCT images. However, more images from different OCT systems, including non-healthy subjects, should be used to verify and improve the analysis. The two studies [42,81] showed that CNNs could be an appropriate tool for image analysis. CNNs are likely to increase in popularity within 10 repetitions; ***** = metrics are calculated as the average from 10-fold crossvalidation; § = metrics are calculated as the average from 6-fold crossvalidation; §§ = metrics are calculated as the average of 100 models. Table 3 Overview of the reviewed studies using biochemical investigations. Study Objective N Clinical Tests Type of Data Type of Algorithm Performance Score(s) Cartes C et al. (2019) [67] Diagnose DED 40 Tear-Lab Osmometer Tear osmolarity measurements LR, Naive Bayes, SVM, RF LR: accuracy = 85% Jung JH et al. (2017) [68] Detect protein patterns in DED 10 Pooled tear and lacrimal fluid, analysed with LC-MS, trypsin digestion, RP-LC fractionation Proteins in tears and lacrimal fluid ""Network model"" based on betweenness centrality Nan Gonzalez N (2014) [69 Diagnose DED 93 Peptide/protein analysis: gel electrophoresis (SDS-PAGE) Peptides and proteins in tears Discriminant analysis, principal component analysis, NN Accuracy = 89.3%, CTRL: sensitivity = 0.99, specificity = 0.96, MGD: sensitivity = 0.85, specificity = 0.96, aqueous-deficient DED: sensitivity = 0.83, specificity = 0.93* Grus FH et al. (2005) [70] Diagnose DED 159 Schirmer’s test with anesthesia, tears analysed by LC-MS Proteins in tears Discriminant analysis, DNN (used sequentially) AUROC = 0.93, sensitivity and specificity = ‘‘approx. 90% each’’ Grus FH et al. (1999) [71] Diagnose DED 60 Protein analysis: gel electrophoresis (SDS-PAGE) Proteins in tears DNN, discriminant analysis DNN: accuracy = 89%, discriminant analysis: accuracy = 71% Grus FH et al. (1998) [72] Diagnose DED 119 Protein analysis: gel electrophoresis (SDS-PAGE) Proteins in tears Principal component analysis, K-means clustering (used sequentially), discriminant analysis K-means: accuracy = 71% (DED vs CTRL) and 42% (DED, diabetes-DED, CTRL), discriminant analysis: accuracy = 72% (DED vs CTRL) and 43% (DED, diabetes-DED, CTRL) Abbreviations: N = number of subjects; DED = dry eye disease; LR = logistic regression; SVM = support vector machine; RF = random forest; AUROC = area under reciever operating characteristic curve; MGD = meibomian gland dysfunction; CTRL = healthy; DNN = deep neural network; Nan = not available; NN = neural network; LC-MS = liquid chromatography mass spectometry; RP-LC = reverse-phase liquid chromatography; SDS-PAGE = sodium dodecyl sulphate-polyacrylamide gel electrophoresis; OSDI = ocular surface disease index; * = metrics are calculated as the average of 10 repetitions. Table 4 Overview of the reviewed studies using demographical investigations. Study Objective N Clinical Tests Type of Data Type of Algorithm Performance Score(s) Choi HR et al. (2020) [73] Investigate DED and dyslipidemia association 2272 OSDI score, health examination, questionnaire Population studies, Korea GLM, LR Nan Nam SM et al. (2020) [74] Detect risk factors for DED 4391 Health examination, health survey, nutrition survey National health survey, Korea Decision tree, Lasso, LR (used sequentially) AUROC = 0.70, 95% CI = 0.61- 0.78, specificity = 68%, sensitivity = 66% Kaido M et al. (2015) [75] Diagnose DED 369 Blink frequency, visual maintenance ratio, questionnaire Functional VA measurement and questionnaire, Japanese visual display terminal workers Discriminant analysis Sensitivity = 93.1%, specificity = 43.7%, precision = 83.8%, NPV = 80.8% Abbreviations: N = number of subjects; DED = dry eye disease; GLM = generalized linear model; AUROC = area under reciever operating characteristic curve; Nan = not available; CI = confidence interval; LR = logistic regression; OSDI = ocular surface disease index; VA = visual acuity; NPV = negative predictive value. A.M. Storås et al. The Ocular Surface 23 (2022) 74–86 83 the field of DED due to promising results for solving image related tasks, including feature extraction. 4.9. Other clinical tests Machine learning models were used to analyse results from a variety of clinical tests to expand understanding of the DED process [66]. The study included subjects with DED and healthy subjects. Subjective cutoff values from clinical tests were used to assign subjects to the DED class. Hierarchical clustering and a decision tree were applied sequentially to group the subjects based on their clinical test results. The resulting groups were compared to the original groups. Because the analysis was based on objective measurements, it could be used to develop more objective diagnostic criteria. This could lead to earlier detection and more effective treatment of DED. Table 5 Overview of the data applied for the analyses. Study Type of Input Data Training Dataset Testing Dataset Reference Standard Clinical Investigations Aggarwal S et al. (2021) [30] Tabular 349 Nan Nan (clinical test results, subjective report) Deng X et al. (2021) [31] Images 253 (images) 232 (images) Senior clinician Elsawy A et al. (2021) [32 Images 29172 (train), 7293 (val) 23760 Certified cornea specialist Khan ZK et al. (2021) [33] Images 90 22 Clinician Xiao P et al. (2021) [34] Images 15 Nan 2 ophthalmologists Yeh C-H et al. (2021) [35] Images 398 (train), 99 (val) 209 Trained clinician da Cruz LB et al. (2020) [36] Tabular 106 (10- fold CV) Nan Optometrist da Cruz LB et al. (2020) [37] Tabular 106 (10- fold CV) Nan Optometrist Fu P-I et al. (2020) [38] Tabular 28 Nan Nan (clinical test results, subjective report) Fujimoto K et al. (2020) [39] Tabular 195 Nan Nan (kerato- conjunctival staining for ac{DED}) Maruoka S et al. (2020) [40] Images 221 (5- fold CV) Nan 3 eyelid specialists Prabhu SM et al. (2020) [41] Images 600 200 Clinical experts Stegmann H et al. (2020) [42] Images 6658 (images) (5-fold CV) Nan Experienced investigator Wei S et al. (2020) [43] Images 5000* 53 (3-5 per patient) Experienced investigator Giannaccare G et al. (2019) [44] Tabular Nan 69 Experienced investigator ~ cite {Chen2017ACCMed} Llorens- Quintana C et al. (2019) [47] Images 149 Nan Clinicians Wang J et al. (2019) [48] Images 398 (train) 99 (val) 209 Experienced clinician Yabusaki K (2019) [49] Tabular 93** 45** Skilled ophthalmologist Yang J et al. (2019) [50] Images 520 Nan ImageJ software Szyperski PD (2018) [51] Tabular 110 Nan Nan Hwang H et al. (2017) [52] Frames 34 Nan Meibomian gland expert Koprowski R et al. (2017) [53] Images 228 (images) Nan Specialized clinicians Peteiro-Barral D et al. (2017) [54] Tabular 105 (LOO CV) Nan Experts Koprowski et al. (2016) [55] Images 172 (images) Nan Ophthalmology expert Remeseiro B et al. (2016) [56] Tabular Nan 128 Optometrists Remeseiro B et al. (2016) [57] Tabular Sampled from test set 50 4 optometrists Tabular 140 Nan Ophthalmologist Table 5 (continued) Study Type of Input Data Training Dataset Testing Dataset Reference Standard Kanellopoulos AJ et al. (2014) [58] Ramos L et al. (2014) [59] Videos 18 Nan 2/4 experts Ramos L et al. (2014) [60] Videos 12 6 4 experts Remeseiro et al. (2014) [61] Tabular 511 (10- fold CV) Nan Experts García-Resúa C et al. (2013) [62] Tabular 105 (6- fold CV) Nan Experienced investigator Rodriquez JD (2013) [63] Tabular 99 (images) Nan 5 trained investigators Koh YW et al. (2012) [64] Tabular 28*** 27*** Experts Yedidya T et al. (2009) [65] Videos 22 Nan Clinician Yedidya T et al. (2007) [13] Frames 8**** Nan Optometrist (evaluated 3 of the 8 patients) Mathers WD et al. (2004) [66] Tabular 513 (10- fold CV) Nan Nan (clinical test results) Biochemical Investigations Cartes C et al. (2019) [67] Tabular 40 (noise added) 40 (no noise) Nan (clinical test results, subjective report) Jung JH et al. (2017) [68] Tabular 10 Nan Ophthalmologist Gonzalez N (2014) [69] Tabular 70% of 93** 30% of 93** Nan (clinical tests) Grus FH et al. (2005) [70] Tabular 50% of 159 50% of 159 Nan (clinical test results, subjective report) Grus FH et al. (1999) [71] Tabular 30 30 Nan (clinical test results, subjective report) Grus FH et al. (1998) [72] Tabular 119 § Nan (clinical test results, subjective report) Demographical Investigations Choi HR et al. (2020) [73] Tabular 2272 Nan Nan (subjective report) Nam SM et al. (2020) [74] Tabular 80% of 4391 20% of 4391 Ophthalmologist Kaido M et al. (2015) [75] Tabular 369 Nan Dry eye specialists Abbreviations: Nan = not available; val = validation; CV = crossvalidation; DED = dry eye disease; LOO = leave one out; * = pretraining images; ** = randomly selected samples, process repeated 10 times; *** = randomly selected samples, process repeated 100 times; **** = 3-5 sequences of video per patient; § = For multivariate analysis model, but the number of samples was not mentioned. A.M. Storås et al. The Ocular Surface 23 (2022) 74–86 84 4.10. Population surveys Population surveys can provide valuable insight regarding the prevalence of DED and help detect risk factors for developing the dis­ ease. Japanese visual terminal display workers were surveyed with the objective of detecting DED [75]. Dry eye exam data and subjective re­ ports were used for diagnosis. This was passed to a discriminant analysis model. When compared to diagnosis by a dry eye specialist, the model showed a high sensitivity of 0.931, but low specificity of 0.437. This is a very low specificity, but is not necessarily bad if the aim is to detect as many cases of DED as possible and there is less concern about misclas­ sification of healthy individuals. Data from a national health survey were analysed in order to detect risk factors for DED [74]. Here, in­ dividuals were regarded as having DED if they had been diagnosed by an ophthalmologist, and were experiencing dryness. Feature modifications were performed by a decision tree, and the most important features were selected using lasso. β-coefficients from a logistic regression trained on the most important features were used to rank the features. Women, individuals who had received refractive surgery and those with depression were detected as having the highest risk for developing DED. Even though the models in the study were trained on data from more than 3500 participants, the reported performance scores were among the poorest in this review with a sensitivity of 0.66 and a specificity of 0.68. A possible reason could be that the selected features were not ideal for detecting DED. However, the detected risk factors have previously been shown to be associated with DED [3,82,83]. The findings suggest that the data quality from population surveys might not be as high as in other types of studies, which could lead to misinterpretation by the machine learning model. The association between DED and dyslipidemia was investigated by combining data from two population surveys in Korea in Ref. [73]. A generalized linear model was used to investigate linear characteristics between features and the severity of DED. The model showed significant increase in age, blood pressure and prevalence of hypercholesterolemia over the range from no DED to severe DED. Evaluation of the association between dyslipidemia and DED using linear regression showed that the odds ratio for men with dyslipidemia was higher than 1 compared to men without dyslipidemia. This association was not found in women. The study results suggest a positive association between DED and dys­ lipidemia in men, but not in women. 4.11. Future perspectives In order to benchmark existing and future models, we advocate that the field of DED should have a common, centralized and openly avail­ able data set for testing and evaluation. The data should be fully representative for the relevant clinical tests. In order to ensure that models are applicable to all populations of patients, medical institutions, and types of equipment around the world, they must be evaluated on data from different demographic groups of patients across several clinics and, if relevant, from different medical devices. Moreover, the test data set should not be available for model development, but only for final evaluation. A common standard on these processes will increase the reproducibility and comparability of studies. Standardized collection and handling of clinical data and samples would also facilitate com­ parisons between different instruments and clinics [84]. In addition, a cross hospitals/centers data set would solve important challenges of applying AI in clinical practice, such as metrics not reflecting clinical applicability, difficulties in comparing algorithms, and under­ specification. These have all been identified as being among the main obstacles for adoption of any medical AI system in clinical practice [85, 86]. A possible challenge regarding implementation in the clinic is that hospitals do not necessarily use the same data platforms, which might prevent widespread use of machine learning systems. Consequently, solutions for implementing digital applications across hospitals should be considered. Model explanations are important in order to understand why a complex machine learning model produces a certain prediction. For healthcare providers to trust the systems and decide to use them in the clinic, the systems should provide understandable and sound explana­ tions of the decision-making process. Moreover, they could assist clini­ cians when making medical decisions [18]. When developing new machine learning systems within DED, effort should be made to present the workings of the resulting models and their predictions in an easy to interpret fashion. 5. Conclusions We observed a large variation in the type of clinical tests and the type of data used in the reviewed studies. This is also true regarding the extent of pre-processing applied to the data before passing it to the machine learning models. The studies analysing images can be divided into those applying deep learning techniques directly on the images, and those performing extensive pre-processing and feature extraction before the data is passed to the machine learning model in a tabular format. The number of studies belonging to the first group has increased significantly over the past 3 years. As deep learning techniques become more estab­ lished, these will probably replace more traditional image pre- processing and feature extraction techniques. We noted that there was a lack of consensus regarding how best to perform model development, including evaluation. This made it difficult to estimate how well some models will perform in the clinic and with new patients, and also to compare the different models. Comparison was further complicated by the use of different types of performance scores. In addition there was no culture of data and code sharing, which makes reproducibility of the results impossible. For the future, focus should be put on establishing data and code sharing as a standard procedure. In conclusion, the results from the different studies’ machine learning models are promising, although much work is still needed on model development, clinical testing and standardisation. AI has a high potential for use in many different applications related to DED, including automatic detection and classification of DED, investigation of the etiology and risk factors for DED, and in the detection of potential biomarkers. Effort should be made to create common guidelines for the model development process, especially regarding model evaluation. Prospective testing is recommended in order to evaluate whether pro­ posed models can improve the diagnostics of DED, and the health and quality of life of patients with DED. Declaration of competing interest The authors report no conflicts of interest. Appendix A. Supplementary data Supplementary data to this article can be found online at org/10.1016/j.jtos.2021.11.004. References [1] Stapleton F, Alves M, Bunya VY, Jalbert I, Lekhanont K, Malet F, Na K-S, Schaumberg D, Uchino M, Vehof J, et al. TFOS DEWS II epidemiology report. Ocul Surf 2017;15(3):334–65. [2] Geerling G, Tauber J, Baudouin C, Goto E, Matsumoto Y, O’Brien T, Rolando M, Tsubota K, Nichols KK. The international workshop on meibomian gland dysfunction: report of the subcommittee on management and treatment of meibomian gland dysfunction. Investig Ophthalmol Vis Sci 2011;52(4):2050–64. [3] Matossian C, McDonald M, Donaldson KE, Nichols KK, MacIver S, Gupta PK. Dry eye disease: consideration for women’s health. J Wom Health 2019;28(4):502–14. dx.d oi.org/10.1089/jwh.2018.7041. [4] Nichols JJ, Ziegler C, Mitchell GL, Nichols KK. Self-reported dry eye disease across refractive modalities. Investig Ophthalmol Vis Sci 2005;46(6):1911–4. org/10.1167/iovs.04-1294. A.M. Storås et al. The Ocular Surface 23 (2022) 74–86 85 [5] Zhang X, Zhao L, Deng S, Sun X, Wang N. Dry eye syndrome in patients with diabetes mellitus: prevalence, etiology, and clinical characteristics. J Ophthalmol 2016. 2016. [6] Mandell JT, Idarraga M, Kumar N, Galor A. Impact of air pollution and weather on dry eye. J Clin Med 2020;9(11). [7] Willcox MD, Argüeso P, Georgiev GA, Holopainen JM, Laurie GW, Millar TJ, Papas EB, Rolland JP, Schmidt TA, Stahl U, et al. TFOS DEWS II tear film report. Ocul Surf 2017;15(3):366–403. [8] McCarthy J, Minsky ML, Rochester N, Shannon CE. A proposal for the Dartmouth summer research project on Artificial Intelligence, august 31, 1955. AI Mag 2006; 27(4). 12-12. [9] Legg S, Hutter M. Universal intelligence: a definition of machine intelligence. Minds Mach 2007;17(4):391–444. [10] Schmidt-Erfurth U, Sadeghipour A, Gerendas BS, Waldstein SM, Bogunovi´c H. Artificial Intelli- gence in retina. Prog Retin Eye Res 2018;67:1–29. org/10.1016/j.preteyeres.2018.07.004. [11] De Fauw J, Ledsam JR, Romera-Paredes B, Nikolov S, Tomasev N, Blackwell S, Askham H, Glorot X, O’Donoghue B, Visentin D, et al. Clinically applicable deep learning for diagnosis and referral in retinal disease. Nat Med 2018;24(9):1342–50. [12] Cię˙zar K, Pochylski M. 2D fourier transform for global analysis and classification of meibomian gland images. Ocul Surf 2020;18(4):865–70. j.jtos.2020.09.005. 420301452. [13] Yedidya T, Hartley R, Guillon J-P, Kanagasingam Y. Automatic dry eye detection. In: International conference on medical image computing and computer-assisted intervention. Springer; 2007. p. 792–9. 75757-3_96. [14] Nielsen KB, Lautrup ML, Andersen JK, Savarimuthu TR, Grauslund J. Deep learning-based algorithms in screening of diabetic retinopathy: a systematic review of diagnostic performance. Ophthalmol Retina 2019;3(4):294–304. org/10.1016/j.oret.2018.10.014. [15] Pead E, Megaw R, Cameron J, Fleming A, Dhillon B, Trucco E, MacGillivray T. Automated detection of age-related macular degeneration in color fundus photography: a systematic review. Surv Ophthalmol 2019;64(4):498–511. https:// doi.org/10.1016/j.survophthal.2019.02.003. ence/article/pii/S0039625718302078. [16] Gensure RH, Chiang MF, Campbell JP. Artificial Intelligence for retinopathy of prematurity. Curr Opin Ophthalmol 2020;31(5):312–7. ICU.0 000000000000680. [17] Esteva A, Kuprel B, Novoa RA, Ko J, Swetter SM, Blau HM, Thrun S. Dermatologist- level classification of skin cancer with deep neural networks. Nature (London) 2017;542:115–8. [18] Lundberg SM, Nair B, Vavilala MS, Horibe M, Eisses MJ, Adams T, Liston DE, Low DK-W, Newman S-F, Kim J, Lee S-I. Explainable machine-learning predictions for the prevention of hypoxaemia during surgery. Nat Biomed Eng 2018;2:749–60. [19] Gulshan V, Peng L, Coram M, Stumpe MC, Wu D, Narayanaswamy A, Venugopalan S, Widner K, Madams T, Cuadros J, Kim R, Raman R, Nelson PC, Mega JL, Webster DR. Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus pho- tographs. J Am Med Assoc 2016;316(22):2402–10. [20] Yousefi S, Takahashi H, Hayashi T, Tampo H, Inoda S, Arai Y, Tabuchi H, Asbell P. Predicting the likelihood of need for future keratoplasty intervention using artificial intelligence. Ocul Surf 2020;18(2):320–5. jtos.2020.02.008. 420300276. [21] Hastie T, Tibshirani R, Friedman J. The elements of statistical learning: data mining, inference, and prediction. Springer Science & Business Media; 2009. 2010.00646_6.x. [22] Palacio-Ni˜no J-O, Berzal F. Evaluation metrics for unsupervised learning algorithms. 2019, 05667. arXiv: 1905. [23] Le Berre C, Sandborn WJ, Aridhi S, Devignes M-D, Fournier L, Smaïl-Tabbone M, Danese S, Peyrin-Biroulet L. Application of artificial intelligence to gastroenterology and hepatology. Gastroenterology 2020;158(1):76–94. https:// doi.org/10.1053/j.gastro.2019.08.058. [24] Thrall JH, Li X, Li Q, Cruz C, Do S, Dreyer K, Brink J. Artificial intelligence and machine learning in radiology: opportunities, challenges, pitfalls, and criteria for success. J Am Coll Radiol 2018;15(3):504–8. jacr.2017.12.026. [25] Thambawita VL, Strümke I, Hicks S, Riegler MA, Halvorsen P, Parasa S. Data augmentation using generative adversarial networks for creating realistic artificial colon polyp images: validation study by endoscopists. Gastrointest Endosc 2021;93 (6):AB190. [26] Gianfrancesco MA, Tamang S, Yazdany J, Schmajuk G. Potential biases in machine learning al- gorithms using electronic health record data. JAMA Int Med 2018;178 (11):1544–7. [27] G´eron A. Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: concepts, tools, and techniques to build intelligent systems. O’Reilly Media; 2019. [28] European Commission. Proposal for a regulation laying down harmonised rules on Artificial Intelligence. 4, sal-regulation-laying-down-harmonised-rules-artificial-intelligence; 2021. [29] U.S. Food & Drug Administration. Artificial intelligence and machine learning (AI/ ML) software as a medical device (SaMD) action plan. 2021. 1, gov/medical-devices/software-medical-device-samd/artificial-intelligence-and -machine-learning-software-medical-device. [30] Aggarwal S, Kheirkhah A, Cavalcanti BM, Cruzat A, Jamali A, Hamrah P. Correlation of corneal immune cell changes with clinical severity in dry eye disease: an in vivo confocal microscopy study. Ocul Surf 2021;19:183–9. https:// doi.org/10.1016/j.jtos.2020.05.012. article/pii/S1542012420300963. [31] Deng X, Tian L, Liu Z, Zhou Y, Jie Y. A deep learning approach for the quantification of lower tear meniscus height. Biomed Signal Process Control 2021; 68:102655. rect.com/science/article/pii/S1746809421002524. [32] Elsawy A, Eleiwa T, Chase C, Ozcan E, Tolba M, Feuer W, Abdel-Mottaleb M, Abou Shousha M. Multidisease deep learning neural network for the diagnosis of corneal diseases. Am J Ophthalmol 2021;226:252–61. ajo.2021.01.018. 421000398. [33] Khan ZK, Umar AI, Shirazi SH, Rasheed A, Qadir A, Gul S. Image based analysis of meibomian gland dysfunction using conditional generative adversarial neural network. BMJ Open Ophthalmol 2021;6(1). 2020-000436. arXiv: [34] Xiao P, Luo Z, Deng Y, Wang G, Yuan J. An automated and multiparametric algorithm for objective analysis of meibography images. Quant Imag Med Surg 2021;11(4):1586–99. [35] Yeh C-H, Yu SX, Lin MC. Meibography phenotyping and classification from unsupervised discrim- inative feature learning. Transl Vis Sci Technol 2021;10(2). 4-4. arXiv:arvojournals.org/arvo/content \_public/journal/tvst/938516/i2164-2591-10-2-4\_16125 19083.80616.pdf. [36] da Cruz LB, Souza JC, de Sousa JA, Santos AM, de Paiva AC, de Almeida JDS, Silva AC, Junior GB, Gattass M. Interferometer eye image classification for dry eye categorization using phylogenetic diversity indexes for texture analysis. Comput Methods Progr Biomed 2020;188:105269. cmpb.2019.105269. 169260719310995. [37] da Cruz LB, Souza JC, de Paiva AC, de Almeida JDS, Junior GB, Aires KRT, Silva AC, Gattass M. Tear film classification in interferometry eye images using phylogenetic diversity indexes and ripley’s k function. IEE J Biomed Health Inf 2020;24(12):3491–8. [38] Fu P-I, Fang P-C, Ho R-W, Chao T-L, Cho W-H, Lai H-Y, Hsiao Y-T, Kuo M-T. Determina- tion of tear lipid film thickness based on a reflected placido disk tear film analyzer. Diagnostics 2020;10(6). diagnostics10060353. [39] Fujimoto K, Inomata T, Okumura Y, Iwata N, Fujio K, Eguchi A, Nagino K, Shokirova H, Kara- sawa M, Murakami A. Comparison of corneal thickness in patients with dry eye disease using the pentacam rotating scheimpflug camera and anterior segment optical coherence tomography. PLoS One 2020;15(2):e0228567. [40] Maruoka S, Tabuchi H, Nagasato D, Masumoto H, Chikama T, Kawai A, Oishi N, Maruyama T, Kato Y, Hayashi T, Katakami C. Deep neural network-based method for detecting obstructive meibomian gland dysfunction with in vivo laser confocal microscopy. Cornea 2020;39(6):720–5. ICO.0000000000002279. [41] Prabhu SM, Chakiat A, S S, Vunnava KP, Shetty R. Deep learning segmentation and quantification of meibomian glands. Biomed Signal Process Control 2020;57: 101776. t.com/science/article/pii/S174680941930357X. [42] Stegmann H, Werkmeister RM, Pfister M, Garh¨ofer G, Schmetterer L, dos Santos VA. Deep learn- ing segmentation for optical coherence tomography measurements of the lower tear meniscus. Biomed Opt Express 2020;11(3): 1539–54. org/boe/abstract.cfm?URI=boe-11-3-1539. [43] Wei S, Ren X, Wang Y, Chou Y, Li X. Therapeutic effect of intense pulsed light (ipl) combined with meibomian gland expression (mgx) on meibomian gland dysfunction (mgd). J Ophthalmol 2020;2020. 3684963. [44] Giannaccare G, Pellegrini M, Sebastiani S, Moscardelli F, Versura P, Campos EC. In vivo confo- cal microscopy morphometric analysis of corneal subbasal nerve plexus in dry eye disease using newly developed fully automated system. Graefe’s Arch Clin Exp Ophthalmol 2019;257(3):583–9. 007/s00417-018-04225-7. [45] Chen X, Graham J, Dabbah MA, Petropoulos IN, Tavakoli M, Malik RA. An automatic tool for quantification of nerve fibers in corneal confocal microscopy images. IEEE (Inst Electr Electron Eng) Trans Biomed Eng 2017;64(4):786–94. [46] Dabbah M, Graham J, Petropoulos I, Tavakoli M, Malik R. Automatic analysis of diabetic peripheral neuropathy using multi-scale quantitative morphology of nerve fibres in corneal confocal microscopy imaging. Med Image Anal 2011;15(5): 738–47. 11.05.016. rect.com/science/article/pii/S1361841511000806. [47] Llorens-Quintana C, Rico-Del-Viejo L, Syga P, Madrid-Costa D, Iskander DR. A novel automated approach for infrared-based assessment of meibomian gland morphology. Transl Vis Sci Technol 2019;8(4). tvst.8.4.17. 17-17. [48] Wang J, Yeh TN, Chakraborty R, Yu SX, Lin MC. A deep learning approach for meibomian gland atrophy evaluation in meibography images. Transl Vis Sci Technol 2019;8(6). 37-37. A.M. Storås et al. The Ocular Surface 23 (2022) 74–86 86 [49] Yabusaki K, Arita R, Yamauchi T. Automated classification of dry eye type analyzing interference fringe color images of tear film using machine learning techniques. Model Artif Intell Ophthalmol 2019;2(3):28–35. 10.35119/maio.v2i3.90. [50] Yang J, Zhu X, Liu Y, Jiang X, Fu J, Ren X, Li K, Qiu W, Li X, Yao J. TMIS: a new image-based software application for the measurement of tear meniscus height. Acta Ophthalmol 2019;97(7):e973–80. [51] Szyperski PD. Comparative study on fractal analysis of interferometry images with application to tear film surface quality assessment. Appl Opt 2018;57(16):4491–8. [52] Hwang H, Jeon H-J, Yow KC, Hwang HS, Chung E. Image-based quantitative analysis of tear film lipid layer thickness for meibomian gland evaluation. Biomed Eng Online 2017;16(1):1–15. [53] Koprowski R, Tian L, Olczyk P. A clinical utility assessment of the automatic measurement method of the quality of meibomian glands. Biomed Eng Online 2017;16(82):1–13. [54] Peteiro-Barral D, Remeseiro B, M´endez R, Penedo MG. Evaluation of an automatic dry eye test using mcdm methods and rank correlation. Med Biol Eng Comput 2017;55(4):527–36. [55] Koprowski R, Wilczy´nski S, Olczyk P, Nowi´nska A, Węglarz B, Wylęgała E. A quantitative method for assessing the quality of meibomian glands. Comput Biol Med 2016;75:130–8. [56] Remeseiro B, Barreira N, García-Resúa C, Lira M, Gir´aldez MJ, Yebra-Pimentel E, Penedo MG. ideas: a web-based system for dry eye assessment. Comput Methods Progr Biomed 2016;130:186–97. [57] Remeseiro B, Mosquera A, Penedo MG. CASDES: a computer-aided system to support dry eye diagnosis based on tear film maps. IEE J Biomed Health Inf 2016; 20(3):936–43. [58] Kanellopoulos AJ, Asimellis G. In vivo 3-dimensional corneal epithelial thickness mapping as an indicator of dry eye: preliminary clinical assessment. Am J Ophthalmol 2014;157(1):63–8. e2, [59] Ramos L, Barreira N, Pena-Verdeal H, Gir´aldez M. Automatic assessment of tear film break-up dynamics. Stud Health Technol Inf 2014;207:173–82. org/10.3233/978-1-61499-474-9-173. [60] Ramos L, Barreira N, Mosquera A, Penedo M, Yebra-Pimentel E, García-Resúa C. Analysis of parameters for the automatic computation of the tear film break-up time test based on cclru standards. Comput Methods Progr Biomed 2014;113(3): 715–24. t.com/science/article/pii/S0169260713003921. [61] Remeseiro B, Bolon-Canedo V, Peteiro-Barral D, Alonso-Betanzos A, Guijarro- Berdi˜nas B, Mos- quera A, Penedo MG, S´anchez-Maro˜no N. A methodology for improving tear film lipid layer classi- fication. IEE J Biomed Health Inf 2014;18(4): 1485–93. [62] García-Resúa C, Fern´andez MJG, Penedo MFG, Calvo D, Penas M, Yebra- Pimentel E. New software application for clarifying tear film lipid layer patterns. Cornea 2013;32(4):538–46. [63] Rodriguez JD, Johnston PR, Ousler GW, Smith LM, Abelson MB. Automated grading system for evaluation of ocular redness associated with dry eye. Clin Ophthalmol 2013;7:1197–204. [64] Koh YW, Celik T, Lee HK, Petznick A, Tong LH. Detection of meibomian glands and classification of meibography images. J Biomed Opt 2012;17(8):086008. https:// doi.org/10.1117/1.JBO.17.8.086008. [65] Yedidya T, Carr P, Hartley R, Guillon J-P. Enforcing monotonic temporal evolution in dry eye images. In: International conference on medical image computing and computer-assisted intervention. Springer; 2009. p. 976–84. 10.1007/978-3-642-04271-3_118. [66] Mathers WD, Choi D. Cluster analysis of patients with ocular surface disease, blepharitis, and dry eye. Arch Ophthalmol 2004;122(11):1700–4. 10.1001/archo pht.122.11.1700. lmology/articlepdf/416676/eeb30021.pdf. [67] Cartes C, L´opez D, Salinas D, Segovia C, Ahumada C, P´erez N, Valenzuela F, Lanza N, Solís RL, Perez V, et al. Dry eye is matched by increased intrasubject variability in tear osmolarity as confirmed by machine learning approach. Arch Soc Esp Oftalmol 2019;94(7):337–42. [68] Jung JH, Ji YW, Hwang HS, Oh JW, Kim HC, Lee HK, Kim KP. Proteomic analysis of human lacrimal and tear fluid in dry eye disease. Sci Rep 2017;7(1):1–11. [69] Gonz´alez N, Iloro I, Soria J, Duran JA, Santamaría A, Elortza F, Su´arez T. Human tear pep- tide/protein profiling study of ocular surface diseases by spe-maldi-tof mass spectrometry analyses. EuPA Open Proteomics 2014;3:206–15. org/10.1016/j.euprot.2014.02.016. le/pii/S221296851400021X. [70] Grus FH, Podust VN, Bruns K, Lackner K, Fu S, Dalmasso EA, Wirthlin A, Pfeiffer N. SELDI- TOF-MS proteinchip array profiling of tears from patients with dry eye. Investig Ophthalmol Vis Sci 2005;46(3):863–76. 0448. [71] Grus F-H, Augustin AJ. Analysis of tear protein patterns by a neural network as a diagnostical tool for the detection of dry eyes, ELECTROPHORESIS. Int J 1999;20 (4-5):875–80. AID-ELPS875> 3.0.CO;2-V. [72] Grus F, Augustin A, Evangelou N, Toth-Sagi K. Analysis of tear-protein patterns as a diagnostic tool for the detection of dry eyes. Eur J Ophthalmol 1998;8(2):90–7. [73] Choi HR, Lee JH, Lee HK, Song JS, Kim HC. Association between dyslipidemia and dry eye syndrome among the Korean middle-aged population. Cornea 2020;39(2): 161–7. [74] Nam SM, Peterson TA, Butte AJ, Seo KY, Han HW. Explanatory model of dry eye disease using health and nutrition examinations: machine learning and network- based factor analysis from a national survey. JMIR Med Inf 2020;8(2):e16153. [75] Kaido M, Kawashima M, Yokoi N, Fukui M, Ichihashi Y, Kato H, Yamatsuji M, Nishida M, Fukagawa K, Kinoshita S, Tsubota K. Advanced dry eye screening for visual display terminal workers using functional visual acuity measurement: the moriguchi study. Br J Ophthalmol 2015;99(11):1488–92. 10.1136/bjophthalmol-2015-306640. [76] Gullion J-PC. Tear film structure of the contact lens wearer. Ph.D. thesis. London: City University; 1990. [77] Holly FJ. Physical chemistry of the normal and disordered tear film. Trans Ophthalmol Soc U K 1985;104(Pt 4):374–80. [78] Rasband W. Imagej. [79] Cruzat M, Andrea, Qazi M, Yureeda, Hamrah M, Pedram. In vivo confocal microscopy of corneal nerves in health and disease. Ocul Surf 2016;15(1):15–47. [80] Villani E, Marelli L, Dellavalle A, Serafino M, Nucci P. Latest evidences on meibomian gland dysfunction diagnosis and management. Ocul Surf 2020;18(4): 871–92. com/science/article/pii/S1542012420301415. [81] Krizhevsky A, Sutskever I, Hinton GE. Imagenet classification with deep convolutional neural net- works. Commun ACM 2017;60(6):84–90. org/10.1145/3065386. [82] Dartt DA. Dysfunctional neural regulation of lacrimal gland secretion and its role in the pathogenesis of dry eye syndromes. Ocul Surf 2004;2(2):76–91. org/10.1016/S1542- 0124(12)70146-5. [83] Wan K, Chen L, Young A. Depression and anxiety in dry eye disease: a systematic review and meta- analysis. Eye 2016;30:1558–67. eye.2016.186. [84] Ambaw YA, Timbadia DP, Raida M, Torta F, Wenk MR, Tong L. Profile of tear lipid mediator as a biomarker of inflammation for meibomian gland dysfunction and ocular surface diseases: standard operating procedures. The Ocular Surface; 2020. 08. ence/article/pii/S1542012420301488. [85] D’Amour A, Heller K, Moldovan D, Adlam B, Alipanahi B, Beutel A, Chen C, Deaton J, Eisen- stein J, Hoffman MD, et al. Underspecification presents challenges for credibility in modern machine learning. arXiv preprint arXiv:2011.03395. 2020. [86] Kelly CJ, Karthikesalingam A, Suleyman M, Corrado G, King D. Key challenges for delivering clinical impact with artificial intelligence. BMC Med 2019;17(1):1–9. A.M. Storås et al."
Achieving Fair Load Balancing by Invoking a Learning Automata-Based Two-Time-Scale Separation Paradigm,"Yazidi, Anis and Hassan, Ismail and Hammer, Hugo L. and Oommen, B. John",2021,8.0,32,IEEE Transactions on Neural Networks and Learning Systems,article,"3444
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
Achieving Fair Load Balancing by Invoking a
Learning Automata-Based Two-Time-Scale
Separation Paradigm
Anis Yazidi
, Senior Member, IEEE, Ismail Hassan, Hugo L. Hammer
,
and B. John Oommen
, Life Fellow, IEEE
Abstract—In this article, we consider the problem of load bal-
ancing (LB), but, unlike the approaches that have been proposed
earlier, we attempt to resolve the problem in a
fair manner
(or rather, it would probably be more appropriate to describe
it as an ϵ-fair manner because, although the LB can, probably,
never be totally fair, we achieve this by being “as close to fair as
possible”). The solution that we propose invokes a novel stochastic
learning automaton (LA) scheme, so as to attain a distribution
of the load to a number of nodes, where the performance level
at the different nodes is approximately equal and each user
experiences approximately the same Quality of the Service (QoS)
irrespective of which node that he/she is connected to. Since the
load is dynamically varying, static resource allocation schemes
are doomed to underperform. This is further relevant in cloud
environments, where we need dynamic approaches because the
available resources are unpredictable (or rather, uncertain) by
virtue of the shared nature of the resource pool. Furthermore,
we prove here that there is a coupling involving LA’s probabilities
and the dynamics of the rewards themselves, which renders the
environments to be nonstationary. This leads to the emergence
of the so-called property of “stochastic diminishing rewards.”
Our newly proposed novel LA algorithm ϵ-optimally solves the
problem, and this is done by resorting to a two-time-scale-based
stochastic learning paradigm. As far as we know, the results
presented here are of a pioneering sort, and we are unaware of
any comparable results.
Index Terms—Continuous learning automaton (LA), fair load
balancing (LB), resource allocation.
I. INTRODUCTION
I
N THIS article, we consider the problem of load balanc-
ing (LB), which is extremely pertinent in today’s highly
connected world. To put the problem in the right perspec-
tive, we observe that, unarguably, computers, and information
technology have experienced enormous growth and devel-
opment over the past three decades. This unalterable trend
Manuscript received December 18, 2019; revised June 3, 2020; accepted
July 12, 2020. Date of publication August 5, 2020; date of current version
August 4, 2021. The work of B. John Oommen was supported in part
by the Natural Sciences and Engineering Council of Canada (NSERC).
(Corresponding author: B. John Oommen.)
Anis Yazidi, Ismail Hassan, and Hugo L. Hammer are with the Department
of Computer Science, Oslo Metropolitan University, 0130 Oslo, Norway.
B. John Oommen is with the School of Computer Science, Carleton
University, Ottawa, ON K1S5B6, Canada, and also with the IKT Department,
University
of
Agder,
4879
Grimstad,
Norway
(e-mail:
oommen@
scs.carleton.ca).
Color versions of one or more of the ﬁgures in this article are available
online at https://ieeexplore.ieee.org.
Digital Object Identiﬁer 10.1109/TNNLS.2020.3010888
has profoundly affected societies worldwide, in every sense
of the word. Products and services that were traditionally
delivered through other means are, currently, online services.
Unlike the scenario a few decades ago, where one “con-
nected” directly to an institution’s machine, most of these
services are now being executed on the internet. Since more
than 50 billion devices will be connected to the Internet
by 2020 [28], one understands that the traditional model of
having in-house computers and resources is not going to be
a sustainable and viable option. Rather, to cope with the
sheer increase in the number of users and devices inter-
acting with the machines, the respective services delivered
online, government, and business institutions are reducing their
investments in on-premise IT infrastructure. Indeed, to mit-
igate the super-exponential increases in the corresponding
communication and computational costs, they are moving to,
and increasing their spending on, cloud-based services [33].
In this context, we mention that the National Institute of
Standards and Technology (NIST) deﬁnes “cloud computing”
as a model for enabling ubiquitous, convenient, on-demand
network access to a shared pool of conﬁgurable comput-
ing resources (e.g., networks, servers, storage, applications,
and services) that can be rapidly provisioned and released
with minimal management effort or service provider interac-
tion [19]. It is clear that one has to now consider how all these
services can be distributed over the cloud of computers. This,
precisely, involves the problem of LB.
LB is like many other related problems [13]; many instances
of LB are considered NP-Hard problems [31]. Thus, we will
never be able to solve the problem, so as to allocate
the resources in a perfectly balanced manner. Unlike the
approaches that have been proposed in the literature [11],
such as round-robin (RR), weighted RR (WRR), power-
of-two choices (Po2), least connection, and weighted least
connection, we attempt to resolve the problem in an “almost
fair” manner, and we shall refer to such an allocation as an
ϵ-fair balance. In other words, we attempt to achieve this by
being “as close to fair as possible.” While one can attempt
to do this intelligently using any of the available AI-based
paradigms, the solution that we propose invokes a novel
stochastic learning automaton (LA) scheme. Our LA-based
solution distributes the load to a number of nodes, where
the performance level at the different nodes is approximately
2162-237X © 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3445
equal and each user experiences approximately the same
Quality of the Service (QoS) irrespective of the node that
he/she is connected to. Although LA has been applied, in a
classical sense, to solve many resource allocation problems
including LB, to the best of our knowledge, this work is
distinct in two aspects. First, to the best of our knowledge,
there is no theoretical analysis of any LB algorithm in the ﬁeld
of LA. LB usually induces the dynamicity of the environment
as the LA actions will continuously alter the load distribution,
and consequently, render the Environment to be nonstationary.
Thus, such settings deviate from the classical multiarmed
bandit settings where the environment is rather static, and
the reward distribution is not inﬂuenced by the actions of
the LA. The analysis of such cases is much more involved than
stationary cases. The reader should also note that, probably,
the most notable example of a theoretical treatment is found
in [31] and [47], where the LB problem is mapped into a
coordinated strategic game. Second, the success of adopting
LA for solving a real-life problem is dependent on an appro-
priate choice, or more precisely, appropriate engineering of
the reward function. Most of the engineered reward functions
in the context of LA-based LB solutions solely rely on “the
response time” of a server. In this article, we have used a
modiﬁed version of the reward that can infer fairness based
on a dynamic comparison threshold.
How then should a cloud-based service model differ from
a more traditional model? From the reported literature [12],
we submit that a cloud-based infrastructure should make it
easy for a customer to request a resource and to have that
resource provisioned and ready for use, in minutes, rather than
days or weeks. The ability to scale the available resources
on demand, with little or no downtime, is another factor that
makes the cloud preferable over traditional enterprise data
centers.
The cloud-based computing paradigm has transformed the
IT industry profoundly, paving the way to foster new concepts,
such as DevOps and microservices. However, to stay com-
petitive and to also ensure customer satisfaction, companies
offering online services aim to quickly deliver new features
to their customers. Developing and deploying software as
a monolithic application do not fully take advantage of the
beneﬁts of a “cloud computing” paradigm, and many compa-
nies are considering migrating toward microservices [7] and a
cloud-native application approach.
While having many beneﬁts, cloud computing still has some
challenges when it comes to offering an optimized system
and a fair allocation of resources. Available cloud models
do not adequately capture uncertainty, nonhomogeneity, and
dynamic performance changes that are inherent to nonuniform
and shared infrastructures [41]. One of the viable ways to
address challenges related to dynamic performance changes
associated with any uncertainties in the load distribution is to
employ an LB technique.
LB is the process of distributing workloads fairly among
multiple hosts. The major advantage of deploying an LB
solution is to be able to handle more trafﬁc than a single
host can tackle. Another advantage of LB is that such a
system offers high availability such that if one service fails,
others are available to ensure that the application stays up and
running.
In order to achieve an optimal distribution of workloads to
any number of hosts, several algorithms have been developed
throughout the years. LB algorithms are mainly classiﬁed as
being static or dynamic.
Static LB schemes assume that the information governing
the LB-oriented decisions is known in advance [32]. The
LB decisions are made deterministically or probabilistically
when the system starts or boots and remain constant during
runtime. Every time the system restarts, the same values get
loaded. Static LB algorithms are mostly suitable for stable
environments with homogeneous systems.
The nature of a data center or of a cloud implicitly requires
dealing with a mixture of stochastic processes [40]. In contrast
to static algorithms, dynamic LB algorithms do not require
prior knowledge or conﬁguration of the system. To make fairer
load distribution decisions, dynamic LB algorithms monitor
the current runtime state of the system and adapt to changing
loads. The experiments that we report tacitly imply that the
servers are not homogenous, as they need not necessarily be
homogenous, especially in cloud environment. Indeed, one of
the reasons for this is that the types of hardware used for the
servers may be different as well as the unpredictability of the
resources in a cloud environment.
A. Distinctive Properties of Our Solution
Without going into any details of the arguments presented in
the body of this article, it is prudent to mention the distinctive
properties of our proposed solution when it concerns the
learning mechanism itself and the associated analysis. In all
brevity, they can be listed as follows.
1) By virtue of the “fair balance” paradigm, the learning
algorithm initiated by the LA proposed here is distinct
from all the families of LA described in the LA-based
LB literature, such as in [23]. This includes those
from the previously reported families of ﬁxed structure,
variable structure, discretized, and estimator-based LA.
2) To achieve a fair load balance, we encounter an irony.
Thus, it is, indeed, the fact that the more often an
“action” is chosen, the likelihood of the LA choos-
ing it, even more, must subsequently decrease. In other
words, the rewards that are received for any action must
decrease as the action is chosen more frequently. This is
contrary to what the properties of absolute expedience
and ϵ-optimality entail, especially since, in these cases,
the LA aims to converge to an absorbing barrier in the
probability space. To the best of our knowledge, LA that
possesses the phenomenon mentioned here has not been
proposed in the literature.
3) Our solution is characterized by the amazing property
that as any speciﬁc pi(t) increases, the corresponding
reward probability of the action in question decreases.
We refer to this phenomenon as the “stochastic dimin-
ishing return property.” Informally, this means that the
more an action is chosen, the less it will be rewarded.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 3446
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
This involves the two-time-scale LA with barriers, as we
shall explain presently, and also facilitates fair LB.
4) The analysis methods that we use here are both distinct
and unique. The mathematical techniques used for the
various families of LA described in the literature are
each distinct in their own right. The methodology for
the family of ﬁxed structure stochastic automata (FSSA)
involves formulating the Markov chain for the LA,
computing its equilibrium probabilities, and then com-
puting the asymptotic action selection probabilities. The
proofs of convergence for variable structure stochastic
automata (VSSAs) involve the theory of small-step
Markov processes, distance diminishing operators, and
the theory of regular functions. The proofs for dis-
cretized LA involve the asymptotic analysis of the
Markov chain that represents the LA in the discretized
space, whence the
total probability of convergence to
the various actions is evaluated. The proof of estima-
tor/pursuit algorithms concerns two intertwined phenom-
ena, i.e., the convergence of the reward estimates and
the convergence of the action probabilities themselves.
The proof methodology considered in this article utilizes
the theory of small-step Markov processes and distance
diminishing operators, but, unlike the existing LA, they
do not converge to absorbing barriers but ﬁxed points in
the corresponding probability vector space.
5) Historically, the metric for analyzing LA has gener-
ally been ϵ-optimality and absolute expedience. Indeed,
the concept of the Lyapunov stability of an LA solution
has been rarely used with few exceptions [9]. This is,
indeed, the metric that we have invoked.
B. Contributions of This Article
The contributions of this article can be summarized as
follows.
1) We present an LA solution for ensuring the fairness of
load distribution in the ﬁeld of LB.
2) We present deep theoretical results that prove the con-
vergence of our scheme.
3) We use some of the most recent advances in the ﬁeld of
LA that combines the time-separation paradigm and the
phenomenon of artiﬁcial barriers, introduced by Yazidi
and Hammer [51] and Yazidi et al. [52], respectively.
4) We prove that the equilibrium point which the algorithm
converges to is asymptotically Lyapunov stable. The
concept of the Lyapunov stability of an LA solution
has been rarely used, except for a very few reported
results [9].
5) We provide some experimental results that conﬁrm and
justify our theoretical assertions.
C. Organization of This Article
This article is organized as follows. The background and
related work are ﬁrst presented in Section II. In Section III,
we give an introduction to the theory of LA that is central to
this article. Section IV includes the details of our proposed
solution, where we present the scheme itself in Section IV-C
and report the theoretical results proving its convergence to an
optimal equilibrium in Section IV-D. Thereafter, in Section V,
we include the results of rigorous simulations that conﬁrm the
theoretical results. Section VI concludes this article.
II. BACKGROUND AND RELATED WORK
Historically, LB and task scheduling have been two closely
related research areas that have been widely investigated.
However, the literature that reports the use of stochastic LA
to achieve these has been limited.
A stochastic LA model for the decentralized control of job
scheduling in distributed processing systems was presented
by [22]. The algorithm proposed by these authors operates
with absolutely no prior knowledge about the job but rather
adapts to the changing loads of the hosts. The aim of the
proposed algorithm was to provide load-balanced jobs to a
number of hosts and to improve the response time while
achieving this.
To minimize the response time, a heuristic LB scheme
based on the concept of a stochastic LA was implemented
by Kunz [15]. Depending on the status of the current load
distribution, a new task would be scheduled to be executed
either locally or on a remote host. This article employed a
learning scheme with a reward constant A of 0.25 and a
penalty constant B of 0.3. Although many ﬁne details were
not reported in this article, the author claimed to also have
examined other inﬂuences on different numbers of automa-
ton states and the behavior of the scheduler under different
network sizes.
Misra et al. [23] presented a framework based on LA that is
capable of addressing some of the challenges and demands of
various cloud applications. The proposed framework analysis
invoked various performance metrics, such as response time,
parallel execution speed, and job priority. These metrics were
then used to select the appropriate resources, using LA.
A Cost Aware S-model (CA-S) Reward Epsilon-Penalty
method was proposed in [46]. The authors employed an
LA-based solution that sought to reduce the average cost in
serving web requests with replicated web servers, deployed in
different geographical regions. To minimize the cost, the LA
made routing decisions for each incoming request by assess-
ing response times and energy prices at the different server
locations through action selection probabilities. This article
reported very promising experimental results by using the
proposed CA-S method. These results demonstrated that the
total average cost of serving web responses could be reduced
up to 33% compared with the minimum cost ﬂow dynamic
server selection algorithm and up to 49.2% compared with
the traditional RR method.
The problem of optimal priority assignment among two
streams of jobs with unknown characteristics, each with ran-
dom service time and a random arrival time, was addressed
in the doctoral thesis of Meybodi [20]. A threshold was
computed, which was the average service time taken over
both streams, and the response time of a served dispatched
request from the chosen stream by the LA was compared
with that threshold for the inferred LA response. This idea
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3447
of using response time-based threshold in a queuing system
as a mechanism for inferring the response of LA to constitute
the rewards/penalties appeared also in [3]. Similarly, in this
work, we resort to a dynamic threshold computed using a
type of moving average, in contrast to a stationary type of
estimator found in the seminal work of Meybodi [20] and
Meybodi and Lakshmivarhan [21]. Apart from the queuing
system model, this article is different from the work in [20].
Indeed, the LA proposed by Meybodi [20] was absorbing
because the optimal solution was to be exclusively chosen
from one of the priority streams. Furthermore, the dynamics
of the reward probabilities addressed here are much more
complicated in our problem setting. An alternative solution to
the priority assignment problem based on FSSA was proposed
by Srikanta Kumar [14]. The problem was revisited recently
using the theory of Petri Nets and LA in [43] and [44].
However, as our model and solution are distinct, in the interest
of brevity, we shall not expand on these articles any further.
Finally, we emphasize that although LA has been applied in
a few instances in the literature for solving LB problems,
we are not aware of any theoretical analyses of the problems.
The theoretical analysis for this type of LA application is
intrinsically hard due to the dynamic nature of the environment
as the reward dynamics are coupled with the changes in the
actions. LA algorithms in this vein are rather presented as
heuristics with no theoretical guarantees. The only possible
attempt to cast an LA-based LB algorithm into a theoretical
framework was reported in a series of works by the same
research group [31], [47], where the LB problem was mapped
onto a coordinated game.
III. STOCHASTIC LEARNING AUTOMATA
We shall now proceed to present a brief overview of LA [1],
which is the toolkit that we will use to solve the problem.
In psychology, learning is characterized as the act of modi-
fying one’s behavior as a result of acquiring knowledge from
past experience. In the ﬁeld of automata theory, an automaton
can be described as a self-operating machine or control mech-
anism consisting of a set of states, a set of outputs or actions,
an input, a function that maps the current state and input to
the next state, and a function that maps a current state (and
input) to the current output.
The term LA was ﬁrst presented in the survey article by
Narendra and Thathachar (see [27]). LA is well suited for sys-
tems with noisy and incomplete information about the environ-
ment in which they function [1], [16], [26], [27], [29], [34].
The environment is generally stochastic, and the LA lacks
prior knowledge as to which action is the optimal one.
Stochastic LA, which is the probabilistic ﬁnite state machine,
attempts to solve this problem by choosing an initial action
randomly and then updating the action probabilities based on
the response received. The action chosen is dependent on the
action probability distribution vector, which, in turn, is updated
based on the reward/penalty input that the LA receives from
the random environment. This process is repeated until the
optimal action is, hopefully, achieved.
The research on LA is comprehensive, and over the past
decades, several classes have been proposed. LA is mainly
categorized as being FSSA or VSSA. In FSSA, the mapping
between transition and output functions is time-invariant.
Initial research into LA was mainly focused on FSSA.
Tsetlin et al. [42] demonstrated several models of this class
of automata. Gradually, research into LA has been advanced
toward VSSA. LA schemes in this category possess transition
and output functions that evolve as the learning process
proceeds [30]. In VSSA, the state transitions or the action
probabilities are updated at every time step. This class of
automata was introduced by Varshavskii and Vorontsova [45]
in the early 1960s.
LA can further be classiﬁed as either ergodic or endowed
with absorbing barriers based on their Markovian properties.
In an ergodic LA system, the ﬁnal steady state is independent
of the initial state. As opposed to this, for LA with absorbing
barriers, the steady state depends on the initial state, and
once the LA has converged, it will be locked into a so-called
absorbing barrier. Furthermore, while ergodic VSSA is suitable
for nonstationary environments, absorbing barrier VSSA is
preferred in stationary environments. As opposed to these,
a unique property of the work in [53] is that the action with
the highest probability may not be the same one being chosen
most frequently.
Stochastic LA had been utilized in many applications
over the years. Recent applications of LA include resource
usage prediction algorithm for cloud computing environ-
ment [35], channel selection in cognitive radio/dynamic spec-
trum access for WiMAX networks [24], distributed network
formation [6], solutions to the single elevator problem [10],
efﬁcient decision making mechanism for stochastic nonlinear
resource allocation [52], dynamic cost-aware routing of web
requests [46], learning periodic spatiotemporal patterns [50],
content placement in cooperative caching [49], resource selec-
tion in computational grids [8], determining proper subset size
in high-dimensional spaces [38], and image segmentation [37],
to mention a few.
IV. LA LOAD-BALANCING MODEL
In this section, we present our LA model for LB, as well
as the theoretical proofs for the solution’s convergence.
A. Model
We consider a scenario where we have a set of r servers.
Each server is modeled as an M/M/1 queue, which means
that arrivals are modeled by a Poisson process with some
intensity λi, and the job service times have an exponential
distribution with a service rate μi.
In our model, we assume that an LA is responsible for dis-
patching the request. The LA sends the request to server i with
probability pi(t). We will later deﬁne the update equations for
the LA. However, for the sake of simplicity, we shall give, ﬁrst,
the overall idea for the different updates involved here at the
two time scales, and subsequently, in Section IV-B, we shall
delve into the LA’s detailed update equations.
By virtue of the M/M/1 queue, the mean-response time at
server i is
MRTi(t) =
1
μi −λi(t)
(1)
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 3448
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
where λi(t) is the average arrival rate at server i. If {pi}
are constant or vary slowly over time, then λi(t) can be
approximated using λi(t) = pi(t)λ, which is a consequence
of the M/M/1 queue model [17].
Let si(t) be the instantaneous response time of server i
at time t. In order to estimate the average response time of
each server (i.e., ˆsi), we merely use the exponential mov-
ing average approach with the learning parameter α. The
parameter α is the learning parameter of the scheme and is
similar to the parameter used in any learning algorithm. It is a
hyperparameter determined by a “rule of thumb” or trial and
error for the particular setting. A larger value of α implies
a larger step away from the current value, and vice versa.
This, in turn, illustrates the speed-accuracy dilemma of the
estimate.
Let ˆsi(t) be the estimate of the average response time of
server i.
Once the action i is polled, i.e., the request is dispatched to
server i, the estimate ˆsi(t + 1) of the average is immediately
updated using an adaptive estimator, namely, the exponential
moving average given by
ˆsi(t + 1) = ˆsi(t) + α(si(t) −ˆsi(t)).
(2)
The average response time for the other severs (actions) are
left unchanged. In other words
ˆs j(t + 1) = ˆs j(t) for j ̸= i,
j ∈[1, n].
(3)
We now consider how the corresponding rewards and
penalties are constructed. If action i is chosen, the reward
or penalty is constructed as following using some type of
dynamic threshold:
1) reward if ˆsi ≤(1/r) r
k=1 ˆsk;
2) penalty if ˆsi > (1/r) r
k=1 ˆsk.
With these deﬁnitions as a backdrop, we are able to formally
present the steps of our algorithm.
B. Initialization Criteria
Without any knowledge of ˆsi, which is estimated using
an exponential moving average as per (2), we have opted
to initialize ˆsi to a random low value of response time
close to zero. As in any exponential moving average scheme,
the value that we use for this initialization is not critical.
In our experiments, we assigned this value as ˆsi(0) for all
the r servers. This is in line with the spirit of what is done
in LA, where the initialization is achieved by values that are
equal. In fact, without the accurate knowledge of initial LA’s
action probability, the initial probability for each action i is
usually set to (pi(0) = (1/r)). In our case, we have also
veriﬁed experimentally that the initial value of ˆsi does not
have any effect on the long-term convergence behavior of the
scheme that is an observation consistent with the behavior of
the exponential moving average schemes that are ergodic by
nature. However, in real-life settings, the experimenter might
assign an initial value of ˆsi that is more informed based on an
a priori knowledge of server i. In this case, one might also
alter the initial LA probabilities, so as to move away from the
uniform distribution, i.e., pi(0) = (1/r).
C. Details of Our Solution: Two-Time-Scale LA With Barriers
The ﬁrst step in our solution process is to see how we
can transform the Markov process given by the probability
space from being absorbing to being ergodic. The reader
who is aware of the ﬁeld of Markov chains will immediately
recognize that this is, actually, the converse of what the
literature [5], [39]1 reports when an ergodic chain is rendered
artiﬁcially absorbing, as in the families of artiﬁcially absorbing
discretized LA, such as ADLRP and ADLIP [30]. Rather than
using the actual limits of the probability space to be zero and
unity, we work with the constraint that no probability value can
take on value below a prespeciﬁed lower threshold of pmin or
a value above a prespeciﬁed upper threshold of pmax [51]. The
action-choosing probability values, which traditionally move
proportionally toward zero and unity for the LRI scheme, for
example, are now made to move toward the respective values
of pmin and pmax, respectively. Interestingly enough, this minor
modiﬁcation renders the scheme to be ergodic, making the
analysis also to be correspondingly distinct from that of LRI
and similar schemes.
To achieve this, we enforce a minimal value pmin, where 0 <
pmin < 1 for each selection probability xi, where 1 ≤i ≤r
and r is the number of actions. As a result, the maximum value
any selection probability pi, where 1 ≤i ≤r, can achieve is
pmax = 1 −(r −1)pmin. This happens when the other r −1
actions take their minimum value pmin, while the action with
the highest probability takes the value pmax. Consequently, pi,
for 1 ≤i ≤r, will take values in the interval [pmin, pmax].
To proceed with the formulation, let α(t) be the index of
the chosen action at time instant t. Then, the value of pi(t) is
updated as per the following simple rule (the rules for other
values of p j(t), j ̸= i, are analogous):
pi(t + 1) ←pi(t) + θ(pmax −pi(t))
when α(t) = i and vi = 1
pi(t + 1) ←pi(t) + θ(pmin −pi(t))
when α(t) = j,
j ̸= i and vi = 1
where θ is a user-deﬁned parameter 0 < θ < 1, typically close
to zero. Furthermore, vi is a reward function indicator deﬁned
as follows.
1) vi = 1, reward, if the instantaneous response of the
chosen server is under the running moving average of
the mean response time si ≤(1/r) r
k=1 ˆsk.
2) vi = 0, penalty, if the instantaneous response of the
chosen server exceeds the running moving average of
the mean response time ˆsi > (1/r) r
k=1 ˆsk.
In our algorithm, we avoid using a classical projection
method to map the solution to our feasible space, implying that
all components of the probability vector are within the interval
[pmin, pmax]. Projection methods have been earlier used in
the ﬁeld of LA for enforcing artiﬁcial barriers. A prominent
example of this is given by Simha and Kurose [39] who tackled
a number of actions r > 2, which is a more challenging
1The projection method is a classical method in constrained optimization
[5] that ensures that the solution is mapped back in the feasible search space
whenever it falls outside. The relative reward LA devised [39] adopts artiﬁcial
barriers for more than two actions using the projection method.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3449
Algorithm 1 Two-Time-Scale-Based LA Solution
Loop
1. Poll an action at time instant t according to the probability
vector [p1, p2, . . . , pr].
2. Updating the response time estimates.
• Update the response time of the chosen action
ˆsi(t + 1) = ˆsi(t) + α(si(t) −ˆsi(t))
• The response estimates for the other actions are kept
unchanged, and so
ˆs j(t + 1) = ˆs j(t) for j ̸= i, j ∈[1,r]
3. Environment response: Reward/Penalty.
• vi = 1 (Reward) if ˆsi ≤1
r
r
k=1 ˆsk;
• Otherwise, vi = 0 (Penalty).
4. Let α(t) be the index of the chosen action at time instant t.
The value of pi(t) is updated as per the following simple
rule below, (where the update rules for other values of
p j(t), j ̸= i, are similar)
pi(t + 1) ←pi(t) + θ(pmax −pi(t))
when α(t) = i
and vi = 1
pi(t + 1) ←pi(t) + θ(pmin −pi(t))
when α(t) = j, j ̸= i
and vi = 1.
scenario than he two-action scenario. However, our approach
does not involve projection methods as the update equations
will always ensure that the probabilities will be in our feasible
space. Furthermore, in contrast to projection methods, our
LA update methodology naturally ensures that the probability
vector will always sum to unity in a manner that can be seen
to be a generalization of the LRI LA. The classical LRI LA
can be seen as an instance of our algorithm with pmax = 1.
Let the average of all the instantaneous response times of
all the nodes at time t be given by ˆs(t) deﬁned by
ˆs(t) = 1
r
r

k=1
ˆsk(t).
(4)
We also introduce the following notation:
Di(t) = Prob(si(t) ≤ˆs(t))
(5)
where ˆs(t) is given by (4).
A consequence of these assignments is a scheme formalized
by the pseudocode given in Algorithm 1. The algorithm
proceeds as follows in a loop. Each time a request is received,
the LA probability vector is used to choose a server by
polling an action, which corresponds here to a server among
the r severs. The server choice corresponds to Step 1 in
the pseudocode given in Algorithm 1. Once the server is
chosen, the instantaneous response time of the chosen server
for that requested is observed. Then, in step 2, based on
this observation, we update the average response time of the
chosen server of the pseudocode using the exponential moving
average. The estimates for the other “unchosen” servers will be
kept unchanged. In Step 3, the chosen action receives a reward
or a penalty by comparing the estimated response time of the
chosen server to a dynamic threshold and the mean of the
individual average response times of the r servers. In Step 4,
we operate with the same rules of the classical LRI LA but
with the exception of accommodating artiﬁcial barriers. If the
chosen action resulted in a reward, its probability is increased,
while the probabilities of the rest of the r −1 actions are
decreased. However, if the chosen action results into a penalty,
the probability vector is kept unchanged as per the LRI LA
philosophy.
With these deﬁnitions in place, we are in a position to
analyze the scheme and give theoretical results. This is done in
Section IV-D. We show that as pi(t) increases this quantity,
Prob(si(t) > ˆs(t)) decreases. This is an extremely interest-
ing observation because the latter quantity is, quite simply,
the reward probability when choosing action i. This is referred
to as the “stochastic diminishing return” property, which,
informally, means that the more an action is chosen, the less
its reward will be. Thereafter, we will prove the scheme’s
convergence.
D. Theoretical Analysis
In this section, we shall investigate and analyze the asymp-
totic behavior of our LA-based two-time-scale separation
solution with artiﬁcial barriers. We shall analyze our scheme
in terms of both its convergence and stability.
Theorem 1: For a sufﬁciently small α and θ ≪α, ˆsi(t) can
be approximated by M RTi(pi(t)) = (1/μi −λi pi(t)) for all
1 ≤i ≤r.
Proof: We will prove that for 1 ≤i ≤r, ˆsi(t) converges
to ¯si(pi(t)), where ¯si denotes MRTi.
The proof is based on the theory of stochastic approx-
imation [2]. Since θ is much smaller than α, pi’s evolve
at a slower time scale compared with ˆsi’s, which, in turn,
guarantees the two-time-scale separation. Using the notation
that α(t) = i means that action i is chosen at time t, we can
write
ˆsi(t + M) = ˆsi(t) + α
M−1

k=0
I{α(t+k+1)=i}(si(t + k) −ˆsi(t + k)).
As per the theory of small step processes, we can
assume that whenever α is small enough, the vector [ˆs1(t),
ˆs2(t), . . . , ˆsr(t)] remains almost unchanged in the discrete
interval {t, t +1, . . ., t +M}. Thus, we can write the following
approximate equations for 1 ≤i ≤r:
ˆsi(t + M) ≈ˆsi(t) + Mα(Ri(t, M) −Qi(t, M)ˆsi(t)).
(6)
For i ∈[1,r], when the values of the estimates {ˆs1(.),
ˆs2(.), . . . , ˆsr(.)} are, respectively, considered ﬁxed at {ˆs1(t),
ˆs2(t), . . . , ˆsr(t)}, and M is large, we now approximate the
quantities
Ri(t, M) =
M−1
k=0 I{α(t+k+1)=i}si(t + k)
M
as well as
Qi(t, M) =
M−1
k=0 I{α(t+k+1)=i}
M
.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 3450
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
The probability vector p1(.), p2(.), . . . , pr(.), too, can be
regarded to be essentially constant in the interval {t, t +
1, . . . , t + M} because we have afﬁrmed that pi evolves at
a slower time scale compared with ˆsi. Note that the fact that
θ is much smaller than α permits the separation at this time
scale.
Now, assuming that M is large enough such that the law of
large numbers is in effect, the average
Qi(t, M) =
M−1
k=0 I{α(t+k+1)=i}
M
that is the fraction of time the action i was chosen in the
interval [t, t + M] and converges to pi(t).
By
reckoning the
actions’
probabilities to
be
ﬁxed,
the response time processes si(.)can converge to a stationary
distribution, with the mean being denoted by ¯si(pi(t)).
Furthermore, the quantities
Ri(t, M) =
M−1
k=0 I{α(t+k+1)=i}si(t + k)
M
can be approximated by pi(t)¯si(pi(t)).
Employing
the
approximations
as
described
earlier,
we
notice
from
(6)
that
the
evolution
of
the
vector
[ˆs1(.), ˆs2(.), . . . , ˆsr(.)] reduces to the following ODE system
when α is sufﬁciently small:
ˆsi(t)
dt
= pi(t).(¯si(pi(t)) −ˆsi(t)).
(7)
One observes that (7) reduces to having the running
response time estimates, given by [ˆs1(.), ˆs2(.), . . . , ˆsr(.)],
converging to a steady-state vector [¯s1(p1(t)), ¯s2(p2(t)),
¯sr(pr(t))] whenever α tends to 0.
We now invoke the properties of the M/M/1 queue model,
alluded to above. As per the properties of the M/M/1 queue
model, we know that
¯si(pi(t)) = MRTi(pi(t)) =
1
μi −λi pi(t).
(8)
This, indeed, concludes the proof.
□
In Theorem 2, we shall prove the diminishing property
of our designed feedback mechanism. In fact, our reward
is deﬁned by the fact that the instantaneous response time
observed when we choose a server is smaller than ˆs(t), which
is the arithmetic mean of ˆsi(t) for 1 ≤i ≤n, where ˆsi(t) is the
running estimate (i.e., the exponential moving average) of the
response time at server i. Using the notation of (5), we will
show that the reward probability decreases as we increase pi.
Theorem 2: Di(t) is monotonically strictly decreasing as a
function of pi.
Proof:
We consider the reward probability Di(t) =
Prob(si(t) ≤ˆs(t)), where ˆs(t) is given by (4).
As a consequence of the previous result from Theorem 1,
if the ˆsi’s evolve at a slower time scale than the pi’s, we can
approximate ˆs(t) by the sum of the mean response times of
each server, i.e., sum of MRTi(t), 1 ≤i ≤r. In other words,
ˆs(t) ≈(r
k=i ¯si(pi(t))/r) = (r
k=i MRTi(pi(t))/r).
The probability that the response time of server i, si(t),
exceeds ˆs(t) is [36]
Di(t) = Prob(si(t) ≤ˆs(t)) = 1 −exp(−ˆs(t)(μi −λi(t))).
(9)
We need to show that as pi(t) increases, this quantity
decreases. To achieve this, consider (d Di(t)/dpi) given by
(d Di(t)/dpi) = (δDi(t)/δpi) + r
j=1
j̸=i
(δDi(t)/δp j)(δp j/δp j).
In order to apply the chain rule for the derivation, we resort
to a subtle mathematical trick similar to the one used in [18]
and [48]. We deﬁne arbitrary constants b j ≥0 for j ̸= i,
whence, following a derivation similar to the one in [18]
and [48], we have
p1 = b1 pi, p2 = b2 pi, . . . pr = br pi,
with b j ≥0 for j ̸= i.
Consequently
p1 = b1(1 −pi)

m bm
· · · = · · ·
p j = b j(1 −pi)

m bm
· · · = · · ·
pr = br(1 −pi)

m bm
.
(10)
Now, since 
m pm = 1, we can obtain (dp j/dpi) =
(−b j/
m̸= j bm) < 0 for all j ̸= i.
Considering the expression for Di(t), we see that
Di(t) = 1 −exp(−ˆs(t)(μi −λi(t))
= 1 −exp

−μi −λi(t)
r

k
1
μk −λk(t)

= 1 −exp
⎛
⎜⎝−1
r −
r

k=1
k̸=i
1
r(μk −λpk(t))
⎞
⎟⎠.
This expression is independent of pi, which implies that
(δDi(t)/δpi) = 0. Consequently, (δDi(t)/δpi) reduces to
(d Di(t)/dpi) = r
j=1
j̸=i
(δDi/δp j)(δp j/δpi).
Algebraic simpliﬁcation leads to
δDi
δp j
=
λ
r(μi −λpi(t))2 exp(−ˆs(t)(μi −λi(t))).
Furthermore, since (dp j/dpi)
<
0, (δDi(t)/δpi)
=
r
j=1
j̸=i
(δDi/δp j)(dp j/dpi) < 0 since all the terms in the
above-mentioned sum are strictly negative.
Hence, the theorem!
□
Theorem 3: For a sufﬁciently small pmin approaching 0,
the system of update equations characterizing the LA has a
unique ﬁxed point equilibrium.
Proof:
E[pi(t + 1) −pi(t)|p(t)] = pi Di(pi)[θ(1 −pi)]
+
r

j=1
j̸=i
p j D j(p j).[θ(pmin −pi)].
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3451
Then
E[pi(t + 1) −pi(t)|p(t) = p]
= pi Di(pi).[θ(1 −pmax + 1 −pi)]
+
r

j=1
j̸=i
p j D j(p j)[θ(pmin −pi)]
(11)
= pi Di(pi).
⎡
⎢⎢⎣θ(1 −pmax +
r

j=1
j̸=i
p j)
⎤
⎥⎥⎦
+
r

j=1
j̸=i
p j D j(p j)[θ(pmin −pi)].
(12)
By taking into account the fact that 1−pmax = (r −1)pmin,
(12) can be simpliﬁed (after some algebraic manipulations)
and written as
E[pi(t + 1) −pi(t)|p(t) = p]
= θ
r

j=1
j̸=i
pi p j(Di(pi) −D j(p j))
+ θpmin
⎛
⎜⎜⎝
r

j=1
j̸=i
p j D j(p j)
⎞
⎟⎟⎠
−θ(r −1)pmin pi Di(pi)
= θ
r

j=1
j̸=i
pi p j(Di(pi) −D j(p j))
+ θpmin
r

j=1
j̸=i
(p j D j(p j) −pi Di(pi))
≈θwi(p)
where wi(p) is deﬁned by wi(p) = r
j=1
j̸=i
pi p j(Di(pi) −
D j(p j)).
For small values of pmin, i.e., as pmin →0, we can
approximate E[pi(t + 1) −pi(t)|p(t) = p] by
E[pi(t + 1) −pi(t)|p(t) = p] = θwi(p).
(13)
We can, thus, write
dpi(t + 1)
dt
= θwi(p).
(14)
Using the above-mentioned result, we shall now proceed
with the details of the proof.
1) Existence and Uniqueness: We will show that w(p) =
(w1(p), w2(p), . . ., wr(p)) has a unique zero in the neighbor-
hood of p∗= (p∗
1, . . . , p∗
r ), which means that we have a ﬁxed
point.
The above-mentioned assertions imply the system of r
equalities
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
r

j=1
j̸=1
p1 p j(D1(p1) −D j(p j)) = 0
r

j=1
j̸=2
p2 p j(D2(p2) −D j(p j)) = 0
...
r

j=1
j̸=r
pn p j(Dr(pr) −D j(p j)) = 0.
⇔
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
p1
r

j=1
j̸=2
p j(D1(p1) −D j(p j)) = 0
p2
r

j=1
j̸=2
p j(D2(p2) −D j(p j)) = 0
...
pn
r

j=1
j̸=r
p j(Dr(pr) −D j(p j)) = 0.
The reader should observe that a crucial concept in our
approach is that we are using the barrier pmin, which ensures
that p1 ̸= 0, p2 ̸= 0, . . . , pr ̸= 0. We can, thus, conﬁdently
divide the ﬁrst equation by p1, the second equation by p2, and
so on, yielding
⇔
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
r

j=1
j̸=1
p j(D1(p1) −D j(p j)) = 0
...
r

j=1
j̸=2
p j(D2(p2) −D j(p j)) = 0
...
r

j=1
j̸=r
p j(Dr(pr) −D j(p j)) = 0.
After invoking some algebraic manipulations, we obtain that
⇔
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
D1(p1) =
r

j=1
p j D j(p j)
...
D2(p2) =
r

j=1
p j D j(p j)
...
Dr(pr) =
r

j=1
p j D j(p j)
which guarantees that D1(p1) = D2(p2) = . . . = Dr(pr).
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 3452
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
Now, we will show that the solution is unique.
2) Uniqueness: The uniqueness of p∗is proven by contra-
diction. Suppose there exists q∗= (q∗
1, q∗
2, . . . , q∗
n) that is a
zero of w(q) such that q∗̸= p∗.
Without loss of generality since p∗and q∗are two probabil-
ity vectors such that p∗̸= q∗, we can conﬁdently afﬁrm that
they have at least two components i and j such that p∗
i > q∗
i
and p∗
j < q∗
j . Observe that the result is general and that it
applies for any two distinct probability vectors. Intuitively, this
means that if we increase any one component of a probability
vector, we should decrease another component, so as to ensure
that the sum of the components is unity.
Suppose now that p∗
i
>
q∗
i . Then, by invoking the
monotonicity of the function Di(.), we obtain that Di(p∗
i ) <
Di(q∗
i ). On the other hand, the condition p∗
j < q∗
j implies
that D j(p∗
j) > D j(q∗
j ), where this is obtained by virtue of
the monotonicity of D j(.). However, since p∗and q∗are
equilibrium points, we know that Di(p∗
i ) = D j(p∗
j) and that
Di(q∗
i ) = D j(q∗
j ). This forces a contradiction since it is
impossible to simultaneously maintain that Di(p∗
i ) < Di(q∗
i )
that is equivalent to D j(p∗
j) < D j(q∗
j ) and D j(p∗
j) > D j(q∗
j ).
Therefore, p∗is unique.
□
Theorem 4: The equilibrium point to which the algorithm
converges is asymptotically Lyapunov stable.
Proof: Consider the following Lyapunov function:
V (p(t)) =
r

k=i
 pt
0
Dk(z)dz.
Consider now its derivative
dV (p(t))
dt
=
r

i=1
dV(p(t))
dpi
dpi
dt .
(15)
It is easy to note that by virtue of the integral derivation,
(dV(p(t))/dpi) = Di(t). Furthermore, according to (14),
(dpi/dt) = θwi(p).
Thus
dV (p(t))
dt
= θ
r

k=1
Dk(t)wk(p)
(16)
where wi(p) is deﬁned by wi(p) = r
j=1
j̸=i
pi p j(Di(pi) −
D j(p j)). Therefore
dV(p(t))
dt
= θ
r

i=1
Di
r

j=1
pi p j(Di −D j)
= θ
r

i=1
r

j=1
pi p j(D2
i −Di D j)
= −θ
2
r

i=1
r

j=1
pi p j(Di −D j)2.
Therefore, (dV(p(t))/dt) ≤0.
Observe though that the Lyapunov function must be zero
at its equilibrium point, and thus, (dV(p(t))/dt) = 0. This,
in turn, means that for every i, j, we have p∗
i p∗
j(D∗
i −
D∗
j)2 = 0. However, since p∗
i
> pmin and p∗
j > pmin,
the equality D∗
i (p∗
i ) −D∗
j(p∗
j) = 0 must necessarily be true,
and consequently, for all i, j
D∗
i (p∗
i ) = D∗
j(p∗
j) = 0.
The result follows, since, by the Lyapunov theorem, we have
shown that p∗is an asymptotically Lyapunov stable equilib-
rium point of the scheme.
□
E. Summary Outlining of the Theoretical Results
In Theorem 1, we show that by imposing a two-time-scale
separation, where we slowly update the LA probabilities, while
we update the response times in a faster scale, we are able to
approximate the estimated response times at each server. For
any probability vector that is slowly varying, the response
time estimates converge to a steady state depending on the
probability vector given by (8). Once we have characterized
the response times, we can analyze the behavior of the reward
probabilities of our LA. This is treated in Theorem 2, where
we show an intuitive property, which states that the reward
probability of action is monotonically strictly decreasing as
a function of its respective action probability. Theorem 3
characterizes the ﬁxed point of the LA update equations. The
artiﬁcial barriers as well as the monotonicity of the reward
functions yield a unique ﬁxed point. Interestingly, the ﬁxed
point achieves fairness as the reward probabilities of the action
are “equalized,” and thus, the LA will be indifferent between
the choices of the servers at this point. Theorem 4 shows that
the algorithm converges to asymptotically Lyapunov stable
state by deﬁning an appropriate Lyapunov function.
V. EXPERIMENTAL VERIFICATION
In this section, we will brieﬂy conﬁrm that the theoretical
results that were derived in Section IV hold true. To achieve
this, we conducted two types of experiments. The intent of
the ﬁrst set of experiments was to prove the claims for a
small-scale system, namely, for one with only three servers.
The second, and more extensive testing, involved a larger pool
of servers, i.e., 15. It is clear that such a setting is well in-line
with real-life LB problems. Furthermore, we tested both of the
scenarios in two types of environments: static and dynamic.
For the dynamic case, we report experiments where we either
changed the serving rates of the services or the arrival rate of
the requests.
A. Experiments With Three Servers
1) Static Environment With Three Servers: In this ﬁrst set
of experiments, we simulated three servers characterized by
the parameters, μ1 = 50, μ2 = 33.33, and μ3 = 25,
respectively. We assumed that the total arrival rate was λ1 +
λ2 + λ3 = 50. Furthermore, we used pmin = 0.01. For
the time scale separation, we used two values θ = 0.001
for updating the LA action probabilities and α = 0.01 for
the estimation of the response times. The intention of our
experiments was to observe the action probabilities and the
corresponding response times when the protocol was tested
for 9000 iterations for an ensemble of 1000 experiments.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3453
Fig. 1.
Evolution of the action selection probabilities in a static environment.
Fig. 2.
Evolution of the response times of the different servers in a static
environment.
Fig. 3.
Evolution of the action selection probabilities in an environment with
dynamic serving rates.
The evolution of the probability and response time are
plotted in Figs. 1 and 2, respectively. Interestingly, from Fig. 2,
we observed that the response time was equalized on the
different servers. The results are quite amazing because even
though the corresponding action probabilities converged to
different values, the composite effect of the convergence was
to make the overall response times to be almost equal.
2) Dynamic Serving Rates With Three Servers: To investi-
gate the performance of the scheme for time-varying systems,
we also ran another experiment where we dynamically shufﬂed
the serving rates of the three servers every 5000 iterations.
In this case, the experiments were run for 15000 iterations,
and the number of experiments (over which the ensemble
average was obtained) was 1000. We again observed that the
system stabilized after some time and that it was again capable
of equalizing the response times. Figs. 3 and 4, respectively,
depict the evolution of the action probabilities of each server,
as well as the evolution of the estimated response times.
It is clear that the results demonstrated that even though the
corresponding action probabilities converged to completely
Fig. 4.
Evolution of the response times of the different servers in an
environment with dynamic serving rates.
Fig. 5.
Evolution of the action selection probabilities in an environment with
varying arrival rates and with three servers.
Fig. 6.
Evolution of the response times of the different servers in an
environment with varying arrival rate with three servers.
different values, the overall effect of the scheme’s convergence
was to make the overall response times to be almost equal.
The power of the scheme to balance the loads in an
ϵ-optimal manner is obvious!
3) Dynamic Arrival Rate With Three Servers: In real-life
scenarios, it is more common that the arrival rate of the trafﬁc
changes over time, while the serving rate is usually stable over
time. This is because the latter is an intrinsic characteristic of
the server and does not, usually, change due to extrinsic factors
related to the environment.2 In our simulations, we adjusted
the arrival rate every 6000 iterations. We started with a total
arrival rate of 50, and after the ﬁrst switch, this number was
increased to 60. It was then lowered to 54 after the second
switch. Figs. 5 and 6 report, respectively, the evolution of
the probabilities and the evolution of the response time esti-
mates for this dynamic environment characterized by varying
2The serving rate of a server might degrade slightly over time due to
hardware issues. It is also possible to upgrade the servers for improved
performance. However, such changes are beyond the scope of this work and
are still rare within the lifetime of a server.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 3454
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
Fig. 7.
Evolution of the action selection probabilities in a static environment
with 15 servers.
Fig. 8.
Evolution of the response times of the different servers in a static
environment with 15 servers.
arrival rates. One should observe that our scheme is able
to equalize the response times of the servers after around
3000 iterations.
B. Larger Scale Experiments
1) Static Environment With 15 Servers: In the second set
of experiments, we increased the number of servers to 15 as
per the following parameters: ﬁve servers with μ = 50,
ﬁve servers with μ = 60, and ﬁve servers with μ = 80.
We assumed that the total arrival rate was λ
=
350.
Figs. 7 and 8 illustrate, respectively, the evolution of the prob-
abilities and the evolution of the response time estimates for
a static environment. When it comes to the parameters of
the algorithm, we use the same tuning parameters as in the
previous experiment involving three servers, i.e., θ = 0.001
and α = 0.01. Interestingly, even though the environment was
intrinsically more challenging than the case of having three
servers, we observed that our scheme was able to stabilize the
response times of the 15 servers after around 5000 iterations.
2) Dynamic Serving Rates With 15 Servers: In order to
test the adaptivity of our scheme in large-scale settings,
we executed a “switch” in the environment by modifying
the serving rates every 30000 iterations. The switch was a
right-circular shift of a single position of the serving rate
vector. For example, before the ﬁrst switch, the serving rate
vector of the 15 servers was (μ1 =50, μ2 =60, μ3 =80,
μ4 =50, μ5 =60, μ6 =80, . . ., μ13 =50, μ14 =60, and
μ15 =80), respectively, and after the ﬁrst switch, the serving
rates became (60, 80,50, . . ., 60, 80, and 50). Figs. 9 and 10,
respectively, depict the evolution of the action probabilities of
each server, as well as the evolution of the estimated response
times.
Fig. 9.
Evolution of the action selection probabilities in a dynamic
environment with dynamic serving rates and with 15 servers.
Fig. 10.
Evolution of the response times of the different servers in a dynamic
varying environment with dynamic serving rates and with 15 servers.
However, with such a large number of servers, it is clear that
we could run into stability issues of the queues whenever the
arrival rate at a given server became higher than its serving rate
as a consequence of the shift in the serving rates. Formally,
this instability can be seen to be a consequence of violating
the condition μi −λi > 0, where λi = λpi. For instance,
this happens after the ﬁrst switch, as we can easily observe.
Consider, in this case, the third server. Before the switch,
p3 stabilized to 0.152, while the processing rate was as high
as 80. Abruptly, however, after the switch, in the serving
rates, the same server, i.e., 3, obtained a new processing rate
50, which was much lower than before, while p3 was 0.152.
This, clearly, led to a queue instability since, in this case,
μ3 −λ3 = 50 −350 × 0.152 = −3.2 < 0 because the server
was receiving more trafﬁc than it could serve, which it, clearly,
could not handle.
3) Dynamic Arrival Rate With 15 Servers: In order to
test the adaptivity of our scheme when facing changes in
the arrival rate, we executed an environment switch every
30000 iterations. We started with an arrival rate of 350,
and after the ﬁrst switch, we dropped it to 280, and then,
we invoked a further drop to 252.
Figs. 11 and 12, respectively, depict the evolution of the
action probabilities of each server, as well as the evolution of
the estimated response times.
C. Comparison Results in Terms of Fairness
In this article, we claimed that our algorithm is fair in
the sense that the response times from the different servers
are equalized, and thus, a client will experience, on average,
the same QoS, measured in terms of the average response time,
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3455
Fig. 11.
Evolution of the action selection probabilities in a dynamic
environment with varying arrival rate and with 15 servers.
Fig. 12.
Evolution of the response times of the different servers in a dynamic
environment with varying arrival rate and with 15 servers.
Fig. 13.
Fairness comparison of the different LB algorithms in a static
environment with varying arrival rate and with three servers.
independent of the chosen server. It is not our place to compare
the presented algorithm to other LB algorithms in the literature
in terms of fairness. To this end, we resort to three commonly
deployed LB algorithms: RR, WRR, and Po2 algorithm [25].
When it comes to WRR, each server’s weight is proportional
to the service rate of the server. The fairness will be measured
utilizing Jain’s fairness index [4], using the formula
JFI =
r
i=1 ˆsi(t)
2
r r
i=1 ˆsi(t)2 .
(17)
If the estimated response times of the different servers
are equalized, the JFI will be equal to unity, its maximum
value. The JFI by deﬁnition ranges between zero and unity.
In Fig. 13, we report the ensemble average over 1000 experi-
ments of the fairness index (JFI) for our LA algorithm against
the aforementioned comparison algorithms for the case of
three servers. The environment is static, and the settings of
the environment are the same settings as in Section V-A1.
From Fig. 13, we see that our LA algorithm achieves the
highest JFI followed by the WRR. The reader should note
Fig. 14.
Fairness comparison of the different LB algorithms in a static
environment with varying arrival rate and with 15 servers.
that the WRR operates with extra knowledge than the LA
algorithm, in which it assumes complete knowledge of the
servers’ serving rates to deﬁne its weights. Thus, we state that
the LA algorithm is a superior solution in the sense that it
achieves almost optimal JFI values, around unity, with little
information, i.e., with no knowledge of the serving rates of the
servers. Similarly, we conducted an experiment with 15 servers
using the same settings as in Section V-B1. Fig. 14 shows
the behavior of our LA algorithms versus the state-of-the-art
comparison algorithms. We observe similar remarks to those of
the case of three servers reported in Fig. 13. In fact, the LA
algorithms are the most superior algorithm in terms of JFI
followed by WRR. However, the Po2 achieves the lowest
performance, which was not the case when we used three
servers (see Fig. 13). The primary reason for this is that, as the
number of servers increases, the Po2 will by deﬁnition select
among two random servers among 15 servers, which gives it a
limited view of the environment composed of a high number
of servers, in this case, 15, and, consequently, leads to poor
performance.
VI. CONCLUSION
With the proliferation of network-based services, the
increasing popularity of the cloud approaches that allow fair
LB is becoming more important than before. Cloud computing
is characterized by the volatility of resources and the vari-
ability that makes static LB approaches inefﬁcient. In this
article, we presented a dynamic LB approach that aspires to
achieve “almost optimal” fairness between different servers
in terms of a QoS-based metric. We used the theory of LA
to deal with the problem and designed a sophisticated LA
that combined the time-separation paradigm and the concept
of “artiﬁcial” ergodic (i.e., nonabsorbing) barriers, which was
recently introduced by Yazidi and Hammer [51] and Yazidi
et al. [52], respectively. In contrast to classical LA, the envi-
ronment considered was modeled to be nonstationary, and the
reward probabilities were shown to be characterized by a law
of diminishing returns.
As a future research endeavor, we intend to implement our
solution in a real-life cloud setting and to test its efﬁciency
and fairness compared with other classical approaches.
ACKNOWLEDGMENT
The authors are very grateful for the feedback from the
anonymous referees of the original submission. Their input
signiﬁcantly improved the quality of this ﬁnal version.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 3456
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
REFERENCES
[1] M. Agache and B. J. Oommen, “Generalized pursuit learning schemes:
New families of continuous and discretized learning automata,” IEEE
Trans. Syst., Man, Cybern. B. Cybern., vol. 32, no. 6, pp. 738–749,
Dec. 2002.
[2] A. Benveniste, P. Priouret, and M. Métivier, Adaptive Algorithms and
Stochastic Approximations. New York, NY, USA: Springer-Verlag, 1990.
[3] E. A. Billard, “Stabilizing distributed queuing systems using feedback
based on diversity,” IEEE Trans. Syst., Man, Cybern. A, Syst. Humans,
vol. 27, no. 2, pp. 251–256, Mar. 1997.
[4] P.
N.
D.
Bukh
and
R.
Jain,
The
Art
of
Computer
Systems
Performance Analysis: Techniques for Experimental Design, Mea-
surement,
Simulation,
and
Modeling.
1992.
[Online].
Available:
https://www.jstor.org/stable/25061650?seq=1
[5] P. H. Calamai and J. J. Moré, “Projected gradient methods for linearly
constrained problems,” Math. Program., vol. 39, no. 1, pp. 93–116,
Sep. 1987.
[6] G. C. Chasparis and J. S. Shamma, “Network formation: Neighborhood
structures, establishment costs, and distributed learning,” IEEE Trans.
Cybern., vol. 43, no. 6, pp. 1950–1962, Dec. 2013.
[7] N. Dragoni et al., “Microservices: Yesterday, today, and tomorrow,”
in Present and Ulterior Software Engineering. Cham, Switzerland:
Springer, 2017, pp. 195–216. [Online]. Available: https://link.springer.
com/chapter/10.1007/978-3-319-67425-4_12
[8] A. Enami, J. A. Torkestani, and A. Karimi, “Resource selection in
computational grids based on learning automata,” Expert Syst. Appl.,
vol. 125, pp. 369–377, Jul. 2019.
[9] M. Fahimi and A. Ghasemi, “A distributed learning automata scheme
for spectrum management in self-organized cognitive radio network,”
IEEE Trans. Mobile Comput., vol. 16, no. 6, pp. 1490–1501, Jun. 2017.
[10] O. Ghaleb and B. J. Oommen, “Learning automata-based solutions
to the single elevator problem,” in Proc. IFIP Int. Conf. Artif. Intell.
Appl. Innov. Cham, Switzerland: Springer, 2019, pp. 439–450. [Online].
Available:
https://link.springer.com/chapter/10.1007/978-3-030-19823-
7_37
[11] E. J. Ghomi, A. M. Rahmani, and N. N. Qader, “Load-balancing
algorithms in cloud computing: A survey,” J. Netw. Comput. Appl.,
vol. 88, pp. 50–71, Jun. 2017.
[12] R. L. Grossman, “The case for cloud computing,” IT Prof., vol. 11, no. 2,
pp. 23–27, Mar./Apr. 2009.
[13] J. Kleinberg and E. Tardos, Algorithm Design: Pearson New Interna-
tional Edition. London, U.K.: Pearson Higher Ed, 2013.
[14] P. S. Kumar, “A simple learning scheme for priority assignment at a
single-server queue,” IEEE Trans. Syst., Man, Cybern., vol. 16, no. 5,
pp. 751–754, Sep. 1986.
[15] T. Kunz, “The inﬂuence of different workload descriptions on a heuristic
load balancing scheme,” IEEE Trans. Softw. Eng., vol. 17, no. 7,
pp. 725–730, Jul. 1991.
[16] S. Lakshmivarahan, Learning Algorithms Theory and Applications.
New York, NY, USA: Springer-Verlag, 1981.
[17] J. D. Little and S. C. Graves, “Little’s law,” in Building Intuition.
Boston, MA, USA: Springer, 2008, pp. 81–100. [Online]. Available:
https://link.springer.com/chapter/10.1007/978-0-387-73699-0_5
[18] L. Mason, “An optimal learning algorithm for S-model environments,”
IEEE Trans. Autom. Control, vol. AC-18, no. 5, pp. 493–496, Oct. 1973.
[19] P. Mell and T. Grance. (2018). The NIST Deﬁnition of Cloud Com-
puting. Accessed: Sep. 16, 2019. [Online]. Available: https://csrc.
nist.gov/publications/detail/sp/800-145/ﬁnal
[20] M. R. Meybodi, “Learning automata and its application to prior-
ity assignment in a queueing system with unknown characteristics,”
Ph.D. dissertation, School Elect. Eng. Comput. Sci., Univ. Oklahoma,
Norman, OK, USA, 1983. [Online]. Available: https://shareok.org/
bitstream/handle/11244/5130/8314780.PDF?sequence=1&isAllowed=y
[21] M. Meybodi and S. Lakshmivarhan, “A learning approach to prior-
ity assignment in a two class m/m/1 queuing system with unknown
parameters,” in Proc. 3rd Yale Workshop Appl. Adapt. Syst. Theory.
New Haven, CT, USA: Yale Univ., 1983, pp. 106–109.
[22] R. Mirchandaney
and J. A. Stankovic,
“Using stochastic
learn-
ing automata for job scheduling in distributed processing systems,”
J. Parallel Distrib. Comput., vol. 3, no. 4, pp. 527–552, Dec. 1986.
[23] S. Misra, P. V. Krishna, K. Kalaiselvan, V. Saritha, and M. S. Obaidat,
“Learning automata-based QoS framework for cloud IaaS,” IEEE Trans.
Netw. Service Manag., vol. 11, no. 1, pp. 15–24, Mar. 2014.
[24] S. Misra, S. S. Chatterjee, and M. Guizani, “Stochastic learning
automata-based channel selection in cognitive radio/dynamic spectrum
access for WiMAX networks,” Int. J. Commun. Syst., vol. 28, no. 5,
pp. 801–817, 2015.
[25] M. Mitzenmacher, “The power of two choices in randomized load
balancing,” IEEE Trans. Parallel Distrib. Syst., vol. 12, no. 10,
pp. 1094–1104, Oct. 2001.
[26] K. Najim and A. S. Poznyak, Learning Automata: Theory and Applica-
tions. Oxford, U.K.: Pergamon Press, 1994.
[27] K. S. Narendra and M. A. L. Thathachar, Learning Automata:
An Introduction. Upper Saddle River, NJ, USA: Prentice-Hall, 1989.
[28] A. Nordrum. Popular Internet of Things Forecast of 50 Billion Devices
by 2020 is Outdated, 2018. Accessed: Sep. 16, 2019. [Online].
Available:
https://spectrum.ieee.org/tech-talk/telecom/internet/popular-
internet-of-things-forecast-of-50-billion-devices-by-2020-is-outdated
[29] M. S. Obaidat, G. I. Papadimitriou, and A. S. Pomportsis, “Learning
automata: Theory, paradigms, and applications,” IEEE Trans. Syst., Man,
Cybern. B. Cybern., vol. 32, no. 6, pp. 706–709, Dec. 2002.
[30] B. J. Oommen, “Absorbing and ergodic discretized two-action learning
automata,” IEEE Trans. Syst., Man, Cybern., vol. SMC-16, no. 2,
pp. 282–293, Mar. 1986.
[31] J. Parent, K. Verbeeck, J. Lemeire, A. Nowe, K. Steenhaut, and E. Dirkx,
“Adaptive load balancing of parallel applications with multi-agent rein-
forcement learning on heterogeneous systems,” Sci. Program., vol. 12,
no. 2, pp. 71–79, 2004.
[32] D. K. Patel, D. Tripathy, and C. R. Tripathy, “Survey of load balancing
techniques for grid,” J. Netw. Comput. Appl., vol. 65, pp. 103–119,
Apr. 2016.
[33] C. Pettey. (2019). Cloud Shift Impacts all it Markets. Accessed:
Sep.
16,
2019.
[Online].
Available:
https://www.gartner.com/
smarterwithgartner/cloud-shift-impacts-all-it-markets/
[34] A. S. Poznyak and K. Najim, Learning Automata and Stochastic
Optimization. Berlin, Germany: Springer-Verlag, 1997.
[35] A. A. Rahmanian, M. Ghobaei-Arani, and S. Toﬁghy, “A learn-
ing automata-based ensemble resource usage prediction algorithm for
cloud computing environment,” Future Gener. Comput. Syst., vol. 79,
pp. 54–71, Feb. 2018.
[36] H. Roh, C. Jung, W. Lee, and D.-Z. Du, “Resource pricing game
in geo-distributed clouds,” in Proc. IEEE INFOCOM, Apr. 2013,
pp. 1519–1527.
[37] Q. Sang, Z. Lin, and S. T. Acton, “Learning automata for image
segmentation,” Pattern Recognit. Lett., vol. 74, pp. 46–52, Apr. 2016.
[38] S. H. Seyyedi and B. Minaei-Bidgoli, “Using learning automata to
determine proper subset size in high-dimensional spaces,” J. Exp. Theor.
Artif. Intell., vol. 29, no. 2, pp. 415–432, Mar. 2017.
[39] R. Simha and J. F. Kurose, “Relative reward strength algorithms for
learning automata,” IEEE Trans. Syst., Man, Cybern., vol. 19, no. 2,
pp. 388–398, Mar./Apr. 1989.
[40] A.-A.
Tantar,
A.
Q.
Nguyen,
P.
Bouvry,
B.
Dorronsoro,
and
E.-G. Talbi, “Computational intelligence for cloud management cur-
rent trends and opportunities,” in Proc. IEEE Congr. Evol. Comput.,
Jun. 2013, pp. 1286–1293.
[41] A. Tchernykh, U. Schwiegelsohn, V. Alexandrov, and E.-G. Talbi,
“Towards understanding uncertainty in cloud computing resource provi-
sioning,” Procedia Comput. Sci., vol. 51, pp. 1772–1781, 2015. [Online].
Available:
https://www.sciencedirect.com/journal/procedia-computer-
science/issues
and
https://www.sciencedirect.com/journal/procedia-
computer-science/vol/51/suppl/C
[42] M. L. Tsetlin, Automaton Theory and Modeling of Biological Systems.
New York, NY, USA: Academic, 1973.
[43] S. M. Vahidipour and M. Esnaashari, “Priority assignment in queuing
systems with unknown characteristics using learning automata and
adaptive stochastic Petri nets,” J. Comput. Sci., vol. 24, pp. 343–357,
Jan. 2018.
[44] S. M. Vahidipour, M. R. Meybodi, and M. Esnaashari, “Learning
automata-based adaptive Petri net and its application to priority assign-
ment in queuing systems with unknown parameters,” IEEE Trans. Syst.,
Man, Cybern. Syst., vol. 45, no. 10, pp. 1373–1384, Oct. 2015.
[45] V. I. Varshavskii and I. P. Vorontsova, “On the behavior of stochastic
automata with a variable structure,” Autom. Remote Control, vol. 24,
no. 3, pp. 327–333, 1963.
[46] G. Velusamy and R. Lent, “Dynamic cost-aware routing of Web
requests,” Future Internet, vol. 10, no. 7, p. 57, Jun. 2018.
[47] K. Verbeeck, A. Nowé, and K. Tuyls, “Coordinated exploration in multi-
agent reinforcement learning: An application to load-balancing,” in Proc.
4th Int. Joint Conf. Auto. Agents Multiagent Syst. (AAMAS), 2005,
pp. 1105–1106.
[48] R. Wheeler and K. Narendra, “Decentralized learning in ﬁnite Markov
chains,” IEEE Trans. Autom. Control, vol. 31, no. 6, pp. 519–526,
Jun. 1986.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3457
[49] Z. Yang, Y. Liu, Y. Chen, and L. Jiao, “Learning automata based
Q-learning for content placement in cooperative
caching,” 2019,
arXiv:1903.06235. [Online]. Available: http://arxiv.org/abs/1903.06235
[50] A. Yazidi, O.-C. Granmo, and B. J. Oommen, “Learning-automaton-
based online discovery and tracking of spatiotemporal event patterns,”
IEEE Trans. Cybern., vol. 43, no. 3, pp. 1118–1130, Jun. 2013.
[51] A. Yazidi and H. L. Hammer, “Solving stochastic nonlinear resource
allocation problems using continuous learning automata,” Appl. Intell.,
vol. 48, no. 11, pp. 4392–4411, 2018.
[52] A. Yazidi, H. L. Hammer, and T. M. Jonassen, “Two-time scale learning
automata: An efﬁcient decision making mechanism for stochastic nonlin-
ear resource allocation,” Appl. Intell., vol. 49, pp. 3392–3405, Apr. 2019.
[53] J. Zhang, C. Wang, D. Zang, and M. Zhou, “Incorporation of optimal
computing budget allocation for ordinal optimization into learning
automata,” IEEE Trans. Autom. Sci. Eng., vol. 13, no. 2, pp. 1008–1017,
Apr. 2016.
Anis Yazidi (Senior Member, IEEE) received the
M.Sc. and Ph.D. degrees from the University of
Agder, Grimstad,
Norway, in 2008 and 2012,
respectively.
He was a Researcher with Teknova AS, Grimstad.
From 2014 to 2019, he was an Associate Professor
with the Department of Computer Science, Oslo
Metropolitan University, Oslo, Norway, where he is
currently a Full Professor and leading the Research
Group in Applied Artiﬁcial Intelligence. He is also
Professor II with the Norwegian University of Sci-
ence and Technology (NTNU), Trondheim, Norway. His current research
interests include machine learning, learning automata, stochastic optimization,
and autonomous computing.
Ismail Hassan received the M.Sc. degree in network
and system administration from the University of
Oslo, Oslo, Norway, in 2005.
In 2005, he joined the Oslo University College
(OsloMet), Oslo Metropolitan University, Oslo, as a
Senior System and a Network Engineer, and after
four years, transitioned to the position of Assistant
Professor. He is currently an Assistant Professor
with OsloMet. His ﬁeld of interests includes cyberse-
curity, networking technologies, operating systems,
DevSecOps, teaching, and learning methods.
Hugo L. Hammer received the M.Sc. and Ph.D.
degrees from the Norwegian University of Science
and Technology, Trondheim, Norway, in 2003 and
2008, respectively.
He is currently a Full Professor of statistics
with the Department of Computer Science, Oslo
Metropolitan University, Oslo, Norway. His current
research interests include computer-intensive sta-
tistical methods, Bayesian statistics, and learning
systems.
B. John Oommen
(Life Fellow, IEEE) was born
in Coonoor, India, in September 1953. He received
the B.Tech. degree from IIT Madras, Chennai, India,
in 1975, the M.E. degree from the Indian Institute
of Science, Bengaluru, India, in 1977, and the M.S.
and Ph.D. degrees from Purdue University, West
Lafayette, IN, USA, in 1979 and 1982, respectively.
He was with the School of Computer Science, Car-
leton University, Ottawa, ON, Canada, from 1981 to
1982, where he is currently a Full Professor and,
since July 2006, has been the Chancellor’s Professor,
which is a lifetime award from Carleton University. He is the author of more
than 485 refereed journal and conference publications. His research interests
include automata learning, adaptive data structures, statistical and syntactic
pattern recognition, stochastic algorithms, and partitioning algorithms.
Dr. Oommen is also a fellow of the International Association for Pat-
tern Recognition (IAPR). He has served on the Editorial Board of the
IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS and Pattern
Recognition.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
",10.1109/TNNLS.2020.3010888,doc26,"3444 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 Achieving Fair Load Balancing by Invoking a Learning Automata-Based Two-Time-Scale Separation Paradigm Anis Yazidi , Senior Member, IEEE, Ismail Hassan, Hugo L. Hammer , and B. John Oommen , Life Fellow, IEEE Abstract—In this article, we consider the problem of load bal- ancing (LB), but, unlike the approaches that have been proposed earlier, we attempt to resolve the problem in a fair manner (or rather, it would probably be more appropriate to describe it as an ϵ-fair manner because, although the LB can, probably, never be totally fair, we achieve this by being “as close to fair as possible”). The solution that we propose invokes a novel stochastic learning automaton (LA) scheme, so as to attain a distribution of the load to a number of nodes, where the performance level at the different nodes is approximately equal and each user experiences approximately the same Quality of the Service (QoS) irrespective of which node that he/she is connected to. Since the load is dynamically varying, static resource allocation schemes are doomed to underperform. This is further relevant in cloud environments, where we need dynamic approaches because the available resources are unpredictable (or rather, uncertain) by virtue of the shared nature of the resource pool. Furthermore, we prove here that there is a coupling involving LA’s probabilities and the dynamics of the rewards themselves, which renders the environments to be nonstationary. This leads to the emergence of the so-called property of “stochastic diminishing rewards.” Our newly proposed novel LA algorithm ϵ-optimally solves the problem, and this is done by resorting to a two-time-scale-based stochastic learning paradigm. As far as we know, the results presented here are of a pioneering sort, and we are unaware of any comparable results. Index Terms—Continuous learning automaton (LA), fair load balancing (LB), resource allocation. I. INTRODUCTION I N THIS article, we consider the problem of load balanc- ing (LB), which is extremely pertinent in today’s highly connected world. To put the problem in the right perspec- tive, we observe that, unarguably, computers, and information technology have experienced enormous growth and devel- opment over the past three decades. This unalterable trend Manuscript received December 18, 2019; revised June 3, 2020; accepted July 12, 2020. Date of publication August 5, 2020; date of current version August 4, 2021. The work of B. John Oommen was supported in part by the Natural Sciences and Engineering Council of Canada (NSERC). (Corresponding author: B. John Oommen.) Anis Yazidi, Ismail Hassan, and Hugo L. Hammer are with the Department of Computer Science, Oslo Metropolitan University, 0130 Oslo, Norway. B. John Oommen is with the School of Computer Science, Carleton University, Ottawa, ON K1S5B6, Canada, and also with the IKT Department, University of Agder, 4879 Grimstad, Norway (e-mail: oommen@ scs.carleton.ca). Color versions of one or more of the ﬁgures in this article are available online at Digital Object Identiﬁer 10.1109/TNNLS.2020.3010888 has profoundly affected societies worldwide, in every sense of the word. Products and services that were traditionally delivered through other means are, currently, online services. Unlike the scenario a few decades ago, where one “con- nected” directly to an institution’s machine, most of these services are now being executed on the internet. Since more than 50 billion devices will be connected to the Internet by 2020 [28], one understands that the traditional model of having in-house computers and resources is not going to be a sustainable and viable option. Rather, to cope with the sheer increase in the number of users and devices inter- acting with the machines, the respective services delivered online, government, and business institutions are reducing their investments in on-premise IT infrastructure. Indeed, to mit- igate the super-exponential increases in the corresponding communication and computational costs, they are moving to, and increasing their spending on, cloud-based services [33]. In this context, we mention that the National Institute of Standards and Technology (NIST) deﬁnes “cloud computing” as a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of conﬁgurable comput- ing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interac- tion [19]. It is clear that one has to now consider how all these services can be distributed over the cloud of computers. This, precisely, involves the problem of LB. LB is like many other related problems [13]; many instances of LB are considered NP-Hard problems [31]. Thus, we will never be able to solve the problem, so as to allocate the resources in a perfectly balanced manner. Unlike the approaches that have been proposed in the literature [11], such as round-robin (RR), weighted RR (WRR), power- of-two choices (Po2), least connection, and weighted least connection, we attempt to resolve the problem in an “almost fair” manner, and we shall refer to such an allocation as an ϵ-fair balance. In other words, we attempt to achieve this by being “as close to fair as possible.” While one can attempt to do this intelligently using any of the available AI-based paradigms, the solution that we propose invokes a novel stochastic learning automaton (LA) scheme. Our LA-based solution distributes the load to a number of nodes, where the performance level at the different nodes is approximately 2162-237X © 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3445 equal and each user experiences approximately the same Quality of the Service (QoS) irrespective of the node that he/she is connected to. Although LA has been applied, in a classical sense, to solve many resource allocation problems including LB, to the best of our knowledge, this work is distinct in two aspects. First, to the best of our knowledge, there is no theoretical analysis of any LB algorithm in the ﬁeld of LA. LB usually induces the dynamicity of the environment as the LA actions will continuously alter the load distribution, and consequently, render the Environment to be nonstationary. Thus, such settings deviate from the classical multiarmed bandit settings where the environment is rather static, and the reward distribution is not inﬂuenced by the actions of the LA. The analysis of such cases is much more involved than stationary cases. The reader should also note that, probably, the most notable example of a theoretical treatment is found in [31] and [47], where the LB problem is mapped into a coordinated strategic game. Second, the success of adopting LA for solving a real-life problem is dependent on an appro- priate choice, or more precisely, appropriate engineering of the reward function. Most of the engineered reward functions in the context of LA-based LB solutions solely rely on “the response time” of a server. In this article, we have used a modiﬁed version of the reward that can infer fairness based on a dynamic comparison threshold. How then should a cloud-based service model differ from a more traditional model? From the reported literature [12], we submit that a cloud-based infrastructure should make it easy for a customer to request a resource and to have that resource provisioned and ready for use, in minutes, rather than days or weeks. The ability to scale the available resources on demand, with little or no downtime, is another factor that makes the cloud preferable over traditional enterprise data centers. The cloud-based computing paradigm has transformed the IT industry profoundly, paving the way to foster new concepts, such as DevOps and microservices. However, to stay com- petitive and to also ensure customer satisfaction, companies offering online services aim to quickly deliver new features to their customers. Developing and deploying software as a monolithic application do not fully take advantage of the beneﬁts of a “cloud computing” paradigm, and many compa- nies are considering migrating toward microservices [7] and a cloud-native application approach. While having many beneﬁts, cloud computing still has some challenges when it comes to offering an optimized system and a fair allocation of resources. Available cloud models do not adequately capture uncertainty, nonhomogeneity, and dynamic performance changes that are inherent to nonuniform and shared infrastructures [41]. One of the viable ways to address challenges related to dynamic performance changes associated with any uncertainties in the load distribution is to employ an LB technique. LB is the process of distributing workloads fairly among multiple hosts. The major advantage of deploying an LB solution is to be able to handle more trafﬁc than a single host can tackle. Another advantage of LB is that such a system offers high availability such that if one service fails, others are available to ensure that the application stays up and running. In order to achieve an optimal distribution of workloads to any number of hosts, several algorithms have been developed throughout the years. LB algorithms are mainly classiﬁed as being static or dynamic. Static LB schemes assume that the information governing the LB-oriented decisions is known in advance [32]. The LB decisions are made deterministically or probabilistically when the system starts or boots and remain constant during runtime. Every time the system restarts, the same values get loaded. Static LB algorithms are mostly suitable for stable environments with homogeneous systems. The nature of a data center or of a cloud implicitly requires dealing with a mixture of stochastic processes [40]. In contrast to static algorithms, dynamic LB algorithms do not require prior knowledge or conﬁguration of the system. To make fairer load distribution decisions, dynamic LB algorithms monitor the current runtime state of the system and adapt to changing loads. The experiments that we report tacitly imply that the servers are not homogenous, as they need not necessarily be homogenous, especially in cloud environment. Indeed, one of the reasons for this is that the types of hardware used for the servers may be different as well as the unpredictability of the resources in a cloud environment. A. Distinctive Properties of Our Solution Without going into any details of the arguments presented in the body of this article, it is prudent to mention the distinctive properties of our proposed solution when it concerns the learning mechanism itself and the associated analysis. In all brevity, they can be listed as follows. 1) By virtue of the “fair balance” paradigm, the learning algorithm initiated by the LA proposed here is distinct from all the families of LA described in the LA-based LB literature, such as in [23]. This includes those from the previously reported families of ﬁxed structure, variable structure, discretized, and estimator-based LA. 2) To achieve a fair load balance, we encounter an irony. Thus, it is, indeed, the fact that the more often an “action” is chosen, the likelihood of the LA choos- ing it, even more, must subsequently decrease. In other words, the rewards that are received for any action must decrease as the action is chosen more frequently. This is contrary to what the properties of absolute expedience and ϵ-optimality entail, especially since, in these cases, the LA aims to converge to an absorbing barrier in the probability space. To the best of our knowledge, LA that possesses the phenomenon mentioned here has not been proposed in the literature. 3) Our solution is characterized by the amazing property that as any speciﬁc pi(t) increases, the corresponding reward probability of the action in question decreases. We refer to this phenomenon as the “stochastic dimin- ishing return property.” Informally, this means that the more an action is chosen, the less it will be rewarded. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. 3446 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 This involves the two-time-scale LA with barriers, as we shall explain presently, and also facilitates fair LB. 4) The analysis methods that we use here are both distinct and unique. The mathematical techniques used for the various families of LA described in the literature are each distinct in their own right. The methodology for the family of ﬁxed structure stochastic automata (FSSA) involves formulating the Markov chain for the LA, computing its equilibrium probabilities, and then com- puting the asymptotic action selection probabilities. The proofs of convergence for variable structure stochastic automata (VSSAs) involve the theory of small-step Markov processes, distance diminishing operators, and the theory of regular functions. The proofs for dis- cretized LA involve the asymptotic analysis of the Markov chain that represents the LA in the discretized space, whence the total probability of convergence to the various actions is evaluated. The proof of estima- tor/pursuit algorithms concerns two intertwined phenom- ena, i.e., the convergence of the reward estimates and the convergence of the action probabilities themselves. The proof methodology considered in this article utilizes the theory of small-step Markov processes and distance diminishing operators, but, unlike the existing LA, they do not converge to absorbing barriers but ﬁxed points in the corresponding probability vector space. 5) Historically, the metric for analyzing LA has gener- ally been ϵ-optimality and absolute expedience. Indeed, the concept of the Lyapunov stability of an LA solution has been rarely used with few exceptions [9]. This is, indeed, the metric that we have invoked. B. Contributions of This Article The contributions of this article can be summarized as follows. 1) We present an LA solution for ensuring the fairness of load distribution in the ﬁeld of LB. 2) We present deep theoretical results that prove the con- vergence of our scheme. 3) We use some of the most recent advances in the ﬁeld of LA that combines the time-separation paradigm and the phenomenon of artiﬁcial barriers, introduced by Yazidi and Hammer [51] and Yazidi et al. [52], respectively. 4) We prove that the equilibrium point which the algorithm converges to is asymptotically Lyapunov stable. The concept of the Lyapunov stability of an LA solution has been rarely used, except for a very few reported results [9]. 5) We provide some experimental results that conﬁrm and justify our theoretical assertions. C. Organization of This Article This article is organized as follows. The background and related work are ﬁrst presented in Section II. In Section III, we give an introduction to the theory of LA that is central to this article. Section IV includes the details of our proposed solution, where we present the scheme itself in Section IV-C and report the theoretical results proving its convergence to an optimal equilibrium in Section IV-D. Thereafter, in Section V, we include the results of rigorous simulations that conﬁrm the theoretical results. Section VI concludes this article. II. BACKGROUND AND RELATED WORK Historically, LB and task scheduling have been two closely related research areas that have been widely investigated. However, the literature that reports the use of stochastic LA to achieve these has been limited. A stochastic LA model for the decentralized control of job scheduling in distributed processing systems was presented by [22]. The algorithm proposed by these authors operates with absolutely no prior knowledge about the job but rather adapts to the changing loads of the hosts. The aim of the proposed algorithm was to provide load-balanced jobs to a number of hosts and to improve the response time while achieving this. To minimize the response time, a heuristic LB scheme based on the concept of a stochastic LA was implemented by Kunz [15]. Depending on the status of the current load distribution, a new task would be scheduled to be executed either locally or on a remote host. This article employed a learning scheme with a reward constant A of 0.25 and a penalty constant B of 0.3. Although many ﬁne details were not reported in this article, the author claimed to also have examined other inﬂuences on different numbers of automa- ton states and the behavior of the scheduler under different network sizes. Misra et al. [23] presented a framework based on LA that is capable of addressing some of the challenges and demands of various cloud applications. The proposed framework analysis invoked various performance metrics, such as response time, parallel execution speed, and job priority. These metrics were then used to select the appropriate resources, using LA. A Cost Aware S-model (CA-S) Reward Epsilon-Penalty method was proposed in [46]. The authors employed an LA-based solution that sought to reduce the average cost in serving web requests with replicated web servers, deployed in different geographical regions. To minimize the cost, the LA made routing decisions for each incoming request by assess- ing response times and energy prices at the different server locations through action selection probabilities. This article reported very promising experimental results by using the proposed CA-S method. These results demonstrated that the total average cost of serving web responses could be reduced up to 33% compared with the minimum cost ﬂow dynamic server selection algorithm and up to 49.2% compared with the traditional RR method. The problem of optimal priority assignment among two streams of jobs with unknown characteristics, each with ran- dom service time and a random arrival time, was addressed in the doctoral thesis of Meybodi [20]. A threshold was computed, which was the average service time taken over both streams, and the response time of a served dispatched request from the chosen stream by the LA was compared with that threshold for the inferred LA response. This idea Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3447 of using response time-based threshold in a queuing system as a mechanism for inferring the response of LA to constitute the rewards/penalties appeared also in [3]. Similarly, in this work, we resort to a dynamic threshold computed using a type of moving average, in contrast to a stationary type of estimator found in the seminal work of Meybodi [20] and Meybodi and Lakshmivarhan [21]. Apart from the queuing system model, this article is different from the work in [20]. Indeed, the LA proposed by Meybodi [20] was absorbing because the optimal solution was to be exclusively chosen from one of the priority streams. Furthermore, the dynamics of the reward probabilities addressed here are much more complicated in our problem setting. An alternative solution to the priority assignment problem based on FSSA was proposed by Srikanta Kumar [14]. The problem was revisited recently using the theory of Petri Nets and LA in [43] and [44]. However, as our model and solution are distinct, in the interest of brevity, we shall not expand on these articles any further. Finally, we emphasize that although LA has been applied in a few instances in the literature for solving LB problems, we are not aware of any theoretical analyses of the problems. The theoretical analysis for this type of LA application is intrinsically hard due to the dynamic nature of the environment as the reward dynamics are coupled with the changes in the actions. LA algorithms in this vein are rather presented as heuristics with no theoretical guarantees. The only possible attempt to cast an LA-based LB algorithm into a theoretical framework was reported in a series of works by the same research group [31], [47], where the LB problem was mapped onto a coordinated game. III. STOCHASTIC LEARNING AUTOMATA We shall now proceed to present a brief overview of LA [1], which is the toolkit that we will use to solve the problem. In psychology, learning is characterized as the act of modi- fying one’s behavior as a result of acquiring knowledge from past experience. In the ﬁeld of automata theory, an automaton can be described as a self-operating machine or control mech- anism consisting of a set of states, a set of outputs or actions, an input, a function that maps the current state and input to the next state, and a function that maps a current state (and input) to the current output. The term LA was ﬁrst presented in the survey article by Narendra and Thathachar (see [27]). LA is well suited for sys- tems with noisy and incomplete information about the environ- ment in which they function [1], [16], [26], [27], [29], [34]. The environment is generally stochastic, and the LA lacks prior knowledge as to which action is the optimal one. Stochastic LA, which is the probabilistic ﬁnite state machine, attempts to solve this problem by choosing an initial action randomly and then updating the action probabilities based on the response received. The action chosen is dependent on the action probability distribution vector, which, in turn, is updated based on the reward/penalty input that the LA receives from the random environment. This process is repeated until the optimal action is, hopefully, achieved. The research on LA is comprehensive, and over the past decades, several classes have been proposed. LA is mainly categorized as being FSSA or VSSA. In FSSA, the mapping between transition and output functions is time-invariant. Initial research into LA was mainly focused on FSSA. Tsetlin et al. [42] demonstrated several models of this class of automata. Gradually, research into LA has been advanced toward VSSA. LA schemes in this category possess transition and output functions that evolve as the learning process proceeds [30]. In VSSA, the state transitions or the action probabilities are updated at every time step. This class of automata was introduced by Varshavskii and Vorontsova [45] in the early 1960s. LA can further be classiﬁed as either ergodic or endowed with absorbing barriers based on their Markovian properties. In an ergodic LA system, the ﬁnal steady state is independent of the initial state. As opposed to this, for LA with absorbing barriers, the steady state depends on the initial state, and once the LA has converged, it will be locked into a so-called absorbing barrier. Furthermore, while ergodic VSSA is suitable for nonstationary environments, absorbing barrier VSSA is preferred in stationary environments. As opposed to these, a unique property of the work in [53] is that the action with the highest probability may not be the same one being chosen most frequently. Stochastic LA had been utilized in many applications over the years. Recent applications of LA include resource usage prediction algorithm for cloud computing environ- ment [35], channel selection in cognitive radio/dynamic spec- trum access for WiMAX networks [24], distributed network formation [6], solutions to the single elevator problem [10], efﬁcient decision making mechanism for stochastic nonlinear resource allocation [52], dynamic cost-aware routing of web requests [46], learning periodic spatiotemporal patterns [50], content placement in cooperative caching [49], resource selec- tion in computational grids [8], determining proper subset size in high-dimensional spaces [38], and image segmentation [37], to mention a few. IV. LA LOAD-BALANCING MODEL In this section, we present our LA model for LB, as well as the theoretical proofs for the solution’s convergence. A. Model We consider a scenario where we have a set of r servers. Each server is modeled as an M/M/1 queue, which means that arrivals are modeled by a Poisson process with some intensity λi, and the job service times have an exponential distribution with a service rate μi. In our model, we assume that an LA is responsible for dis- patching the request. The LA sends the request to server i with probability pi(t). We will later deﬁne the update equations for the LA. However, for the sake of simplicity, we shall give, ﬁrst, the overall idea for the different updates involved here at the two time scales, and subsequently, in Section IV-B, we shall delve into the LA’s detailed update equations. By virtue of the M/M/1 queue, the mean-response time at server i is MRTi(t) = 1 μi −λi(t) (1) Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. 3448 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 where λi(t) is the average arrival rate at server i. If {pi} are constant or vary slowly over time, then λi(t) can be approximated using λi(t) = pi(t)λ, which is a consequence of the M/M/1 queue model [17]. Let si(t) be the instantaneous response time of server i at time t. In order to estimate the average response time of each server (i.e., ˆsi), we merely use the exponential mov- ing average approach with the learning parameter α. The parameter α is the learning parameter of the scheme and is similar to the parameter used in any learning algorithm. It is a hyperparameter determined by a “rule of thumb” or trial and error for the particular setting. A larger value of α implies a larger step away from the current value, and vice versa. This, in turn, illustrates the speed-accuracy dilemma of the estimate. Let ˆsi(t) be the estimate of the average response time of server i. Once the action i is polled, i.e., the request is dispatched to server i, the estimate ˆsi(t + 1) of the average is immediately updated using an adaptive estimator, namely, the exponential moving average given by ˆsi(t + 1) = ˆsi(t) + α(si(t) −ˆsi(t)). (2) The average response time for the other severs (actions) are left unchanged. In other words ˆs j(t + 1) = ˆs j(t) for j ̸= i, j ∈[1, n]. (3) We now consider how the corresponding rewards and penalties are constructed. If action i is chosen, the reward or penalty is constructed as following using some type of dynamic threshold: 1) reward if ˆsi ≤(1/r) r k=1 ˆsk; 2) penalty if ˆsi > (1/r) r k=1 ˆsk. With these deﬁnitions as a backdrop, we are able to formally present the steps of our algorithm. B. Initialization Criteria Without any knowledge of ˆsi, which is estimated using an exponential moving average as per (2), we have opted to initialize ˆsi to a random low value of response time close to zero. As in any exponential moving average scheme, the value that we use for this initialization is not critical. In our experiments, we assigned this value as ˆsi(0) for all the r servers. This is in line with the spirit of what is done in LA, where the initialization is achieved by values that are equal. In fact, without the accurate knowledge of initial LA’s action probability, the initial probability for each action i is usually set to (pi(0) = (1/r)). In our case, we have also veriﬁed experimentally that the initial value of ˆsi does not have any effect on the long-term convergence behavior of the scheme that is an observation consistent with the behavior of the exponential moving average schemes that are ergodic by nature. However, in real-life settings, the experimenter might assign an initial value of ˆsi that is more informed based on an a priori knowledge of server i. In this case, one might also alter the initial LA probabilities, so as to move away from the uniform distribution, i.e., pi(0) = (1/r). C. Details of Our Solution: Two-Time-Scale LA With Barriers The ﬁrst step in our solution process is to see how we can transform the Markov process given by the probability space from being absorbing to being ergodic. The reader who is aware of the ﬁeld of Markov chains will immediately recognize that this is, actually, the converse of what the literature [5], [39]1 reports when an ergodic chain is rendered artiﬁcially absorbing, as in the families of artiﬁcially absorbing discretized LA, such as ADLRP and ADLIP [30]. Rather than using the actual limits of the probability space to be zero and unity, we work with the constraint that no probability value can take on value below a prespeciﬁed lower threshold of pmin or a value above a prespeciﬁed upper threshold of pmax [51]. The action-choosing probability values, which traditionally move proportionally toward zero and unity for the LRI scheme, for example, are now made to move toward the respective values of pmin and pmax, respectively. Interestingly enough, this minor modiﬁcation renders the scheme to be ergodic, making the analysis also to be correspondingly distinct from that of LRI and similar schemes. To achieve this, we enforce a minimal value pmin, where 0 < pmin < 1 for each selection probability xi, where 1 ≤i ≤r and r is the number of actions. As a result, the maximum value any selection probability pi, where 1 ≤i ≤r, can achieve is pmax = 1 −(r −1)pmin. This happens when the other r −1 actions take their minimum value pmin, while the action with the highest probability takes the value pmax. Consequently, pi, for 1 ≤i ≤r, will take values in the interval [pmin, pmax]. To proceed with the formulation, let α(t) be the index of the chosen action at time instant t. Then, the value of pi(t) is updated as per the following simple rule (the rules for other values of p j(t), j ̸= i, are analogous): pi(t + 1) ←pi(t) + θ(pmax −pi(t)) when α(t) = i and vi = 1 pi(t + 1) ←pi(t) + θ(pmin −pi(t)) when α(t) = j, j ̸= i and vi = 1 where θ is a user-deﬁned parameter 0 < θ < 1, typically close to zero. Furthermore, vi is a reward function indicator deﬁned as follows. 1) vi = 1, reward, if the instantaneous response of the chosen server is under the running moving average of the mean response time si ≤(1/r) r k=1 ˆsk. 2) vi = 0, penalty, if the instantaneous response of the chosen server exceeds the running moving average of the mean response time ˆsi > (1/r) r k=1 ˆsk. In our algorithm, we avoid using a classical projection method to map the solution to our feasible space, implying that all components of the probability vector are within the interval [pmin, pmax]. Projection methods have been earlier used in the ﬁeld of LA for enforcing artiﬁcial barriers. A prominent example of this is given by Simha and Kurose [39] who tackled a number of actions r > 2, which is a more challenging 1The projection method is a classical method in constrained optimization [5] that ensures that the solution is mapped back in the feasible search space whenever it falls outside. The relative reward LA devised [39] adopts artiﬁcial barriers for more than two actions using the projection method. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3449 Algorithm 1 Two-Time-Scale-Based LA Solution Loop 1. Poll an action at time instant t according to the probability vector [p1, p2, . . . , pr]. 2. Updating the response time estimates. • Update the response time of the chosen action ˆsi(t + 1) = ˆsi(t) + α(si(t) −ˆsi(t)) • The response estimates for the other actions are kept unchanged, and so ˆs j(t + 1) = ˆs j(t) for j ̸= i, j ∈[1,r] 3. Environment response: Reward/Penalty. • vi = 1 (Reward) if ˆsi ≤1 r r k=1 ˆsk; • Otherwise, vi = 0 (Penalty). 4. Let α(t) be the index of the chosen action at time instant t. The value of pi(t) is updated as per the following simple rule below, (where the update rules for other values of p j(t), j ̸= i, are similar) pi(t + 1) ←pi(t) + θ(pmax −pi(t)) when α(t) = i and vi = 1 pi(t + 1) ←pi(t) + θ(pmin −pi(t)) when α(t) = j, j ̸= i and vi = 1. scenario than he two-action scenario. However, our approach does not involve projection methods as the update equations will always ensure that the probabilities will be in our feasible space. Furthermore, in contrast to projection methods, our LA update methodology naturally ensures that the probability vector will always sum to unity in a manner that can be seen to be a generalization of the LRI LA. The classical LRI LA can be seen as an instance of our algorithm with pmax = 1. Let the average of all the instantaneous response times of all the nodes at time t be given by ˆs(t) deﬁned by ˆs(t) = 1 r r  k=1 ˆsk(t). (4) We also introduce the following notation: Di(t) = Prob(si(t) ≤ˆs(t)) (5) where ˆs(t) is given by (4). A consequence of these assignments is a scheme formalized by the pseudocode given in Algorithm 1. The algorithm proceeds as follows in a loop. Each time a request is received, the LA probability vector is used to choose a server by polling an action, which corresponds here to a server among the r severs. The server choice corresponds to Step 1 in the pseudocode given in Algorithm 1. Once the server is chosen, the instantaneous response time of the chosen server for that requested is observed. Then, in step 2, based on this observation, we update the average response time of the chosen server of the pseudocode using the exponential moving average. The estimates for the other “unchosen” servers will be kept unchanged. In Step 3, the chosen action receives a reward or a penalty by comparing the estimated response time of the chosen server to a dynamic threshold and the mean of the individual average response times of the r servers. In Step 4, we operate with the same rules of the classical LRI LA but with the exception of accommodating artiﬁcial barriers. If the chosen action resulted in a reward, its probability is increased, while the probabilities of the rest of the r −1 actions are decreased. However, if the chosen action results into a penalty, the probability vector is kept unchanged as per the LRI LA philosophy. With these deﬁnitions in place, we are in a position to analyze the scheme and give theoretical results. This is done in Section IV-D. We show that as pi(t) increases this quantity, Prob(si(t) > ˆs(t)) decreases. This is an extremely interest- ing observation because the latter quantity is, quite simply, the reward probability when choosing action i. This is referred to as the “stochastic diminishing return” property, which, informally, means that the more an action is chosen, the less its reward will be. Thereafter, we will prove the scheme’s convergence. D. Theoretical Analysis In this section, we shall investigate and analyze the asymp- totic behavior of our LA-based two-time-scale separation solution with artiﬁcial barriers. We shall analyze our scheme in terms of both its convergence and stability. Theorem 1: For a sufﬁciently small α and θ ≪α, ˆsi(t) can be approximated by M RTi(pi(t)) = (1/μi −λi pi(t)) for all 1 ≤i ≤r. Proof: We will prove that for 1 ≤i ≤r, ˆsi(t) converges to ¯si(pi(t)), where ¯si denotes MRTi. The proof is based on the theory of stochastic approx- imation [2]. Since θ is much smaller than α, pi’s evolve at a slower time scale compared with ˆsi’s, which, in turn, guarantees the two-time-scale separation. Using the notation that α(t) = i means that action i is chosen at time t, we can write ˆsi(t + M) = ˆsi(t) + α M−1  k=0 I{α(t+k+1)=i}(si(t + k) −ˆsi(t + k)). As per the theory of small step processes, we can assume that whenever α is small enough, the vector [ˆs1(t), ˆs2(t), . . . , ˆsr(t)] remains almost unchanged in the discrete interval {t, t +1, . . ., t +M}. Thus, we can write the following approximate equations for 1 ≤i ≤r: ˆsi(t + M) ≈ˆsi(t) + Mα(Ri(t, M) −Qi(t, M)ˆsi(t)). (6) For i ∈[1,r], when the values of the estimates {ˆs1(.), ˆs2(.), . . . , ˆsr(.)} are, respectively, considered ﬁxed at {ˆs1(t), ˆs2(t), . . . , ˆsr(t)}, and M is large, we now approximate the quantities Ri(t, M) = M−1 k=0 I{α(t+k+1)=i}si(t + k) M as well as Qi(t, M) = M−1 k=0 I{α(t+k+1)=i} M . Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. 3450 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 The probability vector p1(.), p2(.), . . . , pr(.), too, can be regarded to be essentially constant in the interval {t, t + 1, . . . , t + M} because we have afﬁrmed that pi evolves at a slower time scale compared with ˆsi. Note that the fact that θ is much smaller than α permits the separation at this time scale. Now, assuming that M is large enough such that the law of large numbers is in effect, the average Qi(t, M) = M−1 k=0 I{α(t+k+1)=i} M that is the fraction of time the action i was chosen in the interval [t, t + M] and converges to pi(t). By reckoning the actions’ probabilities to be ﬁxed, the response time processes si(.)can converge to a stationary distribution, with the mean being denoted by ¯si(pi(t)). Furthermore, the quantities Ri(t, M) = M−1 k=0 I{α(t+k+1)=i}si(t + k) M can be approximated by pi(t)¯si(pi(t)). Employing the approximations as described earlier, we notice from (6) that the evolution of the vector [ˆs1(.), ˆs2(.), . . . , ˆsr(.)] reduces to the following ODE system when α is sufﬁciently small: ˆsi(t) dt = pi(t).(¯si(pi(t)) −ˆsi(t)). (7) One observes that (7) reduces to having the running response time estimates, given by [ˆs1(.), ˆs2(.), . . . , ˆsr(.)], converging to a steady-state vector [¯s1(p1(t)), ¯s2(p2(t)), ¯sr(pr(t))] whenever α tends to 0. We now invoke the properties of the M/M/1 queue model, alluded to above. As per the properties of the M/M/1 queue model, we know that ¯si(pi(t)) = MRTi(pi(t)) = 1 μi −λi pi(t). (8) This, indeed, concludes the proof. □ In Theorem 2, we shall prove the diminishing property of our designed feedback mechanism. In fact, our reward is deﬁned by the fact that the instantaneous response time observed when we choose a server is smaller than ˆs(t), which is the arithmetic mean of ˆsi(t) for 1 ≤i ≤n, where ˆsi(t) is the running estimate (i.e., the exponential moving average) of the response time at server i. Using the notation of (5), we will show that the reward probability decreases as we increase pi. Theorem 2: Di(t) is monotonically strictly decreasing as a function of pi. Proof: We consider the reward probability Di(t) = Prob(si(t) ≤ˆs(t)), where ˆs(t) is given by (4). As a consequence of the previous result from Theorem 1, if the ˆsi’s evolve at a slower time scale than the pi’s, we can approximate ˆs(t) by the sum of the mean response times of each server, i.e., sum of MRTi(t), 1 ≤i ≤r. In other words, ˆs(t) ≈(r k=i ¯si(pi(t))/r) = (r k=i MRTi(pi(t))/r). The probability that the response time of server i, si(t), exceeds ˆs(t) is [36] Di(t) = Prob(si(t) ≤ˆs(t)) = 1 −exp(−ˆs(t)(μi −λi(t))). (9) We need to show that as pi(t) increases, this quantity decreases. To achieve this, consider (d Di(t)/dpi) given by (d Di(t)/dpi) = (δDi(t)/δpi) + r j=1 j̸=i (δDi(t)/δp j)(δp j/δp j). In order to apply the chain rule for the derivation, we resort to a subtle mathematical trick similar to the one used in [18] and [48]. We deﬁne arbitrary constants b j ≥0 for j ̸= i, whence, following a derivation similar to the one in [18] and [48], we have p1 = b1 pi, p2 = b2 pi, . . . pr = br pi, with b j ≥0 for j ̸= i. Consequently p1 = b1(1 −pi)  m bm · · · = · · · p j = b j(1 −pi)  m bm · · · = · · · pr = br(1 −pi)  m bm . (10) Now, since  m pm = 1, we can obtain (dp j/dpi) = (−b j/ m̸= j bm) < 0 for all j ̸= i. Considering the expression for Di(t), we see that Di(t) = 1 −exp(−ˆs(t)(μi −λi(t)) = 1 −exp  −μi −λi(t) r  k 1 μk −λk(t)  = 1 −exp ⎛ ⎜⎝−1 r − r  k=1 k̸=i 1 r(μk −λpk(t)) ⎞ ⎟⎠. This expression is independent of pi, which implies that (δDi(t)/δpi) = 0. Consequently, (δDi(t)/δpi) reduces to (d Di(t)/dpi) = r j=1 j̸=i (δDi/δp j)(δp j/δpi). Algebraic simpliﬁcation leads to δDi δp j = λ r(μi −λpi(t))2 exp(−ˆs(t)(μi −λi(t))). Furthermore, since (dp j/dpi) < 0, (δDi(t)/δpi) = r j=1 j̸=i (δDi/δp j)(dp j/dpi) < 0 since all the terms in the above-mentioned sum are strictly negative. Hence, the theorem! □ Theorem 3: For a sufﬁciently small pmin approaching 0, the system of update equations characterizing the LA has a unique ﬁxed point equilibrium. Proof: E[pi(t + 1) −pi(t)|p(t)] = pi Di(pi)[θ(1 −pi)] + r  j=1 j̸=i p j D j(p j).[θ(pmin −pi)]. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3451 Then E[pi(t + 1) −pi(t)|p(t) = p] = pi Di(pi).[θ(1 −pmax + 1 −pi)] + r  j=1 j̸=i p j D j(p j)[θ(pmin −pi)] (11) = pi Di(pi). ⎡ ⎢⎢⎣θ(1 −pmax + r  j=1 j̸=i p j) ⎤ ⎥⎥⎦ + r  j=1 j̸=i p j D j(p j)[θ(pmin −pi)]. (12) By taking into account the fact that 1−pmax = (r −1)pmin, (12) can be simpliﬁed (after some algebraic manipulations) and written as E[pi(t + 1) −pi(t)|p(t) = p] = θ r  j=1 j̸=i pi p j(Di(pi) −D j(p j)) + θpmin ⎛ ⎜⎜⎝ r  j=1 j̸=i p j D j(p j) ⎞ ⎟⎟⎠ −θ(r −1)pmin pi Di(pi) = θ r  j=1 j̸=i pi p j(Di(pi) −D j(p j)) + θpmin r  j=1 j̸=i (p j D j(p j) −pi Di(pi)) ≈θwi(p) where wi(p) is deﬁned by wi(p) = r j=1 j̸=i pi p j(Di(pi) − D j(p j)). For small values of pmin, i.e., as pmin →0, we can approximate E[pi(t + 1) −pi(t)|p(t) = p] by E[pi(t + 1) −pi(t)|p(t) = p] = θwi(p). (13) We can, thus, write dpi(t + 1) dt = θwi(p). (14) Using the above-mentioned result, we shall now proceed with the details of the proof. 1) Existence and Uniqueness: We will show that w(p) = (w1(p), w2(p), . . ., wr(p)) has a unique zero in the neighbor- hood of p∗= (p∗ 1, . . . , p∗ r ), which means that we have a ﬁxed point. The above-mentioned assertions imply the system of r equalities ⎧ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩ r  j=1 j̸=1 p1 p j(D1(p1) −D j(p j)) = 0 r  j=1 j̸=2 p2 p j(D2(p2) −D j(p j)) = 0 ... r  j=1 j̸=r pn p j(Dr(pr) −D j(p j)) = 0. ⇔ ⎧ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩ p1 r  j=1 j̸=2 p j(D1(p1) −D j(p j)) = 0 p2 r  j=1 j̸=2 p j(D2(p2) −D j(p j)) = 0 ... pn r  j=1 j̸=r p j(Dr(pr) −D j(p j)) = 0. The reader should observe that a crucial concept in our approach is that we are using the barrier pmin, which ensures that p1 ̸= 0, p2 ̸= 0, . . . , pr ̸= 0. We can, thus, conﬁdently divide the ﬁrst equation by p1, the second equation by p2, and so on, yielding ⇔ ⎧ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩ r  j=1 j̸=1 p j(D1(p1) −D j(p j)) = 0 ... r  j=1 j̸=2 p j(D2(p2) −D j(p j)) = 0 ... r  j=1 j̸=r p j(Dr(pr) −D j(p j)) = 0. After invoking some algebraic manipulations, we obtain that ⇔ ⎧ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩ D1(p1) = r  j=1 p j D j(p j) ... D2(p2) = r  j=1 p j D j(p j) ... Dr(pr) = r  j=1 p j D j(p j) which guarantees that D1(p1) = D2(p2) = . . . = Dr(pr). Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. 3452 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 Now, we will show that the solution is unique. 2) Uniqueness: The uniqueness of p∗is proven by contra- diction. Suppose there exists q∗= (q∗ 1, q∗ 2, . . . , q∗ n) that is a zero of w(q) such that q∗̸= p∗. Without loss of generality since p∗and q∗are two probabil- ity vectors such that p∗̸= q∗, we can conﬁdently afﬁrm that they have at least two components i and j such that p∗ i > q∗ i and p∗ j < q∗ j . Observe that the result is general and that it applies for any two distinct probability vectors. Intuitively, this means that if we increase any one component of a probability vector, we should decrease another component, so as to ensure that the sum of the components is unity. Suppose now that p∗ i > q∗ i . Then, by invoking the monotonicity of the function Di(.), we obtain that Di(p∗ i ) < Di(q∗ i ). On the other hand, the condition p∗ j < q∗ j implies that D j(p∗ j) > D j(q∗ j ), where this is obtained by virtue of the monotonicity of D j(.). However, since p∗and q∗are equilibrium points, we know that Di(p∗ i ) = D j(p∗ j) and that Di(q∗ i ) = D j(q∗ j ). This forces a contradiction since it is impossible to simultaneously maintain that Di(p∗ i ) < Di(q∗ i ) that is equivalent to D j(p∗ j) < D j(q∗ j ) and D j(p∗ j) > D j(q∗ j ). Therefore, p∗is unique. □ Theorem 4: The equilibrium point to which the algorithm converges is asymptotically Lyapunov stable. Proof: Consider the following Lyapunov function: V (p(t)) = r  k=i  pt 0 Dk(z)dz. Consider now its derivative dV (p(t)) dt = r  i=1 dV(p(t)) dpi dpi dt . (15) It is easy to note that by virtue of the integral derivation, (dV(p(t))/dpi) = Di(t). Furthermore, according to (14), (dpi/dt) = θwi(p). Thus dV (p(t)) dt = θ r  k=1 Dk(t)wk(p) (16) where wi(p) is deﬁned by wi(p) = r j=1 j̸=i pi p j(Di(pi) − D j(p j)). Therefore dV(p(t)) dt = θ r  i=1 Di r  j=1 pi p j(Di −D j) = θ r  i=1 r  j=1 pi p j(D2 i −Di D j) = −θ 2 r  i=1 r  j=1 pi p j(Di −D j)2. Therefore, (dV(p(t))/dt) ≤0. Observe though that the Lyapunov function must be zero at its equilibrium point, and thus, (dV(p(t))/dt) = 0. This, in turn, means that for every i, j, we have p∗ i p∗ j(D∗ i − D∗ j)2 = 0. However, since p∗ i > pmin and p∗ j > pmin, the equality D∗ i (p∗ i ) −D∗ j(p∗ j) = 0 must necessarily be true, and consequently, for all i, j D∗ i (p∗ i ) = D∗ j(p∗ j) = 0. The result follows, since, by the Lyapunov theorem, we have shown that p∗is an asymptotically Lyapunov stable equilib- rium point of the scheme. □ E. Summary Outlining of the Theoretical Results In Theorem 1, we show that by imposing a two-time-scale separation, where we slowly update the LA probabilities, while we update the response times in a faster scale, we are able to approximate the estimated response times at each server. For any probability vector that is slowly varying, the response time estimates converge to a steady state depending on the probability vector given by (8). Once we have characterized the response times, we can analyze the behavior of the reward probabilities of our LA. This is treated in Theorem 2, where we show an intuitive property, which states that the reward probability of action is monotonically strictly decreasing as a function of its respective action probability. Theorem 3 characterizes the ﬁxed point of the LA update equations. The artiﬁcial barriers as well as the monotonicity of the reward functions yield a unique ﬁxed point. Interestingly, the ﬁxed point achieves fairness as the reward probabilities of the action are “equalized,” and thus, the LA will be indifferent between the choices of the servers at this point. Theorem 4 shows that the algorithm converges to asymptotically Lyapunov stable state by defining an appropriate Lyapunov function. V. EXPERIMENTAL VERIFICATION In this section, we will brieﬂy conﬁrm that the theoretical results that were derived in Section IV hold true. To achieve this, we conducted two types of experiments. The intent of the ﬁrst set of experiments was to prove the claims for a small-scale system, namely, for one with only three servers. The second, and more extensive testing, involved a larger pool of servers, i.e., 15. It is clear that such a setting is well in-line with real-life LB problems. Furthermore, we tested both of the scenarios in two types of environments: static and dynamic. For the dynamic case, we report experiments where we either changed the serving rates of the services or the arrival rate of the requests. A. Experiments With Three Servers 1) Static Environment With Three Servers: In this ﬁrst set of experiments, we simulated three servers characterized by the parameters, μ1 = 50, μ2 = 33.33, and μ3 = 25, respectively. We assumed that the total arrival rate was λ1 + λ2 + λ3 = 50. Furthermore, we used pmin = 0.01. For the time scale separation, we used two values θ = 0.001 for updating the LA action probabilities and α = 0.01 for the estimation of the response times. The intention of our experiments was to observe the action probabilities and the corresponding response times when the protocol was tested for 9000 iterations for an ensemble of 1000 experiments. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3453 Fig. 1. Evolution of the action selection probabilities in a static environment. Fig. 2. Evolution of the response times of the different servers in a static environment. Fig. 3. Evolution of the action selection probabilities in an environment with dynamic serving rates. The evolution of the probability and response time are plotted in Figs. 1 and 2, respectively. Interestingly, from Fig. 2, we observed that the response time was equalized on the different servers. The results are quite amazing because even though the corresponding action probabilities converged to different values, the composite effect of the convergence was to make the overall response times to be almost equal. 2) Dynamic Serving Rates With Three Servers: To investi- gate the performance of the scheme for time-varying systems, we also ran another experiment where we dynamically shufﬂed the serving rates of the three servers every 5000 iterations. In this case, the experiments were run for 15000 iterations, and the number of experiments (over which the ensemble average was obtained) was 1000. We again observed that the system stabilized after some time and that it was again capable of equalizing the response times. Figs. 3 and 4, respectively, depict the evolution of the action probabilities of each server, as well as the evolution of the estimated response times. It is clear that the results demonstrated that even though the corresponding action probabilities converged to completely Fig. 4. Evolution of the response times of the different servers in an environment with dynamic serving rates. Fig. 5. Evolution of the action selection probabilities in an environment with varying arrival rates and with three servers. Fig. 6. Evolution of the response times of the different servers in an environment with varying arrival rate with three servers. different values, the overall effect of the scheme’s convergence was to make the overall response times to be almost equal. The power of the scheme to balance the loads in an ϵ-optimal manner is obvious! 3) Dynamic Arrival Rate With Three Servers: In real-life scenarios, it is more common that the arrival rate of the trafﬁc changes over time, while the serving rate is usually stable over time. This is because the latter is an intrinsic characteristic of the server and does not, usually, change due to extrinsic factors related to the environment.2 In our simulations, we adjusted the arrival rate every 6000 iterations. We started with a total arrival rate of 50, and after the ﬁrst switch, this number was increased to 60. It was then lowered to 54 after the second switch. Figs. 5 and 6 report, respectively, the evolution of the probabilities and the evolution of the response time esti- mates for this dynamic environment characterized by varying 2The serving rate of a server might degrade slightly over time due to hardware issues. It is also possible to upgrade the servers for improved performance. However, such changes are beyond the scope of this work and are still rare within the lifetime of a server. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. 3454 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 Fig. 7. Evolution of the action selection probabilities in a static environment with 15 servers. Fig. 8. Evolution of the response times of the different servers in a static environment with 15 servers. arrival rates. One should observe that our scheme is able to equalize the response times of the servers after around 3000 iterations. B. Larger Scale Experiments 1) Static Environment With 15 Servers: In the second set of experiments, we increased the number of servers to 15 as per the following parameters: ﬁve servers with μ = 50, ﬁve servers with μ = 60, and ﬁve servers with μ = 80. We assumed that the total arrival rate was λ = 350. Figs. 7 and 8 illustrate, respectively, the evolution of the prob- abilities and the evolution of the response time estimates for a static environment. When it comes to the parameters of the algorithm, we use the same tuning parameters as in the previous experiment involving three servers, i.e., θ = 0.001 and α = 0.01. Interestingly, even though the environment was intrinsically more challenging than the case of having three servers, we observed that our scheme was able to stabilize the response times of the 15 servers after around 5000 iterations. 2) Dynamic Serving Rates With 15 Servers: In order to test the adaptivity of our scheme in large-scale settings, we executed a “switch” in the environment by modifying the serving rates every 30000 iterations. The switch was a right-circular shift of a single position of the serving rate vector. For example, before the ﬁrst switch, the serving rate vector of the 15 servers was (μ1 =50, μ2 =60, μ3 =80, μ4 =50, μ5 =60, μ6 =80, . . ., μ13 =50, μ14 =60, and μ15 =80), respectively, and after the ﬁrst switch, the serving rates became (60, 80,50, . . ., 60, 80, and 50). Figs. 9 and 10, respectively, depict the evolution of the action probabilities of each server, as well as the evolution of the estimated response times. Fig. 9. Evolution of the action selection probabilities in a dynamic environment with dynamic serving rates and with 15 servers. Fig. 10. Evolution of the response times of the different servers in a dynamic varying environment with dynamic serving rates and with 15 servers. However, with such a large number of servers, it is clear that we could run into stability issues of the queues whenever the arrival rate at a given server became higher than its serving rate as a consequence of the shift in the serving rates. Formally, this instability can be seen to be a consequence of violating the condition μi −λi > 0, where λi = λpi. For instance, this happens after the ﬁrst switch, as we can easily observe. Consider, in this case, the third server. Before the switch, p3 stabilized to 0.152, while the processing rate was as high as 80. Abruptly, however, after the switch, in the serving rates, the same server, i.e., 3, obtained a new processing rate 50, which was much lower than before, while p3 was 0.152. This, clearly, led to a queue instability since, in this case, μ3 −λ3 = 50 −350 × 0.152 = −3.2 < 0 because the server was receiving more trafﬁc than it could serve, which it, clearly, could not handle. 3) Dynamic Arrival Rate With 15 Servers: In order to test the adaptivity of our scheme when facing changes in the arrival rate, we executed an environment switch every 30000 iterations. We started with an arrival rate of 350, and after the ﬁrst switch, we dropped it to 280, and then, we invoked a further drop to 252. Figs. 11 and 12, respectively, depict the evolution of the action probabilities of each server, as well as the evolution of the estimated response times. C. Comparison Results in Terms of Fairness In this article, we claimed that our algorithm is fair in the sense that the response times from the different servers are equalized, and thus, a client will experience, on average, the same QoS, measured in terms of the average response time, Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3455 Fig. 11. Evolution of the action selection probabilities in a dynamic environment with varying arrival rate and with 15 servers. Fig. 12. Evolution of the response times of the different servers in a dynamic environment with varying arrival rate and with 15 servers. Fig. 13. Fairness comparison of the different LB algorithms in a static environment with varying arrival rate and with three servers. independent of the chosen server. It is not our place to compare the presented algorithm to other LB algorithms in the literature in terms of fairness. To this end, we resort to three commonly deployed LB algorithms: RR, WRR, and Po2 algorithm [25]. When it comes to WRR, each server’s weight is proportional to the service rate of the server. The fairness will be measured utilizing Jain’s fairness index [4], using the formula JFI = r i=1 ˆsi(t) 2 r r i=1 ˆsi(t)2 . (17) If the estimated response times of the different servers are equalized, the JFI will be equal to unity, its maximum value. The JFI by deﬁnition ranges between zero and unity. In Fig. 13, we report the ensemble average over 1000 experi- ments of the fairness index (JFI) for our LA algorithm against the aforementioned comparison algorithms for the case of three servers. The environment is static, and the settings of the environment are the same settings as in Section V-A1. From Fig. 13, we see that our LA algorithm achieves the highest JFI followed by the WRR. The reader should note Fig. 14. Fairness comparison of the different LB algorithms in a static environment with varying arrival rate and with 15 servers. that the WRR operates with extra knowledge than the LA algorithm, in which it assumes complete knowledge of the servers’ serving rates to deﬁne its weights. Thus, we state that the LA algorithm is a superior solution in the sense that it achieves almost optimal JFI values, around unity, with little information, i.e., with no knowledge of the serving rates of the servers. Similarly, we conducted an experiment with 15 servers using the same settings as in Section V-B1. Fig. 14 shows the behavior of our LA algorithms versus the state-of-the-art comparison algorithms. We observe similar remarks to those of the case of three servers reported in Fig. 13. In fact, the LA algorithms are the most superior algorithm in terms of JFI followed by WRR. However, the Po2 achieves the lowest performance, which was not the case when we used three servers (see Fig. 13). The primary reason for this is that, as the number of servers increases, the Po2 will by deﬁnition select among two random servers among 15 servers, which gives it a limited view of the environment composed of a high number of servers, in this case, 15, and, consequently, leads to poor performance. VI. CONCLUSION With the proliferation of network-based services, the increasing popularity of the cloud approaches that allow fair LB is becoming more important than before. Cloud computing is characterized by the volatility of resources and the vari- ability that makes static LB approaches inefﬁcient. In this article, we presented a dynamic LB approach that aspires to achieve “almost optimal” fairness between different servers in terms of a QoS-based metric. We used the theory of LA to deal with the problem and designed a sophisticated LA that combined the time-separation paradigm and the concept of “artiﬁcial” ergodic (i.e., nonabsorbing) barriers, which was recently introduced by Yazidi and Hammer [51] and Yazidi et al. [52], respectively. In contrast to classical LA, the envi- ronment considered was modeled to be nonstationary, and the reward probabilities were shown to be characterized by a law of diminishing returns. As a future research endeavor, we intend to implement our solution in a real-life cloud setting and to test its efﬁciency and fairness compared with other classical approaches. ACKNOWLEDGMENT The authors are very grateful for the feedback from the anonymous referees of the original submission. Their input signiﬁcantly improved the quality of this ﬁnal version. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. 3456 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 REFERENCES [1] M. Agache and B. J. Oommen, “Generalized pursuit learning schemes: New families of continuous and discretized learning automata,” IEEE Trans. Syst., Man, Cybern. B. Cybern., vol. 32, no. 6, pp. 738–749, Dec. 2002. [2] A. Benveniste, P. Priouret, and M. Métivier, Adaptive Algorithms and Stochastic Approximations. New York, NY, USA: Springer-Verlag, 1990. [3] E. A. Billard, “Stabilizing distributed queuing systems using feedback based on diversity,” IEEE Trans. Syst., Man, Cybern. A, Syst. Humans, vol. 27, no. 2, pp. 251–256, Mar. 1997. [4] P. N. D. Bukh and R. Jain, The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Mea- surement, Simulation, and Modeling. 1992. [Online]. Available: [5] P. H. Calamai and J. J. Moré, “Projected gradient methods for linearly constrained problems,” Math. Program., vol. 39, no. 1, pp. 93–116, Sep. 1987. [6] G. C. Chasparis and J. S. Shamma, “Network formation: Neighborhood structures, establishment costs, and distributed learning,” IEEE Trans. Cybern., vol. 43, no. 6, pp. 1950–1962, Dec. 2013. [7] N. Dragoni et al., “Microservices: Yesterday, today, and tomorrow,” in Present and Ulterior Software Engineering. Cham, Switzerland: Springer, 2017, pp. 195–216. [Online]. Available: com/chapter/10.1007/978-3-319-67425-4_12 [8] A. Enami, J. A. Torkestani, and A. Karimi, “Resource selection in computational grids based on learning automata,” Expert Syst. Appl., vol. 125, pp. 369–377, Jul. 2019. [9] M. Fahimi and A. Ghasemi, “A distributed learning automata scheme for spectrum management in self-organized cognitive radio network,” IEEE Trans. Mobile Comput., vol. 16, no. 6, pp. 1490–1501, Jun. 2017. [10] O. Ghaleb and B. J. Oommen, “Learning automata-based solutions to the single elevator problem,” in Proc. IFIP Int. Conf. Artif. Intell. Appl. Innov. Cham, Switzerland: Springer, 2019, pp. 439–450. [Online]. Available: 7_37 [11] E. J. Ghomi, A. M. Rahmani, and N. N. Qader, “Load-balancing algorithms in cloud computing: A survey,” J. Netw. Comput. Appl., vol. 88, pp. 50–71, Jun. 2017. [12] R. L. Grossman, “The case for cloud computing,” IT Prof., vol. 11, no. 2, pp. 23–27, Mar./Apr. 2009. [13] J. Kleinberg and E. Tardos, Algorithm Design: Pearson New Interna- tional Edition. London, U.K.: Pearson Higher Ed, 2013. [14] P. S. Kumar, “A simple learning scheme for priority assignment at a single-server queue,” IEEE Trans. Syst., Man, Cybern., vol. 16, no. 5, pp. 751–754, Sep. 1986. [15] T. Kunz, “The inﬂuence of different workload descriptions on a heuristic load balancing scheme,” IEEE Trans. Softw. Eng., vol. 17, no. 7, pp. 725–730, Jul. 1991. [16] S. Lakshmivarahan, Learning Algorithms Theory and Applications. New York, NY, USA: Springer-Verlag, 1981. [17] J. D. Little and S. C. Graves, “Little’s law,” in Building Intuition. Boston, MA, USA: Springer, 2008, pp. 81–100. [Online]. Available: [18] L. Mason, “An optimal learning algorithm for S-model environments,” IEEE Trans. Autom. Control, vol. AC-18, no. 5, pp. 493–496, Oct. 1973. [19] P. Mell and T. Grance. (2018). The NIST Deﬁnition of Cloud Com- puting. Accessed: Sep. 16, 2019. [Online]. Available: nist.gov/publications/detail/sp/800-145/ﬁnal [20] M. R. Meybodi, “Learning automata and its application to prior- ity assignment in a queueing system with unknown characteristics,” Ph.D. dissertation, School Elect. Eng. Comput. Sci., Univ. Oklahoma, Norman, OK, USA, 1983. [Online]. Available: bitstream/handle/11244/5130/8314780.PDF?sequence=1&isAllowed=y [21] M. Meybodi and S. Lakshmivarhan, “A learning approach to prior- ity assignment in a two class m/m/1 queuing system with unknown parameters,” in Proc. 3rd Yale Workshop Appl. Adapt. Syst. Theory. New Haven, CT, USA: Yale Univ., 1983, pp. 106–109. [22] R. Mirchandaney and J. A. Stankovic, “Using stochastic learn- ing automata for job scheduling in distributed processing systems,” J. Parallel Distrib. Comput., vol. 3, no. 4, pp. 527–552, Dec. 1986. [23] S. Misra, P. V. Krishna, K. Kalaiselvan, V. Saritha, and M. S. Obaidat, “Learning automata-based QoS framework for cloud IaaS,” IEEE Trans. Netw. Service Manag., vol. 11, no. 1, pp. 15–24, Mar. 2014. [24] S. Misra, S. S. Chatterjee, and M. Guizani, “Stochastic learning automata-based channel selection in cognitive radio/dynamic spectrum access for WiMAX networks,” Int. J. Commun. Syst., vol. 28, no. 5, pp. 801–817, 2015. [25] M. Mitzenmacher, “The power of two choices in randomized load balancing,” IEEE Trans. Parallel Distrib. Syst., vol. 12, no. 10, pp. 1094–1104, Oct. 2001. [26] K. Najim and A. S. Poznyak, Learning Automata: Theory and Applica- tions. Oxford, U.K.: Pergamon Press, 1994. [27] K. S. Narendra and M. A. L. Thathachar, Learning Automata: An Introduction. Upper Saddle River, NJ, USA: Prentice-Hall, 1989. [28] A. Nordrum. Popular Internet of Things Forecast of 50 Billion Devices by 2020 is Outdated, 2018. Accessed: Sep. 16, 2019. [Online]. Available: internet-of-things-forecast-of-50-billion-devices-by-2020-is-outdated [29] M. S. Obaidat, G. I. Papadimitriou, and A. S. Pomportsis, “Learning automata: Theory, paradigms, and applications,” IEEE Trans. Syst., Man, Cybern. B. Cybern., vol. 32, no. 6, pp. 706–709, Dec. 2002. [30] B. J. Oommen, “Absorbing and ergodic discretized two-action learning automata,” IEEE Trans. Syst., Man, Cybern., vol. SMC-16, no. 2, pp. 282–293, Mar. 1986. [31] J. Parent, K. Verbeeck, J. Lemeire, A. Nowe, K. Steenhaut, and E. Dirkx, “Adaptive load balancing of parallel applications with multi-agent rein- forcement learning on heterogeneous systems,” Sci. Program., vol. 12, no. 2, pp. 71–79, 2004. [32] D. K. Patel, D. Tripathy, and C. R. Tripathy, “Survey of load balancing techniques for grid,” J. Netw. Comput. Appl., vol. 65, pp. 103–119, Apr. 2016. [33] C. Pettey. (2019). Cloud Shift Impacts all it Markets. Accessed: Sep. 16, 2019. [Online]. Available: smarterwithgartner/cloud-shift-impacts-all-it-markets/ [34] A. S. Poznyak and K. Najim, Learning Automata and Stochastic Optimization. Berlin, Germany: Springer-Verlag, 1997. [35] A. A. Rahmanian, M. Ghobaei-Arani, and S. Toﬁghy, “A learn- ing automata-based ensemble resource usage prediction algorithm for cloud computing environment,” Future Gener. Comput. Syst., vol. 79, pp. 54–71, Feb. 2018. [36] H. Roh, C. Jung, W. Lee, and D.-Z. Du, “Resource pricing game in geo-distributed clouds,” in Proc. IEEE INFOCOM, Apr. 2013, pp. 1519–1527. [37] Q. Sang, Z. Lin, and S. T. Acton, “Learning automata for image segmentation,” Pattern Recognit. Lett., vol. 74, pp. 46–52, Apr. 2016. [38] S. H. Seyyedi and B. Minaei-Bidgoli, “Using learning automata to determine proper subset size in high-dimensional spaces,” J. Exp. Theor. Artif. Intell., vol. 29, no. 2, pp. 415–432, Mar. 2017. [39] R. Simha and J. F. Kurose, “Relative reward strength algorithms for learning automata,” IEEE Trans. Syst., Man, Cybern., vol. 19, no. 2, pp. 388–398, Mar./Apr. 1989. [40] A.-A. Tantar, A. Q. Nguyen, P. Bouvry, B. Dorronsoro, and E.-G. Talbi, “Computational intelligence for cloud management cur- rent trends and opportunities,” in Proc. IEEE Congr. Evol. Comput., Jun. 2013, pp. 1286–1293. [41] A. Tchernykh, U. Schwiegelsohn, V. Alexandrov, and E.-G. Talbi, “Towards understanding uncertainty in cloud computing resource provi- sioning,” Procedia Comput. Sci., vol. 51, pp. 1772–1781, 2015. [Online]. Available: science/issues and computer-science/vol/51/suppl/C [42] M. L. Tsetlin, Automaton Theory and Modeling of Biological Systems. New York, NY, USA: Academic, 1973. [43] S. M. Vahidipour and M. Esnaashari, “Priority assignment in queuing systems with unknown characteristics using learning automata and adaptive stochastic Petri nets,” J. Comput. Sci., vol. 24, pp. 343–357, Jan. 2018. [44] S. M. Vahidipour, M. R. Meybodi, and M. Esnaashari, “Learning automata-based adaptive Petri net and its application to priority assign- ment in queuing systems with unknown parameters,” IEEE Trans. Syst., Man, Cybern. Syst., vol. 45, no. 10, pp. 1373–1384, Oct. 2015. [45] V. I. Varshavskii and I. P. Vorontsova, “On the behavior of stochastic automata with a variable structure,” Autom. Remote Control, vol. 24, no. 3, pp. 327–333, 1963. [46] G. Velusamy and R. Lent, “Dynamic cost-aware routing of Web requests,” Future Internet, vol. 10, no. 7, p. 57, Jun. 2018. [47] K. Verbeeck, A. Nowé, and K. Tuyls, “Coordinated exploration in multi- agent reinforcement learning: An application to load-balancing,” in Proc. 4th Int. Joint Conf. Auto. Agents Multiagent Syst. (AAMAS), 2005, pp. 1105–1106. [48] R. Wheeler and K. Narendra, “Decentralized learning in ﬁnite Markov chains,” IEEE Trans. Autom. Control, vol. 31, no. 6, pp. 519–526, Jun. 1986. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3457 [49] Z. Yang, Y. Liu, Y. Chen, and L. Jiao, “Learning automata based Q-learning for content placement in cooperative caching,” 2019, arXiv:1903.06235. [Online]. Available: [50] A. Yazidi, O.-C. Granmo, and B. J. Oommen, “Learning-automaton- based online discovery and tracking of spatiotemporal event patterns,” IEEE Trans. Cybern., vol. 43, no. 3, pp. 1118–1130, Jun. 2013. [51] A. Yazidi and H. L. Hammer, “Solving stochastic nonlinear resource allocation problems using continuous learning automata,” Appl. Intell., vol. 48, no. 11, pp. 4392–4411, 2018. [52] A. Yazidi, H. L. Hammer, and T. M. Jonassen, “Two-time scale learning automata: An efﬁcient decision making mechanism for stochastic nonlin- ear resource allocation,” Appl. Intell., vol. 49, pp. 3392–3405, Apr. 2019. [53] J. Zhang, C. Wang, D. Zang, and M. Zhou, “Incorporation of optimal computing budget allocation for ordinal optimization into learning automata,” IEEE Trans. Autom. Sci. Eng., vol. 13, no. 2, pp. 1008–1017, Apr. 2016. Anis Yazidi (Senior Member, IEEE) received the M.Sc. and Ph.D. degrees from the University of Agder, Grimstad, Norway, in 2008 and 2012, respectively. He was a Researcher with Teknova AS, Grimstad. From 2014 to 2019, he was an Associate Professor with the Department of Computer Science, Oslo Metropolitan University, Oslo, Norway, where he is currently a Full Professor and leading the Research Group in Applied Artiﬁcial Intelligence. He is also Professor II with the Norwegian University of Sci- ence and Technology (NTNU), Trondheim, Norway. His current research interests include machine learning, learning automata, stochastic optimization, and autonomous computing. Ismail Hassan received the M.Sc. degree in network and system administration from the University of Oslo, Oslo, Norway, in 2005. In 2005, he joined the Oslo University College (OsloMet), Oslo Metropolitan University, Oslo, as a Senior System and a Network Engineer, and after four years, transitioned to the position of Assistant Professor. He is currently an Assistant Professor with OsloMet. His ﬁeld of interests includes cyberse- curity, networking technologies, operating systems, DevSecOps, teaching, and learning methods. Hugo L. Hammer received the M.Sc. and Ph.D. degrees from the Norwegian University of Science and Technology, Trondheim, Norway, in 2003 and 2008, respectively. He is currently a Full Professor of statistics with the Department of Computer Science, Oslo Metropolitan University, Oslo, Norway. His current research interests include computer-intensive sta- tistical methods, Bayesian statistics, and learning systems. B. John Oommen (Life Fellow, IEEE) was born in Coonoor, India, in September 1953. He received the B.Tech. degree from IIT Madras, Chennai, India, in 1975, the M.E. degree from the Indian Institute of Science, Bengaluru, India, in 1977, and the M.S. and Ph.D. degrees from Purdue University, West Lafayette, IN, USA, in 1979 and 1982, respectively. He was with the School of Computer Science, Car- leton University, Ottawa, ON, Canada, from 1981 to 1982, where he is currently a Full Professor and, since July 2006, has been the Chancellor’s Professor, which is a lifetime award from Carleton University. He is the author of more than 485 refereed journal and conference publications. His research interests include automata learning, adaptive data structures, statistical and syntactic pattern recognition, stochastic algorithms, and partitioning algorithms. Dr. Oommen is also a fellow of the International Association for Pat- tern Recognition (IAPR). He has served on the Editorial Board of the IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS and Pattern Recognition. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply."
A graph neural approach for group recommendation system based on pairwise preferences,Roza Abolghasemi and Enrique Herrera Viedma and Paal Engelstad and Youcef Djenouri and Anis Yazidi,2024,,107,Information Fusion,article,"Information Fusion 107 (2024) 102343
Available online 2 March 2024
1566-2535/© 2024 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
Contents lists available at ScienceDirect
Information Fusion
journal homepage: www.elsevier.com/locate/inffus
A graph neural approach for group recommendation system based on
pairwise preferences
Roza Abolghasemi a,∗, Enrique Herrera Viedma b, Paal Engelstad a, Youcef Djenouri c,d,e,
Anis Yazidi a
a Department of Computer Science, Oslo Metropolitan University (OsloMet), Oslo, Norway
b Andalusian Research Institute in Data Science and Computational Intelligence, University of Granada, Granada, Spain
c University of South-Eastern Norway, Kongsbeg, Norway
d Norwegian Research Center, Oslo, Norway
e IDEAS NCBR, Warsaw, Poland
A R T I C L E
I N F O
Keywords:
Graph clustering
Pairwise preferences
Recommendation systems
Group decision making
Group recommendation systems
A B S T R A C T
Pairwise preference information, which involves users expressing their preferences by comparing items,
plays a crucial role in decision-making and has recently found application in recommendation systems. In
this study, we introduce GcPp, a clustering algorithm that leverages pairwise preference data to generate
recommendations for user groups. Initially, we construct individual graphs for each user based on their
pairwise preferences and utilize a graph convolutional network to predict similarities between all pairs of
graphs. These predicted similarity scores form the foundation of our research. We then construct a new
graph where users are nodes and the edges are weighted according to the predicted similarities. Finally, we
perform clustering on the graph’s nodes (users). By evaluating various metrics, we found that employing a
similarity metric based on a convolutional neural network (SimGNN) with our proposed ground truth called
Top-K yielded the highest accuracy. The proposed approach is specifically designed for group recommendation
systems and holds significant potential for group decision-making problems. Code is available at https:
//github.com/RozaAbolghasemi/Group_Recommendation_Syatem_GcPp_clustering.
1. Introduction
With the dramatic expansion of the web of things, recommendation
systems are nowadays prevalent in our daily lives [1–3]. Recommenda-
tion systems explore the historical data represented by user information
and preferences to decide which items might be recommended for
new observations. Numerous recommendation algorithms have been
suggested in the last decade, however, a few of them have been
successfully utilized in real settings [4–6]. However, we are far from
handling the pairwise preferences problem, which is considered a
key ingredient in modern recommendation systems [7,8]. In order to
efficiently explore pairwise preferences, more intelligent methods need
to be incorporated into the recommendation process. Clustering has
paramount importance in the exploration and analysis of data, and it
has extensive applications in data mining, information retrieval, deci-
sion making, computer graphics, bioinformatics, and Very-large-scale
integration (VLSI) design. For an overview of clustering techniques and
applications, we refer the reader to [9]. Usually, clustering consists of
discovering natural groups of similar elements in datasets. However,
∗Corresponding author.
E-mail address: rozaabol@oslomet.no (R. Abolghasemi).
since the similarity can be represented using graphs, graph clustering
has gotten very attention as an important variant of data clustering.
Moreover, to have a more accurate clustering method, using an ac-
curate similarity measure is very crucial. In the learning process, a
good graph similarity function/model would be able to capture all the
hidden information of the data and predict the relationships between
the data points to be able to predict more accurate similarity scores.
Additionally, in some areas like group decision making (GDM) [10,
11] and more specifically group recommendation systems (GRS) [12],
where the pairwise preferences of the users are available, a possible
solution to find common decision/recommendation for the group, is to
first find similar users. The intuition behind this is that similar users
will likely have similar preferences, and their decisions are likely to be
more similar compared to dissimilar users.
This paper addresses the problem of group recommendation based
on graph clustering. In the proposed graph clustering, for each node,
some information like its pairwise preferences is available. Among
the conventional graph similarity methods, those based on neural
https://doi.org/10.1016/j.inffus.2024.102343
Received 15 November 2023; Received in revised form 29 February 2024; Accepted 1 March 2024
 Information Fusion 107 (2024) 102343
2
R. Abolghasemi et al.
networks were shown to be more accurate on different types of graphs.
Traditional similarity measures like Euclidean and cosine, are based
on the input vectors, and graph similarity measures like graph edit
distance (GED) [13] are based on the structure of the graph. Unlike
these traditional methods, the neural networks learn the similarity not
only based on the structure of the graph but also the attributes of the
nodes. This is very crucial and shows the power of this type of similarity
method on different types of data/graphs.
It is noteworthy that our work presents a novel approach to eval-
uating user similarity in recommender systems by shifting away from
traditional feature vector reliance to item-based pairwise preferences,
employing the GcPp algorithm and SimGNN model. This shift is moti-
vated by the limitations of conventional similarity measures based on
feature vectors, as highlighted in previous research [14–16]. Specifi-
cally, measures such as PCC, SPCC, CPCC, ACOS, MSD, Jaccard, PIP,
and NHSM are found to exhibit drawbacks in terms of accuracy and
complexity when calculating user similarity. Additionally, the advan-
tages of employing pairwise preferences over pure rating values are
discussed in [17,18], emphasizing the potential for more precise and ac-
curate recommendations. In [12,19,20], the incorporation of pairwise
preferences in group recommendation systems is examined, introducing
Matrix factorization pair-score prediction (MFP) and comparing it with
well-known approaches like BPR [21], and MPR [22]. The analysis
underscores the superiority of utilizing pairwise comparisons in GRS,
particularly when compared to single-rating data.
The main contributions of this work are listed in the following:
1. We transform users’ pairwise preferences into graphs and devise
a graph convolutional neural network (SimGNN) to assess the
similarity between each pair of user graphs. To accomplish this,
we introduce a novel metric named Top-K to associate users with
the top-k most similar items.
2. We develop the GcPp technique, an abbreviation for ‘‘Graph
Clustering based on Pairwise Preference data’’. This method
leverages the dominant set clustering algorithm to consolidate
users with the highest degrees of similarity into cohesive groups.
Specifically, we enhance the dominant set clustering algorithm
by incorporating SimGNN to gauge user similarity.
3. We evaluate the developed model using two pairwise prefer-
ences datasets, and compare SimGNN with well-known simi-
larity metrics. The results reveal the superiority of SimGNN
compared to the baseline metrics.
In our final step, we capitalized on the clusters of users, which rep-
resent groups of individuals with similar preferences. Leveraging these
clusters enabled us to generate recommendations that are not only more
accurate but also fairer. By considering the preferences and characteris-
tics of users within each cluster, we could tailor recommendations more
precisely to the specific needs and interests of the users within those
groups. This approach enhances the overall recommendation system by
ensuring that recommendations are relevant and equitable for all users.
2. Related work
This study is divided into two primary areas of focus: graph cluster-
ing and recommendation and group recommendation. In the upcoming
sections, we will delve into the existing body of research pertaining to
both of these subjects.
2.1. Graph clustering and recommendation
Sieranoja et al. [23] suggested two novel clustering networks and
graphs techniques. The first one is a direct descendant of the k-means
algorithm and is known as the K-algorithm. Similar iterative local
optimization is used, but the means are not necessary. In terms of both
good local optimization capabilities and a propensity to reach a local
optimum, it shares features with k-means clustering. The second one
called M-algorithm, iteratively enhances the K-output algorithm’s to
uncover new and superior local optima. It repeatedly separates and
merges arbitrary clusters, then uses the K-algorithm to fine-tune the
outcomes. Both algorithms can be applied to various cost functions,
which makes them both generic. By lowering information correlation
in two ways, Liu et al. [24] presented the Dual Correlation Reduction
Network (DCRN), a revolutionary self-supervised deep graph clustering
technique. They specifically created a siamense network first to encrypt
samples. Then, they reduced the information correlation at the dual-
level, enhancing the discriminative power of the resulting features by
pushing the cross-view sample correlation matrix and cross-view fea-
ture correlation matrix to resemble two identity matrices, respectively.
Additionally, they applied a propagation regularization term to the
network’s shallow network structure to help the network gain long-
distance information while alleviating representation collapse brought
on by over-smoothing in GCN. Liao et al. [25] put forth a new deep
linear graph attention model for attributed graph clustering (DLGAMC),
which is made up of a similarity-preserving module and an attention-
based aggregation module. To design the attention for aggregation,
which does not require learning additional attention parameters, the
authors only took advantage of cosine similarity. They also suggested
an adaptive technique to assess the smoothness of node representations,
with intra-cluster distance and inter-cluster distance serving as the
essential indicators in this process.
To address the challenging issue in a non-Euclidean space, Guo
et al. [26] proposed an original end-to-end graph clustering archi-
tecture with a combined strategy. They provide a new variational
graph auto-encoder algorithm based on the GCN for learning the graph
embedding that takes into consideration the boosting effect of a joint
generative model of the graph structure and node characteristics on
the embedding output. They developed an auxiliary distribution based
on the embedding representation to provide a self-training mechanism
that improved the prediction of node categories and enabled the unsu-
pervised clustering mode. In order to avoid huge clusters warping the
embedding space, each cluster’s loss contribution is also normalized.
Liu et al. [27] introduced a multilayer graph contrastive clustering
network, which is a general and efficient autoencoder framework for
multilayer graph clustering (MGCCN). Three modules make up the
MGCCN: (1) attentiveness for better node embeddings, a mechanism
that is used to better capture the importance of nodes and their neigh-
bors. (2) A contrastive fusion approach that effectively investigated
the consistent data in various networks. (3) A self-supervised element
that reinforces the node embedding and clustering iteratively. A novel
unsupervised event-oriented graph clustering framework (EGC) was
proposed [28], which does not require labeled data and can perform
efficient clustering on huge datasets with little time overhead. To be
more precise, EGC changes the textual data of social networks after
first mining the potential relations included in social text data. By
utilizing graph structure for the depiction of complicated relations,
media can be converted into an event-oriented graph. Secondly, EGC
reliably measures the weights of relations in event-oriented graphs
using a keyword-based local importance method.
One of the applications of clustering is group decision making
which can be done easier using a good clustering method. In [29,30]
the idea of dealing with large-scale decision-making problems is dis-
cussed. In [31], large-group decision-making and conflict management
are addressed. The authors propose a dynamic adaptive subgroup-to-
subgroup conflict model that focuses on multicriteria decision-making.
They introduce a compatibility index to quantify cognitive and interest
conflicts among experts and utilize the fuzzy c-means clustering algo-
rithm to classify experts into subgroups. The paper [32] investigates the
achievement of cluster average consensus within a finite time frame
in bidirectional networks. Through the design of distributed linear
iterations using stochastic matrices that align with the network topol-
ogy, the authors demonstrate the possibility of always attaining cluster
average consensus in bidirectional networks that have cluster-spanning
 Information Fusion 107 (2024) 102343
3
R. Abolghasemi et al.
trees. A clustering- and maximum consensus-based model with lin-
guistic distribution is proposed for social network large-scale group
decision making (SNLGDM) problems [33]. The model utilizes social
network analysis (SNA) to determine the weights of decision groups
and reduce the dimension of large-scale decision matrices. It involves
the division of large-scale decision makers (DMs) into independent
sub-groups based on trust relationships [34]. Linguistic distribution
(LD) assessments are used to represent the preference relation of sub-
groups [35]. A maximum consensus-based method is then employed to
generate comprehensive weights for the sub-groups by maximizing the
level of consensus between sub-groups and the collective matrix [36].
The final ranking of alternatives is obtained based on the collective
preference relation [37]. The proposed model is verified through nu-
merical examples, coefficient analysis, and comparative analysis. The
paper in [38] proposes an expert clustering and information fusion
method for large group decision-making (LGDM) problems with double
information and heterogeneous experts. It introduces an optimization
model to derive criteria weights of experts based on the minimiza-
tion of deviation between double information. It presents a double
clustering method that combines the similarity degrees of experts’
fuzzy preference relations and their criteria weights to classify large-
scale experts into clusters. A clustering validity index is introduced to
objectively determine the clustering threshold, ensuring the rationality
of the clustering results.
In addition to clustering, graphs have been utilized in various ways
to generate effective recommendations. In the work by Chen et al. [39]
a method named SR-HetGNN is introduced that is a novel session
recommendation method. SR-HetGNN leverages a heterogeneous graph
neural network (HetGNN) to enhance session-based recommendation
systems. Also, [40] introduces Mandari, a novel approach that lever-
ages a Multi-Modal Temporal Knowledge Graph for Next-POI recom-
mendation. It addresses the challenges of modeling implicit associations
in multi-modal data and capturing variations in user preferences over
time intervals. A method named Satori [41] has been introduced that
leverages a user interaction graph to capture relationships between
users, items, and categories and utilizes a graph attention network to
extract auxiliary features. Additionally, it adopts a self-attention mech-
anism to model user intention and preference, combining them to form
a hybrid user representation. The framework in [42] employs multitask
training to optimize the model with auxiliary tasks. It aims to enhance
cross-domain recommendation performance through adaptive learning
and graph-based techniques. To see how deep learning models offer
effective recommendations we refer the reader to [43,44]. The survey
extensively examines recent studies on serendipitous recommendations,
particularly concentrating on deep learning recommendation models.
It categorizes these models based on their integration of serendipity
objectives at different stages of the recommendation process.
2.2. Group recommendation
Utilizing pairwise preference data within Group Recommender Sys-
tems (GRS) significantly enhances the precision of item recommenda-
tions, as it provides detailed insights into users’ preferences (see [10,
12]). A method known as MFP, introduced by [12], predicts personal-
ized item scores based on such pairwise preference data. In developing
the GRS, the study incorporates users’ personality traits, specifically
assertiveness, and cooperativeness, which closely resemble real-world
decision-making scenarios. Furthermore, the application of an opinion
dynamics model aids in achieving consensus within the system. In [10],
a novel approach grounded in entropy is presented for the prediction
of missing data within pairwise preference datasets. This method excels
by capitalizing on user and item similarity for prediction, even when
confronted with exceptionally sparse datasets, surpassing traditional
methods that may yield no results in such scenarios. The principal
domain of application for this innovative concept lies within Group
Recommender Systems and Group DecisionMaking challenges.
Deep learning plays a pivotal role in both Recommendation sys-
tems and Group Recommender Systems (GRS) methods, as evident in
recent works [45–47]. In the context of GRS, an innovative approach
employing a Graph Attention Network (GAT) is presented in [48]. This
method initially clusters users based on movie genre preferences and
user similarities. Subsequently, it employs GAT to predict users’ movie
ratings by considering their preferences and group relationships. Addi-
tionally, Wu et al. [49] propose a GRS tailored for network document
resource exploration, leveraging knowledge graphs and LSTM within
edge computing. This approach effectively addresses issues related to
information overload and resource tracking. Ait et al. [50] introduced a
distributed group recommendation system built on Apache Spark. This
system employs a novel recommendation method, dimension reduction
techniques, and supervised and unsupervised learning to address the
curse of the dimensionality problem, identify user groups, and enhance
prediction quality. Ali-Yari et al. [51] dealt with the concern related to
the uncertainty and ambiguity surrounding a tourist’s group member-
ship in group tourism. They developed a group recommendation system
that incorporates uncertainty modeling using Bayesian networks, Pear-
son similarity factors, and SOM clustering. It models uncertainties and
estimates tourism preferences for each group, reducing the impact of in-
sufficient user information. The system also suggests tourist attractions
and optimal routes via Google Maps for each user group, enhancing the
recommendation experience. In order to reduce the clustering cost in
group recommendation, Seo et al. [52] introduced a GRS based on the
genre preferences of users. They established a genre preference vector
and employed it for group clustering, resulting in more efficient time
complexity due to the smaller number of genres compared to items.
Furthermore, they introduced a novel item preference mechanism,
incorporating genre weights to further refine user preferences.
2.3. Discussions
In this section, we provide a summary of the limitations and
strengths of the related works, which can be found in the Tables 1 and
2.
3. Method design
3.1. Principle
Within this section, we elucidate the proposed approach, which
encompasses two main steps including GcPp clustering and group
recommendation subsequent to data preprocessing. Fig. 1 indicates the
logical diagram of the proposed method. During the data preprocessing
phase, the data is transformed into a standardized format as follows: if
expert 𝑢expresses a preference for item 𝑖over item 𝑗, the corresponding
pairwise preference 𝑝(𝑢)
𝑖𝑗
is assigned a value of 1. Conversely, if the
two items are considered equally preferred, the preference value 𝑝(𝑢)
𝑖𝑗
is set to 0.5. In cases where expert 𝑢does not prefer item 𝑖over item
𝑗, the pairwise preference value 𝑝(𝑢)
𝑖𝑗
is 0. In the subsequent sections,
we provide comprehensive explanations of both the GcPp clustering
approach and the proposed group recommendation system, delving into
their intricacies and details.
3.2. Clustering
In this section, we present a detailed description of the GcPp (graph
clustering pairwise preference) method. An overview of the proposed
approach is depicted in Fig. 2, and the pseudo-code implementation can
be found in Section 3.2.5. The method encompasses four main phases
as follows:
• The dataset, comprising pairwise preferences of users, is trans-
formed into graphs, as described in Section 3.2.1 and illustrated
in Fig. 2 (part a).
 Information Fusion 107 (2024) 102343
4
R. Abolghasemi et al.
Table 1
Merits and limits of the related works in graph clustering.
Paper
Merit
Limit
Sami et al. [23]
Introducing two cost functions and two clustering methods
that can be applied with various cost functions. Notably, the
M-algorithm outperforms eight other state-of-the-art methods.
The M-algorithm incurs a high computational cost because it
involves the repetitive merging and splitting of random
clusters.
Liu et al. [24]
The suggested DCRN aims to diminish information
correlation at sample and feature levels, a crucial aspect in
preventing representation collapse, ultimately leading to
improved clustering outcomes.
The method’s computational complexity and scalability for
larger graphs require further exploration for practical use
cases.
Liao et al. [25]
Decreasing the attention parameters within GCN, which
involves incorporating a nonlinear attention mechanism that
includes both attribute information similarity and the local
graph structure.
The node pair selection process for the introduced
similarity-preserved module requires improvement.
Guo et al. [26]
The paper’s innovative end-to-end graph clustering approach
effectively integrates embedding and clustering, enhancing
the accuracy of unsupervised clustering tasks.
The paper does not account for unknown prior knowledge of
clusters, leaving potential room for improvement in handling
real-world applications where such information may be
valuable.
Liu et al. [27]
The paper introduces MGCCN, an innovative autoencoder
framework for multilayer graph clustering, surpassing
existing methods in handling complex network frameworks,
often limited to multiview attributes or multiple networks.
The MGCCN framework, while effective, may face scalability
challenges with extremely large or high-dimensional datasets,
requiring careful consideration for practical use.
Hu et al. [28]
EGC effectively converts social text data into an
event-oriented graph, delivering high-quality clustering
performance, rapid query times, and eliminating the need for
labeled data, facilitating timely public opinion analysis on
social media.
The paper may face challenges in optimizing the
event-oriented graph generation for a more lightweight
representation of social text data and improving the
execution time of the graph clustering algorithm.
Morente et al. [29]
The paper introduces an innovative GDM method that
effectively reduces information overload by clustering a large
set of alternatives into manageable groups for expert
discussions and decision-making.
This method’s effectiveness may depend on the quality of
clustering, and it may not fully address the challenges of
handling extremely complex decision environments with
diverse alternatives.
Ding et al. [30]
The paper defines and categorizes Large Scale Decision
Making (LSDM) frameworks, offering insights into managing
complex decision processes involving diverse stakeholders.
It primarily focuses on theoretical models and future research
directions, potentially requiring practical implementation and
validation of LSDM solutions for real-world applicability.
Tang et al. [31]
The paper introduces a dynamic conflict resolution model for
large-scale group decision-making, enhancing our
understanding of conflict management in complex decision
contexts.
Further research is needed to assess the model’s applicability
in diverse settings like social networks and its adaptability to
alternative opinion representation methods.
Shang et al. [32]
The paper provides insights into achieving finite-time cluster
average consensus on bidirectional networks with
cluster-spanning trees, offering valuable guidance for
noise-free scenarios.
The study does not address directed networks or
communication noises, common in practical applications, and
further research is needed to adapt the results to these
scenarios and explore delay robustness.
Table 2
Merits and limits of the related works in group recommendation systems.
Paper
Merit
Limit
Roza et al. [12]
Attaining highly precise and equitable GRS by leveraging
detailed information from pairwise preference data,
incorporating user personalities, and employing opinion
dynamics to reach consensus.
For users, the process of completing the TKI test to unveil
their personality traits can be time-consuming, and turning
to user their social media content may present a feasible
alternative.
Roza et al. [10]
An entropy-based method excels at estimating missing values
in pairwise preference data for GRS and GDM, using user
and item similarity, making it stand out from conventional
methods that struggle with sparse datasets.
Like other methods, the overall model fitting, when
minimizing the cross-entropy loss function, tends to produce
larger errors as the problem’s dimension, specifically the
number of alternatives, increases.
Liao et al. [48]
Utilizing GAT (Graph Attention Network), clustering based
on movie genre preferences and user similarities leads to
significantly improved recommendation accuracy in GRS.
High time complexity due to the nature of the deep learning
techniques.
Wu et al. [49]
By employing a knowledge graph and LSTM within edge
computing for GRS, it effectively addresses the challenges of
information overload and resource tracking.
High time complexity due to the nature of the deep learning
techniques.
Badr et al. [50]
A distributed GRS, built on Apache Spark, capable of
managing large-scale data and addressing sparsity issues.
The absence of social relationship interactions to boost the
performance of the architectures.
Ali et al. [51]
Modeling uncertainties reduces the impact of limited user
information and enhances the recommendation experience by
suggesting tourist attractions and optimal routes through
Google Maps.
The proposed SOM-based method is not compared with other
clustering methods.
Seo et al. [52]
Reduced clustering cost and enhanced time efficiency are
achieved by clustering based on user genre preferences
rather than item ratings.
It appears that all movies (items) sharing the same genre are
assigned an equal weight (score), which could pose
challenges when recommending a subset of items from a
pool with the same genre.
 Information Fusion 107 (2024) 102343
5
R. Abolghasemi et al.
Fig. 1. Logical diagram of the process of the proposed method.
• The similarity between users (graphs of items) is predicted using
the graph convolutional network called SimGNN [53], as depicted
in Fig. 2 (part b) and described in Section 3.2.1.
• A graph is constructed with users represented as nodes, and the
predicted similarity score between each pair of users is assigned
as the weight of the corresponding edge, as shown in Fig. 2 (part
c).
• The ‘‘Dominant-set’’ algorithm [54] is employed as a graph clus-
tering method to group the users based on their relationships.
This algorithm partitions the user graph into distinct clusters by
identifying dominant sets of nodes. The process of clustering is
depicted in Fig. 2 (part d), and you can find detailed explanations
in Section 3.2.3.
In the final phase, we conducted an evaluation of our clustering ap-
proach using various metrics. In the subsequent sections, we will
elaborate on the details of predicting similarity between pairs of graphs
and the process of clustering a graph. This will provide a comprehen-
sive understanding of how the similarity prediction and clustering steps
were executed, allowing for a more in-depth analysis of our approach.
3.2.1. Similarity of graphs
In this section, we will outline our approach for predicting the
similarity scores among users. Based on our datasets, which are de-
scribed in Section 4.1, pairwise preferences on items are available for
each user. This means that users have compared every pair of items
and indicated their preferences. Specifically, we assign 𝑝(𝑢)
𝑖𝑗
= 1 if
user 𝑢prefers item 𝑖over item 𝑗, and 𝑝(𝑢)
𝑖𝑗
= 0 otherwise. To capture
these preferences, we convert the pairwise preferences into graphs
for each user (refer to Fig. 2, part a). In these graphs, the items are
represented as nodes, and a directed edge exists between two nodes
if and only if 𝑝(𝑢)
𝑖𝑗
= 1. Each graph represents the preferences of a
specific user. We utilize these graphs to predict the similarity among
users. Consequently, predicting the similarity between pairs of users
is transformed into predicting the similarity scores between pairs of
graphs. In this study, we adopt the concept of ‘‘a neural network
approach to fast graph similarity computation (SimGNN)’’ introduced
in [53]. An overview of this approach is depicted in Fig. 2 (part b).
The SimGNN model employs a learnable embedding function based on
graph convolutional networks (GCN) to generate an embedding vector
for each graph, which serves as a condensed representation of the
graph. Furthermore, the model incorporates a novel attention mecha-
nism to highlight the significant nodes based on a specific similarity
metric. This attention mechanism aims to emphasize the nodes that
contribute most to the overall similarity computation. Additionally, a
pairwise node comparison method is devised to enhance the graph-level
embeddings by incorporating detailed node-level information. Finally,
fully-connected neural networks are employed to predict the similarity
scores. These networks leverage the graph-level embeddings and the
fine-grained node-level information to estimate the similarity between
pairs of graphs.
3.2.2. Top-K similarity
As SimGNN is a learning algorithm, it requires similarity scores
for each pair of graphs as ground truth. To address this, we used
the Top-k method which is introduced in this section. As previously
mentioned, in our algorithm, each user corresponds to a graph. Thus,
the similarity among users can be leveraged as the similarity between
their corresponding graphs. To achieve this, we utilize the pairwise
preferences of the users as follows: for each user, we arrange the items
in descending order of preference based on personalized item scores
calculated using the following equation:
𝑣(𝑢)
𝑖
=
∑
𝑗∈𝐼⧵{𝑖} 𝑝(𝑢)
𝑖𝑗
|𝐼|
.
(1)
Here, 𝑣(𝑢)
𝑖
represents the personalized item score of user 𝑢on item
𝑖. This score quantifies the degree of preference that user 𝑢has for
item 𝑖relative to all other items in the set 𝐼(refer to [12] for more
details). Using these personalized item scores, we sorted the items for
each user and selected the top-k items with the highest scores as their
most preferred items. Consequently, the Top-K similarity score between
every pair of users is computed as follows:
𝑆(𝑇𝑜𝑝−𝐾)
𝑢𝑖,𝑢𝑗
=
|||𝑢(𝑇𝑜𝑝−𝐾)
𝑖
∩𝑢(𝑇𝑜𝑝−𝐾)
𝑗
|||
𝐾
(2)
where 𝑢𝑇𝑜𝑝−𝐾
𝑖
represents the set of K-most preferred items for user
𝑢𝑖. The Top-K similarity scores, derived from the personalized item
scores, serve as the ground truth for training the SimGNN model. By
using these scores, the SimGNN model is incentivized to assign higher
similarity scores to users whose top preferred items exhibit greater
similarity. In other words, the training process encourages the SimGNN
model to capture and reinforce the similarity patterns among users
whose not only their pairwise preferences are similar, but also the top
preferred items align closely with each other.
3.2.3. Clustering of graphs
Once we have predicted the similarity scores for pairs of users, our
next step is to cluster the users based on these scores. The clustering
method employed in this study is based on the concept of a ‘‘Dominant
set’’. This approach, initially introduced by Pavan et al. [54], was
later utilized by Hung et al. [55] for detecting F-formations in social
environments, and by Yazidi et al. [56] for identifying unreliable
sensors.
In the context of graph clustering, a dominant set refers to a
maximal clique within an edge-weighted graph. By leveraging the
dominant set algorithm, we aim to identify cohesive groups of users
who exhibit similar preferences based on the obtained similarity scores.
In the following, we will delve into the details of how the dominant set
algorithm is applied for graph clustering.
 Information Fusion 107 (2024) 102343
6
R. Abolghasemi et al.
Fig. 2. General overview of the proposed GcPp method containing four main steps. a. converting the training data including pairwise preferences to graphs. b. predicting similarity
between every pair of users (graphs) using SimGNN. c. graph of users, nodes are users, and edges are weighted by the similarity of pair of nodes. 4. clustering the users with
Dominant set clustering.
We aim to cluster the data (users), using an undirected edge-
weighted graph without self-loops. This graph, denoted as 𝐺= (𝑉, 𝐸,
𝑤), consists of a set of vertices 𝑉, a set of edges 𝐸, and a positive edge
weight function 𝑤. In this context, the vertices correspond to the users,
and the graph is assumed to be fully connected. However, the edges
have varying weights that reflect the affinity between pairs of nodes.
To quantify the affinity, we utilize the predicted similarity scores
between each pair of users (see Section 3.2.1) as the edge weights. This
 Information Fusion 107 (2024) 102343
7
R. Abolghasemi et al.
relationship is captured by a weighted affinity matrix 𝐴, where each
element 𝑎𝑖𝑗represents the weight 𝑤(𝑖, 𝑗). When considering a subset 𝑆
of vertices in graph 𝐺, we can assess the average weighted degree of a
vertex 𝑖∈𝑆as follows:
𝑘𝑆(𝑖) =
1
|𝑆|
∑
𝑗∈𝑆
𝑎𝑖𝑗.
(3)
The relative affinity between node 𝑗∉𝑆and 𝑖can be expressed as
follows:
𝜙𝑆(𝑖, 𝑗) = 𝑎𝑖𝑗−𝑘𝑆(𝑖).
(4)
It should be noted that for all 𝑖, 𝑗∈𝑉if 𝑖≠𝑗, then 𝜙𝑖(𝑖, 𝑗) = 𝑎𝑖𝑗,
and 𝜙𝑆(𝑖, 𝑗) can be either positive or negative. Ultimately, the weight
of each node 𝑖with respect to a set 𝑆is defined recursively as follows:
𝑤𝑆(𝑖) =
{
1,
𝑖𝑓|𝑆| = 1
∑
𝑗∈𝑆⧵{𝑖} 𝜙𝑆⧵{𝑖}(𝑗, 𝑖)𝑤𝑆⧵{𝑖}(𝑗),
𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒.
(5)
According to this definition, 𝑤𝑆(𝑖) represents the overall relative
affinity (similarity) between node 𝑖and the other vertices in set 𝑆,
weighted by the overall affinity of the vertices in 𝑆
𝑖. Thus, the
following conditions establish the relationship between the internal
nodes (in set 𝑆) and the external nodes (not in set 𝑆) of a dominant
set 𝑆:
𝑤𝑆(𝑖) > 0, ∀𝑖∈𝑆
(6)
𝑤𝑆∪{𝑖}(𝑖) < 0, ∀𝑖∉𝑆
(7)
3.2.4. Extracting dominating sets with replicator dynamics
The theory of replicator dynamics is attributed to the influential
work of Taylor and Jonker [57] for modeling biological processes in
population genetics. Replicator dynamics models a game of a popu-
lation of competing agents where each agent possesses 𝑁strategies
𝑎1, 𝑎2, … , 𝑎𝑁. The global state of the population is described by 𝑥=
(𝑥1(𝑡), … , 𝑥𝑁(𝑡)) with the constraint that ∑
𝑖𝑥𝑖= 1. For each 1 ≤𝑖≤𝑁,
𝑥𝑖(𝑡) denotes the proportion of the population using strategy 𝑎𝑖at time
𝑡. According to Taylor and Jonker [57], the agents encounter each other
randomly. The random encounters yield a change in the fitness function
according to a payoff matrix. The payoff matrix describes the utility
𝐴𝑖𝑗of a player playing strategy 𝑖against a player playing strategy 𝑗.
The replicator dynamics describes the evolution of the frequencies of
strategies in a population. To each 𝑥𝑖we attach a payoff function 𝑓𝑖.
𝑓𝑖is given by (𝐴𝑥)𝑖which is the expected payoff of strategy 𝑎𝑖from
a single interaction with a random individual in the large population.
More precisely, the expected payoff 𝑓𝑖is written as (𝐴𝑥)𝑖= ∑
𝑗𝑎𝑖𝑗𝑥𝑗, the
average payoff of the population as a whole can be written as 𝑥𝑇𝐴𝑥=
∑
𝑖
∑
𝑗𝑎𝑖𝑗𝑥𝑖𝑥𝑗. The frequency of each strategy is changed according to
the difference between its expected payoff and the average payoff of
the population. In formal terms, this is given by:
𝑑𝑥𝑖
𝑑𝑡= 𝑥𝑖(𝑓𝑖−𝑓)
(8)
The ratio of 𝑑𝑥𝑖
𝑑𝑡and 𝑥𝑖is called the relative growth success rate of
the population. Based on the above expressions, we can present in more
detail the replicator dynamics equation given by (Eq. (8)) as:
𝑑𝑥𝑖
𝑑𝑡= 𝑥𝑖(𝑡)[(𝐴𝑥(𝑡))𝑖−𝑥(𝑡)𝑇𝐴𝑥(𝑡)],
𝑖= 1, … , 𝑁.
(9)
The theory of replicator dynamics has found a large set of applica-
tions in graph theory, including finding dominant sets [58,59], solving
the maximum clique problem [60,61], reinforcement learning [62],
resource allocation problems [63], to mention a few. We shall present
a well-known theorem from the theory of replicator dynamics [57].
Theorem 1.
Let 𝐴be a nonnegative, real-valued symmetric 𝑛⋅𝑛ma-
trix. Then the function 𝑥(𝑡)𝑇𝐴𝑥(𝑡) increases with increasing 𝑡along any
nonstationary trajectory 𝑥(𝑡) under continuous-time replicator dynamics.
Furthermore, any such trajectory converges towards a stationary point 𝑥∗.
Finally, a vector 𝑥∗∈𝑆𝑛is asymptotically stable if and only if 𝑥∗is a
strict local maximizer of 𝑥𝑇𝐴𝑥in the simplex 𝑆𝑁given by ∑𝑁
𝑖𝑥𝑖= 1,
𝑥𝑖≥0, 𝑖= 1, … , 𝑁.
3.2.5. Pseudo code for GcPp method
Algorithm 1 GcPp
1: Input: 𝑈= {𝑢1, 𝑢2, … , 𝑢𝑛}: the set of 𝑛users where 𝑢𝑢=
⎡
⎢
⎢
⎢⎣
𝑝(𝑢𝑛)
11
...
𝑝(𝑢𝑛)
1𝑚
...
...
...
𝑝(𝑢𝑛)
𝑚1
...
𝑝(𝑢𝑛)
𝑚𝑚
⎤
⎥
⎥
⎥⎦
is a matrix
containing pairwise preference scores of user 𝑢on 𝑚items.
2: Output: 𝐶= {𝑐1, 𝑐2, ..., 𝑐𝑇∣𝑐𝑡⊂𝑈}: the set of all clusters of users.
3: for each 𝑢𝑖in 𝑈do
4:
𝑔𝑖←𝑔𝑟𝑎𝑝ℎ(𝑢𝑖);
5: end for
6: for every 𝑢𝑖and 𝑢𝑗in 𝑈do
7:
𝑆(𝑇𝑜𝑝−𝐾)
𝑢𝑖,𝑢𝑗
←Top-K(𝑢𝑖, 𝑢𝑗);
8:
𝑤𝑖𝑗←𝑆𝑖𝑚𝐺𝑁𝑁(𝑔𝑖, 𝑔𝑗, 𝑆(𝑇𝑜𝑝−𝐾)
𝑢𝑖,𝑢𝑗
);
9: end for
10: {Graph G=(V, E, w), maximum number of clusters is T}
11: 𝑉←𝑈{users as nodes of graph}
12: 𝐶∶= ∅
13: 𝑡∶= 0
14: while 𝑉≠∅and 𝑡< 𝑇do
15:
𝑐𝑡= 𝐷𝑜𝑚𝑖𝑛𝑎𝑛𝑡_𝑠𝑒𝑡(𝐺)
16:
𝐶←𝐶∪𝑐𝑡
17:
𝑉←𝑉⧵𝑐𝑡
18:
𝑡←𝑡+ 1
19: end while
20: return
𝐶
A pseudocode for the proposed GcPp method is provided in Al-
gorithm 1. This algorithm outlines the steps involved in clustering
the users in 𝑈based on their pairwise preferences. In the algorithm,
we start by converting the pairwise preference scores of each user 𝑢𝑖
into a graph 𝑔𝑖(see Section 3.2.1). Then, we use the Top-K method
to calculate similarity scores between pairs of users and incorporate
them into SimGNN as inputs (see Sections 3.2.1 and 3.2.2). SimGNN
predicts the similarity scores, which are then used as weights (𝑤𝑖𝑗)
for the edges of a graph 𝐺, where the nodes 𝑉represent the users
𝑈. The algorithm proceeds with a while-loop, where in each iteration,
the dominant set of nodes in 𝐺is determined and assigned to a new
cluster. These nodes are then removed from the set of remaining nodes
in 𝐺. The loop continues until the clustering algorithm cannot find any
dominant sets among the remaining nodes. The pseudo-code provides a
comprehensive representation of the GcPp method, showcasing the pro-
cess of converting pairwise preferences to graphs, predicting similarity
scores with SimGNN, constructing the weighted graph, and iteratively
clustering the users based on dominant sets.
3.3. Group recommendation
In this section, we provide a detailed explanation of how we utilize
the proposed GcPp clustering algorithm to offer effective recommen-
dations for groups of users. The core concept of our proposed group
recommendation system (GRS) is centered around the notion of max-
imizing fairness and accuracy when recommending items to a group
of users. Unlike conventional GRS methods that often rely on random
user selections within the groups, resulting in varying preferences and
limited accuracy and fairness, we harness the power of our GcPp
clustering algorithm to form groups of similar users. By leveraging
the pairwise preferences and Top-K preferred items of users, we can
establish a sense of similarity based on shared opinions regarding
item scores. Consequently, the recommended items are expected to
be appealing to the majority of group members, leading to higher
levels of accuracy and fairness. Our proposed GRS comprises several
key steps, namely: 1. personalized item score calculation, 2. group
aggregation, and 3. group recommendation. Below, we provide a more
comprehensive explanation of each step:
 Information Fusion 107 (2024) 102343
8
R. Abolghasemi et al.
• In the initial stage, it is essential to determine the preferences of
each user towards individual items. To achieve this, we calculate
personalized item scores for every user using (1). However, if
the dataset already includes user scores on items, this step can
be skipped, and the existing scores can be directly utilized as
personalized item scores.
• In this stage, we aim to determine the overall scores of items
based on the preferences of users within each group. It is worth
noting that our groups are created by clustering users using
the GcPp method. Specifically, if 𝐶
= {𝑐1, 𝑐2, … , 𝑐𝑇∣𝑐𝑡⊂𝑈}
represents all the clusters obtained from the GcPp method, then
𝐺= {𝑔1, 𝑔2, … , 𝑔𝑇∣𝑔𝑡⊂𝑈} will represent all the corresponding
groups where 𝑔𝑡is equal to 𝑐𝑡. Among various methods available
for group aggregation, this paper focuses on two approaches:
average and approval voting. The average group score for each
item 𝑖in the group 𝑔𝑡denoted by (𝑣(𝑔𝑡)
𝑖
) is calculated by taking the
average of the personalized item scores (1) of all users 𝑢within
that group. This provides a measure of the collective preference
for each item within the group.
𝑣(𝑔𝑡)
𝑖
=
∑
𝑢∈𝑔𝑡𝑣(𝑢)
𝑖
||𝑔𝑡||
(10)
In approval voting, which is a majority-based aggregation method
[64], the group score for an item is determined by counting the
number of users who approve of it. We use the following equation
to calculate the group score for each item:
𝑣(𝑔𝑡)
𝑖
=
∑
𝑢∈𝑔𝑡𝐼(𝑢)
𝑖
||𝑔𝑡||
(11)
Here, 𝐼(𝑢)
𝑖
= 1 if the individual user’s score 𝑣(𝑢)
𝑖
is above the
threshold (𝑣(𝑢)
𝑖
> 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑), and 𝐼(𝑢)
𝑖
= 0 otherwise. In our
experiments, we found that using a threshold of 0.4 produced
better results.
Based on the superior performance observed during the evalua-
tion phase, we have chosen Average as the primary approach for
aggregating group preferences in our system.
• During the group recommendation phase, we arrange the group
scores 𝑣(𝑔𝑡)
𝑖
for all items in descending order and provide rec-
ommendations to each group 𝑔𝑡based on the top-ranked items.
To assess the performance of our group recommendation system,
we evaluate it using various metrics including precision, recall,
F1-score, and fairness.
4. Performance evaluation
4.1. Datasets
For this paper, we utilized two pairwise preference datasets to
support our research and analysis. The details of these datasets are
provided below:
• The food datasets used in this study were gathered through an
online experiment called Consens@OsloMet, conducted at Oslo
Metropolitan University in Norway. The primary objective of the
experiment was to investigate how groups can achieve consen-
sus or general agreement when presented with multiple food
choices, including Chinese, French, Turkish, Italian, Japanese,
and Mexican cuisines. The experiment was officially registered
and approved by the Norwegian Centre for Research Data (NSD)
with reference number 631862. The dataset consists of four trials,
with five users providing their pairwise preferences for six differ-
ent dishes in each trial. In this research, each user and experiment
were treated as distinct individuals, resulting in a dataset that
encompasses the pairwise preferences of 20 users across the six
food items. For more details, please see section 3.2 in [10].
Table 3
Dataset characteristics.
Dataset
Users
Items
Comparisons
Sparsity
BookCrossing
271,379
278,858
5,893,374
99%
MovieLens 1M
6040
3952
104,931,478
92%
XING
784,687
1,029,480
180,601,043
99%
Movie online interface
46
100
2262
54%
Food
20
6
300
0%
Car
60
10
2700
0%
• The second dataset comprises car preferences1 that were provided
by Abbasnejad et al. [65] in 2013. The dataset was gathered
from 60 users residing in the United States, who participated in
the data collection process through Amazon’s Mechanical Turk.2
The dataset focuses on ten distinct cars, treated as individual
items for comparison purposes. Each user in the dataset provided
responses for all 45 possible pairs of items, resulting in a total
of 90 observations for each expert. In addition to the pairwise
preference scores, the dataset also includes two additional files
containing users’ attributes (education, age, gender, and region)
and car attributes (body type, transmission, engine capacity, and
fuel consumed). However, in our study, neither the users’ at-
tributes nor the cars’ attributes were used during the training of
the model.
Table 3 displays the characteristics of six real-world datasets utilized
in recommendation systems. BookCrossing [66], MovieLens 1M,3 and
XING4 encompass both implicit and explicit feedback from users re-
garding items, without incorporating pairwise preferences. Conversely,
datasets such as Movie online interface [18], food and car datasets
contain pairwise preferences expressed by users towards items. In their
work [19] Kalloori et al. extracted both pairwise comparisons and
ratings from the initial data of the first three datasets. For instance, the
BookCrossing dataset comprises implicit (e.g., item clicks) and explicit
user preferences on a 1–10 rating scale. Items with ratings exceeding 7
are deemed relevant, while the rest are considered irrelevant. Pairwise
comparisons are derived by prioritizing items with implicit preferences
over those deemed irrelevant. Similarly, in the XING dataset, interac-
tions such as ‘click’, ‘bookmark’, ‘apply’, and ‘delete’ are recorded, with
‘apply’ interactions signifying relevance and ‘delete’ indicating irrel-
evance. Implicit preferences are inferred from ‘click’ and ‘bookmark’
actions, guiding the derivation of pairwise comparisons. For MovieLens
1M, items rated 4–5 stars are deemed relevant, while those rated 1–
3 stars are considered irrelevant. All user ratings contribute to the
derivation of pairwise comparisons, with differing ratings from the
same user being subtracted.
Table 3 provides an overview of the datasets and their salient
features. Notably, the sparsity metric is calculated as the ratio of
missing elements to the total number of elements. Due to the substantial
sparsity observed in the generated pairwise comparison datasets for
all datasets except food and car, they are unsuitable for our method.
Our method, which relies on SimGNN and GcPp, involves comparing
user graphs, where nodes represent items and directed edges signify
user preferences. The lack of pairwise comparisons makes it impossible
to compare user graphs and compute user similarities. Therefore, the
food and car datasets emerge as optimal choices for our proposed
methodology.
1 http://users.cecs.anu.edu.au/ u4940058/CarPreferences.html.
2 http://mturk.com.
3 https://grouplens.org/datasets/movielens/.
4 2https://github.com/recsyschallenge/2016.
 Information Fusion 107 (2024) 102343
9
R. Abolghasemi et al.
4.2. Clustering performance
In this section, we provide a detailed explanation of the clustering
evaluation methodology employed, the experiments conducted for the
parameter optimization, and present the related results obtained for the
GcPp clustering method and the SimGNN similarity score prediction.
Please note that the evaluation and discussion related to the proposed
Group Recommendation System (GRS) are presented in Section 4.3.
4.2.1. Metrics
According to an informal definition proposed by Jain et al. [67], ‘‘a
cluster is a set of entities which are alike and entities from different
clusters are not alike’’. Consequently, clustering approaches aim to
achieve high internal homogeneity, which translates to high intra-
cluster similarity (as shown in Eq. (12)), and at the same time, to
maintain significant dissimilarity between entities within a cluster and
those outside it, leading to low inter-cluster similarity (as expressed
in Eq. (13)).
In line with this definition, we define the following equations. For
object 𝑖within cluster 𝑐𝐼,
𝑎(𝑖) =
1
||𝑐𝐼|| −1
∑
𝑗∈𝑐𝐼,𝑖≠𝑗
𝑑(𝑖, 𝑗)
(12)
𝑎(𝑖) represents the average distance between object 𝑖and the other
objects within the same cluster (𝑐𝐼), where 𝑑(𝑖, 𝑗) denotes the distance
between objects 𝑖and 𝑗. A smaller value of 𝑎(𝑖) indicates a better
assignment of the object to its respective cluster.
On the other hand, the dissimilarity of the object 𝑖to other clusters,
such as 𝑐𝐽, is defined as the average distance between object 𝑖and all
objects 𝑗within 𝑐𝐽(where 𝑐𝐼≠𝑐𝐽). For each object 𝑖, we calculate:
𝑏(𝑖) = min
𝐽≠𝐼
1
||𝑐𝐽||
∑
𝑗∈𝑐𝐽
𝑑(𝑖, 𝑗)
(13)
defined as the minimum average distance of object 𝑖to all points in any
other cluster to which 𝑖does not belong. By considering Eqs. (12) and
(13), the silhouette score of an object 𝑖can be determined.
𝑠(𝑖) =
⎧
⎪
⎨
⎪⎩
1 −𝑎(𝑖)
𝑏(𝑖)
𝑖𝑓𝑎(𝑖) < 𝑏(𝑖)
0
𝑖𝑓𝑎(𝑖) = 𝑏(𝑖)
𝑏(𝑖)
𝑎(𝑖) −1
𝑖𝑓𝑎(𝑖) > 𝑏(𝑖)
(14)
From this equation, −1 ≤𝑠(𝑖) ≤1, and a higher value of 𝑠(𝑖) indicates
better clustering results.
4.2.2. Experiment and parameter setting (SimGNN)
In this section, we explain our conducted experiments to evaluate
the GcPp clustering method.
Our first step was to determine the optimal parameters for the
experiment. As mentioned earlier, In the process of clustering by GcPp,
we utilized a similarity method called SimGNN, which is a graph
convolutional neural network, to predict the similarity scores between
pairs of graphs. However, since SimGNN is a learning-based method,
we needed ground truth similarity scores for comparison. To facilitate
this comparison, we obtained ground truth scores from two different
similarity methods: graph edit distance (GED) [13] and the Top-K
similarity that we introduced in this paper (see Section 3.2.2). In graph
theory, GED calculates similarity based on the number of node and edge
deletions and insertions required to transform one graph into another.
This method emphasizes the shape of the graphs and its impact on their
similarity. On the other hand, Top-K similarity compares the K-most
preferred items of each pair of users, indicating that users are similar if
their most preferred items are the same. We conducted the SimGNN
experiment with 100 epochs using both Top-K and GED as ground
truth, varying the training batch sizes (128, 256, and 512 for the car
dataset, and 32, 64, and 128 for the food dataset). The corresponding
results are shown in Fig. 3 for the car dataset and Figure Fig. 4 for the
food dataset. Interestingly, the clustering based on the Top-K method
achieved better test loss and exhibited lower validation and training
loss compared to the clustering based on GED. This significant finding
demonstrates that in calculating the users’ similarities, incorporating
valuable user information, such as their best items according to Top-K
similarity, leads to improved similarity score predictions compared to
GED, which solely relies on the graph structure. Regarding the batch
sizes, we observed that a batch size of 128 and 256 performed better
than 512 for the car dataset, while batch sizes of 32 and 64 were more
effective for the food dataset. We reported the minimum validation and
training loss as well as the test loss for all the experiments conducted
on the car dataset in Table 4. The best results are highlighted in bold
for easy reference.
4.2.3. Experiment and parameter setting (GcPp)
In the subsequent phase of the experiment, we employed the pre-
dicted similarity scores to cluster all of the users. Then, we evaluated
our clustering with the silhouette score. As outlined in Section 4.2.1,
the calculation of the silhouette score necessitates a distance metric.
To this end, we utilized five distinct distance metrics, such as the
Euclidean distance and cosine distance, which are computed based on
the distance between the ‘‘feature vectors of the users’’. Notably, these
feature vectors were not employed in the training of our proposed
method. Additionally, we employed the ‘‘inverses of three similarity
methods’’, namely SimGNN, GED, and Top-K, as three distance met-
rics. These three methods only used ‘‘similarity’’ between the ‘‘graphs
of users’’ and not the ‘‘feature vectors of the users’’. The obtained
silhouette scores based on these five distance metrics are presented
in Table 5. Intriguingly, the inverse of SimGNN yielded the highest
score in all experiments, irrespective of the batch sizes and ground
truth methods. Even Top-K outperformed GED in terms of results.
These remarkable findings underscore the effectiveness of our proposed
method in clustering. There are two primary reasons for this: Firstly,
we integrated the pairwise preferences of users, which provided valu-
able and detailed information about their preferences. This inclusion
allowed us to capture the finer nuances of user preferences, leading
to more accurate similarity predictions. Secondly, by using the Top-
K similarity score as the ground truth, we incorporated the overall
preferences of users in a broader sense. This approach allowed us to
consider the general preferences and popular choices among users,
resulting in a more comprehensive understanding of similarity. By
combining these two approaches, we achieved improved performance
in capturing and predicting similarity scores, resulting in better cluster-
ing. As anticipated, the Euclidean and cosine metrics did not perform
as well as the other metrics. This can be attributed to the fact that
we did not employ the feature vectors of users during the training
process. Instead, training solely relied on the structure of graphs (users’
pairwise preferences). In summary, our GcPp clustering method was
implemented using the concept of ‘‘Dominant Set Clustering’’ and incor-
porated predicted similarity scores obtained from SimGNN, where the
Top-K similarity score served as the ground truth. The construction of
graphs was based on the pairwise preference data of the users. Our eval-
uation metrics demonstrated that the users were effectively clustered
using this approach. Subsequently, we utilized these user clusters as
groups in our Group Recommendation System (GRS) implementation.
Through an ablation study, we optimized the system’s parameters and
evaluated its performance.
4.3. Group recommendation performance
In this section, we will elaborate on the evaluation methodology
used for group recommendation. We will provide a comprehensive
explanation of the experiments conducted to optimize the system’s
parameters and perform an ablation study. Furthermore, the results
obtained from these experiments will be presented and discussed in
detail.
 Information Fusion 107 (2024) 102343
10
R. Abolghasemi et al.
Fig. 3. Car dataset: Performance evaluation of SimGNN with 100 epochs and varying Training batch sizes (128, 256, 512). (Left) Ground truth: is Top-K, (Right) Ground truth is
GED.
Fig. 4. Food dataset: Performance evaluation of SimGNN with 100 epochs and varying Training batch sizes (32, 64, 128). (Left) Ground truth: is Top-K, (Right) Ground truth is
GED.
Table 4
SimGNN was implemented with various parameter configurations, including different ground truth methods
(Top-K and GED) and batch sizes (128, 256, and 512). The minimum loss obtained for each setup is
highlighted in bold.
Ground truth: Top-K
Ground truth: GED
Train and validation batch
Train and validation batch
128
256
512
128
256
512
Min validation loss
0.002
0.002
0.003
0.004
0.006
0.010
Min train loss
0.001
0.002
0.003
0.004
0.005
0.009
Test loss
0.005
0.004
0.005
0.013
0.010
0.011
 Information Fusion 107 (2024) 102343
11
R. Abolghasemi et al.
Table 5
Calculating Silhouette score for evaluation of our proposed GcPp clustering method by applying various parameter
configurations, including different ground truth methods (Top-K and GED) and batch sizes (128, 256, and 512) and
different distance metrics.
Distance metrics in
Ground truth: Top-K
Ground truth: GED
Silhouette score
Train and validation batch
Train and validation batch
128
256
512
128
256
512
1
Euclidean distance
−0.332
−0.179
−0.240
−0.379
−0.411
−0.394
2
Cosine distance
−0.484
−0.504
−0.641
−0.616
−0.642
−0.553
3
Inverse of SimGNN
−0.002
−0.003
−0.003
−0.019
−0.022
−0.021
4
Inverse of GED
−0.026
−0.033
−0.032
−0.025
−0.023
−0.024
5
Inverse of Top-K
−0.006
−0.009
−0.008
−0.056
−0.048
−0.049
Fig. 5. Car dataset: Confusion matrices for different theta values, ranging from 0.1 to 0.9 (The letters N and P represent negative and positive, respectively).
4.3.1. Metrics
Our evaluation of the group recommendation model involves four
key metrics: precision, recall, F1-score, and fairness. Below, I provide
detailed explanations of how each of these metrics is calculated. We
calculate TP (true positive), FP (false positive), and FN (false negative)
based on the following equations (see section 5.2 in [12]):
𝑇𝑃𝐺= {𝑖∈𝑅𝐺|∀𝑢∈𝐺
such that
𝑟𝑢,𝑖≥𝜃}
(15)
𝐹𝑃𝐺= {𝑖∈𝑅𝐺|∃𝑢∈𝐺
such that
𝑟𝑢,𝑖< 𝜃}
(16)
𝐹𝑁𝐺= {𝑖∉𝑅𝐺|∀𝑢∈𝐺
such that
𝑟𝑢,𝑖≥𝜃}
(17)
Here, the set of items recommended to group 𝐺is denoted by 𝑅𝐺,
while the rating of user 𝑢for item 𝑖is 𝑟𝑢,𝑖. To measure whether a user
likes or dislikes an item, we used a threshold 𝜃. In the following, we
describe the process of determining an appropriate value for 𝜃.
4.3.2. Parameters setting
To determine the optimal threshold value for theta (𝜃), we con-
ducted multiple iterations of the experiment using various theta values
ranging from 0.1 to 0.9 for the car dataset and 0.0 to 0.8 for the food
dataset.
As the heatmaps in Figs. 5 and 6 affirm, lower theta values are
associated with higher values of TP and FN. Conversely, higher theta
values result in higher TN and FP. Hence, a well-determined threshold
is necessary to achieve high TP, TN, low FP, and FN, thereby ensuring
high precision and recall. Based on our experiment, we selected a theta
value of 0.4 for the car dataset and 0.1 for the food dataset. This implies
that items with scores above this theta value are considered liked by the
users, while those below, are deemed disliked.
4.3.3. Precision–recall curve
In order to demonstrate the effectiveness of utilizing GcPp clustering
in the group recommendation system (GRS), we conducted two exper-
iments: one with clustering and one without clustering. The precision–
recall curve, depicted in Fig. 7, illustrates the evaluation outcomes at
 Information Fusion 107 (2024) 102343
12
R. Abolghasemi et al.
Fig. 6. Food dataset: Confusion matrices for different theta values, ranging from 0.1 to 0.9 (The letters N and P represent negative and positive, respectively).
Fig. 7. Precision–recall curve for Group recommendation system with/without GcPp clustering on car dataset (left) and food dataset (right).
various thresholds (ranging from theta 0.1 to 0.9). This curve serves as
evidence of the impact and performance of our group recommendation
model with and without GcPp clustering. From these figures, it is
observed that the curve for our model (with clustering) consistently
lies above the curve for the model without clustering across all theta
values. This indicates that our proposed model consistently achieves
higher precision and recall compared to the other one. This means
our model performs better in accurately identifying positive instances
and minimizing false positives compared to the second model. This
suggests that using GcPp clustering results more effectively in the task
at hand, as it achieves a better balance between precision and recall.
This comparison between the precision–recall curves of the two models
highlights the superior performance of GRS with GCPp clustering.
4.3.4. Aggregation function setting
In the pursuit of identifying the most suitable aggregation function
for our group recommendation System, we employed two aggregation
methods: Approval Voting (AV) [68], which quantifies the number
of ratings exceeding a specified threshold, and Average (Avg). These
functions were applied to user groups derived from GcPp clustering and
randomly assembled groups. The outcomes for the car dataset and food
dataset on different thresholds (theta) are presented in Figs. 8 and 9,
respectively.
Within the car dataset, Average exhibited a superior F1-score when
contrasted with Approval Voting in both clustered and random user
groups. Upon scrutinizing the left-hand figures (representing clustered
groups) against the right-hand figures (depicting random groups), it
becomes evident that GRS on groups clustered by GcPp demonstrates
enhanced fairness and F1-score (a combination of precision and recall)
compared to groups composed of random users. This observation un-
derscores the advantageous impact of our proposed GcPp clustering
approach within the context of GRS.
The summary of the parameter configuration of the proposed
method based on the influence of various parameters on experimental
 Information Fusion 107 (2024) 102343
13
R. Abolghasemi et al.
Fig. 8. Comparison of two aggregation functions: Approval Voting (upper panel) and Average (lower panel) applied to groups clustered by GcPp (left) and random groups (right),
under varying theta values within the car dataset.
Fig. 9. Comparison of two aggregation functions: Approval Voting (upper panel) and Average (lower panel) applied to groups clustered by GcPp (left) and random groups (right),
under varying theta values within the food dataset.
outcomes, comes in the following. According to Section 4.2.2, Ta-
ble 4, and Figs. 3 and 4, the choice of ‘‘Top-K’’ as the ground truth
for similarity in SimGNN is highlighted. Additionally, the train and
validation batch sizes were set to 256 for the car dataset and 64 for
the food dataset, driven by observations of lower test and validation
losses. Furthermore, in accordance with Table 5 and the associated
explanations in Section 4.2.3, ‘‘inverse of SimGNN’’ was selected as the
distance metric for evaluating our clustering via the silhouette score.
Having identified the optimal parameters for the clustering method,
attention now shifts to leveraging these user clusters as groups for
our group recommendation system. Towards this objective, as outlined
in Section 4.3.4 and illustrated in Figs. 8 and 9, the aggregation
function ‘‘Average’’ was chosen. Furthermore, guided by insights from
Section 4.3.2 and depicted in Figs. 5 and 6, a theta value of 0.4 was
adopted for the car dataset, while 0.1 was selected for the food dataset.
4.3.5. Comparison with state-of-the-art
In order to assess the effectiveness of our model, we conducted
a comparative analysis with two widely recognized recommendation
system methods, namely BPR [21] and MFP [12], which operate on
pairwise-preference data. We evaluated various performance metrics,
including precision, recall, F1-score, fairness, and execution time, to
 Information Fusion 107 (2024) 102343
14
R. Abolghasemi et al.
Table 6
Comparison of evaluation results between our proposed GRS method with GcPp
clustering and three alternative recommendation methods on the car dataset.
Precision
Recall
F1-score
Fairness
Execution
time
BPR
0.87
0.05
0.10
0.90
0.0061
MFP
0.78
0.30
0.43
0.82
0.0088
GRS without clustering
0.77
0.36
0.50
0.79
0.0088
GRS with GcPp clustering
0.90
0.42
0.57
0.98
0.0077
Table 7
Comparison of evaluation results between our proposed method with GcPp clustering
and three alternative methods on the food dataset.
Precision
Recall
F1-score
Fairness
Execution
time
BPR
0.68
0.74
0.71
0.70
0.0087
MFP
0.71
0.73
0.72
0.78
0.0093
GRS without clustering
0.92
0.50
0.65
1.00
0.0016
GRS with GcPp clustering
0.94
0.85
0.89
1.00
0.0014
gauge the quality and efficiency of our model in relation to these
established methods. Moreover, we compared our method with the
proposed GRS without using GcPp clustering. The obtained results are
displayed in Tables 6 and 7.
The results obtained from our evaluation demonstrate the superior
performance of our proposed method over the other methods across
all evaluation metrics. These findings highlight the significance of
employing GcPp clustering in group recommendation systems. The
high precision, recall, F1-score, and fairness achieved by our proposed
method, which utilizes GcPp clustering, compared to BPR and MFP
in the group recommendation system can be attributed to several key
factors. Firstly, the incorporation of GcPp clustering in our proposed
method allows for a more accurate and effective grouping of indi-
viduals with similar preferences. By clustering individuals based on
their preferences, our method can capture the underlying patterns and
similarities within the group more effectively. This clustering process
enables us to create more homogeneous groups, where the members
share similar tastes and preferences. As a result, our proposed method
can generate recommendations that are more aligned with the indi-
vidual preferences of the group members, leading to higher precision
and recall compared to BPR and MFP. Furthermore, GcPp clustering
facilitates targeted and precise recommendation aggregation within
each cluster. By considering the preferences of the clustered group
members, our method can identify items that are highly preferred by
a significant portion of the group. This targeted aggregation enhances
the relevance and accuracy of the recommendations, resulting in higher
precision and recall scores. In terms of fairness, GcPp clustering helps
to address the fairness concerns in group recommendations. By forming
clusters based on similarity, our method ensures that individuals with
similar preferences are grouped together. This helps in avoiding situa-
tions where certain individuals dominate the recommendation process,
ensuring a fair distribution of recommendations among the group mem-
bers. The recommendations provided by our proposed method take into
account the preferences and interests of the entire group, promoting
fairness in the recommendation outcomes. Moreover, GcPp clustering
helps to mitigate the influence of personal biases or outliers within the
group. By grouping individuals with similar preferences, our method
can reduce the impact of extreme or outlier preferences, resulting in
a more balanced and fair recommendation process. This contributes to
higher fairness scores for our proposed method compared to BPR and
MFP.
To assess the efficacy of the proposed GcPp clustering approach
on Group Recommendation Systems (GRS), we employed Adversarial
Preference Learning with Pairwise Comparisons (CRGAN) [69] as a
recommendation technique suited for pairwise comparison data. For
group recommendation, user groups were formed using two methods:
firstly, by leveraging the GcPp clustering outcomes where each cluster
represented a user group; secondly, by generating random groups of
equivalent sizes to the clustered groups but composed of random users.
To ensure impartiality, the process of generating random groups was
repeated 20 times, and the final evaluation results represent the average
performance across these iterations.
The evaluation encompassed 10 metrics, including HitRatio (HR),
Normalized Discounted Cumulative Gain (NDCG), Area under the ROC
Curve (AUC), Mean Average Precision (MAP), Mean Reciprocal Rank
(MRR), Accuracy, Precision, Recall, F1-score, fairness, and also execu-
tion time. Evaluation results are presented in Table 8. Notably, CRGAN
exhibited superior performance across all metrics when employing
GcPp for group formation compared to random grouping, particularly
excelling in precision, recall, F1-score, and fairness, pivotal evaluation
criteria for group recommendation systems. This superiority stems from
the clustering algorithm’s ability to categorize users based on detailed
(pairwise comparison) and top-K preferred items, resulting in similar
preferences within clustered groups. Specifically, when group members
share similar preferences, precision increases as a larger proportion of
recommended items align closely with group preferences. Conversely,
diversity within random groups poses challenges in matching items to
varying preferences, resulting in lower precision. Additionally, in clus-
tered groups, recommendations cater to common interests, enhancing
recall by capturing relevant items more effectively. In contrast, random
groups with diverse preferences struggle to identify universally relevant
items, leading to lower recall. The F1-score reflects a balanced perfor-
mance between recommendation accuracy and completeness. Fairness
is also higher in clustered groups due to recommendations aligning with
homogeneous group preferences, enhancing the satisfaction of each
user and equitable representation compared to random groups with
diverse preferences.
5. Conclusion
This paper presents a group recommendation approach using the
introduced graph clustering method called GcPp, which relies on users’
pairwise preferences. Initially, a neural network-based similarity score
prediction process is employed, where the top-k preferred items act
as the ground truth, determining the similarity scores between nodes
(users) based on their favorite items and pairwise preference simi-
larities. The integration of GcPp clustering enhances precision, recall,
F1-score, and fairness in the group recommendation system. The clus-
tering process enables accurate grouping and targeted recommenda-
tion aggregation, promoting fairness by considering the entire group’s
preferences and mitigating the impact of personal biases or outliers.
Consequently, our proposed method outperforms BPR and MFP (widely
used recommendation system methods based on pairwise preferences)
in terms of precision, recall, F1-score, and fairness. In future work,
we plan to explore GcPp in other applications such as intelligent
transportation [70,71] or agent-based communication [72,73] to test
the usability of the method in real settings.
Ethical and informed consent for data used
No ethical issue for data used.
CRediT authorship contribution statement
Roza Abolghasemi: Writing – review & editing, Writing – origi-
nal draft, Visualization, Validation, Software, Conceptualization. En-
rique Herrera Viedma: Writing – review & editing, Methodology, Con-
ceptualization. Paal Engelstad: Writing – review & editing, Supervi-
sion, Conceptualization. Youcef Djenouri: Writing – review & editing,
Supervision, Methodology, Formal analysis, Conceptualization. Anis
Yazidi: Writing – review & editing, Supervision, Project administration,
Methodology, Formal analysis, Conceptualization.
 Information Fusion 107 (2024) 102343
15
R. Abolghasemi et al.
Table 8
Comparing assessment outcomes of the GRS through the utilization of CRGAN with GcPp clustering against random
clusters across car and food datasets.
Dataset
Food Dataset
Car Dataset
Method
CRGAN
CRGAN
CRGAN
CRGAN
(random groups)
(clustered groups)
(random groups)
(clustered groups)
HR@3
1.00
1.00
1.00
1.00
NDCG@3
0.77
0.85
0.89
1.00
AUC@3
0.70
0.75
0.87
1.00
MAP@3
0.85
0.90
0.91
1.00
MRR@3
0.47
0.51
0.42
0.44
Accuracy
0.71
0.83
0.85
0.97
Precision
0.78
0.89
0.88
1.00
Recall
0.77
0.92
0.84
0.94
F1-score
0.76
0.89
0.86
0.97
Fairness
0.63
0.68
0.68
0.70
Execution time
0.0114
0.0130
0.0116
0.0130
Declaration of competing interest
The authors declare that they have no known competing finan-
cial interests or personal relationships that could have appeared to
influence the work reported in this paper.
Data availability
Data will be made available on request.
References
[1] J. Lin, M. He, W. Pan, Z. Ming, Collaborative filtering with sequential implicit
feedback via learning users’ preferences over item-sets, Inform. Sci. 621 (2023)
136–155.
[2] L. Zeng, J. Guan, B. Chen, MSBPR: A multi-pairwise preference and similarity
based Bayesian personalized ranking method for recommendation, Knowl.-Based
Syst. 260 (2023) 110165.
[3] Y. Xu, E. Wang, Y. Yang, Y. Chang, A unified collaborative representation
learning for neural-network based recommender systems, IEEE Trans. Knowl.
Data Eng. 34 (11) (2021) 5126–5139.
[4] E. Amigó, Y. Deldjoo, S. Mizzaro, A. Bellogín, A unifying and general account
of fairness measurement in recommender systems, Inf. Process. Manage. 60 (1)
(2023) 103115.
[5] B. Walek, P. Fajmon, A hybrid recommender system for an online store using a
fuzzy expert system, Expert Syst. Appl. 212 (2023) 118565.
[6] X. Shen, H. Jiang, D. Liu, K. Yang, F. Deng, J.C. Lui, J. Liu, S. Dustdar, J. Luo,
PupilRec: Leveraging pupil morphology for recommending on smartphones, IEEE
Internet Things J. 9 (17) (2022) 15538–15553.
[7] X. Chen, Y. Zhang, I.W. Tsang, Y. Pan, J. Su, Toward equivalent transformation
of user preferences in cross domain recommendation, ACM Trans. Inf. Syst. 41
(1) (2023) 1–31.
[8] W. Liu, X. Zheng, J. Su, L. Zheng, C. Chen, M. Hu, Contrastive proxy kernel
stein path alignment for cross-domain cold-start recommendation, IEEE Trans.
Knowl. Data Eng. (2023).
[9] A. Jain, M. Murty, P. Flynn, Data clustering: a review, ACM computing survey,
Journal 31 (3) (1999).
[10] R. Abolghasemi, R. Khadka, P.G. Lind, P. Engelstad, E.H. Viedma, A. Yazidi,
Predicting missing pairwise preferences from similarity features in group decision
making, Knowl.-Based Syst. 256 (2022) 109860.
[11] A. Yazidi, M. Ivanovska, F.M. Zennaro, P.G. Lind, E.H. Viedma, A new decision
making model based on rank centrality for GDM with fuzzy preference relations,
European J. Oper. Res. 297 (3) (2022) 1030–1041.
[12] R. Abolghasemi, P. Engelstad, E. Herrera-Viedma, A. Yazidi, A personality-aware
group recommendation system based on pairwise preferences, Inform. Sci. 595
(2022) 1–17.
[13] A. Sanfeliu, K.-S. Fu, A distance measure between attributed relational graphs
for pattern recognition, IEEE Trans. Syst. Man Cybern. (1983) 353–362.
[14] A. Gazdar, L. Hidri, A new similarity measure for collaborative filtering based
recommender systems, Knowl.-Based Syst. 188 (2020) 105058.
[15] B.K. Patra, R. Launonen, V. Ollikainen, S. Nandi, A new similarity measure using
bhattacharyya coefficient for collaborative filtering in sparse data, Knowl.-Based
Syst. 82 (2015) 163–177.
[16] T. Mahara, et al., A new similarity measure based on mean measure of divergence
for collaborative filtering in sparse environment, Procedia Comput. Sci. 89 (2016)
450–456.
[17] N. Jones, A. Brun, A. Boyer, A. Hamad, An exploratory work in using com-
parisons instead of ratings, in: E-Commerce and Web Technologies - 12th
International Conference, in: Lecture Notes in Business Information Processing,
vol. 85, Springer, 2011, pp. 184–195, http://dx.doi.org/10.1007/978-3-642-
23014-1_16.
[18] L. Blédaité, F. Ricci, Pairwise preferences elicitation and exploitation for conver-
sational collaborative filtering, in: Proceedings of the 26th ACM Conference on
Hypertext & Social Media, 2015, pp. 231–236.
[19] S. Kalloori, T. Li, F. Ricci, Item recommendation by combining relative and
absolute feedback data, in: Proceedings of the 42nd International ACM SIGIR
Conference on Research and Development in Information Retrieval, 2019, pp.
933–936.
[20] S. Kalloori, F. Ricci, M. Tkalcic, Pairwise preferences based matrix factorization
and nearest neighbor recommendation techniques, in: Proceedings of the 10th
ACM Conference on Recommender Systems, 2016, pp. 143–146.
[21] S. Rendle, C. Freudenthaler, Z. Gantner, L. Schmidt-Thieme, BPR: Bayesian
personalized ranking from implicit feedback, 2012, arXiv preprint arXiv:1205.
2618.
[22] R. Yu, Y. Zhang, Y. Ye, L. Wu, C. Wang, Q. Liu, E. Chen, Multiple pairwise
ranking with implicit feedback, in: Proceedings of the 27th ACM International
Conference on Information and Knowledge Management, 2018, pp. 1727–1730.
[23] S. Sieranoja, P. Fränti, Adapting k-means for graph clustering, Knowl. Inf. Syst.
64 (1) (2022) 115–142.
[24] Y. Liu, W. Tu, S. Zhou, X. Liu, L. Song, X. Yang, E. Zhu, Deep graph clustering via
dual correlation reduction, in: Proceedings of the AAAI Conference on Artificial
Intelligence, Vol. 36, 2022, pp. 7603–7611.
[25] H. Liao, J. Hu, T. Li, S. Du, B. Peng, Deep linear graph attention model for
attributed graph clustering, Knowl.-Based Syst. 246 (2022) 108665.
[26] L. Guo, Q. Dai, Graph clustering via variational graph embedding, Pattern
Recognit. 122 (2022) 108334.
[27] L. Liu, Z. Kang, J. Ruan, X. He, Multilayer graph contrastive clustering network,
Inform. Sci. 613 (2022) 256–267.
[28] D. Hu, D. Feng, Y. Xie, EGC: A novel event-oriented graph clustering framework
for social media text, Inf. Process. Manage. 59 (6) (2022) 103059.
[29] J.A. Morente-Molinera, S.R. Aguilar, R. González-Crespo, E. Herrera-Viedma,
Using clustering methods to deal with high number of alternatives on group
decision making, Procedia Comput. Sci. 162 (2019) 316–323.
[30] R.-X. Ding, I. Palomares, X. Wang, G.-R. Yang, B. Liu, Y. Dong, E. Herrera-
Viedma, F. Herrera, Large-scale decision-making: Characterization, taxonomy,
challenges and future directions from an artificial intelligence and applications
perspective, Inf. Fusion 59 (2020) 84–102.
[31] M. Tang, H. Liao, E. Herrera-Viedma, C.P. Chen, W. Pedrycz, A dynamic adap-
tive subgroup-to-subgroup compatibility-based conflict detection and resolution
model for multicriteria large-scale group decision making, IEEE Trans. Cybern.
51 (10) (2020) 4784–4795.
[32] Y. Shang, Finite-time cluster average consensus for networks via distributed
iterations, Int. J. Control Autom. Syst. 15 (2017) 933–938.
[33] P. Liu, K. Zhang, P. Wang, F. Wang, A clustering- and maximum consensus-
based model for social network large-scale group decision making with linguistic
distribution, Inform. Sci. 602 (2022) 269–297.
[34] S. Yao, M. Gu, An influence network-based consensus model for large-scale group
decision making with linguistic information, Int. J. Comput. Intell. Syst. 15 (1)
(2022) http://dx.doi.org/10.1007/s44196-021-00058-1.
[35] F. Jin, J. Liu, L. Zhou, L. Martínez, Consensus-based linguistic distribution
large-scale group decision making using statistical inference and regret theory,
Group Decis. Negot. 30 (4) (2021) 1–33, http://dx.doi.org/10.1007/S10726-021-
09736-Z.
[36] J. Saarinen, A large-scale group decision-making model with no consensus
threshold based on social network analysis, Inform. Sci. 612 (2022) 361–383,
http://dx.doi.org/10.1016/j.ins.2022.08.075.
 Information Fusion 107 (2024) 102343
16
R. Abolghasemi et al.
[37] H. Liao, X. Li, M. Tang, How to process local and global consensus? A large-scale
group decision making model based on social network analysis with probabilistic
linguistic information, Inform. Sci. 579 (2021) 368–387, http://dx.doi.org/10.
1016/J.INS.2021.08.014.
[38] X. Zhong, X. Xu, X. Chen, A clustering and fusion method for large group decision
making with double information and heterogeneous experts, Soft Comput. (2022)
1–13.
[39] J. Chen, H. Li, X. Zhang, F. Zhang, S. Wang, K. Wei, J. Ji, SR-HetGNN: session-
based recommendation with heterogeneous graph neural network, Knowl. Inf.
Syst. (2023) 1–24.
[40] X. Liu, X. Li, Y. Cao, F. Zhang, X. Jin, J. Chen, Mandari: Multi-modal temporal
knowledge graph-aware sub-graph embedding for next-POI recommendation, in:
2023 IEEE International Conference on Multimedia and Expo, ICME, IEEE, 2023,
pp. 1529–1534.
[41] J. Chen, Y. Cao, F. Zhang, P. Sun, K. Wei, Sequential intention-aware rec-
ommender based on user interaction graph, in: Proceedings of the 2022
International Conference on Multimedia Retrieval, 2022, pp. 118–126.
[42] C.-W. Hsu, C.-T. Chen, S.-H. Huang, Adaptive adversarial contrastive learning for
cross-domain recommendation, ACM Trans. Knowl. Discov. Data 18 (3) (2023)
1–34.
[43] Z.
Fu,
X.
Niu,
M.L.
Maher,
Deep
learning
models
for
serendipity
rec-
ommendations:
A
survey
and
new
perspectives,
ACM
Comput.
Surv.
(2023).
[44] D. Han, Y. Huang, J. Liu, K. Liao, K. Lin, LSAB: User behavioral pattern modeling
in sequential recommendation by learning self-attention bias, ACM Trans. Knowl.
Discov. Data 18 (3) (2024) 1–20.
[45] V.R. Yannam, J. Kumar, K.S. Babu, B. Sahoo, Improving group recommendation
using deep collaborative filtering approach, Int. J. Inf. Technol. 15 (3) (2023)
1489–1497.
[46] T. Lalitha, P. Sreeja, Recommendation system based on machine learning and
deep learning in varied perspectives: a systematic review, in: Information and
Communication Technology for Competitive Strategies (ICTCS 2020) Intelligent
Strategies for ICT, Springer, 2021, pp. 419–432.
[47] R.
Shrivastava,
D.S.
Sisodia,
N.K.
Nagwani,
Deep
neural
network-based
multi-stakeholder recommendation system exploiting multi-criteria ratings for
preference learning, Expert Syst. Appl. 213 (2023) 119071.
[48] W.-H. Liao, Y.-T. Lin, C.-Y. Lin, S.-C. Kuai, A group recommendation system
for movies using deep learning, in: 2023 International Conference on Consumer
Electronics-Taiwan, ICCE-Taiwan, IEEE, 2023, pp. 61–62.
[49] Y. Wu, Q. Liu, R. Chen, C. Li, Z. Peng, A group recommendation system
of network document resource based on knowledge graph and LSTM in edge
computing, Secur. Commun. Netw. 2020 (2020) 1–11.
[50] B. Ait Hammou, A. Ait Lahcen, S. Mouline, A distributed group recommendation
system based on extreme gradient boosting and big data technologies, Appl.
Intell. 49 (2019) 4128–4149.
[51] S. Ali-Yari, N. Neissani Samani, M.R. Jelokhani Nayarki, Uncertainty modeling
of a group tourism recommendation system based on pearson similarity criteria,
Bayesian network and self-organizing map clustering algorithm, Eng. J. Geosp.
Inf. Technol. 8 (1) (2020) 39–61.
[52] Y.-D. Seo, Y.-G. Kim, E. Lee, H. Kim, Group recommender system based on genre
preference focusing on reducing the clustering cost, Expert Syst. Appl. 183 (2021)
115396.
[53] Y. Bai, H. Ding, S. Bian, T. Chen, Y. Sun, W. Wang, Simgnn: A neural network
approach to fast graph similarity computation, in: Proceedings of the Twelfth
ACM International Conference on Web Search and Data Mining, 2019, pp.
384–392.
[54] M. Pavan, M. Pelillo, Dominant sets and pairwise clustering, IEEE Trans. Pattern
Anal. Mach. Intell. 29 (1) (2006) 167–172.
[55] H. Hung, B. Kröse, Detecting f-formations as dominant sets, in: Proceedings of
the 13th International Conference on Multimodal Interfaces, 2011, pp. 231–238.
[56] A. Yazidi, M.A. Pinto-Orellana, H. Hammer, P. Mirtaheri, E. Herrera-Viedma,
Solving sensor identification problem without knowledge of the ground truth
using replicator dynamics, IEEE Trans. Cybern. 52 (1) (2020) 16–24.
[57] P.D. Taylor, L.B. Jonker, Evolutionary stable strategies and game dynamics,
Math. Biosci. 40 (1–2) (1978) 145–156.
[58] E.Z. Mequanint, L.T. Alemu, M. Pelillo, Dominant sets for constrained image
segmentation, IEEE Trans. Pattern Anal. Mach. Intell. (2018).
[59] Y.T. Tesfaye, E. Zemene, A. Prati, M. Pelillo, M. Shah, Multi-target tracking in
multiple non-overlapping cameras using fast-constrained dominant sets, Int. J.
Comput. Vis. (2019) 1–18.
[60] M. Pelillo, A. Torsello, Payoff-monotonic game dynamics and the maximum
clique problem, Neural Comput. 18 (5) (2006) 1215–1258.
[61] K. Avrachenkov, V.S. Borkar, Metastability in stochastic replicator dynamics,
Dynam. Games Appl. (2018) 1–25.
[62] W. Barfuss, J.F. Donges, J. Kurths, Deterministic limit of temporal difference
reinforcement learning for stochastic games, Phys. Rev. E 99 (4) (2019) 043305.
[63] Q. Wang, N. He, X. Chen, Replicator dynamics for public goods game with
resource allocation in large populations, Appl. Math. Comput. 328 (2018)
162–170.
[64] A. Felfernig, L. Boratto, M. Stettinger, M. Tkalčič, et al., Group Recommender
Systems: An Introduction, Springer, 2018.
[65] E. Abbasnejad, S. Sanner, E.V. Bonilla, P. Poupart, Learning community-based
preferences via dirichlet process mixtures of gaussian processes, in: Twenty-Third
International Joint Conference on Artificial Intelligence, 2013, pp. 1213–1219.
[66] C.-N. Ziegler, S.M. McNee, J.A. Konstan, G. Lausen, Improving recommendation
lists through topic diversification, in: Proceedings of the 14th International
Conference on World Wide Web, 2005, pp. 22–32.
[67] A.K. Jain, R.C. Dubes, Algorithms for Clustering Data, Prentice-Hall, Inc., 1988.
[68] L. Boratto, S. Carta, G. Fenu, Discovery and representation of the preferences of
automatically detected groups: Exploiting the link between group modeling and
clustering, Future Gener. Comput. Syst. 64 (2016) 165–174.
[69] Z. Wang, Q. Xu, K. Ma, Y. Jiang, X. Cao, Q. Huang, Adversarial preference learn-
ing with pairwise comparisons, in: Proceedings of the 27th ACM International
Conference on Multimedia, 2019, pp. 656–664.
[70] B. Cao, J. Zhao, Z. Lv, P. Yang, Diversified personalized recommendation
optimization based on mobile data, IEEE Trans. Intell. Transp. Syst. 22 (4) (2020)
2133–2139.
[71] J. Xu, K. Guo, X. Zhang, P.Z. Sun, Left gaze bias between LHT and RHT: a
recommendation strategy to mitigate human errors in left-and right-hand driving,
IEEE Trans. Intell. Veh. (2023).
[72] Y. Peng, Y. Zhao, J. Hu, On the role of community structure in evolution of
opinion formation: A new bounded confidence opinion dynamics, Inform. Sci.
621 (2023) 672–690.
[73] J. Dong, J. Hu, Y. Zhao, Y. Peng, Opinion formation analysis for expressed and
private opinions (EPOs) models: Reasoning private opinions from behaviors in
group decision-making systems, Expert Syst. Appl. 236 (2024) 121292.
",https://doi.org/10.1016/j.inffus.2024.102343,doc32,"Information Fusion 107 (2024) 102343 Available online 2 March 2024 1566-2535/ Contents lists available at ScienceDirect Information Fusion journal homepage: www.elsevier.com/locate/inffus A graph neural approach for group recommendation system based on pairwise preferences Roza Abolghasemi a,∗, Enrique Herrera Viedma b, Paal Engelstad a, Youcef Djenouri c,d,e, Anis Yazidi a a Department of Computer Science, Oslo Metropolitan University (OsloMet), Oslo, Norway b Andalusian Research Institute in Data Science and Computational Intelligence, University of Granada, Granada, Spain c University of South-Eastern Norway, Kongsbeg, Norway d Norwegian Research Center, Oslo, Norway e IDEAS NCBR, Warsaw, Poland A R T I C L E I N F O Keywords: Graph clustering Pairwise preferences Recommendation systems Group decision making Group recommendation systems A B S T R A C T Pairwise preference information, which involves users expressing their preferences by comparing items, plays a crucial role in decision-making and has recently found application in recommendation systems. In this study, we introduce GcPp, a clustering algorithm that leverages pairwise preference data to generate recommendations for user groups. Initially, we construct individual graphs for each user based on their pairwise preferences and utilize a graph convolutional network to predict similarities between all pairs of graphs. These predicted similarity scores form the foundation of our research. We then construct a new graph where users are nodes and the edges are weighted according to the predicted similarities. Finally, we perform clustering on the graph’s nodes (users). By evaluating various metrics, we found that employing a similarity metric based on a convolutional neural network (SimGNN) with our proposed ground truth called Top-K yielded the highest accuracy. The proposed approach is specifically designed for group recommendation systems and holds significant potential for group decision-making problems. Code is available at https: //github.com/RozaAbolghasemi/Group_Recommendation_Syatem_GcPp_clustering. 1. Introduction With the dramatic expansion of the web of things, recommendation systems are nowadays prevalent in our daily lives [1–3]. Recommenda- tion systems explore the historical data represented by user information and preferences to decide which items might be recommended for new observations. Numerous recommendation algorithms have been suggested in the last decade, however, a few of them have been successfully utilized in real settings [4–6]. However, we are far from handling the pairwise preferences problem, which is considered a key ingredient in modern recommendation systems [7,8]. In order to efficiently explore pairwise preferences, more intelligent methods need to be incorporated into the recommendation process. Clustering has paramount importance in the exploration and analysis of data, and it has extensive applications in data mining, information retrieval, deci- sion making, computer graphics, bioinformatics, and Very-large-scale integration (VLSI) design. For an overview of clustering techniques and applications, we refer the reader to [9]. Usually, clustering consists of discovering natural groups of similar elements in datasets. However, ∗Corresponding author. E-mail address: rozaabol@oslomet.no (R. Abolghasemi). since the similarity can be represented using graphs, graph clustering has gotten very attention as an important variant of data clustering. Moreover, to have a more accurate clustering method, using an ac- curate similarity measure is very crucial. In the learning process, a good graph similarity function/model would be able to capture all the hidden information of the data and predict the relationships between the data points to be able to predict more accurate similarity scores. Additionally, in some areas like group decision making (GDM) [10, 11] and more specifically group recommendation systems (GRS) [12], where the pairwise preferences of the users are available, a possible solution to find common decision/recommendation for the group, is to first find similar users. The intuition behind this is that similar users will likely have similar preferences, and their decisions are likely to be more similar compared to dissimilar users. This paper addresses the problem of group recommendation based on graph clustering. In the proposed graph clustering, for each node, some information like its pairwise preferences is available. Among the conventional graph similarity methods, those based on neural Received 15 November 2023; Received in revised form 29 February 2024; Accepted 1 March 2024 Information Fusion 107 (2024) 102343 2 R. Abolghasemi et al. networks were shown to be more accurate on different types of graphs. Traditional similarity measures like Euclidean and cosine, are based on the input vectors, and graph similarity measures like graph edit distance (GED) [13] are based on the structure of the graph. Unlike these traditional methods, the neural networks learn the similarity not only based on the structure of the graph but also the attributes of the nodes. This is very crucial and shows the power of this type of similarity method on different types of data/graphs. It is noteworthy that our work presents a novel approach to eval- uating user similarity in recommender systems by shifting away from traditional feature vector reliance to item-based pairwise preferences, employing the GcPp algorithm and SimGNN model. This shift is moti- vated by the limitations of conventional similarity measures based on feature vectors, as highlighted in previous research [14–16]. Specifi- cally, measures such as PCC, SPCC, CPCC, ACOS, MSD, Jaccard, PIP, and NHSM are found to exhibit drawbacks in terms of accuracy and complexity when calculating user similarity. Additionally, the advan- tages of employing pairwise preferences over pure rating values are discussed in [17,18], emphasizing the potential for more precise and ac- curate recommendations. In [12,19,20], the incorporation of pairwise preferences in group recommendation systems is examined, introducing Matrix factorization pair-score prediction (MFP) and comparing it with well-known approaches like BPR [21], and MPR [22]. The analysis underscores the superiority of utilizing pairwise comparisons in GRS, particularly when compared to single-rating data. The main contributions of this work are listed in the following: 1. We transform users’ pairwise preferences into graphs and devise a graph convolutional neural network (SimGNN) to assess the similarity between each pair of user graphs. To accomplish this, we introduce a novel metric named Top-K to associate users with the top-k most similar items. 2. We develop the GcPp technique, an abbreviation for ‘‘Graph Clustering based on Pairwise Preference data’’. This method leverages the dominant set clustering algorithm to consolidate users with the highest degrees of similarity into cohesive groups. Specifically, we enhance the dominant set clustering algorithm by incorporating SimGNN to gauge user similarity. 3. We evaluate the developed model using two pairwise prefer- ences datasets, and compare SimGNN with well-known simi- larity metrics. The results reveal the superiority of SimGNN compared to the baseline metrics. In our final step, we capitalized on the clusters of users, which rep- resent groups of individuals with similar preferences. Leveraging these clusters enabled us to generate recommendations that are not only more accurate but also fairer. By considering the preferences and characteris- tics of users within each cluster, we could tailor recommendations more precisely to the specific needs and interests of the users within those groups. This approach enhances the overall recommendation system by ensuring that recommendations are relevant and equitable for all users. 2. Related work This study is divided into two primary areas of focus: graph cluster- ing and recommendation and group recommendation. In the upcoming sections, we will delve into the existing body of research pertaining to both of these subjects. 2.1. Graph clustering and recommendation Sieranoja et al. [23] suggested two novel clustering networks and graphs techniques. The first one is a direct descendant of the k-means algorithm and is known as the K-algorithm. Similar iterative local optimization is used, but the means are not necessary. In terms of both good local optimization capabilities and a propensity to reach a local optimum, it shares features with k-means clustering. The second one called M-algorithm, iteratively enhances the K-output algorithm’s to uncover new and superior local optima. It repeatedly separates and merges arbitrary clusters, then uses the K-algorithm to fine-tune the outcomes. Both algorithms can be applied to various cost functions, which makes them both generic. By lowering information correlation in two ways, Liu et al. [24] presented the Dual Correlation Reduction Network (DCRN), a revolutionary self-supervised deep graph clustering technique. They specifically created a siamense network first to encrypt samples. Then, they reduced the information correlation at the dual- level, enhancing the discriminative power of the resulting features by pushing the cross-view sample correlation matrix and cross-view fea- ture correlation matrix to resemble two identity matrices, respectively. Additionally, they applied a propagation regularization term to the network’s shallow network structure to help the network gain long- distance information while alleviating representation collapse brought on by over-smoothing in GCN. Liao et al. [25] put forth a new deep linear graph attention model for attributed graph clustering (DLGAMC), which is made up of a similarity-preserving module and an attention- based aggregation module. To design the attention for aggregation, which does not require learning additional attention parameters, the authors only took advantage of cosine similarity. They also suggested an adaptive technique to assess the smoothness of node representations, with intra-cluster distance and inter-cluster distance serving as the essential indicators in this process. To address the challenging issue in a non-Euclidean space, Guo et al. [26] proposed an original end-to-end graph clustering archi- tecture with a combined strategy. They provide a new variational graph auto-encoder algorithm based on the GCN for learning the graph embedding that takes into consideration the boosting effect of a joint generative model of the graph structure and node characteristics on the embedding output. They developed an auxiliary distribution based on the embedding representation to provide a self-training mechanism that improved the prediction of node categories and enabled the unsu- pervised clustering mode. In order to avoid huge clusters warping the embedding space, each cluster’s loss contribution is also normalized. Liu et al. [27] introduced a multilayer graph contrastive clustering network, which is a general and efficient autoencoder framework for multilayer graph clustering (MGCCN). Three modules make up the MGCCN: (1) attentiveness for better node embeddings, a mechanism that is used to better capture the importance of nodes and their neigh- bors. (2) A contrastive fusion approach that effectively investigated the consistent data in various networks. (3) A self-supervised element that reinforces the node embedding and clustering iteratively. A novel unsupervised event-oriented graph clustering framework (EGC) was proposed [28], which does not require labeled data and can perform efficient clustering on huge datasets with little time overhead. To be more precise, EGC changes the textual data of social networks after first mining the potential relations included in social text data. By utilizing graph structure for the depiction of complicated relations, media can be converted into an event-oriented graph. Secondly, EGC reliably measures the weights of relations in event-oriented graphs using a keyword-based local importance method. One of the applications of clustering is group decision making which can be done easier using a good clustering method. In [29,30] the idea of dealing with large-scale decision-making problems is dis- cussed. In [31], large-group decision-making and conflict management are addressed. The authors propose a dynamic adaptive subgroup-to- subgroup conflict model that focuses on multicriteria decision-making. They introduce a compatibility index to quantify cognitive and interest conflicts among experts and utilize the fuzzy c-means clustering algo- rithm to classify experts into subgroups. The paper [32] investigates the achievement of cluster average consensus within a finite time frame in bidirectional networks. Through the design of distributed linear iterations using stochastic matrices that align with the network topol- ogy, the authors demonstrate the possibility of always attaining cluster average consensus in bidirectional networks that have cluster-spanning Information Fusion 107 (2024) 102343 3 R. Abolghasemi et al. trees. A clustering- and maximum consensus-based model with lin- guistic distribution is proposed for social network large-scale group decision making (SNLGDM) problems [33]. The model utilizes social network analysis (SNA) to determine the weights of decision groups and reduce the dimension of large-scale decision matrices. It involves the division of large-scale decision makers (DMs) into independent sub-groups based on trust relationships [34]. Linguistic distribution (LD) assessments are used to represent the preference relation of sub- groups [35]. A maximum consensus-based method is then employed to generate comprehensive weights for the sub-groups by maximizing the level of consensus between sub-groups and the collective matrix [36]. The final ranking of alternatives is obtained based on the collective preference relation [37]. The proposed model is verified through nu- merical examples, coefficient analysis, and comparative analysis. The paper in [38] proposes an expert clustering and information fusion method for large group decision-making (LGDM) problems with double information and heterogeneous experts. It introduces an optimization model to derive criteria weights of experts based on the minimiza- tion of deviation between double information. It presents a double clustering method that combines the similarity degrees of experts’ fuzzy preference relations and their criteria weights to classify large- scale experts into clusters. A clustering validity index is introduced to objectively determine the clustering threshold, ensuring the rationality of the clustering results. In addition to clustering, graphs have been utilized in various ways to generate effective recommendations. In the work by Chen et al. [39] a method named SR-HetGNN is introduced that is a novel session recommendation method. SR-HetGNN leverages a heterogeneous graph neural network (HetGNN) to enhance session-based recommendation systems. Also, [40] introduces Mandari, a novel approach that lever- ages a Multi-Modal Temporal Knowledge Graph for Next-POI recom- mendation. It addresses the challenges of modeling implicit associations in multi-modal data and capturing variations in user preferences over time intervals. A method named Satori [41] has been introduced that leverages a user interaction graph to capture relationships between users, items, and categories and utilizes a graph attention network to extract auxiliary features. Additionally, it adopts a self-attention mech- anism to model user intention and preference, combining them to form a hybrid user representation. The framework in [42] employs multitask training to optimize the model with auxiliary tasks. It aims to enhance cross-domain recommendation performance through adaptive learning and graph-based techniques. To see how deep learning models offer effective recommendations we refer the reader to [43,44]. The survey extensively examines recent studies on serendipitous recommendations, particularly concentrating on deep learning recommendation models. It categorizes these models based on their integration of serendipity objectives at different stages of the recommendation process. 2.2. Group recommendation Utilizing pairwise preference data within Group Recommender Sys- tems (GRS) significantly enhances the precision of item recommenda- tions, as it provides detailed insights into users’ preferences (see [10, 12]). A method known as MFP, introduced by [12], predicts personal- ized item scores based on such pairwise preference data. In developing the GRS, the study incorporates users’ personality traits, specifically assertiveness, and cooperativeness, which closely resemble real-world decision-making scenarios. Furthermore, the application of an opinion dynamics model aids in achieving consensus within the system. In [10], a novel approach grounded in entropy is presented for the prediction of missing data within pairwise preference datasets. This method excels by capitalizing on user and item similarity for prediction, even when confronted with exceptionally sparse datasets, surpassing traditional methods that may yield no results in such scenarios. The principal domain of application for this innovative concept lies within Group Recommender Systems and Group DecisionMaking challenges. Deep learning plays a pivotal role in both Recommendation sys- tems and Group Recommender Systems (GRS) methods, as evident in recent works [45–47]. In the context of GRS, an innovative approach employing a Graph Attention Network (GAT) is presented in [48]. This method initially clusters users based on movie genre preferences and user similarities. Subsequently, it employs GAT to predict users’ movie ratings by considering their preferences and group relationships. Addi- tionally, Wu et al. [49] propose a GRS tailored for network document resource exploration, leveraging knowledge graphs and LSTM within edge computing. This approach effectively addresses issues related to information overload and resource tracking. Ait et al. [50] introduced a distributed group recommendation system built on Apache Spark. This system employs a novel recommendation method, dimension reduction techniques, and supervised and unsupervised learning to address the curse of the dimensionality problem, identify user groups, and enhance prediction quality. Ali-Yari et al. [51] dealt with the concern related to the uncertainty and ambiguity surrounding a tourist’s group member- ship in group tourism. They developed a group recommendation system that incorporates uncertainty modeling using Bayesian networks, Pear- son similarity factors, and SOM clustering. It models uncertainties and estimates tourism preferences for each group, reducing the impact of in- sufficient user information. The system also suggests tourist attractions and optimal routes via Google Maps for each user group, enhancing the recommendation experience. In order to reduce the clustering cost in group recommendation, Seo et al. [52] introduced a GRS based on the genre preferences of users. They established a genre preference vector and employed it for group clustering, resulting in more efficient time complexity due to the smaller number of genres compared to items. Furthermore, they introduced a novel item preference mechanism, incorporating genre weights to further refine user preferences. 2.3. Discussions In this section, we provide a summary of the limitations and strengths of the related works, which can be found in the Tables 1 and 2. 3. Method design 3.1. Principle Within this section, we elucidate the proposed approach, which encompasses two main steps including GcPp clustering and group recommendation subsequent to data preprocessing. Fig. 1 indicates the logical diagram of the proposed method. During the data preprocessing phase, the data is transformed into a standardized format as follows: if expert 𝑢expresses a preference for item 𝑖over item 𝑗, the corresponding pairwise preference 𝑝(𝑢) 𝑖𝑗 is assigned a value of 1. Conversely, if the two items are considered equally preferred, the preference value 𝑝(𝑢) 𝑖𝑗 is set to 0.5. In cases where expert 𝑢does not prefer item 𝑖over item 𝑗, the pairwise preference value 𝑝(𝑢) 𝑖𝑗 is 0. In the subsequent sections, we provide comprehensive explanations of both the GcPp clustering approach and the proposed group recommendation system, delving into their intricacies and details. 3.2. Clustering In this section, we present a detailed description of the GcPp (graph clustering pairwise preference) method. An overview of the proposed approach is depicted in Fig. 2, and the pseudo-code implementation can be found in Section 3.2.5. The method encompasses four main phases as follows: • The dataset, comprising pairwise preferences of users, is trans- formed into graphs, as described in Section 3.2.1 and illustrated in Fig. 2 (part a). Information Fusion 107 (2024) 102343 4 R. Abolghasemi et al. Table 1 Merits and limits of the related works in graph clustering. Paper Merit Limit Sami et al. [23] Introducing two cost functions and two clustering methods that can be applied with various cost functions. Notably, the M-algorithm outperforms eight other state-of-the-art methods. The M-algorithm incurs a high computational cost because it involves the repetitive merging and splitting of random clusters. Liu et al. [24] The suggested DCRN aims to diminish information correlation at sample and feature levels, a crucial aspect in preventing representation collapse, ultimately leading to improved clustering outcomes. The method’s computational complexity and scalability for larger graphs require further exploration for practical use cases. Liao et al. [25] Decreasing the attention parameters within GCN, which involves incorporating a nonlinear attention mechanism that includes both attribute information similarity and the local graph structure. The node pair selection process for the introduced similarity-preserved module requires improvement. Guo et al. [26] The paper’s innovative end-to-end graph clustering approach effectively integrates embedding and clustering, enhancing the accuracy of unsupervised clustering tasks. The paper does not account for unknown prior knowledge of clusters, leaving potential room for improvement in handling real-world applications where such information may be valuable. Liu et al. [27] The paper introduces MGCCN, an innovative autoencoder framework for multilayer graph clustering, surpassing existing methods in handling complex network frameworks, often limited to multiview attributes or multiple networks. The MGCCN framework, while effective, may face scalability challenges with extremely large or high-dimensional datasets, requiring careful consideration for practical use. Hu et al. [28] EGC effectively converts social text data into an event-oriented graph, delivering high-quality clustering performance, rapid query times, and eliminating the need for labeled data, facilitating timely public opinion analysis on social media. The paper may face challenges in optimizing the event-oriented graph generation for a more lightweight representation of social text data and improving the execution time of the graph clustering algorithm. Morente et al. [29] The paper introduces an innovative GDM method that effectively reduces information overload by clustering a large set of alternatives into manageable groups for expert discussions and decision-making. This method’s effectiveness may depend on the quality of clustering, and it may not fully address the challenges of handling extremely complex decision environments with diverse alternatives. Ding et al. [30] The paper defines and categorizes Large Scale Decision Making (LSDM) frameworks, offering insights into managing complex decision processes involving diverse stakeholders. It primarily focuses on theoretical models and future research directions, potentially requiring practical implementation and validation of LSDM solutions for real-world applicability. Tang et al. [31] The paper introduces a dynamic conflict resolution model for large-scale group decision-making, enhancing our understanding of conflict management in complex decision contexts. Further research is needed to assess the model’s applicability in diverse settings like social networks and its adaptability to alternative opinion representation methods. Shang et al. [32] The paper provides insights into achieving finite-time cluster average consensus on bidirectional networks with cluster-spanning trees, offering valuable guidance for noise-free scenarios. The study does not address directed networks or communication noises, common in practical applications, and further research is needed to adapt the results to these scenarios and explore delay robustness. Table 2 Merits and limits of the related works in group recommendation systems. Paper Merit Limit Roza et al. [12] Attaining highly precise and equitable GRS by leveraging detailed information from pairwise preference data, incorporating user personalities, and employing opinion dynamics to reach consensus. For users, the process of completing the TKI test to unveil their personality traits can be time-consuming, and turning to user their social media content may present a feasible alternative. Roza et al. [10] An entropy-based method excels at estimating missing values in pairwise preference data for GRS and GDM, using user and item similarity, making it stand out from conventional methods that struggle with sparse datasets. Like other methods, the overall model fitting, when minimizing the cross-entropy loss function, tends to produce larger errors as the problem’s dimension, specifically the number of alternatives, increases. Liao et al. [48] Utilizing GAT (Graph Attention Network), clustering based on movie genre preferences and user similarities leads to significantly improved recommendation accuracy in GRS. High time complexity due to the nature of the deep learning techniques. Wu et al. [49] By employing a knowledge graph and LSTM within edge computing for GRS, it effectively addresses the challenges of information overload and resource tracking. High time complexity due to the nature of the deep learning techniques. Badr et al. [50] A distributed GRS, built on Apache Spark, capable of managing large-scale data and addressing sparsity issues. The absence of social relationship interactions to boost the performance of the architectures. Ali et al. [51] Modeling uncertainties reduces the impact of limited user information and enhances the recommendation experience by suggesting tourist attractions and optimal routes through Google Maps. The proposed SOM-based method is not compared with other clustering methods. Seo et al. [52] Reduced clustering cost and enhanced time efficiency are achieved by clustering based on user genre preferences rather than item ratings. It appears that all movies (items) sharing the same genre are assigned an equal weight (score), which could pose challenges when recommending a subset of items from a pool with the same genre. Information Fusion 107 (2024) 102343 5 R. Abolghasemi et al. Fig. 1. Logical diagram of the process of the proposed method. • The similarity between users (graphs of items) is predicted using the graph convolutional network called SimGNN [53], as depicted in Fig. 2 (part b) and described in Section 3.2.1. • A graph is constructed with users represented as nodes, and the predicted similarity score between each pair of users is assigned as the weight of the corresponding edge, as shown in Fig. 2 (part c). • The ‘‘Dominant-set’’ algorithm [54] is employed as a graph clus- tering method to group the users based on their relationships. This algorithm partitions the user graph into distinct clusters by identifying dominant sets of nodes. The process of clustering is depicted in Fig. 2 (part d), and you can find detailed explanations in Section 3.2.3. In the final phase, we conducted an evaluation of our clustering ap- proach using various metrics. In the subsequent sections, we will elaborate on the details of predicting similarity between pairs of graphs and the process of clustering a graph. This will provide a comprehen- sive understanding of how the similarity prediction and clustering steps were executed, allowing for a more in-depth analysis of our approach. 3.2.1. Similarity of graphs In this section, we will outline our approach for predicting the similarity scores among users. Based on our datasets, which are de- scribed in Section 4.1, pairwise preferences on items are available for each user. This means that users have compared every pair of items and indicated their preferences. Specifically, we assign 𝑝(𝑢) 𝑖𝑗 = 1 if user 𝑢prefers item 𝑖over item 𝑗, and 𝑝(𝑢) 𝑖𝑗 = 0 otherwise. To capture these preferences, we convert the pairwise preferences into graphs for each user (refer to Fig. 2, part a). In these graphs, the items are represented as nodes, and a directed edge exists between two nodes if and only if 𝑝(𝑢) 𝑖𝑗 = 1. Each graph represents the preferences of a specific user. We utilize these graphs to predict the similarity among users. Consequently, predicting the similarity between pairs of users is transformed into predicting the similarity scores between pairs of graphs. In this study, we adopt the concept of ‘‘a neural network approach to fast graph similarity computation (SimGNN)’’ introduced in [53]. An overview of this approach is depicted in Fig. 2 (part b). The SimGNN model employs a learnable embedding function based on graph convolutional networks (GCN) to generate an embedding vector for each graph, which serves as a condensed representation of the graph. Furthermore, the model incorporates a novel attention mecha- nism to highlight the significant nodes based on a specific similarity metric. This attention mechanism aims to emphasize the nodes that contribute most to the overall similarity computation. Additionally, a pairwise node comparison method is devised to enhance the graph-level embeddings by incorporating detailed node-level information. Finally, fully-connected neural networks are employed to predict the similarity scores. These networks leverage the graph-level embeddings and the fine-grained node-level information to estimate the similarity between pairs of graphs. 3.2.2. Top-K similarity As SimGNN is a learning algorithm, it requires similarity scores for each pair of graphs as ground truth. To address this, we used the Top-k method which is introduced in this section. As previously mentioned, in our algorithm, each user corresponds to a graph. Thus, the similarity among users can be leveraged as the similarity between their corresponding graphs. To achieve this, we utilize the pairwise preferences of the users as follows: for each user, we arrange the items in descending order of preference based on personalized item scores calculated using the following equation: 𝑣(𝑢) 𝑖 = ∑ 𝑗∈𝐼⧵{𝑖} 𝑝(𝑢) 𝑖𝑗 |𝐼| . (1) Here, 𝑣(𝑢) 𝑖 represents the personalized item score of user 𝑢on item 𝑖. This score quantifies the degree of preference that user 𝑢has for item 𝑖relative to all other items in the set 𝐼(refer to [12] for more details). Using these personalized item scores, we sorted the items for each user and selected the top-k items with the highest scores as their most preferred items. Consequently, the Top-K similarity score between every pair of users is computed as follows: 𝑆(𝑇𝑜𝑝−𝐾) 𝑢𝑖,𝑢𝑗 = |||𝑢(𝑇𝑜𝑝−𝐾) 𝑖 ∩𝑢(𝑇𝑜𝑝−𝐾) 𝑗 ||| 𝐾 (2) where 𝑢𝑇𝑜𝑝−𝐾 𝑖 represents the set of K-most preferred items for user 𝑢𝑖. The Top-K similarity scores, derived from the personalized item scores, serve as the ground truth for training the SimGNN model. By using these scores, the SimGNN model is incentivized to assign higher similarity scores to users whose top preferred items exhibit greater similarity. In other words, the training process encourages the SimGNN model to capture and reinforce the similarity patterns among users whose not only their pairwise preferences are similar, but also the top preferred items align closely with each other. 3.2.3. Clustering of graphs Once we have predicted the similarity scores for pairs of users, our next step is to cluster the users based on these scores. The clustering method employed in this study is based on the concept of a ‘‘Dominant set’’. This approach, initially introduced by Pavan et al. [54], was later utilized by Hung et al. [55] for detecting F-formations in social environments, and by Yazidi et al. [56] for identifying unreliable sensors. In the context of graph clustering, a dominant set refers to a maximal clique within an edge-weighted graph. By leveraging the dominant set algorithm, we aim to identify cohesive groups of users who exhibit similar preferences based on the obtained similarity scores. In the following, we will delve into the details of how the dominant set algorithm is applied for graph clustering. Information Fusion 107 (2024) 102343 6 R. Abolghasemi et al. Fig. 2. General overview of the proposed GcPp method containing four main steps. a. converting the training data including pairwise preferences to graphs. b. predicting similarity between every pair of users (graphs) using SimGNN. c. graph of users, nodes are users, and edges are weighted by the similarity of pair of nodes. 4. clustering the users with Dominant set clustering. We aim to cluster the data (users), using an undirected edge- weighted graph without self-loops. This graph, denoted as 𝐺= (𝑉, 𝐸, 𝑤), consists of a set of vertices 𝑉, a set of edges 𝐸, and a positive edge weight function 𝑤. In this context, the vertices correspond to the users, and the graph is assumed to be fully connected. However, the edges have varying weights that reflect the affinity between pairs of nodes. To quantify the affinity, we utilize the predicted similarity scores between each pair of users (see Section 3.2.1) as the edge weights. This Information Fusion 107 (2024) 102343 7 R. Abolghasemi et al. relationship is captured by a weighted affinity matrix 𝐴, where each element 𝑎𝑖𝑗represents the weight 𝑤(𝑖, 𝑗). When considering a subset 𝑆 of vertices in graph 𝐺, we can assess the average weighted degree of a vertex 𝑖∈𝑆as follows: 𝑘𝑆(𝑖) = 1 |𝑆| ∑ 𝑗∈𝑆 𝑎𝑖𝑗. (3) The relative affinity between node 𝑗∉𝑆and 𝑖can be expressed as follows: 𝜙𝑆(𝑖, 𝑗) = 𝑎𝑖𝑗−𝑘𝑆(𝑖). (4) It should be noted that for all 𝑖, 𝑗∈𝑉if 𝑖≠𝑗, then 𝜙𝑖(𝑖, 𝑗) = 𝑎𝑖𝑗, and 𝜙𝑆(𝑖, 𝑗) can be either positive or negative. Ultimately, the weight of each node 𝑖with respect to a set 𝑆is defined recursively as follows: 𝑤𝑆(𝑖) = { 1, 𝑖𝑓|𝑆| = 1 ∑ 𝑗∈𝑆⧵{𝑖} 𝜙𝑆⧵{𝑖}(𝑗, 𝑖)𝑤𝑆⧵{𝑖}(𝑗), 𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒. (5) According to this definition, 𝑤𝑆(𝑖) represents the overall relative affinity (similarity) between node 𝑖and the other vertices in set 𝑆, weighted by the overall affinity of the vertices in 𝑆 𝑖. Thus, the following conditions establish the relationship between the internal nodes (in set 𝑆) and the external nodes (not in set 𝑆) of a dominant set 𝑆: 𝑤𝑆(𝑖) > 0, ∀𝑖∈𝑆 (6) 𝑤𝑆∪{𝑖}(𝑖) < 0, ∀𝑖∉𝑆 (7) 3.2.4. Extracting dominating sets with replicator dynamics The theory of replicator dynamics is attributed to the influential work of Taylor and Jonker [57] for modeling biological processes in population genetics. Replicator dynamics models a game of a popu- lation of competing agents where each agent possesses 𝑁strategies 𝑎1, 𝑎2, … , 𝑎𝑁. The global state of the population is described by 𝑥= (𝑥1(𝑡), … , 𝑥𝑁(𝑡)) with the constraint that ∑ 𝑖𝑥𝑖= 1. For each 1 ≤𝑖≤𝑁, 𝑥𝑖(𝑡) denotes the proportion of the population using strategy 𝑎𝑖at time 𝑡. According to Taylor and Jonker [57], the agents encounter each other randomly. The random encounters yield a change in the fitness function according to a payoff matrix. The payoff matrix describes the utility 𝐴𝑖𝑗of a player playing strategy 𝑖against a player playing strategy 𝑗. The replicator dynamics describes the evolution of the frequencies of strategies in a population. To each 𝑥𝑖we attach a payoff function 𝑓𝑖. 𝑓𝑖is given by (𝐴𝑥)𝑖which is the expected payoff of strategy 𝑎𝑖from a single interaction with a random individual in the large population. More precisely, the expected payoff 𝑓𝑖is written as (𝐴𝑥)𝑖= ∑ 𝑗𝑎𝑖𝑗𝑥𝑗, the average payoff of the population as a whole can be written as 𝑥𝑇𝐴𝑥= ∑ 𝑖 ∑ 𝑗𝑎𝑖𝑗𝑥𝑖𝑥𝑗. The frequency of each strategy is changed according to the difference between its expected payoff and the average payoff of the population. In formal terms, this is given by: 𝑑𝑥𝑖 𝑑𝑡= 𝑥𝑖(𝑓𝑖−𝑓) (8) The ratio of 𝑑𝑥𝑖 𝑑𝑡and 𝑥𝑖is called the relative growth success rate of the population. Based on the above expressions, we can present in more detail the replicator dynamics equation given by (Eq. (8)) as: 𝑑𝑥𝑖 𝑑𝑡= 𝑥𝑖(𝑡)[(𝐴𝑥(𝑡))𝑖−𝑥(𝑡)𝑇𝐴𝑥(𝑡)], 𝑖= 1, … , 𝑁. (9) The theory of replicator dynamics has found a large set of applica- tions in graph theory, including finding dominant sets [58,59], solving the maximum clique problem [60,61], reinforcement learning [62], resource allocation problems [63], to mention a few. We shall present a well-known theorem from the theory of replicator dynamics [57]. Theorem 1. Let 𝐴be a nonnegative, real-valued symmetric 𝑛⋅𝑛ma- trix. Then the function 𝑥(𝑡)𝑇𝐴𝑥(𝑡) increases with increasing 𝑡along any nonstationary trajectory 𝑥(𝑡) under continuous-time replicator dynamics. Furthermore, any such trajectory converges towards a stationary point 𝑥∗. Finally, a vector 𝑥∗∈𝑆𝑛is asymptotically stable if and only if 𝑥∗is a strict local maximizer of 𝑥𝑇𝐴𝑥in the simplex 𝑆𝑁given by ∑𝑁 𝑖𝑥𝑖= 1, 𝑥𝑖≥0, 𝑖= 1, … , 𝑁. 3.2.5. Pseudo code for GcPp method Algorithm 1 GcPp 1: Input: 𝑈= {𝑢1, 𝑢2, … , 𝑢𝑛}: the set of 𝑛users where 𝑢𝑢= ⎡ ⎢ ⎢ ⎢⎣ 𝑝(𝑢𝑛) 11 ... 𝑝(𝑢𝑛) 1𝑚 ... ... ... 𝑝(𝑢𝑛) 𝑚1 ... 𝑝(𝑢𝑛) 𝑚𝑚 ⎤ ⎥ ⎥ ⎥⎦ is a matrix containing pairwise preference scores of user 𝑢on 𝑚items. 2: Output: 𝐶= {𝑐1, 𝑐2, ..., 𝑐𝑇∣𝑐𝑡⊂𝑈}: the set of all clusters of users. 3: for each 𝑢𝑖in 𝑈do 4: 𝑔𝑖←𝑔𝑟𝑎𝑝ℎ(𝑢𝑖); 5: end for 6: for every 𝑢𝑖and 𝑢𝑗in 𝑈do 7: 𝑆(𝑇𝑜𝑝−𝐾) 𝑢𝑖,𝑢𝑗 ←Top-K(𝑢𝑖, 𝑢𝑗); 8: 𝑤𝑖𝑗←𝑆𝑖𝑚𝐺𝑁𝑁(𝑔𝑖, 𝑔𝑗, 𝑆(𝑇𝑜𝑝−𝐾) 𝑢𝑖,𝑢𝑗 ); 9: end for 10: {Graph G=(V, E, w), maximum number of clusters is T} 11: 𝑉←𝑈{users as nodes of graph} 12: 𝐶∶= ∅ 13: 𝑡∶= 0 14: while 𝑉≠∅and 𝑡< 𝑇do 15: 𝑐𝑡= 𝐷𝑜𝑚𝑖𝑛𝑎𝑛𝑡_𝑠𝑒𝑡(𝐺) 16: 𝐶←𝐶∪𝑐𝑡 17: 𝑉←𝑉⧵𝑐𝑡 18: 𝑡←𝑡+ 1 19: end while 20: return 𝐶 A pseudocode for the proposed GcPp method is provided in Al- gorithm 1. This algorithm outlines the steps involved in clustering the users in 𝑈based on their pairwise preferences. In the algorithm, we start by converting the pairwise preference scores of each user 𝑢𝑖 into a graph 𝑔𝑖(see Section 3.2.1). Then, we use the Top-K method to calculate similarity scores between pairs of users and incorporate them into SimGNN as inputs (see Sections 3.2.1 and 3.2.2). SimGNN predicts the similarity scores, which are then used as weights (𝑤𝑖𝑗) for the edges of a graph 𝐺, where the nodes 𝑉represent the users 𝑈. The algorithm proceeds with a while-loop, where in each iteration, the dominant set of nodes in 𝐺is determined and assigned to a new cluster. These nodes are then removed from the set of remaining nodes in 𝐺. The loop continues until the clustering algorithm cannot find any dominant sets among the remaining nodes. The pseudo-code provides a comprehensive representation of the GcPp method, showcasing the pro- cess of converting pairwise preferences to graphs, predicting similarity scores with SimGNN, constructing the weighted graph, and iteratively clustering the users based on dominant sets. 3.3. Group recommendation In this section, we provide a detailed explanation of how we utilize the proposed GcPp clustering algorithm to offer effective recommen- dations for groups of users. The core concept of our proposed group recommendation system (GRS) is centered around the notion of max- imizing fairness and accuracy when recommending items to a group of users. Unlike conventional GRS methods that often rely on random user selections within the groups, resulting in varying preferences and limited accuracy and fairness, we harness the power of our GcPp clustering algorithm to form groups of similar users. By leveraging the pairwise preferences and Top-K preferred items of users, we can establish a sense of similarity based on shared opinions regarding item scores. Consequently, the recommended items are expected to be appealing to the majority of group members, leading to higher levels of accuracy and fairness. Our proposed GRS comprises several key steps, namely: 1. personalized item score calculation, 2. group aggregation, and 3. group recommendation. Below, we provide a more comprehensive explanation of each step: Information Fusion 107 (2024) 102343 8 R. Abolghasemi et al. • In the initial stage, it is essential to determine the preferences of each user towards individual items. To achieve this, we calculate personalized item scores for every user using (1). However, if the dataset already includes user scores on items, this step can be skipped, and the existing scores can be directly utilized as personalized item scores. • In this stage, we aim to determine the overall scores of items based on the preferences of users within each group. It is worth noting that our groups are created by clustering users using the GcPp method. Specifically, if 𝐶 = {𝑐1, 𝑐2, … , 𝑐𝑇∣𝑐𝑡⊂𝑈} represents all the clusters obtained from the GcPp method, then 𝐺= {𝑔1, 𝑔2, … , 𝑔𝑇∣𝑔𝑡⊂𝑈} will represent all the corresponding groups where 𝑔𝑡is equal to 𝑐𝑡. Among various methods available for group aggregation, this paper focuses on two approaches: average and approval voting. The average group score for each item 𝑖in the group 𝑔𝑡denoted by (𝑣(𝑔𝑡) 𝑖 ) is calculated by taking the average of the personalized item scores (1) of all users 𝑢within that group. This provides a measure of the collective preference for each item within the group. 𝑣(𝑔𝑡) 𝑖 = ∑ 𝑢∈𝑔𝑡𝑣(𝑢) 𝑖 ||𝑔𝑡|| (10) In approval voting, which is a majority-based aggregation method [64], the group score for an item is determined by counting the number of users who approve of it. We use the following equation to calculate the group score for each item: 𝑣(𝑔𝑡) 𝑖 = ∑ 𝑢∈𝑔𝑡𝐼(𝑢) 𝑖 ||𝑔𝑡|| (11) Here, 𝐼(𝑢) 𝑖 = 1 if the individual user’s score 𝑣(𝑢) 𝑖 is above the threshold (𝑣(𝑢) 𝑖 > 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑), and 𝐼(𝑢) 𝑖 = 0 otherwise. In our experiments, we found that using a threshold of 0.4 produced better results. Based on the superior performance observed during the evalua- tion phase, we have chosen Average as the primary approach for aggregating group preferences in our system. • During the group recommendation phase, we arrange the group scores 𝑣(𝑔𝑡) 𝑖 for all items in descending order and provide rec- ommendations to each group 𝑔𝑡based on the top-ranked items. To assess the performance of our group recommendation system, we evaluate it using various metrics including precision, recall, F1-score, and fairness. 4. Performance evaluation 4.1. Datasets For this paper, we utilized two pairwise preference datasets to support our research and analysis. The details of these datasets are provided below: • The food datasets used in this study were gathered through an online experiment called Consens@OsloMet, conducted at Oslo Metropolitan University in Norway. The primary objective of the experiment was to investigate how groups can achieve consen- sus or general agreement when presented with multiple food choices, including Chinese, French, Turkish, Italian, Japanese, and Mexican cuisines. The experiment was officially registered and approved by the Norwegian Centre for Research Data (NSD) with reference number 631862. The dataset consists of four trials, with five users providing their pairwise preferences for six differ- ent dishes in each trial. In this research, each user and experiment were treated as distinct individuals, resulting in a dataset that encompasses the pairwise preferences of 20 users across the six food items. For more details, please see section 3.2 in [10]. Table 3 Dataset characteristics. Dataset Users Items Comparisons Sparsity BookCrossing 271,379 278,858 5,893,374 99% MovieLens 1M 6040 3952 104,931,478 92% XING 784,687 1,029,480 180,601,043 99% Movie online interface 46 100 2262 54% Food 20 6 300 0% Car 60 10 2700 0% • The second dataset comprises car preferences1 that were provided by Abbasnejad et al. [65] in 2013. The dataset was gathered from 60 users residing in the United States, who participated in the data collection process through Amazon’s Mechanical Turk.2 The dataset focuses on ten distinct cars, treated as individual items for comparison purposes. Each user in the dataset provided responses for all 45 possible pairs of items, resulting in a total of 90 observations for each expert. In addition to the pairwise preference scores, the dataset also includes two additional files containing users’ attributes (education, age, gender, and region) and car attributes (body type, transmission, engine capacity, and fuel consumed). However, in our study, neither the users’ at- tributes nor the cars’ attributes were used during the training of the model. Table 3 displays the characteristics of six real-world datasets utilized in recommendation systems. BookCrossing [66], MovieLens 1M,3 and XING4 encompass both implicit and explicit feedback from users re- garding items, without incorporating pairwise preferences. Conversely, datasets such as Movie online interface [18], food and car datasets contain pairwise preferences expressed by users towards items. In their work [19] Kalloori et al. extracted both pairwise comparisons and ratings from the initial data of the first three datasets. For instance, the BookCrossing dataset comprises implicit (e.g., item clicks) and explicit user preferences on a 1–10 rating scale. Items with ratings exceeding 7 are deemed relevant, while the rest are considered irrelevant. Pairwise comparisons are derived by prioritizing items with implicit preferences over those deemed irrelevant. Similarly, in the XING dataset, interac- tions such as ‘click’, ‘bookmark’, ‘apply’, and ‘delete’ are recorded, with ‘apply’ interactions signifying relevance and ‘delete’ indicating irrel- evance. Implicit preferences are inferred from ‘click’ and ‘bookmark’ actions, guiding the derivation of pairwise comparisons. For MovieLens 1M, items rated 4–5 stars are deemed relevant, while those rated 1– 3 stars are considered irrelevant. All user ratings contribute to the derivation of pairwise comparisons, with differing ratings from the same user being subtracted. Table 3 provides an overview of the datasets and their salient features. Notably, the sparsity metric is calculated as the ratio of missing elements to the total number of elements. Due to the substantial sparsity observed in the generated pairwise comparison datasets for all datasets except food and car, they are unsuitable for our method. Our method, which relies on SimGNN and GcPp, involves comparing user graphs, where nodes represent items and directed edges signify user preferences. The lack of pairwise comparisons makes it impossible to compare user graphs and compute user similarities. Therefore, the food and car datasets emerge as optimal choices for our proposed methodology. 1 u4940058/CarPreferences.html. 2 3 4 2 Information Fusion 107 (2024) 102343 9 R. Abolghasemi et al. 4.2. Clustering performance In this section, we provide a detailed explanation of the clustering evaluation methodology employed, the experiments conducted for the parameter optimization, and present the related results obtained for the GcPp clustering method and the SimGNN similarity score prediction. Please note that the evaluation and discussion related to the proposed Group Recommendation System (GRS) are presented in Section 4.3. 4.2.1. Metrics According to an informal definition proposed by Jain et al. [67], ‘‘a cluster is a set of entities which are alike and entities from different clusters are not alike’’. Consequently, clustering approaches aim to achieve high internal homogeneity, which translates to high intra- cluster similarity (as shown in Eq. (12)), and at the same time, to maintain significant dissimilarity between entities within a cluster and those outside it, leading to low inter-cluster similarity (as expressed in Eq. (13)). In line with this definition, we define the following equations. For object 𝑖within cluster 𝑐𝐼, 𝑎(𝑖) = 1 ||𝑐𝐼|| −1 ∑ 𝑗∈𝑐𝐼,𝑖≠𝑗 𝑑(𝑖, 𝑗) (12) 𝑎(𝑖) represents the average distance between object 𝑖and the other objects within the same cluster (𝑐𝐼), where 𝑑(𝑖, 𝑗) denotes the distance between objects 𝑖and 𝑗. A smaller value of 𝑎(𝑖) indicates a better assignment of the object to its respective cluster. On the other hand, the dissimilarity of the object 𝑖to other clusters, such as 𝑐𝐽, is defined as the average distance between object 𝑖and all objects 𝑗within 𝑐𝐽(where 𝑐𝐼≠𝑐𝐽). For each object 𝑖, we calculate: 𝑏(𝑖) = min 𝐽≠𝐼 1 ||𝑐𝐽|| ∑ 𝑗∈𝑐𝐽 𝑑(𝑖, 𝑗) (13) defined as the minimum average distance of object 𝑖to all points in any other cluster to which 𝑖does not belong. By considering Eqs. (12) and (13), the silhouette score of an object 𝑖can be determined. 𝑠(𝑖) = ⎧ ⎪ ⎨ ⎪⎩ 1 −𝑎(𝑖) 𝑏(𝑖) 𝑖𝑓𝑎(𝑖) < 𝑏(𝑖) 0 𝑖𝑓𝑎(𝑖) = 𝑏(𝑖) 𝑏(𝑖) 𝑎(𝑖) −1 𝑖𝑓𝑎(𝑖) > 𝑏(𝑖) (14) From this equation, −1 ≤𝑠(𝑖) ≤1, and a higher value of 𝑠(𝑖) indicates better clustering results. 4.2.2. Experiment and parameter setting (SimGNN) In this section, we explain our conducted experiments to evaluate the GcPp clustering method. Our first step was to determine the optimal parameters for the experiment. As mentioned earlier, In the process of clustering by GcPp, we utilized a similarity method called SimGNN, which is a graph convolutional neural network, to predict the similarity scores between pairs of graphs. However, since SimGNN is a learning-based method, we needed ground truth similarity scores for comparison. To facilitate this comparison, we obtained ground truth scores from two different similarity methods: graph edit distance (GED) [13] and the Top-K similarity that we introduced in this paper (see Section 3.2.2). In graph theory, GED calculates similarity based on the number of node and edge deletions and insertions required to transform one graph into another. This method emphasizes the shape of the graphs and its impact on their similarity. On the other hand, Top-K similarity compares the K-most preferred items of each pair of users, indicating that users are similar if their most preferred items are the same. We conducted the SimGNN experiment with 100 epochs using both Top-K and GED as ground truth, varying the training batch sizes (128, 256, and 512 for the car dataset, and 32, 64, and 128 for the food dataset). The corresponding results are shown in Fig. 3 for the car dataset and Figure Fig. 4 for the food dataset. Interestingly, the clustering based on the Top-K method achieved better test loss and exhibited lower validation and training loss compared to the clustering based on GED. This significant finding demonstrates that in calculating the users’ similarities, incorporating valuable user information, such as their best items according to Top-K similarity, leads to improved similarity score predictions compared to GED, which solely relies on the graph structure. Regarding the batch sizes, we observed that a batch size of 128 and 256 performed better than 512 for the car dataset, while batch sizes of 32 and 64 were more effective for the food dataset. We reported the minimum validation and training loss as well as the test loss for all the experiments conducted on the car dataset in Table 4. The best results are highlighted in bold for easy reference. 4.2.3. Experiment and parameter setting (GcPp) In the subsequent phase of the experiment, we employed the pre- dicted similarity scores to cluster all of the users. Then, we evaluated our clustering with the silhouette score. As outlined in Section 4.2.1, the calculation of the silhouette score necessitates a distance metric. To this end, we utilized five distinct distance metrics, such as the Euclidean distance and cosine distance, which are computed based on the distance between the ‘‘feature vectors of the users’’. Notably, these feature vectors were not employed in the training of our proposed method. Additionally, we employed the ‘‘inverses of three similarity methods’’, namely SimGNN, GED, and Top-K, as three distance met- rics. These three methods only used ‘‘similarity’’ between the ‘‘graphs of users’’ and not the ‘‘feature vectors of the users’’. The obtained silhouette scores based on these five distance metrics are presented in Table 5. Intriguingly, the inverse of SimGNN yielded the highest score in all experiments, irrespective of the batch sizes and ground truth methods. Even Top-K outperformed GED in terms of results. These remarkable findings underscore the effectiveness of our proposed method in clustering. There are two primary reasons for this: Firstly, we integrated the pairwise preferences of users, which provided valu- able and detailed information about their preferences. This inclusion allowed us to capture the finer nuances of user preferences, leading to more accurate similarity predictions. Secondly, by using the Top- K similarity score as the ground truth, we incorporated the overall preferences of users in a broader sense. This approach allowed us to consider the general preferences and popular choices among users, resulting in a more comprehensive understanding of similarity. By combining these two approaches, we achieved improved performance in capturing and predicting similarity scores, resulting in better cluster- ing. As anticipated, the Euclidean and cosine metrics did not perform as well as the other metrics. This can be attributed to the fact that we did not employ the feature vectors of users during the training process. Instead, training solely relied on the structure of graphs (users’ pairwise preferences). In summary, our GcPp clustering method was implemented using the concept of ‘‘Dominant Set Clustering’’ and incor- porated predicted similarity scores obtained from SimGNN, where the Top-K similarity score served as the ground truth. The construction of graphs was based on the pairwise preference data of the users. Our eval- uation metrics demonstrated that the users were effectively clustered using this approach. Subsequently, we utilized these user clusters as groups in our Group Recommendation System (GRS) implementation. Through an ablation study, we optimized the system’s parameters and evaluated its performance. 4.3. Group recommendation performance In this section, we will elaborate on the evaluation methodology used for group recommendation. We will provide a comprehensive explanation of the experiments conducted to optimize the system’s parameters and perform an ablation study. Furthermore, the results obtained from these experiments will be presented and discussed in detail. Information Fusion 107 (2024) 102343 10 R. Abolghasemi et al. Fig. 3. Car dataset: Performance evaluation of SimGNN with 100 epochs and varying Training batch sizes (128, 256, 512). (Left) Ground truth: is Top-K, (Right) Ground truth is GED. Fig. 4. Food dataset: Performance evaluation of SimGNN with 100 epochs and varying Training batch sizes (32, 64, 128). (Left) Ground truth: is Top-K, (Right) Ground truth is GED. Table 4 SimGNN was implemented with various parameter configurations, including different ground truth methods (Top-K and GED) and batch sizes (128, 256, and 512). The minimum loss obtained for each setup is highlighted in bold. Ground truth: Top-K Ground truth: GED Train and validation batch Train and validation batch 128 256 512 128 256 512 Min validation loss 0.002 0.002 0.003 0.004 0.006 0.010 Min train loss 0.001 0.002 0.003 0.004 0.005 0.009 Test loss 0.005 0.004 0.005 0.013 0.010 0.011 Information Fusion 107 (2024) 102343 11 R. Abolghasemi et al. Table 5 Calculating Silhouette score for evaluation of our proposed GcPp clustering method by applying various parameter configurations, including different ground truth methods (Top-K and GED) and batch sizes (128, 256, and 512) and different distance metrics. Distance metrics in Ground truth: Top-K Ground truth: GED Silhouette score Train and validation batch Train and validation batch 128 256 512 128 256 512 1 Euclidean distance −0.332 −0.179 −0.240 −0.379 −0.411 −0.394 2 Cosine distance −0.484 −0.504 −0.641 −0.616 −0.642 −0.553 3 Inverse of SimGNN −0.002 −0.003 −0.003 −0.019 −0.022 −0.021 4 Inverse of GED −0.026 −0.033 −0.032 −0.025 −0.023 −0.024 5 Inverse of Top-K −0.006 −0.009 −0.008 −0.056 −0.048 −0.049 Fig. 5. Car dataset: Confusion matrices for different theta values, ranging from 0.1 to 0.9 (The letters N and P represent negative and positive, respectively). 4.3.1. Metrics Our evaluation of the group recommendation model involves four key metrics: precision, recall, F1-score, and fairness. Below, I provide detailed explanations of how each of these metrics is calculated. We calculate TP (true positive), FP (false positive), and FN (false negative) based on the following equations (see section 5.2 in [12]): 𝑇𝑃𝐺= {𝑖∈𝑅𝐺|∀𝑢∈𝐺 such that 𝑟𝑢,𝑖≥𝜃} (15) 𝐹𝑃𝐺= {𝑖∈𝑅𝐺|∃𝑢∈𝐺 such that 𝑟𝑢,𝑖< 𝜃} (16) 𝐹𝑁𝐺= {𝑖∉𝑅𝐺|∀𝑢∈𝐺 such that 𝑟𝑢,𝑖≥𝜃} (17) Here, the set of items recommended to group 𝐺is denoted by 𝑅𝐺, while the rating of user 𝑢for item 𝑖is 𝑟𝑢,𝑖. To measure whether a user likes or dislikes an item, we used a threshold 𝜃. In the following, we describe the process of determining an appropriate value for 𝜃. 4.3.2. Parameters setting To determine the optimal threshold value for theta (𝜃), we con- ducted multiple iterations of the experiment using various theta values ranging from 0.1 to 0.9 for the car dataset and 0.0 to 0.8 for the food dataset. As the heatmaps in Figs. 5 and 6 affirm, lower theta values are associated with higher values of TP and FN. Conversely, higher theta values result in higher TN and FP. Hence, a well-determined threshold is necessary to achieve high TP, TN, low FP, and FN, thereby ensuring high precision and recall. Based on our experiment, we selected a theta value of 0.4 for the car dataset and 0.1 for the food dataset. This implies that items with scores above this theta value are considered liked by the users, while those below, are deemed disliked. 4.3.3. Precision–recall curve In order to demonstrate the effectiveness of utilizing GcPp clustering in the group recommendation system (GRS), we conducted two exper- iments: one with clustering and one without clustering. The precision– recall curve, depicted in Fig. 7, illustrates the evaluation outcomes at Information Fusion 107 (2024) 102343 12 R. Abolghasemi et al. Fig. 6. Food dataset: Confusion matrices for different theta values, ranging from 0.1 to 0.9 (The letters N and P represent negative and positive, respectively). Fig. 7. Precision–recall curve for Group recommendation system with/without GcPp clustering on car dataset (left) and food dataset (right). various thresholds (ranging from theta 0.1 to 0.9). This curve serves as evidence of the impact and performance of our group recommendation model with and without GcPp clustering. From these figures, it is observed that the curve for our model (with clustering) consistently lies above the curve for the model without clustering across all theta values. This indicates that our proposed model consistently achieves higher precision and recall compared to the other one. This means our model performs better in accurately identifying positive instances and minimizing false positives compared to the second model. This suggests that using GcPp clustering results more effectively in the task at hand, as it achieves a better balance between precision and recall. This comparison between the precision–recall curves of the two models highlights the superior performance of GRS with GCPp clustering. 4.3.4. Aggregation function setting In the pursuit of identifying the most suitable aggregation function for our group recommendation System, we employed two aggregation methods: Approval Voting (AV) [68], which quantifies the number of ratings exceeding a specified threshold, and Average (Avg). These functions were applied to user groups derived from GcPp clustering and randomly assembled groups. The outcomes for the car dataset and food dataset on different thresholds (theta) are presented in Figs. 8 and 9, respectively. Within the car dataset, Average exhibited a superior F1-score when contrasted with Approval Voting in both clustered and random user groups. Upon scrutinizing the left-hand figures (representing clustered groups) against the right-hand figures (depicting random groups), it becomes evident that GRS on groups clustered by GcPp demonstrates enhanced fairness and F1-score (a combination of precision and recall) compared to groups composed of random users. This observation un- derscores the advantageous impact of our proposed GcPp clustering approach within the context of GRS. The summary of the parameter configuration of the proposed method based on the influence of various parameters on experimental Information Fusion 107 (2024) 102343 13 R. Abolghasemi et al. Fig. 8. Comparison of two aggregation functions: Approval Voting (upper panel) and Average (lower panel) applied to groups clustered by GcPp (left) and random groups (right), under varying theta values within the car dataset. Fig. 9. Comparison of two aggregation functions: Approval Voting (upper panel) and Average (lower panel) applied to groups clustered by GcPp (left) and random groups (right), under varying theta values within the food dataset. outcomes, comes in the following. According to Section 4.2.2, Ta- ble 4, and Figs. 3 and 4, the choice of ‘‘Top-K’’ as the ground truth for similarity in SimGNN is highlighted. Additionally, the train and validation batch sizes were set to 256 for the car dataset and 64 for the food dataset, driven by observations of lower test and validation losses. Furthermore, in accordance with Table 5 and the associated explanations in Section 4.2.3, ‘‘inverse of SimGNN’’ was selected as the distance metric for evaluating our clustering via the silhouette score. Having identified the optimal parameters for the clustering method, attention now shifts to leveraging these user clusters as groups for our group recommendation system. Towards this objective, as outlined in Section 4.3.4 and illustrated in Figs. 8 and 9, the aggregation function ‘‘Average’’ was chosen. Furthermore, guided by insights from Section 4.3.2 and depicted in Figs. 5 and 6, a theta value of 0.4 was adopted for the car dataset, while 0.1 was selected for the food dataset. 4.3.5. Comparison with state-of-the-art In order to assess the effectiveness of our model, we conducted a comparative analysis with two widely recognized recommendation system methods, namely BPR [21] and MFP [12], which operate on pairwise-preference data. We evaluated various performance metrics, including precision, recall, F1-score, fairness, and execution time, to Information Fusion 107 (2024) 102343 14 R. Abolghasemi et al. Table 6 Comparison of evaluation results between our proposed GRS method with GcPp clustering and three alternative recommendation methods on the car dataset. Precision Recall F1-score Fairness Execution time BPR 0.87 0.05 0.10 0.90 0.0061 MFP 0.78 0.30 0.43 0.82 0.0088 GRS without clustering 0.77 0.36 0.50 0.79 0.0088 GRS with GcPp clustering 0.90 0.42 0.57 0.98 0.0077 Table 7 Comparison of evaluation results between our proposed method with GcPp clustering and three alternative methods on the food dataset. Precision Recall F1-score Fairness Execution time BPR 0.68 0.74 0.71 0.70 0.0087 MFP 0.71 0.73 0.72 0.78 0.0093 GRS without clustering 0.92 0.50 0.65 1.00 0.0016 GRS with GcPp clustering 0.94 0.85 0.89 1.00 0.0014 gauge the quality and efficiency of our model in relation to these established methods. Moreover, we compared our method with the proposed GRS without using GcPp clustering. The obtained results are displayed in Tables 6 and 7. The results obtained from our evaluation demonstrate the superior performance of our proposed method over the other methods across all evaluation metrics. These findings highlight the significance of employing GcPp clustering in group recommendation systems. The high precision, recall, F1-score, and fairness achieved by our proposed method, which utilizes GcPp clustering, compared to BPR and MFP in the group recommendation system can be attributed to several key factors. Firstly, the incorporation of GcPp clustering in our proposed method allows for a more accurate and effective grouping of indi- viduals with similar preferences. By clustering individuals based on their preferences, our method can capture the underlying patterns and similarities within the group more effectively. This clustering process enables us to create more homogeneous groups, where the members share similar tastes and preferences. As a result, our proposed method can generate recommendations that are more aligned with the indi- vidual preferences of the group members, leading to higher precision and recall compared to BPR and MFP. Furthermore, GcPp clustering facilitates targeted and precise recommendation aggregation within each cluster. By considering the preferences of the clustered group members, our method can identify items that are highly preferred by a significant portion of the group. This targeted aggregation enhances the relevance and accuracy of the recommendations, resulting in higher precision and recall scores. In terms of fairness, GcPp clustering helps to address the fairness concerns in group recommendations. By forming clusters based on similarity, our method ensures that individuals with similar preferences are grouped together. This helps in avoiding situa- tions where certain individuals dominate the recommendation process, ensuring a fair distribution of recommendations among the group mem- bers. The recommendations provided by our proposed method take into account the preferences and interests of the entire group, promoting fairness in the recommendation outcomes. Moreover, GcPp clustering helps to mitigate the influence of personal biases or outliers within the group. By grouping individuals with similar preferences, our method can reduce the impact of extreme or outlier preferences, resulting in a more balanced and fair recommendation process. This contributes to higher fairness scores for our proposed method compared to BPR and MFP. To assess the efficacy of the proposed GcPp clustering approach on Group Recommendation Systems (GRS), we employed Adversarial Preference Learning with Pairwise Comparisons (CRGAN) [69] as a recommendation technique suited for pairwise comparison data. For group recommendation, user groups were formed using two methods: firstly, by leveraging the GcPp clustering outcomes where each cluster represented a user group; secondly, by generating random groups of equivalent sizes to the clustered groups but composed of random users. To ensure impartiality, the process of generating random groups was repeated 20 times, and the final evaluation results represent the average performance across these iterations. The evaluation encompassed 10 metrics, including HitRatio (HR), Normalized Discounted Cumulative Gain (NDCG), Area under the ROC Curve (AUC), Mean Average Precision (MAP), Mean Reciprocal Rank (MRR), Accuracy, Precision, Recall, F1-score, fairness, and also execu- tion time. Evaluation results are presented in Table 8. Notably, CRGAN exhibited superior performance across all metrics when employing GcPp for group formation compared to random grouping, particularly excelling in precision, recall, F1-score, and fairness, pivotal evaluation criteria for group recommendation systems. This superiority stems from the clustering algorithm’s ability to categorize users based on detailed (pairwise comparison) and top-K preferred items, resulting in similar preferences within clustered groups. Specifically, when group members share similar preferences, precision increases as a larger proportion of recommended items align closely with group preferences. Conversely, diversity within random groups poses challenges in matching items to varying preferences, resulting in lower precision. Additionally, in clus- tered groups, recommendations cater to common interests, enhancing recall by capturing relevant items more effectively. In contrast, random groups with diverse preferences struggle to identify universally relevant items, leading to lower recall. The F1-score reflects a balanced perfor- mance between recommendation accuracy and completeness. Fairness is also higher in clustered groups due to recommendations aligning with homogeneous group preferences, enhancing the satisfaction of each user and equitable representation compared to random groups with diverse preferences. 5. Conclusion This paper presents a group recommendation approach using the introduced graph clustering method called GcPp, which relies on users’ pairwise preferences. Initially, a neural network-based similarity score prediction process is employed, where the top-k preferred items act as the ground truth, determining the similarity scores between nodes (users) based on their favorite items and pairwise preference simi- larities. The integration of GcPp clustering enhances precision, recall, F1-score, and fairness in the group recommendation system. The clus- tering process enables accurate grouping and targeted recommenda- tion aggregation, promoting fairness by considering the entire group’s preferences and mitigating the impact of personal biases or outliers. Consequently, our proposed method outperforms BPR and MFP (widely used recommendation system methods based on pairwise preferences) in terms of precision, recall, F1-score, and fairness. In future work, we plan to explore GcPp in other applications such as intelligent transportation [70,71] or agent-based communication [72,73] to test the usability of the method in real settings. Ethical and informed consent for data used No ethical issue for data used. CRediT authorship contribution statement Roza Abolghasemi: Writing – review & editing, Writing – origi- nal draft, Visualization, Validation, Software, Conceptualization. En- rique Herrera Viedma: Writing – review & editing, Methodology, Con- ceptualization. Paal Engelstad: Writing – review & editing, Supervi- sion, Conceptualization. Youcef Djenouri: Writing – review & editing, Supervision, Methodology, Formal analysis, Conceptualization. Anis Yazidi: Writing – review & editing, Supervision, Project administration, Methodology, Formal analysis, Conceptualization. Information Fusion 107 (2024) 102343 15 R. Abolghasemi et al. Table 8 Comparing assessment outcomes of the GRS through the utilization of CRGAN with GcPp clustering against random clusters across car and food datasets. Dataset Food Dataset Car Dataset Method CRGAN CRGAN CRGAN CRGAN (random groups) (clustered groups) (random groups) (clustered groups) HR@3 1.00 1.00 1.00 1.00 NDCG@3 0.77 0.85 0.89 1.00 AUC@3 0.70 0.75 0.87 1.00 MAP@3 0.85 0.90 0.91 1.00 MRR@3 0.47 0.51 0.42 0.44 Accuracy 0.71 0.83 0.85 0.97 Precision 0.78 0.89 0.88 1.00 Recall 0.77 0.92 0.84 0.94 F1-score 0.76 0.89 0.86 0.97 Fairness 0.63 0.68 0.68 0.70 Execution time 0.0114 0.0130 0.0116 0.0130 Declaration of competing interest The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper. Data availability Data will be made available on request. References [1] J. Lin, M. He, W. Pan, Z. Ming, Collaborative filtering with sequential implicit feedback via learning users’ preferences over item-sets, Inform. Sci. 621 (2023) 136–155. [2] L. Zeng, J. Guan, B. Chen, MSBPR: A multi-pairwise preference and similarity based Bayesian personalized ranking method for recommendation, Knowl.-Based Syst. 260 (2023) 110165. [3] Y. Xu, E. Wang, Y. Yang, Y. Chang, A unified collaborative representation learning for neural-network based recommender systems, IEEE Trans. Knowl. Data Eng. 34 (11) (2021) 5126–5139. [4] E. Amigó, Y. Deldjoo, S. Mizzaro, A. Bellogín, A unifying and general account of fairness measurement in recommender systems, Inf. Process. Manage. 60 (1) (2023) 103115. [5] B. Walek, P. Fajmon, A hybrid recommender system for an online store using a fuzzy expert system, Expert Syst. Appl. 212 (2023) 118565. [6] X. Shen, H. Jiang, D. Liu, K. Yang, F. Deng, J.C. Lui, J. Liu, S. Dustdar, J. Luo, PupilRec: Leveraging pupil morphology for recommending on smartphones, IEEE Internet Things J. 9 (17) (2022) 15538–15553. [7] X. Chen, Y. Zhang, I.W. Tsang, Y. Pan, J. Su, Toward equivalent transformation of user preferences in cross domain recommendation, ACM Trans. Inf. Syst. 41 (1) (2023) 1–31. [8] W. Liu, X. Zheng, J. Su, L. Zheng, C. Chen, M. Hu, Contrastive proxy kernel stein path alignment for cross-domain cold-start recommendation, IEEE Trans. Knowl. Data Eng. (2023). [9] A. Jain, M. Murty, P. Flynn, Data clustering: a review, ACM computing survey, Journal 31 (3) (1999). [10] R. Abolghasemi, R. Khadka, P.G. Lind, P. Engelstad, E.H. Viedma, A. Yazidi, Predicting missing pairwise preferences from similarity features in group decision making, Knowl.-Based Syst. 256 (2022) 109860. [11] A. Yazidi, M. Ivanovska, F.M. Zennaro, P.G. Lind, E.H. Viedma, A new decision making model based on rank centrality for GDM with fuzzy preference relations, European J. Oper. Res. 297 (3) (2022) 1030–1041. [12] R. Abolghasemi, P. Engelstad, E. Herrera-Viedma, A. Yazidi, A personality-aware group recommendation system based on pairwise preferences, Inform. Sci. 595 (2022) 1–17. [13] A. Sanfeliu, K.-S. Fu, A distance measure between attributed relational graphs for pattern recognition, IEEE Trans. Syst. Man Cybern. (1983) 353–362. [14] A. Gazdar, L. Hidri, A new similarity measure for collaborative filtering based recommender systems, Knowl.-Based Syst. 188 (2020) 105058. [15] B.K. Patra, R. Launonen, V. Ollikainen, S. Nandi, A new similarity measure using bhattacharyya coefficient for collaborative filtering in sparse data, Knowl.-Based Syst. 82 (2015) 163–177. [16] T. Mahara, et al., A new similarity measure based on mean measure of divergence for collaborative filtering in sparse environment, Procedia Comput. Sci. 89 (2016) 450–456. [17] N. Jones, A. Brun, A. Boyer, A. Hamad, An exploratory work in using com- parisons instead of ratings, in: E-Commerce and Web Technologies - 12th International Conference, in: Lecture Notes in Business Information Processing, vol. 85, Springer, 2011, pp. 184–195, 23014-1_16. [18] L. Blédaité, F. Ricci, Pairwise preferences elicitation and exploitation for conver- sational collaborative filtering, in: Proceedings of the 26th ACM Conference on Hypertext & Social Media, 2015, pp. 231–236. [19] S. Kalloori, T. Li, F. Ricci, Item recommendation by combining relative and absolute feedback data, in: Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, 2019, pp. 933–936. [20] S. Kalloori, F. Ricci, M. Tkalcic, Pairwise preferences based matrix factorization and nearest neighbor recommendation techniques, in: Proceedings of the 10th ACM Conference on Recommender Systems, 2016, pp. 143–146. [21] S. Rendle, C. Freudenthaler, Z. Gantner, L. Schmidt-Thieme, BPR: Bayesian personalized ranking from implicit feedback, 2012, arXiv preprint arXiv:1205. 2618. [22] R. Yu, Y. Zhang, Y. Ye, L. Wu, C. Wang, Q. Liu, E. Chen, Multiple pairwise ranking with implicit feedback, in: Proceedings of the 27th ACM International Conference on Information and Knowledge Management, 2018, pp. 1727–1730. [23] S. Sieranoja, P. Fränti, Adapting k-means for graph clustering, Knowl. Inf. Syst. 64 (1) (2022) 115–142. [24] Y. Liu, W. Tu, S. Zhou, X. Liu, L. Song, X. Yang, E. Zhu, Deep graph clustering via dual correlation reduction, in: Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 36, 2022, pp. 7603–7611. [25] H. Liao, J. Hu, T. Li, S. Du, B. Peng, Deep linear graph attention model for attributed graph clustering, Knowl.-Based Syst. 246 (2022) 108665. [26] L. Guo, Q. Dai, Graph clustering via variational graph embedding, Pattern Recognit. 122 (2022) 108334. [27] L. Liu, Z. Kang, J. Ruan, X. He, Multilayer graph contrastive clustering network, Inform. Sci. 613 (2022) 256–267. [28] D. Hu, D. Feng, Y. Xie, EGC: A novel event-oriented graph clustering framework for social media text, Inf. Process. Manage. 59 (6) (2022) 103059. [29] J.A. Morente-Molinera, S.R. Aguilar, R. González-Crespo, E. Herrera-Viedma, Using clustering methods to deal with high number of alternatives on group decision making, Procedia Comput. Sci. 162 (2019) 316–323. [30] R.-X. Ding, I. Palomares, X. Wang, G.-R. Yang, B. Liu, Y. Dong, E. Herrera- Viedma, F. Herrera, Large-scale decision-making: Characterization, taxonomy, challenges and future directions from an artificial intelligence and applications perspective, Inf. Fusion 59 (2020) 84–102. [31] M. Tang, H. Liao, E. Herrera-Viedma, C.P. Chen, W. Pedrycz, A dynamic adap- tive subgroup-to-subgroup compatibility-based conflict detection and resolution model for multicriteria large-scale group decision making, IEEE Trans. Cybern. 51 (10) (2020) 4784–4795. [32] Y. Shang, Finite-time cluster average consensus for networks via distributed iterations, Int. J. Control Autom. Syst. 15 (2017) 933–938. [33] P. Liu, K. Zhang, P. Wang, F. Wang, A clustering- and maximum consensus- based model for social network large-scale group decision making with linguistic distribution, Inform. Sci. 602 (2022) 269–297. [34] S. Yao, M. Gu, An influence network-based consensus model for large-scale group decision making with linguistic information, Int. J. Comput. Intell. Syst. 15 (1) (2022) [35] F. Jin, J. Liu, L. Zhou, L. Martínez, Consensus-based linguistic distribution large-scale group decision making using statistical inference and regret theory, Group Decis. Negot. 30 (4) (2021) 1–33, 09736-Z. [36] J. Saarinen, A large-scale group decision-making model with no consensus threshold based on social network analysis, Inform. Sci. 612 (2022) 361–383, Information Fusion 107 (2024) 102343 16 R. Abolghasemi et al. [37] H. Liao, X. Li, M. Tang, How to process local and global consensus? A large-scale group decision making model based on social network analysis with probabilistic linguistic information, Inform. Sci. 579 (2021) 368–387, 1016/J.INS.2021.08.014. [38] X. Zhong, X. Xu, X. Chen, A clustering and fusion method for large group decision making with double information and heterogeneous experts, Soft Comput. (2022) 1–13. [39] J. Chen, H. Li, X. Zhang, F. Zhang, S. Wang, K. Wei, J. Ji, SR-HetGNN: session- based recommendation with heterogeneous graph neural network, Knowl. Inf. Syst. (2023) 1–24. [40] X. Liu, X. Li, Y. Cao, F. Zhang, X. Jin, J. Chen, Mandari: Multi-modal temporal knowledge graph-aware sub-graph embedding for next-POI recommendation, in: 2023 IEEE International Conference on Multimedia and Expo, ICME, IEEE, 2023, pp. 1529–1534. [41] J. Chen, Y. Cao, F. Zhang, P. Sun, K. Wei, Sequential intention-aware rec- ommender based on user interaction graph, in: Proceedings of the 2022 International Conference on Multimedia Retrieval, 2022, pp. 118–126. [42] C.-W. Hsu, C.-T. Chen, S.-H. Huang, Adaptive adversarial contrastive learning for cross-domain recommendation, ACM Trans. Knowl. Discov. Data 18 (3) (2023) 1–34. [43] Z. Fu, X. Niu, M.L. Maher, Deep learning models for serendipity rec- ommendations: A survey and new perspectives, ACM Comput. Surv. (2023). [44] D. Han, Y. Huang, J. Liu, K. Liao, K. Lin, LSAB: User behavioral pattern modeling in sequential recommendation by learning self-attention bias, ACM Trans. Knowl. Discov. Data 18 (3) (2024) 1–20. [45] V.R. Yannam, J. Kumar, K.S. Babu, B. Sahoo, Improving group recommendation using deep collaborative filtering approach, Int. J. Inf. Technol. 15 (3) (2023) 1489–1497. [46] T. Lalitha, P. Sreeja, Recommendation system based on machine learning and deep learning in varied perspectives: a systematic review, in: Information and Communication Technology for Competitive Strategies (ICTCS 2020) Intelligent Strategies for ICT, Springer, 2021, pp. 419–432. [47] R. Shrivastava, D.S. Sisodia, N.K. Nagwani, Deep neural network-based multi-stakeholder recommendation system exploiting multi-criteria ratings for preference learning, Expert Syst. Appl. 213 (2023) 119071. [48] W.-H. Liao, Y.-T. Lin, C.-Y. Lin, S.-C. Kuai, A group recommendation system for movies using deep learning, in: 2023 International Conference on Consumer Electronics-Taiwan, ICCE-Taiwan, IEEE, 2023, pp. 61–62. [49] Y. Wu, Q. Liu, R. Chen, C. Li, Z. Peng, A group recommendation system of network document resource based on knowledge graph and LSTM in edge computing, Secur. Commun. Netw. 2020 (2020) 1–11. [50] B. Ait Hammou, A. Ait Lahcen, S. Mouline, A distributed group recommendation system based on extreme gradient boosting and big data technologies, Appl. Intell. 49 (2019) 4128–4149. [51] S. Ali-Yari, N. Neissani Samani, M.R. Jelokhani Nayarki, Uncertainty modeling of a group tourism recommendation system based on pearson similarity criteria, Bayesian network and self-organizing map clustering algorithm, Eng. J. Geosp. Inf. Technol. 8 (1) (2020) 39–61. [52] Y.-D. Seo, Y.-G. Kim, E. Lee, H. Kim, Group recommender system based on genre preference focusing on reducing the clustering cost, Expert Syst. Appl. 183 (2021) 115396. [53] Y. Bai, H. Ding, S. Bian, T. Chen, Y. Sun, W. Wang, Simgnn: A neural network approach to fast graph similarity computation, in: Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, 2019, pp. 384–392. [54] M. Pavan, M. Pelillo, Dominant sets and pairwise clustering, IEEE Trans. Pattern Anal. Mach. Intell. 29 (1) (2006) 167–172. [55] H. Hung, B. Kröse, Detecting f-formations as dominant sets, in: Proceedings of the 13th International Conference on Multimodal Interfaces, 2011, pp. 231–238. [56] A. Yazidi, M.A. Pinto-Orellana, H. Hammer, P. Mirtaheri, E. Herrera-Viedma, Solving sensor identification problem without knowledge of the ground truth using replicator dynamics, IEEE Trans. Cybern. 52 (1) (2020) 16–24. [57] P.D. Taylor, L.B. Jonker, Evolutionary stable strategies and game dynamics, Math. Biosci. 40 (1–2) (1978) 145–156. [58] E.Z. Mequanint, L.T. Alemu, M. Pelillo, Dominant sets for constrained image segmentation, IEEE Trans. Pattern Anal. Mach. Intell. (2018). [59] Y.T. Tesfaye, E. Zemene, A. Prati, M. Pelillo, M. Shah, Multi-target tracking in multiple non-overlapping cameras using fast-constrained dominant sets, Int. J. Comput. Vis. (2019) 1–18. [60] M. Pelillo, A. Torsello, Payoff-monotonic game dynamics and the maximum clique problem, Neural Comput. 18 (5) (2006) 1215–1258. [61] K. Avrachenkov, V.S. Borkar, Metastability in stochastic replicator dynamics, Dynam. Games Appl. (2018) 1–25. [62] W. Barfuss, J.F. Donges, J. Kurths, Deterministic limit of temporal difference reinforcement learning for stochastic games, Phys. Rev. E 99 (4) (2019) 043305. [63] Q. Wang, N. He, X. Chen, Replicator dynamics for public goods game with resource allocation in large populations, Appl. Math. Comput. 328 (2018) 162–170. [64] A. Felfernig, L. Boratto, M. Stettinger, M. Tkalčič, et al., Group Recommender Systems: An Introduction, Springer, 2018. [65] E. Abbasnejad, S. Sanner, E.V. Bonilla, P. Poupart, Learning community-based preferences via dirichlet process mixtures of gaussian processes, in: Twenty-Third International Joint Conference on Artificial Intelligence, 2013, pp. 1213–1219. [66] C.-N. Ziegler, S.M. McNee, J.A. Konstan, G. Lausen, Improving recommendation lists through topic diversification, in: Proceedings of the 14th International Conference on World Wide Web, 2005, pp. 22–32. [67] A.K. Jain, R.C. Dubes, Algorithms for Clustering Data, Prentice-Hall, Inc., 1988. [68] L. Boratto, S. Carta, G. Fenu, Discovery and representation of the preferences of automatically detected groups: Exploiting the link between group modeling and clustering, Future Gener. Comput. Syst. 64 (2016) 165–174. [69] Z. Wang, Q. Xu, K. Ma, Y. Jiang, X. Cao, Q. Huang, Adversarial preference learn- ing with pairwise comparisons, in: Proceedings of the 27th ACM International Conference on Multimedia, 2019, pp. 656–664. [70] B. Cao, J. Zhao, Z. Lv, P. Yang, Diversified personalized recommendation optimization based on mobile data, IEEE Trans. Intell. Transp. Syst. 22 (4) (2020) 2133–2139. [71] J. Xu, K. Guo, X. Zhang, P.Z. Sun, Left gaze bias between LHT and RHT: a recommendation strategy to mitigate human errors in left-and right-hand driving, IEEE Trans. Intell. Veh. (2023). [72] Y. Peng, Y. Zhao, J. Hu, On the role of community structure in evolution of opinion formation: A new bounded confidence opinion dynamics, Inform. Sci. 621 (2023) 672–690. [73] J. Dong, J. Hu, Y. Zhao, Y. Peng, Opinion formation analysis for expressed and private opinions (EPOs) models: Reasoning private opinions from behaviors in group decision-making systems, Expert Syst. Appl. 236 (2024) 121292."
Interpretable intrusion detection for next generation of Internet of Things,Youcef Djenouri and Asma Belhadi and Gautam Srivastava and Jerry Chun-Wei Lin and Anis Yazidi,2023,,203,Computer Communications,article,"Computer Communications 203 (2023) 192–198
Contents lists available at ScienceDirect
Computer Communications
journal homepage: www.elsevier.com/locate/comcom
Interpretable intrusion detection for next generation of Internet of Things
Youcef Djenouri a, Asma Belhadi b, Gautam Srivastava c,d,e, Jerry Chun-Wei Lin f,∗, Anis Yazidi g
a NORCE, Norwegian Research Center, Oslo, Norway
b Kristiania University College, Oslo, Norway
c Brandon University, Brandon, Canada
d China Medical University, Taichung, Taiwan
e Lebanese American University, Beirut, Lebanon
f Western Norway University of Applied Sciences, Bergen, Norway
g OsloMet, Oslo, Norway
A R T I C L E
I N F O
Keywords:
Intrusion detection
XAI
NG-IoT
Deep learning
A B S T R A C T
This paper presents a new framework for intrusion detection in the next-generation Internet of Things. MinMax
normalization strategy is used to collect and preprocess data. The Marine Predator algorithm is then used to
select relevant features to be used in the learning process. The selected features are then trained with an
advanced and state-of-the-art recurrent neural network that includes an attention mechanism. Finally, Shapely
values are calculated to determine how much each feature contributes to the final output. The dataset NSL-
KDD was used for intensive simulations. The results show the advantages of the proposed system as well as its
superiority over state-of-the-art methods. In fact, the proposed solution achieved a rate of more than 94% for
both true negative and true position, while the rates of the existing solutions are below 90% for the challenging
NSL-KDD datasets.
1. Introduction
With the advent of the next-generation Internet of Things (NG-
IoT), new research problems and goals have emerged [1–3]. Artificial
intelligence (AI) has the potential to address the highlighted priorities
of this new technology, which requires a high degree of autonomy
and adaptability. In addition, NG-IoT technology has been actively
deployed in intelligent transportation to meet the new market demands
while achieving traditional business objectives [4–6]. The NG-IoT paves
the way for better understanding of manufacturing processes and en-
ables effective and sustainable production [7–9]. IoT devices produce
a huge amount of data that requires the use of smart data analytics,
not only to process the data, but also to secure the various communi-
cations between NG-IoT nodes. Securing NG-IoT and big data systems
is a challenging task and has become an active research topic in the
last two years [10–12]. NG-IoT devices are often distributed over a
large area and have limited storage, processing, and energy resources.
These characteristics make the networks and systems that contain such
devices particularly vulnerable and attractive targets for cyberattacks
by hackers. These systems have a large number of communication
channels, storage, devices, and intrusion risks. These characteristics
increase the likelihood that intrusions will occur in different patterns at
different points in the system, in addition to the limitations mentioned
above. The Mirai incident, in which a large number of NG-IoT devices
∗Corresponding author.
E-mail address: jerrylin@ieee.org (J.C.-W. Lin).
were compromised and used for distributed denial-of-service (DDoS)
attacks that crashed numerous servers, including Etsy, Github, Netflix,
Shopify, Soundcloud, Spotify, Twitter, and many others, is a typical
example of a NG-IoT attack. This highlights the need for efficient and
proactive intrusion detection systems that can not only detect and alert
intruders, but also provide the user with a better understanding of the
detection process.
1.1. Motivation
Many strategies have been taken into account when devising IoT in-
trusion detection systems [13–16]. While signature-based methods can
identify the attack, they are only effective against known threats and
cannot detect new patterns. Anomaly-based solutions, usually based
on monitoring the traffic flow of individual devices and comparing it
to typical patterns, can be used to detect them. The traffic patterns
of individual devices are often treated separately to find anomalies.
Both solutions are limited and so far are only suitable for use in NG-
IoT environments where different types of attacks may be present in
real time. Advanced deep learning [17–20] has been widely explored
in many areas of IoT. They have achieved great success in many
applications. In addition, eXplanaible AI (XAI) [21–23] will be included
to achieve a better understanding of the black box deep learning models
used during the detection process.
https://doi.org/10.1016/j.comcom.2023.03.005
Received 9 November 2022; Received in revised form 20 January 2023; Accepted 7 March 2023
Available online 9 March 2023
0140-3664/© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license
(http://creativecommons.org/licenses/by/4.0/).
 Y. Djenouri, A. Belhadi, G. Srivastava et al.
Computer Communications 203 (2023) 192–198
1.2.
Contributions
Motivated by the success of advanced deep learning solutions and
explainable AI in addressing IoT challenges, we propose a new frame-
work called Interpretable Recurrent Neural Network (IRNN) for intru-
sion detection in NG-IoT. The main contributions are listed below:
1. We provide normalization and feature selection steps based on
the MinMax and marine predator algorithm to select the most
relevant features to be used in the learning phase.
2. We present an effective deep learning method for extracting
intrusion information from NG-IoT data. The model uses an
attention mechanism to compute the relevant features with the
recurrent neural network to avoid the vanishing gradient prob-
lem.
3. We develop a strategy based on shape values to calculate the
contribution of each feature in the detection process. This allows
the user to better understand the developed black-box deep
learning model.
4. Using various criteria and an extensive intrusion detection
dataset, the proposed methodology is evaluated. The results
clearly show the superiority of the proposed framework over the
standard methods.
The rest of the paper is organized as follows. Modern techniques for
intrusion detection are discussed in Section 2. The proposed framework
and its essential elements are described in Section 3. The design and
results of the experiment are summarized in Section 4. Section 5
presents discussions and future directions of this paper. The paper is
then concluded in Section 6.
2. Related work
To create adversarial hostile traffic records intended to evade de-
tection by intrusion detection systems, a generative hostile network
framework known as IDSGAN was proposed in [24]. Since attackers do
not know the basic structure and parameters of the detection system,
adversarial attack examples use black box attacks against the system.
IDSGAN uses a generator to convert the initial malicious traffic records
into adversarial malicious records. The real-time blackbox detection
system is dynamically learned by a discriminator that also categorizes
traffic instances. Moreover, for the generation of the malicious data,
the constrained modification technique has been developed to preserve
the original attack capabilities of the hostile traffic data. To provide
justifications for important Deep Learning (DL)-based decisions for IoT-
related IDS, Zakaria et al. [25] created a new framework based on XAI.
To find IoT-related intrusions, they used a unique IDS for IoT networks,
which they had also created using deep neural networks. To the DL-
based model, they added three primary XAI techniques, e.g., RuleFit,
Local Interpretable Model-Agnostic Explanations (LIME), and SHapley
Additive exPlanations (SHAP). To improve the interpretation of DL-
based judgments, they provide both local and global explanations.
While global explanations focus on identifying the key factors that led
to each decision made, local explanations focus on a single/specific
DL outcome (e.g., intrusion detection). To identify security risks in IoT
contexts, a brand-new deep learning-based intrusion detection system
(DL-IDS) was presented [26].
Although several IDSs are described in the literature, they all have
deficiencies in learning and dataset management that significantly
impact the accuracy of attack detection. To achieve optimal detection,
the authors coupled the Spider Monkey Optimization (SMO) algorithm
and the Stacked-Deep Polynomial Network (SDPN). SMO selects the
best features from the datasets, while SDPN categorizes the data as
normal or anomalous. Denial of Service (DoS), User-to-Root (U2R),
probing, and Remote-to-Local (R2L) attacks are among the anomalies
that DL-IDS can identify. Tanzila et al. [27] presented a CNN-based
strategy for anomaly-based intrusion detection systems that leverages
the potential of IoT and provides capabilities to effectively probe all
traffic in IoT. The proposed model has shown the ability to detect
potential intrusions and unusual traffic patterns. Using deep learning-
based recurrent models, Ravi et al. [28] provided a complete network
attack detection and classification model. The proposed model collects
hidden layer features from recurrent models and then selects the best
features using kernel-based principal component analysis (KPCA) for
feature selection. An ensemble meta-classifier is used to classify the
data after combining the best features from recurrent models. Based
on cost-sensitive deep learning and ensemble algorithms, CSE-IDS, a
three-layer NIDS, was proposed [29]. Layer 1 of the proposed CSE-
IDS uses a cost-sensitive Deep Neural Network to distinguish between
valid and malicious network traffic. These dubious samples are then
forwarded to Layer 2, where they are classified into normal, multiple
majority attack classes, and a single class encompassing all minority
attack classes using the eXtreme Gradient Boosting algorithm. Finally,
layer 3 uses Random Forest to assign appropriate classes to the minority
attacks found in layer 2. Zhang et al. [30] presented TIKI-TAKA, a com-
prehensive framework for evaluating the resilience of cutting-edge deep
learning-based NIDS against hostile tampering. They also incorporated
defense mechanisms to strengthen resistance against attacks using eva-
sion strategies. In particular, they developed five new types of attacks
to subvert three widely used neural network-based malicious traffic
detectors. Alladi et al. [31]presented an AI-based intrusion detection
architecture consisting of deep-learning models to identify and classify
vehicle traffic networks into potential types of cyberattacks. Due to the
mobility of vehicles and the real-time requirements of traffic network
channels, these deep-learning models are run on edge servers rather
than in a remote cloud. Thakkar et al. [32] have developed a fusion-
based solution that aims to improve the effectiveness of deep learning
systems for intrusion detection by presenting a new algorithm that
selects features based on the standard error variance of historical ob-
servations. Features are matched based on their rank, which is derived
from statistical significance fusion. Moreover, statistical significance
fusion aims to produce relevant features with high distinctiveness and
variance, which contributes to better learning. However, the strategy
used is not powerful for NG-IoT data where the data is collected in
different learning spaces.
Based on this relatively brief literature review, we conclude that
intrusion detection methods are efficient in identifying outliers. How-
ever, they are still far from being deployed in NG-IoT environments
where there may be different types of attacks in real time. Effective
preprocessing and feature extraction are required before the learning
process. Moreover, in most of the cases described, there is a lack of
explanations, so the network manager has difficulty in understanding
the features that contribute positively to learning and the features that
contribute negatively to learning. Indeed, an efficient interpretation
strategy is also needed. To overcome the problems of existing solutions,
and motivated by the success of advanced deep learning and XAI, we
introduce in the following section a suitable platform, called IRNN, for
network attack detection and understanding. Unlike existing solutions,
IRNN enables better extraction of relevant features from network traf-
fic data, accurate learning using advanced recurrent neural network
architecture, and better understanding of the learning process using
XAI.
3. IRNN design
In this section, we present a novel framework for intrusion de-
tection from the next generation Internet of Things. The proposed
framework, which we call IRNN (Interpretable Recurrent Neural Net-
work), is shown in Fig. 1. IRNN combines advanced deep learning
architectures with an interpretive process to identify intrusions in
the next-generation IoT environment. The process begins with pre-
processing and extraction of relevant features through normalization
and feature selection. The intruders are then detected using the Atten-
tion Segmental Recurrent Neural Network (ASRNN) algorithm [33]; the
interpretation of the derived intrusions is finally examined using the
Shapely value. Each phase is described in detail below:
193
 Y. Djenouri, A. Belhadi, G. Srivastava et al.
Computer Communications 203 (2023) 192–198
Fig. 1. IRNN Framework: Preprocessing is done first using normalization, and then the pertinent features are extracted using feature selection. The ASRNN technique is then used
to detect the intrusions, and the Shapely value is then used to interpret the resulting intrusions.
3.1. Preprocessing
Data preprocessing is the process of modifying raw data that is
duplicated, erroneous, irrelevant, redundant, incomplete, or incorrectly
formulated. Data preprocessing is the process of removing information.
The main goal was to remove data from the datasets to standardize data
analysis and make it easier to find relevant data for the study. Since
some of the data were already missing or unclear, it was important
to modify the existing data to improve quality by omitting inaccurate
information. The MinMax normalization method [34] is essential for
integrating and normalizing data. Where ‘‘one’’ is assigned as the lowest
feature value and ‘‘zero’’ as the highest value. The binary equivalents of
each value of 0 and 1 are calculated. For each sample x, the 𝑀𝑖𝑛𝑀𝑎𝑥
formula is determined as follows:
𝑀𝑖𝑛𝑀𝑎𝑥(𝑥) =
𝑥−𝑚𝑖𝑛(𝑥)
𝑚𝑎𝑥(𝑥) −𝑚𝑖𝑛(𝑥),
(1)
in which 𝑚𝑖𝑛(𝑥), and 𝑚𝑎𝑥(𝑥) are the minimum and the maximum values
of all samples, respectively. Due to corrupted traffic data, even after
complete normalization for unstructured data, the data is still suspect.
The collection of these attributes from many complex systems enables
the investigation of intrusion detection.
3.2. Feature selection
The feature values are automatically added to the feature selection
when using the data from the preprocessing phase, which helps to
increase accuracy. Feature values that are not needed, redundant, or
irrelevant are disregarded and no longer help classify attacks. There-
fore, to assess the accuracy of the search domain, feature selection
techniques are used to select essential features. The classifier eliminates
the irrelevant components and selects the top ten features based on
their relevance. Combining optimization strategies with exploration
algorithms strengthens the exploration capabilities. We used the Marine
Predators Algorithm (MPA) [35] to extract the relevant features for
prediction. It is a brand new meta-heuristic algorithm inspired by
nature. Similar to other meta-heuristic algorithms, the MPA algorithm
is used to solve practical optimization problems. The broad-scale for-
aging of marine predators and the encounters or interactions between
predators and prey serve as inspiration for MPA. Here, a predator
strategically controls encounter rates to increase its chances of survival
in the wild. Using L’evy flight and Brownian motion, MPA performs a
search using two basic random walk methods. The first type of random
walk is commonly used in meta-heuristic algorithms and is probably
most successful in preventing solution stagnation by performing an
advantageous search in local areas [36]. The latter, on the other hand,
is a well-known stochastic tool for global search. To maximize the bal-
ance between exploration and exploitation, the MPA inventors merged
the search efficiency of the two random walk algorithms. Similar to
a number of other population-based metaheuristic algorithms, MPA
begins the search process by randomly distributing 𝑁search agents
over the search area using Eq. (2):
⃖⃖⃖⃗
𝑋𝑖= ⃖⃖⃖⃗
𝑙𝑏𝑖+ 𝑟× (⃖⃖⃖⃖⃗
𝑢𝑏𝑖−⃖⃖⃖⃗
𝑙𝑏𝑖); 𝑖∈{1, 2, … , 𝑁}
(2)
where ⃖⃖⃖⃗
𝑙𝑏𝑖and ⃖⃖⃖⃖⃗
𝑢𝑏𝑖are two vectors that indicate the lower and higher
bounds for the search to be conducted within, and 𝑟denotes a random
variable between [0, 1]. Another 𝑁×𝐷matrix made up of search agents
with the best fitness values is formed during initialization along with
the primary population matrix, where 𝑁and 𝐷stand for population
size and problem dimensions, respectively. MPA refers to it as Elite,
which is composed by the set of vectors with top fitness. Prey is a
different matrix of the same dimension as Elite, and the predators
adjust their places in accordance with it. The initialization creates
the initial Prey in a single term from which the strongest individual
(predator) creates the Elite. These two matrices play a key role in
the optimization process. After initialization, the main iterative search
process begins. This process is divided into three phases that simulate
various predator–prey scenarios while coming up with various search
tactics. These phases are based on iterations 𝑡∈{1, 2, 3 … 𝑡𝑚𝑎𝑥} where
𝑡𝑚𝑎𝑥is maximum iterations. Note that MPA updates candidate solutions
dimension-wise during these phases.
3.3. Learning
The traffic network is used to detect intrusions with the ASRNN
algorithm [33]. LSTM (Long Short Term Memory) performs better
than the currently used RNN-based systems. Namely, the LSTM model
ensures correlation between different elements in a sequence where
a long dependency is checked. This allows to mitigate the vanishing
gradient problem of the RNN-based systems. Therefore, the LSTM
model is used in the modified ASRNN model proposed in this study.
Two different LSTM models are used to learn from the traffic network.
While the second model uses the attention mechanism to determine
the local features of each element in the context vector, the first
model is based on determining the context vector on the flow time.
At each timestamp, a Bi-LSTM is used to retrieve the context vector,
and a second Bi-LSTM is used in a recursive manner to dynamically
generate the segmental representation for each segment using an at-
tention mechanism. Dynamic recursion is used in the computation of
194
 Y. Djenouri, A. Belhadi, G. Srivastava et al.
Computer Communications 203 (2023) 192–198
the segment. Then, each segmental representation is subjected to label
categorization using a fully connected layer. The score computed by a
fully linked layer is directly used to compute the neural feature scores.
Since the sum of the neural feature scores can be greater than one, the
softmax operation with the fully connected layer is not required for
label classification. The semi-CRF model [37] is then trained together
with the computed neural feature values, which are transferred to the
model along with the traditional semi-CRF features. For the network
structure, the hidden dimension in both the lower and upper Bi-LSTM
networks was set to 50, resulting in a character-level representation
vector with 100 dimensions. The hidden dimension of the lower Bi-
LSTM network and the upper network was set to 100 for the word-level
encoder, resulting in a segmental representation with 200 dimensions.
The output size of the fully linked layer, which had a hidden size of
256 and a number of labels for each task, was equal to the number
of labels. For optimization, we used a mini-batch stochastic gradient
descent with 10 batches and a momentum of 0.9. The initial learning
rate was set to 0.01 and the decay rate to 0.1. To avoid ‘‘breaking out
the gradient’’, the gradient clipping was set to 5.
3.4. Shapely value
Shapley values are an idea from cooperative game theory. Shapley
values were introduced to fairly allocate a player’s contribution to the
final outcome of a game. Suppose we have a cooperative game where
a group of players work together to create value. If we can calculate
the total payoff of the game, the Shapley values capture each player’s
marginal contribution to the final outcome. More formally, suppose we
have a game with 𝑛players, with players 1, 2, … , 𝑛and a value function
v that accepts a small proportion of players and returns the real value
of the game if only those players participated. We also have S as a
coalition or subset of players. Formally, then, the contribution 𝛩of the
𝑖th player is defined as:
𝛩(𝑣)𝑖=
∑
𝑆⊂{𝑁−{𝑖}}
|𝑆|!(𝑁−|𝑆| −1)!
𝑁!
(𝑣(𝑆𝑐𝑢𝑝{𝑖}) −𝑣(𝑆))
(3)
The Shapley score is a metric that can used in explainable machine
learning to quantify the contributions of input features (players) to
the output of an instance-level machine learning model. The goal is
to break down the model prediction into its components and assign
Shapley values to each instance feature given a single data point.
The only requirement for a cooperative game for the interpretation
proposed in this research is that the model can produce a scalar-
valued output, such as the probability of assigning a class label to
an instance. Since the principle of efficiency applies, determining the
Shapley value in such a game leads to a complete deconstruction of
the process of intrusion detection. Missing values of input features are
replaced by a reference value, e.g., the mean value determined from
numerous examples, and the Shapley values of the feature values are
explanatory assignments to the input features. We suppose that the
Shapley values are approximated over linear time. Our goal is to model
the explainability of neurons using a game in which neurons are actors
and neural attributions are rewards. These games will be solved and
the attributions will be computed with respect to the neurons and
filters. The output of the neural network obtained by hiding certain
neurons is what is known in practice as ‘‘payoffs’’. Individual neurons
can be evaluated using the Shapley values obtained in these games.
The proposed strategy is exclusive to deep learning and shares goals
and designs with the games mentioned in universal explainability.
4. Performance evaluation
Extensive simulations were performed to validate the performance
of the proposed IRNN system. The evaluation uses the True Positive
Rate (TPR) and True Negative Rate (TNR), which are commonly used
to evaluate intrusion detection systems. They are specified as follows:
𝑇𝑃𝑅=
𝑇𝑃
𝑇𝑃+ 𝐹𝑃,
(4)
and,
𝑇𝑁𝑅=
𝑇𝑁
𝑇𝑁+ 𝐹𝑃,
(5)
where the TP, FP, and TN variables stand for the number of true
positives, false positives, and true negatives, respectively.
In this experiment, the performance of the IRNN algorithm with the
following baseline solutions: TIKI-TAKA [30], CSE-IDS [29], and DL-
IDS [26]. For the training data, we use a batch size of 512 samples by
default and reduce the batch size if the model does not fit in memory.
We find that we achieve the same speed with batch sizes of 64, 128,
256, or 512. The stack size of the training phase is used to determine
the number of training epochs and the learning rate. The final layer of
our framework and the baseline models is treated with a dropout rate
of 0.7.
4.1. Data description
The NSL-KDD dataset [38] represents an improved version of the
KDD’99 dataset that DARPA had previously published, adding a wide
range of actual attacks on a transportation network. Like the KDD’99
dataset, the NSL-KDD dataset contains 41 network-related features
collected from TCP/IP dumps, as well as examples of 23 different
attacks in the training set and 17 new attacks in the test set. The
NSL-KDD dataset improves upon the KDD’99 dataset in several ways,
including deleting duplicate data streams and using a proportional
inclusion approach to reduce class imbalances caused by unusual attack
types. These improvements are expected to improve consistency and
fairness when comparing different NIDS. In this paper, we train and
test our approach using the datasets ‘‘KDDTrain+’’ and ‘‘DDTest+’’.
Both datasets are annotated where ground truth is available. This
facilitates both the training process for building supervised learners
and the testing process for evaluating the developed system before
deployment. Although the NSL-KDD dataset has certain limitations in
capturing examples of more recent attack methods, it is one of the few
publicly available datasets that can be used to evaluate the performance
of a NIDS when the training and testing distributions differ.
4.2. Inference runtime and accuracy
Extensive testing was performed to evaluate the inference time
of the IRNN. The experimental data was divided into buckets, each
containing a certain amount of network data. The first bucket contains
20% of the test data, the second 50%, the third 80%, and the last 100%
(all test data). The models were trained first and then the inference was
performed with the test data to calculate the inference time.
Fig. 2
shows how the inference times for IRNN and baseline approaches differ.
It can be seen that as the percentage of data features and test data
increases, the inference time for the four methods also increases. The
results also show the superiority of the proposed strategy, with a time
difference of more than 500 ms for the data from NSL-KDD. These
results are justified by combining a state-of-the-art feature selection
technique with a powerful recurrent neural network architecture and
an effective attention mechanism. While IRNN explores a novel MPA-
based method, the baseline methods use traditional feature selection
techniques such as PCA. Extensive experiments have been conducted
to evaluate the quality of traffic network performance in intrusion
detection. The TPR and TNR values are obtained for each iteration
of the experiments. The results are highlighted in the Tables 1, 2.
Compared to the baseline approaches, the numerical results show that
IRNN can identify the correct interventions. The feature selection used
in this study and a deep learning model that analyzes and learns from
the numerous correlations between the input data to determine the
interventions were both carefully employed to achieve these results.
195
 Y. Djenouri, A. Belhadi, G. Srivastava et al.
Computer Communications 203 (2023) 192–198
Fig. 2. Inference time in milliseconds of IRNN vs. state-of-the art NG-IoT intrusion detection algorithms.
Table 1
TNR of IRNN vs. state-of-the art NG-IoT intrusion detection algorithms.
Number of Epochs
IRNN
TIKI-TAKA
CSE-IDS
DL-IDS
100
25
20
8
7
200
41
27
15
13
500
78
63
38
34
800
95
89
61
54
Table 2
TPR of IRNN vs. state-of-the art NG-IoT intrusion detection algorithms.
Number of Epochs
IRNN
TIKI-TAKA
CSE-IDS
DL-IDS
100
38
18
4
3
200
66
41
29
26
500
87
53
41
38
800
94
75
58
56
4.3. Interpretation
To understand the behavior of the IRNN model, an experiment
was conducted to visualize the output of the Shapely value.
Fig. 3
shows the SHAP value for the eight most important variables in the
learning process. It is worth noting that when the SHAP value is
less than 0, the variable has a negative impact on learning, while
when the SHAP value is greater than 0, the variable has a positive
impact on learning. From Fig. 3, we can conclude that there are many
variables that contribute positively to learning, but that more robust
feature selection methods are needed to weed out the variables that
contribute negatively to learning. This will improve intrusion detection
performance. Even though MPA performs very well in selecting the
most relevant features, more efforts need to be made. For example,
combining traditional methods such as PCA with MPA could be a good
direction for future work.
196
 Y. Djenouri, A. Belhadi, G. Srivastava et al.
Computer Communications 203 (2023) 192–198
Fig. 3. Contribution of the most relevant features for the IRNN model output.
5.
Discussions and future directions
The first challenge is to build a comprehensive dictionary of at-
tack signatures in complex NG-IoT systems. This makes detecting a
zero-day attack difficult. Since IRNN lacks attack data, modern data
augmentation techniques such as generative adversarial network and
variable auto-encoder can be useful to generate relevant training data
with different attack types. Although not all attacks generated by data
augmentation models are actual attacks, the comprehensive attack dic-
tionary created appears to be an effective strategy for defending against
zero-day attacks. Heterogeneous data in IoT, especially in NG-IoT, is
considered more vulnerable to a variety of threats than their wired
counterparts. This is because of the complex network topology and high
connectivity between traffic variables. Adversaries face a large attack
surface that includes multiple entry points. Moreover, the attackers
can change their behavior, rendering the initial learning of the IRNN
ineffective. The second challenge is to develop an IRNN model that is
capable of detecting new attacks in a traffic network using a lifetime
learning mechanism. Federated learning (FL) has recently attracted the
interest of academia and industry as an alternative to the traditional
centralized ML approaches. FL has a significant privacy advantage, as
training nodes can build a global model without transmitting their data.
The learning process occurs over a set number of training rounds, in
which each node continuously monitors the parameters of a modeling
framework by training with its local data. In each training round, these
parameters are then accumulated by a central entity to compute an
updated copy of the global model, which is in turn communicated to
the nodes. The third challenge of this work is to take advantage of FL in
the context of IRNN to create distributed models that are shared among
different entities in the network without these entities having access to
their own data.
6. Conclusion
This study presents a revolutionary paradigm for the next genera-
tion Internet of Things dedicated to intrusion detection. The MinMax
normalization approach is used to collect and preprocess the dataset.
The Marine Predator algorithm is then used to select features. The
selected feature is then trained with an advanced recurrent neural
network that includes an attention mechanism. The introduction of the
Shapely value is the final step to determine how each feature affects the
final output. The dataset NSL-KDD was subjected to extensive simula-
tion. The results illustrate the benefits of the framework provided and
how it outperforms state-of-the-art techniques. In the future, we plan to
explore other Deep Learning architectures for intrusion detection, such
as those based on convolutional neural networks [39]. We also plan to
consider group detection [40] as a future strategy in next-generation
IoT. Exploring genetic algorithm, pattern mining, and decomposition
in learning [41–43] is also on our agenda.
CRediT authorship contribution statement
Youcef Djenouri: Conceptualization, Writing – original draft. Asma
Belhadi: Methodology. Gautam Srivastava: Writing – review & edit-
ing. Jerry Chun-Wei Lin: Formal analysis, Writing – review & editing.
Anis Yazidi: Validation.
Declaration of competing interest
The authors declare that they have no known competing finan-
cial interests or personal relationships that could have appeared to
influence the work reported in this paper.
Data availability
Data will be made available on request.
Acknowledgment
This work is supported by the project ULEARN ‘‘Unsupervised Life-
long Learning’’ and co-funded under the grant number 316080 of the
Research Council of Norway.
References
[1] M. Maiti, U. Ghosh, Next generation Internet of Things in fintech ecosystem,
IEEE Internet Things J. (2021).
[2] A. Asheralieva, D. Niyato, Optimizing age of information and security of the
next-generation internet of everything systems, IEEE Internet Things J. (2022).
[3] A. Rejeb, K. Rejeb, S. Simske, H. Treiblmaier, S. Zailani, The big picture on the
Internet of Things and the smart city: A review of what we know and what we
need to know, Internet of Things 19 (2022) 100565.
[4] A.B. Adam, M.S.A. Muthanna, A. Muthanna, T.N. Nguyen, A.A. Abd El-Latif, To-
ward smart traffic management with 3D placement optimization in UAV-assisted
NOMA IIoT networks, IEEE Trans. Intell. Transp. Syst. (2022).
[5] N. Zhang, T. Han, M. Dianati, N. Lu, S. Wang, Guest editorial special issue on
space-air-ground integrated networks for intelligent transportation systems, IEEE
Trans. Intell. Transp. Syst. 23 (3) (2022) 2701–2704.
[6] Y. Yao, H. Zhang, L. Lin, G. Lin, R. Shibasaki, X. Song, K. Yu, Internet of
Things positioning technology based intelligent delivery system, IEEE Trans.
Intell. Transp. Syst. (2022).
[7] V. Delpla, J.-P. Kenné, L.A. Hof, Circular manufacturing 4.0: Towards Internet
of Things embedded closed-loop supply chains, Int. J. Adv. Manuf. Technol. 118
(9) (2022) 3241–3264.
197
 Y. Djenouri, A. Belhadi, G. Srivastava et al.
Computer Communications 203 (2023) 192–198
[8] C. Liu, Z. Su, X. Xu, Y. Lu, Service-oriented industrial Internet of Things gateway
for cloud manufacturing, Robot. Comput.-Integr. Manuf. 73 (2022) 102217.
[9] J. Sousa, J.P. Mendonça, J. Machado, A generic interface and a framework
designed for industrial metrology integration for the Internet of Things, Comput.
Ind. 138 (2022) 103632.
[10] A. El Kamel, H. Eltaief, H. Youssef, On-the-fly (D) DoS attack mitigation in SDN
using deep neural network-based rate limiting, Comput. Commun. 182 (2022)
153–169.
[11] W. Xue, Y. Shen, C. Luo, W. Xu, W. Hu, A. Seneviratne, A differential privacy-
based classification system for edge computing in IoT, Comput. Commun. 182
(2022) 117–128.
[12] M. Rana, A. Shafiq, I. Altaf, M. Alazab, K. Mahmood, S.A. Chaudhry, Y.B.
Zikria, A secure and lightweight authentication scheme for next generation IoT
infrastructure, Comput. Commun. 165 (2021) 85–96.
[13] Y. Djenouri, A. Belhadi, G. Srivastava, U. Ghosh, P. Chatterjee, J.C.-W. Lin, Fast
and accurate deep learning framework for secure fault diagnosis in the industrial
Internet of Things, IEEE Internet Things J. (2021).
[14] F. Hussain, R. Hussain, S.A. Hassan, E. Hossain, Machine learning in IoT security:
Current solutions and future challenges, IEEE Commun. Surv. Tutor. 22 (3)
(2020) 1686–1721.
[15] J.C.-W. Lin, G. Srivastava, Y. Zhang, Y. Djenouri, M. Aloqaily, Privacy-preserving
multiobjective sanitization model in 6G IoT environments, IEEE Internet Things
J. 8 (7) (2020) 5340–5349.
[16] P. Sharma, S. Jain, S. Gupta, V. Chamola, Role of machine learning and deep
learning in securing 5G-driven industrial IoT applications, Ad Hoc Netw. 123
(2021) 102685.
[17] S. Singh, R. Sulthana, T. Shewale, V. Chamola, A. Benslimane, B. Sikdar,
Machine-learning-assisted security and privacy provisioning for edge computing:
A survey, IEEE Internet Things J. 9 (1) (2021) 236–260.
[18] S. Hui, H. Wang, Z. Wang, X. Yang, Z. Liu, D. Jin, Y. Li, Knowledge enhanced
GAN for IoT traffic generation, in: Proceedings of the ACM Web Conference
2022, 2022, pp. 3336–3346.
[19] R. She, P. Fan, From MIM-based GAN to anomaly detection: Event probability
influence on generative adversarial networks, IEEE Internet Things J. (2022).
[20] X. Cao, G. Sun, H. Yu, M. Guizani, PerFED-GAN: Personalized federated learning
via generative adversarial networks, IEEE Internet Things J. (2022).
[21] S.K. Jagatheesaperumal, Q.-V. Pham, R. Ruby, Z. Yang, C. Xu, Z. Zhang,
Explainable AI over the Internet of Things (IoT): Overview, state-of-the-art and
future directions, IEEE Open J. Commun. Soc. (2022).
[22] H. Elayan, M. Aloqaily, F. Karray, M. Guizani, Internet of behavior (IoB) and
explainable ai systems for influencing iot behavior, IEEE Netw. (2022).
[23] L.M. Alkwai, An explainable artificial-intelligence-based CNN model for knowl-
edge extraction from the social Internet of Things: Proposing a new model, IEEE
Syst. Man Cybern. Mag. 8 (4) (2022) 48–51.
[24] Z. Lin, Y. Shi, Z. Xue, Idsgan: Generative adversarial networks for attack
generation against intrusion detection, in: Pacific-Asia Conference on Knowledge
Discovery and Data Mining, Springer, 2022, pp. 79–91.
[25] Z. Abou El Houda, B. Brik, L. Khoukhi, ‘‘Why should I trust your IDS?’’: An
explainable deep learning framework for intrusion detection systems in Internet
of Things networks, IEEE Open J. Commun. Soc. 3 (2022) 1164–1176.
[26] Y. Otoum, D. Liu, A. Nayak, DL-IDS: A deep learning–based intrusion detection
framework for securing IoT, Trans. Emerg. Telecommun. Technol. 33 (3) (2022)
e3803.
[27] T. Saba, A. Rehman, T. Sadad, H. Kolivand, S.A. Bahaj, Anomaly-based intrusion
detection system for IoT networks through deep learning model, Comput. Electr.
Eng. 99 (2022) 107810.
[28] V. Ravi, R. Chaganti, M. Alazab, Recurrent deep learning-based feature fusion
ensemble meta-classifier approach for intelligent network intrusion detection
system, Comput. Electr. Eng. 102 (2022) 108156.
[29] N. Gupta, V. Jindal, P. Bedi, CSE-IDS: Using cost-sensitive deep learning and
ensemble algorithms to handle class imbalance in network-based intrusion
detection systems, Comput. Secur. 112 (2022) 102499.
[30] C. Zhang, X. Costa-Pérez, P. Patras, Adversarial attacks against deep learning-
based network intrusion detection systems and defense mechanisms, IEEE/ACM
Trans. Netw. (2022).
[31] T. Alladi, V. Kohli, V. Chamola, F.R. Yu, M. Guizani, Artificial intelligence (AI)-
empowered intrusion detection architecture for the Internet of Vehicles, IEEE
Wirel. Commun. 28 (3) (2021) 144–149.
[32] A. Thakkar, R. Lohiya, Fusion of statistical importance for feature selection in
deep neural network-based intrusion detection system, Inf. Fusion 90 (2023)
353–363.
[33] J.C.-W. Lin, Y. Shao, Y. Djenouri, U. Yun, ASRNN: A recurrent neural network
with an attention model for sequence labeling, Knowl.-Based Syst. 212 (2021)
106548.
[34] S. Patro, K.K. Sahu, Normalization: A preprocessing stage, 2015, arXiv preprint
arXiv:1503.06462.
[35] A. Faramarzi, M. Heidarinejad, S. Mirjalili, A.H. Gandomi, Marine preda-
tors algorithm: A nature-inspired metaheuristic, Expert Syst. Appl. (2020)
113377.
[36] T. Dokeroglu, E. Sevinc, T. Kucukyilmaz, A. Cosar, A survey on new generation
metaheuristic algorithms, Comput. Ind. Eng. 137 (2019) 106040.
[37] N. Qun, H. Yan, X.-P. Qiu, X.-J. Huang, Chinese word segmentation via
BiLSTM+ semi-CRF with relay node, J. Comput. Sci. Tech. 35 (5) (2020)
1115–1126.
[38] M. Tavallaee, E. Bagheri, W. Lu, A.A. Ghorbani, A detailed analysis of the KDD
CUP 99 data set, in: 2009 IEEE Symposium on Computational Intelligence for
Security and Defense Applications, Ieee, 2009, pp. 1–6.
[39] Y. Djenouri, G. Srivastava, J.C.-W. Lin, Fast and accurate convolution neural
network for detecting manufacturing data, IEEE Trans. Ind. Inform. 17 (4) (2020)
2947–2955.
[40] Y. Djenouri, A. Belhadi, J.C.-W. Lin, Recurrent neural network with density-based
clustering for group pattern detection in energy systems, Sustain. Energy Technol.
Assess. 52 (2022) 102308.
[41] Y. Djenouri, M. Comuzzi, Combining apriori heuristic and bio-inspired algorithms
for solving the frequent itemsets mining problem, Inform. Sci. 420 (2017)
1–15.
[42] Y. Djenouri, D. Djenouri, J.C.-W. Lin, A. Belhadi, Frequent itemset mining in big
data with effective single scan algorithms, Ieee Access 6 (2018) 68013–68026.
[43] Y. Djenouri, A. Belhadi, H.-C. Chen, J.C.-W. Lin, Intelligent deep fusion network
for urban traffic flow anomaly identification, Comput. Commun. 189 (2022)
175–181.
198
",https://doi.org/10.1016/j.comcom.2023.03.005,doc27,"Computer Communications 203 (2023) 192–198 Contents lists available at ScienceDirect Computer Communications journal homepage: www.elsevier.com/locate/comcom Interpretable intrusion detection for next generation of Internet of Things Youcef Djenouri a, Asma Belhadi b, Gautam Srivastava c,d,e, Jerry Chun-Wei Lin f,∗, Anis Yazidi g a NORCE, Norwegian Research Center, Oslo, Norway b Kristiania University College, Oslo, Norway c Brandon University, Brandon, Canada d China Medical University, Taichung, Taiwan e Lebanese American University, Beirut, Lebanon f Western Norway University of Applied Sciences, Bergen, Norway g OsloMet, Oslo, Norway A R T I C L E I N F O Keywords: Intrusion detection XAI NG-IoT Deep learning A B S T R A C T This paper presents a new framework for intrusion detection in the next-generation Internet of Things. MinMax normalization strategy is used to collect and preprocess data. The Marine Predator algorithm is then used to select relevant features to be used in the learning process. The selected features are then trained with an advanced and state-of-the-art recurrent neural network that includes an attention mechanism. Finally, Shapely values are calculated to determine how much each feature contributes to the final output. The dataset NSL- KDD was used for intensive simulations. The results show the advantages of the proposed system as well as its superiority over state-of-the-art methods. In fact, the proposed solution achieved a rate of more than 94% for both true negative and true position, while the rates of the existing solutions are below 90% for the challenging NSL-KDD datasets. 1. Introduction With the advent of the next-generation Internet of Things (NG- IoT), new research problems and goals have emerged [1–3]. Artificial intelligence (AI) has the potential to address the highlighted priorities of this new technology, which requires a high degree of autonomy and adaptability. In addition, NG-IoT technology has been actively deployed in intelligent transportation to meet the new market demands while achieving traditional business objectives [4–6]. The NG-IoT paves the way for better understanding of manufacturing processes and en- ables effective and sustainable production [7–9]. IoT devices produce a huge amount of data that requires the use of smart data analytics, not only to process the data, but also to secure the various communi- cations between NG-IoT nodes. Securing NG-IoT and big data systems is a challenging task and has become an active research topic in the last two years [10–12]. NG-IoT devices are often distributed over a large area and have limited storage, processing, and energy resources. These characteristics make the networks and systems that contain such devices particularly vulnerable and attractive targets for cyberattacks by hackers. These systems have a large number of communication channels, storage, devices, and intrusion risks. These characteristics increase the likelihood that intrusions will occur in different patterns at different points in the system, in addition to the limitations mentioned above. The Mirai incident, in which a large number of NG-IoT devices ∗Corresponding author. E-mail address: jerrylin@ieee.org (J.C.-W. Lin). were compromised and used for distributed denial-of-service (DDoS) attacks that crashed numerous servers, including Etsy, Github, Netflix, Shopify, Soundcloud, Spotify, Twitter, and many others, is a typical example of a NG-IoT attack. This highlights the need for efficient and proactive intrusion detection systems that can not only detect and alert intruders, but also provide the user with a better understanding of the detection process. 1.1. Motivation Many strategies have been taken into account when devising IoT in- trusion detection systems [13–16]. While signature-based methods can identify the attack, they are only effective against known threats and cannot detect new patterns. Anomaly-based solutions, usually based on monitoring the traffic flow of individual devices and comparing it to typical patterns, can be used to detect them. The traffic patterns of individual devices are often treated separately to find anomalies. Both solutions are limited and so far are only suitable for use in NG- IoT environments where different types of attacks may be present in real time. Advanced deep learning [17–20] has been widely explored in many areas of IoT. They have achieved great success in many applications. In addition, eXplanaible AI (XAI) [21–23] will be included to achieve a better understanding of the black box deep learning models used during the detection process. Received 9 November 2022; Received in revised form 20 January 2023; Accepted 7 March 2023 Available online 9 March 2023 0140-3664/ ( Y. Djenouri, A. Belhadi, G. Srivastava et al. Computer Communications 203 (2023) 192–198 1.2. Contributions Motivated by the success of advanced deep learning solutions and explainable AI in addressing IoT challenges, we propose a new frame- work called Interpretable Recurrent Neural Network (IRNN) for intru- sion detection in NG-IoT. The main contributions are listed below: 1. We provide normalization and feature selection steps based on the MinMax and marine predator algorithm to select the most relevant features to be used in the learning phase. 2. We present an effective deep learning method for extracting intrusion information from NG-IoT data. The model uses an attention mechanism to compute the relevant features with the recurrent neural network to avoid the vanishing gradient prob- lem. 3. We develop a strategy based on shape values to calculate the contribution of each feature in the detection process. This allows the user to better understand the developed black-box deep learning model. 4. Using various criteria and an extensive intrusion detection dataset, the proposed methodology is evaluated. The results clearly show the superiority of the proposed framework over the standard methods. The rest of the paper is organized as follows. Modern techniques for intrusion detection are discussed in Section 2. The proposed framework and its essential elements are described in Section 3. The design and results of the experiment are summarized in Section 4. Section 5 presents discussions and future directions of this paper. The paper is then concluded in Section 6. 2. Related work To create adversarial hostile traffic records intended to evade de- tection by intrusion detection systems, a generative hostile network framework known as IDSGAN was proposed in [24]. Since attackers do not know the basic structure and parameters of the detection system, adversarial attack examples use black box attacks against the system. IDSGAN uses a generator to convert the initial malicious traffic records into adversarial malicious records. The real-time blackbox detection system is dynamically learned by a discriminator that also categorizes traffic instances. Moreover, for the generation of the malicious data, the constrained modification technique has been developed to preserve the original attack capabilities of the hostile traffic data. To provide justifications for important Deep Learning (DL)-based decisions for IoT- related IDS, Zakaria et al. [25] created a new framework based on XAI. To find IoT-related intrusions, they used a unique IDS for IoT networks, which they had also created using deep neural networks. To the DL- based model, they added three primary XAI techniques, e.g., RuleFit, Local Interpretable Model-Agnostic Explanations (LIME), and SHapley Additive exPlanations (SHAP). To improve the interpretation of DL- based judgments, they provide both local and global explanations. While global explanations focus on identifying the key factors that led to each decision made, local explanations focus on a single/specific DL outcome (e.g., intrusion detection). To identify security risks in IoT contexts, a brand-new deep learning-based intrusion detection system (DL-IDS) was presented [26]. Although several IDSs are described in the literature, they all have deficiencies in learning and dataset management that significantly impact the accuracy of attack detection. To achieve optimal detection, the authors coupled the Spider Monkey Optimization (SMO) algorithm and the Stacked-Deep Polynomial Network (SDPN). SMO selects the best features from the datasets, while SDPN categorizes the data as normal or anomalous. Denial of Service (DoS), User-to-Root (U2R), probing, and Remote-to-Local (R2L) attacks are among the anomalies that DL-IDS can identify. Tanzila et al. [27] presented a CNN-based strategy for anomaly-based intrusion detection systems that leverages the potential of IoT and provides capabilities to effectively probe all traffic in IoT. The proposed model has shown the ability to detect potential intrusions and unusual traffic patterns. Using deep learning- based recurrent models, Ravi et al. [28] provided a complete network attack detection and classification model. The proposed model collects hidden layer features from recurrent models and then selects the best features using kernel-based principal component analysis (KPCA) for feature selection. An ensemble meta-classifier is used to classify the data after combining the best features from recurrent models. Based on cost-sensitive deep learning and ensemble algorithms, CSE-IDS, a three-layer NIDS, was proposed [29]. Layer 1 of the proposed CSE- IDS uses a cost-sensitive Deep Neural Network to distinguish between valid and malicious network traffic. These dubious samples are then forwarded to Layer 2, where they are classified into normal, multiple majority attack classes, and a single class encompassing all minority attack classes using the eXtreme Gradient Boosting algorithm. Finally, layer 3 uses Random Forest to assign appropriate classes to the minority attacks found in layer 2. Zhang et al. [30] presented TIKI-TAKA, a com- prehensive framework for evaluating the resilience of cutting-edge deep learning-based NIDS against hostile tampering. They also incorporated defense mechanisms to strengthen resistance against attacks using eva- sion strategies. In particular, they developed five new types of attacks to subvert three widely used neural network-based malicious traffic detectors. Alladi et al. [31]presented an AI-based intrusion detection architecture consisting of deep-learning models to identify and classify vehicle traffic networks into potential types of cyberattacks. Due to the mobility of vehicles and the real-time requirements of traffic network channels, these deep-learning models are run on edge servers rather than in a remote cloud. Thakkar et al. [32] have developed a fusion- based solution that aims to improve the effectiveness of deep learning systems for intrusion detection by presenting a new algorithm that selects features based on the standard error variance of historical ob- servations. Features are matched based on their rank, which is derived from statistical significance fusion. Moreover, statistical significance fusion aims to produce relevant features with high distinctiveness and variance, which contributes to better learning. However, the strategy used is not powerful for NG-IoT data where the data is collected in different learning spaces. Based on this relatively brief literature review, we conclude that intrusion detection methods are efficient in identifying outliers. How- ever, they are still far from being deployed in NG-IoT environments where there may be different types of attacks in real time. Effective preprocessing and feature extraction are required before the learning process. Moreover, in most of the cases described, there is a lack of explanations, so the network manager has difficulty in understanding the features that contribute positively to learning and the features that contribute negatively to learning. Indeed, an efficient interpretation strategy is also needed. To overcome the problems of existing solutions, and motivated by the success of advanced deep learning and XAI, we introduce in the following section a suitable platform, called IRNN, for network attack detection and understanding. Unlike existing solutions, IRNN enables better extraction of relevant features from network traf- fic data, accurate learning using advanced recurrent neural network architecture, and better understanding of the learning process using XAI. 3. IRNN design In this section, we present a novel framework for intrusion de- tection from the next generation Internet of Things. The proposed framework, which we call IRNN (Interpretable Recurrent Neural Net- work), is shown in Fig. 1. IRNN combines advanced deep learning architectures with an interpretive process to identify intrusions in the next-generation IoT environment. The process begins with pre- processing and extraction of relevant features through normalization and feature selection. The intruders are then detected using the Atten- tion Segmental Recurrent Neural Network (ASRNN) algorithm [33]; the interpretation of the derived intrusions is finally examined using the Shapely value. Each phase is described in detail below: 193 Y. Djenouri, A. Belhadi, G. Srivastava et al. Computer Communications 203 (2023) 192–198 Fig. 1. IRNN Framework: Preprocessing is done first using normalization, and then the pertinent features are extracted using feature selection. The ASRNN technique is then used to detect the intrusions, and the Shapely value is then used to interpret the resulting intrusions. 3.1. Preprocessing Data preprocessing is the process of modifying raw data that is duplicated, erroneous, irrelevant, redundant, incomplete, or incorrectly formulated. Data preprocessing is the process of removing information. The main goal was to remove data from the datasets to standardize data analysis and make it easier to find relevant data for the study. Since some of the data were already missing or unclear, it was important to modify the existing data to improve quality by omitting inaccurate information. The MinMax normalization method [34] is essential for integrating and normalizing data. Where ‘‘one’’ is assigned as the lowest feature value and ‘‘zero’’ as the highest value. The binary equivalents of each value of 0 and 1 are calculated. For each sample x, the 𝑀𝑖𝑛𝑀𝑎𝑥 formula is determined as follows: 𝑀𝑖𝑛𝑀𝑎𝑥(𝑥) = 𝑥−𝑚𝑖𝑛(𝑥) 𝑚𝑎𝑥(𝑥) −𝑚𝑖𝑛(𝑥), (1) in which 𝑚𝑖𝑛(𝑥), and 𝑚𝑎𝑥(𝑥) are the minimum and the maximum values of all samples, respectively. Due to corrupted traffic data, even after complete normalization for unstructured data, the data is still suspect. The collection of these attributes from many complex systems enables the investigation of intrusion detection. 3.2. Feature selection The feature values are automatically added to the feature selection when using the data from the preprocessing phase, which helps to increase accuracy. Feature values that are not needed, redundant, or irrelevant are disregarded and no longer help classify attacks. There- fore, to assess the accuracy of the search domain, feature selection techniques are used to select essential features. The classifier eliminates the irrelevant components and selects the top ten features based on their relevance. Combining optimization strategies with exploration algorithms strengthens the exploration capabilities. We used the Marine Predators Algorithm (MPA) [35] to extract the relevant features for prediction. It is a brand new meta-heuristic algorithm inspired by nature. Similar to other meta-heuristic algorithms, the MPA algorithm is used to solve practical optimization problems. The broad-scale for- aging of marine predators and the encounters or interactions between predators and prey serve as inspiration for MPA. Here, a predator strategically controls encounter rates to increase its chances of survival in the wild. Using L’evy flight and Brownian motion, MPA performs a search using two basic random walk methods. The first type of random walk is commonly used in meta-heuristic algorithms and is probably most successful in preventing solution stagnation by performing an advantageous search in local areas [36]. The latter, on the other hand, is a well-known stochastic tool for global search. To maximize the bal- ance between exploration and exploitation, the MPA inventors merged the search efficiency of the two random walk algorithms. Similar to a number of other population-based metaheuristic algorithms, MPA begins the search process by randomly distributing 𝑁search agents over the search area using Eq. (2): ⃖⃖⃖⃗ 𝑋𝑖= ⃖⃖⃖⃗ 𝑙𝑏𝑖+ 𝑟× (⃖⃖⃖⃖⃗ 𝑢𝑏𝑖−⃖⃖⃖⃗ 𝑙𝑏𝑖); 𝑖∈{1, 2, … , 𝑁} (2) where ⃖⃖⃖⃗ 𝑙𝑏𝑖and ⃖⃖⃖⃖⃗ 𝑢𝑏𝑖are two vectors that indicate the lower and higher bounds for the search to be conducted within, and 𝑟denotes a random variable between [0, 1]. Another 𝑁×𝐷matrix made up of search agents with the best fitness values is formed during initialization along with the primary population matrix, where 𝑁and 𝐷stand for population size and problem dimensions, respectively. MPA refers to it as Elite, which is composed by the set of vectors with top fitness. Prey is a different matrix of the same dimension as Elite, and the predators adjust their places in accordance with it. The initialization creates the initial Prey in a single term from which the strongest individual (predator) creates the Elite. These two matrices play a key role in the optimization process. After initialization, the main iterative search process begins. This process is divided into three phases that simulate various predator–prey scenarios while coming up with various search tactics. These phases are based on iterations 𝑡∈{1, 2, 3 … 𝑡𝑚𝑎𝑥} where 𝑡𝑚𝑎𝑥is maximum iterations. Note that MPA updates candidate solutions dimension-wise during these phases. 3.3. Learning The traffic network is used to detect intrusions with the ASRNN algorithm [33]. LSTM (Long Short Term Memory) performs better than the currently used RNN-based systems. Namely, the LSTM model ensures correlation between different elements in a sequence where a long dependency is checked. This allows to mitigate the vanishing gradient problem of the RNN-based systems. Therefore, the LSTM model is used in the modified ASRNN model proposed in this study. Two different LSTM models are used to learn from the traffic network. While the second model uses the attention mechanism to determine the local features of each element in the context vector, the first model is based on determining the context vector on the flow time. At each timestamp, a Bi-LSTM is used to retrieve the context vector, and a second Bi-LSTM is used in a recursive manner to dynamically generate the segmental representation for each segment using an at- tention mechanism. Dynamic recursion is used in the computation of 194 Y. Djenouri, A. Belhadi, G. Srivastava et al. Computer Communications 203 (2023) 192–198 the segment. Then, each segmental representation is subjected to label categorization using a fully connected layer. The score computed by a fully linked layer is directly used to compute the neural feature scores. Since the sum of the neural feature scores can be greater than one, the softmax operation with the fully connected layer is not required for label classification. The semi-CRF model [37] is then trained together with the computed neural feature values, which are transferred to the model along with the traditional semi-CRF features. For the network structure, the hidden dimension in both the lower and upper Bi-LSTM networks was set to 50, resulting in a character-level representation vector with 100 dimensions. The hidden dimension of the lower Bi- LSTM network and the upper network was set to 100 for the word-level encoder, resulting in a segmental representation with 200 dimensions. The output size of the fully linked layer, which had a hidden size of 256 and a number of labels for each task, was equal to the number of labels. For optimization, we used a mini-batch stochastic gradient descent with 10 batches and a momentum of 0.9. The initial learning rate was set to 0.01 and the decay rate to 0.1. To avoid ‘‘breaking out the gradient’’, the gradient clipping was set to 5. 3.4. Shapely value Shapley values are an idea from cooperative game theory. Shapley values were introduced to fairly allocate a player’s contribution to the final outcome of a game. Suppose we have a cooperative game where a group of players work together to create value. If we can calculate the total payoff of the game, the Shapley values capture each player’s marginal contribution to the final outcome. More formally, suppose we have a game with 𝑛players, with players 1, 2, … , 𝑛and a value function v that accepts a small proportion of players and returns the real value of the game if only those players participated. We also have S as a coalition or subset of players. Formally, then, the contribution 𝛩of the 𝑖th player is defined as: 𝛩(𝑣)𝑖= ∑ 𝑆⊂{𝑁−{𝑖}} |𝑆|!(𝑁−|𝑆| −1)! 𝑁! (𝑣(𝑆𝑐𝑢𝑝{𝑖}) −𝑣(𝑆)) (3) The Shapley score is a metric that can used in explainable machine learning to quantify the contributions of input features (players) to the output of an instance-level machine learning model. The goal is to break down the model prediction into its components and assign Shapley values to each instance feature given a single data point. The only requirement for a cooperative game for the interpretation proposed in this research is that the model can produce a scalar- valued output, such as the probability of assigning a class label to an instance. Since the principle of efficiency applies, determining the Shapley value in such a game leads to a complete deconstruction of the process of intrusion detection. Missing values of input features are replaced by a reference value, e.g., the mean value determined from numerous examples, and the Shapley values of the feature values are explanatory assignments to the input features. We suppose that the Shapley values are approximated over linear time. Our goal is to model the explainability of neurons using a game in which neurons are actors and neural attributions are rewards. These games will be solved and the attributions will be computed with respect to the neurons and filters. The output of the neural network obtained by hiding certain neurons is what is known in practice as ‘‘payoffs’’. Individual neurons can be evaluated using the Shapley values obtained in these games. The proposed strategy is exclusive to deep learning and shares goals and designs with the games mentioned in universal explainability. 4. Performance evaluation Extensive simulations were performed to validate the performance of the proposed IRNN system. The evaluation uses the True Positive Rate (TPR) and True Negative Rate (TNR), which are commonly used to evaluate intrusion detection systems. They are specified as follows: 𝑇𝑃𝑅= 𝑇𝑃 𝑇𝑃+ 𝐹𝑃, (4) and, 𝑇𝑁𝑅= 𝑇𝑁 𝑇𝑁+ 𝐹𝑃, (5) where the TP, FP, and TN variables stand for the number of true positives, false positives, and true negatives, respectively. In this experiment, the performance of the IRNN algorithm with the following baseline solutions: TIKI-TAKA [30], CSE-IDS [29], and DL- IDS [26]. For the training data, we use a batch size of 512 samples by default and reduce the batch size if the model does not fit in memory. We find that we achieve the same speed with batch sizes of 64, 128, 256, or 512. The stack size of the training phase is used to determine the number of training epochs and the learning rate. The final layer of our framework and the baseline models is treated with a dropout rate of 0.7. 4.1. Data description The NSL-KDD dataset [38] represents an improved version of the KDD’99 dataset that DARPA had previously published, adding a wide range of actual attacks on a transportation network. Like the KDD’99 dataset, the NSL-KDD dataset contains 41 network-related features collected from TCP/IP dumps, as well as examples of 23 different attacks in the training set and 17 new attacks in the test set. The NSL-KDD dataset improves upon the KDD’99 dataset in several ways, including deleting duplicate data streams and using a proportional inclusion approach to reduce class imbalances caused by unusual attack types. These improvements are expected to improve consistency and fairness when comparing different NIDS. In this paper, we train and test our approach using the datasets ‘‘KDDTrain+’’ and ‘‘DDTest+’’. Both datasets are annotated where ground truth is available. This facilitates both the training process for building supervised learners and the testing process for evaluating the developed system before deployment. Although the NSL-KDD dataset has certain limitations in capturing examples of more recent attack methods, it is one of the few publicly available datasets that can be used to evaluate the performance of a NIDS when the training and testing distributions differ. 4.2. Inference runtime and accuracy Extensive testing was performed to evaluate the inference time of the IRNN. The experimental data was divided into buckets, each containing a certain amount of network data. The first bucket contains 20% of the test data, the second 50%, the third 80%, and the last 100% (all test data). The models were trained first and then the inference was performed with the test data to calculate the inference time. Fig. 2 shows how the inference times for IRNN and baseline approaches differ. It can be seen that as the percentage of data features and test data increases, the inference time for the four methods also increases. The results also show the superiority of the proposed strategy, with a time difference of more than 500 ms for the data from NSL-KDD. These results are justified by combining a state-of-the-art feature selection technique with a powerful recurrent neural network architecture and an effective attention mechanism. While IRNN explores a novel MPA- based method, the baseline methods use traditional feature selection techniques such as PCA. Extensive experiments have been conducted to evaluate the quality of traffic network performance in intrusion detection. The TPR and TNR values are obtained for each iteration of the experiments. The results are highlighted in the Tables 1, 2. Compared to the baseline approaches, the numerical results show that IRNN can identify the correct interventions. The feature selection used in this study and a deep learning model that analyzes and learns from the numerous correlations between the input data to determine the interventions were both carefully employed to achieve these results. 195 Y. Djenouri, A. Belhadi, G. Srivastava et al. Computer Communications 203 (2023) 192–198 Fig. 2. Inference time in milliseconds of IRNN vs. state-of-the art NG-IoT intrusion detection algorithms. Table 1 TNR of IRNN vs. state-of-the art NG-IoT intrusion detection algorithms. Number of Epochs IRNN TIKI-TAKA CSE-IDS DL-IDS 100 25 20 8 7 200 41 27 15 13 500 78 63 38 34 800 95 89 61 54 Table 2 TPR of IRNN vs. state-of-the art NG-IoT intrusion detection algorithms. Number of Epochs IRNN TIKI-TAKA CSE-IDS DL-IDS 100 38 18 4 3 200 66 41 29 26 500 87 53 41 38 800 94 75 58 56 4.3. Interpretation To understand the behavior of the IRNN model, an experiment was conducted to visualize the output of the Shapely value. Fig. 3 shows the SHAP value for the eight most important variables in the learning process. It is worth noting that when the SHAP value is less than 0, the variable has a negative impact on learning, while when the SHAP value is greater than 0, the variable has a positive impact on learning. From Fig. 3, we can conclude that there are many variables that contribute positively to learning, but that more robust feature selection methods are needed to weed out the variables that contribute negatively to learning. This will improve intrusion detection performance. Even though MPA performs very well in selecting the most relevant features, more efforts need to be made. For example, combining traditional methods such as PCA with MPA could be a good direction for future work. 196 Y. Djenouri, A. Belhadi, G. Srivastava et al. Computer Communications 203 (2023) 192–198 Fig. 3. Contribution of the most relevant features for the IRNN model output. 5. Discussions and future directions The first challenge is to build a comprehensive dictionary of at- tack signatures in complex NG-IoT systems. This makes detecting a zero-day attack difficult. Since IRNN lacks attack data, modern data augmentation techniques such as generative adversarial network and variable auto-encoder can be useful to generate relevant training data with different attack types. Although not all attacks generated by data augmentation models are actual attacks, the comprehensive attack dic- tionary created appears to be an effective strategy for defending against zero-day attacks. Heterogeneous data in IoT, especially in NG-IoT, is considered more vulnerable to a variety of threats than their wired counterparts. This is because of the complex network topology and high connectivity between traffic variables. Adversaries face a large attack surface that includes multiple entry points. Moreover, the attackers can change their behavior, rendering the initial learning of the IRNN ineffective. The second challenge is to develop an IRNN model that is capable of detecting new attacks in a traffic network using a lifetime learning mechanism. Federated learning (FL) has recently attracted the interest of academia and industry as an alternative to the traditional centralized ML approaches. FL has a significant privacy advantage, as training nodes can build a global model without transmitting their data. The learning process occurs over a set number of training rounds, in which each node continuously monitors the parameters of a modeling framework by training with its local data. In each training round, these parameters are then accumulated by a central entity to compute an updated copy of the global model, which is in turn communicated to the nodes. The third challenge of this work is to take advantage of FL in the context of IRNN to create distributed models that are shared among different entities in the network without these entities having access to their own data. 6. Conclusion This study presents a revolutionary paradigm for the next genera- tion Internet of Things dedicated to intrusion detection. The MinMax normalization approach is used to collect and preprocess the dataset. The Marine Predator algorithm is then used to select features. The selected feature is then trained with an advanced recurrent neural network that includes an attention mechanism. The introduction of the Shapely value is the final step to determine how each feature affects the final output. The dataset NSL-KDD was subjected to extensive simula- tion. The results illustrate the benefits of the framework provided and how it outperforms state-of-the-art techniques. In the future, we plan to explore other Deep Learning architectures for intrusion detection, such as those based on convolutional neural networks [39]. We also plan to consider group detection [40] as a future strategy in next-generation IoT. Exploring genetic algorithm, pattern mining, and decomposition in learning [41–43] is also on our agenda. CRediT authorship contribution statement Youcef Djenouri: Conceptualization, Writing – original draft. Asma Belhadi: Methodology. Gautam Srivastava: Writing – review & edit- ing. Jerry Chun-Wei Lin: Formal analysis, Writing – review & editing. Anis Yazidi: Validation. Declaration of competing interest The authors declare that they have no known competing finan- cial interests or personal relationships that could have appeared to influence the work reported in this paper. Data availability Data will be made available on request. Acknowledgment This work is supported by the project ULEARN ‘‘Unsupervised Life- long Learning’’ and co-funded under the grant number 316080 of the Research Council of Norway. References [1] M. Maiti, U. Ghosh, Next generation Internet of Things in fintech ecosystem, IEEE Internet Things J. (2021). [2] A. Asheralieva, D. Niyato, Optimizing age of information and security of the next-generation internet of everything systems, IEEE Internet Things J. (2022). [3] A. Rejeb, K. Rejeb, S. Simske, H. Treiblmaier, S. Zailani, The big picture on the Internet of Things and the smart city: A review of what we know and what we need to know, Internet of Things 19 (2022) 100565. [4] A.B. Adam, M.S.A. Muthanna, A. Muthanna, T.N. Nguyen, A.A. Abd El-Latif, To- ward smart traffic management with 3D placement optimization in UAV-assisted NOMA IIoT networks, IEEE Trans. Intell. Transp. Syst. (2022). [5] N. Zhang, T. Han, M. Dianati, N. Lu, S. Wang, Guest editorial special issue on space-air-ground integrated networks for intelligent transportation systems, IEEE Trans. Intell. Transp. Syst. 23 (3) (2022) 2701–2704. [6] Y. Yao, H. Zhang, L. Lin, G. Lin, R. Shibasaki, X. Song, K. Yu, Internet of Things positioning technology based intelligent delivery system, IEEE Trans. Intell. Transp. Syst. (2022). [7] V. Delpla, J.-P. Kenné, L.A. Hof, Circular manufacturing 4.0: Towards Internet of Things embedded closed-loop supply chains, Int. J. Adv. Manuf. Technol. 118 (9) (2022) 3241–3264. 197 Y. Djenouri, A. Belhadi, G. Srivastava et al. Computer Communications 203 (2023) 192–198 [8] C. Liu, Z. Su, X. Xu, Y. Lu, Service-oriented industrial Internet of Things gateway for cloud manufacturing, Robot. Comput.-Integr. Manuf. 73 (2022) 102217. [9] J. Sousa, J.P. Mendonça, J. Machado, A generic interface and a framework designed for industrial metrology integration for the Internet of Things, Comput. Ind. 138 (2022) 103632. [10] A. El Kamel, H. Eltaief, H. Youssef, On-the-fly (D) DoS attack mitigation in SDN using deep neural network-based rate limiting, Comput. Commun. 182 (2022) 153–169. [11] W. Xue, Y. Shen, C. Luo, W. Xu, W. Hu, A. Seneviratne, A differential privacy- based classification system for edge computing in IoT, Comput. Commun. 182 (2022) 117–128. [12] M. Rana, A. Shafiq, I. Altaf, M. Alazab, K. Mahmood, S.A. Chaudhry, Y.B. Zikria, A secure and lightweight authentication scheme for next generation IoT infrastructure, Comput. Commun. 165 (2021) 85–96. [13] Y. Djenouri, A. Belhadi, G. Srivastava, U. Ghosh, P. Chatterjee, J.C.-W. Lin, Fast and accurate deep learning framework for secure fault diagnosis in the industrial Internet of Things, IEEE Internet Things J. (2021). [14] F. Hussain, R. Hussain, S.A. Hassan, E. Hossain, Machine learning in IoT security: Current solutions and future challenges, IEEE Commun. Surv. Tutor. 22 (3) (2020) 1686–1721. [15] J.C.-W. Lin, G. Srivastava, Y. Zhang, Y. Djenouri, M. Aloqaily, Privacy-preserving multiobjective sanitization model in 6G IoT environments, IEEE Internet Things J. 8 (7) (2020) 5340–5349. [16] P. Sharma, S. Jain, S. Gupta, V. Chamola, Role of machine learning and deep learning in securing 5G-driven industrial IoT applications, Ad Hoc Netw. 123 (2021) 102685. [17] S. Singh, R. Sulthana, T. Shewale, V. Chamola, A. Benslimane, B. Sikdar, Machine-learning-assisted security and privacy provisioning for edge computing: A survey, IEEE Internet Things J. 9 (1) (2021) 236–260. [18] S. Hui, H. Wang, Z. Wang, X. Yang, Z. Liu, D. Jin, Y. Li, Knowledge enhanced GAN for IoT traffic generation, in: Proceedings of the ACM Web Conference 2022, 2022, pp. 3336–3346. [19] R. She, P. Fan, From MIM-based GAN to anomaly detection: Event probability influence on generative adversarial networks, IEEE Internet Things J. (2022). [20] X. Cao, G. Sun, H. Yu, M. Guizani, PerFED-GAN: Personalized federated learning via generative adversarial networks, IEEE Internet Things J. (2022). [21] S.K. Jagatheesaperumal, Q.-V. Pham, R. Ruby, Z. Yang, C. Xu, Z. Zhang, Explainable AI over the Internet of Things (IoT): Overview, state-of-the-art and future directions, IEEE Open J. Commun. Soc. (2022). [22] H. Elayan, M. Aloqaily, F. Karray, M. Guizani, Internet of behavior (IoB) and explainable ai systems for influencing iot behavior, IEEE Netw. (2022). [23] L.M. Alkwai, An explainable artificial-intelligence-based CNN model for knowl- edge extraction from the social Internet of Things: Proposing a new model, IEEE Syst. Man Cybern. Mag. 8 (4) (2022) 48–51. [24] Z. Lin, Y. Shi, Z. Xue, Idsgan: Generative adversarial networks for attack generation against intrusion detection, in: Pacific-Asia Conference on Knowledge Discovery and Data Mining, Springer, 2022, pp. 79–91. [25] Z. Abou El Houda, B. Brik, L. Khoukhi, ‘‘Why should I trust your IDS?’’: An explainable deep learning framework for intrusion detection systems in Internet of Things networks, IEEE Open J. Commun. Soc. 3 (2022) 1164–1176. [26] Y. Otoum, D. Liu, A. Nayak, DL-IDS: A deep learning–based intrusion detection framework for securing IoT, Trans. Emerg. Telecommun. Technol. 33 (3) (2022) e3803. [27] T. Saba, A. Rehman, T. Sadad, H. Kolivand, S.A. Bahaj, Anomaly-based intrusion detection system for IoT networks through deep learning model, Comput. Electr. Eng. 99 (2022) 107810. [28] V. Ravi, R. Chaganti, M. Alazab, Recurrent deep learning-based feature fusion ensemble meta-classifier approach for intelligent network intrusion detection system, Comput. Electr. Eng. 102 (2022) 108156. [29] N. Gupta, V. Jindal, P. Bedi, CSE-IDS: Using cost-sensitive deep learning and ensemble algorithms to handle class imbalance in network-based intrusion detection systems, Comput. Secur. 112 (2022) 102499. [30] C. Zhang, X. Costa-Pérez, P. Patras, Adversarial attacks against deep learning- based network intrusion detection systems and defense mechanisms, IEEE/ACM Trans. Netw. (2022). [31] T. Alladi, V. Kohli, V. Chamola, F.R. Yu, M. Guizani, Artificial intelligence (AI)- empowered intrusion detection architecture for the Internet of Vehicles, IEEE Wirel. Commun. 28 (3) (2021) 144–149. [32] A. Thakkar, R. Lohiya, Fusion of statistical importance for feature selection in deep neural network-based intrusion detection system, Inf. Fusion 90 (2023) 353–363. [33] J.C.-W. Lin, Y. Shao, Y. Djenouri, U. Yun, ASRNN: A recurrent neural network with an attention model for sequence labeling, Knowl.-Based Syst. 212 (2021) 106548. [34] S. Patro, K.K. Sahu, Normalization: A preprocessing stage, 2015, arXiv preprint arXiv:1503.06462. [35] A. Faramarzi, M. Heidarinejad, S. Mirjalili, A.H. Gandomi, Marine preda- tors algorithm: A nature-inspired metaheuristic, Expert Syst. Appl. (2020) 113377. [36] T. Dokeroglu, E. Sevinc, T. Kucukyilmaz, A. Cosar, A survey on new generation metaheuristic algorithms, Comput. Ind. Eng. 137 (2019) 106040. [37] N. Qun, H. Yan, X.-P. Qiu, X.-J. Huang, Chinese word segmentation via BiLSTM+ semi-CRF with relay node, J. Comput. Sci. Tech. 35 (5) (2020) 1115–1126. [38] M. Tavallaee, E. Bagheri, W. Lu, A.A. Ghorbani, A detailed analysis of the KDD CUP 99 data set, in: 2009 IEEE Symposium on Computational Intelligence for Security and Defense Applications, Ieee, 2009, pp. 1–6. [39] Y. Djenouri, G. Srivastava, J.C.-W. Lin, Fast and accurate convolution neural network for detecting manufacturing data, IEEE Trans. Ind. Inform. 17 (4) (2020) 2947–2955. [40] Y. Djenouri, A. Belhadi, J.C.-W. Lin, Recurrent neural network with density-based clustering for group pattern detection in energy systems, Sustain. Energy Technol. Assess. 52 (2022) 102308. [41] Y. Djenouri, M. Comuzzi, Combining apriori heuristic and bio-inspired algorithms for solving the frequent itemsets mining problem, Inform. Sci. 420 (2017) 1–15. [42] Y. Djenouri, D. Djenouri, J.C.-W. Lin, A. Belhadi, Frequent itemset mining in big data with effective single scan algorithms, Ieee Access 6 (2018) 68013–68026. [43] Y. Djenouri, A. Belhadi, H.-C. Chen, J.C.-W. Lin, Intelligent deep fusion network for urban traffic flow anomaly identification, Comput. Commun. 189 (2022) 175–181. 198"

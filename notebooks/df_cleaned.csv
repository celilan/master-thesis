title,authors,year_published,number,volume,journal,type,content,doi,file,abstract,cleaned_content,cleaned_abstract,cleaned_authors
Advanced Passive Operating System Fingerprinting Using Machine Learning and Deep Learning,"Hagos, Desta Haileselassie and Løland, Martin and Yazidi, Anis and Kure, Øivind and Engelstad, Paal E.",2020,missing,missing,missing,inproceedings,"Advanced Passive Operating System Fingerprinting
Using Machine Learning and Deep Learning
Desta Haileselassie Hagos∗, Martin Løland†, Anis Yazidi‡, Øivind Kure §, Paal E. Engelstad ¶
∗§¶University of Oslo, Department of Technology Systems, Kjeller, Norway
∗†‡¶Oslo Metropolitan University, Department of Computer Science, Oslo, Norway
Email: ∗destahh@iﬁ.uio.no, †martin.loeland@gmail.com, {‡anis.yazidi, ¶paal.engelstad}@oslomet.no, §oivind.kure@its.uio.no
Abstract
Keywords—Operating
System,
Fingerprinting,
Machine
Learning, Deep Learning, Passive Measurements
I.
INTRODUCTION AND MOTIVATION
As modern network infrastructures grow in size, collecting
detailed relevant knowledge about the dynamic characteristics
and complexity of large heterogeneous networks is crucial
for many purposes e.g., network vulnerability assessment
and monitoring, spam detection, etc. Developing advanced
network security and monitoring techniques are important
for both the research and security practitioners. There has
been a signiﬁcant research work in the context of network
management and cybersecurity on developing network security
tools to ﬁngerprint remote Operating Systems (OSes) [26,
27, 28, 41, 42]. OS ﬁngerprinting is the process of inferring
the OS of a machine operating with TC/IP by a remote
device connected on the Internet without having physical
access to the device [20]. There are many different custom
tools for ﬁngerprinting of the most commonly used OSes
based on the characteristics of its underlying TCP/IP network
stack [20] and this, to a large extent, is due to variability
in how the TCP/IP stack is traditionally implemented across
different OSes [25]. One common approach, for example, is
by collecting the TCP/IP stack basic parameters [23], e.g., IP
initial Time To Live (TTL) default values [5], HTTP packets
using the User-agent ﬁeld [22], Internet Control Message
Protocol (ICMP) requests [29], known open port patterns, TCP
window size [18], TCP Maximum Segment Size (MSS) [31],
IP Don’t Fragment (DF) ﬂag [30], a set of other speciﬁc TCP
options to mention a few. However, in our work, we want to
take this one step further by combining these basic features and
other settings with the underlying TCP variant as a feature in
our model due to the fact that different OSes are doing slightly
different implementations of TCP. Some implementations of
common TCP variants quickly overshoot the size of the
Congestion Window (cwnd) because of differences in the
variant implementations. Hence, we believe that knowing the
implementation of the underlying OS may help us understand
better their exact behavior. It can also help us explore how
to classify an OS when different OSes are implementing the
same TCP variant.
Fingerprinting Techniques: We can determine what OS a
remote computer on the Internet is running by either passively
listening to trafﬁc captured from a network or by actively
sending it packets. The most widely used complementary
remote OS ﬁngerprinting proven approaches that employ a
variety of TCP/IP stack scanning are broadly categorized into
classes of active and passive methods.
• Active Fingerprinting: This technique is based on actively
transmitting one or more specially crafted network
packets with different packet settings or ﬂags to a remote
network device in order to analyze the corresponding
potentially identifying replies [26, 41]. This method
determines knowledge of the underlying OS according
to the received responses from the target device by
examining the network behavior of known TCP/IP
stack [35]. However, since this approach injects additional
trafﬁc to the network by generating active probes, it may
itself trigger alarms and get blocked by ﬁrewall rules and
Network address translators (NATs) [8].
• Passive Fingerprinting: This approach, on the other hand,
inspects and analyzes packets traveling between end hosts
without injecting any trafﬁc into the network [27, 28, 42].
This technique with little resource simply analyzes a
pattern of the OS-speciﬁc information that has already
been sent in the network trafﬁc and compares for a
match with a predeﬁned database that contains a list of
known signatures of different OSes. Passive ﬁngerprinting
doesn’t send probes and hence it has a clear advantage
over active ﬁngerprinting since it reduces the risk of
triggering alarms [8].
978-1-7281-6607-0/20/$31.00 ©2020 IEEE
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 OS ﬁngerprinting can also be performed using classical
techniques known as “banner grabbing”. It is an approach used
to gain detailed information about a remote computer system
on a network and the associated services running on its opened
ports [33]. Using techniques like this, some remote computers
announce their underlying OS freely and running application
services with their versions in use to anyone connecting to
them as part of welcome banners or header information.
Some of the widely used services that serve banner grabbing
are: Telnet, FTP, NetCat, SMTP, etc. However, it is useful
to remember that some of these basic services are effective
against less secure networks.
Potential beneﬁts and applications: Network scanning and
accurate remote OS ﬁngerprinting are the crucial steps for
penetration testing in terms of security and privacy protection.
Note that attackers can also embrace passive ﬁngerprinting
techniques to search for potential victims in a network. For
example, by identifying the OS running on a remote computer
and the list of services it runs, an attacker can target the device
to eavesdrop on the communication between the endpoints
without having physical access to the device. However, we
argue that our work presented here is motivated by a number
of practical applications that can be positively used by network
and system administrators. Passively ﬁngerprinting an OS by
analyzing the packets it generates and transmits over a network
is extremely important in the areas of network management
and computer security for several reasons. For example, it
is useful to explore a network for potential exploitations of
security vulnerabilities which can be exploited by attackers,
auditing, identify critical attacks, reveal new information about
a network user etc. Network administrators can, therefore, use
this OS related information to maintain the security policy and
reliability of their network by conﬁguring a network-based
Intrusion Detection Systems (IDS) [24]. Vulnerabilities and
security threats in a network may result from rogue or
unauthorized devices [38], unsecured internal nodes within
the network, and from external nodes [4]. Hence, passively
ﬁngerprinting an OS has a potential beneﬁt in addressing these
critical problems. This, from an academic point of view, is
Client Oses of sending nodes
Fingerprinter
Receiving nodes 
on the Internet
35.195.9.67
Intermediate node (monitor)
Fig. 1: Network architecture for passive OS ﬁngerprinting by
an intermediate node.
Limitations
of
previous
works: Traditionally, most of
the existing general OS ﬁngerprinting techniques resort to
manually generated signature matching from a database of
heuristics which contains features of widely used OSes. This
means, after comparing the generated signatures, the ﬁrst set
of responses match with the highest conﬁdence against a
database of ﬁngerprints would be used to select the speciﬁc
probable OS. However, manually updating a large number
of signature and managing databases of new OSes adds a
considerable amount of time and hence we may suffer from
the consequences of the lack of recent signature updates of the
known OSes. For example as reported in [22], the last updates
of the ﬁngerprint databases of Ettercap [28] and p0f [42]
date to 2011 and 2014 respectively. Consequently, new OSes
families like Android 4.4 and higher versions of Android,
Windows 10 distributions, etc. will not be recognized by these
tools since they are not included in their ﬁngerprint databases.
Hence, we argue that it is important to consider making use of
a ﬁngerprint database that contains variations of most currently
used OSes and automating these tasks by employing learning
algorithms capable of extracting all possible OS-speciﬁc
features for discovering the underlying OSes. To explore this
idea of applying learning algorithms, we present a uniﬁed
and robust classiﬁcation approach to an advanced passive OS
ﬁngerprinting that leverages both machine learning and deep
learning methods. Our ﬁngerprinting technique is completely
passive meaning that we only need to be able to observe
network trafﬁc from a target machine at any observation point
on the network without injecting any trafﬁc into the network.
Note that the TCP/IP header ﬁelds would not be impacted
by SSL/TLS encryption of the TCP payload. Hence, since
we utilize features that are readable even with encryption,
our approach is independent of whether the ﬂow is encrypted
or not. Figure 1 shows the architecture for implementing our
ﬁngerprinting methodology.
Why machine learning approaches to OS ﬁngerprinting?
There
are
several
limitations
imposed
by
classical
ﬁngerprinting techniques. Passive OS ﬁngerprinting generally
relies on recognizing the default values for various TCP/IP
stack parameters. If a user changes these parameters, the task
of OS ﬁngerprinting becomes much more challenging. Most of
the existing works on ﬁngerprinting provide a little capability
to address this challenge. Motivated by this problem, we
proposed a novel approach by leveraging both machine
learning and deep learning-based techniques that consider the
set of parameters as a whole, rather than individually so that
our model caters for variations in TCP parameters. If a user
changes the initial receive window size, for instance, we may
still be able to recognize the OS from other parameters that
have not been changed (TCP congestion control algorithm,
initial cwnd size, etc.). Note that this depends entirely on
the changes made by the user to the default TCP or OS
stack parameters that are commonly used for signature-based
ﬁngerprinting. The other reason why we create a model by
employing learning techniques is to understand the complex
patterns of the varying values in the TCP header and extract
useful input features. Because machine learning offers new
possibilities as it can extract patterns and general rules for
classiﬁcation. Machine learning can also be more robust to
small variations in the input parameters. In addition to this,
with the use of learning techniques, we argue that avoiding
using manually updated static signature databases has two
potential beneﬁts. Firstly there is no tedious task of creating
these unique ﬁngerprints, all you need is a set of values or
features. The second beneﬁt comes from a known ﬂaw in
many of the existing ﬁngerprinting tools, where a “ﬁrst-match”
policy is applied, meaning that if two ﬁngerprints are equal
the tool would always predict the ﬁrst OS with that exact
ﬁngerprint. However, learning techniques, on the other hand,
make calculated guesses of which of the classes with the
same ﬁngerprint that will be predicted.
interesting and something that needs to be addressed from a
network security research point of view.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 Contributions: We summarize our main contributions below.
• We propose and evaluate a robust approach to OS
ﬁngerprinting from passive measurements by leveraging
machine learning and deep learning techniques.
• We investigate the use of TCP congestion control variant
as a distinguishing feature in passive OS ﬁngerprinting.
• We explore variability in implementations of TCP variant
by different OSes and its effect on classifying remote OS.
• We study the applicability of Recurrent Neural Networks
(RNN)-based models for robust and advanced passive OS
ﬁngerprinting by combining the basic TCP/IP features and
the predicted TCP variant as input vectors.
• We show that the TCP ﬂavor has a great potential for
boosting passive OS ﬁngerprinting.
• We build a universal tool for passive monitoring that can
be applied to ﬁrst estimate the TCP cwnd, second predict
the TCP ﬂavor, and ﬁnally uses the TCP variant as an
input feature to detect the remote computer’s OS.
Roadmap: The rest of the paper is organized as follows.
Section II discusses related work, and Section III presents
the experimental datasets. Section IV presents the machine
learning of the OS ﬁngerprinter. The machine learning of
the TCP variant prediction tool is presented in detail in
Section V. Section VI presents the experimental results without
a known TCP variant which will play the role of baseline. In
order to assess the importance of knowing the TCP variant,
experimental results of all the use cases with an Oracle-given
TCP variant are presented in Section VII. Section VIII presents
the experimental results with the predicted TCP variant.
Section IX presents the transfer learning results. Finally,
Section X concludes our paper and suggests directions for
future research work.
II.
RELATED WORK
Remote OSes ﬁngerprinting has a long history in the
computer security community [2, 22, 23, 26]. TCP/IP header
ﬁngerprinting and any information related to application
protocols are used to identify the underlying OS running
on a remote host either actively or passively [25]. As we
explained in Section I, there are multiple existing tools for
both the predominant active and passive OS ﬁngerprinting
approaches, where Nmap [26] is one of the most prominent
open-source active ﬁngerprinting tools. The work presented
in [36], SYNSCAN, works in a similar fashion to Nmap,
but it performs the ﬁngerprinting task by actively sending a
small number of crafted network packets to a single TCP
port. Xprobe2 [41] is another popular ﬁngerprinting tool,
that relies primarily on ICMP packets, and it depends on
how many changes we make to the default TCP/IP stack
parameters.
Since Xprobe2 does fuzzy ﬁngerprinting with
a signature matching algorithm as an alternative to Nmap,
it means that if we make a lot of changes to the default
TCP/IP stack parameters, the underlying OS will not be
detected. However, Xprobe2 is more robust to small ﬁngerprint
variations as compared to Nmap. As explained above the
other ﬁngerprinting tools, Ettercap [28] and p0f [42], have
not been updated since 2011 and 2014 respectively to include
variations of most widely used modern OSes. For passive OS
ﬁngerprinting to be effective, we believe that the limitations
of these ﬁngerprinting tools need to be addressed. The work
in [23] also demonstrates that the OS ﬁngerprinting accuracy of
the Ettercap and p0f signature databases is low and techniques
to improve performance was proposed. Hence, the paper
presents rule-based machine learning classiﬁers capable of
identifying 75 classes of OSes from TCP/IP packet headers
found in the Ettercap database. They proposed a classiﬁer
technique using k-nearest neighbors (KNN) that returns an
approximate ﬁrst match for an OS from a ﬁngerprint database.
This counters the problem of classifying hosts as unknown if
no exact match is found in the database [23]. However, their
evaluation yielded poor experimental results, rejecting as much
as 84% of the test packets, while 44% of the accepted patterns
were wrongly classiﬁed [23]. The problems contributing to
poor performance was believed to be caused by two main
issues. The ﬁrst reason is substitution errors due to multiple
OSes with exactly the same ﬁngerprint feature values. The
second reason for this poor performance is the high rejection
rate caused by numerous unique feature values derived from
the same OS. After combining the OS classes most often
confused with each other, eliminating all the classes where
the error could not be reduced by combining classes, the error
percentage was reduced to 9.8% with no rejected packets.
A recent study that is most closely related to our work,
and which has also given a comprehensive survey on passive
ﬁngerprinting methods, can be found in [22]. The authors
have employed OS ﬁngerprinting methods in the environment
of wireless networks.
Besides using the three basic TCP/IP
stacks (i.e., TTL, window size, and initial SYN packet size),
the authors suggested also using the user-agent information in
HTTP request headers and communication with OS-speciﬁc
domains can be usable in large dynamic networks [22].
The average accuracy of OS classiﬁcation using the TCP/IP
parameters reported in [22] is 80.88%. Zhang et al.’s paper on
OS detection [43] utilizes only one machine learning technique
namely Support Vector Machine (SVM). However, the testing
error rate of identifying some of the OSes e.g., Mac, Cisco,
FreeBSD, and OpenBSD is 25.80%, 24.22%, 17.71%, and
15.85% respectively [43]. Aksoy et al. [2] have employed
genetic algorithms for identifying packet features suitable
for OS classiﬁcation based on the analysis of the network
TCP/IP packets using machine learning algorithms. However,
most of these previous works use the basic actual TCP/IP
features for evaluating passive OS ﬁngerprinting. Besides,
we believe that these tools have the inability to extract all
possible OS-speciﬁc features for passively ﬁngerprinting the
underlying OSes. In contrast, what separates our contribution
in this paper from the other previous related works is that
our model supports a wider range of TCP/IP network stack
features. As shown in Figure 2, the main goal of our work
presented here is to combine these basic TCP/IP features that
are the basis of OS ﬁngerprinting with the underlying TCP
variant by leveraging both machine learning and deep learning
techniques. This contribution remains largely unexplored and
is not used by existing ﬁngerprinting techniques. Detecting the
implementation of a TCP variant passively is a challenging task
and this, we believe, is the reason why no previous works use
it to passively ﬁngerprint remote OSes. However, in our case,
we already have a general solution for this difﬁculty presented
in our previous works [11, 12, 13]. The reason why we focus
on the implementations of the underlying TCP variant as a
feature in our OS classiﬁer model is due to the fact that
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 different OSes are doing slightly different implementations
of TCP. Hence, we believe that passively observing the
network-level characteristics found in TCP packets can give us
more information about the remote computer’s underlying OS.
We further believe that this will also help us to explore in detail
the long-term characteristics of TCP trafﬁc. To the best of
our knowledge, this is the ﬁrst study of passive ﬁngerprinting
OSes by applying RNN methods combining the basic TCP/IP
features and the underlying TCP variant as input vectors.
III.
EXPERIMENTAL DATASETS
Our machine learning models for OS classiﬁcation is
developed and tested on three datasets, presented below.
A. Benchmark Data
First, we utilize a large benchmark dataset that has been
used for OS ﬁngerprinting in a previous related work [22]. This
dataset is closely aligned with our task. The benchmark dataset
was used in the previous work for OS ﬁngerprinting based on
the HTTP header, while the ambition of our paper is to do
generic ﬁngerprinting based only on the TCP packet ﬁelds.
Since we aim at ﬁngerprinting that is not application-speciﬁc,
the TCP information in the dataset is useful for our purpose,
while the HTTP User-agent information in our experiments
is used only to establish ground truth about the OS that
was used. The benchmark dataset contains 79087345 ﬂows,
activity of 21746 unique users, 253374 WiFi sessions, 25642
unique MAC addresses, and 6104 unique IP addresses, a
ﬁngerprint database of 2078 standard TCP/IP signatures of
51 known unique OSes with a total of 529 variations when
considering major and minor versions [22]. It consists of three
basic TCP/IP network stack features, i.e., initial SYN packet
size, TTL, and TCP window size [22]. After our ﬁrst set of
testing, we realized that the data was severely skewed and
that only a few of the classes contained almost all of the
entries, giving us artiﬁcially good classiﬁcation results. We
then removed most of the very seldom occurring classes and
ended up with 33 reduced classes. We also removed all trafﬁc
that did not contain HTTP User-agent information, since we
could not establish ground truth for this trafﬁc. In addition, we
created a new dataset where all the classes were bucketed into
seven groups, consisting of the six most widely used major OS
families: Android, Linux, Mac OS, Unix, Windows, iOS, and
a seventh class called “Other” for OSes not suited for any of
the other groups. Finally, we ended up distributing all of the
labels equally so that each OS class had the same number of
occurrences. This helps us improve the generalizability of our
model with a uniﬁed approach that encompasses all variations
of the most widely used OSes.
B. Realistic Trafﬁc
While benchmark trafﬁc is useful to link our experiments
to previous related work, we also wanted additional realistic
trafﬁc for which we have more control, and that allows us
to make our own assurances of the quality of the data. Thus,
we passively collected our realistic dataset from TCP trafﬁc
originated from the internal network of the Oslo Metropolitan
University and destined to various hosts on the Internet. First,
we collected data for ﬁxed (non-mobile) desktop computers
(typically using OSes like Windows, Linux, Unix, Mac OSx,
etc.) by using an intermediate node as shown in the network
setup in Figure 1. Then, we passively collected the data that
covered mobile devices, like android and iOS. The latter was
collected from the 5G 4IoT research lab [1, 34] of the Oslo
Metropolitan University.
We spent a signiﬁcant amount of effort in establishing
ground truth, i.e., determining the actual OS that has been
used for each trafﬁc ﬂow. To establish ground truth in the
realistic dataset, we follow two approaches. The ﬁrst approach
was only applicable to the non-mobile desktops, while the
second method was used for both mobile and non-mobile
devices. With the ﬁrst method, we leveraged the DHCP log
messages associated with the non-mobile desktops to derive the
ground truth from the DHCP server of the Oslo Metropolitan
University network that logs the sessions by the MAC address
and name of the device. Since we collect the real data from
the internal network of our university, extracting the DHCP log
messages can give us detailed information about the OSes. We
could, for example, see information about the vendor-speciﬁc
preﬁxes since most of the OS variants are identiﬁed based on
their vendors. The list of device vendor preﬁxes is useful in
revealing the speciﬁc implementation of an OS because most
of the modern OSes from the same device vendor usually
share the same OS kernel and similar network behaviors. For
example, we found out that Apple products often share the
same TCP/IP parameters. The second approach we used to
identify the OS is getting the predeﬁned browser strings that
loosely tell the name of the underlying OS assigned by the
vendor from Webserver.
We believe changing the default device names by all users
is not that common and sometimes discouraged by the vendors,
e.g., Google and Apple OSes. However, the device name
of Linux and Windows OSes could be changed easily by
experienced users which would make passively identifying
these devices hard. Since a number of computer vendors offer
devices with a pre-installed OS and default device name and
MAC address, we can use this information to derive the ground
truth for OS ﬁngerprinting. For example, Apple devices use
a default string name of
“<user>-iPhone”, “<user>-iPad”,
Microsoft uses “Windows-Phone” for its mobile devices, and
Android uses “android-<android−id>”, etc. Our real trafﬁc
covers the communication to and from our university and
hence all trafﬁc whose source and destination IP addresses are
within the subnets of our internal network. Hence the network
administrator of our university has full control over the internal
machines with real IP addresses that are not going to a NAT
gateway, and therefore it is fairly possible to tell whether it is a
laptop or a desktop PC by looking it up in the internal database
owned by the university. However, since it is a dynamic
network we do not have full control over external machines,
because they can be anything behind an IP address that changes
dynamically. This is because there is an endless number of
machines spooﬁng scanning the network and they can appear
as Linux-powered OSes but they could be Windows and vice
versa and this happens because the user may have strongly
tuned the TCP stack to look like something else. It is pretty
hard to certainly say anything about the external computers
because the communication can go through a NAT gateway
possessing another OS type. For example, if a user is connected
to a student wireless network, there is a chance that it may go
to a Linux NAT gateway, and hence from outside the user is
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 seen as Linux NAT which makes it hard to predict whether
the underlying OS is Linux, Mac or Windows. Therefore,
ﬁngerprinting devices behind NAT technology on a distributed
network where a number of devices can hide behind a NAT
is another critical challenge. It is, therefore, worth noting that
establishing ground truth in dynamic networks at a larger scale
remains a challenging problem. Further investigation to explore
these difﬁculties will be done in our future works. Finally,
due to the privacy protection of possibly sensitive data, the
payload of all the network packets collected was removed
and anonymized with a preﬁx-preserving algorithm [7, 39].
Furthermore, we were only allowed to collect TCP headers of
the trafﬁc ﬂows, while we could not collect complete trafﬁc
captures, due to privacy protection and legal reasons.
OS Prediction
Fingerprinter using
Machine Learning/
Deep Learning 
Input features
Packet Size
Window Size
TTL
TCP Variant
Oracle
Predicted TCP Variant
1. Baseline 
Experiment
2. Oracle-based 
Experiment
3. Prediction-based 
Experiment
Fig. 2: The process implemented on the intermediate node for
passive OS ﬁngerprinting.
Bytes in 
Flight
Predicted 
TCP Variant
Predicted cwnd
Intercepted Traffic
Deep Learning/LSTM 
Fig. 3: The process implemented on the monitor for prediction
of the TCP variant of the passively intercepted TCP trafﬁc ﬂow.
An LSTM-based machine learning module predicts the cwnd
from the outstanding bytes-in-ﬂight. In the next step, the cwnd
behavior is used to predict the TCP variant as explained in
further detail in our previous works [11, 12, 13]. The predicted
TCP variant is ﬁnally used as an input feature to the OS
ﬁngerprinting process (see bottom right part of Figure 2).
C. Emulated Trafﬁc
In a real scenario where the OS ﬁngerprinting is going
on continuously in an intermediate node of an enterprise or
production network, the intermediate node will have more
information available than only the TCP header, such as
the trafﬁc proﬁle or the knowledge of congestion or the
outstanding bytes-in-ﬂight of a ﬂow. In our experiments below,
we show how this information can be very useful for OS
ﬁngerprinting. Since we do not have full trafﬁc packet captures
in our benchmark dataset or in our realistic dataset, we needed
an additional dataset that we collected from an emulated
network, where there would be no privacy protection or legal
issues related to our dataset. The architecture of our emulated
network is similar to the network setup shown in Figure 1,
except that all the nodes (the sender, the intermediate node,
and the receiver) are implemented in virtual machines. All
background trafﬁc of the OSes for our emulated scenario is
generated using the iperf [6]. Establishing ground truth is
straightforward, as we have full control of the OSes used
when generating the trafﬁc. In addition to establishing the
ground truth, we also wanted to allow the intermediate node
to establish a prediction of the TCP variant by monitoring the
on-going trafﬁc proﬁle of the TCP ﬂow between the sender and
the receiver. As shown later in the paper, using deﬁnitive or
predicted knowledge of the TCP variant as an additional input
feature to the OS ﬁngerprinting, might boost the ﬁngerprinting
accuracy signiﬁcantly. How the machine learning model for
prediction of the TCP variant in the emulated scenario is
trained and how the TCP variant is subsequently predicted are
presented in the following.
IV.
MACHINE LEARNING OF THE OS FINGERPRINTER
A. Classical Machine Learning Approaches
The OS ﬁngerprinter takes various features as input
parameters, and use machine learning to predict the OS as
shown in Figure 2. Many machine learning techniques could
be used to implement a model for passive OS ﬁngerprinting. In
this paper, we have employed the following most commonly
used classical machine learning methods suitable for our
task. In order to train and test our classiﬁcation models, we
employed every experiment with a ratio of 60% training,
40% testing split, and 5-fold cross-validation setting on all
variations of the features into one learning model.
SVM: In order to perform an efﬁcient multi-class SVM
classiﬁcation through cross-validation, we tuned the SVM
hyperparameters using a GridSearchCV that allows specifying
only
the
ranges
of
values
for
optimal
parameters
by
parallelization construction of the model ﬁtting. Finally, in
our evaluation, we found out that SVM with a Radial Basis
Function (RBF) kernel for classiﬁcation model yields a
substantially better result.
Random Forest (RF): We tuned the meta-estimator by varying
the number of decision trees between 1 and 1000. We found
out that increasing the number of trees more than 10 doesn’t
give much improvement in the classiﬁcation accuracy.
KNN: We applied KNN by testing different values of K
ranging from 5 to 100 followed by a weight function for a
total of 20 observations. The observations have been conducted
in two ways. In the ﬁrst experiment, we set the weight to
uniform. In the second experiment, the points are weighted by
the inverse of their distance, causing closer neighbors to have
greater inﬂuence. Finally, we choose the model that has the
highest accuracy for a given unseen instance.
B. Deep Learning Approaches
To
ﬁnd
the
deeper
characteristics
of
TCP
variants
implemented by respective OSes and exploit the extra
OS-speciﬁc information, we apply the following two neural
network architectures.
Multilayer Perceptron (MLP): In our evaluation, MLP model
with a single-layer feedforward neural network [16, 32] has
been used to classify the different classes of OSes. After
the hyperparameter tuning, we tested our MLP model with
a different number of batch sizes, hidden layers, and nodes
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 (e.g., 0, 1, 2, 32, 64, 128) in each layer. Combining all of
these, a total of 324 models were trained with and without
the default TCP variant. We found out that the results for
both with and without a known TCP variant were almost the
same with an insigniﬁcant drop in the accuracy irrespective of
which hyperparameters performed the best. Finally, 128 nodes
of the network per dataset are trained for 150 epochs with
a batch size of 500 by SGD with momentum of 0.9 and a
constant learning rate of 0.01. However, we learned that SGD
is sensitive in regards to the selection of the learning rate
since it doesn’t automatize the values and we also found that
it suffers from premature convergence and is outperformed
by Adam-based optimization methods. Hence, both Adam
and Nadam gradient-based optimization algorithms ﬁt for our
purpose and that is because we wanted to use an optimization
algorithm that adapts its learning rate dynamically in a way that
doesn’t affect the objective function and learning process of the
model. Our experimental results show that the hyperparameter
tuning baseline experiments by applying tanh as activation
function and Adam optimization algorithm and training the
model for 150 epochs, provides a substantial improvement in
accuracy as compared to the other parameters.
Long Short-Term Memory (LSTM) models: We have
explored an approach to classify the underlying OS from
passive measurements using LSTM-based RNN architecture by
combining the basic TCP/IP features and the underlying TCP
variant shown in Table 2 as input vectors. For more details
about LSTM applied in the context of computer networks, we
refer the reader to our previous paper [12]. We trained our
LSTM model over 150 epochs of the training samples with
a batch size of 32
as values in time-series. We propagate
the input feature vector (x) to the model through a multilayer
LSTM cell followed by a fully connected dense layer of 150
hidden nodes with Rectiﬁed Linear Unit (ReLU) activation
function using the hard sigmoid as recurrent activation for
the different layers that generates an output of a sequence
dimensional vector of predicted OSes (yt). We trained our
LSTM-based learning algorithm without the knowledge of the
input features from the true signatures of the OSes during the
learning phase. We learn the model from the training data and
then ﬁnally predict the test labels from the testing instances on
all variations of the OS-speciﬁc parameters. In order to train
our prediction model more quickly, and get a more stable and
robust to changes OS classiﬁcation model, we have applied
one of the most effective optimization algorithms in the deep
learning community, the Adam stochastic algorithm [19] with
an initial learning rate of 0.001 and exponential decay rates
of the ﬁrst (β1) and second (β2) moments set to 0.9 and 0.999
respectively. We further optimize a wide range of important
hyperparameters related to the neural network topology to
improve the performance of our OS classiﬁcation model.
C. Experimental Hardware Setup
All
our
machine
learning
experiments
are
carried
out using a cluster of HPC machines based upon the
GNU/Linux operating system running a modiﬁed version of
the 4.15.0-39-generic kernel release. The prediction model
is performed on an NVIDIA Tesla K80 GPU accelerator
computing with the following characteristics: Intel(R) Xeon(R)
CPU E5-2670 v3 @2.30GHz, 64 CPU processors, 128 GB
RAM, 12 CPU cores running under Linux 64-bit. All nodes in
the cluster are connected to a low latency 56 Gbit/s Inﬁniband,
gigabit Ethernet, and have access to 600 TiB of BeeGFS
parallel ﬁle system storage.
D. Objectives of our Experiments
The aim of our experiments is to explore the effect of the
TCP variant as an input feature when passively detecting the
underlying OS. To investigate this, we divide our analysis into
three different experiments. First, in the baseline experiment
(Section VI) we carry out the OS ﬁngerprinting without using
a known TCP variant as an input feature. This corresponds
to the simplest state-of-the-art transport layer method, which
is illustrated in the upper part of Figure 2. Since there is a
close connection between existing popular OSes and the TCP
variants they use, our hypothesis was that the potential for
improvement by using the TCP variant as an input feature
would be signiﬁcant. For example, CUBIC [9] is the default
congestion control algorithm as part of the Linux kernel
distribution conﬁgurations from version 2.6.19 onwards. Since
Android devices are also Linux-powered, CUBIC remains
to be the default TCP congestion control algorithm. Many
Windows 7 distributions have been shipped with the default
New Reno [15] and whereas Windows 8 families with
CTCP [37]. Therefore, in the next Oracle-based experiment
(Section VII), we investigate the potential of knowing the
TCP variant, and how much this knowledge might boost the
ﬁngerprinting accuracy. Here we assume that there is an Oracle
that can identify and give the TCP variant used in the TCP
ﬂow that is ﬁngerprinted. This is illustrated in the bottom left
part of Figure 2. However, in a real scenario, the intermediate
node would not have access to deﬁnite knowledge of the TCP
variant (e.g., given by an Oracle). Instead, the intermediate
node might at best try to infer it from the monitored trafﬁc.
Thus, in the third prediction-based experiment (Section VIII),
we ﬁrst allow the intermediate node to predict the TCP variant
passively. This is illustrated in the bottom right part of Figure
2. The OS ﬁngerprinter then uses that TCP variant prediction
as an input feature to make the OS prediction illustrated in
the upper part of Figure 2. The TCP variant is predicted by
analyzing the famous sawtooth pattern behavior of estimated
cwnd of TCP, which is computed based on the outstanding
bytes-in-ﬂight [12, 13]. This is presented in more detail in the
next section. Since the latter experiment requires TCP trafﬁc
details of outstanding bytes-in-ﬂight, which is not available in
our benchmark and realistic datasets, this experiment is only
possible with our emulated dataset.
V.
MACHINE LEARNING OF THE TCP VARIANT
PREDICTION TOOL
The main goal of the experiments in the emulated network
is to use the predicted TCP variant as an additional input
feature to the OS ﬁngerprinting. The TCP variant is predicted
by the process illustrated in Figure 3. As described in sufﬁcient
detail in our previous works [11, 12, 13], we used a database
to match and join the intercepted TCP trafﬁc on both the
intermediate node and the sending node. The outstanding
bytes-in-ﬂight of the trafﬁc (i.e., the number of bytes that have
been sent but not yet acknowledged) is used as input to our
machine learning model to predict the cwnd behaviour of the
trafﬁc. We use LSTM for the machine learning. We trained
and veriﬁed the machine learning model by matching the
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 predicted TCP states with the actual TCP kernel states directly
logged from the Linux kernel. Since we have full control of
the sending nodes, we can track the system-wide TCP state
of every packet that is sent and received from the kernel to
verify our model’s prediction accuracy against the actual TCP
variant by matching with the actual sending TCP states using
the techniques presented in our previous works [11, 12, 13].
After the veriﬁcation, we can run our learning model and get
the cwnd predictions of the TCP stack in use.
Once we can estimate the cwnd of the sender, we can
also infer the multiplicative back-off factor (β) which is an
important feature for uniquely identifying the TCP variants.
Finally, we combine the predicted TCP variant as the basis of
OS ﬁngerprinting with the basic TCP/IP features as shown in
Figure 2. Here, we consider only loss-based TCP congestion
control algorithms, e.g., BIC [40], CUBIC [9], CTCP [37],
Reno [17], and New Reno [15]. Delay-based TCP variants are
investigated in a follow-on paper [14]. Our approach could
also be useful to other TCP variants like Google’s QUIC [21].
QUIC uses packet loss as an indicator of congestion and
supports a number of different congestion control algorithms,
including CUBIC [9] and BBR [3].
VI.
BASELINE EXPERIMENT: RESULTS WITHOUT
KNOWING THE TCP VARIANT
Here we present the results of the machine learning and
deep learning techniques under all the validation scenarios
presented above without a known underlying TCP variant
which will play the role of baseline for the other evaluations.
A. Based on Benchmark Data from Previous Related Work
Looking at Tables I and
II,
both machine learning
and deep learning classiﬁcation techniques have consistently
achieved good levels of precision and recall for all general
classes of OSes except iOS. Quantitatively, iOS, and Mac
OS devices were underrepresented in the benchmark data
from previous related work. Besides, as it is shown in
Figures 4, there is a slightly higher misclassiﬁcation of iOS
as unknown and this is why the precision and recall of iOS
are comparably lower than the rest of OSes. We also believe
that the limited TCP/IP stack basic features could contribute
to the indistinguishability and misclassiﬁcation of OS classes
with the same kernel implementation. The false positives are
easier to notice in the corresponding confusion matrices.
TABLE I: Benchmark data [22] experimental results without
a known TCP variant using SVM, RF, and KNN.
SVM
RF
KNN
OS
Precission
Recall
Precision
Recall
Precision
Recall
Android
0.74
0.88
0.87
0.91
0.87
0.91
Linux
0.85
0.85
0.91
0.90
0.91
0.90
Mac OS
0.65
0.77
0.61
0.83
0.58
0.88
Other
0.91
0.81
0.92
0.81
0.92
0.81
Unix
0.91
0.99
0.94
0.99
0.94
0.99
Windows
0.97
0.88
0.98
0.91
0.98
0.91
iOS
0.73
0.55
0.72
0.53
0.79
0.47
Average
0.83
0.82
0.85
0.84
0.86
0.84
Accuracy
81.96%
84.07%
83.95%
B. Based on Realistic Trafﬁc
Our performance results of the realistic trafﬁc without
a known TCP variant using the machine learning and deep
techniques are presented in Tables III and
IV respectively.
The respective confusion matrices are presented in Figures 5.
TABLE II: Benchmark data [22] experimental results without
a known TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.75
0.92
0.77
0.85
Linux
0.90
0.82
0.83
0.85
Mac OS
0.62
0.81
0.58
0.83
Other
1.00
0.74
0.91
0.81
Unix
0.94
0.99
0.94
0.99
Windows
0.97
0.91
0.97
0.86
iOS
0.67
0.57
0.79
0.48
Average
0.84
0.82
0.83
0.81
Accuracy
82.16%
81.04%
TABLE III: Realistic trafﬁc experimental results without a
known TCP variant using SVM, RF, and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.75
0.89
0.86
0.90
0.84
0.93
Linux
0.89
0.82
0.94
0.89
0.93
0.88
Mac OS
0.63
0.81
0.61
0.82
0.61
0.82
Unix
0.94
0.99
0.94
0.99
0.94
0.99
Windows
0.97
0.89
0.98
0.89
0.98
0.89
iOS
0.88
0.72
0.86
0.73
0.88
0.72
Average
0.85
0.83
0.86
0.85
0.87
0.85
Accuracy
83.43%
85%
85.10%
TABLE IV: Realistic trafﬁc experimental results without a
known TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.81
0.83
0.76
0.86
Linux
0.89
0.79
0.90
0.81
Mac OS
0.61
0.82
0.82
0.79
Unix
0.92
0.99
0.94
0.99
Windows
0.98
0.89
0.97
0.89
iOS
0.84
0.73
0.70
0.92
Average
0.84
0.83
0.83
0.84
Accuracy
83.91%
83.27%
C. Based on Emulated Trafﬁc
Our performance results of the emulated trafﬁc without
a known TCP variant as an input feature using both
machine learning and deep learning techniques are presented
in Tables V and VI respectively. As we can see in the
corresponding confusion matrices presented in Figures 6, there
is a slightly inaccurate classiﬁcation of the Mac OS due to its
underrepresentation. The precision and recall for the rest of the
OSes using machine learning and deep learning techniques are
reasonably good.
TABLE V: Emulated trafﬁc experimental results without a
known TCP variant using SVM, RF and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.74
0.90
0.86
0.90
0.85
0.91
Linux
0.92
0.82
0.94
0.89
0.92
0.90
Mac OS
0.63
0.81
0.61
0.82
0.61
0.82
Unix
0.94
0.99
0.94
0.99
0.94
0.99
Windows
0.97
0.89
0.98
0.89
0.98
0.89
iOS
0.88
0.73
0.86
0.73
0.88
0.73
Average
0.85
0.84
0.86
0.85
0.87
0.85
Accuracy
84.67%
85.73%
85.27%
D. Comparison of Results Without Known TCP Variant
As shown in Tables I, II, III, IV, V, and VI, our
experimental results are pretty consistent. Firstly, we can
see that there is not much difference in performance across
different machine learning and deep learning techniques.
But more importantly, there are not many differences in
performance between results from using different types of
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 (a) SVM
(b) KNN
(c) RF
(d) MLP
(e) LSTM
Fig. 4: Confusion matrix comparison of the machine learning and deep learning techniques using the benchmark data [22].
(a) SVM
(b) KNN
(c) RF
(d) MLP
(e) LSTM
Fig. 5: Confusion matrix comparison of the machine learning and deep learning techniques using a realistic trafﬁc.
TABLE VI: Emulated trafﬁc experimental results without a
known TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.75
0.88
0.91
0.85
Linux
0.93
0.78
0.92
0.74
Mac OS
0.62
0.81
0.86
0.88
Unix
0.92
0.99
0.94
1.00
Windows
0.93
0.91
0.98
0.73
iOS
0.88
0.73
0.82
1.00
Average
0.85
0.83
0.89
0.88
Accuracy
84.05%
88.44%
experimental data. This is intuitively correct, since the OS
ﬁngerprinting is based on the basic TCP/IP packet ﬁelds,
and should not differ much between various types of data,
whether we do evaluation using the benchmark data, real
data or emulated data. Secondly, we believe accuracy in the
range of 82-88% (average value) is perhaps not sufﬁcient for
a product in a real deployment. Our hypothesis is that this
accuracy could be boosted considerably had we only known
the implementation of the underlying TCP variant. We will
explore this hypothesis in the next section.
VII.
ORACLE-BASED EXPERIMENT: RESULTS USING
ORACLE-GIVEN TCP VARIANT
Here we assume that we know exactly the underlying TCP
variant, i.e., we assume it is given by an Oracle. We show
that knowledge of the TCP variant has a great potential for
boosting passive ﬁngerprinting of OSes, and in this section,
we will try to quantify this potential. In the next section, we
will show that much of this potential can be harvested by using
a tool that predicts the TCP variant.
A. Based on Benchmark Data from Previous related Work
Tables VII and VIII show a signiﬁcant performance gain
across all classes of OSes when we assume prior knowledge of
the underlying TCP variant, as compared to the results when
the TCP variant is unknown presented in Tables I and II.
TABLE VII: Benchmark data [22] experimental results with
Oracle-given TCP variant using SVM, RF and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.96
0.99
0.99
0.98
0.99
0.98
Linux
0.86
0.95
0.92
0.95
0.93
0.94
Mac OS
0.98
0.89
0.97
0.92
0.97
0.92
Other
0.93
0.81
0.93
0.81
0.90
0.83
Unix
1.00
1.00
1.00
1.00
1.00
1.00
Windows
0.99
0.89
0.97
0.92
0.99
0.91
iOS
0.75
0.89
0.75
0.91
0.76
0.91
Average
0.92
0.92
0.93
0.93
0.93
0.93
Accuracy
91.71%
92.73%
92.69%
TABLE VIII: Benchmark data [22] experimental results with
Oracle-given TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.96
0.97
0.94
0.97
Linux
0.89
0.92
0.88
0.93
Mac OS
0.96
0.92
0.97
0.88
Other
0.93
0.81
0.84
0.84
Unix
1.00
1.00
1.00
1.00
Windows
0.96
0.92
0.98
0.84
iOS
0.76
0.89
0.73
0.83
Average
0.92
0.92
0.91
0.90
Accuracy
91.91%
90.03%
B. Based on Realistic Trafﬁc
The performance results of the realistic trafﬁc with the
Oracle-given TCP variant presented in Tables IX and X show
the potential of knowing TCP variant given by an Oracle for
passive OS ﬁngerprinting in a realistic scenario.
TABLE
IX:
Realistic
trafﬁc
experimental
results
with
Oracle-given TCP variant using SVM, RF and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.95
1.00
0.99
0.98
0.99
0.98
Linux
0.86
0.91
0.94
0.93
0.92
0.94
Mac OS
0.99
0.90
0.96
0.92
0.97
0.92
Unix
1.00
1.00
1.00
1.00
1.00
1.00
Windows
0.99
0.89
0.99
0.89
0.99
0.89
iOS
0.93
0.96
0.91
0.99
0.92
0.98
Average
0.95
0.95
0.96
0.96
0.96
0.96
Accuracy
94.81%
95.65%
95.69%
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 TABLE
X:
Realistic
trafﬁc
experimental
results
with
Oracle-given TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.98
0.97
0.98
0.97
Linux
0.92
0.92
0.90
0.93
Mac OS
0.96
0.92
0.96
0.92
Unix
1.00
1.00
1.00
1.00
Windows
0.97
0.91
0.99
0.88
iOS
0.92
0.97
0.91
0.98
Average
0.95
0.95
0.95
0.95
Accuracy
94.98%
94.89%
C. Based on Emulated Trafﬁc
Our performance results of the emulated trafﬁc with
the Oracle-given TCP variant using both classical machine
learning and deep learning techniques are presented in
Tables XI and XII. We can see that this shows a signiﬁcant
improvement in performance over the results without a known
TCP variant presented in Tables V and VI. Both machine
learning and deep learning techniques have comparable and
consistent results in terms of accuracy.
TABLE XI: Emulated trafﬁc experimental results with the
Oracle-given TCP variant using SVM, RF, and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.97
0.98
0.99
0.98
0.99
0.98
Linux
0.90
0.91
0.95
0.93
0.92
0.95
Mac OS
0.99
0.90
0.97
0.92
0.97
0.92
Unix
1.00
1.00
1.00
1.00
1.00
1.00
Windows
0.99
0.89
0.97
0.91
0.97
0.91
iOS
0.91
0.98
0.92
0.98
0.93
0.97
Average
0.95
0.95
0.96
0.96
0.96
0.96
Accuracy
95.10%
96.02%
95.83%
TABLE XII: Emulated trafﬁc experimental results with the
Oracle-given TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.98
0.97
0.96
0.98
Linux
0.97
0.89
0.93
0.91
Mac OS
0.93
0.94
0.94
0.92
Unix
1.00
1.00
1.00
1.00
Windows
0.99
0.89
0.98
0.88
iOS
0.91
0.99
0.91
0.97
Average
0.95
0.95
0.95
0.95
Accuracy
95.24%
95.08%
D. Comparison of Results with Oracle-given TCP Variant
Our accuracy results presented in Tables
VII,
VIII,
IX, X, XI, and XII, demonstrate that by knowing the TCP
variant we obtain a considerable performance boost in all our
experimental results, compared to our previous results obtained
without knowledge of the TCP ﬂavor. With an Oracle-given
TCP variant, we obtain a prediction accuracy of 94-96%,
with an average value of 94.1% over all trafﬁc classes and
of 95.4% over only emulated trafﬁc. The accuracy results are
pretty consistent across all scenarios. Comparing these results
with our previous results that do not use the Oracle (84.1%
on average for all trafﬁc types and 85.6% only for emulated
trafﬁc), we observe a solid increase in the OS ﬁngerprinting
performance. This improvement would signiﬁcantly boost
the usefulness of a product to be implemented in a real
enterprise network infrastructure. As in the previous section,
here again, we observe highly consistent performance results
across different machine learning and deep learning techniques
and also between the use of different types of experimental
data. The latter is useful knowledge for the next section since
it means that performance increases obtained over one trafﬁc
type is shown to be amenable to other trafﬁc types as well.
In the next section, we will have to base our evaluation on
emulated data, since we do not have the TCP trafﬁc patterns
of the realistic data or benchmark data at hand. These trafﬁc
patterns are required to be able to passively infer the TCP
variant in the experiments presented in the next section. In this
section, the idealistic Oracle was used only to demonstrate the
potential of knowing the TCP variant, but this is not a realistic
assumption. Thus, in the next section, we will instead base our
evaluation on a TCP variant that is passively predicted by a
deep learning-based tool that we developed and presented in
our previous work [11, 12, 13]. Using this tool, we explore
how close our performance will get to the ideal solution of
having an Oracle.
VIII.
PREDICTION-BASED EXPERIMENT: RESULTS USING
TCP VARIANT PREDICTION
In Section VII, we showed that Oracle-given knowledge
of the TCP variant has a great potential for improving the
passive OS ﬁngerprinting. In reality, however, we don’t have
an Oracle-given TCP variant. Since passively detecting the
TCP variant is a challenging task, this is where our tool from
previous works on predicting the underlying TCP variant from
passive measurements [11, 12, 13] comes into play. In this
Section we use the TCP variant passively predicted by this
tool as an input feature for the passive OS ﬁngerprinting. The
TCP variant is inferred from the famous Additive Increase
and Multiplicative Decrease (AIMD) sawtooth pattern of
TCP’s estimated cwnd computed based on the outstanding
bytes-in-ﬂight. Since we don’t have access to the actual cwnd
of the senders in the benchmark data and realistic trafﬁc, here
we consider only the emulated trafﬁc.
A. Based on Emulated Trafﬁc
In this section, we use a tool to predict the TCP variant
from passive measurements of TCP trafﬁc patterns, and this
prediction is used as input to the passive OS ﬁngerprinting
method presented above. The experimental results of both
techniques are presented in Tables XIII and XIV.
TABLE XIII: Emulated trafﬁc experimental results with
predicted TCP variant using SVM, RF, and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.92
0.96
0.92
0.97
1.00
0.97
Linux
0.79
0.85
0.94
0.82
0.92
0.94
Mac OS
0.96
0.88
0.97
0.87
0.85
0.94
Unix
1.00
1.00
1.00
1.00
1.00
1.00
Windows
0.92
0.78
0.85
0.80
0.88
0.91
iOS
0.85
0.94
0.86
0.96
0.93
0.87
Average
0.90
0.90
0.91
0.91
0.93
0.93
Accuracy
90.01%
91.09%
92.15%
TABLE XIV: Emulated trafﬁc experimental results with
predicted TCP variant using MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.95
0.97
0.92
0.96
Linux
0.98
0.79
0.86
0.90
Mac OS
0.95
0.90
0.95
0.88
Unix
1.00
1.00
1.00
1.00
Windows
0.94
0.77
0.97
0.77
iOS
0.82
0.99
0.88
0.96
Average
0.92
0.91
0.92
0.92
Accuracy
91.45%
91.93%
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 (a) SVM
(b) KNN
(c) RF
(d) MLP
(e) LSTM
Fig. 6: Confusion matrix comparison of the machine learning and deep learning techniques using an emulated trafﬁc.
B. Comparison of results with a predicted TCP variant
Results with emulated data and a passive prediction of
the TCP variant (Tables XIII and XIV) gives an accuracy of
91.3% on average, which comes pretty close to the accuracy
of 95.4% obtained on emulated trafﬁc with the TCP-variant
given by the Oracle. Intuitively, when we do learning based
on the TCP variant prediction, the accuracy must be lower
than the Oracle-given TCP variant, but the question is how
close we can get to the idealistic scenario of having an
Oracle. Our results show that using our tool for TCP variant
prediction gives reasonably good OS ﬁngerprinting accuracies
that come close to the results obtained by using Oracle-given
TCP variant. Even though the performance results with the
TCP variant passively predicted by our deep learning-based
tool are slightly lower as compared to the TCP variant given
by an idealistic Oracle, our performance results of using our
tool are reasonably competitive.
IX.
TRANSFER LEARNING RESULTS
Transfer learning is the ability to take a model trained
in one scenario and apply it for classiﬁcation in a different
scenario. For example, in our case, that means we are able
to train our model on a dataset created in an emulated
network with an Oracle-given TCP variant and apply it for
classiﬁcation of our dataset from the realistic trafﬁc. Results
shown in Tables XV and XVI shows that the learning of the OS
ﬁngerprinter transfers well into other scenarios. Good transfer
learning results indicate that our passive OS ﬁngerprinting
model is able to discern the results of unforeseen scenarios
and still perform reasonably well. In previous works, we have
also demonstrated that the TCP variant predictor performs well
in terms of transfer learning [11, 12, 13].
TABLE XV: Transfer learning experimental results using
SVM, RF, and KNN.
SVM
RF
KNN
OS
Precision
Recall
Precision
Recall
Precision
Recall
Android
0.95
1.00
0.98
0.98
0.99
0.98
Linux
0.86
0.91
0.90
0.95
0.92
0.95
Mac OS
0.99
0.90
0.98
0.92
0.97
0.92
Unix
1.00
1.00
1.00
1.00
1.00
1.00
Windows
0.99
0.89
0.98
0.90
0.97
0.91
iOS
0.93
0.96
0.93
0.97
0.93
0.97
Average
0.95
0.95
0.95
0.95
0.96
0.96
Accuracy
94.79%
95.35%
95.76%
X.
CONCLUSION AND FUTURE WORK
In this paper, we proposed and evaluated a novel approach
that attempts to passively ﬁngerprint the underlying remote
OS by leveraging state-of-the-art machine learning and deep
learning techniques under multiple controlled scenarios. We
TABLE XVI: Transfer learning experimental results using
MLP and LSTM.
MLP
LSTM
OS
Precision
Recall
Precision
Recall
Android
0.97
0.98
0.97
0.96
Linux
0.95
0.85
0.91
0.91
Mac OS
0.94
0.94
0.96
0.90
Unix
1.00
1.00
1.00
1.00
Windows
0.99
0.89
0.98
0.87
iOS
0.90
0.98
0.90
0.98
Average
0.95
0.95
0.94
0.94
Accuracy
94.72%
94.28%
show that knowing the Oracle-given TCP variant has a great
potential for boosting the classiﬁcation performance of passive
OS ﬁngerprinting. In our setting, we demonstrate that using
the idealistic Oracle has the potential to boost the prediction
accuracy from 84.1% to 94.1% on average across all trafﬁc
types tested, and from 85.6% to 95.4% in an emulated setting.
However, in reality, we don’t have the Oracle-given TCP
variant and hence we don’t know exactly the underlying TCP
ﬂavor. To address this, we demonstrated a method for passive
OS ﬁngerprinting where the cwnd is ﬁrst computed based on
the outstanding bytes-in-ﬂight, then the underlying TCP ﬂavor
is predicted from the estimated cwnd, and ﬁnally, the predicted
TCP variant is used as an input feature to detect the remote
computer’s OS. This is an additional feature that is added to the
basic TCP/IP features that are the basis of OS ﬁngerprinting
in previous works. We demonstrate that our method performs
signiﬁcantly better than not using the predicted TCP variant
as an input feature, increasing the accuracy in our experiment
from 85.6% to 91.3%. The results of this method come close
to the accuracy of 95.4% obtained by using the idealistic
Oracle. To the best of our knowledge, this is the ﬁrst study that
reports the potential of the underlying TCP feature in boosting
signiﬁcantly the accuracy of passive OS ﬁngerprinting. We
further validate and demonstrate the transferability approach
of our OSes classiﬁcation models by conducting a series
of controlled experiments against other scenarios. Through
comparing the experimental results between the benchmark
dataset, realistic, and emulated trafﬁc in terms of accuracy and
confusion matrix, it is clear that our passive OSes classiﬁcation
models are able to discern the results to unforeseen scenarios.
Therefore, we are able to show that the learned passive OS
ﬁngerprinting model by leveraging a pre-trained knowledge of
classiﬁcation techniques from the emulated network performs
reasonably well as it is shown in the experimental results when
it is applied and transferred to a realistic scenario. Lastly,
in all our experiments, we made sure that both the training
and validation accuracies are closer which gives an idea about
the ability of the OSes classiﬁcation models to generalize on
unforeseen scenarios.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
 The method presented in this paper, where the cwnd is
ﬁrst computed based on the outstanding bytes-in-ﬂight, then
the underlying TCP ﬂavor is predicted from the estimated
cwnd, is particularly efﬁcient for loss-based TCP variants.
In previous works, we have also developed a tool for the
prediction of delay-based TCP ﬂavors [10]. We plan to extend
the method presented in this paper to also cover delay-based
TCP variants and present it in a follow-on paper [14]. Note
that passively detecting the TCP variant is a challenging task,
which led to a two-step approach, where the TCP variant
prediction of a deep learning-based tool is used as input to
another machine learning method in the next step. However, by
integrating the two machine learning approaches better, there
should be potential for increasing the performance even further
and get even closer to the idealistic results of using an Oracle.
Exploring such optimizations is also left for future work. It
is known that TCP clock drift improves OS ﬁngerprinting
and hence measuring differences in the timing of how the IP
stack works may allow us to predict the underlying OS with
greater assurance in terms of accuracy. We, therefore, argue
for using other TCP options like timestamps and queueing
delay characteristics as an input feature vector for passive OSes
ﬁngerprinting model as another interesting direction. Finally,
in addition to the difﬁculties of establishing ground truth (e.g.,
the TCP variant) at a larger scale on a dynamic network
addressed in Section III, there is a lot of other work to be
done as an extension of our work presented here. For example,
addressing answers to valid questions like: What happens if an
end-user (client) changes default parameters that are the basis
of OS ﬁngerprinting? is one possibility for our future work.
We expect that end-users don’t change parameters often, while
servers may do so if it helps improve performance. We believe
this would make OS ﬁngerprinting potentially hard.
REFERENCES
[1] 5G4IoT. 5G4IoT, 2019.
[2] A. Aksoy, S. Louis, and M. H. Gunes.
Operating system
ﬁngerprinting via automated network trafﬁc analysis. In IEEE
Congress on Evolutionary Computation (CEC). IEEE, 2017.
[3] N. Cardwell, Y. Cheng, C. S. Gunn, S. H. Yeganeh, and
V. Jacobson. BBR: Congestion-based congestion control. 2016.
[4] W. R. Cheswick, S. M. Bellovin, and A. D. Rubin. Firewalls
and Internet security: repelling the wily hacker. Addison-Wesley
Longman Publishing Co., Inc., 2003.
[5] N. Davids. Initial TTL values, 2011.
[6] ESnet. iperf3, 2017.
[7] J. Fan, J. Xu, M. H. Ammar, and S. B. Moon. Preﬁx-preserving
IP
address
anonymization:
measurement-based
security
evaluation and a new cryptography-based scheme. 2004.
[8] L. G. Greenwald and T. J. Thomas.
Toward Undetected
Operating System Fingerprinting. WOOT, 7:1–10, 2007.
[9] S. Ha, I. Rhee, and L. Xu.
CUBIC: a new TCP-friendly
high-speed TCP variant. ACM SIGOPS, 2008.
[10] D. H. Hagos, P. E. Engelstad, and A. Yazidi.
Classiﬁcation
of
Delay-based
TCP
Algorithms
From
Passive
Trafﬁc
Measurements. In 18th NCA. IEEE, 2019.
[11] D. H. Hagos, P. E. Engelstad, A. Yazidi, and Ø. Kure.
A
machine learning approach to TCP state monitoring from
passive measurements. pages 164–171. IEEE, 2018.
[12] D. H. Hagos, P. E. Engelstad, A. Yazidi, and Ø. Kure. Recurrent
Neural Network-based Prediction of TCP Transmission States
from Passive Measurements. In NCA, pages 1–10. IEEE, 2018.
[13] D. H. Hagos, P. E. Engelstad, A. Yazidi, and Ø. Kure. Towards a
Robust and Scalable TCP Flavors Prediction Model from Passive
Trafﬁc. In 2018 27th ICCCN, pages 1–11. IEEE, 2018.
[14] D. H. Hagos, A. Yazidi, P. E. Engelstad, and Ø. Kure.
A
Deep Learning-based Universal Tool for Operating Systems
Fingerprinting from Passive Measurements. 2020. Submitted
for publication.
[15] T. Henderson, S. Floyd, A. Gurtov, and Y. Nishida.
The
NewReno modiﬁcation to TCP’s fast recovery algorithm. RFC
6582, 2012.
[16] K. Hornik, M. Stinchcombe, and H. White.
Multilayer
feedforward networks are universal approximators.
Neural
networks, 1989.
[17] V. Jacobson.
Congestion avoidance and control.
In ACM
SIGCOMM computer communication review. ACM, 1988.
[18] V. Jacobson, R. Braden, and D. Borman. TCP extensions for
high performance. RFC 1323, 1992.
[19] D. P. Kingma and J. Ba.
Adam: A method for stochastic
optimization. arXiv preprint arXiv:1412.6980, 2014.
[20] T. Kohno, A. Broido, and K. C. Claffy. Remote physical device
ﬁngerprinting. IEEE, 2005.
[21] A. Langley, A. Riddoch, A. Wilk, A. Vicente, C. Krasic,
D. Zhang, F. Yang, F. Kouranov, I. Swett, J. Iyengar, et al. The
quic transport protocol: Design and internet-scale deployment.
pages 183–196. ACM, 2017.
[22] M.
Lastovicka,
T.
Jirsik,
P.
Celeda,
S.
Spacek,
and
D. Filakovsky. Passive os ﬁngerprinting methods in the jungle
of wireless networks. In NOMS. IEEE, 2018.
[23] R. Lippmann, D. Fried, K. Piwowarski, and W. Streilein. Passive
operating system identiﬁcation from TCP/IP packet headers. In
Data Mining for Computer Security. Citeseer, 2003.
[24] R. Lippmann, S. Webster, and D. Stetson.
The effect of
identifying vulnerabilities and patching software on the utility
of network intrusion detection. Springer, 2002.
[25] G.
F.
Lyon.
Remote
OS
detection
via
TCP/IP
stack
ﬁngerprinting. Phrack Magazine, 8(54), 1998.
[26] G. F. Lyon. Nmap network scanning: The ofﬁcial Nmap project
guide to network discovery and security scanning. 2009.
[27] Netresec. NetworkMiner, 2007.
[28] A. Ornaghi and M. Valleri. Ettercap, 2015.
[29] J. Postel. Internet control message protocol. RFC 792, 1981.
[30] J. Postel. Internet protocol. RFC 791, 1981.
[31] J. Postel. Transmission control protocol. RFC 793, 1981.
[32] F. Rosenbaltt.
The perceptron–a perciving and recognizing
automation. Cornell Aeronautical Laboratory, 1957.
[33] J. Scambray, S. McClure, and G. Kurtz.
Hacking exposed.
McGraw-Hill Professional, 2000.
[34] SCOTT. European Leadership Joint Undertaking, 2019.
[35] R. Spangler.
Analysis of remote active operating system
ﬁngerprinting tools. University of Wisconsin, 2003.
[36] G. Taleck.
Synscan: Towards complete tcp/ip ﬁngerprinting.
CanSecWest, Vancouver BC, Canada, pages 1–12, 2004.
[37] K. Tan, J. Song, Q. Zhang, and M. Sridharan. A compound
TCP approach for high-speed and long distance networks. In
Proceedings IEEE INFOCOM, 2006.
[38] W. Wei, K. Suh, B. Wang, Y. Gu, J. Kurose, and D. Towsley.
Passive online rogue access point detection using sequential
hypothesis testing with TCP ACK-pairs. ACM, 2007.
[39] J. Xu, J. Fan, M. Ammar, and S. B. Moon. On the design and
performance of preﬁx-preserving IP trafﬁc trace anonymization.
In ACM SIGCOMM, pages 263–266. ACM, 2001.
[40] L. Xu, K. Harfoush, and I. Rhee. Binary increase congestion
control (BIC) for fast long-distance networks. IEEE, 2004.
[41] F. Yarochkin and O. Arkin.
Xprobe2- A’Fuzzy’Approach to
Remote Active Operating System Fingerprinting, 2002.
[42] M. Zalewski. p0f: Passive OS ﬁngerprinting tool. Online at
http://lcamtuf.coredump.cx/p0f3, 2017.
[43] B. Zhang, T. Zou, Y. Wang, and B. Zhang. Remote operation
system detection base on machine learning. IEEE, 2009.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore.  Restrictions apply. 
",10.1109/ICCCN49398.2020.9209694,doc28,"—Securing and managing large, complex enterprise
network infrastructure requires capturing and analyzing network
trafﬁc traces in real-time. An accurate passive Operating System
(OS) ﬁngerprinting plays a critical role in effective network
management and cybersecurity protection. Passive ﬁngerprinting
doesn’t send probes that introduce extra load to the network and
hence it has a clear advantage over active ﬁngerprinting since
it also reduces the risk of triggering false alarms. This paper
proposes and evaluates an advanced classiﬁcation approach to
passive OS ﬁngerprinting by leveraging state-of-the-art classical
machine learning and deep learning techniques. Our controlled
experiments on benchmark data, emulated and realistic trafﬁc
is performed using two approaches. Through an Oracle-based
machine learning approach, we found that the underlying TCP
variant is an important feature for predicting the remote OS.
Based on this observation, we develop a sophisticated tool for
OS ﬁngerprinting that ﬁrst predicts the TCP ﬂavor using passive
trafﬁc traces and then uses this prediction as an input feature
for another machine learning algorithm for predicting the remote
OS from passive measurements. This paper takes the passive
ﬁngerprinting problem one step further by introducing the
underlying predicted TCP variant as a distinguishing feature. In
terms of accuracy, we empirically demonstrate that accurately
predicting the TCP variant has the potential to boost the
evaluation performance from 84% to 94% on average across
all our validation scenarios and across different types of trafﬁc
sources. We also demonstrate a practical example of this potential,
by increasing the performance to 91.3% on average using a tool
for TCP variant prediction in an emulated setting. To the best of
our knowledge, this is the ﬁrst study that explores the potential
for using the knowledge of the TCP variant to signiﬁcantly boost
the accuracy of passive OS ﬁngerprinting.","Advanced Passive Operating System Fingerprinting Using Machine Learning and Deep Learning Desta Haileselassie Hagos∗, Martin Løland†, Anis Yazidi‡, Øivind Kure §, Paal E. Engelstad ¶ ∗§¶University of Oslo, Department of Technology Systems, Kjeller, Norway ∗†‡¶Oslo Metropolitan University, Department of Computer Science, Oslo, Norway Email: ∗destahh@iﬁ.uio.no, †martin.loeland@gmail.com, {‡anis.yazidi, ¶paal.engelstad}@oslomet.no, §oivind.kure@its.uio.no Abstract Keywords—Operating System, Fingerprinting, Machine Learning, Deep Learning, Passive Measurements I. INTRODUCTION AND MOTIVATION As modern network infrastructures grow in size, collecting detailed relevant knowledge about the dynamic characteristics and complexity of large heterogeneous networks is crucial for many purposes e.g., network vulnerability assessment and monitoring, spam detection, etc. Developing advanced network security and monitoring techniques are important for both the research and security practitioners. There has been a signiﬁcant research work in the context of network management and cybersecurity on developing network security tools to ﬁngerprint remote Operating Systems (OSes) [26, 27, 28, 41, 42]. OS ﬁngerprinting is the process of inferring the OS of a machine operating with TC/IP by a remote device connected on the Internet without having physical access to the device [20]. There are many different custom tools for ﬁngerprinting of the most commonly used OSes based on the characteristics of its underlying TCP/IP network stack [20] and this, to a large extent, is due to variability in how the TCP/IP stack is traditionally implemented across different OSes [25]. One common approach, for example, is by collecting the TCP/IP stack basic parameters [23], e.g., IP initial Time To Live (TTL) default values [5], HTTP packets using the User-agent ﬁeld [22], Internet Control Message Protocol (ICMP) requests [29], known open port patterns, TCP window size [18], TCP Maximum Segment Size (MSS) [31], IP Don’t Fragment (DF) ﬂag [30], a set of other speciﬁc TCP options to mention a few. However, in our work, we want to take this one step further by combining these basic features and other settings with the underlying TCP variant as a feature in our model due to the fact that different OSes are doing slightly different implementations of TCP. Some implementations of common TCP variants quickly overshoot the size of the Congestion Window (cwnd) because of differences in the variant implementations. Hence, we believe that knowing the implementation of the underlying OS may help us understand better their exact behavior. It can also help us explore how to classify an OS when different OSes are implementing the same TCP variant. Fingerprinting Techniques: We can determine what OS a remote computer on the Internet is running by either passively listening to trafﬁc captured from a network or by actively sending it packets. The most widely used complementary remote OS ﬁngerprinting proven approaches that employ a variety of TCP/IP stack scanning are broadly categorized into classes of active and passive methods. • Active Fingerprinting: This technique is based on actively transmitting one or more specially crafted network packets with different packet settings or ﬂags to a remote network device in order to analyze the corresponding potentially identifying replies [26, 41]. This method determines knowledge of the underlying OS according to the received responses from the target device by examining the network behavior of known TCP/IP stack [35]. However, since this approach injects additional trafﬁc to the network by generating active probes, it may itself trigger alarms and get blocked by ﬁrewall rules and Network address translators (NATs) [8]. • Passive Fingerprinting: This approach, on the other hand, inspects and analyzes packets traveling between end hosts without injecting any trafﬁc into the network [27, 28, 42]. This technique with little resource simply analyzes a pattern of the OS-speciﬁc information that has already been sent in the network trafﬁc and compares for a match with a predeﬁned database that contains a list of known signatures of different OSes. Passive ﬁngerprinting doesn’t send probes and hence it has a clear advantage over active ﬁngerprinting since it reduces the risk of triggering alarms [8]. 978-1-7281-6607-0/20/$31.00 ©2020 IEEE Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. OS ﬁngerprinting can also be performed using classical techniques known as “banner grabbing”. It is an approach used to gain detailed information about a remote computer system on a network and the associated services running on its opened ports [33]. Using techniques like this, some remote computers announce their underlying OS freely and running application services with their versions in use to anyone connecting to them as part of welcome banners or header information. Some of the widely used services that serve banner grabbing are: Telnet, FTP, NetCat, SMTP, etc. However, it is useful to remember that some of these basic services are effective against less secure networks. Potential beneﬁts and applications: Network scanning and accurate remote OS ﬁngerprinting are the crucial steps for penetration testing in terms of security and privacy protection. Note that attackers can also embrace passive ﬁngerprinting techniques to search for potential victims in a network. For example, by identifying the OS running on a remote computer and the list of services it runs, an attacker can target the device to eavesdrop on the communication between the endpoints without having physical access to the device. However, we argue that our work presented here is motivated by a number of practical applications that can be positively used by network and system administrators. Passively ﬁngerprinting an OS by analyzing the packets it generates and transmits over a network is extremely important in the areas of network management and computer security for several reasons. For example, it is useful to explore a network for potential exploitations of security vulnerabilities which can be exploited by attackers, auditing, identify critical attacks, reveal new information about a network user etc. Network administrators can, therefore, use this OS related information to maintain the security policy and reliability of their network by conﬁguring a network-based Intrusion Detection Systems (IDS) [24]. Vulnerabilities and security threats in a network may result from rogue or unauthorized devices [38], unsecured internal nodes within the network, and from external nodes [4]. Hence, passively ﬁngerprinting an OS has a potential beneﬁt in addressing these critical problems. This, from an academic point of view, is Client Oses of sending nodes Fingerprinter Receiving nodes on the Internet 35.195.9.67 Intermediate node (monitor) Fig. 1: Network architecture for passive OS ﬁngerprinting by an intermediate node. Limitations of previous works: Traditionally, most of the existing general OS ﬁngerprinting techniques resort to manually generated signature matching from a database of heuristics which contains features of widely used OSes. This means, after comparing the generated signatures, the ﬁrst set of responses match with the highest conﬁdence against a database of ﬁngerprints would be used to select the speciﬁc probable OS. However, manually updating a large number of signature and managing databases of new OSes adds a considerable amount of time and hence we may suffer from the consequences of the lack of recent signature updates of the known OSes. For example as reported in [22], the last updates of the ﬁngerprint databases of Ettercap [28] and p0f [42] date to 2011 and 2014 respectively. Consequently, new OSes families like Android 4.4 and higher versions of Android, Windows 10 distributions, etc. will not be recognized by these tools since they are not included in their ﬁngerprint databases. Hence, we argue that it is important to consider making use of a ﬁngerprint database that contains variations of most currently used OSes and automating these tasks by employing learning algorithms capable of extracting all possible OS-speciﬁc features for discovering the underlying OSes. To explore this idea of applying learning algorithms, we present a uniﬁed and robust classiﬁcation approach to an advanced passive OS ﬁngerprinting that leverages both machine learning and deep learning methods. Our ﬁngerprinting technique is completely passive meaning that we only need to be able to observe network trafﬁc from a target machine at any observation point on the network without injecting any trafﬁc into the network. Note that the TCP/IP header ﬁelds would not be impacted by SSL/TLS encryption of the TCP payload. Hence, since we utilize features that are readable even with encryption, our approach is independent of whether the ﬂow is encrypted or not. Figure 1 shows the architecture for implementing our ﬁngerprinting methodology. Why machine learning approaches to OS ﬁngerprinting? There are several limitations imposed by classical ﬁngerprinting techniques. Passive OS ﬁngerprinting generally relies on recognizing the default values for various TCP/IP stack parameters. If a user changes these parameters, the task of OS ﬁngerprinting becomes much more challenging. Most of the existing works on ﬁngerprinting provide a little capability to address this challenge. Motivated by this problem, we proposed a novel approach by leveraging both machine learning and deep learning-based techniques that consider the set of parameters as a whole, rather than individually so that our model caters for variations in TCP parameters. If a user changes the initial receive window size, for instance, we may still be able to recognize the OS from other parameters that have not been changed (TCP congestion control algorithm, initial cwnd size, etc.). Note that this depends entirely on the changes made by the user to the default TCP or OS stack parameters that are commonly used for signature-based ﬁngerprinting. The other reason why we create a model by employing learning techniques is to understand the complex patterns of the varying values in the TCP header and extract useful input features. Because machine learning offers new possibilities as it can extract patterns and general rules for classiﬁcation. Machine learning can also be more robust to small variations in the input parameters. In addition to this, with the use of learning techniques, we argue that avoiding using manually updated static signature databases has two potential beneﬁts. Firstly there is no tedious task of creating these unique ﬁngerprints, all you need is a set of values or features. The second beneﬁt comes from a known ﬂaw in many of the existing ﬁngerprinting tools, where a “ﬁrst-match” policy is applied, meaning that if two ﬁngerprints are equal the tool would always predict the ﬁrst OS with that exact ﬁngerprint. However, learning techniques, on the other hand, make calculated guesses of which of the classes with the same ﬁngerprint that will be predicted. interesting and something that needs to be addressed from a network security research point of view. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. Contributions: We summarize our main contributions below. • We propose and evaluate a robust approach to OS ﬁngerprinting from passive measurements by leveraging machine learning and deep learning techniques. • We investigate the use of TCP congestion control variant as a distinguishing feature in passive OS ﬁngerprinting. • We explore variability in implementations of TCP variant by different OSes and its effect on classifying remote OS. • We study the applicability of Recurrent Neural Networks (RNN)-based models for robust and advanced passive OS ﬁngerprinting by combining the basic TCP/IP features and the predicted TCP variant as input vectors. • We show that the TCP ﬂavor has a great potential for boosting passive OS ﬁngerprinting. • We build a universal tool for passive monitoring that can be applied to ﬁrst estimate the TCP cwnd, second predict the TCP ﬂavor, and ﬁnally uses the TCP variant as an input feature to detect the remote computer’s OS. Roadmap: The rest of the paper is organized as follows. Section II discusses related work, and Section III presents the experimental datasets. Section IV presents the machine learning of the OS ﬁngerprinter. The machine learning of the TCP variant prediction tool is presented in detail in Section V. Section VI presents the experimental results without a known TCP variant which will play the role of baseline. In order to assess the importance of knowing the TCP variant, experimental results of all the use cases with an Oracle-given TCP variant are presented in Section VII. Section VIII presents the experimental results with the predicted TCP variant. Section IX presents the transfer learning results. Finally, Section X concludes our paper and suggests directions for future research work. II. RELATED WORK Remote OSes ﬁngerprinting has a long history in the computer security community [2, 22, 23, 26]. TCP/IP header ﬁngerprinting and any information related to application protocols are used to identify the underlying OS running on a remote host either actively or passively [25]. As we explained in Section I, there are multiple existing tools for both the predominant active and passive OS ﬁngerprinting approaches, where Nmap [26] is one of the most prominent open-source active ﬁngerprinting tools. The work presented in [36], SYNSCAN, works in a similar fashion to Nmap, but it performs the ﬁngerprinting task by actively sending a small number of crafted network packets to a single TCP port. Xprobe2 [41] is another popular ﬁngerprinting tool, that relies primarily on ICMP packets, and it depends on how many changes we make to the default TCP/IP stack parameters. Since Xprobe2 does fuzzy ﬁngerprinting with a signature matching algorithm as an alternative to Nmap, it means that if we make a lot of changes to the default TCP/IP stack parameters, the underlying OS will not be detected. However, Xprobe2 is more robust to small ﬁngerprint variations as compared to Nmap. As explained above the other ﬁngerprinting tools, Ettercap [28] and p0f [42], have not been updated since 2011 and 2014 respectively to include variations of most widely used modern OSes. For passive OS ﬁngerprinting to be effective, we believe that the limitations of these ﬁngerprinting tools need to be addressed. The work in [23] also demonstrates that the OS ﬁngerprinting accuracy of the Ettercap and p0f signature databases is low and techniques to improve performance was proposed. Hence, the paper presents rule-based machine learning classiﬁers capable of identifying 75 classes of OSes from TCP/IP packet headers found in the Ettercap database. They proposed a classiﬁer technique using k-nearest neighbors (KNN) that returns an approximate ﬁrst match for an OS from a ﬁngerprint database. This counters the problem of classifying hosts as unknown if no exact match is found in the database [23]. However, their evaluation yielded poor experimental results, rejecting as much as 84% of the test packets, while 44% of the accepted patterns were wrongly classiﬁed [23]. The problems contributing to poor performance was believed to be caused by two main issues. The ﬁrst reason is substitution errors due to multiple OSes with exactly the same ﬁngerprint feature values. The second reason for this poor performance is the high rejection rate caused by numerous unique feature values derived from the same OS. After combining the OS classes most often confused with each other, eliminating all the classes where the error could not be reduced by combining classes, the error percentage was reduced to 9.8% with no rejected packets. A recent study that is most closely related to our work, and which has also given a comprehensive survey on passive ﬁngerprinting methods, can be found in [22]. The authors have employed OS ﬁngerprinting methods in the environment of wireless networks. Besides using the three basic TCP/IP stacks (i.e., TTL, window size, and initial SYN packet size), the authors suggested also using the user-agent information in HTTP request headers and communication with OS-speciﬁc domains can be usable in large dynamic networks [22]. The average accuracy of OS classiﬁcation using the TCP/IP parameters reported in [22] is 80.88%. Zhang et al.’s paper on OS detection [43] utilizes only one machine learning technique namely Support Vector Machine (SVM). However, the testing error rate of identifying some of the OSes e.g., Mac, Cisco, FreeBSD, and OpenBSD is 25.80%, 24.22%, 17.71%, and 15.85% respectively [43]. Aksoy et al. [2] have employed genetic algorithms for identifying packet features suitable for OS classiﬁcation based on the analysis of the network TCP/IP packets using machine learning algorithms. However, most of these previous works use the basic actual TCP/IP features for evaluating passive OS ﬁngerprinting. Besides, we believe that these tools have the inability to extract all possible OS-speciﬁc features for passively ﬁngerprinting the underlying OSes. In contrast, what separates our contribution in this paper from the other previous related works is that our model supports a wider range of TCP/IP network stack features. As shown in Figure 2, the main goal of our work presented here is to combine these basic TCP/IP features that are the basis of OS ﬁngerprinting with the underlying TCP variant by leveraging both machine learning and deep learning techniques. This contribution remains largely unexplored and is not used by existing ﬁngerprinting techniques. Detecting the implementation of a TCP variant passively is a challenging task and this, we believe, is the reason why no previous works use it to passively ﬁngerprint remote OSes. However, in our case, we already have a general solution for this difﬁculty presented in our previous works [11, 12, 13]. The reason why we focus on the implementations of the underlying TCP variant as a feature in our OS classiﬁer model is due to the fact that Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. different OSes are doing slightly different implementations of TCP. Hence, we believe that passively observing the network-level characteristics found in TCP packets can give us more information about the remote computer’s underlying OS. We further believe that this will also help us to explore in detail the long-term characteristics of TCP trafﬁc. To the best of our knowledge, this is the ﬁrst study of passive ﬁngerprinting OSes by applying RNN methods combining the basic TCP/IP features and the underlying TCP variant as input vectors. III. EXPERIMENTAL DATASETS Our machine learning models for OS classiﬁcation is developed and tested on three datasets, presented below. A. Benchmark Data First, we utilize a large benchmark dataset that has been used for OS ﬁngerprinting in a previous related work [22]. This dataset is closely aligned with our task. The benchmark dataset was used in the previous work for OS ﬁngerprinting based on the HTTP header, while the ambition of our paper is to do generic ﬁngerprinting based only on the TCP packet ﬁelds. Since we aim at ﬁngerprinting that is not application-speciﬁc, the TCP information in the dataset is useful for our purpose, while the HTTP User-agent information in our experiments is used only to establish ground truth about the OS that was used. The benchmark dataset contains 79087345 ﬂows, activity of 21746 unique users, 253374 WiFi sessions, 25642 unique MAC addresses, and 6104 unique IP addresses, a ﬁngerprint database of 2078 standard TCP/IP signatures of 51 known unique OSes with a total of 529 variations when considering major and minor versions [22]. It consists of three basic TCP/IP network stack features, i.e., initial SYN packet size, TTL, and TCP window size [22]. After our ﬁrst set of testing, we realized that the data was severely skewed and that only a few of the classes contained almost all of the entries, giving us artiﬁcially good classiﬁcation results. We then removed most of the very seldom occurring classes and ended up with 33 reduced classes. We also removed all trafﬁc that did not contain HTTP User-agent information, since we could not establish ground truth for this trafﬁc. In addition, we created a new dataset where all the classes were bucketed into seven groups, consisting of the six most widely used major OS families: Android, Linux, Mac OS, Unix, Windows, iOS, and a seventh class called “Other” for OSes not suited for any of the other groups. Finally, we ended up distributing all of the labels equally so that each OS class had the same number of occurrences. This helps us improve the generalizability of our model with a uniﬁed approach that encompasses all variations of the most widely used OSes. B. Realistic Trafﬁc While benchmark trafﬁc is useful to link our experiments to previous related work, we also wanted additional realistic trafﬁc for which we have more control, and that allows us to make our own assurances of the quality of the data. Thus, we passively collected our realistic dataset from TCP trafﬁc originated from the internal network of the Oslo Metropolitan University and destined to various hosts on the Internet. First, we collected data for ﬁxed (non-mobile) desktop computers (typically using OSes like Windows, Linux, Unix, Mac OSx, etc.) by using an intermediate node as shown in the network setup in Figure 1. Then, we passively collected the data that covered mobile devices, like android and iOS. The latter was collected from the 5G 4IoT research lab [1, 34] of the Oslo Metropolitan University. We spent a signiﬁcant amount of effort in establishing ground truth, i.e., determining the actual OS that has been used for each trafﬁc ﬂow. To establish ground truth in the realistic dataset, we follow two approaches. The ﬁrst approach was only applicable to the non-mobile desktops, while the second method was used for both mobile and non-mobile devices. With the ﬁrst method, we leveraged the DHCP log messages associated with the non-mobile desktops to derive the ground truth from the DHCP server of the Oslo Metropolitan University network that logs the sessions by the MAC address and name of the device. Since we collect the real data from the internal network of our university, extracting the DHCP log messages can give us detailed information about the OSes. We could, for example, see information about the vendor-speciﬁc preﬁxes since most of the OS variants are identiﬁed based on their vendors. The list of device vendor preﬁxes is useful in revealing the speciﬁc implementation of an OS because most of the modern OSes from the same device vendor usually share the same OS kernel and similar network behaviors. For example, we found out that Apple products often share the same TCP/IP parameters. The second approach we used to identify the OS is getting the predeﬁned browser strings that loosely tell the name of the underlying OS assigned by the vendor from Webserver. We believe changing the default device names by all users is not that common and sometimes discouraged by the vendors, e.g., Google and Apple OSes. However, the device name of Linux and Windows OSes could be changed easily by experienced users which would make passively identifying these devices hard. Since a number of computer vendors offer devices with a pre-installed OS and default device name and MAC address, we can use this information to derive the ground truth for OS ﬁngerprinting. For example, Apple devices use a default string name of “<user>-iPhone”, “<user>-iPad”, Microsoft uses “Windows-Phone” for its mobile devices, and Android uses “android-<android−id>”, etc. Our real trafﬁc covers the communication to and from our university and hence all trafﬁc whose source and destination IP addresses are within the subnets of our internal network. Hence the network administrator of our university has full control over the internal machines with real IP addresses that are not going to a NAT gateway, and therefore it is fairly possible to tell whether it is a laptop or a desktop PC by looking it up in the internal database owned by the university. However, since it is a dynamic network we do not have full control over external machines, because they can be anything behind an IP address that changes dynamically. This is because there is an endless number of machines spooﬁng scanning the network and they can appear as Linux-powered OSes but they could be Windows and vice versa and this happens because the user may have strongly tuned the TCP stack to look like something else. It is pretty hard to certainly say anything about the external computers because the communication can go through a NAT gateway possessing another OS type. For example, if a user is connected to a student wireless network, there is a chance that it may go to a Linux NAT gateway, and hence from outside the user is Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. seen as Linux NAT which makes it hard to predict whether the underlying OS is Linux, Mac or Windows. Therefore, ﬁngerprinting devices behind NAT technology on a distributed network where a number of devices can hide behind a NAT is another critical challenge. It is, therefore, worth noting that establishing ground truth in dynamic networks at a larger scale remains a challenging problem. Further investigation to explore these difﬁculties will be done in our future works. Finally, due to the privacy protection of possibly sensitive data, the payload of all the network packets collected was removed and anonymized with a preﬁx-preserving algorithm [7, 39]. Furthermore, we were only allowed to collect TCP headers of the trafﬁc ﬂows, while we could not collect complete trafﬁc captures, due to privacy protection and legal reasons. OS Prediction Fingerprinter using Machine Learning/ Deep Learning Input features Packet Size Window Size TTL TCP Variant Oracle Predicted TCP Variant 1. Baseline Experiment 2. Oracle-based Experiment 3. Prediction-based Experiment Fig. 2: The process implemented on the intermediate node for passive OS ﬁngerprinting. Bytes in Flight Predicted TCP Variant Predicted cwnd Intercepted Traffic Deep Learning/LSTM Fig. 3: The process implemented on the monitor for prediction of the TCP variant of the passively intercepted TCP trafﬁc ﬂow. An LSTM-based machine learning module predicts the cwnd from the outstanding bytes-in-ﬂight. In the next step, the cwnd behavior is used to predict the TCP variant as explained in further detail in our previous works [11, 12, 13]. The predicted TCP variant is ﬁnally used as an input feature to the OS ﬁngerprinting process (see bottom right part of Figure 2). C. Emulated Trafﬁc In a real scenario where the OS ﬁngerprinting is going on continuously in an intermediate node of an enterprise or production network, the intermediate node will have more information available than only the TCP header, such as the trafﬁc proﬁle or the knowledge of congestion or the outstanding bytes-in-ﬂight of a ﬂow. In our experiments below, we show how this information can be very useful for OS ﬁngerprinting. Since we do not have full trafﬁc packet captures in our benchmark dataset or in our realistic dataset, we needed an additional dataset that we collected from an emulated network, where there would be no privacy protection or legal issues related to our dataset. The architecture of our emulated network is similar to the network setup shown in Figure 1, except that all the nodes (the sender, the intermediate node, and the receiver) are implemented in virtual machines. All background trafﬁc of the OSes for our emulated scenario is generated using the iperf [6]. Establishing ground truth is straightforward, as we have full control of the OSes used when generating the trafﬁc. In addition to establishing the ground truth, we also wanted to allow the intermediate node to establish a prediction of the TCP variant by monitoring the on-going trafﬁc proﬁle of the TCP ﬂow between the sender and the receiver. As shown later in the paper, using deﬁnitive or predicted knowledge of the TCP variant as an additional input feature to the OS ﬁngerprinting, might boost the ﬁngerprinting accuracy signiﬁcantly. How the machine learning model for prediction of the TCP variant in the emulated scenario is trained and how the TCP variant is subsequently predicted are presented in the following. IV. MACHINE LEARNING OF THE OS FINGERPRINTER A. Classical Machine Learning Approaches The OS ﬁngerprinter takes various features as input parameters, and use machine learning to predict the OS as shown in Figure 2. Many machine learning techniques could be used to implement a model for passive OS ﬁngerprinting. In this paper, we have employed the following most commonly used classical machine learning methods suitable for our task. In order to train and test our classiﬁcation models, we employed every experiment with a ratio of 60% training, 40% testing split, and 5-fold cross-validation setting on all variations of the features into one learning model. SVM: In order to perform an efﬁcient multi-class SVM classiﬁcation through cross-validation, we tuned the SVM hyperparameters using a GridSearchCV that allows specifying only the ranges of values for optimal parameters by parallelization construction of the model ﬁtting. Finally, in our evaluation, we found out that SVM with a Radial Basis Function (RBF) kernel for classiﬁcation model yields a substantially better result. Random Forest (RF): We tuned the meta-estimator by varying the number of decision trees between 1 and 1000. We found out that increasing the number of trees more than 10 doesn’t give much improvement in the classiﬁcation accuracy. KNN: We applied KNN by testing different values of K ranging from 5 to 100 followed by a weight function for a total of 20 observations. The observations have been conducted in two ways. In the ﬁrst experiment, we set the weight to uniform. In the second experiment, the points are weighted by the inverse of their distance, causing closer neighbors to have greater inﬂuence. Finally, we choose the model that has the highest accuracy for a given unseen instance. B. Deep Learning Approaches To ﬁnd the deeper characteristics of TCP variants implemented by respective OSes and exploit the extra OS-speciﬁc information, we apply the following two neural network architectures. Multilayer Perceptron (MLP): In our evaluation, MLP model with a single-layer feedforward neural network [16, 32] has been used to classify the different classes of OSes. After the hyperparameter tuning, we tested our MLP model with a different number of batch sizes, hidden layers, and nodes Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. (e.g., 0, 1, 2, 32, 64, 128) in each layer. Combining all of these, a total of 324 models were trained with and without the default TCP variant. We found out that the results for both with and without a known TCP variant were almost the same with an insigniﬁcant drop in the accuracy irrespective of which hyperparameters performed the best. Finally, 128 nodes of the network per dataset are trained for 150 epochs with a batch size of 500 by SGD with momentum of 0.9 and a constant learning rate of 0.01. However, we learned that SGD is sensitive in regards to the selection of the learning rate since it doesn’t automatize the values and we also found that it suffers from premature convergence and is outperformed by Adam-based optimization methods. Hence, both Adam and Nadam gradient-based optimization algorithms ﬁt for our purpose and that is because we wanted to use an optimization algorithm that adapts its learning rate dynamically in a way that doesn’t affect the objective function and learning process of the model. Our experimental results show that the hyperparameter tuning baseline experiments by applying tanh as activation function and Adam optimization algorithm and training the model for 150 epochs, provides a substantial improvement in accuracy as compared to the other parameters. Long Short-Term Memory (LSTM) models: We have explored an approach to classify the underlying OS from passive measurements using LSTM-based RNN architecture by combining the basic TCP/IP features and the underlying TCP variant shown in Table 2 as input vectors. For more details about LSTM applied in the context of computer networks, we refer the reader to our previous paper [12]. We trained our LSTM model over 150 epochs of the training samples with a batch size of 32 as values in time-series. We propagate the input feature vector (x) to the model through a multilayer LSTM cell followed by a fully connected dense layer of 150 hidden nodes with Rectiﬁed Linear Unit (ReLU) activation function using the hard sigmoid as recurrent activation for the different layers that generates an output of a sequence dimensional vector of predicted OSes (yt). We trained our LSTM-based learning algorithm without the knowledge of the input features from the true signatures of the OSes during the learning phase. We learn the model from the training data and then ﬁnally predict the test labels from the testing instances on all variations of the OS-speciﬁc parameters. In order to train our prediction model more quickly, and get a more stable and robust to changes OS classiﬁcation model, we have applied one of the most effective optimization algorithms in the deep learning community, the Adam stochastic algorithm [19] with an initial learning rate of 0.001 and exponential decay rates of the ﬁrst (β1) and second (β2) moments set to 0.9 and 0.999 respectively. We further optimize a wide range of important hyperparameters related to the neural network topology to improve the performance of our OS classiﬁcation model. C. Experimental Hardware Setup All our machine learning experiments are carried out using a cluster of HPC machines based upon the GNU/Linux operating system running a modiﬁed version of the 4.15.0-39-generic kernel release. The prediction model is performed on an NVIDIA Tesla K80 GPU accelerator computing with the following characteristics: Intel(R) Xeon(R) CPU E5-2670 v3 @2.30GHz, 64 CPU processors, 128 GB RAM, 12 CPU cores running under Linux 64-bit. All nodes in the cluster are connected to a low latency 56 Gbit/s Inﬁniband, gigabit Ethernet, and have access to 600 TiB of BeeGFS parallel ﬁle system storage. D. Objectives of our Experiments The aim of our experiments is to explore the effect of the TCP variant as an input feature when passively detecting the underlying OS. To investigate this, we divide our analysis into three different experiments. First, in the baseline experiment (Section VI) we carry out the OS ﬁngerprinting without using a known TCP variant as an input feature. This corresponds to the simplest state-of-the-art transport layer method, which is illustrated in the upper part of Figure 2. Since there is a close connection between existing popular OSes and the TCP variants they use, our hypothesis was that the potential for improvement by using the TCP variant as an input feature would be signiﬁcant. For example, CUBIC [9] is the default congestion control algorithm as part of the Linux kernel distribution conﬁgurations from version 2.6.19 onwards. Since Android devices are also Linux-powered, CUBIC remains to be the default TCP congestion control algorithm. Many Windows 7 distributions have been shipped with the default New Reno [15] and whereas Windows 8 families with CTCP [37]. Therefore, in the next Oracle-based experiment (Section VII), we investigate the potential of knowing the TCP variant, and how much this knowledge might boost the ﬁngerprinting accuracy. Here we assume that there is an Oracle that can identify and give the TCP variant used in the TCP ﬂow that is ﬁngerprinted. This is illustrated in the bottom left part of Figure 2. However, in a real scenario, the intermediate node would not have access to deﬁnite knowledge of the TCP variant (e.g., given by an Oracle). Instead, the intermediate node might at best try to infer it from the monitored trafﬁc. Thus, in the third prediction-based experiment (Section VIII), we ﬁrst allow the intermediate node to predict the TCP variant passively. This is illustrated in the bottom right part of Figure 2. The OS ﬁngerprinter then uses that TCP variant prediction as an input feature to make the OS prediction illustrated in the upper part of Figure 2. The TCP variant is predicted by analyzing the famous sawtooth pattern behavior of estimated cwnd of TCP, which is computed based on the outstanding bytes-in-ﬂight [12, 13]. This is presented in more detail in the next section. Since the latter experiment requires TCP trafﬁc details of outstanding bytes-in-ﬂight, which is not available in our benchmark and realistic datasets, this experiment is only possible with our emulated dataset. V. MACHINE LEARNING OF THE TCP VARIANT PREDICTION TOOL The main goal of the experiments in the emulated network is to use the predicted TCP variant as an additional input feature to the OS ﬁngerprinting. The TCP variant is predicted by the process illustrated in Figure 3. As described in sufﬁcient detail in our previous works [11, 12, 13], we used a database to match and join the intercepted TCP trafﬁc on both the intermediate node and the sending node. The outstanding bytes-in-ﬂight of the trafﬁc (i.e., the number of bytes that have been sent but not yet acknowledged) is used as input to our machine learning model to predict the cwnd behaviour of the trafﬁc. We use LSTM for the machine learning. We trained and veriﬁed the machine learning model by matching the Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. predicted TCP states with the actual TCP kernel states directly logged from the Linux kernel. Since we have full control of the sending nodes, we can track the system-wide TCP state of every packet that is sent and received from the kernel to verify our model’s prediction accuracy against the actual TCP variant by matching with the actual sending TCP states using the techniques presented in our previous works [11, 12, 13]. After the veriﬁcation, we can run our learning model and get the cwnd predictions of the TCP stack in use. Once we can estimate the cwnd of the sender, we can also infer the multiplicative back-off factor (β) which is an important feature for uniquely identifying the TCP variants. Finally, we combine the predicted TCP variant as the basis of OS ﬁngerprinting with the basic TCP/IP features as shown in Figure 2. Here, we consider only loss-based TCP congestion control algorithms, e.g., BIC [40], CUBIC [9], CTCP [37], Reno [17], and New Reno [15]. Delay-based TCP variants are investigated in a follow-on paper [14]. Our approach could also be useful to other TCP variants like Google’s QUIC [21]. QUIC uses packet loss as an indicator of congestion and supports a number of different congestion control algorithms, including CUBIC [9] and BBR [3]. VI. BASELINE EXPERIMENT: RESULTS WITHOUT KNOWING THE TCP VARIANT Here we present the results of the machine learning and deep learning techniques under all the validation scenarios presented above without a known underlying TCP variant which will play the role of baseline for the other evaluations. A. Based on Benchmark Data from Previous Related Work Looking at Tables I and II, both machine learning and deep learning classiﬁcation techniques have consistently achieved good levels of precision and recall for all general classes of OSes except iOS. Quantitatively, iOS, and Mac OS devices were underrepresented in the benchmark data from previous related work. Besides, as it is shown in Figures 4, there is a slightly higher misclassiﬁcation of iOS as unknown and this is why the precision and recall of iOS are comparably lower than the rest of OSes. We also believe that the limited TCP/IP stack basic features could contribute to the indistinguishability and misclassiﬁcation of OS classes with the same kernel implementation. The false positives are easier to notice in the corresponding confusion matrices. TABLE I: Benchmark data [22] experimental results without a known TCP variant using SVM, RF, and KNN. SVM RF KNN OS Precission Recall Precision Recall Precision Recall Android 0.74 0.88 0.87 0.91 0.87 0.91 Linux 0.85 0.85 0.91 0.90 0.91 0.90 Mac OS 0.65 0.77 0.61 0.83 0.58 0.88 Other 0.91 0.81 0.92 0.81 0.92 0.81 Unix 0.91 0.99 0.94 0.99 0.94 0.99 Windows 0.97 0.88 0.98 0.91 0.98 0.91 iOS 0.73 0.55 0.72 0.53 0.79 0.47 Average 0.83 0.82 0.85 0.84 0.86 0.84 Accuracy 81.96% 84.07% 83.95% B. Based on Realistic Trafﬁc Our performance results of the realistic trafﬁc without a known TCP variant using the machine learning and deep techniques are presented in Tables III and IV respectively. The respective confusion matrices are presented in Figures 5. TABLE II: Benchmark data [22] experimental results without a known TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.75 0.92 0.77 0.85 Linux 0.90 0.82 0.83 0.85 Mac OS 0.62 0.81 0.58 0.83 Other 1.00 0.74 0.91 0.81 Unix 0.94 0.99 0.94 0.99 Windows 0.97 0.91 0.97 0.86 iOS 0.67 0.57 0.79 0.48 Average 0.84 0.82 0.83 0.81 Accuracy 82.16% 81.04% TABLE III: Realistic trafﬁc experimental results without a known TCP variant using SVM, RF, and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.75 0.89 0.86 0.90 0.84 0.93 Linux 0.89 0.82 0.94 0.89 0.93 0.88 Mac OS 0.63 0.81 0.61 0.82 0.61 0.82 Unix 0.94 0.99 0.94 0.99 0.94 0.99 Windows 0.97 0.89 0.98 0.89 0.98 0.89 iOS 0.88 0.72 0.86 0.73 0.88 0.72 Average 0.85 0.83 0.86 0.85 0.87 0.85 Accuracy 83.43% 85% 85.10% TABLE IV: Realistic trafﬁc experimental results without a known TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.81 0.83 0.76 0.86 Linux 0.89 0.79 0.90 0.81 Mac OS 0.61 0.82 0.82 0.79 Unix 0.92 0.99 0.94 0.99 Windows 0.98 0.89 0.97 0.89 iOS 0.84 0.73 0.70 0.92 Average 0.84 0.83 0.83 0.84 Accuracy 83.91% 83.27% C. Based on Emulated Trafﬁc Our performance results of the emulated trafﬁc without a known TCP variant as an input feature using both machine learning and deep learning techniques are presented in Tables V and VI respectively. As we can see in the corresponding confusion matrices presented in Figures 6, there is a slightly inaccurate classiﬁcation of the Mac OS due to its underrepresentation. The precision and recall for the rest of the OSes using machine learning and deep learning techniques are reasonably good. TABLE V: Emulated trafﬁc experimental results without a known TCP variant using SVM, RF and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.74 0.90 0.86 0.90 0.85 0.91 Linux 0.92 0.82 0.94 0.89 0.92 0.90 Mac OS 0.63 0.81 0.61 0.82 0.61 0.82 Unix 0.94 0.99 0.94 0.99 0.94 0.99 Windows 0.97 0.89 0.98 0.89 0.98 0.89 iOS 0.88 0.73 0.86 0.73 0.88 0.73 Average 0.85 0.84 0.86 0.85 0.87 0.85 Accuracy 84.67% 85.73% 85.27% D. Comparison of Results Without Known TCP Variant As shown in Tables I, II, III, IV, V, and VI, our experimental results are pretty consistent. Firstly, we can see that there is not much difference in performance across different machine learning and deep learning techniques. But more importantly, there are not many differences in performance between results from using different types of Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. (a) SVM (b) KNN (c) RF (d) MLP (e) LSTM Fig. 4: Confusion matrix comparison of the machine learning and deep learning techniques using the benchmark data [22]. (a) SVM (b) KNN (c) RF (d) MLP (e) LSTM Fig. 5: Confusion matrix comparison of the machine learning and deep learning techniques using a realistic trafﬁc. TABLE VI: Emulated trafﬁc experimental results without a known TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.75 0.88 0.91 0.85 Linux 0.93 0.78 0.92 0.74 Mac OS 0.62 0.81 0.86 0.88 Unix 0.92 0.99 0.94 1.00 Windows 0.93 0.91 0.98 0.73 iOS 0.88 0.73 0.82 1.00 Average 0.85 0.83 0.89 0.88 Accuracy 84.05% 88.44% experimental data. This is intuitively correct, since the OS ﬁngerprinting is based on the basic TCP/IP packet ﬁelds, and should not differ much between various types of data, whether we do evaluation using the benchmark data, real data or emulated data. Secondly, we believe accuracy in the range of 82-88% (average value) is perhaps not sufﬁcient for a product in a real deployment. Our hypothesis is that this accuracy could be boosted considerably had we only known the implementation of the underlying TCP variant. We will explore this hypothesis in the next section. VII. ORACLE-BASED EXPERIMENT: RESULTS USING ORACLE-GIVEN TCP VARIANT Here we assume that we know exactly the underlying TCP variant, i.e., we assume it is given by an Oracle. We show that knowledge of the TCP variant has a great potential for boosting passive ﬁngerprinting of OSes, and in this section, we will try to quantify this potential. In the next section, we will show that much of this potential can be harvested by using a tool that predicts the TCP variant. A. Based on Benchmark Data from Previous related Work Tables VII and VIII show a signiﬁcant performance gain across all classes of OSes when we assume prior knowledge of the underlying TCP variant, as compared to the results when the TCP variant is unknown presented in Tables I and II. TABLE VII: Benchmark data [22] experimental results with Oracle-given TCP variant using SVM, RF and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.96 0.99 0.99 0.98 0.99 0.98 Linux 0.86 0.95 0.92 0.95 0.93 0.94 Mac OS 0.98 0.89 0.97 0.92 0.97 0.92 Other 0.93 0.81 0.93 0.81 0.90 0.83 Unix 1.00 1.00 1.00 1.00 1.00 1.00 Windows 0.99 0.89 0.97 0.92 0.99 0.91 iOS 0.75 0.89 0.75 0.91 0.76 0.91 Average 0.92 0.92 0.93 0.93 0.93 0.93 Accuracy 91.71% 92.73% 92.69% TABLE VIII: Benchmark data [22] experimental results with Oracle-given TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.96 0.97 0.94 0.97 Linux 0.89 0.92 0.88 0.93 Mac OS 0.96 0.92 0.97 0.88 Other 0.93 0.81 0.84 0.84 Unix 1.00 1.00 1.00 1.00 Windows 0.96 0.92 0.98 0.84 iOS 0.76 0.89 0.73 0.83 Average 0.92 0.92 0.91 0.90 Accuracy 91.91% 90.03% B. Based on Realistic Trafﬁc The performance results of the realistic trafﬁc with the Oracle-given TCP variant presented in Tables IX and X show the potential of knowing TCP variant given by an Oracle for passive OS ﬁngerprinting in a realistic scenario. TABLE IX: Realistic trafﬁc experimental results with Oracle-given TCP variant using SVM, RF and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.95 1.00 0.99 0.98 0.99 0.98 Linux 0.86 0.91 0.94 0.93 0.92 0.94 Mac OS 0.99 0.90 0.96 0.92 0.97 0.92 Unix 1.00 1.00 1.00 1.00 1.00 1.00 Windows 0.99 0.89 0.99 0.89 0.99 0.89 iOS 0.93 0.96 0.91 0.99 0.92 0.98 Average 0.95 0.95 0.96 0.96 0.96 0.96 Accuracy 94.81% 95.65% 95.69% Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. TABLE X: Realistic trafﬁc experimental results with Oracle-given TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.98 0.97 0.98 0.97 Linux 0.92 0.92 0.90 0.93 Mac OS 0.96 0.92 0.96 0.92 Unix 1.00 1.00 1.00 1.00 Windows 0.97 0.91 0.99 0.88 iOS 0.92 0.97 0.91 0.98 Average 0.95 0.95 0.95 0.95 Accuracy 94.98% 94.89% C. Based on Emulated Trafﬁc Our performance results of the emulated trafﬁc with the Oracle-given TCP variant using both classical machine learning and deep learning techniques are presented in Tables XI and XII. We can see that this shows a signiﬁcant improvement in performance over the results without a known TCP variant presented in Tables V and VI. Both machine learning and deep learning techniques have comparable and consistent results in terms of accuracy. TABLE XI: Emulated trafﬁc experimental results with the Oracle-given TCP variant using SVM, RF, and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.97 0.98 0.99 0.98 0.99 0.98 Linux 0.90 0.91 0.95 0.93 0.92 0.95 Mac OS 0.99 0.90 0.97 0.92 0.97 0.92 Unix 1.00 1.00 1.00 1.00 1.00 1.00 Windows 0.99 0.89 0.97 0.91 0.97 0.91 iOS 0.91 0.98 0.92 0.98 0.93 0.97 Average 0.95 0.95 0.96 0.96 0.96 0.96 Accuracy 95.10% 96.02% 95.83% TABLE XII: Emulated trafﬁc experimental results with the Oracle-given TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.98 0.97 0.96 0.98 Linux 0.97 0.89 0.93 0.91 Mac OS 0.93 0.94 0.94 0.92 Unix 1.00 1.00 1.00 1.00 Windows 0.99 0.89 0.98 0.88 iOS 0.91 0.99 0.91 0.97 Average 0.95 0.95 0.95 0.95 Accuracy 95.24% 95.08% D. Comparison of Results with Oracle-given TCP Variant Our accuracy results presented in Tables VII, VIII, IX, X, XI, and XII, demonstrate that by knowing the TCP variant we obtain a considerable performance boost in all our experimental results, compared to our previous results obtained without knowledge of the TCP ﬂavor. With an Oracle-given TCP variant, we obtain a prediction accuracy of 94-96%, with an average value of 94.1% over all trafﬁc classes and of 95.4% over only emulated trafﬁc. The accuracy results are pretty consistent across all scenarios. Comparing these results with our previous results that do not use the Oracle (84.1% on average for all trafﬁc types and 85.6% only for emulated trafﬁc), we observe a solid increase in the OS ﬁngerprinting performance. This improvement would signiﬁcantly boost the usefulness of a product to be implemented in a real enterprise network infrastructure. As in the previous section, here again, we observe highly consistent performance results across different machine learning and deep learning techniques and also between the use of different types of experimental data. The latter is useful knowledge for the next section since it means that performance increases obtained over one trafﬁc type is shown to be amenable to other trafﬁc types as well. In the next section, we will have to base our evaluation on emulated data, since we do not have the TCP trafﬁc patterns of the realistic data or benchmark data at hand. These trafﬁc patterns are required to be able to passively infer the TCP variant in the experiments presented in the next section. In this section, the idealistic Oracle was used only to demonstrate the potential of knowing the TCP variant, but this is not a realistic assumption. Thus, in the next section, we will instead base our evaluation on a TCP variant that is passively predicted by a deep learning-based tool that we developed and presented in our previous work [11, 12, 13]. Using this tool, we explore how close our performance will get to the ideal solution of having an Oracle. VIII. PREDICTION-BASED EXPERIMENT: RESULTS USING TCP VARIANT PREDICTION In Section VII, we showed that Oracle-given knowledge of the TCP variant has a great potential for improving the passive OS ﬁngerprinting. In reality, however, we don’t have an Oracle-given TCP variant. Since passively detecting the TCP variant is a challenging task, this is where our tool from previous works on predicting the underlying TCP variant from passive measurements [11, 12, 13] comes into play. In this Section we use the TCP variant passively predicted by this tool as an input feature for the passive OS ﬁngerprinting. The TCP variant is inferred from the famous Additive Increase and Multiplicative Decrease (AIMD) sawtooth pattern of TCP’s estimated cwnd computed based on the outstanding bytes-in-ﬂight. Since we don’t have access to the actual cwnd of the senders in the benchmark data and realistic trafﬁc, here we consider only the emulated trafﬁc. A. Based on Emulated Trafﬁc In this section, we use a tool to predict the TCP variant from passive measurements of TCP trafﬁc patterns, and this prediction is used as input to the passive OS ﬁngerprinting method presented above. The experimental results of both techniques are presented in Tables XIII and XIV. TABLE XIII: Emulated trafﬁc experimental results with predicted TCP variant using SVM, RF, and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.92 0.96 0.92 0.97 1.00 0.97 Linux 0.79 0.85 0.94 0.82 0.92 0.94 Mac OS 0.96 0.88 0.97 0.87 0.85 0.94 Unix 1.00 1.00 1.00 1.00 1.00 1.00 Windows 0.92 0.78 0.85 0.80 0.88 0.91 iOS 0.85 0.94 0.86 0.96 0.93 0.87 Average 0.90 0.90 0.91 0.91 0.93 0.93 Accuracy 90.01% 91.09% 92.15% TABLE XIV: Emulated trafﬁc experimental results with predicted TCP variant using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.95 0.97 0.92 0.96 Linux 0.98 0.79 0.86 0.90 Mac OS 0.95 0.90 0.95 0.88 Unix 1.00 1.00 1.00 1.00 Windows 0.94 0.77 0.97 0.77 iOS 0.82 0.99 0.88 0.96 Average 0.92 0.91 0.92 0.92 Accuracy 91.45% 91.93% Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. (a) SVM (b) KNN (c) RF (d) MLP (e) LSTM Fig. 6: Confusion matrix comparison of the machine learning and deep learning techniques using an emulated trafﬁc. B. Comparison of results with a predicted TCP variant Results with emulated data and a passive prediction of the TCP variant (Tables XIII and XIV) gives an accuracy of 91.3% on average, which comes pretty close to the accuracy of 95.4% obtained on emulated trafﬁc with the TCP-variant given by the Oracle. Intuitively, when we do learning based on the TCP variant prediction, the accuracy must be lower than the Oracle-given TCP variant, but the question is how close we can get to the idealistic scenario of having an Oracle. Our results show that using our tool for TCP variant prediction gives reasonably good OS ﬁngerprinting accuracies that come close to the results obtained by using Oracle-given TCP variant. Even though the performance results with the TCP variant passively predicted by our deep learning-based tool are slightly lower as compared to the TCP variant given by an idealistic Oracle, our performance results of using our tool are reasonably competitive. IX. TRANSFER LEARNING RESULTS Transfer learning is the ability to take a model trained in one scenario and apply it for classiﬁcation in a different scenario. For example, in our case, that means we are able to train our model on a dataset created in an emulated network with an Oracle-given TCP variant and apply it for classiﬁcation of our dataset from the realistic trafﬁc. Results shown in Tables XV and XVI shows that the learning of the OS ﬁngerprinter transfers well into other scenarios. Good transfer learning results indicate that our passive OS ﬁngerprinting model is able to discern the results of unforeseen scenarios and still perform reasonably well. In previous works, we have also demonstrated that the TCP variant predictor performs well in terms of transfer learning [11, 12, 13]. TABLE XV: Transfer learning experimental results using SVM, RF, and KNN. SVM RF KNN OS Precision Recall Precision Recall Precision Recall Android 0.95 1.00 0.98 0.98 0.99 0.98 Linux 0.86 0.91 0.90 0.95 0.92 0.95 Mac OS 0.99 0.90 0.98 0.92 0.97 0.92 Unix 1.00 1.00 1.00 1.00 1.00 1.00 Windows 0.99 0.89 0.98 0.90 0.97 0.91 iOS 0.93 0.96 0.93 0.97 0.93 0.97 Average 0.95 0.95 0.95 0.95 0.96 0.96 Accuracy 94.79% 95.35% 95.76% X. CONCLUSION AND FUTURE WORK In this paper, we proposed and evaluated a novel approach that attempts to passively ﬁngerprint the underlying remote OS by leveraging state-of-the-art machine learning and deep learning techniques under multiple controlled scenarios. We TABLE XVI: Transfer learning experimental results using MLP and LSTM. MLP LSTM OS Precision Recall Precision Recall Android 0.97 0.98 0.97 0.96 Linux 0.95 0.85 0.91 0.91 Mac OS 0.94 0.94 0.96 0.90 Unix 1.00 1.00 1.00 1.00 Windows 0.99 0.89 0.98 0.87 iOS 0.90 0.98 0.90 0.98 Average 0.95 0.95 0.94 0.94 Accuracy 94.72% 94.28% show that knowing the Oracle-given TCP variant has a great potential for boosting the classiﬁcation performance of passive OS ﬁngerprinting. In our setting, we demonstrate that using the idealistic Oracle has the potential to boost the prediction accuracy from 84.1% to 94.1% on average across all trafﬁc types tested, and from 85.6% to 95.4% in an emulated setting. However, in reality, we don’t have the Oracle-given TCP variant and hence we don’t know exactly the underlying TCP ﬂavor. To address this, we demonstrated a method for passive OS ﬁngerprinting where the cwnd is ﬁrst computed based on the outstanding bytes-in-ﬂight, then the underlying TCP ﬂavor is predicted from the estimated cwnd, and ﬁnally, the predicted TCP variant is used as an input feature to detect the remote computer’s OS. This is an additional feature that is added to the basic TCP/IP features that are the basis of OS ﬁngerprinting in previous works. We demonstrate that our method performs signiﬁcantly better than not using the predicted TCP variant as an input feature, increasing the accuracy in our experiment from 85.6% to 91.3%. The results of this method come close to the accuracy of 95.4% obtained by using the idealistic Oracle. To the best of our knowledge, this is the ﬁrst study that reports the potential of the underlying TCP feature in boosting signiﬁcantly the accuracy of passive OS ﬁngerprinting. We further validate and demonstrate the transferability approach of our OSes classiﬁcation models by conducting a series of controlled experiments against other scenarios. Through comparing the experimental results between the benchmark dataset, realistic, and emulated trafﬁc in terms of accuracy and confusion matrix, it is clear that our passive OSes classiﬁcation models are able to discern the results to unforeseen scenarios. Therefore, we are able to show that the learned passive OS ﬁngerprinting model by leveraging a pre-trained knowledge of classiﬁcation techniques from the emulated network performs reasonably well as it is shown in the experimental results when it is applied and transferred to a realistic scenario. Lastly, in all our experiments, we made sure that both the training and validation accuracies are closer which gives an idea about the ability of the OSes classiﬁcation models to generalize on unforeseen scenarios. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply. The method presented in this paper, where the cwnd is ﬁrst computed based on the outstanding bytes-in-ﬂight, then the underlying TCP ﬂavor is predicted from the estimated cwnd, is particularly efﬁcient for loss-based TCP variants. In previous works, we have also developed a tool for the prediction of delay-based TCP ﬂavors [10]. We plan to extend the method presented in this paper to also cover delay-based TCP variants and present it in a follow-on paper [14]. Note that passively detecting the TCP variant is a challenging task, which led to a two-step approach, where the TCP variant prediction of a deep learning-based tool is used as input to another machine learning method in the next step. However, by integrating the two machine learning approaches better, there should be potential for increasing the performance even further and get even closer to the idealistic results of using an Oracle. Exploring such optimizations is also left for future work. It is known that TCP clock drift improves OS ﬁngerprinting and hence measuring differences in the timing of how the IP stack works may allow us to predict the underlying OS with greater assurance in terms of accuracy. We, therefore, argue for using other TCP options like timestamps and queueing delay characteristics as an input feature vector for passive OSes ﬁngerprinting model as another interesting direction. Finally, in addition to the difﬁculties of establishing ground truth (e.g., the TCP variant) at a larger scale on a dynamic network addressed in Section III, there is a lot of other work to be done as an extension of our work presented here. For example, addressing answers to valid questions like: What happens if an end-user (client) changes default parameters that are the basis of OS ﬁngerprinting? is one possibility for our future work. We expect that end-users don’t change parameters often, while servers may do so if it helps improve performance. We believe this would make OS ﬁngerprinting potentially hard. REFERENCES [1] 5G4IoT. 5G4IoT, 2019. [2] A. Aksoy, S. Louis, and M. H. Gunes. Operating system ﬁngerprinting via automated network trafﬁc analysis. In IEEE Congress on Evolutionary Computation (CEC). IEEE, 2017. [3] N. Cardwell, Y. Cheng, C. S. Gunn, S. H. Yeganeh, and V. Jacobson. BBR: Congestion-based congestion control. 2016. [4] W. R. Cheswick, S. M. Bellovin, and A. D. Rubin. Firewalls and Internet security: repelling the wily hacker. Addison-Wesley Longman Publishing Co., Inc., 2003. [5] N. Davids. Initial TTL values, 2011. [6] ESnet. iperf3, 2017. [7] J. Fan, J. Xu, M. H. Ammar, and S. B. Moon. Preﬁx-preserving IP address anonymization: measurement-based security evaluation and a new cryptography-based scheme. 2004. [8] L. G. Greenwald and T. J. Thomas. Toward Undetected Operating System Fingerprinting. WOOT, 7:1–10, 2007. [9] S. Ha, I. Rhee, and L. Xu. CUBIC: a new TCP-friendly high-speed TCP variant. ACM SIGOPS, 2008. [10] D. H. Hagos, P. E. Engelstad, and A. Yazidi. Classiﬁcation of Delay-based TCP Algorithms From Passive Trafﬁc Measurements. In 18th NCA. IEEE, 2019. [11] D. H. Hagos, P. E. Engelstad, A. Yazidi, and Ø. Kure. A machine learning approach to TCP state monitoring from passive measurements. pages 164–171. IEEE, 2018. [12] D. H. Hagos, P. E. Engelstad, A. Yazidi, and Ø. Kure. Recurrent Neural Network-based Prediction of TCP Transmission States from Passive Measurements. In NCA, pages 1–10. IEEE, 2018. [13] D. H. Hagos, P. E. Engelstad, A. Yazidi, and Ø. Kure. Towards a Robust and Scalable TCP Flavors Prediction Model from Passive Trafﬁc. In 2018 27th ICCCN, pages 1–11. IEEE, 2018. [14] D. H. Hagos, A. Yazidi, P. E. Engelstad, and Ø. Kure. A Deep Learning-based Universal Tool for Operating Systems Fingerprinting from Passive Measurements. 2020. Submitted for publication. [15] T. Henderson, S. Floyd, A. Gurtov, and Y. Nishida. The NewReno modiﬁcation to TCP’s fast recovery algorithm. RFC 6582, 2012. [16] K. Hornik, M. Stinchcombe, and H. White. Multilayer feedforward networks are universal approximators. Neural networks, 1989. [17] V. Jacobson. Congestion avoidance and control. In ACM SIGCOMM computer communication review. ACM, 1988. [18] V. Jacobson, R. Braden, and D. Borman. TCP extensions for high performance. RFC 1323, 1992. [19] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. [20] T. Kohno, A. Broido, and K. C. Claffy. Remote physical device ﬁngerprinting. IEEE, 2005. [21] A. Langley, A. Riddoch, A. Wilk, A. Vicente, C. Krasic, D. Zhang, F. Yang, F. Kouranov, I. Swett, J. Iyengar, et al. The quic transport protocol: Design and internet-scale deployment. pages 183–196. ACM, 2017. [22] M. Lastovicka, T. Jirsik, P. Celeda, S. Spacek, and D. Filakovsky. Passive os ﬁngerprinting methods in the jungle of wireless networks. In NOMS. IEEE, 2018. [23] R. Lippmann, D. Fried, K. Piwowarski, and W. Streilein. Passive operating system identiﬁcation from TCP/IP packet headers. In Data Mining for Computer Security. Citeseer, 2003. [24] R. Lippmann, S. Webster, and D. Stetson. The effect of identifying vulnerabilities and patching software on the utility of network intrusion detection. Springer, 2002. [25] G. F. Lyon. Remote OS detection via TCP/IP stack ﬁngerprinting. Phrack Magazine, 8, 1998. [26] G. F. Lyon. Nmap network scanning: The ofﬁcial Nmap project guide to network discovery and security scanning. 2009. [27] Netresec. NetworkMiner, 2007. [28] A. Ornaghi and M. Valleri. Ettercap, 2015. [29] J. Postel. Internet control message protocol. RFC 792, 1981. [30] J. Postel. Internet protocol. RFC 791, 1981. [31] J. Postel. Transmission control protocol. RFC 793, 1981. [32] F. Rosenbaltt. The perceptron–a perciving and recognizing automation. Cornell Aeronautical Laboratory, 1957. [33] J. Scambray, S. McClure, and G. Kurtz. Hacking exposed. McGraw-Hill Professional, 2000. [34] SCOTT. European Leadership Joint Undertaking, 2019. [35] R. Spangler. Analysis of remote active operating system ﬁngerprinting tools. University of Wisconsin, 2003. [36] G. Taleck. Synscan: Towards complete tcp/ip ﬁngerprinting. CanSecWest, Vancouver BC, Canada, pages 1–12, 2004. [37] K. Tan, J. Song, Q. Zhang, and M. Sridharan. A compound TCP approach for high-speed and long distance networks. In Proceedings IEEE INFOCOM, 2006. [38] W. Wei, K. Suh, B. Wang, Y. Gu, J. Kurose, and D. Towsley. Passive online rogue access point detection using sequential hypothesis testing with TCP ACK-pairs. ACM, 2007. [39] J. Xu, J. Fan, M. Ammar, and S. B. Moon. On the design and performance of preﬁx-preserving IP trafﬁc trace anonymization. In ACM SIGCOMM, pages 263–266. ACM, 2001. [40] L. Xu, K. Harfoush, and I. Rhee. Binary increase congestion control (BIC) for fast long-distance networks. IEEE, 2004. [41] F. Yarochkin and O. Arkin. Xprobe2- A’Fuzzy’Approach to Remote Active Operating System Fingerprinting, 2002. [42] M. Zalewski. p0f: Passive OS ﬁngerprinting tool. Online at 2017. [43] B. Zhang, T. Zou, Y. Wang, and B. Zhang. Remote operation system detection base on machine learning. IEEE, 2009. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:13:46 UTC from IEEE Xplore. Restrictions apply.","—Securing and managing large, complex enterprise network infrastructure requires capturing and analyzing network trafﬁc traces in real-time. An accurate passive Operating System (OS) ﬁngerprinting plays a critical role in effective network management and cybersecurity protection. Passive ﬁngerprinting doesn’t send probes that introduce extra load to the network and hence it has a clear advantage over active ﬁngerprinting since it also reduces the risk of triggering false alarms. This paper proposes and evaluates an advanced classiﬁcation approach to passive OS ﬁngerprinting by leveraging state-of-the-art classical machine learning and deep learning techniques. Our controlled experiments on benchmark data, emulated and realistic trafﬁc is performed using two approaches. Through an Oracle-based machine learning approach, we found that the underlying TCP variant is an important feature for predicting the remote OS. Based on this observation, we develop a sophisticated tool for OS ﬁngerprinting that ﬁrst predicts the TCP ﬂavor using passive trafﬁc traces and then uses this prediction as an input feature for another machine learning algorithm for predicting the remote OS from passive measurements. This paper takes the passive ﬁngerprinting problem one step further by introducing the underlying predicted TCP variant as a distinguishing feature. In terms of accuracy, we empirically demonstrate that accurately predicting the TCP variant has the potential to boost the evaluation performance from 84% to 94% on average across all our validation scenarios and across different types of trafﬁc sources. We also demonstrate a practical example of this potential, by increasing the performance to 91.3% on average using a tool for TCP variant prediction in an emulated setting. To the best of our knowledge, this is the ﬁrst study that explores the potential for using the knowledge of the TCP variant to signiﬁcantly boost the accuracy of passive OS ﬁngerprinting.","['Desta Haileselassie Hagos', 'Martin Løland', 'Anis Yazidi', 'Øivind Kure', 'Paal E. Engelstad']"
"Artificial intelligence in the fertility clinic: status, pitfalls and possibilities","Riegler, M A and Stensen, M H and Witczak, O and Andersen, J M and Hicks, S A and Hammer, H L and Delbarre, E and Halvorsen, P and Yazidi, A and Holst, N and Haugen, T B",2021,9.0,36,Human Reproduction,article,"...................................................................
Artificial intelligence in the fertility
clinic: status, pitfalls and possibilities
M.A. Riegler
1,*, M.H. Stensen2, O. Witczak3, J.M. Andersen3,
S.A. Hicks1,4, H.L. Hammer1,4, E. Delbarre
3, P. Halvorsen1,4,
A. Yazidi4, N. Holst2, and T.B. Haugen3
1Department of Holistic Systems, Simula Metropolitan Center for Digital Engineering, Oslo, Norway 2Fertilitetssenteret, Oslo, Norway
3Department of Life Sciences and Health, Faculty of Health Sciences, OsloMet—Oslo Metropolitan University, Oslo, Norway
4Department of Computer Science, Faculty of Technology, Art and Design, OsloMet—Oslo Metropolitan University, Oslo, Norway
*Correspondence address. Department of Holistic Systems, Simula Metropolitan Center for Digital Engineering, Oslo 0167, Norway.
E-mail: michael@simula.no
https://orcid.org/0000-0002-3153-2064
Submitted on May 19, 2021; resubmitted on June 21, 2021; editorial decision on June 23, 2021
ABSTRACT
Introduction
The number of treatments with ART is steadily increasing in Europe,
and in 2016, over 900 000 treatment cycles were performed (Wyns
et al., 2020). Even though there have been gradual improvements in
the success rate, only one-third of the ART cycles result in a live birth,
and only 5% of the aspirated oocytes have the competence to develop
into a child (Lemmen et al., 2016; Wyns et al., 2020). This implies that
there is potential for improvement in the crucial steps in ART treat-
ments, such as the selection of embryos for transfer and the selection
of spermatozoa for ICSI. Improving the ability to select a single em-
bryo with the highest implantation potential could increase live birth
rates and time to pregnancy, as well as minimise the chance of multi-
ple pregnancies due to the transfer of multiple embryos. Likewise, a
more reliable method for sperm selection may increase the success
rates of the ICSI procedure. Furthermore, the disputable clinical value
of semen analysis in male fertility investigation and for ART justifies a
need for improving the methods of sperm evaluation both for diagnos-
tic purposes and for decisions regarding the fertilisation method of the
ART treatment.
Video and image analysis constitutes a major part of ART, and
artificial intelligence (AI) methods are especially suited for image
classification. In addition to videos and images, AI can be used to ana-
lyse other types of data, like text or tabular data. As in other parts of
medicine, AI methods have been introduced in the field of ART. They
have the advantage of objectivity and have the potential to improve
ART, which in some parts are based on subjective assessments.
In this review, we provide an overview of studies found in Embase
(Ovid), where AI methods have been applied in human reproductive
medicine with an emphasis on ART. Furthermore, we discuss how to
avoid the pitfalls and describe the potential use of AI in clinical practice
in the future.
Current challenges in ART
Highly trained personnel in fertility clinics are faced with important and
difficult decisions every day, such as deciding which fertilisation method
to use, which spermatozoon to select for ICSI, and which embryo to
transfer to the uterus. One of the major challenges in the subjective
assessments of embryos is the high intra- and inter-operator variability
which exists in the evaluation of morphology and morphokinetics
(Paternot et al., 2009; Sundvall et al., 2013; Storr et al., 2017). With
time-lapse technology, embryos can be monitored continuously, and
V
C The Author(s) 2021. Published by Oxford University Press on behalf of European Society of Human Reproduction and Embryology. All rights reserved.
For permissions, please email: journals.permissions@oup.com
Human Reproduction, Vol.36, No.9, pp. 2429–2442, 2021
Advance Access Publication on July 29, 2021
doi:10.1093/humrep/deab168
MINI REVIEW
 .............................................................................................................................................................................
the complete process of embryo development is more precisely
assessed. However, there is no evidence that the use of time-lapse
technology has improved live birth rates after ART (Armstrong et al.,
2019).
Whilst sperm morphology has no definite impact on the outcome
after ART, sperm concentration and sperm motility are normally
assessed for deciding whether IVF or ICSI should be used as the fertil-
isation method (Høst et al., 2001). Strikingly, ICSI is increasingly used
irrespective of a male factor infertility diagnosis (Boulet et al., 2015;
Vander Borght and Wyns, 2018). Among the cycles reported in
Europe in 2016, 28% were IVF and 72% ICSI (Wyns et al., 2020), al-
though the male factor accounts for only 20–30% of the diagnoses of
the infertile couples. This is of increasing concern since performing
ICSI instead of IVF in couples where the male partner has a defined
normal semen sample does not increase the live birth rate (Dang
et al., 2021).
Early in the fertility investigation, a standard semen analysis accord-
ing to WHO guidelines (WHO, 2010) is usually performed. This analy-
sis might reveal information essential for deciding whether ART should
be recommended as a treatment. The method is time-consuming and
prone to limited reproducibility and high inter-personnel variation
(Tomlinson, 2016). Several computer-aided sperm analyses (CASA)
systems are available, but they are still most suitable for assessing sper-
matozoa separated from seminal plasma, and their reliability is debat-
able (Mortimer et al., 2015).
When selecting spermatozoa to inject for ICSI, the procedure is
performed by visually evaluating the morphology and motility of sper-
matozoa with an ICSI microscope. This selection process is subjective,
based on a qualitative evaluation of the operator, and not on objective
sperm characteristics.
The potential of AI in ART
New technologies, such as better cameras and data capturing systems,
are rapidly becoming an integrated part of the fertility clinic and result
in a vast amount of stored data, including patient data, embryo time-
lapse videos and sperm videos. In recent years, AI has proved to be a
valuable tool in medicine by analysing large amounts of data (Hosny
et al., 2018; Yang and Bang, 2019). A typical approach for using AI
models in ART can be seen in Fig. 1. In particular, machine learning
(ML), a subfield within AI, refers to algorithms that automatically learn
from data without being explicitly programmed.
An overview of common AI methods used in ART is given in
Fig. 2. Supervised and unsupervised learning are subgroups of ML.
Supervised learning refers to methods that learn from datasets
where the answer (the label) is given for each observation. An ob-
servation within a dataset could be data from an ART cycle, like
an embryo image, and the label regarding whether the embryo
resulted in a pregnancy or not. The algorithm will learn from the
dataset, and the resulting ML model can be used to predict preg-
nancy or not for data from another ART cycle with unknown
labels. Unsupervised learning refers to methods that search for
patterns in unlabelled data, for example, automatically grouping
blastocyst images based on visual features automatically deter-
mined by the algorithm that may correlate with morphological
characteristics. Such visual features can be completely different
from what human observers are able to recognise or may see as
relevant. Artificial neural networks (ANNs) are a class of super-
vised learning, and deep neural networks (DNNs), or deep learn-
ing (DL), refers to especially large and complex ANNs. DL
methods have the ability to learn from unstructured data such as
images or text.
Details of studies discussed in this review can be found in Table I
for embryo related articles and in Table II for sperm related articles.
AI in embryo assessment
Most articles about embryo assessment and selection for transfer
address the prediction of embryo quality, grading and ranking, and
compare the performance of the AI model with an evaluation done by
embryologists (Dirvanauskas et al., 2019; Kanakasabapathy et al., 2019;
Khosravi et al., 2019; Raudonis et al., 2019; Fukunaga et al., 2020;
Bormann et al., 2020a, 2020b; Rad et al., 2020; Zhao et al., 2021). To
make an automatic grading system, the model must learn to locate the
embryo in the dish, segment important features, and then assess and
grade the embryo from manually annotated data. Manual annotations
provided by embryologists are time-consuming to create, leading to
small and sparsely annotated datasets. Therefore, most studies of AI
methods and resulting models in ART can be considered preliminary.
With the development of time-lapse technology, access to image and
video data has become more available, making it possible to utilise this
data to build new AI models. Dirvanauskas et al. (2019) predicted em-
bryo development stages by time-lapse videos using features extracted
from a Convolutional Neural Network (CNN). In one study, an auto-
mated system was established to detect pronuclei in time-lapse images
with the precision almost equivalent to highly skilled embryologists
(Fukunaga et al., 2020). In another study, the zona pellucida (ZP) and
the cytoplasm and pronucleus in zygotes were detected by developing
an algorithm using DL image segmentation technology (Zhao et al.,
2021). One group reported the possibility of identifying human em-
bryo development stages (Raudonis et al., 2019). First, the location of
an embryo in the image was detected by employing a visual image
feature-based classifier. Then, a multi-class prediction model was de-
veloped to predict the cell stage of the embryo using DL. Others
reported a system to detect and assess blastocyst quality by using DL
to detect the ZP area (Rad et al., 2018).
Data augmentation techniques, like cropping and resizing which are
usually used to increase dataset size or variation, were applied to em-
bryo assessment to compensate for the lack of data for training the
DL models (Rad et al., 2020). Augmented images were proven to be
effective in filling the generalisation gap when available data is limited.
Experimental results confirmed that the proposed models were capa-
ble of segmenting trophectoderm (TE) regions.
Inner cell mass (ICM) has been assessed by a computer-based and
semi-automatic grading of human blastocysts (Santos Filho et al.,
2012). A CNN was able to predict ICM and TE grades from a single
frame (a frame is an image extracted from a video), and a recurrent
neural network was applied on top to incorporate temporal informa-
tion of the expanding blastocysts from multiple frames. Additionally,
when evaluating implantation rates for embryos grouped by morphol-
ogy grades, a CNN provided a slightly higher correlation between pre-
dicted embryo quality and implantation ability than did human
2430
Riegler et al.
 .......................................................................
embryologists (Kragh et al., 2019). The use of a CNN trained to as-
sess an embryo’s implantation potential directly, when using euploid
embryos capable of implantation, outperformed 15 trained embryolo-
gists (Bormann et al., 2020a).
In a retrospective analysis of time-lapse videos and clinical outcomes
of 10 000 embryos from eight different IVF clinics across four different
countries, a DL model was built with a high level of predictability re-
garding the embryo implantation likelihood (Tran et al., 2019). A pro-
spective double-blinded study using retrospective data addressed the
variability between embryologists to select embryos for biopsy and
cryopreservation (Bormann et al., 2020b). It was found that the appli-
cation of a DNN could improve the reliability and perform with high
consistency during the process of embryo selection, thereby potentially
improving outcomes.
A DL-based system called Life Whisperer showed a sensitivity of
70% for viable embryos while maintaining a specificity of 61% for
non-viable embryos across three independent blind test sets from
different clinics (Ver Milyea et al., 2020). The model demonstrated
a 25% increase over embryologists for accuracy, and the ranking
comparison demonstrated an improvement of 42% over embryolo-
gists. One embryo ranking model increased the success of ART treat-
ments in oocyte donation programs (Alegre et al., 2021). The
Figure 1. Development of a machine learning model. To implement a machine learning model at the clinic, at ﬁrst a clinically relevant aim
should be deﬁned, and data must be collected in line with this aim. The collected data should then be stored in an appropriate format so that the ma-
chine learning algorithm can process it. The stored data should be split into a training, validation and testing partitions to ensure a robust and thor-
ough evaluation. In the optimal case the testing dataset is provided from an independent source (different clinic, new patients). These parts are then
be used to build a model that is in line with the medical goal. After the model is built, it should be thoroughly evaluated to verify its generalisability
and to avoid unintended biases. Once the model has been thoroughly tested, it can be implemented in the clinic. The model should be continuously
monitored and tested while in production and as the circumstances required are updated.
Figure 2.
Subﬁelds deﬁned by artiﬁcial intelligence.
Machine learning is the most relevant ﬁeld for the current develop-
ment of artiﬁcial intelligence system for the clinic. Machine learning
can further be split into traditional machine learning methods and
deep learning. Note that the subﬁelds are not mutually exclusive;
most of them rely heavily on machine learning, like computer vision
and language processing.
Artificial intelligence in the fertility clinic
2431
 .............................................................................................................................................................................................................................
Table I Overview of studies using AI-methods in embryo assessment and selection, and for prediction before treatment.
Year
Study
Aim of the study
Outcome
Dataset
AI methods
Summary answer
2017 Milewski et al.
Investigating the poten-
tial of using data on em-
bryo implantation and
morphokinetic parame-
ters in predictive AI
models.
Probability of implanta-
tion, clinical pregnancy.
A dataset of time-lapse
recordings of 610 em-
bryos from 514 treat-
ment cycles,
morphokinetic parame-
ters, data on implanta-
tion, women’s age. It is
unclear if the dataset
was prospectively
collected.
Traditional ML (Principal
Component Analysis)
and Deep Learning
(Multilayer Perceptron)
Morphokinetic parame-
ters from the time-lapse
videos used to discrimi-
nate between implanted
and nonimplanted
achieved an AUC of
0.71.
2018 Rad et al.
Automatic segmentation
of the Zona Pellucida.
Segmentation of Zona
Pellucida.
A retrospective dataset
consisting of images of
blastocyst.
Deep Learning
The AI model was able
to segment the Zona
Pellucida with an IoU
score of 0.78.
2019 Tran et al.
Predict the probability of
pregnancy with foetal
heart from time-lapse
videos.
Foetal heart pregnancy
or not.
A retrospective dataset
containing time-lapse
videos of 10,638 em-
bryos cultured to blasto-
cyst stage from 1,648
patients across 8 IVF
clinics. No manual as-
sessment of videos.
Deep Learning (CNN)
AI model (IVY) was able
to predict the probability
of fetal heart pregnancy
based on timelapse vid-
eos with a mean AUC of
0.93.
2019 Dirvanauskas et al.
Predict embryo develop-
ment stage from time-
lapse videos.
Embryo development
stage (1-cell, 2-cell,
4-cell, 8-cell,
no embryo).
A retrospective dataset
containing 7,002 time-
lapse images from 10
embryos.
Deep learning (CNN)
and traditional ML (K
Nearest Neighbour,
Cecoc, Decision
Trees, Naive Bayes
Classiﬁer)
The AI model for em-
bryo classiﬁcation
achieved an accuracy of
97.62%.
2019 Kanakasabapathy et al.
Develop inexpensive
platforms for use in a
stand-alone optical sys-
tem and a smartphone-
based optical system for
automated grading of
embryos based on
images.
Classiﬁcation of embryos
based on cell
morphology.
A retrospective dataset
containing 160 embryo
images from a stand-
alone optical system and
385 embryo images
from a smartphone-
based optical system.
Models were pretrained
on other high-quality
embryo data.
Deep Learning (CNN)
Two systems were de-
veloped for grading em-
bryos (stand-alone
imaging system and
smartphone optical sys-
tem). Both systems
achieve an accuracy
above 90%.
2019 Khosravi et al.
Develop an AI model for
accurate prediction of
blastocyst quality and se-
lection for single embryo
for transfer.
Classiﬁcation of embryos
into poor-quality and
good-quality.
A retrospective dataset
containing 12,001 time-
lapse images at 110 hr
post-insemination from
10,148 embryos. Manual
classiﬁcation by embryol-
ogists. Age of patient
was included in the
model for 2,182 em-
bryos. Two external
datasets were used for
validation.
Deep Learning (CNN)
AI model (STORK) pre-
dicted blastocyst quality
with an AUC above
0.98. The model
achieved an AUC of
0.90 and 0.76 respec-
tively on two datasets
from other clinics.
2019 Kragh et al.
Develop AI method for
automatic grading of
blastocyst morphological
appearance based on
time-lapse images.
Inner cell mass and tro-
phectoderm grading, im-
plantation rate.
A dataset containing
time-lapse videos of
4,483 embryos (both
IVF and ICSI treatment).
All images were graded
by embryologists.
Implantation information
for 287 embryos. It is
unclear if the dataset
was prospectively
collected.
Deep Learning (CNN,
Recurrent Neural
Network)
AI model achieved an
accuracy of 65% for in-
ner cell mass grading and
70% for trophectoderm
grading. Prediction of im-
plantation achieved an
AUC of 0.66.
(continued)
2432
Riegler et al.
 .............................................................................................................................................................................................................................
Table I Continued
Year
Study
Aim of the study
Outcome
Dataset
AI methods
Summary answer
2019 Raudonis et al.
Automatically detect hu-
man embryo develop-
ment stages during
incubation.
Detect embryo in an im-
age and classify the em-
bryo development stage
(1-cell, 2-cell, 3-cell,
4-cell, > 4-cell).
A dataset containing
images of early-stage
embryo development
from an ESCO Miri TL
incubator system. It is
unclear if the dataset
was prospectively
collected.
Deep Learning (CNN)
Two AI models were
considered, both
achieved a stage classiﬁ-
cation accuracy above
92%. The most difﬁcult
stage to classify was
3-cell.
2019 Qiu et al.
Prediction of a clinical
model for estimating the
cumulative live birth
chance of the ﬁrst com-
plete IVF cycle using pre-
treatment variables in-
cluding BMI and AMH.
Cumulative live birth
chance before IVF.
A retrospective dataset
containing age, AMH,
BMI, duration of infertil-
ity, previous live birth,
previous miscarriage,
previous abortion, and
type of infertility.
Traditional ML (Logistic
Regression, Random
Forest, XGBoost,
Support Vector
Machine)
Four machine learning
models were tested, of
which XGBoost
achieved the best score
with an AUC of 0.73.
The results indicate that
BMI and AMH have a
signiﬁcant impact on live
birth.
2019 Vogiatzi et al.
Predict live birth from
embryo variables by in-
cluding parameters that
exert a meaningful effect
on live birth following as-
sisted reproduction.
Live birth or not.
12 input features: Age
(female), Age at menar-
che, Difﬁculty during ET,
Endometrium thickness
prior to OR, ET/2PN,
TQE D3, TQE D3/2PN,
Total gonadotropins,
Age group, Dyspareunia,
Fresh or frozen cycle,
Menarche > 12 years.
The dataset was col-
lected retrospectively.
Deep Learning
(Multilayer Perceptron)
A multilayer perceptron
using the 12 input fea-
tures achieved a sensitiv-
ity of 0.71 and a
speciﬁcity of 0.70 for
predicting live birth.
2020 Bori et al.
Describe novel embryo
features for implantation
potential prediction that
may be used as input
data in AI models.
Prediction of implanta-
tion potential.
A retrospective dataset
containing time-lapse
images from 637 em-
bryos (ICSI-cycles with-
out PGT, single fresh
embryo transfer),
Implantation rate based
on foetal heartbeat ultra-
sound after eight weeks.
Oocyte donation
programme.
Deep Learning
(Multilayer Perceptron)
Two novel embryo fea-
tures with signiﬁcantly
different values in
implanted and nonim-
planted embryos were
identiﬁed. Novel embryo
features, in addition to
conventional morphoki-
netic parameters, can
improve predictive AI
models.
2020 Bormann et al. (a)
Evaluation of AI models
for embryo selection
based on images.
Embryo quality and im-
plantation potential.
A retrospective dataset
containing single time-
point images at 113 h
post-insemination for
742 embryos from 97
patients.
Deep Learning (CNN)
Two AI models were
evaluated. One selected
the highest quality em-
bryo with 90% accuracy,
and the other was able
to assess implantation
potential better than
trained embryologists
from different fertility
centres.
2020 Bormann et al. (b)
Evaluate AI models for
embryo quality scoring
and assessment of bi-
opsy or cryopreserva-
tion of blastocysts,
compared to decisions
by trained
embryologists.
Morphological quality on
a 1–5 scale.
For embryo scoring,
images from 3469 em-
bryos. 748 at 70 h post-
insemination and 742
images at 113 h post-in-
semination. For biopsy
and cryopreservation as-
sessment, 56 blastocysts
images at 113 h post-in-
semination. All images
were evaluated by
Deep Learning (CNN)
The AI models showed
less variability in embryo
grading than embryolo-
gists and outperformed
the embryologists in
selecting blastocyst bi-
opsy and
cryopreservation.
(continued)
Artificial intelligence in the fertility clinic
2433
 .............................................................................................................................................................................................................................
Table I Continued
Year
Study
Aim of the study
Outcome
Dataset
AI methods
Summary answer
trained embryologists.
Both datasets were ret-
rospectively collected.
2020 Chavez-Badiola et al. (a) Evaluate AI model per-
formance for prediction
of ploidy and implanta-
tion compared to
trained embryologists.
Embryo ranking, embryo
ploidy.
A retrospective dataset
containing single time-
point images from 840
embryos at day 5 or 6
after fertilization by ICSI.
Ploidy, hCG results, or
both were known.
Deep Learning
(Multilayer Perceptron)
An AI model (ERICA)
was able to identify and
rank blastocysts with the
best potential from one
image with higher accu-
racy than embryologists.
2020 Chavez-Badiola et al. (b) Predict pregnancy test
results after embryo
transfer.
Successful pregnancy or
not.
A retrospective dataset
containing embryo
images and patient age.
Traditional ML
(Probabilistic Bayesian,
Support Vector
Machine, Decision
Trees, Random Forest)
and Deep Learning
(Multilayer Perceptron)
Several AI models were
tested, of which the sup-
port vector machine
achieved the best result
across three datasets.
2020 Fukunaga et al.
Automatic pronuclei
counting using deep
learning.
Number of pronuclei.
A dataset containing 900
time-lapse images of 300
embryos up to 20 h
post-insemination. 70
images of each embryo.
Manual assessment and
annotation of pronuclei.
It is unclear if the dataset
was prospectively
collected.
Deep Learning (CNN)
The AI model was able
to count pronuclei with
a sensitivity of 99% for
0PN, 82% for 1PN, and
99% for 2PN. The sys-
tem performed similarly
to that of trained human
experts.
2020 Rad et al.
Automatic trophecto-
derm segmentation in
human embryo using
deep learning.
Trophectoderm
segmentation.
A retrospective dataset
containing images of
day-5 human embryo.
Deep Learning (CNN,
Generative Adversarial
Networks)
An AI model was used
to segment human em-
bryos. The model
achieved an IoU score of
76.71.
2020 Raef et al.
Predict implantation out-
come after embryo
transfer cycle.
Implantation rate.
Positive or negative
beta-HCG.
A dataset containing 82
features (patient-related
data, female and male
pathology, semen analy-
sis, lab tests, oocyte and
embryo data and PRP)
Attributes related to im-
plantation arranged in
two groups (N ¼ 82): 1)
patient-related features
(N ¼ 59) and 2) ART cy-
cle features (N ¼ 23). It
is unclear if the dataset
was prospectively
collected.
Traditional ML (Naive
Bayes Classiﬁer, Support
Vector Machine,
Random Forest, K
Nearest Neighbour,
Decision Trees) and
Deep Learning
(Multilayer Perceptron)
Six AI models were
tested, where the ran-
dom forest algorithm
achieved the best result
with an accuracy of
90.4% and an AUC of
93.7%.
2020 Ver Milyea et al.
Predict embryo viability
using images captured by
optical light microscopy.
Implantation rate—foe-
tal heartbeat.
A retrospective dataset
containing light micros-
copy images of blasto-
cysts, clinical outcome.
Deep Learning
(Convolutional Neural
Network)
An AI model (Life
Whisperer) was tested
on three independent
testing datasets, where it
achieved a 70.1% sensi-
tivity for viable embryos
and a speciﬁcity of
60.5% for non-viable
embryos.
2020 Goyal et al.
Predict live birth before
IVF treatment.
Live birth or not.
A retrospective dataset
containing 141,160 pa-
tient records,
Deep Learning
(Multilayer Perceptron)
Several machine learning
models were evaluated,
of which the multilayer
(continued)
2434
Riegler et al.
 ..................................................
multicentre nature of the above study supported its applicability at dif-
ferent clinics, standardising the interpretation of embryo development.
Embryo assessment, ranking, and selection are procedures nor-
mally based on evaluations at different time points during embryo
development and in several focal planes to get a view of the whole
embryo. There are numerous studies where only static images, usu-
ally in one single focal plane, are used for the AI analysis, which do
not mirror the clinical practice (Rad et al., 2018; Kanakasabapathy
et al., 2019; Khosravi et al., 2019; Bormann et al., 2020a, 2020b;
Chavez-Badiola et al., 2020a; Chavez-Badiola et al., 2020b; Bori
et al., 2021). In these models, well-curated, high-quality data is cru-
cial. For example, non-selection of a large number of images repre-
sentative of the diversity, inconsistent image treatment or inaccurate
labelling of images can lead to poor performing models (Tsipras
et al., 2020). Models involving time-lapse videos might also raise
problems since the definition of the important morphokinetic
markers may vary between different laboratories and still requires
an
automated
and
unbiased
process
(Milewski
et
al.,
2017;
Dirvanauskas et al., 2019; Tran et al., 2019; Bori et al., 2020; Alegre
et al., 2021).
AI methods should incorporate patient data that may impact the
outcome, such as maternal age. A framework (STORK) based on a
large collection of human embryo time-lapse images used a CNN to
automatically predict blastocyst quality depending on patient age
(Khosravi et al., 2019). Milewski et al. (2017) extracted several time
points and specific relative cleavage times together with fragmentation
levels, presence of multinucleation, evenness of blastomeres and
woman’s age. An ANN was trained to predict embryo implantation
from the extracted features. Another study that included 82 features
of patient data found that follicle stimulating hormone/human meno-
pausal gonadotropin dosage was the strongest predictor of embryo
implantation (Raef et al., 2020).
.............................................................................................................................................................................................................................
Table I Continued
Year
Study
Aim of the study
Outcome
Dataset
AI methods
Summary answer
anonymized register
data collected from the
year 2010–2016
obtained from the
Human Fertilisation &
Embryology Authority.
perceptron performed
best with an F1-Score of
72.94%.
2021 Alegre et al.
Evaluate and test an au-
tomatic software for em-
bryo evaluation and
selection (Dana).
Embryo implantation
potential.
A retrospective dataset
containing time-lapse
images and patient char-
acteristics from oocyte
donation program.
Phase 1: 1,676 embryos
from 955 couples. Phase
2: 996 embryos from
249 cycles (multiple
centres). Phase 3 147
embryos from 108
patients.
Deep Learning (CNN)
Increased success of IVF
treatment was found
with the assistance of au-
tomated embryo ranking
by Dana. The creation of
a data cloud can improve
the system further.
2021 Bori et al.
Develop an AI model for
prediction of live birth
based on blastocyst
morphology and proteo-
mic proﬁle of culture
media.
Prediction of live birth.
A retrospective dataset
containing single time
point images at 111 hr
þ/- 1.5 hr from 212
patients. 186 embryos
after exclusions (131
non PGT from oocyte
donation programme, 55
PDG with proteomic
proﬁle.
Deep Learning
(Multilayer Perceptron)
Three AI models using
both morphological and
proteomic variables. The
best model predicted
live birth with an AUC of
1.0.
2021 Zhao et al.
Automatic segmentation
of day one embryos in
zona pellucida (ZP), cy-
toplasm, and pronucleus
(PN).
Cytoplasm, ZP and PN
segments.
A dataset containing
images of day-one em-
bryos (zygotes). It is
unclear if the dataset
was prospectively
collected.
Deep Learning (CNN,
Generative Adversarial
Networks)
The AI model achieved a
precision of 97% when
segmenting the cyto-
plasm, 80% for the zona
pellucida, and 84% for
the pronucleus.
AI, Artiﬁcial intelligence; CNN, Convolutional neural network; AUC, Area under the curve; IVF, In vitro fertilization; ICSI, Intracytoplasmic sperm injection; ZP, Zona pellucida; PN,
Pronucleus, PGT, Preimplantation genetic testing; AMH, Anti-Mullerian hormone; BMI, body mass index.
Artificial intelligence in the fertility clinic
2435
 ............................................................................................................................................................................................................................
Table II Overview of studies using AI-methods in semen analysis and selection of sperm for ICSI.
Year
Study
Aim of study
Outcome
Dataset
AI Methods
Summary answer
2014
Chang et al.
Improve AI models
for detection of hu-
man sperm head
characteristics in-
cluding, acrosome
and nucleus.
Sperm morphology
A prospective data-
set containing 20
images with a total
of 210 stained sperm
cells. Sperm cell
details were manu-
ally classiﬁed and an-
notated in the
dataset.
Traditional ML
(Clustering)
Models showed 80%
overlap with manual
classiﬁcation and
more precise sperm
head detection and
segmentation than
previously described
models.
2017
Chang et al.
Explore AI modes to
classify sperm head
morphology into ﬁve
classes (normal, ta-
pered, pyriform,
small, amorphous)
and introduce a new
dataset.
Sperm morphology
A retrospective
dataset containing
images of 1,854
stained sperm heads
from six semen
smears (SCIAN
MorphoSpermGS).
Sperm head shape
was manually classi-
ﬁed and annotated in
the dataset.
432
The best model was
able to obtain 49%
correct classiﬁcation
of head shape into
the ﬁve classes.
2017
Shaker et al.
Explore Dictionary
Learning technique
for classiﬁcation of
sperm head shapes
into four classes
(normal, tapered
pyriform and amor-
phous), and intro-
duce a new dataset.
Sperm morphology
Two retrospective
datasets. 216 images
of stained sperm
heads (HuSHeM
dataset). Sperm
head shape was
manually classiﬁed
and annotated in the
dataset. 1133 images
from the SCIAN-
MorphoSpermGS
dataset.
Traditional ML
(Dictionary Learning)
Use of Dictionary
Learning was more
effective for sperm
head classiﬁcation
than previously pub-
lished shape-based
features.
2017
Goodson et al.
Development of AI
model for classiﬁca-
tion of sperm motil-
ity patterns during
invitro capacitation.
Sperm motility
CASA tracks of
2,817 washed sperm
cells from 18 sub-
jects. All tacks were
manually classiﬁed as
progressive, interme-
diate, hyperacti-
vated, slow, weakly
motile. It is unclear if
the dataset was pro-
spectively collected.
Traditional ML
(Support Vector
Machine, Decision
Tree)
A web-based pro-
gram, CASAnova,
was developed. This
program classiﬁes
sperm motility pat-
terns into one of ﬁve
classes with an over-
all accuracy of
89.9%.
2019
Agarwal et al.
Evaluate the perfor-
mance of an auto-
mated AI system
(LensHook) to mea-
sure sperm concen-
tration and sperm
motility.
Sperm concentration
and sperm motility
A prospective data-
set containing images
and video from 135
semen samples.
No information
available
Concentration and
motility analysed by
LensHook were
comparable to man-
ual assessment.
2019
Hicks et al.
Predict sperm motil-
ity from videos and
introduce a new
dataset.
Sperm motility
A retrospective
dataset containing
videos of live sperm
in untreated samples
from 85 subjects
(VISEM). Semen
analysis was manually
evaluated according
to WHO 2010.
Deep Learning
(CNN)
Deep learning
showed potential for
rapid and consistent
prediction of sperm
motility categories
(WHO 2010) based
on videos of live,
untreated sperm
samples.
(continued)
2436
Riegler et al.
 ............................................................................................................................................................................................................................
Table II Continued
Year
Study
Aim of study
Outcome
Dataset
AI Methods
Summary answer
2019
Riordon et al.
Automatic assess-
ment for classiﬁcation
of sperm head mor-
phology into ﬁve clas-
ses (normal, tapered,
pyriform, small, and
amorphous).
Sperm morphology
Retrospective images
from HuSHeM data-
set and 1,132 images
from SCIAN dataset.
Deep learning
(CNN)
Deep learning can
classify sperm head
morphology with
higher accuracy than
previously published
AI methods used for
the same datasets.
2019
Javadi and
Mirroshandel
Automatic assess-
ment of sperm mor-
phology in unﬁxed
cells and introduce a
new dataset.
Sperm morphology
1,540 retrospective
grey scale images of
unﬁxed sperm cells
from 235 subjects
(MHSMA dataset).
Sperm cells were
manually classiﬁed as
normal or abnormal,
and acrosome, head,
vacuole, tail, and
neck were
annotated.
Deep learning
(CNN)
The method is able
to classify sperm in
real-time, but accu-
racy needs to be
improved.
2019
McCallum et al.
Automatic method
for ranking sperm
cells based on DNA
quality enabling
sperm selection for
ICSI.
Sperm DNA
integrity
1,064 images of
stained sperm cells
with known DNA in-
tegrity from 6 sub-
jects. It is unclear if
the dataset was pro-
spectively collected.
Deep learning
(CNN)
Correlation between
cell image and DNA
integrity was found,
and the model was
able to predict the
DNA integrity of
sperm cells in a rapid
manner.
2019
Movahed et al.
Automatic segmen-
tation of external
(head, mid piece,
and tail) and internal
parts (acrosome and
nucleus) of the
sperm.
Sperm morphology
A retrospective
dataset containing 20
images of stained
sperm cells. Sperm
parts were manually
annotated.
Deep learning
(CNN) and tradi-
tional ML (Support
Vector Machine, K-
nearest neighbour,
Ensemble Method)
The methods were
better at segmenting
the head, acrosome,
and nucleus than
previously described
models. Provides the
ﬁrst method for eval-
uation of tail and mid
piece.
2020
Ilhan et al.
Fully automated
analyses of sperm
morphology by a
smartphone-based
system and intro-
duce a new dataset.
Sperm morphology
200 retrospective
images of stained
sperm cells from 17
subjects (SMIDS
dataset). Sperm cells
were manually classi-
ﬁed as normal or
abnormal.
Deep learning
(CNN) and tradi-
tional ML (Support
Vector Machine,
Decision Trees, K-
Nearest
Neighbours)
The most precise
model was able to
predict normal or
abnormal sperm
with an accuracy of
87%.
2021
Abbasi et al.
Improve AI models
for classiﬁcation of
the sperm head,
vacuoles, and acro-
some as normal or
abnormal.
Sperm morphology
1,540 retrospective
images from the
MHSMA dataset.
Deep learning
(CNN)
Both AI models
were able to predict
sperm head charac-
teristics more accu-
rately than models
previously described
in other studies.
2021
Valiuskaite et al.
Propose an AI
method that can pre-
dict if a semen sam-
ple is suitable for
artiﬁcial insemination
procedure based on
videos of semen
samples.
Sperm motility
85 retrospective
videos from the
VISEM dataset.
Deep learning
(CNN)
The AI model
detected sperm
heads in the videos
with an accuracy of
91.8%, and the
Pearson correlation
between manually
assessed motility and
predicted sperm head
motility was 0.969.
AI, Artiﬁcial intelligence; CNN, Convolutional neural network; CASA, Computer-assisted semen analysis.
Artificial intelligence in the fertility clinic
2437
 .............................................................................................................................................................................
AI in prediction of outcome
before treatment
In several publications, AI was used to build models that predict the
possibility of a successful treatment based on a patient’s medical re-
cord. The result may be of value for patient counselling about the po-
tential results of the treatment. Goyal et al. (2020) used the dataset
provided by Human Fertilisation and Embryology Authority (HFEA)
which included 30 different features such as age, number of previous
ART cycles, number of previous pregnancies, number of inseminated
oocytes, number of embryos transferred, and diagnosis for a total of
140 000 patients. Several ML techniques were evaluated to predict
live-birth occurrence. They concluded that both male and female traits
and living conditions were factors that influenced the outcome of
the treatment. A well-known ML technique called extreme gradient
boosting (XGBoost) has been used to predict live birth from fea-
tures such as age, anti-Mullerian hormone, BMI and patient anam-
nesis (Qiu et al., 2019). Similarly, an ANN was trained to predict
live birth using a collection of features such as the age of the fe-
male, total dose of gonadotrophins administered, endometrial thick-
ness, and the number of top-quality embryos (Vogiatzi et al., 2019).
AI in analysis of sperm
Most studies using an AI approach for semen analyses have been per-
formed for morphology assessments. The morphological classification
is usually performed on stained spermatozoa and implies both distin-
guishing abnormal from normal spermatozoa as well as identifying vari-
ous defects of the sperm cell (WHO, 2010). Some of the developed
AI models have been trained only to predict the morphology of sperm
heads (Chang et al., 2014; Chang et al.; 2017; Shaker et al., 2017;
Riordon et al., 2019), whereas other studies describe the recognition
of various parts of the whole sperm (Movahed et al., 2019; Ilhan et al.,
2020). These differences in the approaches make it difficult to com-
pare results and possible implications for clinical practice even if the
overall goal is similar. This is also fortified by the fact that the data
used is usually very limited, with only a small number of spermatozoa
or patients. Training and evaluating complex methods, for example,
DL, with a small-sized dataset most probably leads to an overfitted
model. An overfitted model is a model that does not generalise well
to unseen real-world cases although it works well on the training data.
For example, suppose that a model is trained on a dataset of embryo
images to predict pregnancy or not. If the model achieves far higher
prediction performance on the embryo images used for training than
on new and unseen images, the model is overfitted to the training
data.
Annotation of the dataset/sperm images must be done manually
and with high accuracy to obtain well-performing models. For recog-
nising and interpreting images of spermatozoa at the pixel level, seg-
mentation is the common approach, in which the spermatozoon is
divided into parts, each consisting of a set of pixels. Some studies
demonstrate high classification accuracy for morphological characteris-
tics, and most of the studies have both trained and validated the mod-
els on freely available datasets, which makes them easier to compare
(HuSHeM in Shaker et al. (2017), SCIAN in Chang et al. (2017), and a
smaller dataset of 264 spermatozoa in Chang et al. (2014)).
Furthermore, the model performance is compared with existing AI
models, and even though this is common practice in the field of AI, it
reveals little knowledge about the clinical usability of the model.
Regarding sperm morphology, as far as we know, there are no studies
comparing the performance of the models with manual assessment
according to the WHO guidelines or in relation to fertility outcomes.
For prediction of sperm motility, only one study compared AI-based
sperm motility classification against sperm motility that was manually
assessed following WHO guidelines (Hicks et al., 2019), while others
were mainly focused on comparing various models or exploring the
sperm kinematics (Goodson et al., 2017; Valiuskait_e et al., 2020).
Studies related to motility and/or morphology also come with the
challenge of small datasets, and for both of them, the evaluation pro-
cedures are often not clear. Cross validation is sometimes used to
compensate for small datasets (Goodson et al., 2017; Shaker et al.,
2017). However, even though cross validation is acceptable for testing
model performance and comparing it to other models on the same
dataset, it does not test the generalisability of the results. In a clinical
setting, an independent test set evaluation should be performed, opti-
mally across different clinics (Abbasi et al., 2021).
Automatic systems for diagnostic purposes have been developed.
One such system based on an automatic segmentation step and a clas-
sification of normal/abnormal spermatozoa has recently been de-
scribed (Ilhan et al., 2020). The authors reported an accuracy of 87%.
However, the method was just compared with other ML methods and
not evaluated for its clinical value. In addition, accuracy alone is not a
sufficient metric to determine the possible clinical performance of a
method, especially if only a small dataset is used. Another automatic
system for analysis of sperm concentration, morphology and motility
used AI optical microscopic technology, for which the performance
was compared with manual assessment (Agarwal et al., 2019, 2021).
Nonetheless, the morphology values did not correlate with the manual
morphology results, and unfortunately, there are no details provided
on the construction and annotation of the dataset.
Parameters that are not part of standard semen analysis have also
been used in AI models. For example, sperm intracellular pH was
shown to be a stable marker for fertilisation outcome (Gunderson
et al., 2021), and sperm DNA integrity could be predicted from bright-
field sperm images at a single cell level through supervised training
(McCallum et al., 2019). These studies show how AI can be used to
automate sperm sorting and selection tasks. However, big datasets
from multicentre cohorts are needed to evaluate whether the results
are generalisable before these AI models can be used in the clinic as
well as for research related purposes. In addition to the conventional
semen variables, image features may detect sperm characteristics that
are too complex to be recognised by humans, for example, motility
patterns or morphological shapes. Nonetheless, from a diagnostic per-
spective, the clinical value of novel traits must be investigated in epide-
miological studies.
The selection of spermatozoa for ICSI is based on a cursory assess-
ment of motility and morphology in real-time, which is especially a
challenge for morphology evaluation. The procedure has a potential
for improvement using AI to obtain a more objective selection based
on the simultaneous monitoring of morphology and motility patterns.
Attempts have been made to develop DL models for morphological
assessment based on images of unstained spermatozoa (Javadi and
Mirroshandel, 2019; Abbasi et al., 2021). Both algorithms can analyse
2438
Riegler et al.
 .............................................................................................................................................................................
fresh human sperm in real-time with a magnification between 400
and 600.
The AI methods used in sperm related studies are mostly based on
simple algorithms that are standard implementation in most ML frame-
works (Table II). The development of more domain-specific methods
and models related to ART will in the long run lead to better results
compared to using out-of-the-box methods from existing generic
frameworks.
Pitfalls
The AI algorithms are only as good as the data they are based on.
There may also be limitations regarding generalisability due to difficul-
ties with the standardisation of the ML methods. Variation in patient
demographics, clinical and laboratory practices may cause data bias.
When an AI model is based on training in one clinic, the AI model
should be validated in independent cohorts (Tran et al., 2019;
Bormann et al., 2020b). Furthermore, the models should not be lim-
ited to strict inclusion criteria, and optimally the datasets should con-
tain data from different clinics where testing data should be from a
different site than the training and validation data (Alegre et al., 2021;
Bori et al., 2020).
Another important issue is that patient data and treatment informa-
tion are not easily obtained for research due to data privacy and ethi-
cal considerations. This naturally limits the amount of patient related
data to be used for training the AI model. DL methods, which are es-
pecially suited for image and video classification, require a large
amount of diverse data to be generalisable. Another weakness for
some studies is that the data used for training are not connected to
any treatment outcome, leading to overly complex models that might
only
detect
irrelevant
correlations
(Dirvanauskas
et
al.,
2019;
Kanakasabapathy et al., 2019; Khosravi et al., 2019; Raudonis et al.,
2019; Bormann et al., 2020a; Bormann et al., 2020b; Fukunaga et al.,
2020; Rad et al., 2020; Zhao et al., 2021; Alegre et al., 2021). This can
raise concerns like, for example, whether the prediction is related to
the embryo implantation potential. Moreover, most articles resort to a
positive heartbeat at ultrasound control or even a positive hCG test
as their outcome, but the most important outcome in ART is the birth
of a living, healthy child (Vogiatzi et al., 2019; Bori et al., 2021).
AI models are usually evaluated using different metrics such as accu-
racy, precision and sensitivity. Often only a small subset or even just a
single metric is used to decide if the model performs well. This is not
sufficient, and to make a proper estimation about the performance, a
set of metrics needs to be considered. It might even be necessary to
develop task specific performance measurements.
The future symbiosis between
AI and ART
AI methods may be a supporting tool in predicting the patient’s
individual chance of achieving a healthy child based on available patient
data. Adjustments of treatment and prediction of risk and possibilities
for complications during pregnancy may be other tasks guided by AI.
In ART, AI models may assist in selecting methods, selecting the em-
bryo for transfer, and selecting the spermatozoon for ICSI.
As far as we know, no published studies have performed AI-guided
sperm selection for ICSI. Detailed real-time assessment of both motil-
ity and morphology simultaneously is a challenge in the present rou-
tine. By analysing video recordings of sperm selections by ML methods
that consider both the spatial and temporal domains, it may be possi-
ble to detect patterns or unknown characteristics that can be related
to ICSI outcomes. Similarly, until-now unrecognised features of impor-
tance for embryo quality might also be detected by analysing images
and videos of embryos.
At present, most of the publications are of a retrospective nature
and there is a lack of prospective studies. However, there are some
studies that are using retrospective data to perform a prospective
study (Bormann et al., 2020b; Huang et al., 2021). The latter should
preferably be performed as randomised controlled trials, in which the
performance of the AI model included in one arm is compared to
decisions routinely performed at a fertility clinic in the other arm, and
the outcome is defined as live births. The studies should optimally be
designed to include just single embryo transfers to exclude the uncer-
tainty arising when two (or more) embryos are transferred and only
one child is born. Most studies using AI for embryo assessment or se-
lection rely on manually extracted features from embryo images or
videos. However, over the last couple of years, there has been a rapid
increase in the use of DL techniques where features are automatically
learned. There are also a few studies using image segmentation techni-
ques to improve automatic embryo assessment (Rad et al., 2020) or
to streamline manual assessment (Zhao et al., 2021). The impact of
these methods in clinical practice is however limited and standardisa-
tion, explainable methods and transparency are keys to improve it.
Standardisation is essential for the development of an applicable and
reliable AI model. It requires close interdisciplinary collaboration from
the planning of the initial study to the clinical evaluation. In particular,
for the successful implementation of AI in the field of ART, a close col-
laboration between computer science, clinical experience and biologi-
cal knowledge, which also agree on a common standard, is crucial.
Most algorithms used in all the aforementioned articles, especially
DL-based, are black boxes. Ongoing research tries to increase the un-
derstanding of these black boxes (Holzinger et al., 2019; Arrieta et al.,
2020). In ART, methods for better understanding of black boxes are
still in their infancy, focusing on simple visualisation methods (Liu et al.,
2020; Abbasi et al., 2021). However, the whole pipeline of an AI sys-
tem should be transparent (Saito and Rehmsmeier, 2015), including
the evaluation method and metrics that need to be described clearly
(as in: Javadi and Mirroshandel, 2019; Bori et al., 2020). Increased
transparency of AI in ART will also be beneficial for discussions of legal
and ethical implications across countries, which often have different
regulations.
Furthermore, we need a common way of benchmarking and com-
paring different systems. In computer science, this is often done using
open benchmarking datasets collected and curated by the scientific
community. If the hardware changes, like data collected at higher reso-
lutions, the systems will have to be evaluated on the data collected
from these new devices. This means we need these community-wide
benchmarking datasets to be continuously tested before, during and af-
ter clinical trials to verify the performance of AI models. This is not
just important for research but also for commercial companies in the
Artificial intelligence in the fertility clinic
2439
 .............................................................................................................................................................................
field. Systems such as iDASCORE, KIDScore, Eeva and LensHooke
should follow the same requirements and be transparent and open
about data, methods and evaluation.
The datasets also need to be continuously updated following tech-
nological advances and new findings. There are a few open datasets
for sperm and embryo (Shaker et al., 2017; Saeedi et al., 2017;
Haugen et al., 2019; Javadi and Mirroshandel, 2019; Ilhan et al., 2020).
For sperm, datasets such as VISEM (Haugen et al., 2019) and
HuSHeM (Shaker et al., 2017) are commonly used for the evaluation
of sperm characteristics. For embryos, even fewer public datasets ex-
ist, and the data published by Saeedi et al. (2017) has been used for
blastocyst evaluation. Ideally, one publicly available dataset should be
used for developing algorithms and a hidden test dataset can be tested
on hardware provided by, for example, the European Society of
Human Reproduction and Embryology or the American Society for
Reproductive Medicine. This would ensure a common standard for
training and testing to provide reproducible and comparable results
necessary to make AI in ART clinically relevant.
Conclusion
Several studies have applied ML in ART, some of them focusing on
clinical relevance, while others concern AI methodological aspects.
The limitations are often small datasets and the use of AI algorithms
not specifically designed for the fertility clinic. Large open datasets and
methods specifically developed and tailored for use in context with
ART could lead to better results and understanding.
For AI to significantly impact ART, the model must be developed in
the context of clinical practice. Critical steps are proper evaluation and
testing of AI systems in relation to outcomes and regulations, a better
understanding of the technical aspects, and determination of the per-
formance of AI models regarding practical value in the clinic. In addi-
tion, it is important to standardise the use of AI in ART to enable
more transparent, comparable, and reproducible results.
To succeed with implementing AI as a valuable tool in the fertility
clinic, a strong interdisciplinary collaboration is required between
researchers in ART and AI as well as the clinical staff. In addition,
there is a need for large-scale randomised controlled trials where sev-
eral clinics are involved in testing the external validity of the algorithms
before defining AI systems that are sufficiently robust for safe clinical
implementation.
Data availability
The data generated during and/or analysed during the current study
(information extracted from the reviewed articles) are available from
the corresponding author on reasonable request.
Authors’ roles
M.A.R.: Lead for AI, literature review, writing and revising of text and
tables. M.H.S.: Lead for embryo section, literature review, writing and
revising. O.W.: Literature search and review, writing and revising.
J.M.A.: Tables, figures, literature review, writing. S.A.H.: Tables, figures,
literature review, writing and revising of text and tables. H.L.H.:
Literature review, writing and revising. E.D.: Literature review, writing.
P.H.: Literature review, writing. A.Y.: Literature review, writing. N.H.:
Literature review, writing. T.B.H.: Lead for sperm section, literature
review, writing and revising.
Funding
The work on this article was partially funded by the Frimedbio project
ReproAI granted by the Norwegian Research Council with Project
number 288727.
Conflicts of interest
Nothing to disclose.
References
Abbasi A, Miahi E, Mirroshandel SA. Effect of deep transfer and
multi-task learning on sperm abnormality detection. Comput Biol
Med 2021;128:104121.
Agarwal A, Henkel R, Huang CC, Lee MS. Automation of human se-
men analysis using a novel artificial intelligence optical microscopic
technology. Andrologia 2019;51:e13440.
Agarwal A, Panner Selvam MK, Ambar RF. Validation of LensHookeV
R
X1 PRO and computer-assisted semen analyzer compared with
laboratory-based manual semen analysis. World J Mens Health
2021;39:e7.
Alegre L, Del Gallego R, Bori L, Loewke K, Maddah M, Aparicio-Ruiz
B, Palma-Govea AP, Marcos J, Meseguer M. Assessment of em-
bryo implantation potential with a cloud-based automatic software.
Reprod Biomed Online 2021;42:66–74.
Armstrong S, Bhide P, Jordan V, Pacey A, Marjoribanks J, Farquhar
C. Time-lapse systems for embryo incubation and assessment in
assisted reproduction. Cochrane Database Syst Rev 2019; 5:
CD011320. doi: 10.1002/14651858.CD011320.pub4.
Arrieta AB, Diaz-Rodriguez N, Del Ser J, Bennetot A, Tabik S,
Barbado A, Garcia S, Gil-Lopez S, Molina D, Benjamins R. et al.
Explainable Artificial Intelligence (XAI): concepts, taxonomies, op-
portunities and challenges toward responsible AI. Inform Fusion
2020;58:82–115.
Bori L, Dominguez F, Fernandez EI, Del Gallego R, Alegre L,
Hickman C, Quinonero A, Nogueira MFG, Rocha JC, Meseguer M.
An artificial intelligence model based on the proteomic profile of
euploid embryos and blastocyst morphology: a preliminary study.
Reprod Biomed Online 2021;42:340–350.
Bori L, Paya E, Alegre L, Viloria TA, Remohi JA, Naranjo V,
Meseguer M. Novel and conventional embryo parameters as input
data for artificial neural networks: an artificial intelligence model
applied for prediction of the implantation potential. Fertil Steril
2020;114:1232–1241.
Bormann CL, Kanakasabapathy MK, Thirumalaraju P, Gupta R,
Pooniwala R, Kandula H, Hariton E, Souter I, Dimitriadis I,
Ramirez LB. et al. Performance of a deep learning based neural
2440
Riegler et al.
 ..............................................................................................................................................................................
network in the selection of human blastocysts for implantation.
eLife 2020a;9:1–14.
Bormann CL, Thirumalaraju P, Kanakasabapathy MK, Kandula H,
Souter I, Dimitriadis I, Gupta R, Pooniwala R, Shafiee H.
Consistency and objectivity of automated embryo assessments us-
ing deep neural networks. Fertil Steril 2020b;113:781–787.
Boulet SL, Mehta A, Kissin DM, Warner L, Kawwass JF, Jamieson DJ.
Trends in use of and reproductive outcomes associated with intra-
cytoplasmic sperm injection. JAMA 2015;313:255–263.
Chang V, Garcia A, Hitschfeld N, Hartel S. Gold-standard for
computer-assisted morphological sperm analysis. Comput Biol Med
2017;83:143–150.
Chang V, Saavedra JM, Castaneda V, Sarabia L, Hitschfeld N, Hartel
S. Gold-standard and improved framework for sperm head seg-
mentation. Comput Methods Programs Biomed 2014;117:225–237.
Chavez-Badiola
A,
Flores-Saiffe-Farias
A,
Mendizabal-Ruiz
G,
Drakeley AJ, Cohen J. Embryo Ranking Intelligent Classification
Algorithm (ERICA): artificial intelligence clinical assistant predicting
embryo ploidy and implantation. Reprod Biomed Online 2020a;41:
585–593.
Chavez-Badiola A, Flores-Saiffe Farias A, Mendizabal-Ruiz G, Garcia-
Sanchez R, Drakeley AJ, Garcia-Sandoval JP. Predicting pregnancy
test results after embryo transfer by image feature extraction and
analysis using machine learning. Sci Rep 2020b;10:4394.
Dang VQ, Vuong LN, Luu TM, Pham TD, Ho TM, Ha AN, Truong
BT, Phan AK, Nguyen DP, Pham TN. et al. Intracytoplasmic sperm
injection versus conventional in-vitro fertilisation in couples with in-
fertility in whom the male partner has normal total sperm count
and motility: an open-label, randomised controlled trial. Lancet
2021;397:1554–1563.
Dirvanauskas D, Maskeliunas R, Raudonis V, Damasevicius R.
Embryo development stage prediction algorithm for automated
time lapse incubators. Comput Methods Programs Biomed 2019;
177:161–174.
Fukunaga N, Sanami S, Kitasaka H, Tsuzuki Y, Watanabe H, Kida Y,
Takeda S, Asada Y. Development of an automated two pronuclei
detection system on time-lapse embryo images using deep learning
techniques. Reprod Med Biol 2020;19:286–294.
Goodson SG, White S, Stevans AM, Bhat S, Kao C-Y, Jaworski S,
Marlowe TR, Kohlmeier
M, McMillan
L,
Zeisel SH.
et al.
CASAnova: a multiclass support vector machine model for the
classification of human sperm motility patterns. Biol Reprod 2017;
97:698–708.
Goyal A, Kuchana M, Ayyagari KPR. Machine learning predicts
live-birth occurrence before in-vitro fertilization treatment. Sci
Rep 2020;10:20925.
Gunderson SJ, Puga Molina LC, Spies N, Balestrini PA, Buffone MG,
Jungheim ES, Riley J, Santi CM. Machine-learning algorithm incorpo-
rating capacitated sperm intracellular pH predicts conventional
in vitro fertilization success in normospermic patients. Fertil Steril
2021;115:930–939.
Haugen TB, Hicks SA, Andersen JM, Witczak O, Hammer HL, Borgli
R, Halvorsen P, Riegler M. Visem: a multimodal video dataset of
human spermatozoa. In: Proceedings of the 10th ACM Multimedia
Systems Conference, 2019, 261–266.
Hicks SA, Andersen JM, Witczak O, Thambawita V, Halvorsen P,
Hammer HL, Haugen TB, Riegler MA. Machine learning-based
analysis of sperm videos and participant data for male fertility pre-
diction. Sci Rep 2019;9:16770.
Holzinger A, Langs G, Denk H, Zatloukal K, Muller H. Causability
and
explainability
of
artificial
intelligence
in
medicine.
Wiley
Interdiscip Rev Data Min Knowl Discov 2019;9:e1312.
Hosny A, Parmar C, Quackenbush J, Schwartz LH, Aerts H. Artificial
intelligence in radiology. Nat Rev Cancer 2018;18:500–510.
Huang TTF, Kosasa T, Walker B, Arnett C, Huang CTF, Yin C,
Harun Y, Ahn HJ, Ohta A. Deep learning neural network
analysis of human blastocyst expansion from time-lapse image
files. Reprod Biomed Online 2021; 42:1075–1085. doi:10.1016/
j.rbmo.2021.02.015.
Høst E, Ernst E, Lindenberg S, Smidt-Jensen S. Morphology of sper-
matozoa used in IVF and ICSI from oligozoospermic men. Reprod
Biomed Online 2001;3:212–215.
Ilhan HO, Sigirci IO, Serbes G, Aydin N. A fully automated hybrid hu-
man sperm detection and classification system based on mobile-net
and the performance comparison with conventional methods. Med
Biol Eng Comput 2020;58:1047–1068.
Javadi S, Mirroshandel SA. A novel deep learning method for auto-
matic assessment of human sperm images. Comput Biol Med 2019;
109:182–194.
Kanakasabapathy MK, Thirumalaraju P, Bormann CL, Kandula H,
Dimitriadis I, Souter I, Yogesh V, Kota Sai Pavan S, Yarravarapu D,
Gupta R. et al. Development and evaluation of inexpensive auto-
mated deep learning-based imaging systems for embryology. Lab
Chip 2019;19:4139–4145.
Khosravi P, Kazemi E, Zhan Q, Malmsten JE, Toschi M, Zisimopoulos
P, Sigaras A, Lavery S, Cooper LAD, Hickman C. et al. Deep
learning enables robust assessment and selection of human blasto-
cysts after in vitro fertilization. Npj Digit Med 2019;2:21. doi:
10.1038/s41746-019-0096-y.
Kragh MF, Rimestad J, Berntsen J, Karstoft H. Automatic grading of
human blastocysts from time-lapse imaging. Comput Biol Med 2019;
115:103494.
Lemmen JG, Rodriguez NM, Andreasen LD, Loft A, Ziebe S. The to-
tal pregnancy potential
per oocyte
aspiration
after assisted
reproduction-in how many cycles are biologically competent
oocytes available? J Assist Reprod Genet 2016;33:849–854.
Liu L, Jiao Y, Li X, Ouyang Y, Shi D. Machine learning algorithms to
predict early pregnancy loss after in vitro fertilization-embryo
transfer with fetal heart rate as a strong predictor. Comput
Methods Programs Biomed 2020;196:105624.
McCallum C, Riordon J, Wang Y, Kong T, You JB, Sanner S, Lagunov
A, Hannam TG, Jarvi K, Sinton D. Deep learning-based selection
of human sperm with high DNA integrity. Commun Biol 2019;2:
250. doi:10.1038/s42003-019-0491-6.
Milewski R, Kuczynska A, Stankiewicz B, Kuczynski W. How much in-
formation about embryo implantation potential is included in morpho-
kinetic data? A prediction model based on artificial neural networks
and principal component analysis. Adv Med Sci 2017;62:202–206.
Mortimer ST, van der Horst G, Mortimer D. The future of
computer-aided sperm analysis. Asian J Androl 2015;17:545–553.
Movahed RA, Mohammadi E, Orooji M. Automatic segmentation of
Sperm’s parts in microscopic images of human semen smears using
concatenated learning approaches. Comput Biol Med 2019;109:
242–253.
Artificial intelligence in the fertility clinic
2441
 ........................................................................................................................
Paternot G, Devroe J, Debrock S, D’Hooghe TM, Spiessens C. Intra-
and inter-observer analysis in the morphological assessment of
early-stage
embryos.
Reprod
Biol
Endocrinol
2009;7:105.doi:
10.1186/1477-7827-7-105.
Qiu J, Li P, Dong M, Xin X, Tan J. Personalized prediction of live
birth prior to the first in vitro fertilization treatment: a machine
learning method. J Transl Med 2019;17:317. doi:10.1186/s12967-
019-2062-5.
Rad RM, Saeedi P, Au J, Havelock J. Human Blastocyst’s Zona
Pellucida segmentation via boosting ensemble of complementary
learning. Inform Med Unlocked 2018;13:112–121.
Rad RM, Saeedi P, Au J, Havelock J. Trophectoderm segmentation in
human embryo images via inceptioned U-Net. Med Image Anal
2020;62:101612.
Raef B, Maleki M, Ferdousi R. Computational prediction of implanta-
tion outcome after embryo transfer. Health Informatics J 2020;26:
1810–1826.
Raudonis V, Paulauskaite-Taraseviciene A, Sutiene K, Jonaitis D.
Towards the automation of early-stage human embryo develop-
ment
detection.
BioMed
Eng
OnLine
2019;18:120.
doi:
10.1186/s12938-019-0738-y.
Riordon J, McCallum C, Sinton D. Deep learning for the classification
of human sperm. Comput Biol Med 2019;111:103342.
Saeedi P, Yee D, Au J, Havelock J. Automatic identification of human
blastocyst components via texture. IEEE Trans Biomed Eng 2017;
64:2968–2978.
Saito T, Rehmsmeier M. The precision-recall plot is more informative
than the ROC plot when evaluating binary classifiers on imbal-
anced datasets. PLoS One 2015;10:e0118432.
Santos Filho E, Noble JA, Poli M, Griffiths T, Emerson G, Wells D. A
method for semi-automatic grading of human blastocyst micro-
scope images. Hum Reprod 2012;27:2641–2648.
Shaker F, Monadjemi SA, Alirezaie J, Naghsh-Nilchi AR. A dictionary
learning approach for human sperm heads classification. Comput
Biol Med 2017;91:181–190.
Storr A, Venetis CA, Cooke S, Kilani S, Ledger W. Inter-observer
and intra-observer agreement between embryologists during selec-
tion of a single Day 5 embryo for transfer: a multicenter study.
Hum Reprod 2017;32:307–314.
Sundvall L, Ingerslev HJ, Breth Knudsen U, Kirkegaard K. Inter- and
intra-observer variability of time-lapse annotations. Hum Reprod
2013;28:3215–3221.
Tomlinson MJ. Uncertainty of measurement and clinical value of se-
men analysis: has standardisation through professional guidelines
helped or hindered progress? Andrology 2016;4:763–770.
Tran D, Cooke S, Illingworth PJ, Gardner DK. Deep learning as a
predictive tool for fetal heart pregnancy following time-lapse
incubation
and
blastocyst
transfer.
Hum
Reprod
2019;34:
1011–1018.
Tsipras D, Santurkar S, Engstrom L, Ilyas A, Madry A. From imagenet
to image classification: contextualizing progress on benchmarks. Int
Conference on Machine Learning, Vol. 119 2020, 9625–9635.
Valiuskait_e V, Raudonis V, Maskeliunas R, Damasevicius R, Krilavicius
T. Deep learning based evaluation of spermatozoid motility for ar-
tificial insemination. Sensors 2021;21:72.
Vander Borght M, Wyns C. Fertility and infertility: definition and epi-
demiology. Clin Biochem 2018;62:2–10.
Ver Milyea M, Hall JMM, Diakiw SM, Johnston A, Nguyen T, Perugini
D, Miller A, Picou A, Murphy AP, Perugini M. Development of an
artificial intelligence-based assessment model for prediction of em-
bryo viability using static images captured by optical light micros-
copy during IVF. Hum Reprod 2020;35:770–784.
Vogiatzi P, Pouliakis A, Siristatidis C. An artificial neural network for
the prediction of assisted reproduction outcome. J Assist Reprod
Genet 2019;36:1441–1448.
WHO Laboratory Manual for the Examination and Processing of Human
Semen, 5th edn. Genova, Switzerland: WHO Press, 2010. World
Health Organization.
Wyns C, Bergh C, Calhaz-Jorge C, De Geyter C, Kupka M, Motrenko
T, Rugescu I, Smeenk JA. ART in Europe, 2020: results generated
from European registries by ESHRE. Hum Reprod Open 2020:
hoaa032. doi: 10.1093/hropen/hoaa032.
Yang YJ, Bang CS. Application of artificial intelligence in gastroenter-
ology. World J Gastroenterol 2019;25:1666–1683.
Zhao M, Xu M, Li H, Alqawasmeh O, Chung JPW, Li TC, Lee TL,
Tang PMK, Chan DYL. Application of convolutional neural net-
work on early human embryo segmentation during in vitro fertiliza-
tion. J Cell Mol Med 2021;25:2633–2644.
2442
Riegler et al.
",10.1093/humrep/deab168,doc14,": In recent years, the amount of data produced in the ﬁeld of ART has increased exponentially. The diversity of data is large,
ranging from videos to tabular data. At the same time, artiﬁcial intelligence (AI) is progressively used in medical practice and may become
a promising tool to improve success rates with ART. AI models may compensate for the lack of objectivity in several critical procedures in
fertility clinics, especially embryo and sperm assessments. Various models have been developed, and even though several of them show
promising performance, there are still many challenges to overcome. In this review, we present recent research on AI in the context of
ART. We discuss the strengths and weaknesses of the presented methods, especially regarding clinical relevance. We also address the pit-
falls hampering successful use of AI in the clinic and discuss future possibilities and important aspects to make AI truly useful for ART.
Key words: artiﬁcial intelligence / machine learning / ART / embryology / semen analysis / embryo / spermatozoa / fertility / infertility /
algorithm","................................................................... Artificial intelligence in the fertility clinic: status, pitfalls and possibilities M.A. Riegler 1,*, M.H. Stensen2, O. Witczak3, J.M. Andersen3, S.A. Hicks1,4, H.L. Hammer1,4, E. Delbarre 3, P. Halvorsen1,4, A. Yazidi4, N. Holst2, and T.B. Haugen3 1Department of Holistic Systems, Simula Metropolitan Center for Digital Engineering, Oslo, Norway 2Fertilitetssenteret, Oslo, Norway 3Department of Life Sciences and Health, Faculty of Health Sciences, OsloMet—Oslo Metropolitan University, Oslo, Norway 4Department of Computer Science, Faculty of Technology, Art and Design, OsloMet—Oslo Metropolitan University, Oslo, Norway *Correspondence address. Department of Holistic Systems, Simula Metropolitan Center for Digital Engineering, Oslo 0167, Norway. E-mail: michael@simula.no Submitted on May 19, 2021; resubmitted on June 21, 2021; editorial decision on June 23, 2021 ABSTRACT Introduction The number of treatments with ART is steadily increasing in Europe, and in 2016, over 900 000 treatment cycles were performed (Wyns et al., 2020). Even though there have been gradual improvements in the success rate, only one-third of the ART cycles result in a live birth, and only 5% of the aspirated oocytes have the competence to develop into a child (Lemmen et al., 2016; Wyns et al., 2020). This implies that there is potential for improvement in the crucial steps in ART treat- ments, such as the selection of embryos for transfer and the selection of spermatozoa for ICSI. Improving the ability to select a single em- bryo with the highest implantation potential could increase live birth rates and time to pregnancy, as well as minimise the chance of multi- ple pregnancies due to the transfer of multiple embryos. Likewise, a more reliable method for sperm selection may increase the success rates of the ICSI procedure. Furthermore, the disputable clinical value of semen analysis in male fertility investigation and for ART justifies a need for improving the methods of sperm evaluation both for diagnos- tic purposes and for decisions regarding the fertilisation method of the ART treatment. Video and image analysis constitutes a major part of ART, and artificial intelligence (AI) methods are especially suited for image classification. In addition to videos and images, AI can be used to ana- lyse other types of data, like text or tabular data. As in other parts of medicine, AI methods have been introduced in the field of ART. They have the advantage of objectivity and have the potential to improve ART, which in some parts are based on subjective assessments. In this review, we provide an overview of studies found in Embase (Ovid), where AI methods have been applied in human reproductive medicine with an emphasis on ART. Furthermore, we discuss how to avoid the pitfalls and describe the potential use of AI in clinical practice in the future. Current challenges in ART Highly trained personnel in fertility clinics are faced with important and difficult decisions every day, such as deciding which fertilisation method to use, which spermatozoon to select for ICSI, and which embryo to transfer to the uterus. One of the major challenges in the subjective assessments of embryos is the high intra- and inter-operator variability which exists in the evaluation of morphology and morphokinetics (Paternot et al., 2009; Sundvall et al., 2013; Storr et al., 2017). With time-lapse technology, embryos can be monitored continuously, and V C The Author(s) 2021. Published by Oxford University Press on behalf of European Society of Human Reproduction and Embryology. All rights reserved. For permissions, please email: journals.permissions@oup.com Human Reproduction, Vol.36, No.9, pp. 2429–2442, 2021 Advance Access Publication on July 29, 2021 doi:10.1093/humrep/deab168 MINI REVIEW ............................................................................................................................................................................. the complete process of embryo development is more precisely assessed. However, there is no evidence that the use of time-lapse technology has improved live birth rates after ART (Armstrong et al., 2019). Whilst sperm morphology has no definite impact on the outcome after ART, sperm concentration and sperm motility are normally assessed for deciding whether IVF or ICSI should be used as the fertil- isation method (Høst et al., 2001). Strikingly, ICSI is increasingly used irrespective of a male factor infertility diagnosis (Boulet et al., 2015; Vander Borght and Wyns, 2018). Among the cycles reported in Europe in 2016, 28% were IVF and 72% ICSI (Wyns et al., 2020), al- though the male factor accounts for only 20–30% of the diagnoses of the infertile couples. This is of increasing concern since performing ICSI instead of IVF in couples where the male partner has a defined normal semen sample does not increase the live birth rate (Dang et al., 2021). Early in the fertility investigation, a standard semen analysis accord- ing to WHO guidelines (WHO, 2010) is usually performed. This analy- sis might reveal information essential for deciding whether ART should be recommended as a treatment. The method is time-consuming and prone to limited reproducibility and high inter-personnel variation (Tomlinson, 2016). Several computer-aided sperm analyses (CASA) systems are available, but they are still most suitable for assessing sper- matozoa separated from seminal plasma, and their reliability is debat- able (Mortimer et al., 2015). When selecting spermatozoa to inject for ICSI, the procedure is performed by visually evaluating the morphology and motility of sper- matozoa with an ICSI microscope. This selection process is subjective, based on a qualitative evaluation of the operator, and not on objective sperm characteristics. The potential of AI in ART New technologies, such as better cameras and data capturing systems, are rapidly becoming an integrated part of the fertility clinic and result in a vast amount of stored data, including patient data, embryo time- lapse videos and sperm videos. In recent years, AI has proved to be a valuable tool in medicine by analysing large amounts of data (Hosny et al., 2018; Yang and Bang, 2019). A typical approach for using AI models in ART can be seen in Fig. 1. In particular, machine learning (ML), a subfield within AI, refers to algorithms that automatically learn from data without being explicitly programmed. An overview of common AI methods used in ART is given in Fig. 2. Supervised and unsupervised learning are subgroups of ML. Supervised learning refers to methods that learn from datasets where the answer (the label) is given for each observation. An ob- servation within a dataset could be data from an ART cycle, like an embryo image, and the label regarding whether the embryo resulted in a pregnancy or not. The algorithm will learn from the dataset, and the resulting ML model can be used to predict preg- nancy or not for data from another ART cycle with unknown labels. Unsupervised learning refers to methods that search for patterns in unlabelled data, for example, automatically grouping blastocyst images based on visual features automatically deter- mined by the algorithm that may correlate with morphological characteristics. Such visual features can be completely different from what human observers are able to recognise or may see as relevant. Artificial neural networks (ANNs) are a class of super- vised learning, and deep neural networks (DNNs), or deep learn- ing (DL), refers to especially large and complex ANNs. DL methods have the ability to learn from unstructured data such as images or text. Details of studies discussed in this review can be found in Table I for embryo related articles and in Table II for sperm related articles. AI in embryo assessment Most articles about embryo assessment and selection for transfer address the prediction of embryo quality, grading and ranking, and compare the performance of the AI model with an evaluation done by embryologists (Dirvanauskas et al., 2019; Kanakasabapathy et al., 2019; Khosravi et al., 2019; Raudonis et al., 2019; Fukunaga et al., 2020; Bormann et al., 2020a, 2020b; Rad et al., 2020; Zhao et al., 2021). To make an automatic grading system, the model must learn to locate the embryo in the dish, segment important features, and then assess and grade the embryo from manually annotated data. Manual annotations provided by embryologists are time-consuming to create, leading to small and sparsely annotated datasets. Therefore, most studies of AI methods and resulting models in ART can be considered preliminary. With the development of time-lapse technology, access to image and video data has become more available, making it possible to utilise this data to build new AI models. Dirvanauskas et al. predicted em- bryo development stages by time-lapse videos using features extracted from a Convolutional Neural Network (CNN). In one study, an auto- mated system was established to detect pronuclei in time-lapse images with the precision almost equivalent to highly skilled embryologists (Fukunaga et al., 2020). In another study, the zona pellucida (ZP) and the cytoplasm and pronucleus in zygotes were detected by developing an algorithm using DL image segmentation technology (Zhao et al., 2021). One group reported the possibility of identifying human em- bryo development stages (Raudonis et al., 2019). First, the location of an embryo in the image was detected by employing a visual image feature-based classifier. Then, a multi-class prediction model was de- veloped to predict the cell stage of the embryo using DL. Others reported a system to detect and assess blastocyst quality by using DL to detect the ZP area (Rad et al., 2018). Data augmentation techniques, like cropping and resizing which are usually used to increase dataset size or variation, were applied to em- bryo assessment to compensate for the lack of data for training the DL models (Rad et al., 2020). Augmented images were proven to be effective in filling the generalisation gap when available data is limited. Experimental results confirmed that the proposed models were capa- ble of segmenting trophectoderm (TE) regions. Inner cell mass (ICM) has been assessed by a computer-based and semi-automatic grading of human blastocysts (Santos Filho et al., 2012). A CNN was able to predict ICM and TE grades from a single frame (a frame is an image extracted from a video), and a recurrent neural network was applied on top to incorporate temporal informa- tion of the expanding blastocysts from multiple frames. Additionally, when evaluating implantation rates for embryos grouped by morphol- ogy grades, a CNN provided a slightly higher correlation between pre- dicted embryo quality and implantation ability than did human 2430 Riegler et al. ....................................................................... embryologists (Kragh et al., 2019). The use of a CNN trained to as- sess an embryo’s implantation potential directly, when using euploid embryos capable of implantation, outperformed 15 trained embryolo- gists (Bormann et al., 2020a). In a retrospective analysis of time-lapse videos and clinical outcomes of 10 000 embryos from eight different IVF clinics across four different countries, a DL model was built with a high level of predictability re- garding the embryo implantation likelihood (Tran et al., 2019). A pro- spective double-blinded study using retrospective data addressed the variability between embryologists to select embryos for biopsy and cryopreservation (Bormann et al., 2020b). It was found that the appli- cation of a DNN could improve the reliability and perform with high consistency during the process of embryo selection, thereby potentially improving outcomes. A DL-based system called Life Whisperer showed a sensitivity of 70% for viable embryos while maintaining a specificity of 61% for non-viable embryos across three independent blind test sets from different clinics (Ver Milyea et al., 2020). The model demonstrated a 25% increase over embryologists for accuracy, and the ranking comparison demonstrated an improvement of 42% over embryolo- gists. One embryo ranking model increased the success of ART treat- ments in oocyte donation programs (Alegre et al., 2021). The Figure 1. Development of a machine learning model. To implement a machine learning model at the clinic, at ﬁrst a clinically relevant aim should be deﬁned, and data must be collected in line with this aim. The collected data should then be stored in an appropriate format so that the ma- chine learning algorithm can process it. The stored data should be split into a training, validation and testing partitions to ensure a robust and thor- ough evaluation. In the optimal case the testing dataset is provided from an independent source (different clinic, new patients). These parts are then be used to build a model that is in line with the medical goal. After the model is built, it should be thoroughly evaluated to verify its generalisability and to avoid unintended biases. Once the model has been thoroughly tested, it can be implemented in the clinic. The model should be continuously monitored and tested while in production and as the circumstances required are updated. Figure 2. Subﬁelds deﬁned by artiﬁcial intelligence. Machine learning is the most relevant ﬁeld for the current develop- ment of artiﬁcial intelligence system for the clinic. Machine learning can further be split into traditional machine learning methods and deep learning. Note that the subﬁelds are not mutually exclusive; most of them rely heavily on machine learning, like computer vision and language processing. Artificial intelligence in the fertility clinic 2431 ............................................................................................................................................................................................................................. Table I Overview of studies using AI-methods in embryo assessment and selection, and for prediction before treatment. Year Study Aim of the study Outcome Dataset AI methods Summary answer 2017 Milewski et al. Investigating the poten- tial of using data on em- bryo implantation and morphokinetic parame- ters in predictive AI models. Probability of implanta- tion, clinical pregnancy. A dataset of time-lapse recordings of 610 em- bryos from 514 treat- ment cycles, morphokinetic parame- ters, data on implanta- tion, women’s age. It is unclear if the dataset was prospectively collected. Traditional ML (Principal Component Analysis) and Deep Learning (Multilayer Perceptron) Morphokinetic parame- ters from the time-lapse videos used to discrimi- nate between implanted and nonimplanted achieved an AUC of 0.71. 2018 Rad et al. Automatic segmentation of the Zona Pellucida. Segmentation of Zona Pellucida. A retrospective dataset consisting of images of blastocyst. Deep Learning The AI model was able to segment the Zona Pellucida with an IoU score of 0.78. 2019 Tran et al. Predict the probability of pregnancy with foetal heart from time-lapse videos. Foetal heart pregnancy or not. A retrospective dataset containing time-lapse videos of 10,638 em- bryos cultured to blasto- cyst stage from 1,648 patients across 8 IVF clinics. No manual as- sessment of videos. Deep Learning (CNN) AI model (IVY) was able to predict the probability of fetal heart pregnancy based on timelapse vid- eos with a mean AUC of 0.93. 2019 Dirvanauskas et al. Predict embryo develop- ment stage from time- lapse videos. Embryo development stage (1-cell, 2-cell, 4-cell, 8-cell, no embryo). A retrospective dataset containing 7,002 time- lapse images from 10 embryos. Deep learning (CNN) and traditional ML (K Nearest Neighbour, Cecoc, Decision Trees, Naive Bayes Classiﬁer) The AI model for em- bryo classiﬁcation achieved an accuracy of 97.62%. 2019 Kanakasabapathy et al. Develop inexpensive platforms for use in a stand-alone optical sys- tem and a smartphone- based optical system for automated grading of embryos based on images. Classiﬁcation of embryos based on cell morphology. A retrospective dataset containing 160 embryo images from a stand- alone optical system and 385 embryo images from a smartphone- based optical system. Models were pretrained on other high-quality embryo data. Deep Learning (CNN) Two systems were de- veloped for grading em- bryos (stand-alone imaging system and smartphone optical sys- tem). Both systems achieve an accuracy above 90%. 2019 Khosravi et al. Develop an AI model for accurate prediction of blastocyst quality and se- lection for single embryo for transfer. Classiﬁcation of embryos into poor-quality and good-quality. A retrospective dataset containing 12,001 time- lapse images at 110 hr post-insemination from 10,148 embryos. Manual classiﬁcation by embryol- ogists. Age of patient was included in the model for 2,182 em- bryos. Two external datasets were used for validation. Deep Learning (CNN) AI model (STORK) pre- dicted blastocyst quality with an AUC above 0.98. The model achieved an AUC of 0.90 and 0.76 respec- tively on two datasets from other clinics. 2019 Kragh et al. Develop AI method for automatic grading of blastocyst morphological appearance based on time-lapse images. Inner cell mass and tro- phectoderm grading, im- plantation rate. A dataset containing time-lapse videos of 4,483 embryos (both IVF and ICSI treatment). All images were graded by embryologists. Implantation information for 287 embryos. It is unclear if the dataset was prospectively collected. Deep Learning (CNN, Recurrent Neural Network) AI model achieved an accuracy of 65% for in- ner cell mass grading and 70% for trophectoderm grading. Prediction of im- plantation achieved an AUC of 0.66. (continued) 2432 Riegler et al. ............................................................................................................................................................................................................................. Table I Continued Year Study Aim of the study Outcome Dataset AI methods Summary answer 2019 Raudonis et al. Automatically detect hu- man embryo develop- ment stages during incubation. Detect embryo in an im- age and classify the em- bryo development stage (1-cell, 2-cell, 3-cell, 4-cell, > 4-cell). A dataset containing images of early-stage embryo development from an ESCO Miri TL incubator system. It is unclear if the dataset was prospectively collected. Deep Learning (CNN) Two AI models were considered, both achieved a stage classiﬁ- cation accuracy above 92%. The most difﬁcult stage to classify was 3-cell. 2019 Qiu et al. Prediction of a clinical model for estimating the cumulative live birth chance of the ﬁrst com- plete IVF cycle using pre- treatment variables in- cluding BMI and AMH. Cumulative live birth chance before IVF. A retrospective dataset containing age, AMH, BMI, duration of infertil- ity, previous live birth, previous miscarriage, previous abortion, and type of infertility. Traditional ML (Logistic Regression, Random Forest, XGBoost, Support Vector Machine) Four machine learning models were tested, of which XGBoost achieved the best score with an AUC of 0.73. The results indicate that BMI and AMH have a signiﬁcant impact on live birth. 2019 Vogiatzi et al. Predict live birth from embryo variables by in- cluding parameters that exert a meaningful effect on live birth following as- sisted reproduction. Live birth or not. 12 input features: Age (female), Age at menar- che, Difﬁculty during ET, Endometrium thickness prior to OR, ET/2PN, TQE D3, TQE D3/2PN, Total gonadotropins, Age group, Dyspareunia, Fresh or frozen cycle, Menarche > 12 years. The dataset was col- lected retrospectively. Deep Learning (Multilayer Perceptron) A multilayer perceptron using the 12 input fea- tures achieved a sensitiv- ity of 0.71 and a speciﬁcity of 0.70 for predicting live birth. 2020 Bori et al. Describe novel embryo features for implantation potential prediction that may be used as input data in AI models. Prediction of implanta- tion potential. A retrospective dataset containing time-lapse images from 637 em- bryos (ICSI-cycles with- out PGT, single fresh embryo transfer), Implantation rate based on foetal heartbeat ultra- sound after eight weeks. Oocyte donation programme. Deep Learning (Multilayer Perceptron) Two novel embryo fea- tures with signiﬁcantly different values in implanted and nonim- planted embryos were identiﬁed. Novel embryo features, in addition to conventional morphoki- netic parameters, can improve predictive AI models. 2020 Bormann et al. (a) Evaluation of AI models for embryo selection based on images. Embryo quality and im- plantation potential. A retrospective dataset containing single time- point images at 113 h post-insemination for 742 embryos from 97 patients. Deep Learning (CNN) Two AI models were evaluated. One selected the highest quality em- bryo with 90% accuracy, and the other was able to assess implantation potential better than trained embryologists from different fertility centres. 2020 Bormann et al. (b) Evaluate AI models for embryo quality scoring and assessment of bi- opsy or cryopreserva- tion of blastocysts, compared to decisions by trained embryologists. Morphological quality on a 1–5 scale. For embryo scoring, images from 3469 em- bryos. 748 at 70 h post- insemination and 742 images at 113 h post-in- semination. For biopsy and cryopreservation as- sessment, 56 blastocysts images at 113 h post-in- semination. All images were evaluated by Deep Learning (CNN) The AI models showed less variability in embryo grading than embryolo- gists and outperformed the embryologists in selecting blastocyst bi- opsy and cryopreservation. (continued) Artificial intelligence in the fertility clinic 2433 ............................................................................................................................................................................................................................. Table I Continued Year Study Aim of the study Outcome Dataset AI methods Summary answer trained embryologists. Both datasets were ret- rospectively collected. 2020 Chavez-Badiola et al. (a) Evaluate AI model per- formance for prediction of ploidy and implanta- tion compared to trained embryologists. Embryo ranking, embryo ploidy. A retrospective dataset containing single time- point images from 840 embryos at day 5 or 6 after fertilization by ICSI. Ploidy, hCG results, or both were known. Deep Learning (Multilayer Perceptron) An AI model (ERICA) was able to identify and rank blastocysts with the best potential from one image with higher accu- racy than embryologists. 2020 Chavez-Badiola et al. (b) Predict pregnancy test results after embryo transfer. Successful pregnancy or not. A retrospective dataset containing embryo images and patient age. Traditional ML (Probabilistic Bayesian, Support Vector Machine, Decision Trees, Random Forest) and Deep Learning (Multilayer Perceptron) Several AI models were tested, of which the sup- port vector machine achieved the best result across three datasets. 2020 Fukunaga et al. Automatic pronuclei counting using deep learning. Number of pronuclei. A dataset containing 900 time-lapse images of 300 embryos up to 20 h post-insemination. 70 images of each embryo. Manual assessment and annotation of pronuclei. It is unclear if the dataset was prospectively collected. Deep Learning (CNN) The AI model was able to count pronuclei with a sensitivity of 99% for 0PN, 82% for 1PN, and 99% for 2PN. The sys- tem performed similarly to that of trained human experts. 2020 Rad et al. Automatic trophecto- derm segmentation in human embryo using deep learning. Trophectoderm segmentation. A retrospective dataset containing images of day-5 human embryo. Deep Learning (CNN, Generative Adversarial Networks) An AI model was used to segment human em- bryos. The model achieved an IoU score of 76.71. 2020 Raef et al. Predict implantation out- come after embryo transfer cycle. Implantation rate. Positive or negative beta-HCG. A dataset containing 82 features (patient-related data, female and male pathology, semen analy- sis, lab tests, oocyte and embryo data and PRP) Attributes related to im- plantation arranged in two groups (N ¼ 82): 1) patient-related features (N ¼ 59) and 2) ART cy- cle features (N ¼ 23). It is unclear if the dataset was prospectively collected. Traditional ML (Naive Bayes Classiﬁer, Support Vector Machine, Random Forest, K Nearest Neighbour, Decision Trees) and Deep Learning (Multilayer Perceptron) Six AI models were tested, where the ran- dom forest algorithm achieved the best result with an accuracy of 90.4% and an AUC of 93.7%. 2020 Ver Milyea et al. Predict embryo viability using images captured by optical light microscopy. Implantation rate—foe- tal heartbeat. A retrospective dataset containing light micros- copy images of blasto- cysts, clinical outcome. Deep Learning (Convolutional Neural Network) An AI model (Life Whisperer) was tested on three independent testing datasets, where it achieved a 70.1% sensi- tivity for viable embryos and a speciﬁcity of 60.5% for non-viable embryos. 2020 Goyal et al. Predict live birth before IVF treatment. Live birth or not. A retrospective dataset containing 141,160 pa- tient records, Deep Learning (Multilayer Perceptron) Several machine learning models were evaluated, of which the multilayer (continued) 2434 Riegler et al. .................................................. multicentre nature of the above study supported its applicability at dif- ferent clinics, standardising the interpretation of embryo development. Embryo assessment, ranking, and selection are procedures nor- mally based on evaluations at different time points during embryo development and in several focal planes to get a view of the whole embryo. There are numerous studies where only static images, usu- ally in one single focal plane, are used for the AI analysis, which do not mirror the clinical practice (Rad et al., 2018; Kanakasabapathy et al., 2019; Khosravi et al., 2019; Bormann et al., 2020a, 2020b; Chavez-Badiola et al., 2020a; Chavez-Badiola et al., 2020b; Bori et al., 2021). In these models, well-curated, high-quality data is cru- cial. For example, non-selection of a large number of images repre- sentative of the diversity, inconsistent image treatment or inaccurate labelling of images can lead to poor performing models (Tsipras et al., 2020). Models involving time-lapse videos might also raise problems since the definition of the important morphokinetic markers may vary between different laboratories and still requires an automated and unbiased process (Milewski et al., 2017; Dirvanauskas et al., 2019; Tran et al., 2019; Bori et al., 2020; Alegre et al., 2021). AI methods should incorporate patient data that may impact the outcome, such as maternal age. A framework (STORK) based on a large collection of human embryo time-lapse images used a CNN to automatically predict blastocyst quality depending on patient age (Khosravi et al., 2019). Milewski et al. extracted several time points and specific relative cleavage times together with fragmentation levels, presence of multinucleation, evenness of blastomeres and woman’s age. An ANN was trained to predict embryo implantation from the extracted features. Another study that included 82 features of patient data found that follicle stimulating hormone/human meno- pausal gonadotropin dosage was the strongest predictor of embryo implantation (Raef et al., 2020). ............................................................................................................................................................................................................................. Table I Continued Year Study Aim of the study Outcome Dataset AI methods Summary answer anonymized register data collected from the year 2010–2016 obtained from the Human Fertilisation & Embryology Authority. perceptron performed best with an F1-Score of 72.94%. 2021 Alegre et al. Evaluate and test an au- tomatic software for em- bryo evaluation and selection (Dana). Embryo implantation potential. A retrospective dataset containing time-lapse images and patient char- acteristics from oocyte donation program. Phase 1: 1,676 embryos from 955 couples. Phase 2: 996 embryos from 249 cycles (multiple centres). Phase 3 147 embryos from 108 patients. Deep Learning (CNN) Increased success of IVF treatment was found with the assistance of au- tomated embryo ranking by Dana. The creation of a data cloud can improve the system further. 2021 Bori et al. Develop an AI model for prediction of live birth based on blastocyst morphology and proteo- mic proﬁle of culture media. Prediction of live birth. A retrospective dataset containing single time point images at 111 hr þ/- 1.5 hr from 212 patients. 186 embryos after exclusions (131 non PGT from oocyte donation programme, 55 PDG with proteomic proﬁle. Deep Learning (Multilayer Perceptron) Three AI models using both morphological and proteomic variables. The best model predicted live birth with an AUC of 1.0. 2021 Zhao et al. Automatic segmentation of day one embryos in zona pellucida (ZP), cy- toplasm, and pronucleus (PN). Cytoplasm, ZP and PN segments. A dataset containing images of day-one em- bryos (zygotes). It is unclear if the dataset was prospectively collected. Deep Learning (CNN, Generative Adversarial Networks) The AI model achieved a precision of 97% when segmenting the cyto- plasm, 80% for the zona pellucida, and 84% for the pronucleus. AI, Artiﬁcial intelligence; CNN, Convolutional neural network; AUC, Area under the curve; IVF, In vitro fertilization; ICSI, Intracytoplasmic sperm injection; ZP, Zona pellucida; PN, Pronucleus, PGT, Preimplantation genetic testing; AMH, Anti-Mullerian hormone; BMI, body mass index. Artificial intelligence in the fertility clinic 2435 ............................................................................................................................................................................................................................ Table II Overview of studies using AI-methods in semen analysis and selection of sperm for ICSI. Year Study Aim of study Outcome Dataset AI Methods Summary answer 2014 Chang et al. Improve AI models for detection of hu- man sperm head characteristics in- cluding, acrosome and nucleus. Sperm morphology A prospective data- set containing 20 images with a total of 210 stained sperm cells. Sperm cell details were manu- ally classiﬁed and an- notated in the dataset. Traditional ML (Clustering) Models showed 80% overlap with manual classiﬁcation and more precise sperm head detection and segmentation than previously described models. 2017 Chang et al. Explore AI modes to classify sperm head morphology into ﬁve classes (normal, ta- pered, pyriform, small, amorphous) and introduce a new dataset. Sperm morphology A retrospective dataset containing images of 1,854 stained sperm heads from six semen smears (SCIAN MorphoSpermGS). Sperm head shape was manually classi- ﬁed and annotated in the dataset. 432 The best model was able to obtain 49% correct classiﬁcation of head shape into the ﬁve classes. 2017 Shaker et al. Explore Dictionary Learning technique for classiﬁcation of sperm head shapes into four classes (normal, tapered pyriform and amor- phous), and intro- duce a new dataset. Sperm morphology Two retrospective datasets. 216 images of stained sperm heads (HuSHeM dataset). Sperm head shape was manually classiﬁed and annotated in the dataset. 1133 images from the SCIAN- MorphoSpermGS dataset. Traditional ML (Dictionary Learning) Use of Dictionary Learning was more effective for sperm head classiﬁcation than previously pub- lished shape-based features. 2017 Goodson et al. Development of AI model for classiﬁca- tion of sperm motil- ity patterns during invitro capacitation. Sperm motility CASA tracks of 2,817 washed sperm cells from 18 sub- jects. All tacks were manually classiﬁed as progressive, interme- diate, hyperacti- vated, slow, weakly motile. It is unclear if the dataset was pro- spectively collected. Traditional ML (Support Vector Machine, Decision Tree) A web-based pro- gram, CASAnova, was developed. This program classiﬁes sperm motility pat- terns into one of ﬁve classes with an over- all accuracy of 89.9%. 2019 Agarwal et al. Evaluate the perfor- mance of an auto- mated AI system (LensHook) to mea- sure sperm concen- tration and sperm motility. Sperm concentration and sperm motility A prospective data- set containing images and video from 135 semen samples. No information available Concentration and motility analysed by LensHook were comparable to man- ual assessment. 2019 Hicks et al. Predict sperm motil- ity from videos and introduce a new dataset. Sperm motility A retrospective dataset containing videos of live sperm in untreated samples from 85 subjects (VISEM). Semen analysis was manually evaluated according to WHO 2010. Deep Learning (CNN) Deep learning showed potential for rapid and consistent prediction of sperm motility categories (WHO 2010) based on videos of live, untreated sperm samples. (continued) 2436 Riegler et al. ............................................................................................................................................................................................................................ Table II Continued Year Study Aim of study Outcome Dataset AI Methods Summary answer 2019 Riordon et al. Automatic assess- ment for classiﬁcation of sperm head mor- phology into ﬁve clas- ses (normal, tapered, pyriform, small, and amorphous). Sperm morphology Retrospective images from HuSHeM data- set and 1,132 images from SCIAN dataset. Deep learning (CNN) Deep learning can classify sperm head morphology with higher accuracy than previously published AI methods used for the same datasets. 2019 Javadi and Mirroshandel Automatic assess- ment of sperm mor- phology in unﬁxed cells and introduce a new dataset. Sperm morphology 1,540 retrospective grey scale images of unﬁxed sperm cells from 235 subjects (MHSMA dataset). Sperm cells were manually classiﬁed as normal or abnormal, and acrosome, head, vacuole, tail, and neck were annotated. Deep learning (CNN) The method is able to classify sperm in real-time, but accu- racy needs to be improved. 2019 McCallum et al. Automatic method for ranking sperm cells based on DNA quality enabling sperm selection for ICSI. Sperm DNA integrity 1,064 images of stained sperm cells with known DNA in- tegrity from 6 sub- jects. It is unclear if the dataset was pro- spectively collected. Deep learning (CNN) Correlation between cell image and DNA integrity was found, and the model was able to predict the DNA integrity of sperm cells in a rapid manner. 2019 Movahed et al. Automatic segmen- tation of external (head, mid piece, and tail) and internal parts (acrosome and nucleus) of the sperm. Sperm morphology A retrospective dataset containing 20 images of stained sperm cells. Sperm parts were manually annotated. Deep learning (CNN) and tradi- tional ML (Support Vector Machine, K- nearest neighbour, Ensemble Method) The methods were better at segmenting the head, acrosome, and nucleus than previously described models. Provides the ﬁrst method for eval- uation of tail and mid piece. 2020 Ilhan et al. Fully automated analyses of sperm morphology by a smartphone-based system and intro- duce a new dataset. Sperm morphology 200 retrospective images of stained sperm cells from 17 subjects (SMIDS dataset). Sperm cells were manually classi- ﬁed as normal or abnormal. Deep learning (CNN) and tradi- tional ML (Support Vector Machine, Decision Trees, K- Nearest Neighbours) The most precise model was able to predict normal or abnormal sperm with an accuracy of 87%. 2021 Abbasi et al. Improve AI models for classiﬁcation of the sperm head, vacuoles, and acro- some as normal or abnormal. Sperm morphology 1,540 retrospective images from the MHSMA dataset. Deep learning (CNN) Both AI models were able to predict sperm head charac- teristics more accu- rately than models previously described in other studies. 2021 Valiuskaite et al. Propose an AI method that can pre- dict if a semen sam- ple is suitable for artiﬁcial insemination procedure based on videos of semen samples. Sperm motility 85 retrospective videos from the VISEM dataset. Deep learning (CNN) The AI model detected sperm heads in the videos with an accuracy of 91.8%, and the Pearson correlation between manually assessed motility and predicted sperm head motility was 0.969. AI, Artiﬁcial intelligence; CNN, Convolutional neural network; CASA, Computer-assisted semen analysis. Artificial intelligence in the fertility clinic 2437 ............................................................................................................................................................................. AI in prediction of outcome before treatment In several publications, AI was used to build models that predict the possibility of a successful treatment based on a patient’s medical re- cord. The result may be of value for patient counselling about the po- tential results of the treatment. Goyal et al. used the dataset provided by Human Fertilisation and Embryology Authority (HFEA) which included 30 different features such as age, number of previous ART cycles, number of previous pregnancies, number of inseminated oocytes, number of embryos transferred, and diagnosis for a total of 140 000 patients. Several ML techniques were evaluated to predict live-birth occurrence. They concluded that both male and female traits and living conditions were factors that influenced the outcome of the treatment. A well-known ML technique called extreme gradient boosting (XGBoost) has been used to predict live birth from fea- tures such as age, anti-Mullerian hormone, BMI and patient anam- nesis (Qiu et al., 2019). Similarly, an ANN was trained to predict live birth using a collection of features such as the age of the fe- male, total dose of gonadotrophins administered, endometrial thick- ness, and the number of top-quality embryos (Vogiatzi et al., 2019). AI in analysis of sperm Most studies using an AI approach for semen analyses have been per- formed for morphology assessments. The morphological classification is usually performed on stained spermatozoa and implies both distin- guishing abnormal from normal spermatozoa as well as identifying vari- ous defects of the sperm cell (WHO, 2010). Some of the developed AI models have been trained only to predict the morphology of sperm heads (Chang et al., 2014; Chang et al.; 2017; Shaker et al., 2017; Riordon et al., 2019), whereas other studies describe the recognition of various parts of the whole sperm (Movahed et al., 2019; Ilhan et al., 2020). These differences in the approaches make it difficult to com- pare results and possible implications for clinical practice even if the overall goal is similar. This is also fortified by the fact that the data used is usually very limited, with only a small number of spermatozoa or patients. Training and evaluating complex methods, for example, DL, with a small-sized dataset most probably leads to an overfitted model. An overfitted model is a model that does not generalise well to unseen real-world cases although it works well on the training data. For example, suppose that a model is trained on a dataset of embryo images to predict pregnancy or not. If the model achieves far higher prediction performance on the embryo images used for training than on new and unseen images, the model is overfitted to the training data. Annotation of the dataset/sperm images must be done manually and with high accuracy to obtain well-performing models. For recog- nising and interpreting images of spermatozoa at the pixel level, seg- mentation is the common approach, in which the spermatozoon is divided into parts, each consisting of a set of pixels. Some studies demonstrate high classification accuracy for morphological characteris- tics, and most of the studies have both trained and validated the mod- els on freely available datasets, which makes them easier to compare (HuSHeM in Shaker et al. , SCIAN in Chang et al. , and a smaller dataset of 264 spermatozoa in Chang et al. ). Furthermore, the model performance is compared with existing AI models, and even though this is common practice in the field of AI, it reveals little knowledge about the clinical usability of the model. Regarding sperm morphology, as far as we know, there are no studies comparing the performance of the models with manual assessment according to the WHO guidelines or in relation to fertility outcomes. For prediction of sperm motility, only one study compared AI-based sperm motility classification against sperm motility that was manually assessed following WHO guidelines (Hicks et al., 2019), while others were mainly focused on comparing various models or exploring the sperm kinematics (Goodson et al., 2017; Valiuskait_e et al., 2020). Studies related to motility and/or morphology also come with the challenge of small datasets, and for both of them, the evaluation pro- cedures are often not clear. Cross validation is sometimes used to compensate for small datasets (Goodson et al., 2017; Shaker et al., 2017). However, even though cross validation is acceptable for testing model performance and comparing it to other models on the same dataset, it does not test the generalisability of the results. In a clinical setting, an independent test set evaluation should be performed, opti- mally across different clinics (Abbasi et al., 2021). Automatic systems for diagnostic purposes have been developed. One such system based on an automatic segmentation step and a clas- sification of normal/abnormal spermatozoa has recently been de- scribed (Ilhan et al., 2020). The authors reported an accuracy of 87%. However, the method was just compared with other ML methods and not evaluated for its clinical value. In addition, accuracy alone is not a sufficient metric to determine the possible clinical performance of a method, especially if only a small dataset is used. Another automatic system for analysis of sperm concentration, morphology and motility used AI optical microscopic technology, for which the performance was compared with manual assessment (Agarwal et al., 2019, 2021). Nonetheless, the morphology values did not correlate with the manual morphology results, and unfortunately, there are no details provided on the construction and annotation of the dataset. Parameters that are not part of standard semen analysis have also been used in AI models. For example, sperm intracellular pH was shown to be a stable marker for fertilisation outcome (Gunderson et al., 2021), and sperm DNA integrity could be predicted from bright- field sperm images at a single cell level through supervised training (McCallum et al., 2019). These studies show how AI can be used to automate sperm sorting and selection tasks. However, big datasets from multicentre cohorts are needed to evaluate whether the results are generalisable before these AI models can be used in the clinic as well as for research related purposes. In addition to the conventional semen variables, image features may detect sperm characteristics that are too complex to be recognised by humans, for example, motility patterns or morphological shapes. Nonetheless, from a diagnostic per- spective, the clinical value of novel traits must be investigated in epide- miological studies. The selection of spermatozoa for ICSI is based on a cursory assess- ment of motility and morphology in real-time, which is especially a challenge for morphology evaluation. The procedure has a potential for improvement using AI to obtain a more objective selection based on the simultaneous monitoring of morphology and motility patterns. Attempts have been made to develop DL models for morphological assessment based on images of unstained spermatozoa (Javadi and Mirroshandel, 2019; Abbasi et al., 2021). Both algorithms can analyse 2438 Riegler et al. ............................................................................................................................................................................. fresh human sperm in real-time with a magnification between 400 and 600. The AI methods used in sperm related studies are mostly based on simple algorithms that are standard implementation in most ML frame- works (Table II). The development of more domain-specific methods and models related to ART will in the long run lead to better results compared to using out-of-the-box methods from existing generic frameworks. Pitfalls The AI algorithms are only as good as the data they are based on. There may also be limitations regarding generalisability due to difficul- ties with the standardisation of the ML methods. Variation in patient demographics, clinical and laboratory practices may cause data bias. When an AI model is based on training in one clinic, the AI model should be validated in independent cohorts (Tran et al., 2019; Bormann et al., 2020b). Furthermore, the models should not be lim- ited to strict inclusion criteria, and optimally the datasets should con- tain data from different clinics where testing data should be from a different site than the training and validation data (Alegre et al., 2021; Bori et al., 2020). Another important issue is that patient data and treatment informa- tion are not easily obtained for research due to data privacy and ethi- cal considerations. This naturally limits the amount of patient related data to be used for training the AI model. DL methods, which are es- pecially suited for image and video classification, require a large amount of diverse data to be generalisable. Another weakness for some studies is that the data used for training are not connected to any treatment outcome, leading to overly complex models that might only detect irrelevant correlations (Dirvanauskas et al., 2019; Kanakasabapathy et al., 2019; Khosravi et al., 2019; Raudonis et al., 2019; Bormann et al., 2020a; Bormann et al., 2020b; Fukunaga et al., 2020; Rad et al., 2020; Zhao et al., 2021; Alegre et al., 2021). This can raise concerns like, for example, whether the prediction is related to the embryo implantation potential. Moreover, most articles resort to a positive heartbeat at ultrasound control or even a positive hCG test as their outcome, but the most important outcome in ART is the birth of a living, healthy child (Vogiatzi et al., 2019; Bori et al., 2021). AI models are usually evaluated using different metrics such as accu- racy, precision and sensitivity. Often only a small subset or even just a single metric is used to decide if the model performs well. This is not sufficient, and to make a proper estimation about the performance, a set of metrics needs to be considered. It might even be necessary to develop task specific performance measurements. The future symbiosis between AI and ART AI methods may be a supporting tool in predicting the patient’s individual chance of achieving a healthy child based on available patient data. Adjustments of treatment and prediction of risk and possibilities for complications during pregnancy may be other tasks guided by AI. In ART, AI models may assist in selecting methods, selecting the em- bryo for transfer, and selecting the spermatozoon for ICSI. As far as we know, no published studies have performed AI-guided sperm selection for ICSI. Detailed real-time assessment of both motil- ity and morphology simultaneously is a challenge in the present rou- tine. By analysing video recordings of sperm selections by ML methods that consider both the spatial and temporal domains, it may be possi- ble to detect patterns or unknown characteristics that can be related to ICSI outcomes. Similarly, until-now unrecognised features of impor- tance for embryo quality might also be detected by analysing images and videos of embryos. At present, most of the publications are of a retrospective nature and there is a lack of prospective studies. However, there are some studies that are using retrospective data to perform a prospective study (Bormann et al., 2020b; Huang et al., 2021). The latter should preferably be performed as randomised controlled trials, in which the performance of the AI model included in one arm is compared to decisions routinely performed at a fertility clinic in the other arm, and the outcome is defined as live births. The studies should optimally be designed to include just single embryo transfers to exclude the uncer- tainty arising when two (or more) embryos are transferred and only one child is born. Most studies using AI for embryo assessment or se- lection rely on manually extracted features from embryo images or videos. However, over the last couple of years, there has been a rapid increase in the use of DL techniques where features are automatically learned. There are also a few studies using image segmentation techni- ques to improve automatic embryo assessment (Rad et al., 2020) or to streamline manual assessment (Zhao et al., 2021). The impact of these methods in clinical practice is however limited and standardisa- tion, explainable methods and transparency are keys to improve it. Standardisation is essential for the development of an applicable and reliable AI model. It requires close interdisciplinary collaboration from the planning of the initial study to the clinical evaluation. In particular, for the successful implementation of AI in the field of ART, a close col- laboration between computer science, clinical experience and biologi- cal knowledge, which also agree on a common standard, is crucial. Most algorithms used in all the aforementioned articles, especially DL-based, are black boxes. Ongoing research tries to increase the un- derstanding of these black boxes (Holzinger et al., 2019; Arrieta et al., 2020). In ART, methods for better understanding of black boxes are still in their infancy, focusing on simple visualisation methods (Liu et al., 2020; Abbasi et al., 2021). However, the whole pipeline of an AI sys- tem should be transparent (Saito and Rehmsmeier, 2015), including the evaluation method and metrics that need to be described clearly (as in: Javadi and Mirroshandel, 2019; Bori et al., 2020). Increased transparency of AI in ART will also be beneficial for discussions of legal and ethical implications across countries, which often have different regulations. Furthermore, we need a common way of benchmarking and com- paring different systems. In computer science, this is often done using open benchmarking datasets collected and curated by the scientific community. If the hardware changes, like data collected at higher reso- lutions, the systems will have to be evaluated on the data collected from these new devices. This means we need these community-wide benchmarking datasets to be continuously tested before, during and af- ter clinical trials to verify the performance of AI models. This is not just important for research but also for commercial companies in the Artificial intelligence in the fertility clinic 2439 ............................................................................................................................................................................. field. Systems such as iDASCORE, KIDScore, Eeva and LensHooke should follow the same requirements and be transparent and open about data, methods and evaluation. The datasets also need to be continuously updated following tech- nological advances and new findings. There are a few open datasets for sperm and embryo (Shaker et al., 2017; Saeedi et al., 2017; Haugen et al., 2019; Javadi and Mirroshandel, 2019; Ilhan et al., 2020). For sperm, datasets such as VISEM (Haugen et al., 2019) and HuSHeM (Shaker et al., 2017) are commonly used for the evaluation of sperm characteristics. For embryos, even fewer public datasets ex- ist, and the data published by Saeedi et al. has been used for blastocyst evaluation. Ideally, one publicly available dataset should be used for developing algorithms and a hidden test dataset can be tested on hardware provided by, for example, the European Society of Human Reproduction and Embryology or the American Society for Reproductive Medicine. This would ensure a common standard for training and testing to provide reproducible and comparable results necessary to make AI in ART clinically relevant. Conclusion Several studies have applied ML in ART, some of them focusing on clinical relevance, while others concern AI methodological aspects. The limitations are often small datasets and the use of AI algorithms not specifically designed for the fertility clinic. Large open datasets and methods specifically developed and tailored for use in context with ART could lead to better results and understanding. For AI to significantly impact ART, the model must be developed in the context of clinical practice. Critical steps are proper evaluation and testing of AI systems in relation to outcomes and regulations, a better understanding of the technical aspects, and determination of the per- formance of AI models regarding practical value in the clinic. In addi- tion, it is important to standardise the use of AI in ART to enable more transparent, comparable, and reproducible results. To succeed with implementing AI as a valuable tool in the fertility clinic, a strong interdisciplinary collaboration is required between researchers in ART and AI as well as the clinical staff. In addition, there is a need for large-scale randomised controlled trials where sev- eral clinics are involved in testing the external validity of the algorithms before defining AI systems that are sufficiently robust for safe clinical implementation. Data availability The data generated during and/or analysed during the current study (information extracted from the reviewed articles) are available from the corresponding author on reasonable request. Authors’ roles M.A.R.: Lead for AI, literature review, writing and revising of text and tables. M.H.S.: Lead for embryo section, literature review, writing and revising. O.W.: Literature search and review, writing and revising. J.M.A.: Tables, figures, literature review, writing. S.A.H.: Tables, figures, literature review, writing and revising of text and tables. H.L.H.: Literature review, writing and revising. E.D.: Literature review, writing. P.H.: Literature review, writing. A.Y.: Literature review, writing. N.H.: Literature review, writing. T.B.H.: Lead for sperm section, literature review, writing and revising. Funding The work on this article was partially funded by the Frimedbio project ReproAI granted by the Norwegian Research Council with Project number 288727. Conflicts of interest Nothing to disclose. References Abbasi A, Miahi E, Mirroshandel SA. Effect of deep transfer and multi-task learning on sperm abnormality detection. Comput Biol Med 2021;128:104121. Agarwal A, Henkel R, Huang CC, Lee MS. Automation of human se- men analysis using a novel artificial intelligence optical microscopic technology. Andrologia 2019;51:e13440. Agarwal A, Panner Selvam MK, Ambar RF. Validation of LensHookeV R X1 PRO and computer-assisted semen analyzer compared with laboratory-based manual semen analysis. World J Mens Health 2021;39:e7. Alegre L, Del Gallego R, Bori L, Loewke K, Maddah M, Aparicio-Ruiz B, Palma-Govea AP, Marcos J, Meseguer M. Assessment of em- bryo implantation potential with a cloud-based automatic software. Reprod Biomed Online 2021;42:66–74. Armstrong S, Bhide P, Jordan V, Pacey A, Marjoribanks J, Farquhar C. Time-lapse systems for embryo incubation and assessment in assisted reproduction. Cochrane Database Syst Rev 2019; 5: CD011320. doi: 10.1002/14651858.CD011320.pub4. Arrieta AB, Diaz-Rodriguez N, Del Ser J, Bennetot A, Tabik S, Barbado A, Garcia S, Gil-Lopez S, Molina D, Benjamins R. et al. Explainable Artificial Intelligence (XAI): concepts, taxonomies, op- portunities and challenges toward responsible AI. Inform Fusion 2020;58:82–115. Bori L, Dominguez F, Fernandez EI, Del Gallego R, Alegre L, Hickman C, Quinonero A, Nogueira MFG, Rocha JC, Meseguer M. An artificial intelligence model based on the proteomic profile of euploid embryos and blastocyst morphology: a preliminary study. Reprod Biomed Online 2021;42:340–350. Bori L, Paya E, Alegre L, Viloria TA, Remohi JA, Naranjo V, Meseguer M. Novel and conventional embryo parameters as input data for artificial neural networks: an artificial intelligence model applied for prediction of the implantation potential. Fertil Steril 2020;114:1232–1241. Bormann CL, Kanakasabapathy MK, Thirumalaraju P, Gupta R, Pooniwala R, Kandula H, Hariton E, Souter I, Dimitriadis I, Ramirez LB. et al. Performance of a deep learning based neural 2440 Riegler et al. .............................................................................................................................................................................. network in the selection of human blastocysts for implantation. eLife 2020a;9:1–14. Bormann CL, Thirumalaraju P, Kanakasabapathy MK, Kandula H, Souter I, Dimitriadis I, Gupta R, Pooniwala R, Shafiee H. Consistency and objectivity of automated embryo assessments us- ing deep neural networks. Fertil Steril 2020b;113:781–787. Boulet SL, Mehta A, Kissin DM, Warner L, Kawwass JF, Jamieson DJ. Trends in use of and reproductive outcomes associated with intra- cytoplasmic sperm injection. JAMA 2015;313:255–263. Chang V, Garcia A, Hitschfeld N, Hartel S. Gold-standard for computer-assisted morphological sperm analysis. Comput Biol Med 2017;83:143–150. Chang V, Saavedra JM, Castaneda V, Sarabia L, Hitschfeld N, Hartel S. Gold-standard and improved framework for sperm head seg- mentation. Comput Methods Programs Biomed 2014;117:225–237. Chavez-Badiola A, Flores-Saiffe-Farias A, Mendizabal-Ruiz G, Drakeley AJ, Cohen J. Embryo Ranking Intelligent Classification Algorithm (ERICA): artificial intelligence clinical assistant predicting embryo ploidy and implantation. Reprod Biomed Online 2020a;41: 585–593. Chavez-Badiola A, Flores-Saiffe Farias A, Mendizabal-Ruiz G, Garcia- Sanchez R, Drakeley AJ, Garcia-Sandoval JP. Predicting pregnancy test results after embryo transfer by image feature extraction and analysis using machine learning. Sci Rep 2020b;10:4394. Dang VQ, Vuong LN, Luu TM, Pham TD, Ho TM, Ha AN, Truong BT, Phan AK, Nguyen DP, Pham TN. et al. Intracytoplasmic sperm injection versus conventional in-vitro fertilisation in couples with in- fertility in whom the male partner has normal total sperm count and motility: an open-label, randomised controlled trial. Lancet 2021;397:1554–1563. Dirvanauskas D, Maskeliunas R, Raudonis V, Damasevicius R. Embryo development stage prediction algorithm for automated time lapse incubators. Comput Methods Programs Biomed 2019; 177:161–174. Fukunaga N, Sanami S, Kitasaka H, Tsuzuki Y, Watanabe H, Kida Y, Takeda S, Asada Y. Development of an automated two pronuclei detection system on time-lapse embryo images using deep learning techniques. Reprod Med Biol 2020;19:286–294. Goodson SG, White S, Stevans AM, Bhat S, Kao C-Y, Jaworski S, Marlowe TR, Kohlmeier M, McMillan L, Zeisel SH. et al. CASAnova: a multiclass support vector machine model for the classification of human sperm motility patterns. Biol Reprod 2017; 97:698–708. Goyal A, Kuchana M, Ayyagari KPR. Machine learning predicts live-birth occurrence before in-vitro fertilization treatment. Sci Rep 2020;10:20925. Gunderson SJ, Puga Molina LC, Spies N, Balestrini PA, Buffone MG, Jungheim ES, Riley J, Santi CM. Machine-learning algorithm incorpo- rating capacitated sperm intracellular pH predicts conventional in vitro fertilization success in normospermic patients. Fertil Steril 2021;115:930–939. Haugen TB, Hicks SA, Andersen JM, Witczak O, Hammer HL, Borgli R, Halvorsen P, Riegler M. Visem: a multimodal video dataset of human spermatozoa. In: Proceedings of the 10th ACM Multimedia Systems Conference, 2019, 261–266. Hicks SA, Andersen JM, Witczak O, Thambawita V, Halvorsen P, Hammer HL, Haugen TB, Riegler MA. Machine learning-based analysis of sperm videos and participant data for male fertility pre- diction. Sci Rep 2019;9:16770. Holzinger A, Langs G, Denk H, Zatloukal K, Muller H. Causability and explainability of artificial intelligence in medicine. Wiley Interdiscip Rev Data Min Knowl Discov 2019;9:e1312. Hosny A, Parmar C, Quackenbush J, Schwartz LH, Aerts H. Artificial intelligence in radiology. Nat Rev Cancer 2018;18:500–510. Huang TTF, Kosasa T, Walker B, Arnett C, Huang CTF, Yin C, Harun Y, Ahn HJ, Ohta A. Deep learning neural network analysis of human blastocyst expansion from time-lapse image files. Reprod Biomed Online 2021; 42:1075–1085. doi:10.1016/ j.rbmo.2021.02.015. Høst E, Ernst E, Lindenberg S, Smidt-Jensen S. Morphology of sper- matozoa used in IVF and ICSI from oligozoospermic men. Reprod Biomed Online 2001;3:212–215. Ilhan HO, Sigirci IO, Serbes G, Aydin N. A fully automated hybrid hu- man sperm detection and classification system based on mobile-net and the performance comparison with conventional methods. Med Biol Eng Comput 2020;58:1047–1068. Javadi S, Mirroshandel SA. A novel deep learning method for auto- matic assessment of human sperm images. Comput Biol Med 2019; 109:182–194. Kanakasabapathy MK, Thirumalaraju P, Bormann CL, Kandula H, Dimitriadis I, Souter I, Yogesh V, Kota Sai Pavan S, Yarravarapu D, Gupta R. et al. Development and evaluation of inexpensive auto- mated deep learning-based imaging systems for embryology. Lab Chip 2019;19:4139–4145. Khosravi P, Kazemi E, Zhan Q, Malmsten JE, Toschi M, Zisimopoulos P, Sigaras A, Lavery S, Cooper LAD, Hickman C. et al. Deep learning enables robust assessment and selection of human blasto- cysts after in vitro fertilization. Npj Digit Med 2019;2:21. doi: 10.1038/s41746-019-0096-y. Kragh MF, Rimestad J, Berntsen J, Karstoft H. Automatic grading of human blastocysts from time-lapse imaging. Comput Biol Med 2019; 115:103494. Lemmen JG, Rodriguez NM, Andreasen LD, Loft A, Ziebe S. The to- tal pregnancy potential per oocyte aspiration after assisted reproduction-in how many cycles are biologically competent oocytes available? J Assist Reprod Genet 2016;33:849–854. Liu L, Jiao Y, Li X, Ouyang Y, Shi D. Machine learning algorithms to predict early pregnancy loss after in vitro fertilization-embryo transfer with fetal heart rate as a strong predictor. Comput Methods Programs Biomed 2020;196:105624. McCallum C, Riordon J, Wang Y, Kong T, You JB, Sanner S, Lagunov A, Hannam TG, Jarvi K, Sinton D. Deep learning-based selection of human sperm with high DNA integrity. Commun Biol 2019;2: 250. doi:10.1038/s42003-019-0491-6. Milewski R, Kuczynska A, Stankiewicz B, Kuczynski W. How much in- formation about embryo implantation potential is included in morpho- kinetic data? A prediction model based on artificial neural networks and principal component analysis. Adv Med Sci 2017;62:202–206. Mortimer ST, van der Horst G, Mortimer D. The future of computer-aided sperm analysis. Asian J Androl 2015;17:545–553. Movahed RA, Mohammadi E, Orooji M. Automatic segmentation of Sperm’s parts in microscopic images of human semen smears using concatenated learning approaches. Comput Biol Med 2019;109: 242–253. Artificial intelligence in the fertility clinic 2441 ........................................................................................................................ Paternot G, Devroe J, Debrock S, D’Hooghe TM, Spiessens C. Intra- and inter-observer analysis in the morphological assessment of early-stage embryos. Reprod Biol Endocrinol 2009;7:105.doi: 10.1186/1477-7827-7-105. Qiu J, Li P, Dong M, Xin X, Tan J. Personalized prediction of live birth prior to the first in vitro fertilization treatment: a machine learning method. J Transl Med 2019;17:317. doi:10.1186/s12967- 019-2062-5. Rad RM, Saeedi P, Au J, Havelock J. Human Blastocyst’s Zona Pellucida segmentation via boosting ensemble of complementary learning. Inform Med Unlocked 2018;13:112–121. Rad RM, Saeedi P, Au J, Havelock J. Trophectoderm segmentation in human embryo images via inceptioned U-Net. Med Image Anal 2020;62:101612. Raef B, Maleki M, Ferdousi R. Computational prediction of implanta- tion outcome after embryo transfer. Health Informatics J 2020;26: 1810–1826. Raudonis V, Paulauskaite-Taraseviciene A, Sutiene K, Jonaitis D. Towards the automation of early-stage human embryo develop- ment detection. BioMed Eng OnLine 2019;18:120. doi: 10.1186/s12938-019-0738-y. Riordon J, McCallum C, Sinton D. Deep learning for the classification of human sperm. Comput Biol Med 2019;111:103342. Saeedi P, Yee D, Au J, Havelock J. Automatic identification of human blastocyst components via texture. IEEE Trans Biomed Eng 2017; 64:2968–2978. Saito T, Rehmsmeier M. The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbal- anced datasets. PLoS One 2015;10:e0118432. Santos Filho E, Noble JA, Poli M, Griffiths T, Emerson G, Wells D. A method for semi-automatic grading of human blastocyst micro- scope images. Hum Reprod 2012;27:2641–2648. Shaker F, Monadjemi SA, Alirezaie J, Naghsh-Nilchi AR. A dictionary learning approach for human sperm heads classification. Comput Biol Med 2017;91:181–190. Storr A, Venetis CA, Cooke S, Kilani S, Ledger W. Inter-observer and intra-observer agreement between embryologists during selec- tion of a single Day 5 embryo for transfer: a multicenter study. Hum Reprod 2017;32:307–314. Sundvall L, Ingerslev HJ, Breth Knudsen U, Kirkegaard K. Inter- and intra-observer variability of time-lapse annotations. Hum Reprod 2013;28:3215–3221. Tomlinson MJ. Uncertainty of measurement and clinical value of se- men analysis: has standardisation through professional guidelines helped or hindered progress? Andrology 2016;4:763–770. Tran D, Cooke S, Illingworth PJ, Gardner DK. Deep learning as a predictive tool for fetal heart pregnancy following time-lapse incubation and blastocyst transfer. Hum Reprod 2019;34: 1011–1018. Tsipras D, Santurkar S, Engstrom L, Ilyas A, Madry A. From imagenet to image classification: contextualizing progress on benchmarks. Int Conference on Machine Learning, Vol. 119 2020, 9625–9635. Valiuskait_e V, Raudonis V, Maskeliunas R, Damasevicius R, Krilavicius T. Deep learning based evaluation of spermatozoid motility for ar- tificial insemination. Sensors 2021;21:72. Vander Borght M, Wyns C. Fertility and infertility: definition and epi- demiology. Clin Biochem 2018;62:2–10. Ver Milyea M, Hall JMM, Diakiw SM, Johnston A, Nguyen T, Perugini D, Miller A, Picou A, Murphy AP, Perugini M. Development of an artificial intelligence-based assessment model for prediction of em- bryo viability using static images captured by optical light micros- copy during IVF. Hum Reprod 2020;35:770–784. Vogiatzi P, Pouliakis A, Siristatidis C. An artificial neural network for the prediction of assisted reproduction outcome. J Assist Reprod Genet 2019;36:1441–1448. WHO Laboratory Manual for the Examination and Processing of Human Semen, 5th edn. Genova, Switzerland: WHO Press, 2010. World Health Organization. Wyns C, Bergh C, Calhaz-Jorge C, De Geyter C, Kupka M, Motrenko T, Rugescu I, Smeenk JA. ART in Europe, 2020: results generated from European registries by ESHRE. Hum Reprod Open 2020: hoaa032. doi: 10.1093/hropen/hoaa032. Yang YJ, Bang CS. Application of artificial intelligence in gastroenter- ology. World J Gastroenterol 2019;25:1666–1683. Zhao M, Xu M, Li H, Alqawasmeh O, Chung JPW, Li TC, Lee TL, Tang PMK, Chan DYL. Application of convolutional neural net- work on early human embryo segmentation during in vitro fertiliza- tion. J Cell Mol Med 2021;25:2633–2644. 2442 Riegler et al.",": In recent years, the amount of data produced in the ﬁeld of ART has increased exponentially. The diversity of data is large, ranging from videos to tabular data. At the same time, artiﬁcial intelligence (AI) is progressively used in medical practice and may become a promising tool to improve success rates with ART. AI models may compensate for the lack of objectivity in several critical procedures in fertility clinics, especially embryo and sperm assessments. Various models have been developed, and even though several of them show promising performance, there are still many challenges to overcome. In this review, we present recent research on AI in the context of ART. We discuss the strengths and weaknesses of the presented methods, especially regarding clinical relevance. We also address the pit- falls hampering successful use of AI in the clinic and discuss future possibilities and important aspects to make AI truly useful for ART. Key words: artiﬁcial intelligence / machine learning / ART / embryology / semen analysis / embryo / spermatozoa / fertility / infertility / algorithm","['M A Riegler', 'M H Stensen', 'O Witczak', 'J M Andersen', 'S A Hicks', 'H L Hammer', 'E Delbarre', 'P Halvorsen', 'A Yazidi', 'N Holst', 'T B Haugen']"
EvoDynamic: A Framework for the Evolution of Generally Represented Dynamical Systems and Its Application to Criticality,"Pontes-Filho, Sidney
and Lind, Pedro
and Yazidi, Anis
and Zhang, Jianhua
and Hammer, Hugo
and Mello, Gustavo B. M.
and Sandvig, Ioanna
and Tufte, Gunnar
and Nichele, Stefano",2020,missing,missing,missing,inproceedings,"EvoDynamic: a framework for the evolution of
generally represented dynamical systems and its
application to criticality
Sidney Pontes-Filho1,2[0000−0002−0489−5652], Pedro Lind1, Anis Yazidi1,
Jianhua Zhang1, Hugo Hammer1, Gustavo B. M. Mello1, Ioanna Sandvig3,
Gunnar Tufte2, and Stefano Nichele1,4
1 Department of Computer Science, Oslo Metropolitan University, Oslo, Norway
2 Department of Computer Science, Norwegian University of Science and Technology,
Trondheim, Norway
3 Department of Neuromedicine and Movement Science, Norwegian University of
Science and Technology, Trondheim, Norway
4 Holistic Systems, SimulaMet, Oslo, Norway
Email: sidneyp@oslomet.no
Abstract
Keywords: Cellular automata · Dynamical systems · Implementation ·
Reservoir computing · Evolution · Criticality
1
Introduction
A cellular automaton (CA) is the simplest computing system where the emer-
gence of complex dynamics from local interactions might take place. It consists
This is a post-peer-review, pre-copyedit version of a conference proceeding published in Applications of Evolutionary Computation 23rd European Conference, 
EvoApplications 2020, Held as Part of EvoStar 2020, Proceedings, that is part of the Lecture Notes in Computer Science book series (volume 12104). 
The final authenticated version is available online at: https://doi.org/10.1007/978-3-030-43722-0_9
 2
S. Pontes-Filho et al.
of a grid of cells with a ﬁnite number of states that change according to sim-
ple rules depending on the neighborhood and own state in discrete time-steps.
Some notable examples are the elementary CA [30], which is unidimensional
with three neighbors and eight update cases, and Conway’s Game of Life [24],
which is two-dimensional with nine neighbors and three update cases.
Table 1 presents some computing systems that are capable of giving rise to
the emergence of complex dynamics. Those systems can be exploited by reservoir
computing, which is a paradigm that resorts to dynamical systems to simplify
complex data. Such simpliﬁcation means that reservoir computing utilizes the
non-linear dynamical system to perform a non-linear transformation from non-
linear data to higher dimensional linear data. Such linearized data can be applied
in linear machine learning methods which are faster for training and computing
because has less trainable variables and operations. Hence, reservoir computing
is more energy eﬃcient than deep learning methods and it can even yield compet-
itive results, especially for temporal data [25,27]. Basically, reservoir computing
exploits a dynamical system that possesses the echo state property and fading
memory, where the internals of the reservoir are untrained and the only training
happens at the linear readout stage [16].
Reservoir computers are most useful when the substrate’s dynamics are at
the “edge of chaos” [17], meaning a range of dynamical behaviors that is between
order and disorder. Cellular automata with such dynamical behavior are capable
of being exploited as reservoirs [21,22]. Other systems can also exhibit similar
dynamics. The coupled map lattice [15] is very similar to CA, the only exception
is that the coupled map lattice has continuous states which are updated by a
recurrence equation involving the neighborhood. Random Boolean network [10]
is a generalization of CA where random connectivity exists. Echo state network
[13] is an artiﬁcial neural network (ANN) with random topology while liquid
state machine [18] is similar to echo state network with the diﬀerence that it is a
spiking neural network that communicates through discrete-events (spikes) over
continuous time.
One important aspect of the computation performed in a dynamical system
is the trajectory of system states traversed during the computation [19]. Such
trajectory may be guided by system parameters [23]. Another characteristic of
a dynamical system, which is crucial for computation, is to be in a critical state,
Table 1: Examples of dynamical systems.
Dynamical system
State
Time
Connectivity
Cellular automata
Discrete
Discrete
Regular
Coupled map lattice
Continuous Discrete
Regular
Random Boolean network Discrete
Discrete
Random
Echo state network
Continuous Discrete
Random
Liquid state machine
Discrete
Continuous Random
 EvoDynamic: a framework for the evolution of dynamical systems
3
as indicated by Langton [17]. If the attractors of the system are in the critical
state, this characteristic is called self-organized criticality [7].
Besides, computation in dynamical systems may be carried out in physical
substrates [27], such as networks of biological neurons [3] or in nanoscale ma-
terials [8]. Finding the correct abstraction for the computation in a dynamical
system, e.g. CA, is an open problem [20].
All the systems described in Table 1 are sparsely connected and can be
represented by a weighted adjacency matrix, such as a graph. The connectivity
from a layer to another in a fully connected feedforward ANN is represented
with a weighted adjacency matrix that contains the weights of each connection.
Our CA implementation is similar to this, but the connectivity goes from the
“layer” of cells to itself.
The goal of representing CA with a weighted adjacency matrix is to imple-
ment a framework which facilitates the development of all types of CAs, from
unidimensional to multidimensional, with all kinds of lattices and without any
boundary conditions during execution; and also allowing the inclusion of other
major dynamical systems, independent of the type of the state, time and connec-
tivity. Such initial implementation is the ﬁrst component of a Python framework
under development, based on TensorFlow deep neural network library [4]. There-
fore, it beneﬁts from powerful and parallel computing systems with multi-CPU
and multi-GPU. One of the framework’s goals is to have a balance between
performance and generalization of computing dynamical systems, since general
methods are slower than specialized ones. Nevertheless, this framework, called
EvoDynamic, aims at evolving (i.e., using evolutionary algorithms) the connec-
tivity, update and learning rules of sparsely connected networks to improve their
usage for reservoir computing guided by the echo state property, fading memory,
state trajectory, and other quality measurements. Such improvement of reser-
voirs is applied similarly in [26], where the internal connectivity of a reservoir
is trained to increase its performance to several tasks. Moreover, evolution will
model the dynamics and behavior of physical reservoirs, such as in-vitro biolog-
ical neural networks interfaced with microelectrode arrays, and nanomagnetic
ensembles. Those two substrates have real applicability as reservoirs. For exam-
ple, the former substrate is applied to control a robot, in fact making it into a
cyborg, a closed-loop biological-artiﬁcial neuro-system [3], and the latter pos-
sesses computation capability as shown by a square lattice of nanomagnets [14].
Those substrates are the main interest of the SOCRATES project [1] which aims
to explore a dynamic, robust and energy eﬃcient hardware for data analysis.
There exist some implementations of CA similar to the one of EvoDynamic
framework. They typically implement Conway’s Game of Life by applying 2D
convolution with a kernel that is used to count the “alive” neighbors, then the
resulting matrix consists of the number of “alive” neighboring cells and is used to
update the CA. One such implementation, also based on TensorFlow, is available
open-source in [2].
This paper is organized as follows. Section 2 describes our method according
to which we use weighted adjacency matrix to compute CA. Section 3 presents
 4
S. Pontes-Filho et al.
the results obtained from the method. Section 4 discusses the initial advances
and future plan of EvoDynamic framework and Section 5 concludes this paper.
2
Method
In our proposed method, the equation to calculate the next states of the cells in
a cellular automaton is
ct+1 = f(A · ct).
(1)
It is similar to the equation of the forward pass of an artiﬁcial neural network,
but without the bias. The layer is connected to itself, and the activation function
f deﬁnes the update rules of the CA. The next states of the CA ct+1 is calculated
from the result of the activation function f which receives as argument the dot
product between the weighted adjacency matrix A and the current states of the
CA ct. c is always a column vector of size len(c) × 1, that does not depend on
how many dimensions the CA has, and A is a matrix of size len(c) × len(c).
Hence the result of A · c is also a column vector of size len(c) × 1 as c.
The implementation of cellular automata as an artiﬁcial neural network re-
quires the procedural generation of the weighted adjacency matrix of the grid.
In this way, any lattice type or multidimensional CAs can be implemented us-
ing the same approach. The adjacency matrix of a sparsely connected network
contains many zeros because of the small number of connections. Since we im-
plement it on TensorFlow, the data type of the adjacency matrix is preferably
a SparseTensor. A dot product with this data type can be up to 9 times faster
than the dense counterpart. However, it depends on the conﬁguration of the
tensors (or, in our case, the adjacency matrices) [28]. The update rule of the CA
alters the weights of the connections in the adjacency matrix. In a CA whose
cells have two states meaning “dead” (zero) or “alive” (one), the weights in the
adjacency matrix are one for connection and zero for no connection, such as an
ordinary adjacency matrix. Such matrix facilitates the description of the update
rule for counting the number of “alive” neighbors because the result of the dot
product between the adjacency matrix and the cell state vector is the vector
that contains the number of “alive” neighbors for each cell. If the pattern of the
neighborhood matters in the update rule, each cell has its neighbors encoded as
a n-ary string where n means the number of states that a cell can have. In this
case, the weights of the connections with the neighbors are n-base identiﬁers and
are calculated by
neighbori = ni, ∀i ∈{0..len(neighbors) −1}
(2)
where neighbors is a vector of the cell’s neighbors. In the adjacency matrix,
each neighbor receives a weight according to (2). The result of the dot product
with such weighted adjacency matrix is a vector that consists of unique integers
per neighborhood pattern. Thus, the activation function is a lookup table from
integer (i.e., pattern) to next state.
Algorithm 1 generates the weighted adjacency matrix for one-dimensional
CA, such as the elementary CA, where widthCA is the width or number of
 EvoDynamic: a framework for the evolution of dynamical systems
5
Algorithm 1 Generation of weighted adjacency matrix for 1D cellular automa-
ton
1: procedure generateCA1D
2:
numberOfCells ←widthCA
3:
A ←0numberOfCells×numberOfCells
▷Adjacency matrix initialization
4:
for i ←{0..(numberOfCells −1)} do
5:
for
j
←
{−indexNeighborCenter..(len(neighborhood)
−
indexNeighborCenter −1)} do
6:
currentNeighbor ←neighborhoodj+indexNeighborCenter
7:
if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧(0 ≤
(i + j) < widthCA)) then
8:
Ai,((i+j) mod widthCA) ←currentNeighbor
9:
return A
cells of a unidimensional CA and neighborhood is a vector which describes
the region around the center cell. The connection weights depend on the type
of update rule as previously explained. For example, in case of an elementary
CA neighborhood = [4 2 1]. indexNeighborCenter is the index of the center
cell in the neighborhood whose starting index is zero. isWrappedGrid is a
Boolean value that works as a ﬂag for adding a wrapped grid or not. A wrapped
grid for one-dimensional CA means that the initial and ﬁnal cells are neighbors.
With all these parameters, Algorithm 1 creates an adjacency matrix by looping
over the indices of the cells (from zero to numberOfCells −1) with an inner
loop for the indices of the neighbors. If the selected currentNeighbor is a non-
zero value and its indices do not aﬀect the boundary condition, then the value
of currentNeighbor is assigned to the adjacency matrix A in the indices that
correspond to the connection between the current cell in the outer loop and the
actual index of currentNeighbor. Finally, this procedure returns the adjacency
matrix A.
To procedurally generate an adjacency matrix for 2D CA instead of 1D CA,
the algorithm needs to have small adjustments. Algorithm 2 shows that for two-
dimensional CA, such as Conway’s Game of Life. In this case, the height of
the CA is an argument passed as heightCA. Neighborhood is a 2D matrix
and indexNeighborCenter is a vector of two components meaning the in-
dices of the center of Neighborhood. This procedure is similar to the one in
Algorithm 1, but it contains one more loop for the additional dimension.
The activation function for CA is diﬀerent from the ones used for ANN.
For CA, it contains the update rules that verify the vector returned by the
dot product between the weighted adjacency matrix and the vector of states.
Normally, the update rules of the CA are implemented as a lookup table from
neighborhood to next state. In our implementation, the lookup table maps the
resulting vector of the dot product to the next state of the central cell.
 6
S. Pontes-Filho et al.
Algorithm 2 Generation of adjacency matrix of 2D cellular automaton
1: procedure generateCA2D
2:
numberOfCells ←widthCA ∗heightCA
3:
A ←0numberOfCells×numberOfCells
▷Adjacency matrix initialization
4:
widthNB, heightNB ←shape(Neighborhood)
5:
for i ←{0..(numberOfCells −1)} do
6:
for
j
←
{−indexNeighborCenter0..(widthNB
−
indexNeighborCenter0 −1)} do
7:
for
k
←
{−indexNeighborCenter1..(heightNB
−
indexNeighborCenter1 −1)} do
8:
currentNeighbor ←Neighborhoodj+indexNeighborCenter
9:
if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧
(0 ≤((i mod heightCA)+j) < widthCA)∧(0 ≤(⌊i/widthCA⌋+k) < heightCA))
then
10:
Ai,(((i+k) mod widthCA)+((⌊i/widthCA⌋+j) mod heightCA)∗widthCA) ←
currentNeighbor
11:
return A
3
Results
This section presents the results of the proposed method and it also stands for
the preliminary results of the EvoDynamic framework.
Fig. 1 illustrates a wrapped elementary CA described in the procedure of
Algorithm 1 and its generated weighted adjacency matrix. Fig. 1a shows the
appearance of the desired elementary CA with 16 cells (i.e., widthCA = 16).
Fig. 1b describes its pattern 3-neighborhood and the indices of the cells. Fig 1c
shows the result of the Algorithm 1 with the neighborhood calculated by (2) for
pattern matching in the activation function. In Fig. 1c, we can verify that the
left neighbor has weight equal to 4 (or 22 for the most signiﬁcant bit), central cell
weight is 2 (or 21) and right neighbor weight is 1 (or 20 for the least signiﬁcant
bit) as deﬁned by (2). Since the CA is wrapped, we can notice in row index 0
of the adjacency matrix in Fig. 1c that the left neighbor of cell 0 is the cell 15,
and in row index 15 that the right neighbor of cell 15 is the cell 0.
Fig. 2 describes a wrapped 2D CA (similar to Game of Life but with less
number of neighbors) for Algorithm 2 and shows the resulting adjacency matrix.
Fig. 2a illustrates the desired two-dimensional CA with 16 cells (i.e., widthCA =
4 and heightCA = 4). Fig. 2b presents the von Neumann neighborhood [29]
which is used for counting the number of “alive” neighbors (the connection
weights are only zero and one, and Neighborhood argument of Algorithm 2
deﬁnes it). It also shows the index distribution of the CA whose order is preserved
after ﬂatting it to a column vector. Fig 2c contains the generated adjacency
matrix of Algorithm 2 for the described 2D CA. Fig. 2b shows an example of
a central cell with its neighbors, the index of this central cell is 5 and the row
index 5 in the adjacency matrix of Fig. 2c presents the same neighbor indices,
i.e., 1, 4, 6 and 9. Since this is a symmetric matrix, the columns have the same
connectivity of the rows. That means the neighborhood of a cell considers this cell
 EvoDynamic: a framework for the evolution of dynamical systems
7
as a neighbor too. Therefore, the connections are bidirectional and the adjacency
matrix represents an undirected graph. The wrapping eﬀect is also observable.
For example, the neighbors of the cell index 0 are 1, 3, 4 and 12. So the neighbors
3 and 12 are the ones that the wrapped grid allowed to exist for cell index 0.
(a)
(b)
(c)
Fig. 1: Elementary cellular automaton with 16 cells and wrapped grid. (a) Exam-
ple of the grid of cells with states. (b) Indices of the cells and standard pattern
neighborhood of elementary CA where thick border means the central cell and
thin border means the neighbors. (c) Generated weighted adjacency matrix for
the described elementary CA.
4
On-going and future applications with EvoDynamic
The method of implementing a CA as an artiﬁcial neural network is beneﬁcial for
the further development of EvoDynamic framework. Since the implementation of
 8
S. Pontes-Filho et al.
(a)
(b)
(c)
Fig. 2: 2D cellular automaton with 16 cells (4×4) and wrapped grid. (a) Example
of the grid of cells with states. (b) Indices of the cells and von Neumann counting
neighborhood of 2D CA where thick border means the current cell and thin
border means the neighbors. (c) Generated adjacency matrix for the described
2D CA.
 EvoDynamic: a framework for the evolution of dynamical systems
9
all sparsely connected networks in Table 1 is already planned in forthcoming re-
leases of the Python framework, EvoDynamic shall have a general representation
to all of them. Therefore, CAs are treated as ANNs and then can be extended to
random Boolean network by shuﬄing the connections, and to the models that
are already ANNs, such as echo state networks and liquid state machines. More-
over, EvoDynamic framework will evolve the connectivity, update and learning
rules of the dynamical systems for reservoir computing improvement and physi-
cal substrate modeling. This common representation facilitates the evolution of
such systems and models which will be guided by several methods that measure
the quality of a reservoir or the similarity to a dataset. The following subsections
explain two on-going applications with CA that use the EvoDynamic framework.
4.1
State trajectory
An example of methods to guide the evolution of dynamical system is the state
trajectory. This method can be used to cluster similar states for model abstrac-
tion and to measure the quality of the reservoir. Therefore, a graph can be
formed and analysis can be made by searching for attractors and cycles. For
visualization of the state trajectory, we use principal component analysis (PCA)
to reduce the dimensionality of the states and present them as a state transi-
tion diagram as shown in Fig. 3. The depicted dynamical system is Conway’s
Game of Life with 7x7 cells and wrapped boundaries. A glider is its initial state
(Fig. 3a) and this system cycles over 28 unique states as illustrated in the state
transition diagram of Fig. 3l.
4.2
Towards the evolution for criticality
Evolution of dynamical systems is a feature currently under development of
EvoDynamic framework. The ﬁrst on-going evolution task of our framework is
to ﬁnd systems with criticality [7] using genetic algorithm, in order to allow for
better computational capacity [17]. The ﬁrst dynamical system for this task is a
modiﬁed version of stochastic elementary cellular automata (SECA) introduced
by Baetens et al. [6]. Our stochastic elementary cellular automaton works as a
1D three neighbors elementary CA, but the next state in time t+1 of the central
cell ci is deﬁned by a probability p to be 1 and a probability 1−p to be 0 for each
of the eight diﬀerent neighborhood patterns this CA has. Formally, probability
p is represented by
p = P(ci,t+1 = 1|N(ci,t))
(3)
where the neighborhood pattern N(ci,t) is denoted as
N(ci,t) = (ci−1,t, ci,t, ci+1,t).
(4)
The genetic algorithm for criticality is guided by a ﬁtness function which
mainly veriﬁes if the probability distributions of avalanche size (i.e., cluster size5
5 Cluster size stands for the number of repetitions of a state that happened consecu-
tively without any interruption of another state.
 10
S. Pontes-Filho et al.
−1
0
1
−1
0
1
(a) Step 1
−1
0
1
−1
0
1
(b) Step 2
−1
0
1
−1
0
1
(c) Step 3
−1
0
1
−1
0
1
(d) Step 4
−1
0
1
−1
0
1
(e) Step 11
−1
0
1
−1
0
1
(f) Step 12
−1
0
1
−1
0
1
(g) Step 13
−1
0
1
−1
0
1
(h) Step 14
−1
0
1
−1
0
1
(i) Step 26
−1
0
1
−1
0
1
(j) Step 27
−1
0
1
−1
0
1
(k) Step 28
−1
0
1
−1
0
1
(l) Step 29
Fig. 3: States of Conway’s Game of Life in a 7x7 wrapped lattice alongside their
PCA-transformed state transition diagrams of the two ﬁrst principal compo-
nents. (a) Initial state is a glider. (a)-(d) Four ﬁrst steps in this CA. (e)-(h) Four
intermediate steps in this CA while reaching the wrapped border. (i)-(l) Four
last steps in this CA before repeating the initial state and closing a cycle.
in space) and duration (i.e., cluster size in time) follow a power-law distribu-
tion. Such veriﬁcation can be done by checking how linear is the probability
distribution in a log-log plot, by performing goodness-of-ﬁt tests based on the
Kolmogorov-Smirnov (KS) statistic and by comparing the power-law model with
the exponential model using log-likelihood ratio [9]. For our ﬁtness function, we
estimate the candidate distributions with the linear ﬁtting of the ﬁrst 10 points
of the log-log plot using least squares regression, which was veriﬁed to be not
biased and gives a fast and acceptable estimation of the slope of the power-law
distribution [12]. After the linear 10-points ﬁtting, the model is tested using KS
statistic. One beneﬁt of using such estimation method is that when the model
is not a power-law, the KS statistic reports a large error, i.e., an error greater
than one. Another objective in the ﬁtness function is the coeﬃcient of determi-
nation [31], but for a complete linear ﬁt of the log-log plot. The ﬁtness function
also considers the number of unique states of the stochastic elementary CA, the
number of bins in the raw histogram and the value of the estimated power-law
exponent. All these ﬁtness function objectives are calculated using a randomly
initialized CA of 1,000 cells with wrapped boundaries during 1,000 time-steps.
The avalanche size and duration are computed for the cell values 0 and 1, thus
producing four diﬀerent distributions (see Fig. 4) for extracting vectors of their
 EvoDynamic: a framework for the evolution of dynamical systems
11
normalized number of histogram bins6 bin; coeﬃcient of determination R2 of
complete linear ﬁtting; KS statistic D and estimated power-law exponent ˆα
from the 10-points linear estimation. The ﬁtness score s for each objective is
then calculated by the following equations:
bins = tanh(5 ∗(0.9 ∗max(bin) + 0.1 ∗mean(bin))),
(5)
R2
s = mean(R2),
(6)
Ds = exp(−(0.9 ∗min(D) + 0.1 ∗mean(D))),
(7)
ˆαs = mean(ˆα),
(8)
uniques = #uniqueStates
#timesteps
.
(9)
The (5)-(9) are all objective values for calculating the ﬁtness score s. Those
values are real numbers between zero and one, except the score for the estimated
power-law exponent ˆαs, and they have weights attributed to them regarding their
level of importance and for compensating small and large values. The following
equation denotes how the ﬁtness score s is calculated:
s = 10 ∗bins + 10 ∗R2
s + 10 ∗Ds + 0.1 ∗ˆαs + 10 ∗uniques.
(10)
The genetic algorithm has 40 individuals that evolve through 100 generations.
The optimization performed by GA is to maximize the ﬁtness score. The genome
of the individuals has eight real number genes with a value range between zero
and one. Each gene represents the probability of the next state becoming one
(i.e., p in (3)) for its respective neighborhood pattern. The selection of two par-
ents is done by deterministic tournament selection [11]. After that, the crossover
between the genomes of the parents can happen with probability 0.8, then each
gene can be exchanged with probability 0.5. Afterward, a mutation occurs to a
gene with probability 0.1. This mutation adds a random value from a normal
distribution with mean and standard deviation equals to, respectively, 0 and 0.2.
The mating process of the two parents produces an oﬀspring of two new individ-
uals who replace the parents in the next generation. An example of an evolved
genome for the best resulting individual is presented in Table 2. The ﬁtness score
s and all objective scores with their respective weights for calculating s are in
Table 3.
With the genome or probabilities of the eight diﬀerent neighborhood patterns
of the best evolved individual, we can produce the log-log plots of the probability
distribution of avalanche size and duration for the states zero and one. Such plots
6 The actual number of histogram bins is normalized or divided by the possible total
number of bins.
 12
S. Pontes-Filho et al.
Table 2: Best individual
Neighborhood N(ci,t) Probability p
(0,0,0)
0.103009
(0,0,1)
0.536786
(0,1,0)
0.216794
(0,1,1)
0.393468
(1,0,0)
0.679836
(1,0,1)
0.175458
(1,1,0)
0.724778
(1,1,1)
1.000000
Table 3: Fitness score of the best individual
Objective
Score
10 ∗bins
9.780749590096136
10 ∗R2
s
8.832520186440096
10 ∗Ds
9.655719560019996
0.1 ∗ˆαs
0.18022617747972156
10 ∗uniques 10.0
s
38.44921551403595
are depicted in Fig. 4. The p-value of goodness-of-ﬁt test is calculated using 1,000
randomly generated data with 10,000 samples applying the power-law exponent
ˆα estimated by maximum likelihood estimation method with minimum x of
the distribution ﬁxed to 1. The Fig. 4a and Fig. 4b show the avalanche size and
duration for the state 0 or black. They present distributions that are not a power-
law because they do not ﬁt the power-law estimation (the black dashed line).
Moreover, the p-value is equal to 0.0 which proves that those two distributions are
not a power-law. The Fig. 4c and Fig. 4d present the avalanche size and duration
for the state 1 or white. Those distributions follow a power-law because, visually,
the estimated power-law distribution ﬁts the empirical probability distribution
and, quantitatively, the p-value is equal to 1.0 which means that 100% of the KS
statistic of the generated data is greater than the KS statistic of the empirical
distribution of avalanche size and duration of state 1. The number of samples in
those distributions (62,731 for avalanche size and 52,902 for avalanche duration)
conﬁrms that the p-value is trustworthy. Such power-law analysis is performed
by utilizing the powerlaw Python library [5]. It is important to warn that high
ﬁtness scores do not mean p-values closer to 1.0 and the goodness-of-ﬁt test is
not part of the ﬁtness score because it is a slow process.
A sample of the resulting stochastic elementary cellular automaton of the best
individual is illustrated in Fig. 5. This CA, as seen, has no static nor periodic
states, and no random evolution of its states. Therefore, this dynamical system
 EvoDynamic: a framework for the evolution of dynamical systems
13
is between a strongly and weakly coupled substrate. Therefore, the CA presents
patterns or structures that mean the cells are interdependent in this system.
5
Conclusion
In this paper, we present an alternative method to implement a cellular au-
tomaton. This allows any CA to be computed as an artiﬁcial neural network.
That means, any lookup table can be an activation function, and any neigh-
borhood and dimensionality can be represented as a weight matrix. Therefore,
this will help to extend the CA implementation to more complex dynamical sys-
tems, such as random Boolean networks, echo state networks and liquid state
machines. Furthermore, the EvoDynamic framework is built on a deep learning
library, TensorFlow, which permits the acceleration and parallelization of ma-
trix operations when applied on computational platforms with fast CPUs and
(a) Avalanche size of state 0
(b) Avalanche duration of state 0
(c) Avalanche size of state 1
(d) Avalanche duration of state 1
Fig. 4: Avalanche size and duration of the two states 0 and 1 of the evolved
stochastic elementary CA.
 14
S. Pontes-Filho et al.
Fig. 5: Sample of the best evolved stochastic elementary CA of 200 cells (horizon-
tal axis) randomly initialized with wrapped boundaries through 400 time-steps
(vertical axis).
GPUs. The planned future implementations of EvoDynamic are presented and
discussed. The state trajectory is an important feature for the targeted future
tasks. The evolution with genetic algorithm towards criticality of stochastic CA
is showing promising results and our next goal can be for self-organized criti-
cality. The future work for the CA implementation is to develop algorithms to
procedurally generate weighted adjacency matrices for 3D and multidimensional
cellular automata with diﬀerent types of cells, such as the cells with hexagonal
shape in a 2D CA.
 EvoDynamic: a framework for the evolution of dynamical systems
15
Acknowledgments
We thank Kristine Heiney for thoughtful discussions about self-organized criti-
cality.
References
1. SOCRATES – Self-Organizing Computational substRATES, https://www.ntnu.
edu/socrates
2. Conway’s game of life implemented using tensorﬂow 2d convolution function
(2016), https://github.com/conceptacid/conv2d life
3. Aaser, P., Knudsen, M., Ramstad, O.H., van de Wijdeven, R., Nichele, S., Sandvig,
I., Tufte, G., Stefan Bauer, U., Halaas, Ø., Hendseth, S., Sandvig, A., Valderhaug,
V.: Towards making a cyborg: A closed-loop reservoir-neuro system. The 2018
Conference on Artiﬁcial Life: A Hybrid of the European Conference on Artiﬁcial
Life (ECAL) and the International Conference on the Synthesis and Simulation of
Living Systems (ALIFE) (29), 430–437 (2017). https://doi.org/10.1162/isal a 072
4. Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghe-
mawat, S., Irving, G., Isard, M., Kudlur, M., Levenberg, J., Monga, R., Moore,
S., Murray, D.G., Steiner, B., Tucker, P., Vasudevan, V., Warden, P., Wicke, M.,
Yu, Y., Zheng, X.: Tensorﬂow: A system for large-scale machine learning. In: 12th
USENIX Symposium on Operating Systems Design and Implementation (OSDI
16). pp. 265–283. USENIX Association, Savannah, GA (2016)
5. Alstott,
J.,
Bullmore,
E.,
Plenz,
D.:
powerlaw:
A
python
package
for
analysis
of
heavy-tailed
distributions.
PLOS
ONE
9(1),
1–11
(01
2014).
https://doi.org/10.1371/journal.pone.0085777
6. Baetens, J.M., Van der Meeren, W., De Baets, B.: On the dynamics of stochastic
elementary cellular automata. Journal of Cellular Automata 12 (2016)
7. Bak,
P.,
Tang,
C.,
Wiesenfeld,
K.:
Self-organized
criticality:
An
expla-
nation
of
the
1/f
noise.
Phys.
Rev.
Lett.
59,
381–384
(Jul
1987).
https://doi.org/10.1103/PhysRevLett.59.381
8. Broersma, H., Miller, J.F., Nichele, S.: Computational Matter: Evolving Com-
putational Functions in Nanoscale Materials, pp. 397–428. Springer International
Publishing, Cham (2017). https://doi.org/10.1007/978-3-319-33921-4 16
9. Clauset, A., Shalizi, C.R., Newman, M.E.: Power-law distributions in empirical
data. SIAM review 51(4), 661–703 (2009)
10. Gershenson, C.: Introduction to random boolean networks. arXiv preprint
nlin/0408006 (2004)
11. Goldberg, D.E., Deb, K.: A comparative analysis of selection schemes used in
genetic algorithms. In: Foundations of genetic algorithms, vol. 1, pp. 69–93. Elsevier
(1991)
12. Goldstein, M.L., Morris, S.A., Yen, G.G.: Problems with ﬁtting to the power-law
distribution. The European Physical Journal B-Condensed Matter and Complex
Systems 41(2), 255–258 (2004)
13. Jaeger, H., Haas, H.: Harnessing nonlinearity: Predicting chaotic systems and
saving energy in wireless communication. Science 304(5667), 78–80 (2004).
https://doi.org/10.1126/science.1091277
 16
S. Pontes-Filho et al.
14. Jensen, J.H., Folven, E., Tufte, G.: Computation in artiﬁcial spin ice. The 2018
Conference on Artiﬁcial Life: A Hybrid of the European Conference on Artiﬁcial
Life (ECAL) and the International Conference on the Synthesis and Simulation of
Living Systems (ALIFE) (30), 15–22 (2018). https://doi.org/10.1162/isal a 00011
15. Kaneko, K.: Overview of coupled map lattices. Chaos: An Interdisciplinary Journal
of Nonlinear Science 2(3), 279–282 (1992)
16. Konkoli, Z., Nichele, S., Dale, M., Stepney, S.: Reservoir Computing with Com-
putational Matter, pp. 269–293. Springer International Publishing, Cham (2018).
https://doi.org/10.1007/978-3-319-65826-1 14
17. Langton, C.G.: Computation at the edge of chaos: Phase transitions and emer-
gent computation. Physica D: Nonlinear Phenomena 42(1), 12 – 37 (1990).
https://doi.org/https://doi.org/10.1016/0167-2789(90)90064-V
18. Maass, W., Markram, H.: On the computational power of circuits of spiking
neurons. Journal of Computer and System Sciences 69(4), 593 – 616 (2004).
https://doi.org/https://doi.org/10.1016/j.jcss.2004.04.001
19. Nichele, S., Tufte, G.: Trajectories and attractors as speciﬁcation for the evolution
of behaviour in cellular automata. In: IEEE Congress on Evolutionary Computa-
tion. pp. 1–8 (July 2010). https://doi.org/10.1109/CEC.2010.5586115
20. Nichele, S., Farstad, S.S., Tufte, G.: Universality of evolved cellular automata in-
materio. International Journal of Unconventional Computing 13(1) (2017)
21. Nichele,
S.,
Gundersen,
M.S.:
Reservoir
computing
using
nonuniform
bi-
nary
cellular
automata.
Complex
Systems
26(3),
225–245
(Sep
2017).
https://doi.org/10.25088/complexsystems.26.3.225
22. Nichele,
S.,
Molund,
A.:
Deep
learning
with
cellular
automaton-based
reservoir
computing.
Complex
Systems
26(4),
319–339
(Dec
2017).
https://doi.org/10.25088/complexsystems.26.4.319
23. Nichele, S., Tufte, G.: Genome parameters as information to forecast emergent
developmental behaviors. In: Durand-Lose, J., Jonoska, N. (eds.) Unconventional
Computation and Natural Computation. pp. 186–197. Springer Berlin Heidelberg,
Berlin, Heidelberg (2012)
24. Rendell, P.: Turing Universality of the Game of Life, pp. 513–539. Springer London,
London (2002). https://doi.org/10.1007/978-1-4471-0129-1 18
25. Schrauwen, B., Verstraeten, D., Van Campenhout, J.: An overview of reservoir
computing: theory, applications and implementations. In: Proceedings of the 15th
European Symposium on Artiﬁcial Neural Networks. p. 471-482 2007. pp. 471–482
(2007)
26. Subramoney, A., Scherr, F., Maass, W.: Reservoirs learn to learn. arXiv preprint
arXiv:1909.07486 (2019)
27. Tanaka, G., Yamane, T., H´eroux, J.B., Nakane, R., Kanazawa, N., Takeda,
S.,
Numata,
H.,
Nakano,
D.,
Hirose,
A.:
Recent
advances
in
physical
reservoir computing: A review. Neural Networks 115, 100 – 123 (2019).
https://doi.org/https://doi.org/10.1016/j.neunet.2019.03.005
28. TensorFlow: tf.sparse.sparse dense matmul — tensorﬂow core r1.14 — tensorﬂow,
https://www.tensorﬂow.org/api docs/python/tf/sparse/sparse dense matmul
29. Toﬀoli, T., Margolus, N.: Cellular automata machines: a new environment for mod-
eling. MIT press (1987)
30. Wolfram, S.: A new kind of science, vol. 5. Wolfram media Champaign, IL (2002)
31. Wright, S.: Correlation and causation. Journal of Agricultural Research 20, 557–
580 (1921)
",missing,doc10,". Dynamical systems possess a computational capacity that
may be exploited in a reservoir computing paradigm. This paper presents
a general representation of dynamical systems which is based on matrix
multiplication. That is similar to how an artiﬁcial neural network (ANN)
would be represented in a deep learning library and its computation
would be faster because of the optimized matrix operations that such
type of libraries have. Initially, we implement the simplest dynamical
system, a cellular automaton. The mathematical fundamentals behind
an ANN are maintained, but the weights of the connections and the ac-
tivation function are adjusted to work as an update rule in the context
of cellular automata. The advantages of such implementation are its us-
age on specialized and optimized deep learning libraries, the capabilities
to generalize it to other types of networks and the possibility to evolve
cellular automata and other dynamical systems in terms of connectivity,
update and learning rules. Our implementation of cellular automata con-
stitutes an initial step towards a more general framework for dynamical
systems. Our objective is to evolve such systems to optimize their usage
in reservoir computing and to model physical computing substrates. Fur-
thermore, we present promising preliminary results toward the evolution
of complex behavior and criticality using genetic algorithm in stochastic
elementary cellular automata.","EvoDynamic: a framework for the evolution of generally represented dynamical systems and its application to criticality Sidney Pontes-Filho1,2[0000−0002−0489−5652], Pedro Lind1, Anis Yazidi1, Jianhua Zhang1, Hugo Hammer1, Gustavo B. M. Mello1, Ioanna Sandvig3, Gunnar Tufte2, and Stefano Nichele1,4 1 Department of Computer Science, Oslo Metropolitan University, Oslo, Norway 2 Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway 3 Department of Neuromedicine and Movement Science, Norwegian University of Science and Technology, Trondheim, Norway 4 Holistic Systems, SimulaMet, Oslo, Norway Email: sidneyp@oslomet.no Abstract Keywords: Cellular automata · Dynamical systems · Implementation · Reservoir computing · Evolution · Criticality 1 Introduction A cellular automaton (CA) is the simplest computing system where the emer- gence of complex dynamics from local interactions might take place. It consists This is a post-peer-review, pre-copyedit version of a conference proceeding published in Applications of Evolutionary Computation 23rd European Conference, EvoApplications 2020, Held as Part of EvoStar 2020, Proceedings, that is part of the Lecture Notes in Computer Science book series (volume 12104). The final authenticated version is available online at: 2 S. Pontes-Filho et al. of a grid of cells with a ﬁnite number of states that change according to sim- ple rules depending on the neighborhood and own state in discrete time-steps. Some notable examples are the elementary CA [30], which is unidimensional with three neighbors and eight update cases, and Conway’s Game of Life [24], which is two-dimensional with nine neighbors and three update cases. Table 1 presents some computing systems that are capable of giving rise to the emergence of complex dynamics. Those systems can be exploited by reservoir computing, which is a paradigm that resorts to dynamical systems to simplify complex data. Such simpliﬁcation means that reservoir computing utilizes the non-linear dynamical system to perform a non-linear transformation from non- linear data to higher dimensional linear data. Such linearized data can be applied in linear machine learning methods which are faster for training and computing because has less trainable variables and operations. Hence, reservoir computing is more energy eﬃcient than deep learning methods and it can even yield compet- itive results, especially for temporal data [25,27]. Basically, reservoir computing exploits a dynamical system that possesses the echo state property and fading memory, where the internals of the reservoir are untrained and the only training happens at the linear readout stage [16]. Reservoir computers are most useful when the substrate’s dynamics are at the “edge of chaos” [17], meaning a range of dynamical behaviors that is between order and disorder. Cellular automata with such dynamical behavior are capable of being exploited as reservoirs [21,22]. Other systems can also exhibit similar dynamics. The coupled map lattice [15] is very similar to CA, the only exception is that the coupled map lattice has continuous states which are updated by a recurrence equation involving the neighborhood. Random Boolean network [10] is a generalization of CA where random connectivity exists. Echo state network [13] is an artiﬁcial neural network (ANN) with random topology while liquid state machine [18] is similar to echo state network with the diﬀerence that it is a spiking neural network that communicates through discrete-events (spikes) over continuous time. One important aspect of the computation performed in a dynamical system is the trajectory of system states traversed during the computation [19]. Such trajectory may be guided by system parameters [23]. Another characteristic of a dynamical system, which is crucial for computation, is to be in a critical state, Table 1: Examples of dynamical systems. Dynamical system State Time Connectivity Cellular automata Discrete Discrete Regular Coupled map lattice Continuous Discrete Regular Random Boolean network Discrete Discrete Random Echo state network Continuous Discrete Random Liquid state machine Discrete Continuous Random EvoDynamic: a framework for the evolution of dynamical systems 3 as indicated by Langton [17]. If the attractors of the system are in the critical state, this characteristic is called self-organized criticality [7]. Besides, computation in dynamical systems may be carried out in physical substrates [27], such as networks of biological neurons [3] or in nanoscale ma- terials [8]. Finding the correct abstraction for the computation in a dynamical system, e.g. CA, is an open problem [20]. All the systems described in Table 1 are sparsely connected and can be represented by a weighted adjacency matrix, such as a graph. The connectivity from a layer to another in a fully connected feedforward ANN is represented with a weighted adjacency matrix that contains the weights of each connection. Our CA implementation is similar to this, but the connectivity goes from the “layer” of cells to itself. The goal of representing CA with a weighted adjacency matrix is to imple- ment a framework which facilitates the development of all types of CAs, from unidimensional to multidimensional, with all kinds of lattices and without any boundary conditions during execution; and also allowing the inclusion of other major dynamical systems, independent of the type of the state, time and connec- tivity. Such initial implementation is the ﬁrst component of a Python framework under development, based on TensorFlow deep neural network library [4]. There- fore, it beneﬁts from powerful and parallel computing systems with multi-CPU and multi-GPU. One of the framework’s goals is to have a balance between performance and generalization of computing dynamical systems, since general methods are slower than specialized ones. Nevertheless, this framework, called EvoDynamic, aims at evolving (i.e., using evolutionary algorithms) the connec- tivity, update and learning rules of sparsely connected networks to improve their usage for reservoir computing guided by the echo state property, fading memory, state trajectory, and other quality measurements. Such improvement of reser- voirs is applied similarly in [26], where the internal connectivity of a reservoir is trained to increase its performance to several tasks. Moreover, evolution will model the dynamics and behavior of physical reservoirs, such as in-vitro biolog- ical neural networks interfaced with microelectrode arrays, and nanomagnetic ensembles. Those two substrates have real applicability as reservoirs. For exam- ple, the former substrate is applied to control a robot, in fact making it into a cyborg, a closed-loop biological-artiﬁcial neuro-system [3], and the latter pos- sesses computation capability as shown by a square lattice of nanomagnets [14]. Those substrates are the main interest of the SOCRATES project [1] which aims to explore a dynamic, robust and energy eﬃcient hardware for data analysis. There exist some implementations of CA similar to the one of EvoDynamic framework. They typically implement Conway’s Game of Life by applying 2D convolution with a kernel that is used to count the “alive” neighbors, then the resulting matrix consists of the number of “alive” neighboring cells and is used to update the CA. One such implementation, also based on TensorFlow, is available open-source in [2]. This paper is organized as follows. Section 2 describes our method according to which we use weighted adjacency matrix to compute CA. Section 3 presents 4 S. Pontes-Filho et al. the results obtained from the method. Section 4 discusses the initial advances and future plan of EvoDynamic framework and Section 5 concludes this paper. 2 Method In our proposed method, the equation to calculate the next states of the cells in a cellular automaton is ct+1 = f(A · ct). It is similar to the equation of the forward pass of an artiﬁcial neural network, but without the bias. The layer is connected to itself, and the activation function f deﬁnes the update rules of the CA. The next states of the CA ct+1 is calculated from the result of the activation function f which receives as argument the dot product between the weighted adjacency matrix A and the current states of the CA ct. c is always a column vector of size len(c) × 1, that does not depend on how many dimensions the CA has, and A is a matrix of size len(c) × len(c). Hence the result of A · c is also a column vector of size len(c) × 1 as c. The implementation of cellular automata as an artiﬁcial neural network re- quires the procedural generation of the weighted adjacency matrix of the grid. In this way, any lattice type or multidimensional CAs can be implemented us- ing the same approach. The adjacency matrix of a sparsely connected network contains many zeros because of the small number of connections. Since we im- plement it on TensorFlow, the data type of the adjacency matrix is preferably a SparseTensor. A dot product with this data type can be up to 9 times faster than the dense counterpart. However, it depends on the conﬁguration of the tensors (or, in our case, the adjacency matrices) [28]. The update rule of the CA alters the weights of the connections in the adjacency matrix. In a CA whose cells have two states meaning “dead” (zero) or “alive” (one), the weights in the adjacency matrix are one for connection and zero for no connection, such as an ordinary adjacency matrix. Such matrix facilitates the description of the update rule for counting the number of “alive” neighbors because the result of the dot product between the adjacency matrix and the cell state vector is the vector that contains the number of “alive” neighbors for each cell. If the pattern of the neighborhood matters in the update rule, each cell has its neighbors encoded as a n-ary string where n means the number of states that a cell can have. In this case, the weights of the connections with the neighbors are n-base identiﬁers and are calculated by neighbori = ni, ∀i ∈{0..len(neighbors) −1} where neighbors is a vector of the cell’s neighbors. In the adjacency matrix, each neighbor receives a weight according to . The result of the dot product with such weighted adjacency matrix is a vector that consists of unique integers per neighborhood pattern. Thus, the activation function is a lookup table from integer (i.e., pattern) to next state. Algorithm 1 generates the weighted adjacency matrix for one-dimensional CA, such as the elementary CA, where widthCA is the width or number of EvoDynamic: a framework for the evolution of dynamical systems 5 Algorithm 1 Generation of weighted adjacency matrix for 1D cellular automa- ton 1: procedure generateCA1D 2: numberOfCells ←widthCA 3: A ←0numberOfCells×numberOfCells ▷Adjacency matrix initialization 4: for i ←{0..(numberOfCells −1)} do 5: for j ← {−indexNeighborCenter..(len(neighborhood) − indexNeighborCenter −1)} do 6: currentNeighbor ←neighborhoodj+indexNeighborCenter 7: if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧(0 ≤ (i + j) < widthCA)) then 8: Ai,((i+j) mod widthCA) ←currentNeighbor 9: return A cells of a unidimensional CA and neighborhood is a vector which describes the region around the center cell. The connection weights depend on the type of update rule as previously explained. For example, in case of an elementary CA neighborhood = [4 2 1]. indexNeighborCenter is the index of the center cell in the neighborhood whose starting index is zero. isWrappedGrid is a Boolean value that works as a ﬂag for adding a wrapped grid or not. A wrapped grid for one-dimensional CA means that the initial and ﬁnal cells are neighbors. With all these parameters, Algorithm 1 creates an adjacency matrix by looping over the indices of the cells (from zero to numberOfCells −1) with an inner loop for the indices of the neighbors. If the selected currentNeighbor is a non- zero value and its indices do not aﬀect the boundary condition, then the value of currentNeighbor is assigned to the adjacency matrix A in the indices that correspond to the connection between the current cell in the outer loop and the actual index of currentNeighbor. Finally, this procedure returns the adjacency matrix A. To procedurally generate an adjacency matrix for 2D CA instead of 1D CA, the algorithm needs to have small adjustments. Algorithm 2 shows that for two- dimensional CA, such as Conway’s Game of Life. In this case, the height of the CA is an argument passed as heightCA. Neighborhood is a 2D matrix and indexNeighborCenter is a vector of two components meaning the in- dices of the center of Neighborhood. This procedure is similar to the one in Algorithm 1, but it contains one more loop for the additional dimension. The activation function for CA is diﬀerent from the ones used for ANN. For CA, it contains the update rules that verify the vector returned by the dot product between the weighted adjacency matrix and the vector of states. Normally, the update rules of the CA are implemented as a lookup table from neighborhood to next state. In our implementation, the lookup table maps the resulting vector of the dot product to the next state of the central cell. 6 S. Pontes-Filho et al. Algorithm 2 Generation of adjacency matrix of 2D cellular automaton 1: procedure generateCA2D 2: numberOfCells ←widthCA ∗heightCA 3: A ←0numberOfCells×numberOfCells ▷Adjacency matrix initialization 4: widthNB, heightNB ←shape(Neighborhood) 5: for i ←{0..(numberOfCells −1)} do 6: for j ← {−indexNeighborCenter0..(widthNB − indexNeighborCenter0 −1)} do 7: for k ← {−indexNeighborCenter1..(heightNB − indexNeighborCenter1 −1)} do 8: currentNeighbor ←Neighborhoodj+indexNeighborCenter 9: if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧ (0 ≤((i mod heightCA)+j) < widthCA)∧(0 ≤(⌊i/widthCA⌋+k) < heightCA)) then 10: Ai,(((i+k) mod widthCA)+((⌊i/widthCA⌋+j) mod heightCA)∗widthCA) ← currentNeighbor 11: return A 3 Results This section presents the results of the proposed method and it also stands for the preliminary results of the EvoDynamic framework. Fig. 1 illustrates a wrapped elementary CA described in the procedure of Algorithm 1 and its generated weighted adjacency matrix. Fig. 1a shows the appearance of the desired elementary CA with 16 cells (i.e., widthCA = 16). Fig. 1b describes its pattern 3-neighborhood and the indices of the cells. Fig 1c shows the result of the Algorithm 1 with the neighborhood calculated by for pattern matching in the activation function. In Fig. 1c, we can verify that the left neighbor has weight equal to 4 (or 22 for the most signiﬁcant bit), central cell weight is 2 (or 21) and right neighbor weight is 1 (or 20 for the least signiﬁcant bit) as deﬁned by . Since the CA is wrapped, we can notice in row index 0 of the adjacency matrix in Fig. 1c that the left neighbor of cell 0 is the cell 15, and in row index 15 that the right neighbor of cell 15 is the cell 0. Fig. 2 describes a wrapped 2D CA (similar to Game of Life but with less number of neighbors) for Algorithm 2 and shows the resulting adjacency matrix. Fig. 2a illustrates the desired two-dimensional CA with 16 cells (i.e., widthCA = 4 and heightCA = 4). Fig. 2b presents the von Neumann neighborhood [29] which is used for counting the number of “alive” neighbors (the connection weights are only zero and one, and Neighborhood argument of Algorithm 2 deﬁnes it). It also shows the index distribution of the CA whose order is preserved after ﬂatting it to a column vector. Fig 2c contains the generated adjacency matrix of Algorithm 2 for the described 2D CA. Fig. 2b shows an example of a central cell with its neighbors, the index of this central cell is 5 and the row index 5 in the adjacency matrix of Fig. 2c presents the same neighbor indices, i.e., 1, 4, 6 and 9. Since this is a symmetric matrix, the columns have the same connectivity of the rows. That means the neighborhood of a cell considers this cell EvoDynamic: a framework for the evolution of dynamical systems 7 as a neighbor too. Therefore, the connections are bidirectional and the adjacency matrix represents an undirected graph. The wrapping eﬀect is also observable. For example, the neighbors of the cell index 0 are 1, 3, 4 and 12. So the neighbors 3 and 12 are the ones that the wrapped grid allowed to exist for cell index 0. (a) (b) (c) Fig. 1: Elementary cellular automaton with 16 cells and wrapped grid. (a) Exam- ple of the grid of cells with states. (b) Indices of the cells and standard pattern neighborhood of elementary CA where thick border means the central cell and thin border means the neighbors. (c) Generated weighted adjacency matrix for the described elementary CA. 4 On-going and future applications with EvoDynamic The method of implementing a CA as an artiﬁcial neural network is beneﬁcial for the further development of EvoDynamic framework. Since the implementation of 8 S. Pontes-Filho et al. (a) (b) (c) Fig. 2: 2D cellular automaton with 16 cells (4×4) and wrapped grid. (a) Example of the grid of cells with states. (b) Indices of the cells and von Neumann counting neighborhood of 2D CA where thick border means the current cell and thin border means the neighbors. (c) Generated adjacency matrix for the described 2D CA. EvoDynamic: a framework for the evolution of dynamical systems 9 all sparsely connected networks in Table 1 is already planned in forthcoming re- leases of the Python framework, EvoDynamic shall have a general representation to all of them. Therefore, CAs are treated as ANNs and then can be extended to random Boolean network by shuﬄing the connections, and to the models that are already ANNs, such as echo state networks and liquid state machines. More- over, EvoDynamic framework will evolve the connectivity, update and learning rules of the dynamical systems for reservoir computing improvement and physi- cal substrate modeling. This common representation facilitates the evolution of such systems and models which will be guided by several methods that measure the quality of a reservoir or the similarity to a dataset. The following subsections explain two on-going applications with CA that use the EvoDynamic framework. 4.1 State trajectory An example of methods to guide the evolution of dynamical system is the state trajectory. This method can be used to cluster similar states for model abstrac- tion and to measure the quality of the reservoir. Therefore, a graph can be formed and analysis can be made by searching for attractors and cycles. For visualization of the state trajectory, we use principal component analysis (PCA) to reduce the dimensionality of the states and present them as a state transi- tion diagram as shown in Fig. 3. The depicted dynamical system is Conway’s Game of Life with 7x7 cells and wrapped boundaries. A glider is its initial state (Fig. 3a) and this system cycles over 28 unique states as illustrated in the state transition diagram of Fig. 3l. 4.2 Towards the evolution for criticality Evolution of dynamical systems is a feature currently under development of EvoDynamic framework. The ﬁrst on-going evolution task of our framework is to ﬁnd systems with criticality [7] using genetic algorithm, in order to allow for better computational capacity [17]. The ﬁrst dynamical system for this task is a modiﬁed version of stochastic elementary cellular automata (SECA) introduced by Baetens et al. [6]. Our stochastic elementary cellular automaton works as a 1D three neighbors elementary CA, but the next state in time t+1 of the central cell ci is deﬁned by a probability p to be 1 and a probability 1−p to be 0 for each of the eight diﬀerent neighborhood patterns this CA has. Formally, probability p is represented by p = P(ci,t+1 = 1|N(ci,t)) where the neighborhood pattern N(ci,t) is denoted as N(ci,t) = (ci−1,t, ci,t, ci+1,t). The genetic algorithm for criticality is guided by a ﬁtness function which mainly veriﬁes if the probability distributions of avalanche size (i.e., cluster size5 5 Cluster size stands for the number of repetitions of a state that happened consecu- tively without any interruption of another state. 10 S. Pontes-Filho et al. −1 0 1 −1 0 1 (a) Step 1 −1 0 1 −1 0 1 (b) Step 2 −1 0 1 −1 0 1 (c) Step 3 −1 0 1 −1 0 1 (d) Step 4 −1 0 1 −1 0 1 (e) Step 11 −1 0 1 −1 0 1 (f) Step 12 −1 0 1 −1 0 1 (g) Step 13 −1 0 1 −1 0 1 (h) Step 14 −1 0 1 −1 0 1 (i) Step 26 −1 0 1 −1 0 1 (j) Step 27 −1 0 1 −1 0 1 (k) Step 28 −1 0 1 −1 0 1 (l) Step 29 Fig. 3: States of Conway’s Game of Life in a 7x7 wrapped lattice alongside their PCA-transformed state transition diagrams of the two ﬁrst principal compo- nents. (a) Initial state is a glider. (a)-(d) Four ﬁrst steps in this CA. (e)-(h) Four intermediate steps in this CA while reaching the wrapped border. (i)-(l) Four last steps in this CA before repeating the initial state and closing a cycle. in space) and duration (i.e., cluster size in time) follow a power-law distribu- tion. Such veriﬁcation can be done by checking how linear is the probability distribution in a log-log plot, by performing goodness-of-ﬁt tests based on the Kolmogorov-Smirnov (KS) statistic and by comparing the power-law model with the exponential model using log-likelihood ratio [9]. For our ﬁtness function, we estimate the candidate distributions with the linear ﬁtting of the ﬁrst 10 points of the log-log plot using least squares regression, which was veriﬁed to be not biased and gives a fast and acceptable estimation of the slope of the power-law distribution [12]. After the linear 10-points ﬁtting, the model is tested using KS statistic. One beneﬁt of using such estimation method is that when the model is not a power-law, the KS statistic reports a large error, i.e., an error greater than one. Another objective in the ﬁtness function is the coeﬃcient of determi- nation [31], but for a complete linear ﬁt of the log-log plot. The ﬁtness function also considers the number of unique states of the stochastic elementary CA, the number of bins in the raw histogram and the value of the estimated power-law exponent. All these ﬁtness function objectives are calculated using a randomly initialized CA of 1,000 cells with wrapped boundaries during 1,000 time-steps. The avalanche size and duration are computed for the cell values 0 and 1, thus producing four diﬀerent distributions (see Fig. 4) for extracting vectors of their EvoDynamic: a framework for the evolution of dynamical systems 11 normalized number of histogram bins6 bin; coeﬃcient of determination R2 of complete linear ﬁtting; KS statistic D and estimated power-law exponent ˆα from the 10-points linear estimation. The ﬁtness score s for each objective is then calculated by the following equations: bins = tanh(5 ∗(0.9 ∗max(bin) + 0.1 ∗mean(bin))), R2 s = mean(R2), Ds = exp(−(0.9 ∗min(D) + 0.1 ∗mean(D))), ˆαs = mean(ˆα), uniques = #uniqueStates #timesteps . The - are all objective values for calculating the ﬁtness score s. Those values are real numbers between zero and one, except the score for the estimated power-law exponent ˆαs, and they have weights attributed to them regarding their level of importance and for compensating small and large values. The following equation denotes how the ﬁtness score s is calculated: s = 10 ∗bins + 10 ∗R2 s + 10 ∗Ds + 0.1 ∗ˆαs + 10 ∗uniques. The genetic algorithm has 40 individuals that evolve through 100 generations. The optimization performed by GA is to maximize the ﬁtness score. The genome of the individuals has eight real number genes with a value range between zero and one. Each gene represents the probability of the next state becoming one (i.e., p in ) for its respective neighborhood pattern. The selection of two par- ents is done by deterministic tournament selection [11]. After that, the crossover between the genomes of the parents can happen with probability 0.8, then each gene can be exchanged with probability 0.5. Afterward, a mutation occurs to a gene with probability 0.1. This mutation adds a random value from a normal distribution with mean and standard deviation equals to, respectively, 0 and 0.2. The mating process of the two parents produces an oﬀspring of two new individ- uals who replace the parents in the next generation. An example of an evolved genome for the best resulting individual is presented in Table 2. The ﬁtness score s and all objective scores with their respective weights for calculating s are in Table 3. With the genome or probabilities of the eight diﬀerent neighborhood patterns of the best evolved individual, we can produce the log-log plots of the probability distribution of avalanche size and duration for the states zero and one. Such plots 6 The actual number of histogram bins is normalized or divided by the possible total number of bins. 12 S. Pontes-Filho et al. Table 2: Best individual Neighborhood N(ci,t) Probability p (0,0,0) 0.103009 (0,0,1) 0.536786 (0,1,0) 0.216794 (0,1,1) 0.393468 (1,0,0) 0.679836 (1,0,1) 0.175458 (1,1,0) 0.724778 (1,1,1) 1.000000 Table 3: Fitness score of the best individual Objective Score 10 ∗bins 9.780749590096136 10 ∗R2 s 8.832520186440096 10 ∗Ds 9.655719560019996 0.1 ∗ˆαs 0.18022617747972156 10 ∗uniques 10.0 s 38.44921551403595 are depicted in Fig. 4. The p-value of goodness-of-ﬁt test is calculated using 1,000 randomly generated data with 10,000 samples applying the power-law exponent ˆα estimated by maximum likelihood estimation method with minimum x of the distribution ﬁxed to 1. The Fig. 4a and Fig. 4b show the avalanche size and duration for the state 0 or black. They present distributions that are not a power- law because they do not ﬁt the power-law estimation (the black dashed line). Moreover, the p-value is equal to 0.0 which proves that those two distributions are not a power-law. The Fig. 4c and Fig. 4d present the avalanche size and duration for the state 1 or white. Those distributions follow a power-law because, visually, the estimated power-law distribution ﬁts the empirical probability distribution and, quantitatively, the p-value is equal to 1.0 which means that 100% of the KS statistic of the generated data is greater than the KS statistic of the empirical distribution of avalanche size and duration of state 1. The number of samples in those distributions (62,731 for avalanche size and 52,902 for avalanche duration) conﬁrms that the p-value is trustworthy. Such power-law analysis is performed by utilizing the powerlaw Python library [5]. It is important to warn that high ﬁtness scores do not mean p-values closer to 1.0 and the goodness-of-ﬁt test is not part of the ﬁtness score because it is a slow process. A sample of the resulting stochastic elementary cellular automaton of the best individual is illustrated in Fig. 5. This CA, as seen, has no static nor periodic states, and no random evolution of its states. Therefore, this dynamical system EvoDynamic: a framework for the evolution of dynamical systems 13 is between a strongly and weakly coupled substrate. Therefore, the CA presents patterns or structures that mean the cells are interdependent in this system. 5 Conclusion In this paper, we present an alternative method to implement a cellular au- tomaton. This allows any CA to be computed as an artiﬁcial neural network. That means, any lookup table can be an activation function, and any neigh- borhood and dimensionality can be represented as a weight matrix. Therefore, this will help to extend the CA implementation to more complex dynamical sys- tems, such as random Boolean networks, echo state networks and liquid state machines. Furthermore, the EvoDynamic framework is built on a deep learning library, TensorFlow, which permits the acceleration and parallelization of ma- trix operations when applied on computational platforms with fast CPUs and (a) Avalanche size of state 0 (b) Avalanche duration of state 0 (c) Avalanche size of state 1 (d) Avalanche duration of state 1 Fig. 4: Avalanche size and duration of the two states 0 and 1 of the evolved stochastic elementary CA. 14 S. Pontes-Filho et al. Fig. 5: Sample of the best evolved stochastic elementary CA of 200 cells (horizon- tal axis) randomly initialized with wrapped boundaries through 400 time-steps (vertical axis). GPUs. The planned future implementations of EvoDynamic are presented and discussed. The state trajectory is an important feature for the targeted future tasks. The evolution with genetic algorithm towards criticality of stochastic CA is showing promising results and our next goal can be for self-organized criti- cality. The future work for the CA implementation is to develop algorithms to procedurally generate weighted adjacency matrices for 3D and multidimensional cellular automata with diﬀerent types of cells, such as the cells with hexagonal shape in a 2D CA. EvoDynamic: a framework for the evolution of dynamical systems 15 Acknowledgments We thank Kristine Heiney for thoughtful discussions about self-organized criti- cality. References 1. SOCRATES – Self-Organizing Computational substRATES, edu/socrates 2. Conway’s game of life implemented using tensorﬂow 2d convolution function , life 3. Aaser, P., Knudsen, M., Ramstad, O.H., van de Wijdeven, R., Nichele, S., Sandvig, I., Tufte, G., Stefan Bauer, U., Halaas, Ø., Hendseth, S., Sandvig, A., Valderhaug, V.: Towards making a cyborg: A closed-loop reservoir-neuro system. The 2018 Conference on Artiﬁcial Life: A Hybrid of the European Conference on Artiﬁcial Life (ECAL) and the International Conference on the Synthesis and Simulation of Living Systems (ALIFE) , 430–437 . a 072 4. Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghe- mawat, S., Irving, G., Isard, M., Kudlur, M., Levenberg, J., Monga, R., Moore, S., Murray, D.G., Steiner, B., Tucker, P., Vasudevan, V., Warden, P., Wicke, M., Yu, Y., Zheng, X.: Tensorﬂow: A system for large-scale machine learning. In: 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16). pp. 265–283. USENIX Association, Savannah, GA 5. Alstott, J., Bullmore, E., Plenz, D.: powerlaw: A python package for analysis of heavy-tailed distributions. PLOS ONE 9, 1–11 (01 2014). 6. Baetens, J.M., Van der Meeren, W., De Baets, B.: On the dynamics of stochastic elementary cellular automata. Journal of Cellular Automata 12 7. Bak, P., Tang, C., Wiesenfeld, K.: Self-organized criticality: An expla- nation of the 1/f noise. Phys. Rev. Lett. 59, 381–384 (Jul 1987). 8. Broersma, H., Miller, J.F., Nichele, S.: Computational Matter: Evolving Com- putational Functions in Nanoscale Materials, pp. 397–428. Springer International Publishing, Cham . 16 9. Clauset, A., Shalizi, C.R., Newman, M.E.: Power-law distributions in empirical data. SIAM review 51, 661–703 10. Gershenson, C.: Introduction to random boolean networks. arXiv preprint nlin/0408006 11. Goldberg, D.E., Deb, K.: A comparative analysis of selection schemes used in genetic algorithms. In: Foundations of genetic algorithms, vol. 1, pp. 69–93. Elsevier 12. Goldstein, M.L., Morris, S.A., Yen, G.G.: Problems with ﬁtting to the power-law distribution. The European Physical Journal B-Condensed Matter and Complex Systems 41, 255–258 13. Jaeger, H., Haas, H.: Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication. Science 304, 78–80 . 16 S. Pontes-Filho et al. 14. Jensen, J.H., Folven, E., Tufte, G.: Computation in artiﬁcial spin ice. The 2018 Conference on Artiﬁcial Life: A Hybrid of the European Conference on Artiﬁcial Life (ECAL) and the International Conference on the Synthesis and Simulation of Living Systems (ALIFE) , 15–22 . a 00011 15. Kaneko, K.: Overview of coupled map lattices. Chaos: An Interdisciplinary Journal of Nonlinear Science 2, 279–282 16. Konkoli, Z., Nichele, S., Dale, M., Stepney, S.: Reservoir Computing with Com- putational Matter, pp. 269–293. Springer International Publishing, Cham . 14 17. Langton, C.G.: Computation at the edge of chaos: Phase transitions and emer- gent computation. Physica D: Nonlinear Phenomena 42, 12 – 37 . 18. Maass, W., Markram, H.: On the computational power of circuits of spiking neurons. Journal of Computer and System Sciences 69, 593 – 616 . 19. Nichele, S., Tufte, G.: Trajectories and attractors as speciﬁcation for the evolution of behaviour in cellular automata. In: IEEE Congress on Evolutionary Computa- tion. pp. 1–8 (July 2010). 20. Nichele, S., Farstad, S.S., Tufte, G.: Universality of evolved cellular automata in- materio. International Journal of Unconventional Computing 13 21. Nichele, S., Gundersen, M.S.: Reservoir computing using nonuniform bi- nary cellular automata. Complex Systems 26, 225–245 (Sep 2017). 22. Nichele, S., Molund, A.: Deep learning with cellular automaton-based reservoir computing. Complex Systems 26, 319–339 (Dec 2017). 23. Nichele, S., Tufte, G.: Genome parameters as information to forecast emergent developmental behaviors. In: Durand-Lose, J., Jonoska, N. (eds.) Unconventional Computation and Natural Computation. pp. 186–197. Springer Berlin Heidelberg, Berlin, Heidelberg 24. Rendell, P.: Turing Universality of the Game of Life, pp. 513–539. Springer London, London . 18 25. Schrauwen, B., Verstraeten, D., Van Campenhout, J.: An overview of reservoir computing: theory, applications and implementations. In: Proceedings of the 15th European Symposium on Artiﬁcial Neural Networks. p. 471-482 2007. pp. 471–482 26. Subramoney, A., Scherr, F., Maass, W.: Reservoirs learn to learn. arXiv preprint arXiv:1909.07486 27. Tanaka, G., Yamane, T., H´eroux, J.B., Nakane, R., Kanazawa, N., Takeda, S., Numata, H., Nakano, D., Hirose, A.: Recent advances in physical reservoir computing: A review. Neural Networks 115, 100 – 123 . 28. TensorFlow: tf.sparse.sparse dense matmul — tensorﬂow core r1.14 — tensorﬂow, docs/python/tf/sparse/sparse dense matmul 29. Toﬀoli, T., Margolus, N.: Cellular automata machines: a new environment for mod- eling. MIT press 30. Wolfram, S.: A new kind of science, vol. 5. Wolfram media Champaign, IL 31. Wright, S.: Correlation and causation. Journal of Agricultural Research 20, 557– 580",". Dynamical systems possess a computational capacity that may be exploited in a reservoir computing paradigm. This paper presents a general representation of dynamical systems which is based on matrix multiplication. That is similar to how an artiﬁcial neural network (ANN) would be represented in a deep learning library and its computation would be faster because of the optimized matrix operations that such type of libraries have. Initially, we implement the simplest dynamical system, a cellular automaton. The mathematical fundamentals behind an ANN are maintained, but the weights of the connections and the ac- tivation function are adjusted to work as an update rule in the context of cellular automata. The advantages of such implementation are its us- age on specialized and optimized deep learning libraries, the capabilities to generalize it to other types of networks and the possibility to evolve cellular automata and other dynamical systems in terms of connectivity, update and learning rules. Our implementation of cellular automata con- stitutes an initial step towards a more general framework for dynamical systems. Our objective is to evolve such systems to optimize their usage in reservoir computing and to model physical computing substrates. Fur- thermore, we present promising preliminary results toward the evolution of complex behavior and criticality using genetic algorithm in stochastic elementary cellular automata.","['Sidney Pontes-Filho', 'Pedro Lind', 'Anis Yazidi', 'Jianhua Zhang', 'Hugo Hammer', 'Gustavo Mello', 'Ioanna Sandvig', 'Gunnar Tufte', 'Stefano Nichele']"
A general representation of dynamical systems for reservoir computing,"Sidney Pontes{-}Filho and
Anis Yazidi and
Jianhua Zhang and
Hugo Hammer and
Gustavo B. M. Mello and
Ioanna Sandvig and
Gunnar Tufte and
Stefano Nichele",2019,missing,abs/1907.01856,CoRR,article,"A general representation of dynamical systems for
reservoir computing
Sidney Pontes-Filho∗,†,§, Anis Yazidi∗, Jianhua Zhang∗, Hugo Hammer∗,
Gustavo B. M. Mello∗, Ioanna Sandvig‡, Gunnar Tufte† and Stefano Nichele∗
∗Department of Computer Science, Oslo Metropolitan University, Oslo, Norway
†Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway
‡Department of Neuromedicine and Movement Science, Norwegian University of Science and Technology, Trondheim, Norway
Email: §sidneyp@oslomet.no
Abstract INTRODUCTION
A cellular automaton (CA) is the simplest computing sys-
tem where the emergence of complex dynamics from local
interactions might take place. It consists of a grid of cells
with a ﬁnite number of states that change according to simple
rules depending on the neighborhood and own state in discrete
time-steps. Some notable examples are the elementary CA
[1], which is unidimensional with three neighbors and eight
update rules, and Conway’s Game of Life [2], which is two-
dimensional with nine neighbors and three update rules.
Table I presents some computing systems that are capable
of giving rise to the emergence of complex dynamics. Those
systems can be exploited by reservoir computing which is a
paradigm that resorts to dynamical systems to simplify com-
plex data. Hence, simpler and faster machine learning methods
can be applied with such simpliﬁed data. Reservoir computing
is more energy efﬁcient than deep learning methods and it can
even yield competitive results, especially for temporal data [3].
In short, reservoir computing exploits a dynamical system that
possesses the echo state property and fading memory, where
the internals of the reservoir are untrained and the only training
happens at the linear readout stage [4]. Reservoir computers
are most useful when the substrate’s dynamics are at the
“edge of chaos”, meaning a range of dynamical behaviors
that is between order and disorder [5]. Cellular automata with
such dynamical behavior are capable of being exploited as
TABLE I
EXAMPLES OF DYNAMICAL SYSTEMS.
Dynamical system
State
Time
Connectivity
Cellular automata
Discrete
Discrete
Regular
Coupled map lattice
Continuous
Discrete
Regular
Random Boolean network
Discrete
Discrete
Random
Echo state network
Continuous
Discrete
Random
Liquid state machine
Discrete
Continuous
Random
reservoirs [6], [7]. Other systems can also exhibit the same
dynamics. The coupled map lattice [8] is very similar to
CA, the only exception is that the coupled map lattice has
continuous states which are updated by a recurrence equation
involving the neighborhood. Random Boolean network [9] is a
generalization of CA where random connectivity exists. Echo
state network [10] is an artiﬁcial neural network (ANN) with
random topology while liquid state machine [11] is similar to
echo state network with the difference that it is a spiking neural
network that communicates through discrete-events (spikes)
over continuous time. One important aspect of the computation
performed in a dynamical system is the trajectory of system’s
states traversed during the computation [12]. Such trajectory
may be guided by system parameters [13]. Computation in
dynamical systems may be carried out in physical substrates
[14], such as networks of biological neurons [15] or in other
nanoscale materials [16]. Finding the correct abstraction for
the computation in a dynamical system, e.g. CA, is an open
problem [17]. All the systems described in Table I are sparsely
connected and can be represented by an adjacency matrix, such
as a graph. A fully connected feedforward ANN represents
its connectivity from a layer to another with an adjacency
matrix that contains the weights of each connection. Our CA
implementation is similar to this, but the connectivity is from
the ”layer” of cells to itself.
The goal of representing CA with an adjacency matrix is to
implement a framework which facilitates the development of
all types of CAs, from unidimensional to multidimensional,
with all kinds of lattices and without any boundary checks
during execution; and also the inclusion of the major dynam-
ical systems, independent of the type of the state, time and
arXiv:1907.01856v1  [cs.NE]  3 Jul 2019
 connectivity. Such initial implementation is the ﬁrst part of a
Python framework under development, based on TensorFlow
deep neural network library [18]. Therefore, it beneﬁts from
powerful and parallel computing systems with multi-CPU and
multi-GPU. This framework, called EvoDynamic1, aims at
evolving the connectivity, update and learning rules of sparsely
connected networks to improve their usage for reservoir com-
puting guided by the echo state property, fading memory, state
trajectory and other quality measurements, and to model the
dynamics and behavior of physical reservoirs, such as in-
vitro biological neural networks interfaced with microelectrode
arrays and nanomagnetic ensembles. Those two substrates
have real applicability as reservoirs. For example, the former
substrate is applied to control a robot, in fact making it into a
cyborg, a closed-loop biological-artiﬁcial neuro-system [15],
and the latter possesses computation capability as shown by
a square lattice of nanomagnets [19]. Those substrates are the
main interest of the SOCRATES project [20] which aims to
explore a dynamic, robust and energy efﬁcient hardware for
data analysis.
There are some implementations of CA similar to the one of
EvoDynamic framework. They normally implement Conway’s
Game of Life by applying 2D convolution with a kernel that is
used to count the neighbors, then the resulting matrix consists
of the number of neighboring cells and is used to update the
CA. One such implementation, also based on TensorFlow, is
available open-source in [21].
This paper is organized as follows. Section II describes
our method according to which we use adjacency matrix to
compute CA. Section III presents the results obtained from the
method. Section IV discusses the future plan of EvoDynamic
framework and Section V concludes this paper.
II. METHOD
In our proposed method, the equation to calculate the next
states of the cells in a cellular automaton is
cat+1 = f(A · cat).
(1)
It is similar to the equation of the forward pass of an
artiﬁcial neural network, but without the bias. The layer is
connected to itself, and the activation function f deﬁnes the
update rules of the CA. The next states of the CA cat+1 is
calculated from the result of the activation function f which
receives as argument the dot product between the adjacency
matrix A and the current states of the CA cat. ca is always
a column vector of size len(ca) × 1, that does not depend on
how many dimensions the CA has, and A is a matrix of size
len(ca)×len(ca). Hence the result of A·ca is also a column
vector of size len(ca) × 1 as ca.
The implementation of cellular automata as an artiﬁcial neu-
ral network requires the procedural generation of the adjacency
matrix of the grid. In this way, any lattice type or multidi-
mensional CAs can be implemented using the same approach.
1EvoDynamic
v0.1
available
at
https://github.com/SocratesNFR/
EvoDynamic.
The adjacency matrix of a sparsely connected network contains
many zeros because of the small number of connections. Since
we implement it on TensorFlow, the data type of the adjacency
matrix is preferably a SparseTensor. A dot product with
this data type can be up to 9 times faster depending on the
conﬁguration of the tensors [22]. The update rule of the CA
alters the weights of the connections in the adjacency matrix.
In a CA whose cells have two states meaning “dead” (zero) or
“alive” (one), the weights in the adjacency matrix are one for
connection and zero for no connection, such as an ordinary
adjacency matrix. Such matrix facilitates the description of
the update rule for counting the number of “alive” neighbors
because the result of the dot product between the adjacency
matrix and the cell state vector is the vector that contains the
number of “alive” neighbors for each cell. If the pattern of
the neighborhood matters in the update rule, each cell has
its neighbors encoded as a n-ary string where n means the
number of states that a cell can have. In this case the weights
of the connections with the neighbors are n-base identiﬁers
and are calculated by
neighbori = ni, ∀i ∈{0..len(neighbors) −1}.
(2)
Where neighbors is a vector of the cell’s neighbors. In the
adjacency matrix, each neighbor receives a weight according
to (2). The result of the dot product with such adjacency matrix
is a vector that consists of unique integers per neighborhood
pattern. Thus, the activation function is a lookup table from
integer (i.e., pattern) to next state.
Algorithm 1 generates the adjacency matrix for one-
dimensional CA, such as the elementary CA. Where widthCA
is the width or number of cells of a unidimensional CA
and neighborhood is a vector which describes the region
around the center cell. The connection weights depend on
the type of update rule as previously explained. For ex-
ample, in case of an elementary CA neighborhood =
[4 2 1]. indexNeighborCenter is the index of the center
cell in the neighborhood whose starting index is zero.
isWrappedGrid is a Boolean value that works as a ﬂag
for adding wrapped grid or not. A wrapped grid for one-
dimensional CA means that the initial and ﬁnal cells are
neighbors. With all these parameters, Algorithm 1 creates an
adjacency matrix by looping over the indices of the cells (from
zero to numberOfCells −1) with an inner loop for the
indices of the neighbors. If the selected currentNeighbor is
a non-zero value and its indices do not affect the boundary
condition, then the value of currentNeighbor is assigned
to the adjacency matrix A in the indices that correspond to
the connection between the current cell in the outer loop and
the actual index of currentNeighbor. Finally, this procedure
returns the adjacency matrix A.
To procedurally generate an adjacency matrix for 2D CA
instead of 1D CA, the algorithm needs to have small adjust-
ments. Algorithm 2 shows that for two-dimensional CA, such
as Conway’s Game of Life. In this case, the height of the
CA is an argument passed as heightCA. Neighborhood
 Algorithm 1 Generation of adjacency matrix for 1D cellular automaton
1: procedure GENERATECA1D(widthCA, neighborhood, indexNeighborCenter, isWrappedGrid)
2:
numberOfCells ←widthCA
3:
A ←0numberOfCells×numberOfCells
▷Adjacency matrix initialization
4:
for i ←{0..numberOfCells −1} do
5:
for j ←{−indexNeighborCenter..len(neighborhood) −indexNeighborCenter −1} do
6:
currentNeighbor ←neighborhoodj+indexNeighborCenter
7:
if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧(0 ≤(i + j) < widthCA)) then
8:
Ai,((i+j) mod widthCA) ←currentNeighbor
9:
return A
is a 2D matrix and indexNeighborCenter is a vector
of two components meaning the indices of the center of
Neighborhood. This procedure is similar to the one in
Algorithm 1, but it contains one more loop for the additional
dimension.
The activation function for CA is different from the ones
used for ANN. For CA, it contains the update rules that verify
the vector returned by the dot product between the adjacency
matrix and the vector of states. Normally, the update rules of
the CA are implemented as a lookup table from neighborhood
to next state. In our implementation, the lookup table maps
the resulting vector of the dot product to the next state of the
central cell.
III. RESULTS
This section presents the results of the proposed method and
it also stands for the preliminary results of the EvoDynamic
framework.
Fig. 1 illustrates a wrapped elementary CA described in the
procedure of Algorithm 1 and its generated adjacency matrix.
Fig. 1a shows the appearance of the desired elementary CA
with 16 cells (i.e., widthCA = 16). Fig. 1b describes its
pattern 3-neighborhood and the indices of the cells. Fig 1c
shows the result of the Algorithm 1 with the neighborhood
calculated by (2) for pattern matching in the activation func-
tion. In Fig. 1c, we can verify that the left neighbor has weight
equals to 4 (or 22 for the most signiﬁcant bit), central cell
weight is 2 (or 21) and right neighbor weight is 1 (or 20
for the least signiﬁcant bit) as deﬁned by (2). Since the CA
is wrapped, we can notice in row index 0 of the adjacency
matrix in Fig. 1c that the left neighbor of cell 0 is the cell 15,
and in row index 15 that the right neighbor of cell 15 is the
cell 0.
Fig. 2 describes a wrapped 2D CA for Algorithm 2 and
shows the resulting adjacency matrix. Fig. 2a illustrates the
desired two-dimensional CA with 16 cells (i.e., widthCA = 4
and heightCA = 4). Fig. 2b presents the von Neumann
neighborhood [23] which is used for counting the number of
”alive” neighbors (the connection weights are only zero and
one, and Neighborhood argument of Algorithm 2 deﬁnes
it). It also shows the index distribution of the CA whose
order is preserved after ﬂatting it to a column vector. Fig 2c
contains the generated adjacency matrix of Algorithm 2 for
the described 2D CA. Fig. 2b shows an example of a central
(a)
(b)
(c)
Fig. 1.
Elementary cellular automaton with 16 cells and wrapped grid. (a)
Example of the grid of cells with states. (b) Indices of the cells and standard
pattern neighborhood of elementary CA where thick border means the central
cell and thin border means the neighbors. (c) Generated adjacency matrix for
this elementary CA.
cell with its neighbors, the index of this central cell is 5 and
the row index 5 in the adjacency matrix of Fig. 2c presents
the same neighbor indices, i.e., 1, 4, 6 and 9. Since this is
a symmetric matrix, the columns have the same connectivity
of the rows. Therefore, this adjacency matrix represents an
undirected graph. The wrapping effect is also observable. For
example, the neighbors of the cell index 0 are 1, 3, 4 and 12.
So the neighbors 3 and 12 are the ones that the wrapped grid
allowed to exist for cell index 0.
IV. EVODYNAMIC FUTURE
The method of implementing a CA as an artiﬁcial neural
network will be beneﬁcial for the future of EvoDynamic
framework. Since the implementation of all sparsely connected
networks in Table I are already planned in future releases
 Algorithm 2 Generation of adjacency matrix of 2D cellular automaton
1: procedure GENERATECA2D(widthCA, heightCA, Neighborhood, indexNeighborCenter, isWrappedGrid)
2:
numberOfCells ←widthCA ∗heightCA
3:
A ←0numberOfCells×numberOfCells
▷Adjacency matrix initialization
4:
widthNB, heightNB ←shape(Neighborhood)
5:
for i ←{0..numberOfCells −1} do
6:
for j ←{−indexNeighborCenter0..widthNB −indexNeighborCenter0 −1} do
7:
for k ←{−indexNeighborCenter1..heightNB −indexNeighborCenter1 −1} do
8:
currentNeighbor ←Neighborhoodj+indexNeighborCenter
9:
if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧(0 ≤((i mod heightCA) + j) <
widthCA) ∧(0 ≤(⌊i/widthCA⌋+ k) < heightCA)) then
10:
Ai,(((i+k) mod widthCA)+((⌊i/widthCA⌋+j) mod heightCA)∗widthCA) ←currentNeighbor
11:
return A
(a)
(b)
(c)
Fig. 2. 2D cellular automaton with 16 cells (4 × 4) and wrapped grid. (a)
Example of the grid of cells with states. (b) Indices of the cells and von
Neumann counting neighborhood of 2D CA where thick border means the
current cell and thin border means the neighbors. (c) Generated adjacency
matrix for this 2D CA.
of the Python framework, EvoDynamic must have a general
representation to all of them. Therefore we are treating CA
as an ANN. Moreover, EvoDynamic framework will evolve
the connectivity, update and learning rules of the dynamical
systems for reservoir computing improvement and physical
substrate modeling. This common representation facilitates the
evolution of such systems and models which will be guided by
several methods that measure the quality of a reservoir or the
similarity to a dataset. One example of these methods is the
state trajectory. For visualization, we use principal component
analysis (PCA) to reduce the dimensionality of the states and
present them as a state transition diagram as shown in Fig. 3.
V. CONCLUSION
In this paper, we present an alternative method to implement
a cellular automaton. This allows any CA to be computed as an
artiﬁcial neural network. Therefore, this will help to extend the
CA implementation to more complex dynamical systems, such
as echo state networks and liquid state machines. Furthermore,
the EvoDynamic framework is built on a deep learning library,
TensorFlow, which permits the acceleration of the execution
when applied on parallel computational platforms with fast
CPUs and GPUs. The future work for this CA implementation
is to develop algorithms to procedurally generate adjacency
matrices for 3D and multidimensional cellular automata with
different types of cells, such as the cells with hexagonal shape.
ACKNOWLEDGMENTS
This work was supported by Norwegian Research Council
SOCRATES project (grant number 270961).
REFERENCES
[1] S. Wolfram, A new kind of science.
Wolfram media Champaign, IL,
2002, vol. 5.
[2] P. Rendell, Turing Universality of the Game of Life.
London:
Springer London, 2002, pp. 513–539. [Online]. Available: https:
//doi.org/10.1007/978-1-4471-0129-1 18
[3] B. Schrauwen, D. Verstraeten, and J. Van Campenhout, “An overview
of reservoir computing: theory, applications and implementations,” in
Proceedings of the 15th European Symposium on Artiﬁcial Neural
Networks. p. 471-482 2007, 2007, pp. 471–482.
[4] Z.
Konkoli,
S.
Nichele,
M.
Dale,
and
S.
Stepney,
Reservoir
Computing with Computational Matter.
Cham: Springer International
Publishing, 2018, pp. 269–293. [Online]. Available: https://doi.org/10.
1007/978-3-319-65826-1 14
[5] C. G. Langton, “Computation at the edge of chaos: Phase transitions
and
emergent
computation,”
Physica
D:
Nonlinear
Phenomena,
vol. 42, no. 1, pp. 12 – 37, 1990. [Online]. Available: http:
//www.sciencedirect.com/science/article/pii/016727899090064V
[6] S.
Nichele
and
M.
S.
Gundersen,
“Reservoir
computing
using
nonuniform binary cellular automata,” Complex Systems, vol. 26, no. 3,
pp. 225–245, Sep. 2017. [Online]. Available: https://doi.org/10.25088/
complexsystems.26.3.225
[7] S. Nichele and A. Molund, “Deep learning with cellular automaton-
based reservoir computing,” Complex Systems, vol. 26, no. 4, pp.
319–339, Dec. 2017. [Online]. Available: https://doi.org/10.25088/
complexsystems.26.4.319
[8] K. Kaneko, “Overview of coupled map lattices,” Chaos: An Interdisci-
plinary Journal of Nonlinear Science, vol. 2, no. 3, pp. 279–282, 1992.
 (a) Step 1
(b) Step 2
(c) Step 3
(d) Step 4
(e) Step 11
(f) Step 12
(g) Step 13
(h) Step 14
(i) Step 26
(j) Step 27
(k) Step 28
(l) Step 29
Fig. 3.
States of Conway’s Game of Life in a 7x7 wrapped lattice alongside their PCA-transformed state transition diagrams of the two ﬁrst principal
components. (a) Initial state is a glider. (a)-(d) Four ﬁrst steps in this CA. (e)-(h) Four intermediate steps in this CA while reaching the wrapped border. (i)-(l)
Four last steps in this CA before repeating the initial state and closing a cycle.
[9] C. Gershenson, “Introduction to random boolean networks,” arXiv
preprint nlin/0408006, 2004.
[10] H. Jaeger and H. Haas, “Harnessing nonlinearity: Predicting chaotic
systems and saving energy in wireless communication,” Science,
vol. 304, no. 5667, pp. 78–80, 2004. [Online]. Available: https:
//science.sciencemag.org/content/304/5667/78
[11] W.
Maass
and
H.
Markram,
“On
the
computational
power
of
circuits
of
spiking
neurons,”
Journal
of
Computer
and
System
Sciences, vol. 69, no. 4, pp. 593 – 616, 2004. [Online]. Available:
http://www.sciencedirect.com/science/article/pii/S0022000004000406
[12] S. Nichele and G. Tufte, “Trajectories and attractors as speciﬁcation for
the evolution of behaviour in cellular automata,” in IEEE Congress on
Evolutionary Computation, July 2010, pp. 1–8.
[13] S. Nichele and G. Tufte, “Genome parameters as information to forecast
emergent developmental behaviors,” in Unconventional Computation
and Natural Computation, J. Durand-Lose and N. Jonoska, Eds. Berlin,
Heidelberg: Springer Berlin Heidelberg, 2012, pp. 186–197.
[14] G. Tanaka, T. Yamane, J. B. Hroux, R. Nakane, N. Kanazawa,
S.
Takeda,
H.
Numata,
D.
Nakano,
and
A.
Hirose,
“Recent
advances
in
physical
reservoir
computing:
A
review,”
Neural
Networks, vol. 115, pp. 100 – 123, 2019. [Online]. Available:
http://www.sciencedirect.com/science/article/pii/S0893608019300784
[15] P. Aaser, M. Knudsen, O. H. Ramstad, R. van de Wijdeven, S. Nichele,
I. Sandvig, G. Tufte, U. Stefan Bauer, . Halaas, S. Hendseth,
A. Sandvig, and V. Valderhaug, “Towards making a cyborg: A
closed-loop reservoir-neuro system,” The 2018 Conference on Artiﬁcial
Life: A Hybrid of the European Conference on Artiﬁcial Life (ECAL)
and the International Conference on the Synthesis and Simulation
of Living Systems (ALIFE), no. 29, pp. 430–437, 2017. [Online].
Available: https://www.mitpressjournals.org/doi/abs/10.1162/isal a 072
[16] H. Broersma, J. F. Miller, and S. Nichele, Computational Matter:
Evolving Computational Functions in Nanoscale Materials.
Cham:
Springer
International
Publishing,
2017,
pp.
397–428.
[Online].
Available: https://doi.org/10.1007/978-3-319-33921-4 16
[17] S. Nichele, S. S. Farstad, and G. Tufte, “Universality of evolved
cellular automata in-materio.” International Journal of Unconventional
Computing, vol. 13, no. 1, 2017.
[18] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin,
S. Ghemawat, G. Irving, M. Isard, M. Kudlur, J. Levenberg, R. Monga,
S. Moore, D. G. Murray, B. Steiner, P. Tucker, V. Vasudevan, P. Warden,
M. Wicke, Y. Yu, and X. Zheng, “Tensorﬂow: A system for large-scale
machine learning,” in 12th USENIX Symposium on Operating Systems
Design and Implementation (OSDI 16).
Savannah, GA: USENIX
Association, 2016, pp. 265–283. [Online]. Available: https://www.
usenix.org/conference/osdi16/technical-sessions/presentation/abadi
[19] J. H. Jensen, E. Folven, and G. Tufte, “Computation in artiﬁcial
spin
ice,”
The
2018
Conference
on
Artiﬁcial
Life:
A
Hybrid
of the European Conference on Artiﬁcial Life (ECAL) and the
International Conference on the Synthesis and Simulation of Living
Systems (ALIFE), no. 30, pp. 15–22, 2018. [Online]. Available:
https://www.mitpressjournals.org/doi/abs/10.1162/isal a 00011
[20] SOCRATES
Self-Organizing Computational substRATES. [Online].
Available: https://www.ntnu.edu/socrates
[21] “Conway’s game of life implemented using tensorﬂow 2d convolution
function,” 2016. [Online]. Available: https://github.com/conceptacid/
conv2d life
[22] TensorFlow, “tf.sparse.sparse dense matmul — tensorﬂow core r1.14
— tensorﬂow.” [Online]. Available: https://www.tensorﬂow.org/api
docs/python/tf/sparse/sparse dense matmul
[23] T. Toffoli and N. Margolus, Cellular automata machines: a new envi-
ronment for modeling.
MIT press, 1987.
",missing,doc11,"—Dynamical systems are capable of performing com-
putation in a reservoir computing paradigm. This paper presents
a general representation of these systems as an artiﬁcial neural
network (ANN). Initially, we implement the simplest dynamical
system, a cellular automaton. The mathematical fundamentals be-
hind an ANN are maintained, but the weights of the connections
and the activation function are adjusted to work as an update
rule in the context of cellular automata. The advantages of such
implementation are its usage on specialized and optimized deep
learning libraries, the capabilities to generalize it to other types of
networks and the possibility to evolve cellular automata and other
dynamical systems in terms of connectivity, update and learning
rules. Our implementation of cellular automata constitutes an
initial step towards a general framework for dynamical systems.
It aims to evolve such systems to optimize their usage in reservoir
computing and to model physical computing substrates.
I.","A general representation of dynamical systems for reservoir computing Sidney Pontes-Filho∗,†,§, Anis Yazidi∗, Jianhua Zhang∗, Hugo Hammer∗, Gustavo B. M. Mello∗, Ioanna Sandvig‡, Gunnar Tufte† and Stefano Nichele∗ ∗Department of Computer Science, Oslo Metropolitan University, Oslo, Norway †Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway ‡Department of Neuromedicine and Movement Science, Norwegian University of Science and Technology, Trondheim, Norway Email: §sidneyp@oslomet.no Abstract INTRODUCTION A cellular automaton (CA) is the simplest computing sys- tem where the emergence of complex dynamics from local interactions might take place. It consists of a grid of cells with a ﬁnite number of states that change according to simple rules depending on the neighborhood and own state in discrete time-steps. Some notable examples are the elementary CA [1], which is unidimensional with three neighbors and eight update rules, and Conway’s Game of Life [2], which is two- dimensional with nine neighbors and three update rules. Table I presents some computing systems that are capable of giving rise to the emergence of complex dynamics. Those systems can be exploited by reservoir computing which is a paradigm that resorts to dynamical systems to simplify com- plex data. Hence, simpler and faster machine learning methods can be applied with such simpliﬁed data. Reservoir computing is more energy efﬁcient than deep learning methods and it can even yield competitive results, especially for temporal data [3]. In short, reservoir computing exploits a dynamical system that possesses the echo state property and fading memory, where the internals of the reservoir are untrained and the only training happens at the linear readout stage [4]. Reservoir computers are most useful when the substrate’s dynamics are at the “edge of chaos”, meaning a range of dynamical behaviors that is between order and disorder [5]. Cellular automata with such dynamical behavior are capable of being exploited as TABLE I EXAMPLES OF DYNAMICAL SYSTEMS. Dynamical system State Time Connectivity Cellular automata Discrete Discrete Regular Coupled map lattice Continuous Discrete Regular Random Boolean network Discrete Discrete Random Echo state network Continuous Discrete Random Liquid state machine Discrete Continuous Random reservoirs [6], [7]. Other systems can also exhibit the same dynamics. The coupled map lattice [8] is very similar to CA, the only exception is that the coupled map lattice has continuous states which are updated by a recurrence equation involving the neighborhood. Random Boolean network [9] is a generalization of CA where random connectivity exists. Echo state network [10] is an artiﬁcial neural network (ANN) with random topology while liquid state machine [11] is similar to echo state network with the difference that it is a spiking neural network that communicates through discrete-events (spikes) over continuous time. One important aspect of the computation performed in a dynamical system is the trajectory of system’s states traversed during the computation [12]. Such trajectory may be guided by system parameters [13]. Computation in dynamical systems may be carried out in physical substrates [14], such as networks of biological neurons [15] or in other nanoscale materials [16]. Finding the correct abstraction for the computation in a dynamical system, e.g. CA, is an open problem [17]. All the systems described in Table I are sparsely connected and can be represented by an adjacency matrix, such as a graph. A fully connected feedforward ANN represents its connectivity from a layer to another with an adjacency matrix that contains the weights of each connection. Our CA implementation is similar to this, but the connectivity is from the ”layer” of cells to itself. The goal of representing CA with an adjacency matrix is to implement a framework which facilitates the development of all types of CAs, from unidimensional to multidimensional, with all kinds of lattices and without any boundary checks during execution; and also the inclusion of the major dynam- ical systems, independent of the type of the state, time and arXiv:1907.01856v1 [cs.NE] 3 Jul 2019 connectivity. Such initial implementation is the ﬁrst part of a Python framework under development, based on TensorFlow deep neural network library [18]. Therefore, it beneﬁts from powerful and parallel computing systems with multi-CPU and multi-GPU. This framework, called EvoDynamic1, aims at evolving the connectivity, update and learning rules of sparsely connected networks to improve their usage for reservoir com- puting guided by the echo state property, fading memory, state trajectory and other quality measurements, and to model the dynamics and behavior of physical reservoirs, such as in- vitro biological neural networks interfaced with microelectrode arrays and nanomagnetic ensembles. Those two substrates have real applicability as reservoirs. For example, the former substrate is applied to control a robot, in fact making it into a cyborg, a closed-loop biological-artiﬁcial neuro-system [15], and the latter possesses computation capability as shown by a square lattice of nanomagnets [19]. Those substrates are the main interest of the SOCRATES project [20] which aims to explore a dynamic, robust and energy efﬁcient hardware for data analysis. There are some implementations of CA similar to the one of EvoDynamic framework. They normally implement Conway’s Game of Life by applying 2D convolution with a kernel that is used to count the neighbors, then the resulting matrix consists of the number of neighboring cells and is used to update the CA. One such implementation, also based on TensorFlow, is available open-source in [21]. This paper is organized as follows. Section II describes our method according to which we use adjacency matrix to compute CA. Section III presents the results obtained from the method. Section IV discusses the future plan of EvoDynamic framework and Section V concludes this paper. II. METHOD In our proposed method, the equation to calculate the next states of the cells in a cellular automaton is cat+1 = f(A · cat). It is similar to the equation of the forward pass of an artiﬁcial neural network, but without the bias. The layer is connected to itself, and the activation function f deﬁnes the update rules of the CA. The next states of the CA cat+1 is calculated from the result of the activation function f which receives as argument the dot product between the adjacency matrix A and the current states of the CA cat. ca is always a column vector of size len(ca) × 1, that does not depend on how many dimensions the CA has, and A is a matrix of size len(ca)×len(ca). Hence the result of A·ca is also a column vector of size len(ca) × 1 as ca. The implementation of cellular automata as an artiﬁcial neu- ral network requires the procedural generation of the adjacency matrix of the grid. In this way, any lattice type or multidi- mensional CAs can be implemented using the same approach. 1EvoDynamic v0.1 available at EvoDynamic. The adjacency matrix of a sparsely connected network contains many zeros because of the small number of connections. Since we implement it on TensorFlow, the data type of the adjacency matrix is preferably a SparseTensor. A dot product with this data type can be up to 9 times faster depending on the conﬁguration of the tensors [22]. The update rule of the CA alters the weights of the connections in the adjacency matrix. In a CA whose cells have two states meaning “dead” (zero) or “alive” (one), the weights in the adjacency matrix are one for connection and zero for no connection, such as an ordinary adjacency matrix. Such matrix facilitates the description of the update rule for counting the number of “alive” neighbors because the result of the dot product between the adjacency matrix and the cell state vector is the vector that contains the number of “alive” neighbors for each cell. If the pattern of the neighborhood matters in the update rule, each cell has its neighbors encoded as a n-ary string where n means the number of states that a cell can have. In this case the weights of the connections with the neighbors are n-base identiﬁers and are calculated by neighbori = ni, ∀i ∈{0..len(neighbors) −1}. Where neighbors is a vector of the cell’s neighbors. In the adjacency matrix, each neighbor receives a weight according to . The result of the dot product with such adjacency matrix is a vector that consists of unique integers per neighborhood pattern. Thus, the activation function is a lookup table from integer (i.e., pattern) to next state. Algorithm 1 generates the adjacency matrix for one- dimensional CA, such as the elementary CA. Where widthCA is the width or number of cells of a unidimensional CA and neighborhood is a vector which describes the region around the center cell. The connection weights depend on the type of update rule as previously explained. For ex- ample, in case of an elementary CA neighborhood = [4 2 1]. indexNeighborCenter is the index of the center cell in the neighborhood whose starting index is zero. isWrappedGrid is a Boolean value that works as a ﬂag for adding wrapped grid or not. A wrapped grid for one- dimensional CA means that the initial and ﬁnal cells are neighbors. With all these parameters, Algorithm 1 creates an adjacency matrix by looping over the indices of the cells (from zero to numberOfCells −1) with an inner loop for the indices of the neighbors. If the selected currentNeighbor is a non-zero value and its indices do not affect the boundary condition, then the value of currentNeighbor is assigned to the adjacency matrix A in the indices that correspond to the connection between the current cell in the outer loop and the actual index of currentNeighbor. Finally, this procedure returns the adjacency matrix A. To procedurally generate an adjacency matrix for 2D CA instead of 1D CA, the algorithm needs to have small adjust- ments. Algorithm 2 shows that for two-dimensional CA, such as Conway’s Game of Life. In this case, the height of the CA is an argument passed as heightCA. Neighborhood Algorithm 1 Generation of adjacency matrix for 1D cellular automaton 1: procedure GENERATECA1D(widthCA, neighborhood, indexNeighborCenter, isWrappedGrid) 2: numberOfCells ←widthCA 3: A ←0numberOfCells×numberOfCells ▷Adjacency matrix initialization 4: for i ←{0..numberOfCells −1} do 5: for j ←{−indexNeighborCenter..len(neighborhood) −indexNeighborCenter −1} do 6: currentNeighbor ←neighborhoodj+indexNeighborCenter 7: if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧(0 ≤(i + j) < widthCA)) then 8: Ai,((i+j) mod widthCA) ←currentNeighbor 9: return A is a 2D matrix and indexNeighborCenter is a vector of two components meaning the indices of the center of Neighborhood. This procedure is similar to the one in Algorithm 1, but it contains one more loop for the additional dimension. The activation function for CA is different from the ones used for ANN. For CA, it contains the update rules that verify the vector returned by the dot product between the adjacency matrix and the vector of states. Normally, the update rules of the CA are implemented as a lookup table from neighborhood to next state. In our implementation, the lookup table maps the resulting vector of the dot product to the next state of the central cell. III. RESULTS This section presents the results of the proposed method and it also stands for the preliminary results of the EvoDynamic framework. Fig. 1 illustrates a wrapped elementary CA described in the procedure of Algorithm 1 and its generated adjacency matrix. Fig. 1a shows the appearance of the desired elementary CA with 16 cells (i.e., widthCA = 16). Fig. 1b describes its pattern 3-neighborhood and the indices of the cells. Fig 1c shows the result of the Algorithm 1 with the neighborhood calculated by for pattern matching in the activation func- tion. In Fig. 1c, we can verify that the left neighbor has weight equals to 4 (or 22 for the most signiﬁcant bit), central cell weight is 2 (or 21) and right neighbor weight is 1 (or 20 for the least signiﬁcant bit) as deﬁned by . Since the CA is wrapped, we can notice in row index 0 of the adjacency matrix in Fig. 1c that the left neighbor of cell 0 is the cell 15, and in row index 15 that the right neighbor of cell 15 is the cell 0. Fig. 2 describes a wrapped 2D CA for Algorithm 2 and shows the resulting adjacency matrix. Fig. 2a illustrates the desired two-dimensional CA with 16 cells (i.e., widthCA = 4 and heightCA = 4). Fig. 2b presents the von Neumann neighborhood [23] which is used for counting the number of ”alive” neighbors (the connection weights are only zero and one, and Neighborhood argument of Algorithm 2 deﬁnes it). It also shows the index distribution of the CA whose order is preserved after ﬂatting it to a column vector. Fig 2c contains the generated adjacency matrix of Algorithm 2 for the described 2D CA. Fig. 2b shows an example of a central (a) (b) (c) Fig. 1. Elementary cellular automaton with 16 cells and wrapped grid. (a) Example of the grid of cells with states. (b) Indices of the cells and standard pattern neighborhood of elementary CA where thick border means the central cell and thin border means the neighbors. (c) Generated adjacency matrix for this elementary CA. cell with its neighbors, the index of this central cell is 5 and the row index 5 in the adjacency matrix of Fig. 2c presents the same neighbor indices, i.e., 1, 4, 6 and 9. Since this is a symmetric matrix, the columns have the same connectivity of the rows. Therefore, this adjacency matrix represents an undirected graph. The wrapping effect is also observable. For example, the neighbors of the cell index 0 are 1, 3, 4 and 12. So the neighbors 3 and 12 are the ones that the wrapped grid allowed to exist for cell index 0. IV. EVODYNAMIC FUTURE The method of implementing a CA as an artiﬁcial neural network will be beneﬁcial for the future of EvoDynamic framework. Since the implementation of all sparsely connected networks in Table I are already planned in future releases Algorithm 2 Generation of adjacency matrix of 2D cellular automaton 1: procedure GENERATECA2D(widthCA, heightCA, Neighborhood, indexNeighborCenter, isWrappedGrid) 2: numberOfCells ←widthCA ∗heightCA 3: A ←0numberOfCells×numberOfCells ▷Adjacency matrix initialization 4: widthNB, heightNB ←shape(Neighborhood) 5: for i ←{0..numberOfCells −1} do 6: for j ←{−indexNeighborCenter0..widthNB −indexNeighborCenter0 −1} do 7: for k ←{−indexNeighborCenter1..heightNB −indexNeighborCenter1 −1} do 8: currentNeighbor ←Neighborhoodj+indexNeighborCenter 9: if currentNeighbor ̸= 0 ∧(isWrappedGrid ∨(¬isWrappedGrid ∧(0 ≤((i mod heightCA) + j) < widthCA) ∧(0 ≤(⌊i/widthCA⌋+ k) < heightCA)) then 10: Ai,(((i+k) mod widthCA)+((⌊i/widthCA⌋+j) mod heightCA)∗widthCA) ←currentNeighbor 11: return A (a) (b) (c) Fig. 2. 2D cellular automaton with 16 cells (4 × 4) and wrapped grid. (a) Example of the grid of cells with states. (b) Indices of the cells and von Neumann counting neighborhood of 2D CA where thick border means the current cell and thin border means the neighbors. (c) Generated adjacency matrix for this 2D CA. of the Python framework, EvoDynamic must have a general representation to all of them. Therefore we are treating CA as an ANN. Moreover, EvoDynamic framework will evolve the connectivity, update and learning rules of the dynamical systems for reservoir computing improvement and physical substrate modeling. This common representation facilitates the evolution of such systems and models which will be guided by several methods that measure the quality of a reservoir or the similarity to a dataset. One example of these methods is the state trajectory. For visualization, we use principal component analysis (PCA) to reduce the dimensionality of the states and present them as a state transition diagram as shown in Fig. 3. V. CONCLUSION In this paper, we present an alternative method to implement a cellular automaton. This allows any CA to be computed as an artiﬁcial neural network. Therefore, this will help to extend the CA implementation to more complex dynamical systems, such as echo state networks and liquid state machines. Furthermore, the EvoDynamic framework is built on a deep learning library, TensorFlow, which permits the acceleration of the execution when applied on parallel computational platforms with fast CPUs and GPUs. The future work for this CA implementation is to develop algorithms to procedurally generate adjacency matrices for 3D and multidimensional cellular automata with different types of cells, such as the cells with hexagonal shape. ACKNOWLEDGMENTS This work was supported by Norwegian Research Council SOCRATES project (grant number 270961). REFERENCES [1] S. Wolfram, A new kind of science. Wolfram media Champaign, IL, 2002, vol. 5. [2] P. Rendell, Turing Universality of the Game of Life. London: Springer London, 2002, pp. 513–539. [Online]. Available: https: //doi.org/10.1007/978-1-4471-0129-1 18 [3] B. Schrauwen, D. Verstraeten, and J. Van Campenhout, “An overview of reservoir computing: theory, applications and implementations,” in Proceedings of the 15th European Symposium on Artiﬁcial Neural Networks. p. 471-482 2007, 2007, pp. 471–482. [4] Z. Konkoli, S. Nichele, M. Dale, and S. Stepney, Reservoir Computing with Computational Matter. Cham: Springer International Publishing, 2018, pp. 269–293. [Online]. Available: 1007/978-3-319-65826-1 14 [5] C. G. Langton, “Computation at the edge of chaos: Phase transitions and emergent computation,” Physica D: Nonlinear Phenomena, vol. 42, no. 1, pp. 12 – 37, 1990. [Online]. Available: http: // [6] S. Nichele and M. S. Gundersen, “Reservoir computing using nonuniform binary cellular automata,” Complex Systems, vol. 26, no. 3, pp. 225–245, Sep. 2017. [Online]. Available: complexsystems.26.3.225 [7] S. Nichele and A. Molund, “Deep learning with cellular automaton- based reservoir computing,” Complex Systems, vol. 26, no. 4, pp. 319–339, Dec. 2017. [Online]. Available: complexsystems.26.4.319 [8] K. Kaneko, “Overview of coupled map lattices,” Chaos: An Interdisci- plinary Journal of Nonlinear Science, vol. 2, no. 3, pp. 279–282, 1992. (a) Step 1 (b) Step 2 (c) Step 3 (d) Step 4 (e) Step 11 (f) Step 12 (g) Step 13 (h) Step 14 (i) Step 26 (j) Step 27 (k) Step 28 (l) Step 29 Fig. 3. States of Conway’s Game of Life in a 7x7 wrapped lattice alongside their PCA-transformed state transition diagrams of the two ﬁrst principal components. (a) Initial state is a glider. (a)-(d) Four ﬁrst steps in this CA. (e)-(h) Four intermediate steps in this CA while reaching the wrapped border. (i)-(l) Four last steps in this CA before repeating the initial state and closing a cycle. [9] C. Gershenson, “Introduction to random boolean networks,” arXiv preprint nlin/0408006, 2004. [10] H. Jaeger and H. Haas, “Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication,” Science, vol. 304, no. 5667, pp. 78–80, 2004. [Online]. Available: https: //science.sciencemag.org/content/304/5667/78 [11] W. Maass and H. Markram, “On the computational power of circuits of spiking neurons,” Journal of Computer and System Sciences, vol. 69, no. 4, pp. 593 – 616, 2004. [Online]. Available: [12] S. Nichele and G. Tufte, “Trajectories and attractors as speciﬁcation for the evolution of behaviour in cellular automata,” in IEEE Congress on Evolutionary Computation, July 2010, pp. 1–8. [13] S. Nichele and G. Tufte, “Genome parameters as information to forecast emergent developmental behaviors,” in Unconventional Computation and Natural Computation, J. Durand-Lose and N. Jonoska, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2012, pp. 186–197. [14] G. Tanaka, T. Yamane, J. B. Hroux, R. Nakane, N. Kanazawa, S. Takeda, H. Numata, D. Nakano, and A. Hirose, “Recent advances in physical reservoir computing: A review,” Neural Networks, vol. 115, pp. 100 – 123, 2019. [Online]. Available: [15] P. Aaser, M. Knudsen, O. H. Ramstad, R. van de Wijdeven, S. Nichele, I. Sandvig, G. Tufte, U. Stefan Bauer, . Halaas, S. Hendseth, A. Sandvig, and V. Valderhaug, “Towards making a cyborg: A closed-loop reservoir-neuro system,” The 2018 Conference on Artiﬁcial Life: A Hybrid of the European Conference on Artiﬁcial Life (ECAL) and the International Conference on the Synthesis and Simulation of Living Systems (ALIFE), no. 29, pp. 430–437, 2017. [Online]. Available: a 072 [16] H. Broersma, J. F. Miller, and S. Nichele, Computational Matter: Evolving Computational Functions in Nanoscale Materials. Cham: Springer International Publishing, 2017, pp. 397–428. [Online]. Available: 16 [17] S. Nichele, S. S. Farstad, and G. Tufte, “Universality of evolved cellular automata in-materio.” International Journal of Unconventional Computing, vol. 13, no. 1, 2017. [18] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat, G. Irving, M. Isard, M. Kudlur, J. Levenberg, R. Monga, S. Moore, D. G. Murray, B. Steiner, P. Tucker, V. Vasudevan, P. Warden, M. Wicke, Y. Yu, and X. Zheng, “Tensorﬂow: A system for large-scale machine learning,” in 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16). Savannah, GA: USENIX Association, 2016, pp. 265–283. [Online]. Available: usenix.org/conference/osdi16/technical-sessions/presentation/abadi [19] J. H. Jensen, E. Folven, and G. Tufte, “Computation in artiﬁcial spin ice,” The 2018 Conference on Artiﬁcial Life: A Hybrid of the European Conference on Artiﬁcial Life (ECAL) and the International Conference on the Synthesis and Simulation of Living Systems (ALIFE), no. 30, pp. 15–22, 2018. [Online]. Available: a 00011 [20] SOCRATES Self-Organizing Computational substRATES. [Online]. Available: [21] “Conway’s game of life implemented using tensorﬂow 2d convolution function,” 2016. [Online]. Available: conv2d life [22] TensorFlow, “tf.sparse.sparse dense matmul — tensorﬂow core r1.14 — tensorﬂow.” [Online]. Available: docs/python/tf/sparse/sparse dense matmul [23] T. Toffoli and N. Margolus, Cellular automata machines: a new envi- ronment for modeling. MIT press, 1987.","—Dynamical systems are capable of performing com- putation in a reservoir computing paradigm. This paper presents a general representation of these systems as an artiﬁcial neural network (ANN). Initially, we implement the simplest dynamical system, a cellular automaton. The mathematical fundamentals be- hind an ANN are maintained, but the weights of the connections and the activation function are adjusted to work as an update rule in the context of cellular automata. The advantages of such implementation are its usage on specialized and optimized deep learning libraries, the capabilities to generalize it to other types of networks and the possibility to evolve cellular automata and other dynamical systems in terms of connectivity, update and learning rules. Our implementation of cellular automata constitutes an initial step towards a general framework for dynamical systems. It aims to evolve such systems to optimize their usage in reservoir computing and to model physical computing substrates. I.","['Sidney Pontes-Filho', 'Anis Yazidi', 'Jianhua Zhang', 'Hugo Hammer', 'Gustavo Mello', 'Ioanna Sandvig', 'Gunnar Tufte', 'Stefano Nichele']"
Exploring Multilingual Word Embedding Alignments in BERT Models: A Case Study of English and Norwegian,"Aaby, Pernille
and Biermann, Daniel
and Yazidi, Anis
and Mello, Gustavo Borges Moreno e.
and Palumbo, Fabrizio",2023,missing,missing,missing,inproceedings," 
 
 
 
Accepted manuscript 
Aaby, P., Biermann, D., Yazidi, A., Borges Moreno e Mello, G. & Palumbo, F. (2023). Exploring 
Multilingual Word Embedding Alignments in BERT Models: A Case Study of English and 
Norwegian. Lecture Notes in Computer Science (LNCS), 14381, 47-58. 
https://doi.org/10.1007/978-3-031-47994-6_4 
 
 
Published in: 
Lecture Notes in Computer Science (LNCS) 
 
DOI:   
 
https://doi.org/10.1007/978-3-031-47994-6_4 
 
AURA:  
 
https://hdl.handle.net/11250/3122000 
 
Copyright:  
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2023 
 
Available: 
 
08. Nov. 2024 
 Exploring Multilingual Word Embedding Alignments in
BERT Models: A Case Study of English and Norwegian
Pernille Aaby1, Daniel Biermann2, Anis Yazidi1, Gustavo Borges Moreno e Mello1,
and Fabrizio Palumbo1
1 Artificial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi,
Oslo Metropolitan University, Oslo, Norway
2 Centre for Artificial Intelligence Research (CAIR)
Department of ICT, University of Agder, Grimstad, Norway
fabrizio.palumbo@oslomet.no
Abstract
Keywords: Natural Language Processing · Multilingual Bert · Word Alignment
· Data Sparsity.
1
Introduction
Over recent years, the field of AI has made impressive progress regarding the perfor-
mance of natural language processing tasks such as text classification, question answer-
ing, machine translation, or language generation. This progress is mainly driven by
purely data-driven models such as transformers. To encode how words relate to their
context, transformers are pre-trained on vast, unlabeled and mostly monolingual train-
ing corpora. This approach is powerful for languages such as English or Spanish, with
an abundance of language resources consisting in raw text, labeled datasets, and bench-
marks. However, when it comes to low-resource languages, such as Norwegian, the
available language datasets are often limited. Unfortunately, the performance in such
data-driven models and approaches heavily depends on the quality and amount of train-
ing data available. That is, good performance depends on high-quality datasets. At the
This is a post-peer-review, pre-copyedit version of the following conference proceeding: Aaby, P., Biermann, D., Yazidi, A., Mello, G.B.M.e., Palumbo, F. (2023).
Exploring Multilingual Word Embedding Alignments in BERT Models: A Case Study of English and Norwegian. In: Bramer, M., Stahl, F. (eds) Artificial Intelligence XL. SGAI 2023.
Lecture Notes in Computer Science(), vol 14381. Springer, Cham. DOI: https://doi.org/10.1007/978-3-031-47994-6_4 
 written time, there are 2181 matches for English datasets and only 67 for Norwegian
datasets on huggingface.co3. More training data tend to improve the performance of
language models [17,3]. Consequently, monolingual Norwegian language models will
likely not achieve the same performance as monolingual English language models.
Most existing language models today have been trained on monolingual corpora
[7,14], which do not benefit languages with sparse data availability. Isbister et al.[11]
proposed an approach that translates the text from a low-resource language to a high-
resource language. Then, it uses a state-of-the-art performing model trained on high-
resource language to alleviate the data sparsity problem. However, recent work shows
that specific multilingual language models manage to align words from different lan-
guages without learning from parallel data, which machine translation requires [4,15].
Therefore, we pose the questions:
– Can multilingual models relieve the need for monolingual models?
– Can knowledge from one language be transferred to another without parallel data?
In this article, we explore the similarities and dissimilarities between the word represen-
tations in English and Norwegian, using two multilingual language models. To this end,
we use different methods from recent literature and combine them in a comprehensive
study of the case of the English-Norwegian language pair.
To find similarities we evaluate word retrieval performance, from an English source
vocabulary to a Norwegian target vocabulary. To find dissimilarities, we quantify the
accuracy of retrieving the original language from the word representation. All methods
are non-parametric and rely purely on vector proximity. The model architecture we have
used is BERT (Bidirectional Encoder from Transformer) [7] since previous work has
shown its capability to align words automatically [4,16].
We believe that this exploration can provide the research community with a better
understanding of how the information of different languages manifests inside the word
representations of multilingual models and ultimately help improve existing models and
applications that suffer from data sparsity.
2
Related Work
2.1
Multilingual Word Retrieval
Mikolov et al. [22] noticed that the distribution of word embeddings in latent space
showed similar characteristics across different languages. Motivated by the similarity
of distributions, they hypothesized that they could align two distributions with word
embeddings from two different languages to create a bilingual dictionary with word
retrieval. Their technique relied on bilingual parallel corpora. Conneau et al. [6] showed
that it was possible to align two-word embedding distributions from different languages
without any supervision (parallel corpora). They utilized adversarial training to learn a
linear mapping from the source to the target language, alleviating the need for parallel
corpora.
3 !https://huggingface.co/datasets Visited: 19.01.2023
2
 2.2
Multilingual BERT
BERT is a transformer-based [30] model which improved state-of-the-art results on sev-
eral NLP tasks at the time of release [7]. It improved on question-answering tasks like
SQuAD v1.1 [25] and SQuAD v2.0 [24], and language understanding tasks like GLUE
[31] and MutliNLI [33]. The model is trained on vast amounts of text corpora, the orig-
inal English BERT used the English part of Wikipedia [7], but today it is being trained
on bigger collections, even book collections from a whole library [13]. The model has
been trained for several languages like French, Swedish, and Norwegian [20,19,14].
BERT can also be trained in several languages simultaneously to obtain multilingual
understanding. mBERT is one of these models, and it is trained on Wikipedia corpus
for 104 different languages, including English and Norwegian4.
Notram, Norwegian Transformer Model, is a BERT model initialized from mBERT
and further trained on mostly Norwegian book-corpus data [13]. Although the model
is mainly trained on Norwegian corpus, after initialization, the authors estimate that a
portion of 4% is English. The model scores high on Named Entity Recognition both for
the Norwegian language and the English language.
Previous work [4,15] also shows that the semantics of two (and more) languages
align automatically in BERT. So the model does not only represent two languages sep-
arately, but it is also able to encode connections between two languages through shared
semantics of the words, without being trained on parallel data.
2.3
From Contextual to Static Embeddings
In order to benefit from previous benchmarks like SimLex999 [10], WordSim353 [1]
and SimVerb3500 [9] that evaluate semantics, Bommasani et al. [2] distilled a set of
static word embeddings from contextual word embeddings. This way the results could
be compared to traditional word embeddings [21,23,12]. To create the static word em-
beddings from BERT they tried different aggregation and pooling strategies. The best-
performing aggregation method was to take the average over several contexts, also re-
ferred to as AOC (Average Over Context). They also used mean pooling, taking the
mean of all token representations over subtokens of a word in case a word consists of
more than one token.
2.4
Probing BERT
Probing BERT has become a popular area of research to better justify its success and
understand the model better so it is easier to improve the architecture [27]. It entails
creating a simple classifier and using the features from the pre-trained model. If the
simple classifier manages to solve the task, then we can assume that the necessary
information is already within the features we extract.
From previous work, we know that BERT represents words with information about
syntax and semantics [27]. Tenney et al. [28] discovered that BERT hierarchically learns
information that corresponds to the traditional NLP (Natural Language Processing)
4 !https://huggingface.co/bert-base-multilingual-cased
3
 pipeline. Starting with local syntax structure such as POS tagging and parsing in the
lower layers, while finding named entity recognition, semantic roles, and co-reference
are information encoded later in the model in the respective order. Similar discoveries
can be found in other works as well [16,29].
Naturally, since BERT is a contextual model representing a word based on not only
itself but also the surrounding words, the question of whether one could distinguish
different meanings of an ambiguous through the representation arose. In previous work
[32,18] they find that ambiguous words divide different meanings into clusters from the
contextual representation, although it is not always the same clusters as we would have
defined from a human perspective.
3
Methods
Our analysis examines similarities and differences between word representations in two
languages. Similarities are found through static word retrieval and differences through
language detection. Our non-parametric method only relies on finding the most similar
embedding(s) from a source word to a target collection. We used KNN (K- Nearest
Neighbours) with cosine similarity to find the most similar vectors.
3.1
Static Word Retrieval
Following the work by Bommasani et al. [2] we created a static set of word embeddings
by taking the AOC of several contextual embeddings for a term t. The contextual em-
bedding for word t is obtained from a context ct ∈Ct, where each ct is two sentences
from the relevant language corpus.
st = 1
Nt
N
X
n=1
wtn
(1)
wtn is the nth contextual embedding for the number of contexts Nt = |Ct|. For words
that consist of more than one workpiece, we used mean pooling, taking the mean of all
subtokens, to aggregate all token embeddings.
wtn = 1
It
I
X
i=1
pti
(2)
pti is the ith token in the word. We created static embeddings for all 13 intermediate
representations from BERT, one after all the 12 stacked layers and the input layer. We
aimed to retrieve a Norwegian target word from an English source word. The objective
becomes, for each of the English word representations si−en, evaluate the cosine simi-
larity to all the Norwegian word representations sj−no, rank the similarities, and return
the top(@) match(s). If a translation of the English word is one of the returned words,
we achieved a correct word retrieval.
k-neighbours(i) = argmax
j
sim(si−en, sj−no)
(3)
4
 yi =
(
1,
if k-neighbours(i) ∈translation(sno)
0,
otherwise
(4)
accuracy static word retrieval = 1
T
T
X
i=1
yi
(5)
T is the number of terms in the English vocabulary.
Liu et al. [15] test if word retrieval performance increases by doing a mean shift.
Mean shift entails shifting from an English source word to be closer to a Norwegian
target word by first subtracting the mean of all the English word embeddings and then
adding the mean of all the Norwegian word embeddings. We define a language vector
as the mean of all the static word embeddings in one vocabulary.
Ll = 1
T
T
X
t=1
wt
(6)
l ∈{English, Norwegian} and T is the number of words in each vocabulary. Mean
shift:
st,en−>no = st,en −Len + Lno
(7)
Len and Lno are language vectors for English and Norwegian respectively.
yi−l =





1,
if
sim(si−l, Len) > sim(si−l, Lno)
and
l = en
1,
elif
sim(si−l, Len) < sim(si−l, Lno)
and
l = no
0,
otherwise
(8)
accuracy language detection = 1
2T
T
X
i=1
yi−en + 1
2T
T
X
i=1
yi−no
(9)
3.2
Language Detection
Motivated by the fact that words from the same language could be aggregated to a lan-
guage vector, we asked the question:
Can we detect the language of a word based on the similarity to the language embed-
dings?
We detected the language by evaluating which language vector a word representation is
most similar to.
3.3
Data
The Norwegian News Corpus5 is used as the raw text corpora for the Norwegian part.
We only used the part in Norwegian bokmÃˇel (not nynorsk). The articles in the dataset
5 !https://www.nb.no/sprakbanken/ressurskatalog/oai-nb-no-sbr-4/
5
 are from multiple different newspapers, such as “VG”, “Aftenposten” and “Dagens
nÃ˛eringsliv” etc., collected from the years 1998 to 2019. We chose a set of contexts
from the corpus for each word in our Norwegian vocabulary between 100 and 500. A
context is defined as two sentences.
The vocabulary is restricted to only include the 50,000 most common words from
the Norwegian News Corpus. In addition, we checked that the word is present in a
Norwegian wordlist for BokmÃˇel 6.
To evaluate the word retrieval from English to Norwegian, we have used the English-
Norwegian word benchmark from MUSE 7 [6]. We only used the word pairs, where the
Norwegian word is in our top 50,000 vocabularies, and the English word is present
in the Brown corpus 8 [8]. Some English words have more than one Norwegian word
translation. We define a correct word retrieval as at least one match.
The Brown corpus gives the context sentences for the English word embedding vo-
cabulary. The number of contexts for a word is the number of times a word stands in the
Brown corpus but a maximum of 500 times. We only obtained static word embeddings
for the words in the MUSE benchmark. The MUSE-filtered vocabulary ended up with
approximately 12,000 English source words.
4
Results
4.1
Static Word Retrieval
In Figure 1 we report the results of the English to Norwegian word retrieval using
KNN and cosine similarity. We compare the performance of both mBERT (Figure 1a)
and Notram (Figure 1c) for different numbers of top matches (@1,@3,@10). Notram
achieved better accuracy than mBERT in general. The middle layers seem to perform
best for both models, with Notram achieving around 50% at @1 match and more than
70% accuracy when using the @10 matches at layer 7. In addition, for the Notram
model. we notice a dip in performance for layer 11. Overall, we argue that BERT models
are capable of aligning semantics across English and Norwegian without using any
supervised datasets with parallel sentences.
4.2
Static Word Retrieval with Mean Shift
Figure 1b and Figure 1d show the static word retrieval performances when adjusted
with the mean shift. To illustrate the impact of the mean shift on the word retrieval per-
formance better, the performance increase between the shifted and non-shifted model
is depicted by the dashed lines. We can see that the overall influence of the mean shift
on performance is relatively low across all layers. When mean shifting, the model re-
tains word retrieval accuracy better from the middle layers to the subsequent layers than
without the mean shift. The maximum word retrieval performance increase is reached
in layer 11 for the Notram model, improving by 8% for K at @1, @3, and @10. Thus,
6 !https://www.nb.no/sprakbanken/en/resource-catalogue/oai-nb-no-sbr-23/
7 !https://github.com/facebookresearch/MUSE
8 !https://www.nltk.org/nltk_data/
6
 (a) mBERT
(b) mBERT, shifted
//
(c) Notram
(d) Notram, shifted
Fig. 1: Static word retrieval performance from English to Norwegian with layer-wise
performance accuracy with and without mean shift. The lower dashed lines depict the
performance increase when using the mean shift. The star marker shows at which layer
the performance peaked. Both models experience the highest performance increase in
layer 11 for all chosen @matches.
the mean shift seems to alleviate the cause of the performance dip seen before in later
layers.
4.3
Language Detection
Figure 2 reports the results from the language detection experiment. The non-parametric
method clearly shows that it is possible to find the language of a word using this method
as the performance reaches almost 100% in the top-performing layer. The language
detection accuracy reaches values above 95% for both models as soon as layer 1. This
strongly indicates that the closest language vector can serve as a strong predictor for the
language of the embedding.
4.4
Both Semantics and Language Properties can Cluster
For a more qualitative inspection of the word representations, Figure 3 illustrates both
semantic alignment and language properties between English and Norwegian. The top
7
 (a) mBERT: Language Belonging.
(b) Notram
Fig. 2: Layer wise language detection performance. The lighter line (circle) describes
the prediction accuracy for the English vocabulary, the darkest line (square) describes
the prediction accuracy for the Norwegian language and the line of intermediate shade
(triangle) describes the combined prediction accuracy of language detection. The stars
mark in which layer the performance peaks.
graph Figure 3a, inspired by previous work on semantic alignment in BERT [4], shows a
plot comparing a set of 5 words in each English and Norwegian, respectively. The words
were taken from the parallel corpus with sentences from riksrevisjonen9[26]. We can
observe that all word pairs are clustering together, indicating the semantic alignment of
the word embeddings between the languages.
In the bottom graph Figure 3b we see two sets of 500 static word embeddings from
each language. We can notice a clear clustering of the two languages. In both graphs,
we reduce the embedding dimension to two dimensions with the t-SNE method. This
further solidifies that BERT models are able to align semantics across English and Nor-
wegian without using any supervised data
5
Discussion
Our analysis shows that layers 5-9 (middle layers) have the highest accuracy on static
word retrieval. This result is in line with previous work on semantic similarity [5].
We argue that the best-performing layers in semantic similarity will also be the best-
performing layers in semantic alignment between two languages. Although we observe
a clear separation between languages in the word representation space, the mean shift
method did not significantly impact the word retrieval accuracy. In layer 11, the accu-
racy does increase by around 8% in the Notram model. However, in the best performing
layer of the same model, layer 7 (or 5), the increase is only around 1%. We consider
this a slight change since the accuracy at @1 is around 50%. Overall, the word retrieval
9 !https://www.elrc-share.eu/repository/browse/bilingual-english-norwegian-parallel-corpus-f
rom-the-office-of-the-auditor-general-riksrevisjonen-website/a5d2470201e311e9b7d400155
d0267060fffdc9258a741659ce9e52ef15a7c26/
8
 (a) Visualizing contextual word embeddings for word pairs in English and
Norwegian. Contextual embeddings taken from layer 8 of the Notram model
and the English contextual embeddings have experienced a mean shift. The
word embeddings are reduced to 2D with t-SNE. The darker colored markers
show contextual word embeddings for Norwegian while the lighter color show
contextual embedding for English. Each word pair has its own marker.
(b) 500 random words from Norwegian and English vocabulary respectively.
The static word embeddings are from Notram layer 12. The word embeddings
are reduced to 2D with t-SNE. Lighter points correspond to English embed-
dings and darkest points correspond to Norwegian embeddings.
Fig. 3: Visualizing static and contextual word embeddings from BERT
9
 results suggest that the hypothesis that translating one language to another in the word
representation space by looking at the closest matched embedding of the other lan-
guage is a promising approach. Though, the low impact of the mean shift indicates that
the translation from one language to another is not as simple as shifting the embedding
by a simple mean language vector. This warrants further investigation into better meth-
ods to create language vector representations that might improve the impact of such a
language vector shift. Nevertheless, the language vectors from the mean shift analysis
remain strong predictors for identifying the language of an embedding as can be seen
by the strong performance results of our language detection analysis.
It is noteworthy that static word retrieval does not deal with ambiguous words. Both
language vocabularies most likely contain words with multiple meanings, leading to a
conflation of meaning in the embedding. Conflated meanings most likely affected word
retrieval since the English and Norwegian corpus do not provide the same contexts, and
a word representation can be conflated with different meanings depending on the text
corpus. In addition, words within each language can have different meanings. There-
fore, an ambiguous word can often be detected because it will translate to different
words in another language depending on the context. To deal with this downside, one
would have to include a more nuanced analysis of either sense or a word pair from the
same context. We believe that ambiguous words have a negative impact on accuracy
as we could observe significantly better results when considering @3 and @10 nearest
neighbours, with an increase of more than a 20% going from @1 to @10.
Norwegian is a language that borrows many words and phrases from English. It
can be single words like ""skateboard"" or whole phrases like movie titles. Even though
we filtered out sentences detected as English from the Norwegian text corpus, single
words and smaller phrases may have been hard to remove. The effect could be English
noise in the Norwegian part of the corpus and hence an effect in language detection.
mBERT outperforms Notram in the subsequent layers of the model in detecting the
correct language, and it achieves close to 100% accuracy. However, we question if the
accuracy is this high because there might exist English noise in the Norwegian corpus,
which would mean that the accuracy should not be 100%. A better evaluation dataset
could be used to inspect this effect further.
6
Conclusion
In this exploratory analysis, we have shown that BERT’s word representations automat-
ically align semantics across English and Norwegian. We showed this with an accuracy
of 50% for @1 nearest neighbor and an accuracy of more than 70 % for @10 nearest
neighbor on the word retrieval task. In addition, we found that language is encoded in
the word representation: We could detect the correct language of a word, with close to
100% accuracy, only by looking at its proximity to the two language vectors for English
and Norwegian, respectively. We demonstrate that the model can align semantics and
learn language properties by training on only raw text data (no parallel sentences).
We believe that the combination of automatic language detection and word re-
trieval between language embeddings allows for knowledge to be transferred between
languages, ultimately helping alleviate the data sparsity problem in low-resource lan-
10
 guages, such as Norwegian. While our results show promising tendencies, further in-
vestigations into reaching higher word retrieval accuracies and better aligning language
vectors are warranted to make this approach reliable. We hope that our findings moti-
vate new ways of using multilingual models and inspire more research in training and
investigating multilingual models for low-resource languages.
References
1. Agirre, E., Alfonseca, E., Hall, K., Kravalova, J., Pasca, M., Soroa, A.: A study on similarity
and relatedness using distributional and wordnet-based approaches (2009)
2. Bommasani, R., Davis, K., Cardie, C.: Interpreting Pretrained Contextualized Representa-
tions via Reductions to Static Embeddings. In: Proceedings of the 58th Annual Meeting of
the Association for Computational Linguistics. pp. 4758–4781 (2020)
3. Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A.,
Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan,
T., Child, R., Ramesh, A., Ziegler, D.M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E.,
Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever,
I., Amodei, D.: Language Models are Few-Shot Learners. arXiv preprint arXiv:2005.14165
(2020)
4. Cao, S., Kitaev, N., Klein, D.: Multilingual alignment of contextual word representations.
arXiv preprint arXiv:2002.03518 (2020)
5. Chronis, G., Erk, K.: When is a bishop not like a rook? When itâ ˘A´Zs like a rabbi! Multi-
prototype BERT embeddings for estimating semantic relationships. In: Proceedings of the
24th Conference on Computational Natural Language Learning. pp. 227–244 (2020)
6. Conneau, A., Lample, G., Ranzato, M., Denoyer, L., Jégou, H.: Word translation without
parallel data. arXiv preprint arXiv:1710.04087 (2017)
7. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of deep bidirectional
transformers for language understanding. NAACL HLT 2019 - 2019 Conference of the
North American Chapter of the Association for Computational Linguistics: Human Lan-
guage Technologies - Proceedings of the Conference 1(Mlm), 4171–4186 (2019)
8. Francis, W.N., Kucera, H.: Brown corpus manual. Letters to the Editor 5(2), 7 (1979)
9. Gerz, D., Vuli´c, I., Hill, F., Reichart, R., Korhonen, A.: Simverb-3500: A large-scale evalua-
tion set of verb similarity. arXiv preprint arXiv:1608.00869 (2016)
10. Hill, F., Reichart, R., Korhonen, A.: Simlex-999: Evaluating semantic models with (genuine)
similarity estimation. Computational Linguistics 41(4), 665–695 (2015)
11. Isbister, T., Carlsson, F., Sahlgren, M.: Should we Stop Training More Monolingual Models,
and Simply Use Machine Translation Instead? arXiv preprint arXiv:2104.10441 (2021)
12. Joulin, A., Grave, E., Bojanowski, P., Mikolov, T.: Bag of tricks for efficient text classifi-
cation. In: 15th Conference of the European Chapter of the Association for Computational
Linguistics, EACL 2017 - Proceedings of Conference. vol. 2 (2017). https://doi.org/10.186
53/v1/e17-2068
13. Kummervold, P.E., la Rosa, J., Wetjen, F., Brygfjeld, S.A.: Operationalizing a national dig-
ital library: The case for a norwegian transformer model. arXiv preprint arXiv:2104.09617
(2021)
14. Kutuzov, A., Barnes, J., Velldal, E., Øvrelid, L., Oepen, S.: Large-scale contextualised lan-
guage modelling for norwegian. arXiv preprint arXiv:2104.06546 (2021)
15. Liu, C.L., Hsu, T.Y., Chuang, Y.S., Lee, H.Y.: A study of cross-lingual ability and language-
specific information in multilingual BERT. arXiv preprint arXiv:2004.09205 (2020)
11
 16. Liu, N.F., Gardner, M., Belinkov, Y., Peters, M.E., Smith, N.A.: Linguistic knowledge and
transferability of contextual representations. arXiv preprint arXiv:1903.08855 (2019)
17. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer,
L., Stoyanov, V.: RoBERTa: A Robustly Optimized BERT Pretraining Approach. CoRR
abs/1907.1 (2019), http://arxiv.org/abs/1907.11692
18. Loureiro, D., Rezaee, K., Pilehvar, M.T., Camacho-Collados, J.: Analysis and Evaluation
of Language Models for Word Sense Disambiguation. Computational Linguistics pp. 1–55
(2021)
19. Malmsten, M., Börjeson, L., Haffenden, C.: Playing with Words at the National Library of
Sweden–Making a Swedish BERT. arXiv preprint arXiv:2007.01658 (2020)
20. Martin, L., Muller, B., Suárez, P.J.O., Dupont, Y., Romary, L., de La Clergerie, Ã.V.,
Seddah, D., Sagot, B.: CamemBERT: a tasty French language model. arXiv preprint
arXiv:1911.03894 (2019)
21. Mikolov, T., Chen, K., Corrado, G., Dean, J.: Efficient estimation of word representations
in vector space. 1st International Conference on Learning Representations, ICLR 2013 -
Workshop Track Proceedings ICLR 2013, 1–12 (2013), https://arxiv.org/abs/1301.3781
22. Mikolov, T., Le, Q.V., Sutskever, I.: Exploiting similarities among languages for machine
translation. arXiv preprint arXiv:1309.4168 (2013)
23. Pennington, J., Socher, R., Manning, C.D.: GloVe: Global vectors for word representation.
In: EMNLP 2014 - 2014 Conference on Empirical Methods in Natural Language Processing,
Proceedings of the Conference (2014). https://doi.org/10.3115/v1/d14-1162
24. Rajpurkar, P., Jia, R., Liang, P.: Know what you don’t know: Unanswerable questions for
SQuAD. arXiv preprint arXiv:1806.03822 (2018)
25. Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P.: SQuad: 100,000+ questions for machine
comprehension of text. EMNLP 2016 - Conference on Empirical Methods in Natural Lan-
guage Processing, Proceedings (ii), 2383–2392 (2016). https://doi.org/10.18653/v1/d16-126
4
26. Riksrevisjonen: Bilingual English-Norwegian parallel corpus from the Office of the Auditor
General (Riksrevisjonen) website â ˘A¸S ELRC-SHARE (2018), https://www.elrc-share.eu/re
pository/browse/bilingual-english-norwegian-parallel-corpus-from-the-office-of-the-audit
or-general-riksrevisjonen-website/a5d2470201e311e9b7d400155d0267060fffdc9258a741
659ce9e52ef15a7c26/
27. Rogers, A., Kovaleva, O., Rumshisky, A.: A primer in bertology: What we know about how
bert works. Transactions of the Association for Computational Linguistics 8, 842–866 (2020)
28. Tenney, I., Das, D., Pavlick, E.: BERT rediscovers the classical NLP pipeline. arXiv preprint
arXiv:1905.05950 (2019)
29. Tenney, I., Xia, P., Chen, B., Wang, A., Poliak, A., McCoy, R.T., Kim, N., Van Durme,
B., Bowman, S.R., Das, D., others: What do you learn from context? probing for sentence
structure in contextualized word representations. arXiv preprint arXiv:1905.06316 (2019)
30. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Å.,
Polosukhin, I.: Attention is all you need. Advances in Neural Information Processing Sys-
tems 2017-Decem(Nips), 5999–6009 (2017)
31. Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., Bowman, S.R.: GLUE: A multi-
task benchmark and analysis platform for natural language understanding. arXiv preprint
arXiv:1804.07461 (2018)
32. Wiedemann, G., Remus, S., Chawla, A., Biemann, C.: Does BERT make any sense? In-
terpretable word sense disambiguation with contextualized embeddings. arXiv preprint
arXiv:1909.10430 (2019)
33. Williams, A., Nangia, N., Bowman, S.R.: A broad-coverage challenge corpus for sentence
understanding through inference. arXiv preprint arXiv:1704.05426 (2017)
12
",missing,doc12,". Contextual language models, such as transformers, can solve a wide
range of language tasks ranging from text classification to question answering and
machine translation. Like many deep learning models, the performance heavily
depends on the quality and amount of data available for training. This poses a
problem for low-resource languages, such as Norwegian, that can not provide the
necessary amount of training data. In this article, we investigate the use of mul-
tilingual models as a step toward overcoming the data sparsity problem for mi-
nority languages. In detail, we study how words are represented by multilingual
BERT models across two languages of our interest: English and Norwegian. Our
analysis shows that multilingual models similarly encode English-Norwegian
word pairs. The multilingual model automatically aligns semantics across lan-
guages without supervision. Additionally, our analysis also shows that embed-
ding a word encodes information about the language to which it belongs. We,
therefore, believe that in pre-trained multilingual modelsâ ˘A´Z knowledge from
one language can be transferred to another without direct supervision and help
solve the data sparsity problem for minor languages.","Accepted manuscript Aaby, P., Biermann, D., Yazidi, A., Borges Moreno e Mello, G. & Palumbo, F. . Exploring Multilingual Word Embedding Alignments in BERT Models: A Case Study of English and Norwegian. Lecture Notes in Computer Science (LNCS), 14381, 47-58. Published in: Lecture Notes in Computer Science (LNCS) DOI: AURA: Copyright: © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023 Available: 08. Nov. 2024 Exploring Multilingual Word Embedding Alignments in BERT Models: A Case Study of English and Norwegian Pernille Aaby1, Daniel Biermann2, Anis Yazidi1, Gustavo Borges Moreno e Mello1, and Fabrizio Palumbo1 1 Artificial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi, Oslo Metropolitan University, Oslo, Norway 2 Centre for Artificial Intelligence Research (CAIR) Department of ICT, University of Agder, Grimstad, Norway fabrizio.palumbo@oslomet.no Abstract Keywords: Natural Language Processing · Multilingual Bert · Word Alignment · Data Sparsity. 1 Introduction Over recent years, the field of AI has made impressive progress regarding the perfor- mance of natural language processing tasks such as text classification, question answer- ing, machine translation, or language generation. This progress is mainly driven by purely data-driven models such as transformers. To encode how words relate to their context, transformers are pre-trained on vast, unlabeled and mostly monolingual train- ing corpora. This approach is powerful for languages such as English or Spanish, with an abundance of language resources consisting in raw text, labeled datasets, and bench- marks. However, when it comes to low-resource languages, such as Norwegian, the available language datasets are often limited. Unfortunately, the performance in such data-driven models and approaches heavily depends on the quality and amount of train- ing data available. That is, good performance depends on high-quality datasets. At the This is a post-peer-review, pre-copyedit version of the following conference proceeding: Aaby, P., Biermann, D., Yazidi, A., Mello, G.B.M.e., Palumbo, F. . Exploring Multilingual Word Embedding Alignments in BERT Models: A Case Study of English and Norwegian. In: Bramer, M., Stahl, F. (eds) Artificial Intelligence XL. SGAI 2023. Lecture Notes in Computer Science(), vol 14381. Springer, Cham. DOI: written time, there are 2181 matches for English datasets and only 67 for Norwegian datasets on huggingface.co3. More training data tend to improve the performance of language models [17,3]. Consequently, monolingual Norwegian language models will likely not achieve the same performance as monolingual English language models. Most existing language models today have been trained on monolingual corpora [7,14], which do not benefit languages with sparse data availability. Isbister et al.[11] proposed an approach that translates the text from a low-resource language to a high- resource language. Then, it uses a state-of-the-art performing model trained on high- resource language to alleviate the data sparsity problem. However, recent work shows that specific multilingual language models manage to align words from different lan- guages without learning from parallel data, which machine translation requires [4,15]. Therefore, we pose the questions: – Can multilingual models relieve the need for monolingual models? – Can knowledge from one language be transferred to another without parallel data? In this article, we explore the similarities and dissimilarities between the word represen- tations in English and Norwegian, using two multilingual language models. To this end, we use different methods from recent literature and combine them in a comprehensive study of the case of the English-Norwegian language pair. To find similarities we evaluate word retrieval performance, from an English source vocabulary to a Norwegian target vocabulary. To find dissimilarities, we quantify the accuracy of retrieving the original language from the word representation. All methods are non-parametric and rely purely on vector proximity. The model architecture we have used is BERT (Bidirectional Encoder from Transformer) [7] since previous work has shown its capability to align words automatically [4,16]. We believe that this exploration can provide the research community with a better understanding of how the information of different languages manifests inside the word representations of multilingual models and ultimately help improve existing models and applications that suffer from data sparsity. 2 Related Work 2.1 Multilingual Word Retrieval Mikolov et al. [22] noticed that the distribution of word embeddings in latent space showed similar characteristics across different languages. Motivated by the similarity of distributions, they hypothesized that they could align two distributions with word embeddings from two different languages to create a bilingual dictionary with word retrieval. Their technique relied on bilingual parallel corpora. Conneau et al. [6] showed that it was possible to align two-word embedding distributions from different languages without any supervision (parallel corpora). They utilized adversarial training to learn a linear mapping from the source to the target language, alleviating the need for parallel corpora. 3 ! Visited: 19.01.2023 2 2.2 Multilingual BERT BERT is a transformer-based [30] model which improved state-of-the-art results on sev- eral NLP tasks at the time of release [7]. It improved on question-answering tasks like SQuAD v1.1 [25] and SQuAD v2.0 [24], and language understanding tasks like GLUE [31] and MutliNLI [33]. The model is trained on vast amounts of text corpora, the orig- inal English BERT used the English part of Wikipedia [7], but today it is being trained on bigger collections, even book collections from a whole library [13]. The model has been trained for several languages like French, Swedish, and Norwegian [20,19,14]. BERT can also be trained in several languages simultaneously to obtain multilingual understanding. mBERT is one of these models, and it is trained on Wikipedia corpus for 104 different languages, including English and Norwegian4. Notram, Norwegian Transformer Model, is a BERT model initialized from mBERT and further trained on mostly Norwegian book-corpus data [13]. Although the model is mainly trained on Norwegian corpus, after initialization, the authors estimate that a portion of 4% is English. The model scores high on Named Entity Recognition both for the Norwegian language and the English language. Previous work [4,15] also shows that the semantics of two (and more) languages align automatically in BERT. So the model does not only represent two languages sep- arately, but it is also able to encode connections between two languages through shared semantics of the words, without being trained on parallel data. 2.3 From Contextual to Static Embeddings In order to benefit from previous benchmarks like SimLex999 [10], WordSim353 [1] and SimVerb3500 [9] that evaluate semantics, Bommasani et al. [2] distilled a set of static word embeddings from contextual word embeddings. This way the results could be compared to traditional word embeddings [21,23,12]. To create the static word em- beddings from BERT they tried different aggregation and pooling strategies. The best- performing aggregation method was to take the average over several contexts, also re- ferred to as AOC (Average Over Context). They also used mean pooling, taking the mean of all token representations over subtokens of a word in case a word consists of more than one token. 2.4 Probing BERT Probing BERT has become a popular area of research to better justify its success and understand the model better so it is easier to improve the architecture [27]. It entails creating a simple classifier and using the features from the pre-trained model. If the simple classifier manages to solve the task, then we can assume that the necessary information is already within the features we extract. From previous work, we know that BERT represents words with information about syntax and semantics [27]. Tenney et al. [28] discovered that BERT hierarchically learns information that corresponds to the traditional NLP (Natural Language Processing) 4 ! 3 pipeline. Starting with local syntax structure such as POS tagging and parsing in the lower layers, while finding named entity recognition, semantic roles, and co-reference are information encoded later in the model in the respective order. Similar discoveries can be found in other works as well [16,29]. Naturally, since BERT is a contextual model representing a word based on not only itself but also the surrounding words, the question of whether one could distinguish different meanings of an ambiguous through the representation arose. In previous work [32,18] they find that ambiguous words divide different meanings into clusters from the contextual representation, although it is not always the same clusters as we would have defined from a human perspective. 3 Methods Our analysis examines similarities and differences between word representations in two languages. Similarities are found through static word retrieval and differences through language detection. Our non-parametric method only relies on finding the most similar embedding(s) from a source word to a target collection. We used KNN (K- Nearest Neighbours) with cosine similarity to find the most similar vectors. 3.1 Static Word Retrieval Following the work by Bommasani et al. [2] we created a static set of word embeddings by taking the AOC of several contextual embeddings for a term t. The contextual em- bedding for word t is obtained from a context ct ∈Ct, where each ct is two sentences from the relevant language corpus. st = 1 Nt N X n=1 wtn wtn is the nth contextual embedding for the number of contexts Nt = |Ct|. For words that consist of more than one workpiece, we used mean pooling, taking the mean of all subtokens, to aggregate all token embeddings. wtn = 1 It I X i=1 pti pti is the ith token in the word. We created static embeddings for all 13 intermediate representations from BERT, one after all the 12 stacked layers and the input layer. We aimed to retrieve a Norwegian target word from an English source word. The objective becomes, for each of the English word representations si−en, evaluate the cosine simi- larity to all the Norwegian word representations sj−no, rank the similarities, and return the top(@) match(s). If a translation of the English word is one of the returned words, we achieved a correct word retrieval. k-neighbours(i) = argmax j sim(si−en, sj−no) 4 yi = ( 1, if k-neighbours(i) ∈translation(sno) 0, otherwise accuracy static word retrieval = 1 T T X i=1 yi T is the number of terms in the English vocabulary. Liu et al. [15] test if word retrieval performance increases by doing a mean shift. Mean shift entails shifting from an English source word to be closer to a Norwegian target word by first subtracting the mean of all the English word embeddings and then adding the mean of all the Norwegian word embeddings. We define a language vector as the mean of all the static word embeddings in one vocabulary. Ll = 1 T T X t=1 wt l ∈{English, Norwegian} and T is the number of words in each vocabulary. Mean shift: st,en−>no = st,en −Len + Lno Len and Lno are language vectors for English and Norwegian respectively. yi−l =      1, if sim(si−l, Len) > sim(si−l, Lno) and l = en 1, elif sim(si−l, Len) < sim(si−l, Lno) and l = no 0, otherwise accuracy language detection = 1 2T T X i=1 yi−en + 1 2T T X i=1 yi−no 3.2 Language Detection Motivated by the fact that words from the same language could be aggregated to a lan- guage vector, we asked the question: Can we detect the language of a word based on the similarity to the language embed- dings? We detected the language by evaluating which language vector a word representation is most similar to. 3.3 Data The Norwegian News Corpus5 is used as the raw text corpora for the Norwegian part. We only used the part in Norwegian bokmÃˇel (not nynorsk). The articles in the dataset 5 ! 5 are from multiple different newspapers, such as “VG”, “Aftenposten” and “Dagens nÃ˛eringsliv” etc., collected from the years 1998 to 2019. We chose a set of contexts from the corpus for each word in our Norwegian vocabulary between 100 and 500. A context is defined as two sentences. The vocabulary is restricted to only include the 50,000 most common words from the Norwegian News Corpus. In addition, we checked that the word is present in a Norwegian wordlist for BokmÃˇel 6. To evaluate the word retrieval from English to Norwegian, we have used the English- Norwegian word benchmark from MUSE 7 [6]. We only used the word pairs, where the Norwegian word is in our top 50,000 vocabularies, and the English word is present in the Brown corpus 8 [8]. Some English words have more than one Norwegian word translation. We define a correct word retrieval as at least one match. The Brown corpus gives the context sentences for the English word embedding vo- cabulary. The number of contexts for a word is the number of times a word stands in the Brown corpus but a maximum of 500 times. We only obtained static word embeddings for the words in the MUSE benchmark. The MUSE-filtered vocabulary ended up with approximately 12,000 English source words. 4 Results 4.1 Static Word Retrieval In Figure 1 we report the results of the English to Norwegian word retrieval using KNN and cosine similarity. We compare the performance of both mBERT (Figure 1a) and Notram (Figure 1c) for different numbers of top matches (@1,@3,@10). Notram achieved better accuracy than mBERT in general. The middle layers seem to perform best for both models, with Notram achieving around 50% at @1 match and more than 70% accuracy when using the @10 matches at layer 7. In addition, for the Notram model. we notice a dip in performance for layer 11. Overall, we argue that BERT models are capable of aligning semantics across English and Norwegian without using any supervised datasets with parallel sentences. 4.2 Static Word Retrieval with Mean Shift Figure 1b and Figure 1d show the static word retrieval performances when adjusted with the mean shift. To illustrate the impact of the mean shift on the word retrieval per- formance better, the performance increase between the shifted and non-shifted model is depicted by the dashed lines. We can see that the overall influence of the mean shift on performance is relatively low across all layers. When mean shifting, the model re- tains word retrieval accuracy better from the middle layers to the subsequent layers than without the mean shift. The maximum word retrieval performance increase is reached in layer 11 for the Notram model, improving by 8% for K at @1, @3, and @10. Thus, 6 ! 7 ! 8 ! 6 (a) mBERT (b) mBERT, shifted // (c) Notram (d) Notram, shifted Fig. 1: Static word retrieval performance from English to Norwegian with layer-wise performance accuracy with and without mean shift. The lower dashed lines depict the performance increase when using the mean shift. The star marker shows at which layer the performance peaked. Both models experience the highest performance increase in layer 11 for all chosen @matches. the mean shift seems to alleviate the cause of the performance dip seen before in later layers. 4.3 Language Detection Figure 2 reports the results from the language detection experiment. The non-parametric method clearly shows that it is possible to find the language of a word using this method as the performance reaches almost 100% in the top-performing layer. The language detection accuracy reaches values above 95% for both models as soon as layer 1. This strongly indicates that the closest language vector can serve as a strong predictor for the language of the embedding. 4.4 Both Semantics and Language Properties can Cluster For a more qualitative inspection of the word representations, Figure 3 illustrates both semantic alignment and language properties between English and Norwegian. The top 7 (a) mBERT: Language Belonging. (b) Notram Fig. 2: Layer wise language detection performance. The lighter line (circle) describes the prediction accuracy for the English vocabulary, the darkest line (square) describes the prediction accuracy for the Norwegian language and the line of intermediate shade (triangle) describes the combined prediction accuracy of language detection. The stars mark in which layer the performance peaks. graph Figure 3a, inspired by previous work on semantic alignment in BERT [4], shows a plot comparing a set of 5 words in each English and Norwegian, respectively. The words were taken from the parallel corpus with sentences from riksrevisjonen9[26]. We can observe that all word pairs are clustering together, indicating the semantic alignment of the word embeddings between the languages. In the bottom graph Figure 3b we see two sets of 500 static word embeddings from each language. We can notice a clear clustering of the two languages. In both graphs, we reduce the embedding dimension to two dimensions with the t-SNE method. This further solidifies that BERT models are able to align semantics across English and Nor- wegian without using any supervised data 5 Discussion Our analysis shows that layers 5-9 (middle layers) have the highest accuracy on static word retrieval. This result is in line with previous work on semantic similarity [5]. We argue that the best-performing layers in semantic similarity will also be the best- performing layers in semantic alignment between two languages. Although we observe a clear separation between languages in the word representation space, the mean shift method did not significantly impact the word retrieval accuracy. In layer 11, the accu- racy does increase by around 8% in the Notram model. However, in the best performing layer of the same model, layer 7 (or 5), the increase is only around 1%. We consider this a slight change since the accuracy at @1 is around 50%. Overall, the word retrieval 9 ! rom-the-office-of-the-auditor-general-riksrevisjonen-website/a5d2470201e311e9b7d400155 d0267060fffdc9258a741659ce9e52ef15a7c26/ 8 (a) Visualizing contextual word embeddings for word pairs in English and Norwegian. Contextual embeddings taken from layer 8 of the Notram model and the English contextual embeddings have experienced a mean shift. The word embeddings are reduced to 2D with t-SNE. The darker colored markers show contextual word embeddings for Norwegian while the lighter color show contextual embedding for English. Each word pair has its own marker. (b) 500 random words from Norwegian and English vocabulary respectively. The static word embeddings are from Notram layer 12. The word embeddings are reduced to 2D with t-SNE. Lighter points correspond to English embed- dings and darkest points correspond to Norwegian embeddings. Fig. 3: Visualizing static and contextual word embeddings from BERT 9 results suggest that the hypothesis that translating one language to another in the word representation space by looking at the closest matched embedding of the other lan- guage is a promising approach. Though, the low impact of the mean shift indicates that the translation from one language to another is not as simple as shifting the embedding by a simple mean language vector. This warrants further investigation into better meth- ods to create language vector representations that might improve the impact of such a language vector shift. Nevertheless, the language vectors from the mean shift analysis remain strong predictors for identifying the language of an embedding as can be seen by the strong performance results of our language detection analysis. It is noteworthy that static word retrieval does not deal with ambiguous words. Both language vocabularies most likely contain words with multiple meanings, leading to a conflation of meaning in the embedding. Conflated meanings most likely affected word retrieval since the English and Norwegian corpus do not provide the same contexts, and a word representation can be conflated with different meanings depending on the text corpus. In addition, words within each language can have different meanings. There- fore, an ambiguous word can often be detected because it will translate to different words in another language depending on the context. To deal with this downside, one would have to include a more nuanced analysis of either sense or a word pair from the same context. We believe that ambiguous words have a negative impact on accuracy as we could observe significantly better results when considering @3 and @10 nearest neighbours, with an increase of more than a 20% going from @1 to @10. Norwegian is a language that borrows many words and phrases from English. It can be single words like ""skateboard"" or whole phrases like movie titles. Even though we filtered out sentences detected as English from the Norwegian text corpus, single words and smaller phrases may have been hard to remove. The effect could be English noise in the Norwegian part of the corpus and hence an effect in language detection. mBERT outperforms Notram in the subsequent layers of the model in detecting the correct language, and it achieves close to 100% accuracy. However, we question if the accuracy is this high because there might exist English noise in the Norwegian corpus, which would mean that the accuracy should not be 100%. A better evaluation dataset could be used to inspect this effect further. 6 Conclusion In this exploratory analysis, we have shown that BERT’s word representations automat- ically align semantics across English and Norwegian. We showed this with an accuracy of 50% for @1 nearest neighbor and an accuracy of more than 70 % for @10 nearest neighbor on the word retrieval task. In addition, we found that language is encoded in the word representation: We could detect the correct language of a word, with close to 100% accuracy, only by looking at its proximity to the two language vectors for English and Norwegian, respectively. We demonstrate that the model can align semantics and learn language properties by training on only raw text data (no parallel sentences). We believe that the combination of automatic language detection and word re- trieval between language embeddings allows for knowledge to be transferred between languages, ultimately helping alleviate the data sparsity problem in low-resource lan- 10 guages, such as Norwegian. While our results show promising tendencies, further in- vestigations into reaching higher word retrieval accuracies and better aligning language vectors are warranted to make this approach reliable. We hope that our findings moti- vate new ways of using multilingual models and inspire more research in training and investigating multilingual models for low-resource languages. References 1. Agirre, E., Alfonseca, E., Hall, K., Kravalova, J., Pasca, M., Soroa, A.: A study on similarity and relatedness using distributional and wordnet-based approaches 2. Bommasani, R., Davis, K., Cardie, C.: Interpreting Pretrained Contextualized Representa- tions via Reductions to Static Embeddings. In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. pp. 4758–4781 3. Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D.M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., Amodei, D.: Language Models are Few-Shot Learners. arXiv preprint arXiv:2005.14165 4. Cao, S., Kitaev, N., Klein, D.: Multilingual alignment of contextual word representations. arXiv preprint arXiv:2002.03518 5. Chronis, G., Erk, K.: When is a bishop not like a rook? When itâ ˘A´Zs like a rabbi! Multi- prototype BERT embeddings for estimating semantic relationships. In: Proceedings of the 24th Conference on Computational Natural Language Learning. pp. 227–244 6. Conneau, A., Lample, G., Ranzato, M., Denoyer, L., Jégou, H.: Word translation without parallel data. arXiv preprint arXiv:1710.04087 7. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of deep bidirectional transformers for language understanding. NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan- guage Technologies - Proceedings of the Conference 1(Mlm), 4171–4186 8. Francis, W.N., Kucera, H.: Brown corpus manual. Letters to the Editor 5, 7 9. Gerz, D., Vuli´c, I., Hill, F., Reichart, R., Korhonen, A.: Simverb-3500: A large-scale evalua- tion set of verb similarity. arXiv preprint arXiv:1608.00869 10. Hill, F., Reichart, R., Korhonen, A.: Simlex-999: Evaluating semantic models with (genuine) similarity estimation. Computational Linguistics 41, 665–695 11. Isbister, T., Carlsson, F., Sahlgren, M.: Should we Stop Training More Monolingual Models, and Simply Use Machine Translation Instead? arXiv preprint arXiv:2104.10441 12. Joulin, A., Grave, E., Bojanowski, P., Mikolov, T.: Bag of tricks for efficient text classifi- cation. In: 15th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2017 - Proceedings of Conference. vol. 2 . 53/v1/e17-2068 13. Kummervold, P.E., la Rosa, J., Wetjen, F., Brygfjeld, S.A.: Operationalizing a national dig- ital library: The case for a norwegian transformer model. arXiv preprint arXiv:2104.09617 14. Kutuzov, A., Barnes, J., Velldal, E., Øvrelid, L., Oepen, S.: Large-scale contextualised lan- guage modelling for norwegian. arXiv preprint arXiv:2104.06546 15. Liu, C.L., Hsu, T.Y., Chuang, Y.S., Lee, H.Y.: A study of cross-lingual ability and language- specific information in multilingual BERT. arXiv preprint arXiv:2004.09205 11 16. Liu, N.F., Gardner, M., Belinkov, Y., Peters, M.E., Smith, N.A.: Linguistic knowledge and transferability of contextual representations. arXiv preprint arXiv:1903.08855 17. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., Stoyanov, V.: RoBERTa: A Robustly Optimized BERT Pretraining Approach. CoRR abs/1907.1 , 18. Loureiro, D., Rezaee, K., Pilehvar, M.T., Camacho-Collados, J.: Analysis and Evaluation of Language Models for Word Sense Disambiguation. Computational Linguistics pp. 1–55 19. Malmsten, M., Börjeson, L., Haffenden, C.: Playing with Words at the National Library of Sweden–Making a Swedish BERT. arXiv preprint arXiv:2007.01658 20. Martin, L., Muller, B., Suárez, P.J.O., Dupont, Y., Romary, L., de La Clergerie, Ã.V., Seddah, D., Sagot, B.: CamemBERT: a tasty French language model. arXiv preprint arXiv:1911.03894 21. Mikolov, T., Chen, K., Corrado, G., Dean, J.: Efficient estimation of word representations in vector space. 1st International Conference on Learning Representations, ICLR 2013 - Workshop Track Proceedings ICLR 2013, 1–12 , 22. Mikolov, T., Le, Q.V., Sutskever, I.: Exploiting similarities among languages for machine translation. arXiv preprint arXiv:1309.4168 23. Pennington, J., Socher, R., Manning, C.D.: GloVe: Global vectors for word representation. In: EMNLP 2014 - 2014 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference . 24. Rajpurkar, P., Jia, R., Liang, P.: Know what you don’t know: Unanswerable questions for SQuAD. arXiv preprint arXiv:1806.03822 25. Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P.: SQuad: 100,000+ questions for machine comprehension of text. EMNLP 2016 - Conference on Empirical Methods in Natural Lan- guage Processing, Proceedings (ii), 2383–2392 . 4 26. Riksrevisjonen: Bilingual English-Norwegian parallel corpus from the Office of the Auditor General (Riksrevisjonen) website â ˘A¸S ELRC-SHARE , pository/browse/bilingual-english-norwegian-parallel-corpus-from-the-office-of-the-audit or-general-riksrevisjonen-website/a5d2470201e311e9b7d400155d0267060fffdc9258a741 659ce9e52ef15a7c26/ 27. Rogers, A., Kovaleva, O., Rumshisky, A.: A primer in bertology: What we know about how bert works. Transactions of the Association for Computational Linguistics 8, 842–866 28. Tenney, I., Das, D., Pavlick, E.: BERT rediscovers the classical NLP pipeline. arXiv preprint arXiv:1905.05950 29. Tenney, I., Xia, P., Chen, B., Wang, A., Poliak, A., McCoy, R.T., Kim, N., Van Durme, B., Bowman, S.R., Das, D., others: What do you learn from context? probing for sentence structure in contextualized word representations. arXiv preprint arXiv:1905.06316 30. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Å., Polosukhin, I.: Attention is all you need. Advances in Neural Information Processing Sys- tems 2017-Decem(Nips), 5999–6009 31. Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., Bowman, S.R.: GLUE: A multi- task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461 32. Wiedemann, G., Remus, S., Chawla, A., Biemann, C.: Does BERT make any sense? In- terpretable word sense disambiguation with contextualized embeddings. arXiv preprint arXiv:1909.10430 33. Williams, A., Nangia, N., Bowman, S.R.: A broad-coverage challenge corpus for sentence understanding through inference. arXiv preprint arXiv:1704.05426 12",". Contextual language models, such as transformers, can solve a wide range of language tasks ranging from text classification to question answering and machine translation. Like many deep learning models, the performance heavily depends on the quality and amount of data available for training. This poses a problem for low-resource languages, such as Norwegian, that can not provide the necessary amount of training data. In this article, we investigate the use of mul- tilingual models as a step toward overcoming the data sparsity problem for mi- nority languages. In detail, we study how words are represented by multilingual BERT models across two languages of our interest: English and Norwegian. Our analysis shows that multilingual models similarly encode English-Norwegian word pairs. The multilingual model automatically aligns semantics across lan- guages without supervision. Additionally, our analysis also shows that embed- ding a word encodes information about the language to which it belongs. We, therefore, believe that in pre-trained multilingual modelsâ ˘A´Z knowledge from one language can be transferred to another without direct supervision and help solve the data sparsity problem for minor languages.","['Pernille Aaby', 'Daniel Biermann', 'Anis Yazidi', 'Gustavo Mello', 'Gustavo Mello', 'Fabrizio Palumbo']"
A Deep Learning-Based Tool for Automatic Brain Extraction from Functional Magnetic Resonance Images of Rodents,"Pontes-Filho, Sidney
and Dahl, Annelene Gulden
and Nichele, Stefano
and Mello, Gustavo Borges Moreno e.",2022,missing,missing,missing,inproceedings,"A deep learning based tool for automatic brain
extraction from functional magnetic resonance
images in rodents
Sidney Pontes-Filho∗,†, Annelene Gulden Dahl‡, Stefano Nichele∗and Gustavo Borges Moreno e Mello∗,§
∗Department of Computer Science, Oslo Metropolitan University, Oslo, Norway
†Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway
‡Kavli Institute for Systems Neuroscience, Norwegian University of Science and Technology, Trondheim, Norway
§Department of Mech., Elec. and Chem. Engineering, Oslo Metropolitan University, Oslo, Norway
Email: gustavom@oslomet.no
Abstract INTRODUCTION
Functional magnetic imaging (fMRI) has emerged as a
powerful tool to investigate functional networks in the brain.
Because fMRI is a non-invasive technology, the ﬁeld has
primarily been driven by its application to the study of the
human brain. Consequently, great advances in automating
analysis of fMRI data through tools that improve its speed and
efﬁciency have been achieved to process human data, saving
both time and costs associated with fMRI studies. However,
efforts to either modify preexisting tools, or develop similar
tools for use on rodent datasets are lagging.
Currently, one of the most time consuming steps in the
processing of rodent fMRI data is the process of brain ex-
traction or skull stripping. This step consists of segmenting
the whole brain, which is equivalent to removing all non-
cerebral tissue, including the skull, nose, mouth, ears, and
muscles [1]. Accurate extraction of the brain is essential to
ensure that fMRI data of all the subjects in the study are
anatomically aligned, which is necessary to allow for reliable
statistical comparison across large cohorts of animals [2]–[6].
Because skull stripping is a well understood problem [7] and
a necessity in every fMRI analysis, the development of tools
to automatise and increase the speed and reliability of results
might have a great positive impact into fMRI research.
Rodent’s brain extraction poses additional challenges when
compared to segmenting the human brains from fMRI data.
Rodents have a smaller gap between the brain and the skull,
resulting in a less clear edge demarcation than in humans.
Additionally, the rodent brain differs in shape, texture, size
and proportion from the human brain. This means that the
automated tools developed to handle human data such as
Brain Extraction Toolkit (BET) [8] and BrainSuites Brain
Surface Extractor (BSE) [9] usually fail to process images of
rodent brains. Therefore, brain extraction of rodent anatomical
and functional data is predominantly carried out manually.
This process involves researchers going slice-by-slice through
the acquired (anatomical and functional) images in all three
dimensions and manually drawing masks for the brain using
a mouse or a tablet.
A tool to efﬁciently extract the brain from rodent anatomical
images was recently published [10]. This tool takes as input
one representative brain from the study and its manually
created brain mask, and uses this information to carry out the
brain extraction of the remaining subjects in the study. While
this is a great tool for extracting the brains in the anatomical
images, it is not intended for use in functional datasets, and
there is, to the best of our knowledge, no equivalent tool
available for extracting the brain from the functional dataset.
In order to observe the changing activity of the brain over time,
the functional datasets have to be acquired at a much greater
speed than the anatomical images, resulting in a much lower
spatial resolution than the anatomical images. To preserve
the sensitivity to blood-oxygenation-level-dependent (BOLD)
contrast the images are also frequently subject to severe
susceptibility-induced distortions, in particular, in the back of
the brain near ear canals and sinuses. Due to these confounds,
skull extraction of functional rodent images commonly fails,
and the current state-of-the-art in the ﬁeld of rodent imaging
is to manually draw the masks. This process is both time-
consuming and often inaccurate, contributing to a less-than-
arXiv:1912.01359v2  [eess.IV]  6 Dec 2019
 perfect alignment of the functional data to the template brain.
To overcome this obstacle, we have developed a deep
learning-based tool in Python that quickly and successfully
extracts the brain from the functional datasets, thus improving
the speed and accuracy of the preprocessing pipeline. The tool,
furthermore, does not require any study-speciﬁc input from the
researcher in order to successfully separate brain from non-
brain tissue. The tool is freely available online.
II. RELATED WORKS
In the last three decades, many methods for skull stripping
have been proposed [11]–[13], ranging from simple luminance
thresholding to 3D-convolutional deep learning techniques
[14]. Among them, the most promising are the water-shedding
based segmentation [1], the Brain Extraction Tool (BET) [8]
and the most recent 3D-U-Net [14]. Watershed based methods
are image processing pipelines originally described in [15]
that are advantageous for being unsupervised, fast, and easy
to tune; they leverage luminance gradients to deﬁne regions of
interest that can be deﬁned either as brain or non-brain. BET,
on the other hand, uses a malleable model, where a spherical
mesh is initialized at the center of mass and then expanded
towards the surface of the brain; locally adaptive model forces
based on local intensity values guide this process, allowing
BET to quickly segment the brain. The caveat is that BET
has a spherical (human) brain assumption, and has irregular
performance with oblong elliptical shaped brains, such as
rodent brains. Finally, 3D-U-Net is a promising robust method-
ology that uses convolutional neural networks to perform
semantic binary segmentation. This method has the advantage
of being able to learn from experts by mapping spacial features
of the raw fMRI image to ground-truth data generated by
manual segmentation. Because of the need for coregistration
and alignment in the z-axis, this method cannot beneﬁt from
several of the data augmentation methods available, such as
elastic transformations [16], [17], thus requiring much more
data than the standard U-Net [17]. All of these methods were
developed to handle human fMRI data, and regardless of
the great levels of performance achieved by the previously
cited methods, a solution to reliably perform skull stripping in
rodent data is still missing.
The solutions to particularly handle rodent fMRI data
use more modest technologies. More often than not, skull
stripping is still done by creating hand-drawn masks and
only occasionally helped by semi-automation tools such as
BrainSuite’s Brain Surface Extractor (BSE) [9] which pro-
duces an initial mask that subsequently needs to be reﬁned
and corrected by hand. Beyond BSE other two automation
method categories are available, warping to brain atlas based
methods, and surface template based methods [10]. Both
methods are built extending the NiftyReg software package
[18]; and both dependent on the warping of the image to
a template coordinate map, or on warping a mask to the
raw image through a series of afﬁne and non-linear transfor-
mations. These methods produce excellent results on high-
resolution anatomical images, but due to the lower spatial
resolution and image distortions in the functional datasets the
automated skull stripping methods currently available fail to
perform correctly on rodent functional images. Hence, the
brain extraction problem in functional images from rodent data
has yet to be solved satisfactorily in a generic and robust way.
III. METHODS
A. Image acquisition
62 fMRI datasets from 31 McGill-R-thy-App rats were
acquired on a 7T Biospec 70/30 (Bruker BioSpin) preclin-
ical scanner, equipped with an actively shielded 660 mT/m
BGA12S HP gradient set (Bruker) in combination with a
quadrature surface coil (Bruker BioSpin). Aspin-echo EPI
sequence was used with the following parameters: 600 repeti-
tions (total scan time of 30 min each) with 2 segments, TE=
20ms, repetition time (TR) = 1.5s for a full-volume acquisition
of 3s., ﬁeld-of-view (FOV) of 20x20mm, matrix size 80x80,
55 dummy scans, ﬂip angle of 90 degrees. Seventeen slices
were acquired in rostro-caudal direction for a ﬁnal resolution
of 250 x 250 x 1000um. All procedures were approved by
the Norwegian Food Safety Authority as well as the local
Animal Welfare Committee of the Norwegian University of
Science and Technology (NTNU). All animals were housed
and handled according to the Norwegian laws and regulations
concerning animal welfare and animal research. Experimental
protocols were approved by the Norwegian Animal Research
Authority (FOTS application number 11932) and were in
accordance with the European Convention for the Protection of
Vertebrate Animals used for Experimental and Other Scientiﬁc
Purposes.
B. Training dataset and Watershedding-based brain segmen-
tation
Due to the success of the watershedding algorithm to
segment the brain in human fMRI dataset [19], we used it
as a semi-automated approach to generate a dataset of masks
that were used to train the neural network to segment the
brain from the skull. Watershedding is a region-based approach
that considers the target structure as a homogeneous region
which is determined by a search process guided by appropriate
criteria for homogeneity. We implemented the watershedding
segmentation by using functions in OpenCV [20] to preprocess
the images by gray-scaling, mean-shifting and normalizing
them. Once the images were considered suitable for seg-
mentation, we thresholded the gray-scaled image into masks,
calculated their basin gradients, ﬁltered these gradients, and
identiﬁed the segmented areas as connected components. As
result, the watershed method provides per each image a series
of masks for each structure in each image. The gradient of
an image function f is the vector constituted by the partial
derivatives in each image dimension. The gradient’s direction
is the direction of steepest descent and a magnitude (mag) is
the length of the gradient vector. For an image function in R2,
f(x, y) the magnitude of the gradient is calculated as
mag(▽f) =
s
(δf
δx)2 + (δf
δy )2.
(1)
 To choose the mask that represented the brain structure,
we leveraged the regularities in the data. Because in this
dataset the brain was always very close to the center, this
meant that the average polar radial distance between each
point of the brain structure mask and the center of the image
was shorter than any other structure. Thus, we used this as
the criterion to exclude other structures. The parameters for
this process were chosen manually and the results followed
by close supervised eye-inspection. Nonetheless, this semi-
supervised approach proved to be substantially faster than the
manual alternative, because the same parameters could be used
for different datasets acquired in similar conditions.
C. Deep-Learning-based segmentation
In this article, we use a standard U-Net [17] architecture to
perform skull stripping from fMRI images of rodents. U-Nets
are most often used for semantic segmentation tasks. Beyond
performing well on the task, they allow for efﬁcient use of
GPU memory, which is an asset for processing big image
datasets with many features. This is heavily dependent on the
fully convolutional architecture of the U-Net, which enables
the extraction of image features at multiple image scales. In the
U-Net, different layers capture coarse feature-maps that reﬂect
this contextual information about the category and location of
objects at multiple scales. These feature-maps are later merged
through skip connections to combine coarse- and ﬁne-level
dense predictions [17].
The goal of the U-Net neural network architecture is to
predict which pixels in the image matrix are to be classiﬁed
as brain and which ones are to be classiﬁed otherwise. Thus,
the output of the ﬁnal decoder layer is a soft mask (see Fig.
1) that when multiplied to the input image produces the ﬁnal
segmented brain region.
D. Data Augmentation and Training
One major advantage of using the U-Net is that it is possible
and simple to use several methods for data augmentation such
as resizing, ﬂipping, rotating, and minor translations. These
data augmentation strategies increase the performance of the
model by increasing the size and variety of the dataset [21].
Additionally, fMRI images often do have distortions and
movement artifacts. To improve U-Net’s robustness in face
of such artifacts, elastic afﬁne transformations were applied
equally to the input image and the target masks. In total, the
training and validation datasets were increased by 50% with
these slightly deformed images [21].
To speed up training we utilized a U-Net pre-trained to
segment pathological structures in human MRI images. In-
stead of stochastic gradient descent, we modiﬁed the original
optimizer of U-Net to Adam [22] with the learning rate of
0.001. Additionally, the training used batches of 25 images
during 1,000 epochs.
IV. RESULTS
This section presents the quantitative and qualitative results
of the deep learning neural network for our task of segmenting
Fig. 1.
Soft masks examples: The left column represents the input image.
The right column illustrates the mask prediction for three different coronal
slices of a rodent’s .
rodents’ brains. Table I contains the quantitative results of
binary cross-entropy (BCE) loss, accuracy, F1 score, precision
and recall on the validation dataset of 49 images (5 % of our
dataset). All these values show that our model segments almost
all pixels that contain the brain (98.3 % recall) with precision
of 98.5 %. The F1 score is a metric that combines recall and
precision. The accuracy represents the percentage of correct
answers for the pixels predicted as part of the brain or not.
Such value is high and it is 99.35 %. Those measurements
suggest that the model performance is excellent.
TABLE I
VALIDATION RESULTS OF THE BEST (LOWEST) LOSS.
Measurement
Value
BCE loss
0.01562267541885376
Accuracy
0.9935703277587891
F1 Score
0.9843953251838684
Precision
0.9854521751403809
Recall
0.9833407998085022
 (a)
(b)
(c)
(d)
(e)
(f)
Fig. 2. Validation results. Green line represents the ground truth and red line is the predicted region.
The same model that obtained the best BCE loss on vali-
dation dataset has 6 out of its 49 results depicted in Fig. 2.
In general, the model performs well to segment the rodent’s
brain in an fMRI. There is one validation result which has a
small mistake in the segmentation. That is depicted in Fig 2e
and it has a small predicted region on the right side of the
image which means that the model predicted a “second” tiny
brain. Despite that, the qualitative and qualitative results are
impressive.
V. DISCUSSION
Much of what is known in neuroscience is derived from
studies using rodent models, due to its versatility and the
large selection of methods (e.g., invasive methods) available
to study them. On the other hand, much of what is known
about the human brain is derived from MRI and fMRI studies.
Thus, fMRI holds the promise of bridging the gap between
what we know about the mammalian brain. It may provide
evidence to generalize results from rodent-derived studies
using electrophysiology, optical, and pharmacological methods
to the human model. In this context, it is important to create
powerful tools that can increase the speed and the reliability
of the analysis performed on data derived from rodent models
and can equally be applied to human data. In this article we
made a step towards democratizing deep learning tools to the
neuroscience community by successfully applying a U-Net to
perform skull stripping of low resolution functional magnetic
resonance images from rodents. The method was quick to
train, required little data due to the usage of data augmentation
techniques, and qualitatively performed reasonably well. In
contrast to other approaches that depend on images with
high-resolution images or deformations of initial masks, U-
Nets work well with low resolution images and can segment
distorted images, even with motion artifacts. Additionally, by
using a network that operates on images as inputs instead
of a 3D tensor with all the image slices at once, we could
use data augmentation strategies without major problems with
respect to alignment issues. However, we recognize that U-
Net may not be the best nor the fastest architecture to perform
semantic segmentation. Other topologies such as Albunet, or
Ternausnet [23] might deploy better segmentation at higher
speeds. Additionally, because fMRI has a temporal component,
recursive layers could be added to take the dynamic nature
of the signal in the brain as a feature to better segment and
remove the skull, perhaps even in a non-supervised manner.
Consequently, a logical step is to explore how more modern
 architectures could perform in this task. We hope this tool
helps neuroscientists to reduce time in preprocessing steps of
their analysis of fMRI data in non-human models.
ACKNOWLEDGMENT
The two authors, Annelene Gulden Dahl and Sidney Pontes-
Filho contributed equally to the work. We also thank Stefano
Nichele for the comments on the manuscript. This work
was supported by Norwegian Research Council SOCRATES
project (grant number 270961) and received internal support
as a lighthouse project in Computer Vision from the Faculty
of Technology, Art and Design (TKD) at Oslo Metropolitan
University, Norway.
REPOSITORY
Code and example data can be found in the following
repository: https://github.com/sidneyp/skull-stripper
REFERENCES
[1] H. K. Hahn and H.-O. Peitgen, “The skull stripping problem in mri
solved by a single 3d watershed transform,” in International Conference
on Medical Image Computing and Computer-Assisted Intervention.
Springer, 2000, pp. 134–143.
[2] S. Spring, J. P. Lerch, and R. M. Henkelman, “Sexual dimorphism
revealed in the structure of the mouse brain using three-dimensional
magnetic resonance imaging,” Neuroimage, vol. 35, no. 4, pp. 1424–
1433, 2007.
[3] E. L. Bearer, X. Zhang, D. Janvelyan, B. Boulat, and R. E. Jacobs, “Re-
ward circuitry is perturbed in the absence of the serotonin transporter,”
Neuroimage, vol. 46, no. 4, pp. 1091–1104, 2009.
[4] D. A. Vousden, J. Epp, H. Okuno, B. J. Nieman, M. van Eede, J. Dazai,
T. Ragan, H. Bito, P. W. Frankland, J. P. Lerch et al., “Whole-brain
mapping of behaviourally induced neural activation in mice,” Brain
Structure and Function, vol. 220, no. 4, pp. 2043–2057, 2015.
[5] X. Zhang, E. L. Bearer, B. Boulat, F. S. Hall, G. R. Uhl, and R. E.
Jacobs, “Altered neurocircuitry in the dopamine transporter knockout
mouse brain,” PloS one, vol. 5, no. 7, p. e11506, 2010.
[6] M. C. van Eede, J. Scholz, M. M. Chakravarty, R. M. Henkelman, and
J. P. Lerch, “Mapping registration sensitivity in mr mouse brain images,”
Neuroimage, vol. 82, pp. 226–236, 2013.
[7] T. Kapur, W. E. L. Grimson, W. M. Wells III, and R. Kikinis, “Segmen-
tation of brain tissue from magnetic resonance images,” Medical image
analysis, vol. 1, no. 2, pp. 109–127, 1996.
[8] S. M. Smith, “Fast robust automated brain extraction,” Human brain
mapping, vol. 17, no. 3, pp. 143–155, 2002.
[9] D. W. Shattuck and R. M. Leahy, “Brainsuite: an automated cortical
surface identiﬁcation tool,” Medical image analysis, vol. 6, no. 2, pp.
129–142, 2002.
[10] A. Delora, A. Gonzales, C. S. Medina, A. Mitchell, A. F. Mohed, R. E.
Jacobs, and E. L. Bearer, “A simple rapid process for semi-automated
brain extraction from magnetic resonance images of the whole mouse
head,” Journal of neuroscience methods, vol. 257, pp. 185–193, 2016.
[11] S. F. Eskildsen, P. Coup´e, V. Fonov, J. V. Manj´on, K. K. Leung,
N. Guizard, S. N. Wassef, L. R. Østergaard, D. L. Collins, A. D. N.
Initiative et al., “Beast: brain extraction based on nonlocal segmentation
technique,” NeuroImage, vol. 59, no. 3, pp. 2362–2373, 2012.
[12] F. J. Galdames, F. Jaillet, and C. A. Perez, “An accurate skull stripping
method based on simplex meshes and histogram analysis for magnetic
resonance images,” Journal of neuroscience methods, vol. 206, no. 2,
pp. 103–119, 2012.
[13] W. Speier, J. E. Iglesias, L. El-Kara, Z. Tu, and C. Arnold, “Robust
skull stripping of clinical glioblastoma multiforme data,” in Interna-
tional Conference on Medical Image Computing and Computer-Assisted
Intervention.
Springer, 2011, pp. 659–666.
[14] H. Hwang, H. Z. U. Rehman, and S. Lee, “3d u-net for skull stripping
in brain mri,” Applied Sciences, vol. 9, no. 3, p. 569, 2019.
[15] S. Hahn, S. Oberbauer, R. Gebauer, N. Grulke, O. Lange, and J. Ten-
hunen, “Vegetation structure and aboveground carbon and nutrient pools
in the imnavait creek watershed,” in Landscape function and disturbance
in Arctic tundra.
Springer, 1996, pp. 109–128.
[16] M. Moshfeghi, “Elastic matching of multimodality medical images,”
CVGIP: Graphical Models and Image Processing, vol. 53, no. 3, pp.
271–282, 1991.
[17] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks
for biomedical image segmentation,” in International Conference on
Medical image computing and computer-assisted intervention. Springer,
2015, pp. 234–241.
[18] M. Modat, J. McClelland, and S. Ourselin, “Lung registration using
the niftyreg package,” Medical image analysis for the clinic-a grand
Challenge, vol. 2010, pp. 33–42, 2010.
[19] N. Malpica, C. O. De Sol´orzano, J. J. Vaquero, A. Santos, I. Vallcorba,
J. M. Garc´ıa-Sagredo, and F. Del Pozo, “Applying watershed algorithms
to the segmentation of clustered nuclei,” Cytometry: The Journal of the
International Society for Analytical Cytology, vol. 28, no. 4, pp. 289–
297, 1997.
[20] G. Bradski, “The OpenCV Library,” Dr. Dobb’s Journal of Software
Tools, 2000.
[21] P. Y. Simard, D. Steinkraus, J. C. Platt et al., “Best practices for
convolutional neural networks applied to visual document analysis.” in
Icdar, vol. 3, no. 2003, 2003.
[22] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
arXiv preprint arXiv:1412.6980, 2014.
[23] S. Wang, Y. Hua, Y. Cao, T. Song, Z. Xue, X. Gong, G. Wang,
R. Ma, and H. Guan, “Deep learning based fetal middle cerebral
artery segmentation in large-scale ultrasound images,” in 2018 IEEE
International Conference on Bioinformatics and Biomedicine (BIBM).
IEEE, 2018, pp. 532–539.
",missing,doc9,"—Removing skull artifacts from functional magnetic
images (fMRI) is a well understood and frequently encountered
problem. Because the fMRI ﬁeld has grown mostly due to human
studies, many new tools were developed to handle human data.
Nonetheless, these tools are not equally useful to handle the
data derived from animal studies, especially from rodents. This
represents a major problem to the ﬁeld because rodent studies
generate larger datasets from larger populations, which implies
that preprocessing these images manually to remove the skull
becomes a bottleneck in the data analysis pipeline. In this study,
we address this problem by implementing a neural network based
method that uses a U-Net architecture to segment the brain
area into a mask and removing the skull and other tissues from
the image. We demonstrate several strategies to speed up the
process of generating the training dataset using watershedding
and several strategies for data augmentation that allowed to
train faster the U-Net to perform the segmentation. Finally, we
deployed the trained network freely available.
Index Terms—neural network, deep learning, fMRI, rodent,
brain extraction, skull stripping, MRI, U-Net
I.","A deep learning based tool for automatic brain extraction from functional magnetic resonance images in rodents Sidney Pontes-Filho∗,†, Annelene Gulden Dahl‡, Stefano Nichele∗and Gustavo Borges Moreno e Mello∗,§ ∗Department of Computer Science, Oslo Metropolitan University, Oslo, Norway †Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway ‡Kavli Institute for Systems Neuroscience, Norwegian University of Science and Technology, Trondheim, Norway §Department of Mech., Elec. and Chem. Engineering, Oslo Metropolitan University, Oslo, Norway Email: gustavom@oslomet.no Abstract INTRODUCTION Functional magnetic imaging (fMRI) has emerged as a powerful tool to investigate functional networks in the brain. Because fMRI is a non-invasive technology, the ﬁeld has primarily been driven by its application to the study of the human brain. Consequently, great advances in automating analysis of fMRI data through tools that improve its speed and efﬁciency have been achieved to process human data, saving both time and costs associated with fMRI studies. However, efforts to either modify preexisting tools, or develop similar tools for use on rodent datasets are lagging. Currently, one of the most time consuming steps in the processing of rodent fMRI data is the process of brain ex- traction or skull stripping. This step consists of segmenting the whole brain, which is equivalent to removing all non- cerebral tissue, including the skull, nose, mouth, ears, and muscles [1]. Accurate extraction of the brain is essential to ensure that fMRI data of all the subjects in the study are anatomically aligned, which is necessary to allow for reliable statistical comparison across large cohorts of animals [2]–[6]. Because skull stripping is a well understood problem [7] and a necessity in every fMRI analysis, the development of tools to automatise and increase the speed and reliability of results might have a great positive impact into fMRI research. Rodent’s brain extraction poses additional challenges when compared to segmenting the human brains from fMRI data. Rodents have a smaller gap between the brain and the skull, resulting in a less clear edge demarcation than in humans. Additionally, the rodent brain differs in shape, texture, size and proportion from the human brain. This means that the automated tools developed to handle human data such as Brain Extraction Toolkit (BET) [8] and BrainSuites Brain Surface Extractor (BSE) [9] usually fail to process images of rodent brains. Therefore, brain extraction of rodent anatomical and functional data is predominantly carried out manually. This process involves researchers going slice-by-slice through the acquired (anatomical and functional) images in all three dimensions and manually drawing masks for the brain using a mouse or a tablet. A tool to efﬁciently extract the brain from rodent anatomical images was recently published [10]. This tool takes as input one representative brain from the study and its manually created brain mask, and uses this information to carry out the brain extraction of the remaining subjects in the study. While this is a great tool for extracting the brains in the anatomical images, it is not intended for use in functional datasets, and there is, to the best of our knowledge, no equivalent tool available for extracting the brain from the functional dataset. In order to observe the changing activity of the brain over time, the functional datasets have to be acquired at a much greater speed than the anatomical images, resulting in a much lower spatial resolution than the anatomical images. To preserve the sensitivity to blood-oxygenation-level-dependent (BOLD) contrast the images are also frequently subject to severe susceptibility-induced distortions, in particular, in the back of the brain near ear canals and sinuses. Due to these confounds, skull extraction of functional rodent images commonly fails, and the current state-of-the-art in the ﬁeld of rodent imaging is to manually draw the masks. This process is both time- consuming and often inaccurate, contributing to a less-than- arXiv:1912.01359v2 [eess.IV] 6 Dec 2019 perfect alignment of the functional data to the template brain. To overcome this obstacle, we have developed a deep learning-based tool in Python that quickly and successfully extracts the brain from the functional datasets, thus improving the speed and accuracy of the preprocessing pipeline. The tool, furthermore, does not require any study-speciﬁc input from the researcher in order to successfully separate brain from non- brain tissue. The tool is freely available online. II. RELATED WORKS In the last three decades, many methods for skull stripping have been proposed [11]–[13], ranging from simple luminance thresholding to 3D-convolutional deep learning techniques [14]. Among them, the most promising are the water-shedding based segmentation [1], the Brain Extraction Tool (BET) [8] and the most recent 3D-U-Net [14]. Watershed based methods are image processing pipelines originally described in [15] that are advantageous for being unsupervised, fast, and easy to tune; they leverage luminance gradients to deﬁne regions of interest that can be deﬁned either as brain or non-brain. BET, on the other hand, uses a malleable model, where a spherical mesh is initialized at the center of mass and then expanded towards the surface of the brain; locally adaptive model forces based on local intensity values guide this process, allowing BET to quickly segment the brain. The caveat is that BET has a spherical (human) brain assumption, and has irregular performance with oblong elliptical shaped brains, such as rodent brains. Finally, 3D-U-Net is a promising robust method- ology that uses convolutional neural networks to perform semantic binary segmentation. This method has the advantage of being able to learn from experts by mapping spacial features of the raw fMRI image to ground-truth data generated by manual segmentation. Because of the need for coregistration and alignment in the z-axis, this method cannot beneﬁt from several of the data augmentation methods available, such as elastic transformations [16], [17], thus requiring much more data than the standard U-Net [17]. All of these methods were developed to handle human fMRI data, and regardless of the great levels of performance achieved by the previously cited methods, a solution to reliably perform skull stripping in rodent data is still missing. The solutions to particularly handle rodent fMRI data use more modest technologies. More often than not, skull stripping is still done by creating hand-drawn masks and only occasionally helped by semi-automation tools such as BrainSuite’s Brain Surface Extractor (BSE) [9] which pro- duces an initial mask that subsequently needs to be reﬁned and corrected by hand. Beyond BSE other two automation method categories are available, warping to brain atlas based methods, and surface template based methods [10]. Both methods are built extending the NiftyReg software package [18]; and both dependent on the warping of the image to a template coordinate map, or on warping a mask to the raw image through a series of afﬁne and non-linear transfor- mations. These methods produce excellent results on high- resolution anatomical images, but due to the lower spatial resolution and image distortions in the functional datasets the automated skull stripping methods currently available fail to perform correctly on rodent functional images. Hence, the brain extraction problem in functional images from rodent data has yet to be solved satisfactorily in a generic and robust way. III. METHODS A. Image acquisition 62 fMRI datasets from 31 McGill-R-thy-App rats were acquired on a 7T Biospec 70/30 (Bruker BioSpin) preclin- ical scanner, equipped with an actively shielded 660 mT/m BGA12S HP gradient set (Bruker) in combination with a quadrature surface coil (Bruker BioSpin). Aspin-echo EPI sequence was used with the following parameters: 600 repeti- tions (total scan time of 30 min each) with 2 segments, TE= 20ms, repetition time (TR) = 1.5s for a full-volume acquisition of 3s., ﬁeld-of-view (FOV) of 20x20mm, matrix size 80x80, 55 dummy scans, ﬂip angle of 90 degrees. Seventeen slices were acquired in rostro-caudal direction for a ﬁnal resolution of 250 x 250 x 1000um. All procedures were approved by the Norwegian Food Safety Authority as well as the local Animal Welfare Committee of the Norwegian University of Science and Technology (NTNU). All animals were housed and handled according to the Norwegian laws and regulations concerning animal welfare and animal research. Experimental protocols were approved by the Norwegian Animal Research Authority (FOTS application number 11932) and were in accordance with the European Convention for the Protection of Vertebrate Animals used for Experimental and Other Scientiﬁc Purposes. B. Training dataset and Watershedding-based brain segmen- tation Due to the success of the watershedding algorithm to segment the brain in human fMRI dataset [19], we used it as a semi-automated approach to generate a dataset of masks that were used to train the neural network to segment the brain from the skull. Watershedding is a region-based approach that considers the target structure as a homogeneous region which is determined by a search process guided by appropriate criteria for homogeneity. We implemented the watershedding segmentation by using functions in OpenCV [20] to preprocess the images by gray-scaling, mean-shifting and normalizing them. Once the images were considered suitable for seg- mentation, we thresholded the gray-scaled image into masks, calculated their basin gradients, ﬁltered these gradients, and identiﬁed the segmented areas as connected components. As result, the watershed method provides per each image a series of masks for each structure in each image. The gradient of an image function f is the vector constituted by the partial derivatives in each image dimension. The gradient’s direction is the direction of steepest descent and a magnitude (mag) is the length of the gradient vector. For an image function in R2, f(x, y) the magnitude of the gradient is calculated as mag(▽f) = s (δf δx)2 + (δf δy )2. To choose the mask that represented the brain structure, we leveraged the regularities in the data. Because in this dataset the brain was always very close to the center, this meant that the average polar radial distance between each point of the brain structure mask and the center of the image was shorter than any other structure. Thus, we used this as the criterion to exclude other structures. The parameters for this process were chosen manually and the results followed by close supervised eye-inspection. Nonetheless, this semi- supervised approach proved to be substantially faster than the manual alternative, because the same parameters could be used for different datasets acquired in similar conditions. C. Deep-Learning-based segmentation In this article, we use a standard U-Net [17] architecture to perform skull stripping from fMRI images of rodents. U-Nets are most often used for semantic segmentation tasks. Beyond performing well on the task, they allow for efﬁcient use of GPU memory, which is an asset for processing big image datasets with many features. This is heavily dependent on the fully convolutional architecture of the U-Net, which enables the extraction of image features at multiple image scales. In the U-Net, different layers capture coarse feature-maps that reﬂect this contextual information about the category and location of objects at multiple scales. These feature-maps are later merged through skip connections to combine coarse- and ﬁne-level dense predictions [17]. The goal of the U-Net neural network architecture is to predict which pixels in the image matrix are to be classiﬁed as brain and which ones are to be classiﬁed otherwise. Thus, the output of the ﬁnal decoder layer is a soft mask (see Fig. 1) that when multiplied to the input image produces the ﬁnal segmented brain region. D. Data Augmentation and Training One major advantage of using the U-Net is that it is possible and simple to use several methods for data augmentation such as resizing, ﬂipping, rotating, and minor translations. These data augmentation strategies increase the performance of the model by increasing the size and variety of the dataset [21]. Additionally, fMRI images often do have distortions and movement artifacts. To improve U-Net’s robustness in face of such artifacts, elastic afﬁne transformations were applied equally to the input image and the target masks. In total, the training and validation datasets were increased by 50% with these slightly deformed images [21]. To speed up training we utilized a U-Net pre-trained to segment pathological structures in human MRI images. In- stead of stochastic gradient descent, we modiﬁed the original optimizer of U-Net to Adam [22] with the learning rate of 0.001. Additionally, the training used batches of 25 images during 1,000 epochs. IV. RESULTS This section presents the quantitative and qualitative results of the deep learning neural network for our task of segmenting Fig. 1. Soft masks examples: The left column represents the input image. The right column illustrates the mask prediction for three different coronal slices of a rodent’s . rodents’ brains. Table I contains the quantitative results of binary cross-entropy (BCE) loss, accuracy, F1 score, precision and recall on the validation dataset of 49 images (5 % of our dataset). All these values show that our model segments almost all pixels that contain the brain (98.3 % recall) with precision of 98.5 %. The F1 score is a metric that combines recall and precision. The accuracy represents the percentage of correct answers for the pixels predicted as part of the brain or not. Such value is high and it is 99.35 %. Those measurements suggest that the model performance is excellent. TABLE I VALIDATION RESULTS OF THE BEST (LOWEST) LOSS. Measurement Value BCE loss 0.01562267541885376 Accuracy 0.9935703277587891 F1 Score 0.9843953251838684 Precision 0.9854521751403809 Recall 0.9833407998085022 (a) (b) (c) (d) (e) (f) Fig. 2. Validation results. Green line represents the ground truth and red line is the predicted region. The same model that obtained the best BCE loss on vali- dation dataset has 6 out of its 49 results depicted in Fig. 2. In general, the model performs well to segment the rodent’s brain in an fMRI. There is one validation result which has a small mistake in the segmentation. That is depicted in Fig 2e and it has a small predicted region on the right side of the image which means that the model predicted a “second” tiny brain. Despite that, the qualitative and qualitative results are impressive. V. DISCUSSION Much of what is known in neuroscience is derived from studies using rodent models, due to its versatility and the large selection of methods (e.g., invasive methods) available to study them. On the other hand, much of what is known about the human brain is derived from MRI and fMRI studies. Thus, fMRI holds the promise of bridging the gap between what we know about the mammalian brain. It may provide evidence to generalize results from rodent-derived studies using electrophysiology, optical, and pharmacological methods to the human model. In this context, it is important to create powerful tools that can increase the speed and the reliability of the analysis performed on data derived from rodent models and can equally be applied to human data. In this article we made a step towards democratizing deep learning tools to the neuroscience community by successfully applying a U-Net to perform skull stripping of low resolution functional magnetic resonance images from rodents. The method was quick to train, required little data due to the usage of data augmentation techniques, and qualitatively performed reasonably well. In contrast to other approaches that depend on images with high-resolution images or deformations of initial masks, U- Nets work well with low resolution images and can segment distorted images, even with motion artifacts. Additionally, by using a network that operates on images as inputs instead of a 3D tensor with all the image slices at once, we could use data augmentation strategies without major problems with respect to alignment issues. However, we recognize that U- Net may not be the best nor the fastest architecture to perform semantic segmentation. Other topologies such as Albunet, or Ternausnet [23] might deploy better segmentation at higher speeds. Additionally, because fMRI has a temporal component, recursive layers could be added to take the dynamic nature of the signal in the brain as a feature to better segment and remove the skull, perhaps even in a non-supervised manner. Consequently, a logical step is to explore how more modern architectures could perform in this task. We hope this tool helps neuroscientists to reduce time in preprocessing steps of their analysis of fMRI data in non-human models. ACKNOWLEDGMENT The two authors, Annelene Gulden Dahl and Sidney Pontes- Filho contributed equally to the work. We also thank Stefano Nichele for the comments on the manuscript. This work was supported by Norwegian Research Council SOCRATES project (grant number 270961) and received internal support as a lighthouse project in Computer Vision from the Faculty of Technology, Art and Design (TKD) at Oslo Metropolitan University, Norway. REPOSITORY Code and example data can be found in the following repository: REFERENCES [1] H. K. Hahn and H.-O. Peitgen, “The skull stripping problem in mri solved by a single 3d watershed transform,” in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2000, pp. 134–143. [2] S. Spring, J. P. Lerch, and R. M. Henkelman, “Sexual dimorphism revealed in the structure of the mouse brain using three-dimensional magnetic resonance imaging,” Neuroimage, vol. 35, no. 4, pp. 1424– 1433, 2007. [3] E. L. Bearer, X. Zhang, D. Janvelyan, B. Boulat, and R. E. Jacobs, “Re- ward circuitry is perturbed in the absence of the serotonin transporter,” Neuroimage, vol. 46, no. 4, pp. 1091–1104, 2009. [4] D. A. Vousden, J. Epp, H. Okuno, B. J. Nieman, M. van Eede, J. Dazai, T. Ragan, H. Bito, P. W. Frankland, J. P. Lerch et al., “Whole-brain mapping of behaviourally induced neural activation in mice,” Brain Structure and Function, vol. 220, no. 4, pp. 2043–2057, 2015. [5] X. Zhang, E. L. Bearer, B. Boulat, F. S. Hall, G. R. Uhl, and R. E. Jacobs, “Altered neurocircuitry in the dopamine transporter knockout mouse brain,” PloS one, vol. 5, no. 7, p. e11506, 2010. [6] M. C. van Eede, J. Scholz, M. M. Chakravarty, R. M. Henkelman, and J. P. Lerch, “Mapping registration sensitivity in mr mouse brain images,” Neuroimage, vol. 82, pp. 226–236, 2013. [7] T. Kapur, W. E. L. Grimson, W. M. Wells III, and R. Kikinis, “Segmen- tation of brain tissue from magnetic resonance images,” Medical image analysis, vol. 1, no. 2, pp. 109–127, 1996. [8] S. M. Smith, “Fast robust automated brain extraction,” Human brain mapping, vol. 17, no. 3, pp. 143–155, 2002. [9] D. W. Shattuck and R. M. Leahy, “Brainsuite: an automated cortical surface identiﬁcation tool,” Medical image analysis, vol. 6, no. 2, pp. 129–142, 2002. [10] A. Delora, A. Gonzales, C. S. Medina, A. Mitchell, A. F. Mohed, R. E. Jacobs, and E. L. Bearer, “A simple rapid process for semi-automated brain extraction from magnetic resonance images of the whole mouse head,” Journal of neuroscience methods, vol. 257, pp. 185–193, 2016. [11] S. F. Eskildsen, P. Coup´e, V. Fonov, J. V. Manj´on, K. K. Leung, N. Guizard, S. N. Wassef, L. R. Østergaard, D. L. Collins, A. D. N. Initiative et al., “Beast: brain extraction based on nonlocal segmentation technique,” NeuroImage, vol. 59, no. 3, pp. 2362–2373, 2012. [12] F. J. Galdames, F. Jaillet, and C. A. Perez, “An accurate skull stripping method based on simplex meshes and histogram analysis for magnetic resonance images,” Journal of neuroscience methods, vol. 206, no. 2, pp. 103–119, 2012. [13] W. Speier, J. E. Iglesias, L. El-Kara, Z. Tu, and C. Arnold, “Robust skull stripping of clinical glioblastoma multiforme data,” in Interna- tional Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2011, pp. 659–666. [14] H. Hwang, H. Z. U. Rehman, and S. Lee, “3d u-net for skull stripping in brain mri,” Applied Sciences, vol. 9, no. 3, p. 569, 2019. [15] S. Hahn, S. Oberbauer, R. Gebauer, N. Grulke, O. Lange, and J. Ten- hunen, “Vegetation structure and aboveground carbon and nutrient pools in the imnavait creek watershed,” in Landscape function and disturbance in Arctic tundra. Springer, 1996, pp. 109–128. [16] M. Moshfeghi, “Elastic matching of multimodality medical images,” CVGIP: Graphical Models and Image Processing, vol. 53, no. 3, pp. 271–282, 1991. [17] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for biomedical image segmentation,” in International Conference on Medical image computing and computer-assisted intervention. Springer, 2015, pp. 234–241. [18] M. Modat, J. McClelland, and S. Ourselin, “Lung registration using the niftyreg package,” Medical image analysis for the clinic-a grand Challenge, vol. 2010, pp. 33–42, 2010. [19] N. Malpica, C. O. De Sol´orzano, J. J. Vaquero, A. Santos, I. Vallcorba, J. M. Garc´ıa-Sagredo, and F. Del Pozo, “Applying watershed algorithms to the segmentation of clustered nuclei,” Cytometry: The Journal of the International Society for Analytical Cytology, vol. 28, no. 4, pp. 289– 297, 1997. [20] G. Bradski, “The OpenCV Library,” Dr. Dobb’s Journal of Software Tools, 2000. [21] P. Y. Simard, D. Steinkraus, J. C. Platt et al., “Best practices for convolutional neural networks applied to visual document analysis.” in Icdar, vol. 3, no. 2003, 2003. [22] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” arXiv preprint arXiv:1412.6980, 2014. [23] S. Wang, Y. Hua, Y. Cao, T. Song, Z. Xue, X. Gong, G. Wang, R. Ma, and H. Guan, “Deep learning based fetal middle cerebral artery segmentation in large-scale ultrasound images,” in 2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE, 2018, pp. 532–539.","—Removing skull artifacts from functional magnetic images (fMRI) is a well understood and frequently encountered problem. Because the fMRI ﬁeld has grown mostly due to human studies, many new tools were developed to handle human data. Nonetheless, these tools are not equally useful to handle the data derived from animal studies, especially from rodents. This represents a major problem to the ﬁeld because rodent studies generate larger datasets from larger populations, which implies that preprocessing these images manually to remove the skull becomes a bottleneck in the data analysis pipeline. In this study, we address this problem by implementing a neural network based method that uses a U-Net architecture to segment the brain area into a mask and removing the skull and other tissues from the image. We demonstrate several strategies to speed up the process of generating the training dataset using watershedding and several strategies for data augmentation that allowed to train faster the U-Net to perform the segmentation. Finally, we deployed the trained network freely available. Index Terms—neural network, deep learning, fMRI, rodent, brain extraction, skull stripping, MRI, U-Net I.","['Sidney Pontes-Filho', 'Annelene Gulden Dahl', 'Stefano Nichele', 'Gustavo Mello', 'Gustavo Mello']"
Genetic Algorithms For Tightening Security,"Palumbo, Fabrizio and Buji, Adam and Yazidi, Anis and Haugerud, Hårek",2022,missing,missing,missing,inproceedings,"Genetic Algorithms For Tightening Security
1stFabrizio Palumbo
Artiﬁcial Intelligence Lab (AI Lab),
Institutt for informasjonsteknologi
Oslo Metropolitan University, Oslo, Norway
fabrizio@oslomet.no
2nd Adam Buji
Artiﬁcial Intelligence Lab (AI Lab),
Institutt for informasjonsteknologi
Oslo Metropolitan University, Oslo, Norway
Adam.buji@hotmail.no
3rd Anis Yazidi
Artiﬁcial Intelligence Lab (AI Lab),
Institutt for informasjonsteknologi
Oslo Metropolitan University, Oslo, Norway
Anis.Yazidi@oslomet.no
4th H˚arek Haugerud
Artiﬁcial Intelligence Lab (AI Lab),
Institutt for informasjonsteknologi
Oslo Metropolitan University, Oslo, Norway
Harek.Haugerud@oslomet.no
Abstract INTRODUCTION
A. Background
The last two decades of the 21st century experienced an in-
crease in the penetration and expansion of digital technologies.
With the decrease in Internet access’ costs and information
processing, more people are using computers and they expect
a quality of service (QoS) compatible with the QoS they are
used to getting with other utilities [1].
This service is expected to be available continuously, from
anywhere at any time, secure, friendly, and reliable. People
expect to log on to the terminal, read mails, make reservations,
and do other activities, and with wireless technology, people
can access the Internet from anywhere [1].
Web technologies have evolved rapidly in the last ﬁve
years through web-enabled applications where browsers have
become the user interface. Critical functions are done through
web applications, such as money transactions, which make
web applications attractive targets for hackers [2].
The system can therefore be made more difﬁcult to ex-
ploit with better awareness, stronger operating systems, and
improved security defense. There is a need for a better
understanding of web applications’ security since the attackers
have moved from attacking the network layer to attacking the
application layer [1].
Web applications use the HTTP protocol over the internet by
using a web browser which makes it possible to access web
applications from anywhere [3]. However, Web applications
have bugs in their code that make them vulnerable and they
can compromise the system. These vulnerabilities are greater
in web applications than in other applications.
More speciﬁcally, the operations in a software are controlled
by a set of parameters such as the settings of the operating
system or the ﬁle permissions. These parameters affect both
the operating system and the application performance and
have therefore implications for the security posture of the
system [4]. Some conﬁguration parameters affect the security
individually and some do in combination with others.
Many cyber attacks are preceded by a search for vulnerabili-
ties within the network, often caused by a network misconﬁgu-
ration. Such threats can therefore be eliminated by tuning the
correct combination of parameters. Some operating systems
offer solutions to prevent security vulnerabilities. However,
there is a need for a low-cost method to conﬁgure network
parameters in order to prevent and defuse cyber attacks.
Genetic Algorithms (GA), a class of heuristic searching
algorithms, are applied in this article to discover new, secure,
and diverse parameter conﬁgurations by modeling a computer
conﬁguration as chromosomes, and the individual settings
conﬁgurations as alleles. The basic idea behind GA is: good
chromosomes will generate better chromosomes through a
series of selection, crossover, and mutation processes. These
processes are stochastic, ensuring therefore a high degree
of diversity in the outputs. Additionally, a population of
chromosomes can then continuously evolve to become more
and more secure in the current environment.
To improve protection against cyber attacks, a continuous
change of computer or program parameters conﬁguration can
mislead the attacker. The GA will ideally have changed the
conﬁgurations before the attacker is able to launch his attack,
turning obsolete the previously discovered vulnerabilities.
ISBN 978-3-903176-52-2© 2022 IFIP
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
62
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 Therefore, GA can signiﬁcantly improve cyber security by
changing the parameters’ conﬁgurations and increasing their
ﬁtness score.
B. Previous Work
A crucial characteristic, that any cyber security defense
algorithm needs to posses, is the capability to adapt to new
emerging threats and depending on the situation to choose
the best reactive action possible. The concept of learning has
therefore been applied already in the earliest form of the
autonomous defense system, being inspired by reinforcement
learning algorithms [5] and from biology itself, taking as
examples the immune system [6] and the defensive mutualism
in microbial symbiosis [7]. However, also cyber attackers can
learn and adapt over time [8]. As a consequence traditional
static defense techniques (i.e. ﬁrewall) are not successful
anymore [9]. The moving target (MT) defense approach has
therefore emerged and proved successful in increasing network
security [9]–[13]. The overall concept of MT is the following:
the machine conﬁguration changes as a function of time so
that it is more complicated for an attacker to exploit previously
identiﬁed weak conﬁgurations. Importantly, deploying learning
algorithms within the MT strategy can improve drastically
security by learning over time what parameter conﬁgurations
are particularly susceptible to cyber attacks [9]–[13]. The idea
of deploying evolutionary algorithms in the moving target
defense was already introduced in the early 2010s [14]–[17].
GA can play a crucial role in identifying new solutions in the
parameters conﬁguration space that would be more and more
resilient to cyber-attacks over time. The Works of Smith [18]
and Zhou [19] show that an evolutionary strategy is a powerful
approach when defending against cyber-attacks. Smith ﬁrst
investigates the application of GA to learn secure parameter
conﬁgurations, also called chromosomes, and to implement
the moving target defense (MT) strategy. A computer’s ge-
netic code, or DNA, includes all the settings of all of its
parameters. GA then evolves, over iterations/generations, more
secure conﬁgurations which are then used to immunize the
machine to attacks. In his work, Smith [18] also implements
a beam search-based system to select which chromosomes
are inherited across generations. This approach outperformed
GA in increasing average conﬁguration ﬁtness while still
maintaining high diversity. Experimentation showed that a
prototype system using these strategies, for a small number
of attacks per generation, was often successful in creating a
new generation of chromosomes that were immune to attacks
from the previous generation [18] [19]. Additionally, it is also
introduced the idea that the efﬁciency of GA is improved by
using machine learning to classify generated solutions and
ﬁltering the sub-optimal low ﬁtness conﬁgurations [18] [19].
Software conﬁguration consists of parameters and through
them, it is possible to control aspects of the system. Therefore,
a misconﬁgured software, by a single parameter or a combina-
tion of parameters, exposes the system to vulnerabilities. The
huge number of parameters makes it hard to identify vulner-
able settings that can be attacked. Moreover, combinations of
settings might cause hidden vulnerabilities, complicating the
problem.
A ﬁrst solution to the problem exploits the identiﬁcation
of common features across vulnerable conﬁgurations. In her
Ph.D. thesis, Dr.Oddell [20] developed a method to detect
security-relevant parameters. By analyzing conﬁgurations that
are vulnerable to the same exploit and comparing the similarity
of their parameters it is possible to highlight the ones that are
vulnerable to a speciﬁc attack. Genetic Algorithms are then
used to generate the conﬁgurations used for the identiﬁcation
of vulnerable parameters.
Another approach is based on the time of the incorrect
function of a system, which can be caused by errors in its
conﬁguration. In [21], the authors address the problem of
diagnosing conﬁguration errors. For example, changing the
local ﬁrewall policy could cause a network-based application
to malfunction. This approach searches the time point at
which the system transitioned into malfunctioning. The cause
of the failure is then identiﬁed by comparing the system
conﬁguration before and after the malfunction. Whitaker et
al [21] implement a tool called Chronus to reduce the need
for human expertise. Chronus automates the search for failure-
inducing state changes and identiﬁes the conﬁguration errors.
However, this tool requires, among other utils, user-written
software to ﬁnd out if the system is currently working and
only then ﬁnds the error.
A ﬁnal approach is presented by Zhang et al. [22]
and it is implemented in the tool called EnCore. EnCore
detect software misconﬁguration by taking into account the
correlations between conﬁguration entries and their interaction
with the executing environment. Encore consists of four steps;
data collecting, data assembling, rule generator, and anomaly
detection. It is able to learn a broad set of conﬁguration
anomalies that span the entire system and detect real-world
problems as well as injected errors.
The work presented in this article builds on previous
research and aims to improve on its weaknesses as follow:
• By using real parameters for each conﬁguration, allowing
us to replicate possible machine misconﬁgurations lead-
ing to attack vulnerability.
• By directly simulate attackers targeting the system, al-
lowing us to directly test the security level.
II. METHODS
This article uses Apache v2.2 conﬁguration parameters as
deﬁned in STIG [23], which stands for Security Technical
Implementation Guides. The STIG was developed by The
Defense Information Systems Agency in order to implement
conﬁguration guidelines for systems that are deployed across
the Department of Defense. The scores are based on the CVSS
scoring system [24], according to the results of the test code.
In this article, a part of the Apache v2.2 conﬁguration was
used as proof of the GA concept and its capability of ﬁnding
the ﬁttest solution.
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
63
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 DiSA’s Security Technical Implementation Guides gather all
conﬁguration parameters that contribute to known vulnerabil-
ity attack paths.
STIG provides a network administrator with an explanation
on how these conﬁgurations can contribute to a vulnerability
and how it can be ﬁxed [23].
A. Genetic algorithm server
The chromosomes represent a conﬁguration’s combination
of parameters. The size of each chromosome is based on the
conﬁgurations’ parameters, where one allele or more represent
a parameter. In this research, the chromosome size is 25 and
the total number of chromosomes in one generation is 40,
which is enough to keep the parameters’ diversity according
to the number of parameters. The number of solutions in one
generation has been determined after many experiments of the
algorithm. It is possible to increase the number of chromo-
somes in one generation; this might increase the diversity, but
at the same time it would cost more computational resources.
All parameters are represented as a binary presentation, so
the parameter that needs to be integers is converted to integers
while converting the chromosomes into conﬁgurations. The
parameters represented as ”element from a list” are also
converted from binary to element from a list while converting
the chromosome into a conﬁguration.
Two algorithms have been developed and a total of four
scripts have been used.
• The genetic algorithm will generate security solutions.
• The ﬁtness score algorithm is responsible for providing
the genetic algorithm with the ﬁtness scores of the secu-
rity solutions. The scoring system relies on previous pref-
erences from STIG which provides the vulnerabilities, the
parameters responsible for them, and the solutions.
In the beginning, the ﬁrst chromosomes are initiated ran-
domly using a uniform distribution, and then saved to the
population’s pool.
In a Multi-point crossover, two or more random values
are selected and at these selected points, the variables are
exchanged between the individuals as shown in Figure 1.
Fig. 1. multi-points crossover
The experiments presented in Figure 2 and 3 show that
the multi-point crossover is more effective than the single-
point crossover because it increases the probability of the new
chromosomes getting the ﬁt parts of both parents [25].
If we consider the following two individuals with 10 binary
variables in each and the selected points are(4,7):
chromosome 1
0 1 1 0 →010→011
chromosome 2
0 0 1 0 →100→101
The generated new chromosomes would be:
chromosome 3
0 1 1 0 →100→011
chromosome 4
0 0 1 0 →010→101
Fig. 2. Single crossover
Fig. 3. Multi-point crossover
After executing the crossover function it is necessary to
run a mutation process in order to prevent the algorithm from
being trapped in a local minimum. The mutation is an operator
which maintains genetic diversity within the population. The
mutation process introduces a new genetic structure into the
population by modifying some of the alleles. [25].
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
64
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 In this article, binary representatives were used, so the
mutation process was done by ﬂipping a random allele in the
chromosome to the opposite value as shown in the following
example:
If we consider the following two individuals with 10 binary
variables in each and the selected allele location is 5:
chromosome 1
0 1 1 0 —0 — 1 0 0 1 1
In the mutation process, it would ﬂip the value from 0 to
1, so the generated new chromosome would be:
chromosome 2
0 1 1 0 —1 — 1 0 0 1 1
After executing the crossover and mutation process, the
algorithm divides the existing solutions in the population’s
pool between the available docker containers in the farm. This
is done to compute the ﬁtness scores and select the ﬁttest
solutions of the whole population. We then select the best n
solutions for further mating and to produce the next generation.
When the algorithm sends the solutions to the web servers,
it makes sure it sends them only to available web servers. It
checks their availability before sending the solutions in order
to avoid any future errors, and ensure that all the solutions are
tested as planned. After sending the solutions to VM’s farm,
the algorithm opens a port temporarily to receive the scores
for each solution. After receiving all the scores, the algorithm
selects the n ﬁttest solutions for further mating.
The algorithm runs 40 generations and the experiments
show that 40 generations are good enough to reach a solution
close to the optimal ﬁtness. However, the generation number
can be increased in case of the need to improve a more
complex chromosome to optimize the solution.
B. Reconﬁguring the Apache server
The Genetic Algorithm generates solutions and sends them
to the VMs farm which then applies those conﬁgurations to
the Apache server in order to execute the automated attacks.
The VM receives the solutions as a list and through an agent
script, it translates the list into conﬁgurations and then applies
them to the Apache server.
C. Quality of service
It is important to make sure that a good QoS is maintained
while tightening the security.
The QoS was measured by the total used time for the
following processes: Lookup time, Connect time, Pre-transfer
time, and Start-transfer time. The total used time was measured
by running the ”curl” command while pressing the web
server using ”httperf” on two web servers; one web server
with the ﬁttest conﬁguration, and another with a vulnerable
conﬁguration. The experiments on both web servers were done
under the same conditions which contain six load stress levels.
The experiment was run 10,000 tests/webpage requests on
each web server on every stress load level which makes it
60,000 tests/webpage requests in total on each web server,
where each level had a different load rate generated by httperf
tool, and is this explained in more detail later.
III. RESULTS
A. Security solutions
In this article we show experimentally, by using real pa-
rameter conﬁgurations and simulated cyber-attacks, that evolu-
tionary algorithms represent a powerful tool to improve cyber
security.
The experiments were conducted using conﬁgurations of 24
Apache 2.2 parameters.
We show that by using GA it is possible to improve system
security over the course of generations. Through iterations
of trial and error, we identify that the best performance was
achieved by:
• using a population size consisting of 50 individuals.
• running for 40-45 generations.
• One or two genes are modiﬁed in every mutation, using
elitism as the deterministic tournament selection, and
using a two-point crossover.
The start point solution was initialized randomly. In the
documented experiment, the initialized solution was 1035.2
when using a one-point crossover, and it was 1011.6 when
using a two-point crossover. The ﬁttest solution was 1490.0
when using a one-point crossover and 1584.2 when using a
two-point crossover as shown in Figure 4.
The experiment shows maintenance of diversity which is
required in order to ensure the solution space is checked
thoroughly enough, especially in the earlier stages of the
process. Population diversity is considered to be the main
reason for premature convergence.
The experiment also shows that the diversity was high in
the start and it became lower and lower in the later stages,
as shown in Figure 5. The results also show that crossover
types signiﬁcantly impacted ﬁtness or diversity in this article,
as shown in Figure 2 and Figure 3.
A high diversity in the population generates a different
solution from generation to generation implementing a moving
target defense. This results in wasting the attacker’s reconnais-
sance effort by changing the conﬁgurations continuously until
reaching the ﬁttest solution possible.
To quantify the impact of our approach on the QoS for the
user, we focus on the total time used between establishing a
connection and data transfer, as shown in 6. The mean value
of the total time of all test levels for the web server with
the ﬁttest conﬁguration was 0.004062783, while for the web
server with the vulnerable conﬁguration was 0.002006883.
Therefore, using the ﬁttest conﬁguration solution increase the
time necessary to send the requested page, compared to the
vulnerable solution.
B. Fitness score
This article investigates the role of the GA in improving
cyber security. We deﬁne a ﬁtness value for each chromosome,
as an estimate for security. Those values were then used to
select conﬁgurations with higher ﬁtness values.
The ﬁrst scores were decided according to randomly gen-
erated chromosomes, which varied from one experiment to
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
65
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 Fig. 4. Security solution’s evolving
Fig. 5. Diversity
another. Then, the GA performed the selection based on those
scores. Crossovers also used the same scores to decide which
chromosome moves forward, which are based on random
selection and affect the evolution process.
The mutation process took place after the crossover with
randomly selected candidates preventing the algorithm to fall
into local minima.
The scoring system was built over the course of three
experiments:
• An ofﬂine scoring system based on information from the
STIG database.
• An online-scoring system based on the OWASP vulner-
ability scanning
• Real-life attacks were executed on both the most vulner-
able solution and the ﬁttest solution
The GA successfully generated a more secure conﬁguration
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
66
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 Fig. 6. Security impact on QoS of webserver
that was not vulnerable to real-life attacks.
The QoS is an important factor to consider while improving
the security solution. The conducted experiment shows that
tightening the security does affect the QoS.
The experiment reported in Figure 6 and Table 1 shows a
signiﬁcantly longer time required for secure conﬁguration to
start transferring once a connection is established. The average
time used by the ﬁttest conﬁguration was 0.004062783, while
the average time used by the vulnerable conﬁguration was
0.002006883 which is a signiﬁcant difference.
Fittest
solution
Vulnerable
solution
Mean
0.004062783
0.002006883
Standard Deviation
0.004011096
0.001806554
Total tests
60000
60000
Variance
1.60889E-05
3.26364E-06
Table 1. Security impact on QoS of webserver
More investigation and experiments are required in the QoS
area to make a concrete analysis. Time constraints made it
impossible to conduct a more thorough investigation in this
article.
The total ﬁtness (100%) in this article was deﬁned as:
• the conﬁguration ﬁtness (70%)
• Moving target success (10%)
• the 2 attacks experiments’ success (10%)
• the QoS ﬁtness (10%)
The Conﬁguration’s ﬁtness was calculated according to the
expected highest ﬁtness (1700), and the ﬁttest solution was
1584.2. The moving target was calculated according to the
change in every ﬁve generations: a change in the conﬁguration
in every ﬁve generations is considered a ﬁnding. The 2attacks
score was deﬁned by the success or failure of the two
cyber attack strategies tested: Denial of service and buffer
overﬂow. The QoS ﬁtness was calculated according to how
many of the 60000 tests still got a comparable response time
between the case of the ﬁttest security solution and the case
of a vulnerable solution (<0.006s), which was 45620 in the
conducted experiments.
f(TFitness) =
!
ConfScore +
!
MovingTargetScore
+
!
2AttacksScore +
!
QoSScore
(1)
f(TFitness) = 65, 2 + 10 + 10 + 7.6
(2)
TotalFitness = 92.8%
(3)
IV. DISCUSSION
This article shows that GA can contribute to reducing sys-
tem vulnerabilities by detecting and solving misconﬁguration.
The GA evolves ﬁtter solutions within every iteration, reducing
vulnerabilities over generations.
Vulnerabilities caused by human misconﬁguration are hard
to ﬁnd manually, due to the huge number of parameters, and it
is even harder to ﬁnd the right chain of parameters. However,
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
67
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 GA can automate this process and provide more and more
accurate solutions over the course of generations.
The implemented algorithm aims to ﬁnd the ﬁttest conﬁg-
uration in Apache 2.2 server, ﬁxing the vulnerabilities caused
by human misconﬁguration. This algorithm can then replace
manual human work which is impossible to consider due to
time constrain.
The GA manages to reach the ﬁttest solution possible
through 40 generations, ﬁnding the correct parameters and the
correct chain of parameters.
The GA preserves diversity within each generation and
maintain a diverse solution from generation to generation. This
is particularly important since it can mislead an attacker that
has done reconnaissance between the generations.
A. Fitness
The main objective of this article is to reach the ﬁttest
solution through the use of GA. The ﬁtness function showed
ﬂexibility in a constantly changing environment. The ﬁtness
of the chromosome is based on a discovered security concern
that has been run through the penetration test. The test sends
back the security level of each chromosome with the goal to
reach as few vulnerabilities as possible.
The CVSS score of a parameter setting, which has been
used to score the security, is based on the effect it might cause
on information security such as conﬁdentiality, integrity, and
availability.
The scoring system starts with simulated attacks, based on
information from STIG. In the second step, the scoring system
is developed to run a vulnerability scanning using OWASP,
showing results close to the simulated attacks. Finally, the
security level is tested through real-life attacks, showing results
as expected.
B. Moving target
Implementing a moving target defense strategy is an ob-
jective of this article. It protects from attacks by changing
parameter conﬁgurations continuously, so in case the attacker
did his reconnaissance, it would be non-effective because
of the change in the conﬁguration. Diversity is therefore an
important factor during the evolution process to implement a
moving target defense within each generation.
Keeping the diversity of high-quality conﬁgurations is
important within the moving target strategy since different
conﬁgurations are applied on a number of machines.
The difference between the ﬁtness of two different solutions
in one generation represents the diversity within a generation.
The diversity from generation to generation is calculated by
looking at the differences between the ﬁttest solution in the
generation and the following generation.
In this article, the diversity is maintained across generations
which implements a moving target defense until the ﬁttest
solution possible is reached. This misleads an attacker in case
of conﬁguration reconnaissance. The diversity also prevented
the algorithm from falling into a local minimum, which helped
it to evolve the ﬁttest solution.
C. Quality of Service
Improving security is an important factor, but at the same
time, it should be parallel with having good QoS. In this
article, the QoS was investigated in order to see if there is any
noticeable relation between security and QoS. The conducted
experiments do show a negative impact on the QoS when
improving security, in terms of total used time between when a
connection was established and when the data actually began
to be transferred. The impact was measured while the web
server was under continuous stress of HTTP requests load. The
average used time, from starting the connection to starting the
data transfer, signiﬁcantly increase for server conﬁgurations
with tighter security.
V. CONCLUSION
The objective of this article is to improve the security so-
lutions by applying the genetic algorithm to the conﬁguration
parameters of Apache2.2. The genetic algorithm is applied
successfully allowing the conﬁgurations to evolve to be diverse
and more secure over generations. Additionally, this approach
also allows for a moving target defense by changing the
conﬁguration from generation to generation until reaching the
ﬁttest solution possible.
Vulnerabilities can be caused by a misconﬁguration or by
an unlucky chain of conﬁgurations. This is difﬁcult or even
impossible for the system administrator to discover manually
due to the huge amount of parameters, and big amount of
possible combinations. Therefore, a Genetic Algorithm was
used to ﬁnd more secure conﬁgurations. Conﬁgurations were
represented as chromosomes and the GA took those through
a series of selection, crossover, and mutation processes which
resulted in more secure conﬁgurations across each generation.
The results demonstrate the performance of the evolu-
tionary approach for managing conﬁgurations consisting of
24 parameters from Apache 2.2. The simulated attacks of
these conﬁgurations are based on information from the STIG
database. The genetic algorithm discovers better parameter
settings for the attacked parameters in each generation.
At the ﬁrst stages, the solution ﬁtness improves signiﬁcantly.
A reasonable level of diversity is maintained. It starts with a
high level of diversity because the parameters are randomly
initialized. In the late stages, the ﬁtness improvement decrease
alongside a decrease in diversity.
The experiment showed that the diversity within the gener-
ation maintained the ability to have a diverse conﬁguration
from generation to generation. Changing the conﬁguration
from generation to generation creates a moving target that
misleads an attacker based on reconnaissance.
In terms of security, this experiment demonstrates resilience.
As an added contribution of this paper, the genetic algo-
rithm manages to ﬁnd the ﬁttest solution possible, which helps
prevent attacks caused by a misconﬁguration or by a poor
chain of parameters. This is considered to be a new concept
in improving security.
As an added contribution of this paper, the genetic algo-
rithm helps prevent attacks by spoiling an attacker‘s recon-
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
68
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
 naissance efforts by continuously changing the conﬁguration.
A series of changes in the conﬁguration from generation to
generation makes it possible to enhance security by deploying
a moving target defense.
As an added contribution of this paper, the investigation
of the relationship between security and QoS shows that the
security level has a signiﬁcant impact on the QoS. Improved
security results in a longer time delay between establishing
the connection and the start of data transfer. This might be
a reasonable price to pay for having a higher security level.
However, to be more concrete about the impact of this delay
on the QoS, it is recommended that further investigation -as
future work- covering other areas in QoS are conducted.
REFERENCES
[1] Y. Liao, V. Vemuri, Enhancing computer security with smart technology
(2006).
[2] A. Tsalgatidou, T. Pilioura, An overview of standards and related
technology in web services, Distributed and Parallel Databases 12 (2-3)
(2002) 135–162.
[3] R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P. Leach,
T. Berners-Lee, Hypertext transfer protocol–http/1.1, Tech. rep. (1999).
[4] J. Oberheide, E. Cooke, F. Jahanian, If it ain’t broke, don’t ﬁx it:
Challenges and new directions for inferring the impact of software
patches., in: HotOS, 2009.
[5] L. Beaudoin, Autonomic computer network defence using risk states
and reinforcement learning, 2009.
[6] S.
Hofmeyr,
S.
Forrest,
Architecture
for
an
artiﬁcial
immune
system,
Evolutionary
computation
8
(2000)
443–73.
doi:10.1162/106365600568257.
[7] S. Stolfo, Symbiotes and defensive Mutualism: Moving Target Defense,
2011, pp. 99–108. doi:10.1007/978-1-4614-0977-9 5.
[8] M. L. Winterrose, K. M. Carter, Strategic evolution of adversaries against
temporal platform diversity active cyber defenses, ADS ’14, Society for
Computer Simulation International, San Diego, CA, USA, 2014.
[9] E. W. Fulp, H. D. Gage, D. J. John, M. R. McNiece, W. H. Turkett,
X. Zhou, An evolutionary strategy for resilient cyber defense, in: 2015
IEEE Global Communications Conference (GLOBECOM), 2015, pp.
1–6. doi:10.1109/GLOCOM.2015.7417814.
[10] M. Carvalho, R. Ford, Moving-target defenses for computer networks,
IEEE Security Privacy 12 (2) (2014) 73–76. doi:10.1109/MSP.2014.30.
[11] P. Pal, R. Schantz, A. Paulos, B. Benyo, D. Johnson, M. Hibler, E. Eide,
A3: An environment for self-adaptive diagnosis and immunization of
novel attacks, in: 2012 IEEE Sixth International Conference on Self-
Adaptive and Self-Organizing Systems Workshops, 2012, pp. 15–22.
doi:10.1109/SASOW.2012.13.
[12] P. Pal, R. Schantz, A. Paulos, B. Benyo, Managed execution environment
as a moving-target defense infrastructure, IEEE Security Privacy 12 (2)
(2014) 51–59. doi:10.1109/MSP.2013.133.
[13] D.
J.
Musliner,
J.
M.
Rye,
D.
Thomsen,
D.
D.
McDonald,
M. H. Burstein, P. Robertson, Fuzzbuster: Towards adaptive immu-
nity from cyber threats, in: 2011 Fifth IEEE Conference on Self-
Adaptive and Self-Organizing Systems Workshops, 2011, pp. 137–140.
doi:10.1109/SASOW.2011.26.
[14] M. Crouse, E. W. Fulp, A moving target environment for computer
conﬁgurations using genetic algorithms, in: Conﬁguration Analytics and
Automation (SAFECONFIG), 2011 4th Symposium on, IEEE, 2011, pp.
1–7.
[15] M. Crouse, E. W. Fulp, D. Canas, Improving the diversity defense of
genetic algorithm-based moving target approaches, in: Proceedings of
the National Symposium on Moving Target Research, 2012.
[16] D. J. John, R. W. Smith, W. H. Turkett, D. A. Ca˜nas, E. W. Fulp,
Evolutionary based moving target cyber defense, in: Proceedings of
the Companion Publication of the 2014 Annual Conference on Genetic
and Evolutionary Computation, GECCO Comp ’14, Association for
Computing Machinery, New York, NY, USA, 2014, p. 1261–1268.
doi:10.1145/2598394.2605437.
URL https://doi.org/10.1145/2598394.2605437
[17] D. Zegzhda, D. Lavrova, E. Pavlenko, A. Shtyrkina, Cyber attack pre-
vention based on evolutionary cybernetics approach, Symmetry 12 (11).
doi:10.3390/sym12111931.
URL https://www.mdpi.com/2073-8994/12/11/1931
[18] R. W. Smith, Evolutionary strategies for secure moving target conﬁgu-
ration discovery, Ph.D. thesis, Wake Forest University (2014).
[19] X. Zhou, Measurements associated with learning more secure computer
conﬁguration parameters, Ph.D. thesis, Wake Forest University (2015).
[20] C. A. Odell, Using genetic algorithms to detect security related software
parameter chains, Ph.D. thesis, Wake Forest University (2016).
[21] A. Whitaker, R. S. Cox, S. D. Gribble, Conﬁguration debugging as
search: Finding the needle in the haystack., in: OSDI, Vol. 4, 2004,
pp. 6–6.
[22] J. Zhang, L. Renganarayana, X. Zhang, N. Ge, V. Bala, T. Xu, Y. Zhou,
Encore: Exploiting system environment and correlation information for
misconﬁguration detection, ACM SIGPLAN Notices 49 (4) (2014) 687–
700.
[23] [Accessed Mars. 08 2017] (Mars 2017). [link].
URL https://www.stigviewer.com/
[24] [link].
URL https://www.first.org/cvss/specification-document
[25] S. Sivanandam, S. Deepa, Introduction to genetic algorithms, Springer
Science & Business Media, 2007.
2022 14th IFIP Wireless and Mobile Networking Conference (WMNC)
69
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore.  Restrictions apply. 
",10.23919/WMNC56391.2022.9954297,doc7,"—Proper conﬁguration of operating systems and pro-
gram parameters is known to be a key security factor in order
to remove vulnerabilities. It is known that vulnerabilities can
be caused by a human misconﬁguration or by an improper
chain of parameter settings. It is impossible to ﬁnd an optimal
combination manually due to the enormous number of possible
conﬁgurations. In this article, we resort to a Genetic Algorithm
equipped with a user-deﬁned ﬁtness function in order to compute
a conﬁguration of high ﬁtness.
Our work presents a two-fold contribution. First, we suc-
cessfully use a GA to implement a moving target defense by
alerting the conﬁguration regularly in order to spoil an attacker’s
reconnaissance efforts. The GA tightens the security solution
by evolving the ﬁtness of the conﬁguration over generations
while maintaining diversity within generations across a pool of
servers. This resulted in high-quality conﬁgurations crucial for
a successful moving target defense strategy.
Second, we try to ﬁnd a compromise between tightening the
security of the conﬁguration and maintaining the Quality of
Service (QoS) on a web server. In practice, usually tightening
security on a web server comes at the cost of a decrease in QoS.
I.","Genetic Algorithms For Tightening Security 1stFabrizio Palumbo Artiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi Oslo Metropolitan University, Oslo, Norway fabrizio@oslomet.no 2nd Adam Buji Artiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi Oslo Metropolitan University, Oslo, Norway Adam.buji@hotmail.no 3rd Anis Yazidi Artiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi Oslo Metropolitan University, Oslo, Norway Anis.Yazidi@oslomet.no 4th H˚arek Haugerud Artiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi Oslo Metropolitan University, Oslo, Norway Harek.Haugerud@oslomet.no Abstract INTRODUCTION A. Background The last two decades of the 21st century experienced an in- crease in the penetration and expansion of digital technologies. With the decrease in Internet access’ costs and information processing, more people are using computers and they expect a quality of service (QoS) compatible with the QoS they are used to getting with other utilities [1]. This service is expected to be available continuously, from anywhere at any time, secure, friendly, and reliable. People expect to log on to the terminal, read mails, make reservations, and do other activities, and with wireless technology, people can access the Internet from anywhere [1]. Web technologies have evolved rapidly in the last ﬁve years through web-enabled applications where browsers have become the user interface. Critical functions are done through web applications, such as money transactions, which make web applications attractive targets for hackers [2]. The system can therefore be made more difﬁcult to ex- ploit with better awareness, stronger operating systems, and improved security defense. There is a need for a better understanding of web applications’ security since the attackers have moved from attacking the network layer to attacking the application layer [1]. Web applications use the HTTP protocol over the internet by using a web browser which makes it possible to access web applications from anywhere [3]. However, Web applications have bugs in their code that make them vulnerable and they can compromise the system. These vulnerabilities are greater in web applications than in other applications. More speciﬁcally, the operations in a software are controlled by a set of parameters such as the settings of the operating system or the ﬁle permissions. These parameters affect both the operating system and the application performance and have therefore implications for the security posture of the system [4]. Some conﬁguration parameters affect the security individually and some do in combination with others. Many cyber attacks are preceded by a search for vulnerabili- ties within the network, often caused by a network misconﬁgu- ration. Such threats can therefore be eliminated by tuning the correct combination of parameters. Some operating systems offer solutions to prevent security vulnerabilities. However, there is a need for a low-cost method to conﬁgure network parameters in order to prevent and defuse cyber attacks. Genetic Algorithms (GA), a class of heuristic searching algorithms, are applied in this article to discover new, secure, and diverse parameter conﬁgurations by modeling a computer conﬁguration as chromosomes, and the individual settings conﬁgurations as alleles. The basic idea behind GA is: good chromosomes will generate better chromosomes through a series of selection, crossover, and mutation processes. These processes are stochastic, ensuring therefore a high degree of diversity in the outputs. Additionally, a population of chromosomes can then continuously evolve to become more and more secure in the current environment. To improve protection against cyber attacks, a continuous change of computer or program parameters conﬁguration can mislead the attacker. The GA will ideally have changed the conﬁgurations before the attacker is able to launch his attack, turning obsolete the previously discovered vulnerabilities. ISBN 978-3-903176-52-2© 2022 IFIP 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 62 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. Therefore, GA can signiﬁcantly improve cyber security by changing the parameters’ conﬁgurations and increasing their ﬁtness score. B. Previous Work A crucial characteristic, that any cyber security defense algorithm needs to posses, is the capability to adapt to new emerging threats and depending on the situation to choose the best reactive action possible. The concept of learning has therefore been applied already in the earliest form of the autonomous defense system, being inspired by reinforcement learning algorithms [5] and from biology itself, taking as examples the immune system [6] and the defensive mutualism in microbial symbiosis [7]. However, also cyber attackers can learn and adapt over time [8]. As a consequence traditional static defense techniques (i.e. ﬁrewall) are not successful anymore [9]. The moving target (MT) defense approach has therefore emerged and proved successful in increasing network security [9]–[13]. The overall concept of MT is the following: the machine conﬁguration changes as a function of time so that it is more complicated for an attacker to exploit previously identiﬁed weak conﬁgurations. Importantly, deploying learning algorithms within the MT strategy can improve drastically security by learning over time what parameter conﬁgurations are particularly susceptible to cyber attacks [9]–[13]. The idea of deploying evolutionary algorithms in the moving target defense was already introduced in the early 2010s [14]–[17]. GA can play a crucial role in identifying new solutions in the parameters conﬁguration space that would be more and more resilient to cyber-attacks over time. The Works of Smith [18] and Zhou [19] show that an evolutionary strategy is a powerful approach when defending against cyber-attacks. Smith ﬁrst investigates the application of GA to learn secure parameter conﬁgurations, also called chromosomes, and to implement the moving target defense (MT) strategy. A computer’s ge- netic code, or DNA, includes all the settings of all of its parameters. GA then evolves, over iterations/generations, more secure conﬁgurations which are then used to immunize the machine to attacks. In his work, Smith [18] also implements a beam search-based system to select which chromosomes are inherited across generations. This approach outperformed GA in increasing average conﬁguration ﬁtness while still maintaining high diversity. Experimentation showed that a prototype system using these strategies, for a small number of attacks per generation, was often successful in creating a new generation of chromosomes that were immune to attacks from the previous generation [18] [19]. Additionally, it is also introduced the idea that the efﬁciency of GA is improved by using machine learning to classify generated solutions and ﬁltering the sub-optimal low ﬁtness conﬁgurations [18] [19]. Software conﬁguration consists of parameters and through them, it is possible to control aspects of the system. Therefore, a misconﬁgured software, by a single parameter or a combina- tion of parameters, exposes the system to vulnerabilities. The huge number of parameters makes it hard to identify vulner- able settings that can be attacked. Moreover, combinations of settings might cause hidden vulnerabilities, complicating the problem. A ﬁrst solution to the problem exploits the identiﬁcation of common features across vulnerable conﬁgurations. In her Ph.D. thesis, Dr.Oddell [20] developed a method to detect security-relevant parameters. By analyzing conﬁgurations that are vulnerable to the same exploit and comparing the similarity of their parameters it is possible to highlight the ones that are vulnerable to a speciﬁc attack. Genetic Algorithms are then used to generate the conﬁgurations used for the identiﬁcation of vulnerable parameters. Another approach is based on the time of the incorrect function of a system, which can be caused by errors in its conﬁguration. In [21], the authors address the problem of diagnosing conﬁguration errors. For example, changing the local ﬁrewall policy could cause a network-based application to malfunction. This approach searches the time point at which the system transitioned into malfunctioning. The cause of the failure is then identiﬁed by comparing the system conﬁguration before and after the malfunction. Whitaker et al [21] implement a tool called Chronus to reduce the need for human expertise. Chronus automates the search for failure- inducing state changes and identiﬁes the conﬁguration errors. However, this tool requires, among other utils, user-written software to ﬁnd out if the system is currently working and only then ﬁnds the error. A ﬁnal approach is presented by Zhang et al. [22] and it is implemented in the tool called EnCore. EnCore detect software misconﬁguration by taking into account the correlations between conﬁguration entries and their interaction with the executing environment. Encore consists of four steps; data collecting, data assembling, rule generator, and anomaly detection. It is able to learn a broad set of conﬁguration anomalies that span the entire system and detect real-world problems as well as injected errors. The work presented in this article builds on previous research and aims to improve on its weaknesses as follow: • By using real parameters for each conﬁguration, allowing us to replicate possible machine misconﬁgurations lead- ing to attack vulnerability. • By directly simulate attackers targeting the system, al- lowing us to directly test the security level. II. METHODS This article uses Apache v2.2 conﬁguration parameters as deﬁned in STIG [23], which stands for Security Technical Implementation Guides. The STIG was developed by The Defense Information Systems Agency in order to implement conﬁguration guidelines for systems that are deployed across the Department of Defense. The scores are based on the CVSS scoring system [24], according to the results of the test code. In this article, a part of the Apache v2.2 conﬁguration was used as proof of the GA concept and its capability of ﬁnding the ﬁttest solution. 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 63 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. DiSA’s Security Technical Implementation Guides gather all conﬁguration parameters that contribute to known vulnerabil- ity attack paths. STIG provides a network administrator with an explanation on how these conﬁgurations can contribute to a vulnerability and how it can be ﬁxed [23]. A. Genetic algorithm server The chromosomes represent a conﬁguration’s combination of parameters. The size of each chromosome is based on the conﬁgurations’ parameters, where one allele or more represent a parameter. In this research, the chromosome size is 25 and the total number of chromosomes in one generation is 40, which is enough to keep the parameters’ diversity according to the number of parameters. The number of solutions in one generation has been determined after many experiments of the algorithm. It is possible to increase the number of chromo- somes in one generation; this might increase the diversity, but at the same time it would cost more computational resources. All parameters are represented as a binary presentation, so the parameter that needs to be integers is converted to integers while converting the chromosomes into conﬁgurations. The parameters represented as ”element from a list” are also converted from binary to element from a list while converting the chromosome into a conﬁguration. Two algorithms have been developed and a total of four scripts have been used. • The genetic algorithm will generate security solutions. • The ﬁtness score algorithm is responsible for providing the genetic algorithm with the ﬁtness scores of the secu- rity solutions. The scoring system relies on previous pref- erences from STIG which provides the vulnerabilities, the parameters responsible for them, and the solutions. In the beginning, the ﬁrst chromosomes are initiated ran- domly using a uniform distribution, and then saved to the population’s pool. In a Multi-point crossover, two or more random values are selected and at these selected points, the variables are exchanged between the individuals as shown in Figure 1. Fig. 1. multi-points crossover The experiments presented in Figure 2 and 3 show that the multi-point crossover is more effective than the single- point crossover because it increases the probability of the new chromosomes getting the ﬁt parts of both parents [25]. If we consider the following two individuals with 10 binary variables in each and the selected points are(4,7): chromosome 1 0 1 1 0 →010→011 chromosome 2 0 0 1 0 →100→101 The generated new chromosomes would be: chromosome 3 0 1 1 0 →100→011 chromosome 4 0 0 1 0 →010→101 Fig. 2. Single crossover Fig. 3. Multi-point crossover After executing the crossover function it is necessary to run a mutation process in order to prevent the algorithm from being trapped in a local minimum. The mutation is an operator which maintains genetic diversity within the population. The mutation process introduces a new genetic structure into the population by modifying some of the alleles. [25]. 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 64 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. In this article, binary representatives were used, so the mutation process was done by ﬂipping a random allele in the chromosome to the opposite value as shown in the following example: If we consider the following two individuals with 10 binary variables in each and the selected allele location is 5: chromosome 1 0 1 1 0 —0 — 1 0 0 1 1 In the mutation process, it would ﬂip the value from 0 to 1, so the generated new chromosome would be: chromosome 2 0 1 1 0 —1 — 1 0 0 1 1 After executing the crossover and mutation process, the algorithm divides the existing solutions in the population’s pool between the available docker containers in the farm. This is done to compute the ﬁtness scores and select the ﬁttest solutions of the whole population. We then select the best n solutions for further mating and to produce the next generation. When the algorithm sends the solutions to the web servers, it makes sure it sends them only to available web servers. It checks their availability before sending the solutions in order to avoid any future errors, and ensure that all the solutions are tested as planned. After sending the solutions to VM’s farm, the algorithm opens a port temporarily to receive the scores for each solution. After receiving all the scores, the algorithm selects the n ﬁttest solutions for further mating. The algorithm runs 40 generations and the experiments show that 40 generations are good enough to reach a solution close to the optimal ﬁtness. However, the generation number can be increased in case of the need to improve a more complex chromosome to optimize the solution. B. Reconﬁguring the Apache server The Genetic Algorithm generates solutions and sends them to the VMs farm which then applies those conﬁgurations to the Apache server in order to execute the automated attacks. The VM receives the solutions as a list and through an agent script, it translates the list into conﬁgurations and then applies them to the Apache server. C. Quality of service It is important to make sure that a good QoS is maintained while tightening the security. The QoS was measured by the total used time for the following processes: Lookup time, Connect time, Pre-transfer time, and Start-transfer time. The total used time was measured by running the ”curl” command while pressing the web server using ”httperf” on two web servers; one web server with the ﬁttest conﬁguration, and another with a vulnerable conﬁguration. The experiments on both web servers were done under the same conditions which contain six load stress levels. The experiment was run 10,000 tests/webpage requests on each web server on every stress load level which makes it 60,000 tests/webpage requests in total on each web server, where each level had a different load rate generated by httperf tool, and is this explained in more detail later. III. RESULTS A. Security solutions In this article we show experimentally, by using real pa- rameter conﬁgurations and simulated cyber-attacks, that evolu- tionary algorithms represent a powerful tool to improve cyber security. The experiments were conducted using conﬁgurations of 24 Apache 2.2 parameters. We show that by using GA it is possible to improve system security over the course of generations. Through iterations of trial and error, we identify that the best performance was achieved by: • using a population size consisting of 50 individuals. • running for 40-45 generations. • One or two genes are modiﬁed in every mutation, using elitism as the deterministic tournament selection, and using a two-point crossover. The start point solution was initialized randomly. In the documented experiment, the initialized solution was 1035.2 when using a one-point crossover, and it was 1011.6 when using a two-point crossover. The ﬁttest solution was 1490.0 when using a one-point crossover and 1584.2 when using a two-point crossover as shown in Figure 4. The experiment shows maintenance of diversity which is required in order to ensure the solution space is checked thoroughly enough, especially in the earlier stages of the process. Population diversity is considered to be the main reason for premature convergence. The experiment also shows that the diversity was high in the start and it became lower and lower in the later stages, as shown in Figure 5. The results also show that crossover types signiﬁcantly impacted ﬁtness or diversity in this article, as shown in Figure 2 and Figure 3. A high diversity in the population generates a different solution from generation to generation implementing a moving target defense. This results in wasting the attacker’s reconnais- sance effort by changing the conﬁgurations continuously until reaching the ﬁttest solution possible. To quantify the impact of our approach on the QoS for the user, we focus on the total time used between establishing a connection and data transfer, as shown in 6. The mean value of the total time of all test levels for the web server with the ﬁttest conﬁguration was 0.004062783, while for the web server with the vulnerable conﬁguration was 0.002006883. Therefore, using the ﬁttest conﬁguration solution increase the time necessary to send the requested page, compared to the vulnerable solution. B. Fitness score This article investigates the role of the GA in improving cyber security. We deﬁne a ﬁtness value for each chromosome, as an estimate for security. Those values were then used to select conﬁgurations with higher ﬁtness values. The ﬁrst scores were decided according to randomly gen- erated chromosomes, which varied from one experiment to 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 65 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. Fig. 4. Security solution’s evolving Fig. 5. Diversity another. Then, the GA performed the selection based on those scores. Crossovers also used the same scores to decide which chromosome moves forward, which are based on random selection and affect the evolution process. The mutation process took place after the crossover with randomly selected candidates preventing the algorithm to fall into local minima. The scoring system was built over the course of three experiments: • An ofﬂine scoring system based on information from the STIG database. • An online-scoring system based on the OWASP vulner- ability scanning • Real-life attacks were executed on both the most vulner- able solution and the ﬁttest solution The GA successfully generated a more secure conﬁguration 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 66 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. Fig. 6. Security impact on QoS of webserver that was not vulnerable to real-life attacks. The QoS is an important factor to consider while improving the security solution. The conducted experiment shows that tightening the security does affect the QoS. The experiment reported in Figure 6 and Table 1 shows a signiﬁcantly longer time required for secure conﬁguration to start transferring once a connection is established. The average time used by the ﬁttest conﬁguration was 0.004062783, while the average time used by the vulnerable conﬁguration was 0.002006883 which is a signiﬁcant difference. Fittest solution Vulnerable solution Mean 0.004062783 0.002006883 Standard Deviation 0.004011096 0.001806554 Total tests 60000 60000 Variance 1.60889E-05 3.26364E-06 Table 1. Security impact on QoS of webserver More investigation and experiments are required in the QoS area to make a concrete analysis. Time constraints made it impossible to conduct a more thorough investigation in this article. The total ﬁtness (100%) in this article was deﬁned as: • the conﬁguration ﬁtness (70%) • Moving target success (10%) • the 2 attacks experiments’ success (10%) • the QoS ﬁtness (10%) The Conﬁguration’s ﬁtness was calculated according to the expected highest ﬁtness , and the ﬁttest solution was 1584.2. The moving target was calculated according to the change in every ﬁve generations: a change in the conﬁguration in every ﬁve generations is considered a ﬁnding. The 2attacks score was deﬁned by the success or failure of the two cyber attack strategies tested: Denial of service and buffer overﬂow. The QoS ﬁtness was calculated according to how many of the 60000 tests still got a comparable response time between the case of the ﬁttest security solution and the case of a vulnerable solution (<0.006s), which was 45620 in the conducted experiments. f(TFitness) = ! ConfScore + ! MovingTargetScore + ! 2AttacksScore + ! QoSScore f(TFitness) = 65, 2 + 10 + 10 + 7.6 TotalFitness = 92.8% IV. DISCUSSION This article shows that GA can contribute to reducing sys- tem vulnerabilities by detecting and solving misconﬁguration. The GA evolves ﬁtter solutions within every iteration, reducing vulnerabilities over generations. Vulnerabilities caused by human misconﬁguration are hard to ﬁnd manually, due to the huge number of parameters, and it is even harder to ﬁnd the right chain of parameters. However, 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 67 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. GA can automate this process and provide more and more accurate solutions over the course of generations. The implemented algorithm aims to ﬁnd the ﬁttest conﬁg- uration in Apache 2.2 server, ﬁxing the vulnerabilities caused by human misconﬁguration. This algorithm can then replace manual human work which is impossible to consider due to time constrain. The GA manages to reach the ﬁttest solution possible through 40 generations, ﬁnding the correct parameters and the correct chain of parameters. The GA preserves diversity within each generation and maintain a diverse solution from generation to generation. This is particularly important since it can mislead an attacker that has done reconnaissance between the generations. A. Fitness The main objective of this article is to reach the ﬁttest solution through the use of GA. The ﬁtness function showed ﬂexibility in a constantly changing environment. The ﬁtness of the chromosome is based on a discovered security concern that has been run through the penetration test. The test sends back the security level of each chromosome with the goal to reach as few vulnerabilities as possible. The CVSS score of a parameter setting, which has been used to score the security, is based on the effect it might cause on information security such as conﬁdentiality, integrity, and availability. The scoring system starts with simulated attacks, based on information from STIG. In the second step, the scoring system is developed to run a vulnerability scanning using OWASP, showing results close to the simulated attacks. Finally, the security level is tested through real-life attacks, showing results as expected. B. Moving target Implementing a moving target defense strategy is an ob- jective of this article. It protects from attacks by changing parameter conﬁgurations continuously, so in case the attacker did his reconnaissance, it would be non-effective because of the change in the conﬁguration. Diversity is therefore an important factor during the evolution process to implement a moving target defense within each generation. Keeping the diversity of high-quality conﬁgurations is important within the moving target strategy since different conﬁgurations are applied on a number of machines. The difference between the ﬁtness of two different solutions in one generation represents the diversity within a generation. The diversity from generation to generation is calculated by looking at the differences between the ﬁttest solution in the generation and the following generation. In this article, the diversity is maintained across generations which implements a moving target defense until the ﬁttest solution possible is reached. This misleads an attacker in case of conﬁguration reconnaissance. The diversity also prevented the algorithm from falling into a local minimum, which helped it to evolve the ﬁttest solution. C. Quality of Service Improving security is an important factor, but at the same time, it should be parallel with having good QoS. In this article, the QoS was investigated in order to see if there is any noticeable relation between security and QoS. The conducted experiments do show a negative impact on the QoS when improving security, in terms of total used time between when a connection was established and when the data actually began to be transferred. The impact was measured while the web server was under continuous stress of HTTP requests load. The average used time, from starting the connection to starting the data transfer, signiﬁcantly increase for server conﬁgurations with tighter security. V. CONCLUSION The objective of this article is to improve the security so- lutions by applying the genetic algorithm to the conﬁguration parameters of Apache2.2. The genetic algorithm is applied successfully allowing the conﬁgurations to evolve to be diverse and more secure over generations. Additionally, this approach also allows for a moving target defense by changing the conﬁguration from generation to generation until reaching the ﬁttest solution possible. Vulnerabilities can be caused by a misconﬁguration or by an unlucky chain of conﬁgurations. This is difﬁcult or even impossible for the system administrator to discover manually due to the huge amount of parameters, and big amount of possible combinations. Therefore, a Genetic Algorithm was used to ﬁnd more secure conﬁgurations. Conﬁgurations were represented as chromosomes and the GA took those through a series of selection, crossover, and mutation processes which resulted in more secure conﬁgurations across each generation. The results demonstrate the performance of the evolu- tionary approach for managing conﬁgurations consisting of 24 parameters from Apache 2.2. The simulated attacks of these conﬁgurations are based on information from the STIG database. The genetic algorithm discovers better parameter settings for the attacked parameters in each generation. At the ﬁrst stages, the solution ﬁtness improves signiﬁcantly. A reasonable level of diversity is maintained. It starts with a high level of diversity because the parameters are randomly initialized. In the late stages, the ﬁtness improvement decrease alongside a decrease in diversity. The experiment showed that the diversity within the gener- ation maintained the ability to have a diverse conﬁguration from generation to generation. Changing the conﬁguration from generation to generation creates a moving target that misleads an attacker based on reconnaissance. In terms of security, this experiment demonstrates resilience. As an added contribution of this paper, the genetic algo- rithm manages to ﬁnd the ﬁttest solution possible, which helps prevent attacks caused by a misconﬁguration or by a poor chain of parameters. This is considered to be a new concept in improving security. As an added contribution of this paper, the genetic algo- rithm helps prevent attacks by spoiling an attacker‘s recon- 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 68 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply. naissance efforts by continuously changing the conﬁguration. A series of changes in the conﬁguration from generation to generation makes it possible to enhance security by deploying a moving target defense. As an added contribution of this paper, the investigation of the relationship between security and QoS shows that the security level has a signiﬁcant impact on the QoS. Improved security results in a longer time delay between establishing the connection and the start of data transfer. This might be a reasonable price to pay for having a higher security level. However, to be more concrete about the impact of this delay on the QoS, it is recommended that further investigation -as future work- covering other areas in QoS are conducted. REFERENCES [1] Y. Liao, V. Vemuri, Enhancing computer security with smart technology . [2] A. Tsalgatidou, T. Pilioura, An overview of standards and related technology in web services, Distributed and Parallel Databases 12 (2-3) 135–162. [3] R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P. Leach, T. Berners-Lee, Hypertext transfer protocol–http/1.1, Tech. rep. . [4] J. Oberheide, E. Cooke, F. Jahanian, If it ain’t broke, don’t ﬁx it: Challenges and new directions for inferring the impact of software patches., in: HotOS, 2009. [5] L. Beaudoin, Autonomic computer network defence using risk states and reinforcement learning, 2009. [6] S. Hofmeyr, S. Forrest, Architecture for an artiﬁcial immune system, Evolutionary computation 8 443–73. doi:10.1162/106365600568257. [7] S. Stolfo, Symbiotes and defensive Mutualism: Moving Target Defense, 2011, pp. 99–108. doi:10.1007/978-1-4614-0977-9 5. [8] M. L. Winterrose, K. M. Carter, Strategic evolution of adversaries against temporal platform diversity active cyber defenses, ADS ’14, Society for Computer Simulation International, San Diego, CA, USA, 2014. [9] E. W. Fulp, H. D. Gage, D. J. John, M. R. McNiece, W. H. Turkett, X. Zhou, An evolutionary strategy for resilient cyber defense, in: 2015 IEEE Global Communications Conference (GLOBECOM), 2015, pp. 1–6. doi:10.1109/GLOCOM.2015.7417814. [10] M. Carvalho, R. Ford, Moving-target defenses for computer networks, IEEE Security Privacy 12 73–76. doi:10.1109/MSP.2014.30. [11] P. Pal, R. Schantz, A. Paulos, B. Benyo, D. Johnson, M. Hibler, E. Eide, A3: An environment for self-adaptive diagnosis and immunization of novel attacks, in: 2012 IEEE Sixth International Conference on Self- Adaptive and Self-Organizing Systems Workshops, 2012, pp. 15–22. doi:10.1109/SASOW.2012.13. [12] P. Pal, R. Schantz, A. Paulos, B. Benyo, Managed execution environment as a moving-target defense infrastructure, IEEE Security Privacy 12 51–59. doi:10.1109/MSP.2013.133. [13] D. J. Musliner, J. M. Rye, D. Thomsen, D. D. McDonald, M. H. Burstein, P. Robertson, Fuzzbuster: Towards adaptive immu- nity from cyber threats, in: 2011 Fifth IEEE Conference on Self- Adaptive and Self-Organizing Systems Workshops, 2011, pp. 137–140. doi:10.1109/SASOW.2011.26. [14] M. Crouse, E. W. Fulp, A moving target environment for computer conﬁgurations using genetic algorithms, in: Conﬁguration Analytics and Automation (SAFECONFIG), 2011 4th Symposium on, IEEE, 2011, pp. 1–7. [15] M. Crouse, E. W. Fulp, D. Canas, Improving the diversity defense of genetic algorithm-based moving target approaches, in: Proceedings of the National Symposium on Moving Target Research, 2012. [16] D. J. John, R. W. Smith, W. H. Turkett, D. A. Ca˜nas, E. W. Fulp, Evolutionary based moving target cyber defense, in: Proceedings of the Companion Publication of the 2014 Annual Conference on Genetic and Evolutionary Computation, GECCO Comp ’14, Association for Computing Machinery, New York, NY, USA, 2014, p. 1261–1268. doi:10.1145/2598394.2605437. URL [17] D. Zegzhda, D. Lavrova, E. Pavlenko, A. Shtyrkina, Cyber attack pre- vention based on evolutionary cybernetics approach, Symmetry 12 . doi:10.3390/sym12111931. URL [18] R. W. Smith, Evolutionary strategies for secure moving target conﬁgu- ration discovery, Ph.D. thesis, Wake Forest University . [19] X. Zhou, Measurements associated with learning more secure computer conﬁguration parameters, Ph.D. thesis, Wake Forest University . [20] C. A. Odell, Using genetic algorithms to detect security related software parameter chains, Ph.D. thesis, Wake Forest University . [21] A. Whitaker, R. S. Cox, S. D. Gribble, Conﬁguration debugging as search: Finding the needle in the haystack., in: OSDI, Vol. 4, 2004, pp. 6–6. [22] J. Zhang, L. Renganarayana, X. Zhang, N. Ge, V. Bala, T. Xu, Y. Zhou, Encore: Exploiting system environment and correlation information for misconﬁguration detection, ACM SIGPLAN Notices 49 687– 700. [23] [Accessed Mars. 08 2017] (Mars 2017). [link]. URL [24] [link]. URL [25] S. Sivanandam, S. Deepa, Introduction to genetic algorithms, Springer Science & Business Media, 2007. 2022 14th IFIP Wireless and Mobile Networking Conference (WMNC) 69 Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 05,2025 at 10:33:35 UTC from IEEE Xplore. Restrictions apply.","—Proper conﬁguration of operating systems and pro- gram parameters is known to be a key security factor in order to remove vulnerabilities. It is known that vulnerabilities can be caused by a human misconﬁguration or by an improper chain of parameter settings. It is impossible to ﬁnd an optimal combination manually due to the enormous number of possible conﬁgurations. In this article, we resort to a Genetic Algorithm equipped with a user-deﬁned ﬁtness function in order to compute a conﬁguration of high ﬁtness. Our work presents a two-fold contribution. First, we suc- cessfully use a GA to implement a moving target defense by alerting the conﬁguration regularly in order to spoil an attacker’s reconnaissance efforts. The GA tightens the security solution by evolving the ﬁtness of the conﬁguration over generations while maintaining diversity within generations across a pool of servers. This resulted in high-quality conﬁgurations crucial for a successful moving target defense strategy. Second, we try to ﬁnd a compromise between tightening the security of the conﬁguration and maintaining the Quality of Service (QoS) on a web server. In practice, usually tightening security on a web server comes at the cost of a decrease in QoS. I.","['Fabrizio Palumbo', 'Adam Buji', 'Anis Yazidi', 'Hårek Haugerud']"
How (not to) Run an AI Project in Investigative Journalism,"M. Fridman, R. Krøvel and F. Palumbo",2023,0.0,0,Journalism Practice,article,"Journalism Practice
ISSN: (Print) (Online) Journal homepage: www.tandfonline.com/journals/rjop20
How (not to) Run an AI Project in Inveﬆigative
Journalism
M. Fridman, R. Krøvel & F. Palumbo
To cite this article: M. Fridman, R. Krøvel & F. Palumbo (04 Sep 2023): How (not to) Run an AI
Project in Investigative Journalism, Journalism Practice, DOI: 10.1080/17512786.2023.2253797
To link to this article:  https://doi.org/10.1080/17512786.2023.2253797
© 2023 The Author(s). Published by Informa
UK Limited, trading as Taylor & Francis
Group
Published online: 04 Sep 2023.
Submit your article to this journal 
Article views: 3867
View related articles 
View Crossmark data
Citing articles: 6 View citing articles 
Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=rjop20
 How (not to) Run an AI Project in Investigative Journalism
M. Fridman
a, R. Krøvel
b and F. Palumbo
a,b
aArtiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi, Oslo Metropolitan University, Oslo,
Norway; bFakultet for samfunnsvitenskap, Institutt for journalistikk og mediefag, Oslo Metropolitan
University, Oslo, Norway
ABSTRACT

KEYWORDS
Data journalism;
investigative journalism;
machine learning; data
science; artiﬁcial intelligence;
trans-disciplinary journalism
Introduction
Artiﬁcial Intelligence (AI) is a broad ﬁeld of computer science that aims to develop intel-
ligent machines capable of performing tasks that typically require human intelligence.
Machine learning is a subset of AI that develops algorithms and statistical models
enabling computers to learn and make predictions or decisions without being explicitly
programmed by humans. AI also includes other approaches such as natural language pro-
cessing, computer vision, expert systems, and robotics, which collectively enable AI
systems to understand, reason, learn, and interact with humans and their environments.
Artiﬁcial intelligence (AI) is being rapidly adopted by news media around the world, to
the point that both the public and the journalists themselves start to wonder whether
“robots will replace journalists” (Miroshnichenko 2018). However, while the adoption of
AI in journalism is accelerating, experiential knowledge about AI applications in
© 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group
This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/
licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly
cited. The terms on which this article has been published allow the posting of the Accepted Manuscript in a repository by the author(s)
or with their consent.
CONTACT R. Krøvel
royk@oslomet.no
JOURNALISM PRACTICE
https://doi.org/10.1080/17512786.2023.2253797
 journalism is lagging. Research on AI in journalism has been mostly qualitative and
focused on a few topics such as data journalism, robotic writing, and news review
(Parratt-Fernández, Mayoral-Sánchez, and Mera-Fernández 2021).
With the advent of digital technology and the explosion of data, it is becoming increas-
ingly important to use AI to support investigative journalism, as traditional methods are
no longer practical. The development of new, often open-source, tools makes solutions
easier and faster to implement and requires fewer specialized resources. In this context,
computers can play a central role in automating repetitive and computationally intensive
processes, enabling journalists to extract information that would otherwise be inaccess-
ible (Beckett 2019). To visualize the growth in automated data handling it´s enough to
consider that the “Pandora Papers”, released by ICIJ and composed of 2.94TB of docu-
ments, is 1700 times as large as the “2010 Wikileaks”, which was 1.7GB (Infographic
2021; Pandora Papers 2021).
Upon examining the current research landscape, it is evident that two main research
strands are prominently featured in the ﬁeld: reports by journalists and/or developers
describing a speciﬁc use case, and research articles based on interviews, surveys, and lit-
erature reviews (Ausserhofer et al. 2017; de-Lima-Santos and Ceron 2022; Stray 2019a).
However, the complex nature of investigative journalism requires alternative and exper-
imental research methodologies that enable researchers to understand and analyse often
novel investigative methodologies. One of the biggest challenges for multidisciplinary
teams working on AI in investigative journalism is to be able to communicate and collab-
orate eﬀectively (Santos and de-Lima-Santos 2022).
This article draws on the insights and experiences gained from participation in four
interdisciplinary teams in which data scientists and journalism researchers collaborated
with investigative journalists on various projects. Our goal is to analyse how interdisciplin-
ary teams can overcome the problems and limitations identiﬁed by researchers such as
Stray (Stray 2019a) and lead to a better inclusion of AI methods in investigative journalism.
By understanding the problems that need to be addressed, this paper aims to develop
better methods for incorporating AI into investigative journalism.
Data Journalism and AI in Journalism
Data journalism is a ﬁeld that incorporates data analysis, visualization, and database use
with traditional journalism practices to uncover and tell stories. Data journalism has made
substantial contributions to society, oﬀering information and insights that have led to
increased transparency, accountability, informed decision-making, and public under-
standing (Bounegru and Grey 2021). Data visualization is a critical aspect, as it helps jour-
nalists present complex information in a simple format (Rodríguez, Nunes, and Devezas
2015). Using data and interactive visualization, data journalism has revealed injustices,
held powerful individuals accountable, and improved the functioning of society and
the lives of citizens (Ausserhofer et al. 2017; Borges-Rey 2016; Bounegru and Grey 2021;
Santos and de-Lima-Santos 2022; Young, Hermida, and Fulda 2018).
There has been a push to include more data science and AI in data journalism. Data
journalism and AI journalism are two diﬀerent approaches to journalism that can
overlap. Data journalism involves the use of statistical methods, data visualization tools,
and other techniques to identify patterns and trends in large datasets, and to present
2
M. FRIDMAN ET AL.
 this information in a way that is accessible to the general public. AI in journalism addition-
ally involves using AI technology to analyze data and discover, develop and publish new
stories. Whereas the most used software by data journalists are Microsoft Excel and
Google Sheets (The State of Data Journalism 2023), data scientists regularly use program-
ming to wrangle and scrape data, improve data cleaning, and create custom analysis and
dynamic interfaces to promote data interaction. They can also use machine learning and
recent AI advances to automate repetitive processes, extract relationships that are hard to
see otherwise and detect newsworthy anomalies (Amazon Mining Watch n.d.). Data jour-
nalists are now more reliant on automation and AI to process and analyse massive data-
sets, and even generate new stories (Challenges and Opportunities – Survey – State of
Data Journalism 2022, n.d.). Florian Stalph identiﬁes four main categories of data journal-
ism: explanatory data journalism, investigative data journalism, interactive data journal-
ism, and advocacy data journalism (Stalph 2018). A similar approach is followed by
Konstantin Nicholas Dörr mapping the ﬁeld of AI journalism into automated news
writing, data-driven journalism, personalized news recommendation, and algorithmic
curation (Dörr 2016). In addition, AI can contribute to journalism by creating visualiza-
tions, verifying the accuracy of statements, analysing historical data, and monitoring
social media (AI and the Future of Journalism n.d.; Hacks/Hackers LDN 2019; Miroshni-
chenko 2018; Weber 2021). However, it is important to view AI as an aid to journalists,
not a replacement. The best outcomes are achieved by combining AI with human exper-
tise and ensuring unbiased and diverse data is used for training.
Data collection is a critical aspect of artiﬁcial intelligence (AI) because AI algorithms
rely on large and diverse datasets to make accurate predictions and decisions. However,
data collection for AI can be problematic due to several reasons. First, it can introduce
bias and discrimination if the collected data reﬂects societal biases or discriminates
against certain groups, leading to unfair outcomes (Buolamwini and Gebru 2018;
Zhao et al. 2018). Second, limited or incomplete data can result in models lacking accu-
racy and reliability (Jain et al. 2020). Moreover, privacy concerns arise when personal
data is collected, stored, and potentially used without consent, posing risks to
privacy and data security (Crawford and Schultz 2014). Ethical considerations are also
important, especially when sensitive information is involved, requiring transparency
and adherence to ethical guidelines (O’Neil 2016). Data quality and pre-processing chal-
lenges, including errors and inconsistencies, can undermine AI model eﬀectiveness.
Data imbalance, where certain groups are underrepresented, can lead to biased
results. Additionally, data ownership and access rights can create barriers to research
and fair competition.
The research into data journalism is an ever-evolving ﬁeld, but a few trends are emer-
ging. Several studies highlight the importance of multidisciplinary teams (Borges-Rey
2016; de-Lima-Santos & Salaverría 2021; Santos and de-Lima-Santos 2022). Collaborations
between journalists, data scientists, and developers to create tailored analyses and data-
wrangling solutions are key to an investigations’ success. Teams that instead have to rely
on readily available free online tools struggle with the lack of customization (Young,
Hermida, and Fulda 2018).
Despite the potential beneﬁts, the adoption of AI in the ﬁeld of investigative journalism
has not been widespread. The cost of implementing new technologies, like AI, in various
industries may be a factor. However, there is potential for AI to reduce costs as well, in the
JOURNALISM PRACTICE
3
 scope of automation and lead generation. In addition, given its potential to recognize pat-
terns and ﬁnd stories that would otherwise stay buried, the cost-beneﬁt analysis cannot
be calculated purely in ﬁnancial terms. This value to society allows such projects to turn to
public funds, philanthropy, and crowdfunding.
Apart from the economical hurdles to incorporating AI and data science into data jour-
nalism, there are also the obstacles inherited from data journalism itself. These challenges
are well explained in a comparative study between the United States and North European
countries (Fink and Anderson 2015). Fink and Anderson summarize the main limiting
factor for data journalism across newsrooms in the lack of: Time, Tools, Manpower and
Legal Resources. They also point out that the role of a data journalist within an organiz-
ation often lacks clear deﬁnition, frequently resulting in them either working in isolation
or being burdened with an overwhelming amount of tasks.
An overview of the pros and cons of AI integration within newsrooms is given by Wu
et al. after conducting interviews with professionals. In their work, they discuss the emer-
gence of automation technologies, such as artiﬁcial intelligence, machine learning, and
natural language processing, and their potential applications in journalism. They
explore how these technologies are being integrated into newsrooms to streamline
workﬂows, generate news content, and personalize news delivery. Some of the potentials
of AI consist of increased eﬃciency, improved accuracy, and enhanced audience engage-
ment through personalized news experiences. At the same time, concerns are related to
job displacement, ethical considerations, and the need for human oversight in the auto-
mated news production (Wu, Tandoc, and Salmon 2019).
Nevertheless, AI journalism can play a crucial role in supporting the role of journalists
as “watchdogs”, to quote Tom Felle (Felle 2016), in providing the public with valuable
information and holding those in power accountable for their actions. Of course, this
comes not without challenges, but by focusing on disclosing sources, methodologies,
and limitations journalists can enable audiences to assess the credibility and reliability
of data-driven news stories (Anderson 2018; Zamith 2019).
Methodology
Parratt-Fernández et al. observe that 60% of academic work on AI applications in journal-
ism utilizes qualitative methods, despite the numerical nature of the subject. While digital
methods are prevalent in digital humanities, they are less common in journalism studies
(Parratt-Fernández, Mayoral-Sánchez, and Mera-Fernández 2021). Sjøvaag and Karlsson
attribute this to a higher threshold for journalism scholars, who often lack the necessary
skills and knowledge to perform automated analysis on large datasets (Karlsson and
Sjøvaag 2016). We have consequently chosen to develop and employ alternative method-
ologies to enrich the existing literature from complementary methodological perspec-
tives. The methodology used in this research is practice-based (Biggs and Büchler 2007;
Vear 2022).
Practice-based research emphasizes the study of real-world problems and practices,
rather than solely theoretical or abstract concepts. In contrast to other methodologies,
practice-based research focuses on understanding how people actually do things,
rather than how they should theoretically do them. This allows us to focus on how inves-
tigative journalists do their job. It is an empirical research method, which is based on the
4
M. FRIDMAN ET AL.
 collection of data through observation, discussion, and other forms of direct engagement:
practitioners and researchers work together to identify research questions, collect data,
and analyse results.
Practice-based research allows journalists and scholars to better understand the
practical implications of new technologies and changing newsroom practices. It is
necessary to bridge the gap between academic research and industry practice
and can lead to the development of more innovative and eﬀective journalism
(Barroca et al. 2018; Biesta 2007). In addition to its beneﬁts for practitioners, prac-
tice-based research also proﬁts academia by helping educators and researchers
stay current with the latest trends and developments in the ﬁeld. This results in
the development of more relevant and eﬀective journalism curricula (Niblock
2007; 2012; Robie 2015).
In designing the methodology of this study, we chose to conduct practice-based
research by collaborating with the Norwegian Association for Investigative Journalism
(Skup.No n.d.). SKUP is a non-proﬁt organization that promotes investigative journalism
in Norway. Together with SKUP, we published a call in May 2021 inviting investigative
journalists to submit projects where we could assist using data science and AI
techniques.
By opening a public call, we allocate ﬁnancial resources to support academic staﬀ
dedicated to 4 projects for a period of 6 months. We encouraged all the Norwegian
newsrooms to submit a project proposal and a committee of both AI and Journalism
academics was appointed to select the 3 best ones. By doing so we encourage Norwe-
gian newsrooms to explore avenues with which they are not familiar and that in
normal circumstances they would have not pursued We received several applications
and for the three selected projects, we dedicated an Associate Professor of Artiﬁcial
Intelligence. Each team was then composed of one academic from OsloMet, one Inves-
tigative Journalist daily collaborating with the AI expert, and a staﬀof supporting
journalists.
In our research approach, the investigative journalists were responsible for deciding
the topic, ﬁnding the initial data sources, formulating the research questions, and inter-
preting the results. The teams had variable compositions in terms of the number of jour-
nalists and experience with data handling. A smaller team of data journalists assisted with
data-related issues. Regular meetings ensured alignment between the data-focused
teams and the journalists. This collaborative approach enabled a targeted use of data
science and AI techniques in investigative journalism.
In 2022, we again selected three new projects and provided similar support.
The collaboration with SKUP not only provided access to experienced investigative
journalists but also ensured that the research had a direct impact on the ﬁeld.
The insights drawn from applying data science and AI techniques to investigative jour-
nalistic questions form the backbone of the present study. The journalistic results were
published in various outlets. Here, we have anonymized identities to maintain conﬁdenti-
ality. Team meetings and Discord channels were utilized to ensure eﬃcient collaboration
among stakeholders. Group meetings were held to identify signiﬁcant learning experi-
ences and analyse ﬁndings considering the existing literature. For the purpose of this
article, we draw on notes and discussions in team meetings and on Discord channel to
reconstruct the research processes.
JOURNALISM PRACTICE
5
 Description of Projects
Project 1
Exploration reimbursement scheme in the petroleum industry. The main goal of this
project was to bring attention to the exploration reimbursement tax scheme in the pet-
roleum industry. The journalists proposed to investigate and combine two publicly avail-
able data sources: the Petroleum Tax Lists (The Norwegian Tax Administration 2020) and
the Norwegian Petroleum Directorate (NPD) Fact pages (NPD Fact Pages n.d.). The goal of
the project was to better understand how companies were accessing and using the
exploration reimbursement scheme, which has been in place since 2005. Additionally,
the project aimed to provide some oversight to the program by mapping oil exploration
activities, documented in the NPD fact pages, to the reimbursement claims in annual
taxes. In the process of this investigation, the idea emerged to deploy graph databases
to represent connections between petroleum companies, reimbursement payments
and drilling licenses.
Project 2
Adverse events in elderly care. The main goal of this project was to better understand how
the quality of elderly care varies across municipalities. The journalists proposed to corre-
late publicly available data recording “non-conformity reports” (NCR) and statistics from
SSB. NCR are gathered at the municipality level and are regulated by the government
guidelines “Norsk kodeverk for uønskede pasienthendelser” (Helsedirektoratet 2021).
The statistics available from SSB describe a wide set of municipality parameters. By corre-
lating these datasets, the project aimed to identify critical factors that contribute to the
occurrence of adverse events in elderly care.
Project 3
Eating disorders in professional skiers. The main goal of this project was to investigate the
occurrence of eating disorders among top athletes. The journalists proposed an innova-
tive approach to solve this problem by using computer vision. The core idea was to take
advantage of the mediatic exposure of the athletes. By collecting public images of the
athletes over time it is possible to infer the body mass index and body fat percentage
and consequently investigate drastic changes over the years.
Project 4
Media landscape analysis. The main goal of this project was to better understand
the Norwegian media landscape. The project started with an exploratory data analy-
sis of a dataset of Norwegian news and blog stories. The dataset collected infor-
mation about the article itself, including title, publisher, authors, and links, as well
as information about its social media engagement. In addition to exploratory analy-
sis, this project grew to track how stories move across both traditional and social
media.
6
M. FRIDMAN ET AL.
 Results
In the ﬁeld of data journalism, the deployment of machine learning (ML) and artiﬁcial
intelligence (AI) algorithms requires a thorough understanding of the necessary data
and the feasibility of obtaining and processing that data. Based on existing literature,
we expected this process to be time-consuming – particularly in investigative journal-
ism projects where there is signiﬁcant complexity in both the questions and societal
structures involved. However, as we experienced, one should carefully consider the
quality and availability of the required data to correctly estimate the feasibility of the
project and its potential outcomes. It is crucial to note that input data of poor
quality will result in equally poor output, regardless of the algorithm’s computational
power.
We found similar diﬃculties and challenges across all of three projects, which we could
broadly categorize using the concepts introduced by Stray (Stray 2019b) as follows:
.
Data availability: Data relevant to a story may not be publicly accessible, data collection
results to be challenging, or the available dataset is incomplete/scattered
.
Data quality: Journalistic inference requires high-accuracy data
.
Newsworthiness: The concept of “newsworthy” is diﬃcult to encode computationally
Data Collection is a Critical Aspect of AI in Journalism
We found that the availability of data was a recurring challenge across all projects. Despite
identifying data sources before the project’s start and therefore expecting that data was
readily accessible, each project encountered diﬃculties in obtaining the necessary data.
The project exploring the reimbursement scheme in the petroleum industry stumbled
across a lack of consistent historical records. Despite the presence of publicly available
data from sources such as the Brønnøysund registry (brreg.no n.d.), historical data for
defunct companies was often missing. This required the purchase of data or the use of
alternative methods for collection. This project also suﬀered from a lack of transparent
data from the side of the tax authorities. While the oil exploration reimbursement
amounts are ostensibly available and published every year by the Norwegian Tax
Oﬃce, these reimbursements are not split between exploration and termination reimbur-
sements. The Norwegian Tax Oﬃce refused to release this information on request,
without which it is impossible to evaluate the success or failure of the exploration reim-
bursement policy. Moreover, the life cycle of a company can be complex and involves
merges and splits, takeovers and name changes. This makes it complicated to track
licenses and understand ﬁnancial ﬂows over time. Petroleum extraction licenses are typi-
cally shared between several companies in alliances that might also change over time. It is
consequently very diﬃcult to reconstruct the timeline of company history and reimburse-
ments without support from experts.
The project which sought to investigate the quality of elderly care in Norway also
encountered challenges in obtaining data. Despite the requirement for municipalities
to keep detailed records of non-conformity reports (NCR) in the elderly care sector, a com-
prehensive analysis of these reports had never been conducted. We discovered that often
the data was missing, unstructured or in hard-to-access formats. There were diﬀerent
JOURNALISM PRACTICE
7
 reasons for this, ranging from a lack of human resources in the municipality to a lack of
digital reporting systems. Privacy issues also prevented data sharing in the case of
small municipalities. Even when the municipality invested signiﬁcant resources to
collect and anonymize the records, the data analysis was not trivial due to the lack of stan-
dardization across municipalities. In the best-case scenario, municipalities sent their data
in the shape of Microsoft Excel spreadsheets. This required extensive eﬀort from the team
to restructure the data in a standard format and sometimes led to data loss. Other muni-
cipalities delivered data in unstructured formats such as PDFs, Word ﬁles or just printed
out on A4 paper, leading to additional challenges wrangling the data into a usable
format. At a later stage, the project intended to correlate the NCR statistics with publicly
available data from the Norwegian Central Bureau of Statistics (SSB) (Statistisk sentralbyrå
2023) to better understand factors contributing to adverse events in elderly care facilities.
SSB maintains updated statistics of many societal parameters; however, historical analysis
of the data was challenging given the complex and frequent changes to the structure of
Norwegian municipalities. Upon request, SSB supported our investigation by allowing our
team to purchase restructured datasets, but these datasets were not provided freely
through their platform. Since then, they have integrated our proposed indexing of the
data in their report system for current and future data. This example shows how the struc-
ture and shareability of the data improved through the interaction between journalists
and data collectors.
These experiences highlight the need for increased transparency and accessibility of
data, particularly regarding business and healthcare. The lack of labeled data when
looking for suspicious activity and the unstructured nature of business annual reports
also presented signiﬁcant obstacles in utilizing AI and ML algorithms. Considering
these challenges, it is crucial to consider the feasibility of obtaining a complete and
high-quality dataset before embarking on investigative journalism projects that involve
data analysis.
Journalism would Beneﬁt from Greater Transparency in Company Structure
In recent years, there has been a growing recognition of the need for greater transparency
in the ﬁnancial ﬂows of companies, particularly in the extractive and ﬁnancial sectors (Sti-
glitz 2002). This is because these sectors are often characterized by complex and opaque
ownership structures (Sachs and Warner 2001). One of the main challenges in uncovering
these ﬁnancial ﬂows is the lack of comprehensive and publicly available data on company
ownership and beneﬁcial ownership (Cobham and Janský 2020). While some countries
have made progress in this area, for example by joining the Extractive Industries Transpar-
ency Initiative (EITI) (Extractive Industries Transparency Initiative n.d.), many countries still
lack comprehensive and publicly available registers.
Additionally, even when data is publicly available, it is often unstructured, on paper
and in a customized format, which makes it challenging to extract information even
with state-of-the-art Object Character Recognition (OCR) algorithms. Furthermore, in
some cases, the companies themselves may be unwilling to disclose information about
their ownership and ﬁnancial ﬂows, making it diﬃcult for investigative journalists to
access the necessary data (Making Transparency Possible 2019). Even when a company
is willing to disclose information, it might be diﬃcult to access it as datasets might be
8
M. FRIDMAN ET AL.
 scattered across multiple platforms and in multiple countries, not to mention privacy
legislations limiting data access (EU Court of Justice Delivers Blow to Beneﬁcial Owner-
ship … 2022).
While investigating the reimbursement scheme in the Norwegian petroleum industry
we experienced how complex and opaque ownership structures are. This is a particularly
illustrative example given that Norway, as a member of EITI, commits to disclose infor-
mation regarding the extractive (Extractive Industries Transparency Initiative n.d.).
There are numerous reasons why investigative journalists, and the news media, might
want to investigate complex and opaque ownership structures in the extractive and
ﬁnancial sectors. First, opaque ownership structure makes it diﬃcult to hold companies
accountable for their actions, especially when it comes to taxes and royalties for the
resources they extract. Several studies suggest that investigative journalism, and other
forms of transparency-promoting activities, can play a critical role in exposing complex
and opaque ownership structures in the extractive and ﬁnancial sectors (Beckett 2019;
Radon and Achuthan 2017). Based on our research, we believe data journalism in this
ﬁeld depends on initiatives such as OpenCorporates (OpenCorporates :: The Open Data-
base Of The Corporate World n.d.) and OpenOwnership (Open Ownership n.d.) to
move the ﬁeld forward. These and other organizations are taking the lead in utilizing
advanced Machine Learning and Graph Databases to analyse complex company struc-
tures and beneﬁcial ownership.
Information is Often not Publicly Accessible
In the case of the investigation of accidents in elderly care, Norwegian municipalities are
obliged to provide data to journalists. However, a signiﬁcant number of municipalities did
not provide the requested information. Various factors can inﬂuence whether municipa-
lities provide requested information to journalists or not. However, as the context can vary
from country to country and region to region, it is important to consider the speciﬁc cir-
cumstances and legal framework of each inquiry. Among the municipalities that did not
provide the data in our investigation, the main reasons cited were a lack of digital records,
on-going lawsuits that prevented the sharing of data and insuﬃcient human resources to
anonymize the data for privacy reasons. In addition, some municipalities simply failed to
respond to the journalist’s requests.
Additionally, there were also challenges in obtaining data from SSB (Statistisk sentral-
byrå 2023) due to the frequent rearrangements of municipalities by the government. Fre-
quent re-organization of municipalities leads to several challenges in terms of data
analysis (Kommunereformen 2020, 2021). Administrative boundary changes can impact
data quality, as data collection and reporting procedures may change, resulting in incon-
sistent or inaccurate data. This makes it diﬃcult to conduct accurate and reliable analyses
of parameters over the years.
In the project employing computer vision for BMI estimation, we negotiated with other
researchers to share their datasets, some of which had been scraped from public sources
like Reddit. While at ﬁrst glance there were multiple approaches, public and shared data-
sets available, we quickly realized that these were not suﬃcient for the uses of the project.
It is therefore important to highlight that it’s not only the quantity of data that is crucial,
but also their relevance to the research question.
JOURNALISM PRACTICE
9
 Given the challenges of limited access to data, it is likely that journalists will need to
invest signiﬁcant resources to obtain the necessary data, as demonstrated by the
examples presented in this article. Strategies such as collaborating with organizations
or individuals who have access to relevant data sets, using publicly available data
sources, or using alternative data sources can help obtain relevant datasets.
Journalistic Inference Requires Very High Accuracy
In the context of our practice-based research, it became clear that the process of journal-
istic inference demands high accuracy. Machine learning algorithms have been devel-
oped to identify patterns and common characteristics within datasets. However, when
it comes to investigative journalism, particularly in the realm of fraud detection, the
goal is to uncover the unusual, events that were not expected to occur. These subtle vari-
ations are crucial to consider, as they do not align with the primary purpose for which ML
and AI algorithms were developed.
Deﬁning what constitutes suspicious or unethical practices within the available
datasets is a diﬃcult task, due to obscure business practices and opaqueness in the
law and interpretation of it. This is perhaps unsurprising, as even cases with extensive
evidence have been ruled legal by the courts (Skattemotiverte transaksjoner – opplys-
ningsplikt og fradragsrett 2020). More fundamentally, even deﬁning what is a
“company” over the years within a landscape of multiple organizations and leadership
structures can be prohibitively complex, as we described in the previous chapter. This
makes it precarious to associate any company or private entity with an accusation of
misconduct.
Our research on the care of the elderly highlighted the diﬃculty in categorizing
events into diﬀerent classes. After evaluating multiple language models, we determined
that accurate quantiﬁcation of all categories could not be guaranteed. Thus, we decided
to focus solely on adverse events related to medicine, which were successfully classiﬁed.
It is important to note that we were not investigating causality in this project, but rather
exploring correlations between variables, which can provide insight into relevant vari-
ables for optimizing the services oﬀered by the municipality. Although it was not poss-
ible to quantify issues and problems related to elderly care within this landscape, our
research aimed to guide the journalist’s investigation towards addressing these issues,
supported by data when the administration or leaders of the municipality were
questioned.
A ﬁnal aspect worth mentioning is the variation in data reporting among municipali-
ties. Our analysis of collected databases revealed that each municipality, depending on
its size and structure, may report data on ﬁnances and human resources with varying
degrees of resolution. This makes the analysis process signiﬁcantly more challenging,
as municipalities may report a single budget for their entire health department while
others may report individual budgets for diﬀerent health departments (home assistance,
hospitals, nursing homes, etc.), making comparisons diﬃcult.
In our study on eating disorders in sports, we ultimately had to abandon the model due
to insuﬃcient accuracy. This serves as a crucial example of why expertise in AI is impor-
tant. A team without suﬃcient knowledge of AI may not have been able to understand
that the model was unreliable and unsuitable for use.
10
M. FRIDMAN ET AL.
 Finally, in the research we did with the fact-checking organization Faktisk.no we did
succeed in identifying certain claims that could be conﬁdently made and relayed,
mainly because they were of a generalized, descriptive and qualitative nature.
Discussion
Data Preparation Tasks
According to Stray (Stray 2019a), data preparation tasks represent a signiﬁcant opportu-
nity for AI to beneﬁt investigative journalism in the short term.
In the context of the petroleum exploration reimbursement investigation, we found
that linking databases and transforming into Graph databases can reveal connections
that were previously unknown, by identifying patterns and relationships within large
amounts of data. This enhances the ability to uncover hidden links between entities
and to build a comprehensive picture of the issue at hand.
In the care for the elderly project, we faced the challenge of merging information from
various data types, including excel sheets, pdf ﬁles, and printed papers. Our research indi-
cates that public bodies should play a role in standardizing data dissemination, similar to
the example set by VG during the COVID-19 pandemic, where the government was
weekly providing updated statistics to the media.
Finally, in our study with the fact-checking organization Faktisk.no, we discovered that
most of the “AI”, speciﬁcally unsupervised machine learning, was used in the pre-proces-
sing steps to cluster similar stories. This step greatly assisted in the later analysis, demon-
strating the potential for AI in improving the eﬃciency of investigative journalism.
Our research supports the ﬁndings of Stray that data preparation tasks are the area
where AI seems to have the most immediate impact on investigative journalism.
However, much research and development are still needed to fully realize the potential
of AI in this ﬁeld and to ensure its ethical and eﬀective application.
Cross-Database Record Linkage
The use of AI in investigative journalism presents signiﬁcant potential for cross-database
record linkage. The ability to link records across databases has the potential to greatly
reduce the time, eﬀort, and costs associated with many investigations while producing
more robust results.
Referential integrity across databases refers to the consistency of relationships
between records in diﬀerent databases. Ensuring referential integrity is important in
ensuring the accuracy of the information being analysed and can greatly assist in connect-
ing records that would have been diﬃcult to link otherwise. However, referential integrity
can be diﬃcult to achieve due to diﬀerences in keys and naming conventions across
databases.
In the context of investigative journalism, referential integrity is crucial when linking
records from various sources. For example, in the investigation of petroleum tax reimbur-
sements, linking tax data with petroleum discovery data can help to hold companies
accountable. However, in some cases we found that companies used diﬀerent organiz-
ation numbers for taxation and licensing purposes, which made linking records
JOURNALISM PRACTICE
11
 diﬃcult. Similarly, in the investigation of care for the elderly, referential integrity across
databases is essential to ensure that information is accurate and correctly linked.
Our practice-based research highlights the potential of AI in facilitating cross-database
record linkage, which could greatly enhance the eﬀectiveness of investigative journalism.
Using the Right Tools Saves Time and Money and Enhances the Results’ Quality
In our investigation, we identiﬁed a multitude of tools that can be adapted and leveraged
for the purpose of investigation. These tools, including Pandas (Pandas - Python Data
Analysis Library n.d.), Seaborn (Waskom 2021), Norwegian language models such as
NorBERT or NoTraM (Web64 2016/2023), zero-shot classiﬁcation (NbAiLab/Nb-Bert-Base-
Mnli Hugging Face 2023), Neo4j (Neo4j Graph Data Platform – The Leader in Graph Data-
bases n.d.), NetworkX (NetworkX — NetworkX Documentation n.d.), and HuggingFace
(Hugging Face – The AI Community Building the Future. n.d.), represent only a selection
of the numerous available options that can be utilized to fulﬁll speciﬁc needs. It is of
utmost importance to have a comprehensive understanding of recent advancements in
AI to make informed decisions when selecting the most appropriate tools and platforms
for a given investigation.
Pandas, a data analysis library in Python, provides eﬃcient storage and manipulation of
tabular data through its data structures. Seaborn, another Python library, oﬀers a high-
level interface for generating informative and visually appealing statistical graphics. NB-
NERT, a Norwegian language model for named entity recognition (NER), can be utilized
to identify named entities in text. Zero-shot classiﬁcation, a machine learning technique,
enables categorization of unseen categories without the need for any additional training
data. Neo4j is a graph database management system designed for the storage and query-
ing of complex networked data. NetworkX, a Python library, enables the creation, manipu-
lation, and analysis of the structure, dynamics, and functions of complex networks. Lastly,
HuggingFace is a natural language processing platform providing access to a wide range
of pre-trained language models, including NER models.
These tools can be employed in a variety of ways to support journalistic investigations.
They can be used to analyze data and generate visualizations to gain a deeper under-
standing of trends and patterns, identify named entities in text, categorize text, store
and query complex networked data, and access pre-trained language models for NER
tasks. In our research project, we invested signiﬁcant resources to support the four pro-
jects. Two associate professors were dedicated to the projects and worked almost full-
time. Three masters students also contributed to the work. Additionally, two other pro-
fessors provided support, including time spent on funding and administrative tasks. All
in all, we estimate that the total cost of the projects was close to $200,000.
The sizes of the projects varied greatly. Two of the projects were large-scale eﬀorts that
involved a substantial team of journalists and developers. At times, each team could
consist of over ten individuals. The cost related to data science and AI was a small
portion of the overall budget for the largest projects, estimated to be less than 10%.
On the other hand, one of the smaller projects had a signiﬁcantly higher proportion of
its budget allocated to data science and AI, approximately half of the total. However, it
should be noted that it is challenging to provide precise estimates as several journalists
and developers worked on multiple projects simultaneously.
12
M. FRIDMAN ET AL.
 The projects presented signiﬁcant challenges in terms of budgeting and resource allo-
cation. The extent of the data pre-processing required was unforeseen and caused unfore-
seen expenses. When evaluating the costs of investment in data science and AI, it is
important to weigh them against the potential beneﬁts. In one instance, having
machine learning experts working on the project prevented the publication of unreliable
results. In another instance, the potential beneﬁts could be measured in terms of improve-
ments to quality of life and longevity. While it is diﬃcult to determine the ﬁnancial returns
of these investigations to the news media, we believe that they hold great promise for
long-term beneﬁt to society.
Importantly, the advent of AI in the media industry is already changing the pro-
fessional proﬁle of the journalist, since they have to manage constantly developing tech-
nologies, an increasing amount of accessible data, fake news generation, and last but
not least, the ethical implications introduced by the use of AI in modern society
(Túñez-López, Fieiras-Ceide, and Vaz-Álvarez 2021). Therefore, appropriate training of
journalists, as well as a productive collaboration with experts in the ﬁelds of AI, is necess-
ary to allow them to automate repetitive tasks and to process large amount of data
eﬃciently so that they can focus on creating high-quality human-crafted journalism
(Noain-Sánchez 2022).
Conclusion
In this study, we applied an interdisciplinary approach to enhance investigative journal-
ism with advanced machine learning and data science techniques. We utilized a variety
of tools, including Pandas, Seaborn, Norwegian language models like NB-BERT, zero-
shot classiﬁcation, Neo4j, NetworkX, and HuggingFace to build applications that made
the investigative process more cost-eﬀective. During the course of this project, we
observed that the landscape of large language models and computer vision was
rapidly changing, with the release of four major neural networks in the latter half of
2022. This trend is likely to continue, with the speed of innovation and openness in the
ﬁeld leading to falling costs of investigative projects.
Based on our experiences, we believe that it is crucial to move beyond interdisciplinary
projects and towards true trans-disciplinary projects. “Trans-disciplinary” refers to a colla-
borative approach that integrates knowledge and skills from multiple disciplines to solve
complex problems and address real-world challenges. It diﬀers from interdisciplinary
teamwork in that it involves active participation and collaboration from all stakeholders
including those outside the ﬁeld of expertise, to ensure that the solutions produced
are holistic and relevant to the real-world context. Additionally, it requires participants
to develop joint theoretical and methodological frameworks to guide the teamwork.
In order to maximize the chances of success we have developed a recommended
workﬂow summarized in Figure 1. We recommend prioritizing projects with well-stated
research questions and a clear hypothesis, while also considering the potential value of
the database itself, even in the absence of a “smoking gun”. Moreover, it is important
to keep in mind that historical data can be missing, incomplete and diﬃcult to interpret,
therefore, we recommend focusing on projects based on recent or current time periods.
Happily, data are becoming increasingly available, thanks to the active contribution of
both private and public bodies, such that hopefully this restriction will diminish with
JOURNALISM PRACTICE
13
 time. Additionally, we suggest using explainable methods and visualization techniques
that are easily understandable to journalists, editors, and the general public.
In addition to the tangible outcomes of these projects in the form of news reports and
documentaries, we also gained valuable insights into the challenges and complexities of
these types of collaborations. We found that the investigations were more productive
when both journalists and AI specialists became literate in each other’s ﬁelds and
Figure 1. Recommended workﬂow to successfully implement and develop an AI Journalism project.
This recommendation is based on the practice and experience of the projects we describe in this
article, and it aims to guide other journalists on how to implement AI in their newsrooms.
Figure 2. Schematic representation of what we envision as trans-disciplinary collaborations between
AI experts and Investigative Journalists. These two professional ﬁgures do not work independently,
but actively collaborate with each other integrating their skills to solve complex problems.
14
M. FRIDMAN ET AL.
 engaged in a mutual learning process, as represented in Figure 2. This highlights the
importance of using existing algorithms, programs, and models, as well as developing
an understanding of the broader range of techniques in AI and data analysis.
Data journalism has emerged as an important ﬁeld in contemporary journalism. The
rise of big data, open data and data visualization technologies have enabled journalists
to leverage data in innovative ways to tell more compelling stories. Data journalism
oﬀers a new way of reporting that is grounded in the analysis of large data sets, and
that allows for the creation of new insights that would not be possible through traditional
reporting methods. In this paper, we explore the role of data journalism in contemporary
journalism and examine the ways in which it is transforming the ﬁeld of journalism.
Acknowledgment
We thank Gustavo Borges Moreno e Mello for the main contribution in establishing the “The AI Jour-
nalism Resource Center” and supporting the group in obtaining the necessary fundings supporting
the work presented in this article. We also thank Morten Goodwin for contributing to the develop-
ment of the projects with stimulating discussions and insight.
Disclosure Statement
No potential conﬂict of interest was reported by the author(s).
Funding
This work was supported by Artiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi,
Oslo Metropolitan University, Oslo, Norway and Fritt Ord Foundation and the Norwegian Directorate
for Higher Education and Skills.
ORCID
M. Fridman
http://orcid.org/0000-0002-3065-8888
R. Krøvel
http://orcid.org/0000-0003-2231-7714
F. Palumbo
http://orcid.org/0000-0002-5571-5420
References
AI and the Future of Journalism. n.d. Accessed September 3, 2021. http://ulam.ai/ai-and-the-future-
of-journalism/.
Amazon Mining Watch. n.d. Accessed February 27, 2023. https://amazonminingwatch.org/en.
Anderson, C. W. 2018. Apostles of Certainty. Vol. 1. Oxford University Press. https://doi.org/10.1093/
oso/9780190492335.001.0001.
Ausserhofer, J., R. Gutounig, M. Oppermann, M. Oppermann, S. Matiasek, and E. Goldgruber. 2017.
“The Dataﬁcation of Data Journalism Scholarship: Focal Points, Methods, and Research
Propositions for the Investigation of Data-Intensive Newswork.” Journalism: Theory, Practice &
Criticism 21: 950–973. https://doi.org/10.1177/1464884917700667.
Barroca, L., H. Sharp, D. Salah, K. Taylor, and P. Gregory. 2018. “Bridging the Gap between Research
and Agile Practice: An Evolutionary Model.” International Journal of System Assurance Engineering
and Management 9 (2): 323–334. https://doi.org/10.1007/s13198-015-0355-5.
Beckett, P. 2019. Ownership, Financial Accountability and the law: Transparency Strategies and
Counter-Initiatives. London: Routledge, Taylor & Francis Group.
JOURNALISM PRACTICE
15
 Biesta, G. 2007. “Bridging the Gap between Educational Research and Educational Practice: The
Need for Critical Distance.” Educational Research and Evaluation 13 (3): 295–301. https://doi.
org/10.1080/13803610701640227.
Biggs, M. A. R., and D. Büchler. 2007. “Rigor and Practice-Based Research.” Design Issues 23 (3): 62–69.
https://doi.org/10.1162/desi.2007.23.3.62.
Borges-Rey, E. 2016. “Unravelling Data Journalism a Study of Data Journalism Practice in British
Newsrooms.” Journalism Practice 10 (7): 833–843. https://doi.org/10.1080/17512786.2016.
1159921.
Bounegru, L., and J. Grey, eds. 2021. The Data Journalism Handbook: Towards a Critical Data Practice.
Amsterdam: Amsterdam University Press.
Brreg.no. n.d. Brønnøysundregistrene. Accessed February 28, 2023. https://www.brreg.no.
Buolamwini, J., and T. Gebru. 2018. “Gender Shades: Intersectional Accuracy Disparities in
Commercial
Gender
Classiﬁcation.”
In
Proceedings
of
the
1st
Conference
on
Fairness,
Accountability and Transparency, edited by S. A. Friedler, and C. Wilson, 77–91. Vol. 81. PMLR.
https://proceedings.mlr.press/v81/buolamwini18a.html.
Challenges and Opportunities – Survey – .State of .Data .Journalism 2022. n.d. Accessed February 28,
2023. https://datajournalism.com/survey/2022/challenges-and-opportunities/.
Cobham, A., and P. Janský. 2020. Estimating Illicit Financial Flows: A Critical Guide to the Data,
Methodologies, and Findings. 1st ed. Oxford University PressOxford. https://doi.org/10.1093/
oso/9780198854418.001.0001
Crawford, Kate, and Jason Schultz. 2014. “Big Data and Due Process: Toward a Framework to Redress
Predictive Privacy Harms.” Boston College Law Review 55: 93. https://ssrn.com/abstract=2325784.
de-Lima-Santos, M.-F., and W. Ceron. 2022. “Artiﬁcial Intelligence in News Media: Current
Perceptions and Future Outlook.” Journalism and Media 3 (1): 13–26. https://doi.org/10.3390/
journalmedia3010002.
De-Lima-Santos, M. F., and R. Salaverría. 2021. “From data journalism to artiﬁcial intelligence: chal-
lenges faced by La Nación in implementing computer vision in news reporting.” Palabra Clave 24
(3).
Dörr, K. N. 2016. “Mapping the Field of Algorithmic Journalism.” Digital Journalism 4 (6): 700–722.
https://doi.org/10.1080/21670811.2015.1096748.
EU Court of Justice delivers blow to beneﬁcial ownership … . 2022, November 22. Transparency.Org.
https://www.transparency.org/en/press/eu-court-of-justice-delivers-blow-to-beneﬁcial-
ownership-transparency.
Extractive Industries Transparency Initiative. n.d. EITI. Accessed February 28, 2023. https://eiti.org/.
Felle, T. 2016. “Digital Watchdogs? Data Reporting and the News Media’s Traditional ‘Fourth Estate’
Function.” Journalism 17 (1): 85–96. https://doi.org/10.1177/1464884915593246.
Fink, K., and C. W. Anderson. 2015. “Data Journalism in the United States: Beyond the “Usual
Suspects”.” Journalism Studies 16 (4): 467–481. https://doi.org/10.1080/1461670X.2014.939852.
Hacks/Hackers LDN (Director). 2019, November 29. AI & Journalism: New powers, new responsibil-
ities
\textbar
Charlie
Beckett.
https://www.youtube.com/watch?feature=youtu.be&v=L-
qgP14TK8U&app=desktop.
Helsedirektoratet.
2021.
Norsk
kodeverk
for
uønskede
pasienthendelser.
https://www.
helsedirektoratet.no/rapporter/norsk-kodeverk-for-uonskede-pasienthendelser/Norsk%
20kodeverk%20for%20uønskede%20pasienthendelser.pdf/_/attachment/inline/e95247b1-
bdb4-463b-b730-5a09398db917:88e99f1e911c29fd8101025ad12f685eef995b9c/Norsk%
20kodeverk%20for%20uønskede%20pasienthendelser.pdf.
Hugging Face – The AI community building the future. n.d. Accessed March 1, 2023. https://
huggingface.co/.
Infographic: The Scale Of The Pandora Papers Leak. 2021, October 4. Statista Infographics. https://
www.statista.com/chart/11698/the-scale-of-the-paradise-papers-leak.
Jain, A., H. Patel, L. Nagalapatti, N. Gupta, S. Mehta, S. Guttula, S. Mujumdar, S. Afzal, R. Sharma Mittal,
and V. Munigala. 2020. “Overview and Importance of Data Quality for Machine Learning Tasks.”
Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data
Mining, 3561–3562. https://doi.org/10.1145/3394486.3406477.
16
M. FRIDMAN ET AL.
 Karlsson, M., and H. Sjøvaag. 2016. “Content Analysis and Online News: Epistemologies of Analysing
the Ephemeral Web.” Digital Journalism 4 (1): 177–192. https://doi.org/10.1080/21670811.2015.
1096619.
Kommunereformen 2020. 2021, March 15. ssb.no. https://www.ssb.no/oﬀentlig-sektor/kommune-
stat-rapportering/kommunereformen-2020.
Making Transparency Possible. 2019. Cappelen Damm Akademisk/NOASP. https://doi.org/10.23865/
noasp.64
Miroshnichenko, A. 2018. “AI to Bypass Creativity. Will Robots Replace Journalists? (The Answer Is
“Yes”).” Information 9 (7): 183. https://doi.org/10.3390/info9070183.
NbAiLab/nb-bert-base-mnli Hugging Face. 2023, January 25. https://huggingface.co/NbAiLab/nb-
bert-base-mnli.
Neo4j Graph Data Platform – The Leader in Graph Databases. n.d. Neo4j Graph Data Platform.
Accessed March 1, 2023. https://neo4j.com/.
NetworkX — NetworkX documentation. n.d. Accessed March 1, 2023. https://networkx.org/.
Niblock, S. 2007. “From “Knowing How” to “Being Able”: Negotiating the Meanings of Reﬂective
Practice and Reﬂexive Research in Journalism Studies.” Journalism Practice 1 (1): 20–32. https://
doi.org/10.1080/17512780601078829.
Niblock, S. 2012. “Envisioning Journalism Practice as Research.” Journalism Practice 6 (4): 497–512.
https://doi.org/10.1080/17512786.2011.650922.
Noain-Sánchez, A. 2022. “Addressing the Impact of Artiﬁcial Intelligence on Journalism: The
Perception of Experts, Journalists and Academics.” Communication & Society 35 (3): 105–121.
https://doi.org/10.15581/003.35.3.105-121.
TheNorwegianTaxAdministration.2020.Petroleumsskattpå116milliarderkronerfor2019.https://www.
skatteetaten.no/en/presse/nyhetsrommet/petroleumsskatt-pa-116-milliarder-kroner-for-2019/.
NPD Fact Pages. n.d. Accessed May 1, 2022. https://factpages.npd.no/.
O’Neil, C. 2016. Weapons of Math Destruction: How big Data Increases Inequality and Threatens
Democracy. 1st ed. Crown.
OpenCorporates: The Open Database Of The Corporate World. n.d. Accessed February 28, 2023.
https://opencorporates.com/.
Open
Ownership.
n.d.
Openownership.Org.
Accessed
February
28,
2023.
https://www.
openownership.org/en/.
pandas—Python Data Analysis Library. n.d. Accessed March 1, 2023. https://pandas.pydata.org/.
Pandora Papers: An oﬀshore data tsunami - ICIJ. 2021, October 6. https://web.archive.org/web/
20211006063105/https://www.icij.org/investigations/pandora-papers/about-pandora-papers-
leak-dataset/.
Parratt-Fernández, S., J. Mayoral-Sánchez, and M. Mera-Fernández. 2021. “Aplicación de la inteligen-
cia artiﬁcial al periodismo: Análisis de la producción académica.” El Profesional de La Información,
e300317. https://doi.org/10.3145/epi.2021.may.17.
Radon, J., and M. Achuthan. 2017. “Beneﬁcial Ownership Disclosure.” Journal of International Aﬀairs
70 (2): 85–108. JSTOR.
Robie, D. 2015. “Advocating Journalism Practice-as-research: A Case for Recognition in the New
Zealand PBRF Context.” Asia Paciﬁc Media Educator 25 (1): 62–73. https://doi.org/10.1177/
1326365X15575591.
Rodríguez, M. T., S. Nunes, and T. Devezas. 2015. “Telling Stories with Data Visualization.”
Proceedings of the 2015 Workshop on Narrative & Hypertext - NHT 15: 7–11. https://doi.org/10.
1145/2804565.2804567.
Sachs, J. D., and A. M. Warner. 2001. “The Curse of Natural Resources.” European Economic Review 45
(4–6): 827–838. https://doi.org/10.1016/S0014-2921(01)00125-8.
Santos, M. F. D. L., and M.-F. de-Lima-Santos. 2022. “ProPublica’s Data Journalism: How
Multidisciplinary Teams and Hybrid Proﬁles Create Impactful Data Stories.” Media and
Communication, https://doi.org/10.17645/mac.v10i1.4433.
Skattemotiverte transaksjoner – opplysningsplikt og fradragsrett. November 13, 2020. HR-2020-
2200-A (Høyesterett (Norwegian Supreme Court)). https://www.domstol.no/no/hoyesterett/
avgjorelser/2020/hoyesterett-straﬀ/hr-2020-2200-a/.
JOURNALISM PRACTICE
17
 Skup.no. n.d. Accessed February 28, 2023. https://www.skup.no/.
Stalph, F. 2018. “Classifying Data Journalism: A Content Analysis of Daily Data-Driven Stories.”
Journalism Practice 12 (10): 1332–1350. https://doi.org/10.1080/17512786.2017.1386583.
The State of Data Journalism (No. 2022). 2023. datajournalism.com. https://datajournalism.com/
survey/2022/.
Statistisk sentralbyrå. 2023, February 28. SSB. https://www.ssb.no/.
Stiglitz, J. 2002. “Transparency in Government.” In The Right to Tell: The Role of Mass Media in
Economic Development. 1st ed. World Bank Publications.
Stray, J. 2019a. “Making Artiﬁcial Intelligence Work for Investigative Journalism.” Digital Journalism 7
(8): 1076–1097. https://doi.org/10.1080/21670811.2019.1630289.
Túñez-López, J.-M., C. Fieiras-Ceide, and M. Vaz-Álvarez. 2021. “Impact of Artiﬁcial Intelligence on
Journalism: Transformations in the Company, Products, Contents and Professional Proﬁle.”
Communication & Society 34 (1): 177–193. https://doi.org/10.15581/003.34.1.177-193.
Vear, C. ed. 2022. The Routledge International Handbook of Practice-Based Research. Routledge.
Waskom, M. 2021. “seaborn: Statistical Data Visualization.” Journal of Open Source Software 6 (60):
3021. https://doi.org/10.21105/joss.03021.
Web64. 2023. Norwegian NLP Resources. https://github.com/web64/norwegian-nlp-resources
(Original work published 2016).
Weber, M. 2021. “AI, Media and the Future of News on the Web.” 13th ACM Web Science Conference
2021: 10. https://doi.org/10.1145/3447535.3468474.
Wu, S., E. C. Tandoc, and C. T. Salmon. 2019. “When Journalism and Automation Intersect: Assessing
the Inﬂuence of the Technological Field on Contemporary Newsrooms.” Journalism Practice 13
(10): 1238–1254. https://doi.org/10.1080/17512786.2019.1585198.
Young, M. L., A. Hermida, and J. Fulda. 2018. What Makes for Great Data Journalism. Journalism
Practice 12 (1): 115–135. https://doi.org/10.1080/17512786.2016.1270171.
Zamith, R. 2019. “Transparency, Interactivity, Diversity, and Information Provenance in Everyday
Data Journalism.” Digital Journalism 7 (4): 470–489. https://doi.org/10.1080/21670811.2018.
1554409.
Zhao, J., T. Wang, M. Yatskar, V. Ordonez, and K.-W. Chang. 2018. Gender Bias in Coreference
Resolution: Evaluation and Debiasing Methods. https://doi.org/10.48550/ARXIV.1804.06876.
18
M. FRIDMAN ET AL.
",10.1080/17512786.2023.2253797,doc3,"Data journalists are increasingly reliant on automation and artiﬁcial
intelligence (AI) to process and analyse massive datasets. AI can
contribute to journalism by creating visualizations, verifying
accuracy of information, analysing historical data, monitoring
social media, ﬁnding patterns and outliers, generating text and
much more. However, the integration of AI into the newsroom
comes with its own challenges. In this article, we take a practice-
based approach to develop a deeper understanding of how to
overcome such challenges. Our teams of data scientists, AI
experts and journalists took on four projects incorporating data
science and machine learning into investigative journalism. From
those experiences, we found that access to data at scale, data
quality and reworking the concept of “newsworthy” as a machine
learning
question
were
the
most
signiﬁcant
obstacles
to
deploying
AI
in
the
newsroom.
We
recommend
closer
collaborations between team members of diﬀerent disciplines to
create a truly trans-disciplinary approach, as well as some
practical
considerations
for
choosing
projects
to
facilitate
successful AI-assisted investigations.
ARTICLE HISTORY
Received 21 March 2023
Accepted 27 August 2023","Journalism Practice (Online) Journal homepage: How (not to) Run an AI Project in Inveﬆigative Journalism M. Fridman, R. Krøvel & F. Palumbo To cite this article: M. Fridman, R. Krøvel & F. Palumbo (04 Sep 2023): How (not to) Run an AI Project in Investigative Journalism, Journalism Practice, DOI: 10.1080/17512786.2023.2253797 To link to this article: © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group Published online: 04 Sep 2023. Submit your article to this journal Article views: 3867 View related articles View Crossmark data Citing articles: 6 View citing articles Full Terms & Conditions of access and use can be found at How (not to) Run an AI Project in Investigative Journalism M. Fridman a, R. Krøvel b and F. Palumbo a,b aArtiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi, Oslo Metropolitan University, Oslo, Norway; bFakultet for samfunnsvitenskap, Institutt for journalistikk og mediefag, Oslo Metropolitan University, Oslo, Norway ABSTRACT KEYWORDS Data journalism; investigative journalism; machine learning; data science; artiﬁcial intelligence; trans-disciplinary journalism Introduction Artiﬁcial Intelligence (AI) is a broad ﬁeld of computer science that aims to develop intel- ligent machines capable of performing tasks that typically require human intelligence. Machine learning is a subset of AI that develops algorithms and statistical models enabling computers to learn and make predictions or decisions without being explicitly programmed by humans. AI also includes other approaches such as natural language pro- cessing, computer vision, expert systems, and robotics, which collectively enable AI systems to understand, reason, learn, and interact with humans and their environments. Artiﬁcial intelligence (AI) is being rapidly adopted by news media around the world, to the point that both the public and the journalists themselves start to wonder whether “robots will replace journalists” (Miroshnichenko 2018). However, while the adoption of AI in journalism is accelerating, experiential knowledge about AI applications in © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group This is an Open Access article distributed under the terms of the Creative Commons Attribution License ( licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. The terms on which this article has been published allow the posting of the Accepted Manuscript in a repository by the author(s) or with their consent. CONTACT R. Krøvel royk@oslomet.no JOURNALISM PRACTICE journalism is lagging. Research on AI in journalism has been mostly qualitative and focused on a few topics such as data journalism, robotic writing, and news review (Parratt-Fernández, Mayoral-Sánchez, and Mera-Fernández 2021). With the advent of digital technology and the explosion of data, it is becoming increas- ingly important to use AI to support investigative journalism, as traditional methods are no longer practical. The development of new, often open-source, tools makes solutions easier and faster to implement and requires fewer specialized resources. In this context, computers can play a central role in automating repetitive and computationally intensive processes, enabling journalists to extract information that would otherwise be inaccess- ible (Beckett 2019). To visualize the growth in automated data handling it´s enough to consider that the “Pandora Papers”, released by ICIJ and composed of 2.94TB of docu- ments, is 1700 times as large as the “2010 Wikileaks”, which was 1.7GB (Infographic 2021; Pandora Papers 2021). Upon examining the current research landscape, it is evident that two main research strands are prominently featured in the ﬁeld: reports by journalists and/or developers describing a speciﬁc use case, and research articles based on interviews, surveys, and lit- erature reviews (Ausserhofer et al. 2017; de-Lima-Santos and Ceron 2022; Stray 2019a). However, the complex nature of investigative journalism requires alternative and exper- imental research methodologies that enable researchers to understand and analyse often novel investigative methodologies. One of the biggest challenges for multidisciplinary teams working on AI in investigative journalism is to be able to communicate and collab- orate eﬀectively (Santos and de-Lima-Santos 2022). This article draws on the insights and experiences gained from participation in four interdisciplinary teams in which data scientists and journalism researchers collaborated with investigative journalists on various projects. Our goal is to analyse how interdisciplin- ary teams can overcome the problems and limitations identiﬁed by researchers such as Stray (Stray 2019a) and lead to a better inclusion of AI methods in investigative journalism. By understanding the problems that need to be addressed, this paper aims to develop better methods for incorporating AI into investigative journalism. Data Journalism and AI in Journalism Data journalism is a ﬁeld that incorporates data analysis, visualization, and database use with traditional journalism practices to uncover and tell stories. Data journalism has made substantial contributions to society, oﬀering information and insights that have led to increased transparency, accountability, informed decision-making, and public under- standing (Bounegru and Grey 2021). Data visualization is a critical aspect, as it helps jour- nalists present complex information in a simple format (Rodríguez, Nunes, and Devezas 2015). Using data and interactive visualization, data journalism has revealed injustices, held powerful individuals accountable, and improved the functioning of society and the lives of citizens (Ausserhofer et al. 2017; Borges-Rey 2016; Bounegru and Grey 2021; Santos and de-Lima-Santos 2022; Young, Hermida, and Fulda 2018). There has been a push to include more data science and AI in data journalism. Data journalism and AI journalism are two diﬀerent approaches to journalism that can overlap. Data journalism involves the use of statistical methods, data visualization tools, and other techniques to identify patterns and trends in large datasets, and to present 2 M. FRIDMAN ET AL. this information in a way that is accessible to the general public. AI in journalism addition- ally involves using AI technology to analyze data and discover, develop and publish new stories. Whereas the most used software by data journalists are Microsoft Excel and Google Sheets (The State of Data Journalism 2023), data scientists regularly use program- ming to wrangle and scrape data, improve data cleaning, and create custom analysis and dynamic interfaces to promote data interaction. They can also use machine learning and recent AI advances to automate repetitive processes, extract relationships that are hard to see otherwise and detect newsworthy anomalies (Amazon Mining Watch n.d.). Data jour- nalists are now more reliant on automation and AI to process and analyse massive data- sets, and even generate new stories (Challenges and Opportunities – Survey – State of Data Journalism 2022, n.d.). Florian Stalph identiﬁes four main categories of data journal- ism: explanatory data journalism, investigative data journalism, interactive data journal- ism, and advocacy data journalism (Stalph 2018). A similar approach is followed by Konstantin Nicholas Dörr mapping the ﬁeld of AI journalism into automated news writing, data-driven journalism, personalized news recommendation, and algorithmic curation (Dörr 2016). In addition, AI can contribute to journalism by creating visualiza- tions, verifying the accuracy of statements, analysing historical data, and monitoring social media (AI and the Future of Journalism n.d.; Hacks/Hackers LDN 2019; Miroshni- chenko 2018; Weber 2021). However, it is important to view AI as an aid to journalists, not a replacement. The best outcomes are achieved by combining AI with human exper- tise and ensuring unbiased and diverse data is used for training. Data collection is a critical aspect of artiﬁcial intelligence (AI) because AI algorithms rely on large and diverse datasets to make accurate predictions and decisions. However, data collection for AI can be problematic due to several reasons. First, it can introduce bias and discrimination if the collected data reﬂects societal biases or discriminates against certain groups, leading to unfair outcomes (Buolamwini and Gebru 2018; Zhao et al. 2018). Second, limited or incomplete data can result in models lacking accu- racy and reliability (Jain et al. 2020). Moreover, privacy concerns arise when personal data is collected, stored, and potentially used without consent, posing risks to privacy and data security (Crawford and Schultz 2014). Ethical considerations are also important, especially when sensitive information is involved, requiring transparency and adherence to ethical guidelines (O’Neil 2016). Data quality and pre-processing chal- lenges, including errors and inconsistencies, can undermine AI model eﬀectiveness. Data imbalance, where certain groups are underrepresented, can lead to biased results. Additionally, data ownership and access rights can create barriers to research and fair competition. The research into data journalism is an ever-evolving ﬁeld, but a few trends are emer- ging. Several studies highlight the importance of multidisciplinary teams (Borges-Rey 2016; de-Lima-Santos & Salaverría 2021; Santos and de-Lima-Santos 2022). Collaborations between journalists, data scientists, and developers to create tailored analyses and data- wrangling solutions are key to an investigations’ success. Teams that instead have to rely on readily available free online tools struggle with the lack of customization (Young, Hermida, and Fulda 2018). Despite the potential beneﬁts, the adoption of AI in the ﬁeld of investigative journalism has not been widespread. The cost of implementing new technologies, like AI, in various industries may be a factor. However, there is potential for AI to reduce costs as well, in the JOURNALISM PRACTICE 3 scope of automation and lead generation. In addition, given its potential to recognize pat- terns and ﬁnd stories that would otherwise stay buried, the cost-beneﬁt analysis cannot be calculated purely in ﬁnancial terms. This value to society allows such projects to turn to public funds, philanthropy, and crowdfunding. Apart from the economical hurdles to incorporating AI and data science into data jour- nalism, there are also the obstacles inherited from data journalism itself. These challenges are well explained in a comparative study between the United States and North European countries (Fink and Anderson 2015). Fink and Anderson summarize the main limiting factor for data journalism across newsrooms in the lack of: Time, Tools, Manpower and Legal Resources. They also point out that the role of a data journalist within an organiz- ation often lacks clear deﬁnition, frequently resulting in them either working in isolation or being burdened with an overwhelming amount of tasks. An overview of the pros and cons of AI integration within newsrooms is given by Wu et al. after conducting interviews with professionals. In their work, they discuss the emer- gence of automation technologies, such as artiﬁcial intelligence, machine learning, and natural language processing, and their potential applications in journalism. They explore how these technologies are being integrated into newsrooms to streamline workﬂows, generate news content, and personalize news delivery. Some of the potentials of AI consist of increased eﬃciency, improved accuracy, and enhanced audience engage- ment through personalized news experiences. At the same time, concerns are related to job displacement, ethical considerations, and the need for human oversight in the auto- mated news production (Wu, Tandoc, and Salmon 2019). Nevertheless, AI journalism can play a crucial role in supporting the role of journalists as “watchdogs”, to quote Tom Felle (Felle 2016), in providing the public with valuable information and holding those in power accountable for their actions. Of course, this comes not without challenges, but by focusing on disclosing sources, methodologies, and limitations journalists can enable audiences to assess the credibility and reliability of data-driven news stories (Anderson 2018; Zamith 2019). Methodology Parratt-Fernández et al. observe that 60% of academic work on AI applications in journal- ism utilizes qualitative methods, despite the numerical nature of the subject. While digital methods are prevalent in digital humanities, they are less common in journalism studies (Parratt-Fernández, Mayoral-Sánchez, and Mera-Fernández 2021). Sjøvaag and Karlsson attribute this to a higher threshold for journalism scholars, who often lack the necessary skills and knowledge to perform automated analysis on large datasets (Karlsson and Sjøvaag 2016). We have consequently chosen to develop and employ alternative method- ologies to enrich the existing literature from complementary methodological perspec- tives. The methodology used in this research is practice-based (Biggs and Büchler 2007; Vear 2022). Practice-based research emphasizes the study of real-world problems and practices, rather than solely theoretical or abstract concepts. In contrast to other methodologies, practice-based research focuses on understanding how people actually do things, rather than how they should theoretically do them. This allows us to focus on how inves- tigative journalists do their job. It is an empirical research method, which is based on the 4 M. FRIDMAN ET AL. collection of data through observation, discussion, and other forms of direct engagement: practitioners and researchers work together to identify research questions, collect data, and analyse results. Practice-based research allows journalists and scholars to better understand the practical implications of new technologies and changing newsroom practices. It is necessary to bridge the gap between academic research and industry practice and can lead to the development of more innovative and eﬀective journalism (Barroca et al. 2018; Biesta 2007). In addition to its beneﬁts for practitioners, prac- tice-based research also proﬁts academia by helping educators and researchers stay current with the latest trends and developments in the ﬁeld. This results in the development of more relevant and eﬀective journalism curricula (Niblock 2007; 2012; Robie 2015). In designing the methodology of this study, we chose to conduct practice-based research by collaborating with the Norwegian Association for Investigative Journalism (Skup.No n.d.). SKUP is a non-proﬁt organization that promotes investigative journalism in Norway. Together with SKUP, we published a call in May 2021 inviting investigative journalists to submit projects where we could assist using data science and AI techniques. By opening a public call, we allocate ﬁnancial resources to support academic staﬀ dedicated to 4 projects for a period of 6 months. We encouraged all the Norwegian newsrooms to submit a project proposal and a committee of both AI and Journalism academics was appointed to select the 3 best ones. By doing so we encourage Norwe- gian newsrooms to explore avenues with which they are not familiar and that in normal circumstances they would have not pursued We received several applications and for the three selected projects, we dedicated an Associate Professor of Artiﬁcial Intelligence. Each team was then composed of one academic from OsloMet, one Inves- tigative Journalist daily collaborating with the AI expert, and a staﬀof supporting journalists. In our research approach, the investigative journalists were responsible for deciding the topic, ﬁnding the initial data sources, formulating the research questions, and inter- preting the results. The teams had variable compositions in terms of the number of jour- nalists and experience with data handling. A smaller team of data journalists assisted with data-related issues. Regular meetings ensured alignment between the data-focused teams and the journalists. This collaborative approach enabled a targeted use of data science and AI techniques in investigative journalism. In 2022, we again selected three new projects and provided similar support. The collaboration with SKUP not only provided access to experienced investigative journalists but also ensured that the research had a direct impact on the ﬁeld. The insights drawn from applying data science and AI techniques to investigative jour- nalistic questions form the backbone of the present study. The journalistic results were published in various outlets. Here, we have anonymized identities to maintain conﬁdenti- ality. Team meetings and Discord channels were utilized to ensure eﬃcient collaboration among stakeholders. Group meetings were held to identify signiﬁcant learning experi- ences and analyse ﬁndings considering the existing literature. For the purpose of this article, we draw on notes and discussions in team meetings and on Discord channel to reconstruct the research processes. JOURNALISM PRACTICE 5 Description of Projects Project 1 Exploration reimbursement scheme in the petroleum industry. The main goal of this project was to bring attention to the exploration reimbursement tax scheme in the pet- roleum industry. The journalists proposed to investigate and combine two publicly avail- able data sources: the Petroleum Tax Lists (The Norwegian Tax Administration 2020) and the Norwegian Petroleum Directorate (NPD) Fact pages (NPD Fact Pages n.d.). The goal of the project was to better understand how companies were accessing and using the exploration reimbursement scheme, which has been in place since 2005. Additionally, the project aimed to provide some oversight to the program by mapping oil exploration activities, documented in the NPD fact pages, to the reimbursement claims in annual taxes. In the process of this investigation, the idea emerged to deploy graph databases to represent connections between petroleum companies, reimbursement payments and drilling licenses. Project 2 Adverse events in elderly care. The main goal of this project was to better understand how the quality of elderly care varies across municipalities. The journalists proposed to corre- late publicly available data recording “non-conformity reports” (NCR) and statistics from SSB. NCR are gathered at the municipality level and are regulated by the government guidelines “Norsk kodeverk for uønskede pasienthendelser” (Helsedirektoratet 2021). The statistics available from SSB describe a wide set of municipality parameters. By corre- lating these datasets, the project aimed to identify critical factors that contribute to the occurrence of adverse events in elderly care. Project 3 Eating disorders in professional skiers. The main goal of this project was to investigate the occurrence of eating disorders among top athletes. The journalists proposed an innova- tive approach to solve this problem by using computer vision. The core idea was to take advantage of the mediatic exposure of the athletes. By collecting public images of the athletes over time it is possible to infer the body mass index and body fat percentage and consequently investigate drastic changes over the years. Project 4 Media landscape analysis. The main goal of this project was to better understand the Norwegian media landscape. The project started with an exploratory data analy- sis of a dataset of Norwegian news and blog stories. The dataset collected infor- mation about the article itself, including title, publisher, authors, and links, as well as information about its social media engagement. In addition to exploratory analy- sis, this project grew to track how stories move across both traditional and social media. 6 M. FRIDMAN ET AL. Results In the ﬁeld of data journalism, the deployment of machine learning (ML) and artiﬁcial intelligence (AI) algorithms requires a thorough understanding of the necessary data and the feasibility of obtaining and processing that data. Based on existing literature, we expected this process to be time-consuming – particularly in investigative journal- ism projects where there is signiﬁcant complexity in both the questions and societal structures involved. However, as we experienced, one should carefully consider the quality and availability of the required data to correctly estimate the feasibility of the project and its potential outcomes. It is crucial to note that input data of poor quality will result in equally poor output, regardless of the algorithm’s computational power. We found similar diﬃculties and challenges across all of three projects, which we could broadly categorize using the concepts introduced by Stray (Stray 2019b) as follows: . Data availability: Data relevant to a story may not be publicly accessible, data collection results to be challenging, or the available dataset is incomplete/scattered . Data quality: Journalistic inference requires high-accuracy data . Newsworthiness: The concept of “newsworthy” is diﬃcult to encode computationally Data Collection is a Critical Aspect of AI in Journalism We found that the availability of data was a recurring challenge across all projects. Despite identifying data sources before the project’s start and therefore expecting that data was readily accessible, each project encountered diﬃculties in obtaining the necessary data. The project exploring the reimbursement scheme in the petroleum industry stumbled across a lack of consistent historical records. Despite the presence of publicly available data from sources such as the Brønnøysund registry (brreg.no n.d.), historical data for defunct companies was often missing. This required the purchase of data or the use of alternative methods for collection. This project also suﬀered from a lack of transparent data from the side of the tax authorities. While the oil exploration reimbursement amounts are ostensibly available and published every year by the Norwegian Tax Oﬃce, these reimbursements are not split between exploration and termination reimbur- sements. The Norwegian Tax Oﬃce refused to release this information on request, without which it is impossible to evaluate the success or failure of the exploration reim- bursement policy. Moreover, the life cycle of a company can be complex and involves merges and splits, takeovers and name changes. This makes it complicated to track licenses and understand ﬁnancial ﬂows over time. Petroleum extraction licenses are typi- cally shared between several companies in alliances that might also change over time. It is consequently very diﬃcult to reconstruct the timeline of company history and reimburse- ments without support from experts. The project which sought to investigate the quality of elderly care in Norway also encountered challenges in obtaining data. Despite the requirement for municipalities to keep detailed records of non-conformity reports (NCR) in the elderly care sector, a com- prehensive analysis of these reports had never been conducted. We discovered that often the data was missing, unstructured or in hard-to-access formats. There were diﬀerent JOURNALISM PRACTICE 7 reasons for this, ranging from a lack of human resources in the municipality to a lack of digital reporting systems. Privacy issues also prevented data sharing in the case of small municipalities. Even when the municipality invested signiﬁcant resources to collect and anonymize the records, the data analysis was not trivial due to the lack of stan- dardization across municipalities. In the best-case scenario, municipalities sent their data in the shape of Microsoft Excel spreadsheets. This required extensive eﬀort from the team to restructure the data in a standard format and sometimes led to data loss. Other muni- cipalities delivered data in unstructured formats such as PDFs, Word ﬁles or just printed out on A4 paper, leading to additional challenges wrangling the data into a usable format. At a later stage, the project intended to correlate the NCR statistics with publicly available data from the Norwegian Central Bureau of Statistics (SSB) (Statistisk sentralbyrå 2023) to better understand factors contributing to adverse events in elderly care facilities. SSB maintains updated statistics of many societal parameters; however, historical analysis of the data was challenging given the complex and frequent changes to the structure of Norwegian municipalities. Upon request, SSB supported our investigation by allowing our team to purchase restructured datasets, but these datasets were not provided freely through their platform. Since then, they have integrated our proposed indexing of the data in their report system for current and future data. This example shows how the struc- ture and shareability of the data improved through the interaction between journalists and data collectors. These experiences highlight the need for increased transparency and accessibility of data, particularly regarding business and healthcare. The lack of labeled data when looking for suspicious activity and the unstructured nature of business annual reports also presented signiﬁcant obstacles in utilizing AI and ML algorithms. Considering these challenges, it is crucial to consider the feasibility of obtaining a complete and high-quality dataset before embarking on investigative journalism projects that involve data analysis. Journalism would Beneﬁt from Greater Transparency in Company Structure In recent years, there has been a growing recognition of the need for greater transparency in the ﬁnancial ﬂows of companies, particularly in the extractive and ﬁnancial sectors (Sti- glitz 2002). This is because these sectors are often characterized by complex and opaque ownership structures (Sachs and Warner 2001). One of the main challenges in uncovering these ﬁnancial ﬂows is the lack of comprehensive and publicly available data on company ownership and beneﬁcial ownership (Cobham and Janský 2020). While some countries have made progress in this area, for example by joining the Extractive Industries Transpar- ency Initiative (EITI) (Extractive Industries Transparency Initiative n.d.), many countries still lack comprehensive and publicly available registers. Additionally, even when data is publicly available, it is often unstructured, on paper and in a customized format, which makes it challenging to extract information even with state-of-the-art Object Character Recognition (OCR) algorithms. Furthermore, in some cases, the companies themselves may be unwilling to disclose information about their ownership and ﬁnancial ﬂows, making it diﬃcult for investigative journalists to access the necessary data (Making Transparency Possible 2019). Even when a company is willing to disclose information, it might be diﬃcult to access it as datasets might be 8 M. FRIDMAN ET AL. scattered across multiple platforms and in multiple countries, not to mention privacy legislations limiting data access (EU Court of Justice Delivers Blow to Beneﬁcial Owner- ship … 2022). While investigating the reimbursement scheme in the Norwegian petroleum industry we experienced how complex and opaque ownership structures are. This is a particularly illustrative example given that Norway, as a member of EITI, commits to disclose infor- mation regarding the extractive (Extractive Industries Transparency Initiative n.d.). There are numerous reasons why investigative journalists, and the news media, might want to investigate complex and opaque ownership structures in the extractive and ﬁnancial sectors. First, opaque ownership structure makes it diﬃcult to hold companies accountable for their actions, especially when it comes to taxes and royalties for the resources they extract. Several studies suggest that investigative journalism, and other forms of transparency-promoting activities, can play a critical role in exposing complex and opaque ownership structures in the extractive and ﬁnancial sectors (Beckett 2019; Radon and Achuthan 2017). Based on our research, we believe data journalism in this ﬁeld depends on initiatives such as OpenCorporates (OpenCorporates :: The Open Data- base Of The Corporate World n.d.) and OpenOwnership (Open Ownership n.d.) to move the ﬁeld forward. These and other organizations are taking the lead in utilizing advanced Machine Learning and Graph Databases to analyse complex company struc- tures and beneﬁcial ownership. Information is Often not Publicly Accessible In the case of the investigation of accidents in elderly care, Norwegian municipalities are obliged to provide data to journalists. However, a signiﬁcant number of municipalities did not provide the requested information. Various factors can inﬂuence whether municipa- lities provide requested information to journalists or not. However, as the context can vary from country to country and region to region, it is important to consider the speciﬁc cir- cumstances and legal framework of each inquiry. Among the municipalities that did not provide the data in our investigation, the main reasons cited were a lack of digital records, on-going lawsuits that prevented the sharing of data and insuﬃcient human resources to anonymize the data for privacy reasons. In addition, some municipalities simply failed to respond to the journalist’s requests. Additionally, there were also challenges in obtaining data from SSB (Statistisk sentral- byrå 2023) due to the frequent rearrangements of municipalities by the government. Fre- quent re-organization of municipalities leads to several challenges in terms of data analysis (Kommunereformen 2020, 2021). Administrative boundary changes can impact data quality, as data collection and reporting procedures may change, resulting in incon- sistent or inaccurate data. This makes it diﬃcult to conduct accurate and reliable analyses of parameters over the years. In the project employing computer vision for BMI estimation, we negotiated with other researchers to share their datasets, some of which had been scraped from public sources like Reddit. While at ﬁrst glance there were multiple approaches, public and shared data- sets available, we quickly realized that these were not suﬃcient for the uses of the project. It is therefore important to highlight that it’s not only the quantity of data that is crucial, but also their relevance to the research question. JOURNALISM PRACTICE 9 Given the challenges of limited access to data, it is likely that journalists will need to invest signiﬁcant resources to obtain the necessary data, as demonstrated by the examples presented in this article. Strategies such as collaborating with organizations or individuals who have access to relevant data sets, using publicly available data sources, or using alternative data sources can help obtain relevant datasets. Journalistic Inference Requires Very High Accuracy In the context of our practice-based research, it became clear that the process of journal- istic inference demands high accuracy. Machine learning algorithms have been devel- oped to identify patterns and common characteristics within datasets. However, when it comes to investigative journalism, particularly in the realm of fraud detection, the goal is to uncover the unusual, events that were not expected to occur. These subtle vari- ations are crucial to consider, as they do not align with the primary purpose for which ML and AI algorithms were developed. Deﬁning what constitutes suspicious or unethical practices within the available datasets is a diﬃcult task, due to obscure business practices and opaqueness in the law and interpretation of it. This is perhaps unsurprising, as even cases with extensive evidence have been ruled legal by the courts (Skattemotiverte transaksjoner – opplys- ningsplikt og fradragsrett 2020). More fundamentally, even deﬁning what is a “company” over the years within a landscape of multiple organizations and leadership structures can be prohibitively complex, as we described in the previous chapter. This makes it precarious to associate any company or private entity with an accusation of misconduct. Our research on the care of the elderly highlighted the diﬃculty in categorizing events into diﬀerent classes. After evaluating multiple language models, we determined that accurate quantiﬁcation of all categories could not be guaranteed. Thus, we decided to focus solely on adverse events related to medicine, which were successfully classiﬁed. It is important to note that we were not investigating causality in this project, but rather exploring correlations between variables, which can provide insight into relevant vari- ables for optimizing the services oﬀered by the municipality. Although it was not poss- ible to quantify issues and problems related to elderly care within this landscape, our research aimed to guide the journalist’s investigation towards addressing these issues, supported by data when the administration or leaders of the municipality were questioned. A ﬁnal aspect worth mentioning is the variation in data reporting among municipali- ties. Our analysis of collected databases revealed that each municipality, depending on its size and structure, may report data on ﬁnances and human resources with varying degrees of resolution. This makes the analysis process signiﬁcantly more challenging, as municipalities may report a single budget for their entire health department while others may report individual budgets for diﬀerent health departments (home assistance, hospitals, nursing homes, etc.), making comparisons diﬃcult. In our study on eating disorders in sports, we ultimately had to abandon the model due to insuﬃcient accuracy. This serves as a crucial example of why expertise in AI is impor- tant. A team without suﬃcient knowledge of AI may not have been able to understand that the model was unreliable and unsuitable for use. 10 M. FRIDMAN ET AL. Finally, in the research we did with the fact-checking organization Faktisk.no we did succeed in identifying certain claims that could be conﬁdently made and relayed, mainly because they were of a generalized, descriptive and qualitative nature. Discussion Data Preparation Tasks According to Stray (Stray 2019a), data preparation tasks represent a signiﬁcant opportu- nity for AI to beneﬁt investigative journalism in the short term. In the context of the petroleum exploration reimbursement investigation, we found that linking databases and transforming into Graph databases can reveal connections that were previously unknown, by identifying patterns and relationships within large amounts of data. This enhances the ability to uncover hidden links between entities and to build a comprehensive picture of the issue at hand. In the care for the elderly project, we faced the challenge of merging information from various data types, including excel sheets, pdf ﬁles, and printed papers. Our research indi- cates that public bodies should play a role in standardizing data dissemination, similar to the example set by VG during the COVID-19 pandemic, where the government was weekly providing updated statistics to the media. Finally, in our study with the fact-checking organization Faktisk.no, we discovered that most of the “AI”, speciﬁcally unsupervised machine learning, was used in the pre-proces- sing steps to cluster similar stories. This step greatly assisted in the later analysis, demon- strating the potential for AI in improving the eﬃciency of investigative journalism. Our research supports the ﬁndings of Stray that data preparation tasks are the area where AI seems to have the most immediate impact on investigative journalism. However, much research and development are still needed to fully realize the potential of AI in this ﬁeld and to ensure its ethical and eﬀective application. Cross-Database Record Linkage The use of AI in investigative journalism presents signiﬁcant potential for cross-database record linkage. The ability to link records across databases has the potential to greatly reduce the time, eﬀort, and costs associated with many investigations while producing more robust results. Referential integrity across databases refers to the consistency of relationships between records in diﬀerent databases. Ensuring referential integrity is important in ensuring the accuracy of the information being analysed and can greatly assist in connect- ing records that would have been diﬃcult to link otherwise. However, referential integrity can be diﬃcult to achieve due to diﬀerences in keys and naming conventions across databases. In the context of investigative journalism, referential integrity is crucial when linking records from various sources. For example, in the investigation of petroleum tax reimbur- sements, linking tax data with petroleum discovery data can help to hold companies accountable. However, in some cases we found that companies used diﬀerent organiz- ation numbers for taxation and licensing purposes, which made linking records JOURNALISM PRACTICE 11 diﬃcult. Similarly, in the investigation of care for the elderly, referential integrity across databases is essential to ensure that information is accurate and correctly linked. Our practice-based research highlights the potential of AI in facilitating cross-database record linkage, which could greatly enhance the eﬀectiveness of investigative journalism. Using the Right Tools Saves Time and Money and Enhances the Results’ Quality In our investigation, we identiﬁed a multitude of tools that can be adapted and leveraged for the purpose of investigation. These tools, including Pandas (Pandas - Python Data Analysis Library n.d.), Seaborn (Waskom 2021), Norwegian language models such as NorBERT or NoTraM (Web64 2016/2023), zero-shot classiﬁcation (NbAiLab/Nb-Bert-Base- Mnli Hugging Face 2023), Neo4j (Neo4j Graph Data Platform – The Leader in Graph Data- bases n.d.), NetworkX (NetworkX — NetworkX Documentation n.d.), and HuggingFace (Hugging Face – The AI Community Building the Future. n.d.), represent only a selection of the numerous available options that can be utilized to fulﬁll speciﬁc needs. It is of utmost importance to have a comprehensive understanding of recent advancements in AI to make informed decisions when selecting the most appropriate tools and platforms for a given investigation. Pandas, a data analysis library in Python, provides eﬃcient storage and manipulation of tabular data through its data structures. Seaborn, another Python library, oﬀers a high- level interface for generating informative and visually appealing statistical graphics. NB- NERT, a Norwegian language model for named entity recognition (NER), can be utilized to identify named entities in text. Zero-shot classiﬁcation, a machine learning technique, enables categorization of unseen categories without the need for any additional training data. Neo4j is a graph database management system designed for the storage and query- ing of complex networked data. NetworkX, a Python library, enables the creation, manipu- lation, and analysis of the structure, dynamics, and functions of complex networks. Lastly, HuggingFace is a natural language processing platform providing access to a wide range of pre-trained language models, including NER models. These tools can be employed in a variety of ways to support journalistic investigations. They can be used to analyze data and generate visualizations to gain a deeper under- standing of trends and patterns, identify named entities in text, categorize text, store and query complex networked data, and access pre-trained language models for NER tasks. In our research project, we invested signiﬁcant resources to support the four pro- jects. Two associate professors were dedicated to the projects and worked almost full- time. Three masters students also contributed to the work. Additionally, two other pro- fessors provided support, including time spent on funding and administrative tasks. All in all, we estimate that the total cost of the projects was close to $200,000. The sizes of the projects varied greatly. Two of the projects were large-scale eﬀorts that involved a substantial team of journalists and developers. At times, each team could consist of over ten individuals. The cost related to data science and AI was a small portion of the overall budget for the largest projects, estimated to be less than 10%. On the other hand, one of the smaller projects had a signiﬁcantly higher proportion of its budget allocated to data science and AI, approximately half of the total. However, it should be noted that it is challenging to provide precise estimates as several journalists and developers worked on multiple projects simultaneously. 12 M. FRIDMAN ET AL. The projects presented signiﬁcant challenges in terms of budgeting and resource allo- cation. The extent of the data pre-processing required was unforeseen and caused unfore- seen expenses. When evaluating the costs of investment in data science and AI, it is important to weigh them against the potential beneﬁts. In one instance, having machine learning experts working on the project prevented the publication of unreliable results. In another instance, the potential beneﬁts could be measured in terms of improve- ments to quality of life and longevity. While it is diﬃcult to determine the ﬁnancial returns of these investigations to the news media, we believe that they hold great promise for long-term beneﬁt to society. Importantly, the advent of AI in the media industry is already changing the pro- fessional proﬁle of the journalist, since they have to manage constantly developing tech- nologies, an increasing amount of accessible data, fake news generation, and last but not least, the ethical implications introduced by the use of AI in modern society (Túñez-López, Fieiras-Ceide, and Vaz-Álvarez 2021). Therefore, appropriate training of journalists, as well as a productive collaboration with experts in the ﬁelds of AI, is necess- ary to allow them to automate repetitive tasks and to process large amount of data eﬃciently so that they can focus on creating high-quality human-crafted journalism (Noain-Sánchez 2022). Conclusion In this study, we applied an interdisciplinary approach to enhance investigative journal- ism with advanced machine learning and data science techniques. We utilized a variety of tools, including Pandas, Seaborn, Norwegian language models like NB-BERT, zero- shot classiﬁcation, Neo4j, NetworkX, and HuggingFace to build applications that made the investigative process more cost-eﬀective. During the course of this project, we observed that the landscape of large language models and computer vision was rapidly changing, with the release of four major neural networks in the latter half of 2022. This trend is likely to continue, with the speed of innovation and openness in the ﬁeld leading to falling costs of investigative projects. Based on our experiences, we believe that it is crucial to move beyond interdisciplinary projects and towards true trans-disciplinary projects. “Trans-disciplinary” refers to a colla- borative approach that integrates knowledge and skills from multiple disciplines to solve complex problems and address real-world challenges. It diﬀers from interdisciplinary teamwork in that it involves active participation and collaboration from all stakeholders including those outside the ﬁeld of expertise, to ensure that the solutions produced are holistic and relevant to the real-world context. Additionally, it requires participants to develop joint theoretical and methodological frameworks to guide the teamwork. In order to maximize the chances of success we have developed a recommended workﬂow summarized in Figure 1. We recommend prioritizing projects with well-stated research questions and a clear hypothesis, while also considering the potential value of the database itself, even in the absence of a “smoking gun”. Moreover, it is important to keep in mind that historical data can be missing, incomplete and diﬃcult to interpret, therefore, we recommend focusing on projects based on recent or current time periods. Happily, data are becoming increasingly available, thanks to the active contribution of both private and public bodies, such that hopefully this restriction will diminish with JOURNALISM PRACTICE 13 time. Additionally, we suggest using explainable methods and visualization techniques that are easily understandable to journalists, editors, and the general public. In addition to the tangible outcomes of these projects in the form of news reports and documentaries, we also gained valuable insights into the challenges and complexities of these types of collaborations. We found that the investigations were more productive when both journalists and AI specialists became literate in each other’s ﬁelds and Figure 1. Recommended workﬂow to successfully implement and develop an AI Journalism project. This recommendation is based on the practice and experience of the projects we describe in this article, and it aims to guide other journalists on how to implement AI in their newsrooms. Figure 2. Schematic representation of what we envision as trans-disciplinary collaborations between AI experts and Investigative Journalists. These two professional ﬁgures do not work independently, but actively collaborate with each other integrating their skills to solve complex problems. 14 M. FRIDMAN ET AL. engaged in a mutual learning process, as represented in Figure 2. This highlights the importance of using existing algorithms, programs, and models, as well as developing an understanding of the broader range of techniques in AI and data analysis. Data journalism has emerged as an important ﬁeld in contemporary journalism. The rise of big data, open data and data visualization technologies have enabled journalists to leverage data in innovative ways to tell more compelling stories. Data journalism oﬀers a new way of reporting that is grounded in the analysis of large data sets, and that allows for the creation of new insights that would not be possible through traditional reporting methods. In this paper, we explore the role of data journalism in contemporary journalism and examine the ways in which it is transforming the ﬁeld of journalism. Acknowledgment We thank Gustavo Borges Moreno e Mello for the main contribution in establishing the “The AI Jour- nalism Resource Center” and supporting the group in obtaining the necessary fundings supporting the work presented in this article. We also thank Morten Goodwin for contributing to the develop- ment of the projects with stimulating discussions and insight. Disclosure Statement No potential conﬂict of interest was reported by the author(s). Funding This work was supported by Artiﬁcial Intelligence Lab (AI Lab), Institutt for informasjonsteknologi, Oslo Metropolitan University, Oslo, Norway and Fritt Ord Foundation and the Norwegian Directorate for Higher Education and Skills. ORCID M. Fridman R. Krøvel F. Palumbo References AI and the Future of Journalism. n.d. Accessed September 3, 2021. of-journalism/. Amazon Mining Watch. n.d. Accessed February 27, 2023. Anderson, C. W. 2018. Apostles of Certainty. Vol. 1. Oxford University Press. oso/9780190492335.001.0001. Ausserhofer, J., R. Gutounig, M. Oppermann, M. Oppermann, S. Matiasek, and E. Goldgruber. 2017. “The Dataﬁcation of Data Journalism Scholarship: Focal Points, Methods, and Research Propositions for the Investigation of Data-Intensive Newswork.” Journalism: Theory, Practice & Criticism 21: 950–973. Barroca, L., H. Sharp, D. Salah, K. Taylor, and P. Gregory. 2018. “Bridging the Gap between Research and Agile Practice: An Evolutionary Model.” International Journal of System Assurance Engineering and Management 9 : 323–334. Beckett, P. 2019. Ownership, Financial Accountability and the law: Transparency Strategies and Counter-Initiatives. London: Routledge, Taylor & Francis Group. JOURNALISM PRACTICE 15 Biesta, G. 2007. “Bridging the Gap between Educational Research and Educational Practice: The Need for Critical Distance.” Educational Research and Evaluation 13 : 295–301. org/10.1080/13803610701640227. Biggs, M. A. R., and D. Büchler. 2007. “Rigor and Practice-Based Research.” Design Issues 23 : 62–69. Borges-Rey, E. 2016. “Unravelling Data Journalism a Study of Data Journalism Practice in British Newsrooms.” Journalism Practice 10 : 833–843. 1159921. Bounegru, L., and J. Grey, eds. 2021. The Data Journalism Handbook: Towards a Critical Data Practice. Amsterdam: Amsterdam University Press. Brreg.no. n.d. Brønnøysundregistrene. Accessed February 28, 2023. Buolamwini, J., and T. Gebru. 2018. “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classiﬁcation.” In Proceedings of the 1st Conference on Fairness, Accountability and Transparency, edited by S. A. Friedler, and C. Wilson, 77–91. Vol. 81. PMLR. Challenges and Opportunities – Survey – .State of .Data .Journalism 2022. n.d. Accessed February 28, 2023. Cobham, A., and P. Janský. 2020. Estimating Illicit Financial Flows: A Critical Guide to the Data, Methodologies, and Findings. 1st ed. Oxford University PressOxford. oso/9780198854418.001.0001 Crawford, Kate, and Jason Schultz. 2014. “Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms.” Boston College Law Review 55: 93. de-Lima-Santos, M.-F., and W. Ceron. 2022. “Artiﬁcial Intelligence in News Media: Current Perceptions and Future Outlook.” Journalism and Media 3 : 13–26. journalmedia3010002. De-Lima-Santos, M. F., and R. Salaverría. 2021. “From data journalism to artiﬁcial intelligence: chal- lenges faced by La Nación in implementing computer vision in news reporting.” Palabra Clave 24 . Dörr, K. N. 2016. “Mapping the Field of Algorithmic Journalism.” Digital Journalism 4 : 700–722. EU Court of Justice delivers blow to beneﬁcial ownership … . 2022, November 22. Transparency.Org. ownership-transparency. Extractive Industries Transparency Initiative. n.d. EITI. Accessed February 28, 2023. Felle, T. 2016. “Digital Watchdogs? Data Reporting and the News Media’s Traditional ‘Fourth Estate’ Function.” Journalism 17 : 85–96. Fink, K., and C. W. Anderson. 2015. “Data Journalism in the United States: Beyond the “Usual Suspects”.” Journalism Studies 16 : 467–481. Hacks/Hackers LDN (Director). 2019, November 29. AI & Journalism: New powers, new responsibil- ities \textbar Charlie Beckett. qgP14TK8U&app=desktop. Helsedirektoratet. 2021. Norsk kodeverk for uønskede pasienthendelser. helsedirektoratet.no/rapporter/norsk-kodeverk-for-uonskede-pasienthendelser/Norsk% 20kodeverk%20for%20uønskede%20pasienthendelser.pdf/_/attachment/inline/e95247b1- bdb4-463b-b730-5a09398db917:88e99f1e911c29fd8101025ad12f685eef995b9c/Norsk% 20kodeverk%20for%20uønskede%20pasienthendelser.pdf. Hugging Face – The AI community building the future. n.d. Accessed March 1, 2023. https:// huggingface.co/. Infographic: The Scale Of The Pandora Papers Leak. 2021, October 4. Statista Infographics. https:// Jain, A., H. Patel, L. Nagalapatti, N. Gupta, S. Mehta, S. Guttula, S. Mujumdar, S. Afzal, R. Sharma Mittal, and V. Munigala. 2020. “Overview and Importance of Data Quality for Machine Learning Tasks.” Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 3561–3562. 16 M. FRIDMAN ET AL. Karlsson, M., and H. Sjøvaag. 2016. “Content Analysis and Online News: Epistemologies of Analysing the Ephemeral Web.” Digital Journalism 4 : 177–192. 1096619. Kommunereformen 2020. 2021, March 15. ssb.no. stat-rapportering/kommunereformen-2020. Making Transparency Possible. 2019. Cappelen Damm Akademisk/NOASP. noasp.64 Miroshnichenko, A. 2018. “AI to Bypass Creativity. Will Robots Replace Journalists? (The Answer Is “Yes”).” Information 9 : 183. NbAiLab/nb-bert-base-mnli Hugging Face. 2023, January 25. bert-base-mnli. Neo4j Graph Data Platform – The Leader in Graph Databases. n.d. Neo4j Graph Data Platform. Accessed March 1, 2023. NetworkX — NetworkX documentation. n.d. Accessed March 1, 2023. Niblock, S. 2007. “From “Knowing How” to “Being Able”: Negotiating the Meanings of Reﬂective Practice and Reﬂexive Research in Journalism Studies.” Journalism Practice 1 : 20–32. https:// doi.org/10.1080/17512780601078829. Niblock, S. 2012. “Envisioning Journalism Practice as Research.” Journalism Practice 6 : 497–512. Noain-Sánchez, A. 2022. “Addressing the Impact of Artiﬁcial Intelligence on Journalism: The Perception of Experts, Journalists and Academics.” Communication & Society 35 : 105–121. TheNorwegianTaxAdministration.2020.Petroleumsskattpå116milliarderkronerfor2019. skatteetaten.no/en/presse/nyhetsrommet/petroleumsskatt-pa-116-milliarder-kroner-for-2019/. NPD Fact Pages. n.d. Accessed May 1, 2022. O’Neil, C. 2016. Weapons of Math Destruction: How big Data Increases Inequality and Threatens Democracy. 1st ed. Crown. OpenCorporates: The Open Database Of The Corporate World. n.d. Accessed February 28, 2023. Open Ownership. n.d. Openownership.Org. Accessed February 28, 2023. openownership.org/en/. pandas—Python Data Analysis Library. n.d. Accessed March 1, 2023. Pandora Papers: An oﬀshore data tsunami - ICIJ. 2021, October 6. 20211006063105/ leak-dataset/. Parratt-Fernández, S., J. Mayoral-Sánchez, and M. Mera-Fernández. 2021. “Aplicación de la inteligen- cia artiﬁcial al periodismo: Análisis de la producción académica.” El Profesional de La Información, e300317. Radon, J., and M. Achuthan. 2017. “Beneﬁcial Ownership Disclosure.” Journal of International Aﬀairs 70 : 85–108. JSTOR. Robie, D. 2015. “Advocating Journalism Practice-as-research: A Case for Recognition in the New Zealand PBRF Context.” Asia Paciﬁc Media Educator 25 : 62–73. 1326365X15575591. Rodríguez, M. T., S. Nunes, and T. Devezas. 2015. “Telling Stories with Data Visualization.” Proceedings of the 2015 Workshop on Narrative & Hypertext - NHT 15: 7–11. 1145/2804565.2804567. Sachs, J. D., and A. M. Warner. 2001. “The Curse of Natural Resources.” European Economic Review 45 (4–6): 827–838. Santos, M. F. D. L., and M.-F. de-Lima-Santos. 2022. “ProPublica’s Data Journalism: How Multidisciplinary Teams and Hybrid Proﬁles Create Impactful Data Stories.” Media and Communication, Skattemotiverte transaksjoner – opplysningsplikt og fradragsrett. November 13, 2020. HR-2020- 2200-A (Høyesterett (Norwegian Supreme Court)). avgjorelser/2020/hoyesterett-straﬀ/hr-2020-2200-a/. JOURNALISM PRACTICE 17 Skup.no. n.d. Accessed February 28, 2023. Stalph, F. 2018. “Classifying Data Journalism: A Content Analysis of Daily Data-Driven Stories.” Journalism Practice 12 : 1332–1350. The State of Data Journalism (No. 2022). 2023. datajournalism.com. survey/2022/. Statistisk sentralbyrå. 2023, February 28. SSB. Stiglitz, J. 2002. “Transparency in Government.” In The Right to Tell: The Role of Mass Media in Economic Development. 1st ed. World Bank Publications. Stray, J. 2019a. “Making Artiﬁcial Intelligence Work for Investigative Journalism.” Digital Journalism 7 : 1076–1097. Túñez-López, J.-M., C. Fieiras-Ceide, and M. Vaz-Álvarez. 2021. “Impact of Artiﬁcial Intelligence on Journalism: Transformations in the Company, Products, Contents and Professional Proﬁle.” Communication & Society 34 : 177–193. Vear, C. ed. 2022. The Routledge International Handbook of Practice-Based Research. Routledge. Waskom, M. 2021. “seaborn: Statistical Data Visualization.” Journal of Open Source Software 6 : 3021. Web64. 2023. Norwegian NLP Resources. (Original work published 2016). Weber, M. 2021. “AI, Media and the Future of News on the Web.” 13th ACM Web Science Conference 2021: 10. Wu, S., E. C. Tandoc, and C. T. Salmon. 2019. “When Journalism and Automation Intersect: Assessing the Inﬂuence of the Technological Field on Contemporary Newsrooms.” Journalism Practice 13 : 1238–1254. Young, M. L., A. Hermida, and J. Fulda. 2018. What Makes for Great Data Journalism. Journalism Practice 12 : 115–135. Zamith, R. 2019. “Transparency, Interactivity, Diversity, and Information Provenance in Everyday Data Journalism.” Digital Journalism 7 : 470–489. 1554409. Zhao, J., T. Wang, M. Yatskar, V. Ordonez, and K.-W. Chang. 2018. Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods. 18 M. FRIDMAN ET AL.","Data journalists are increasingly reliant on automation and artiﬁcial intelligence (AI) to process and analyse massive datasets. AI can contribute to journalism by creating visualizations, verifying accuracy of information, analysing historical data, monitoring social media, ﬁnding patterns and outliers, generating text and much more. However, the integration of AI into the newsroom comes with its own challenges. In this article, we take a practice- based approach to develop a deeper understanding of how to overcome such challenges. Our teams of data scientists, AI experts and journalists took on four projects incorporating data science and machine learning into investigative journalism. From those experiences, we found that access to data at scale, data quality and reworking the concept of “newsworthy” as a machine learning question were the most signiﬁcant obstacles to deploying AI in the newsroom. We recommend closer collaborations between team members of diﬀerent disciplines to create a truly trans-disciplinary approach, as well as some practical considerations for choosing projects to facilitate successful AI-assisted investigations. ARTICLE HISTORY Received 21 March 2023 Accepted 27 August 2023","['R. Krøvel M. Fridman', 'Fabrizio Palumbo']"
A New Adaptive Mixture Distance-Based Improved Density Peaks Clustering for Gearbox Fault Diagnosis,"Sharma, Krishna Kumar and Seal, Ayan and Yazidi, Anis and Krejcar, Ondrej",2022,missing,71,IEEE Transactions on Instrumentation and Measurement,article,"IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
3528716
A New Adaptive Mixture Distance-Based
Improved Density Peaks Clustering for
Gearbox Fault Diagnosis
Krishna Kumar Sharma
, Ayan Seal
, Senior Member, IEEE,
Anis Yazidi
, Senior Member, IEEE, and Ondrej Krejcar
Abstract INTRODUCTION
A
PPROPRIATE fault detection of the gearbox and bearing
will be advantageous for the rotary machine, as they are
indispensable components of it. Typically, rotary machines
operate under harsh conditions, for example, uncertain or
driving loads, up/variable speeds, and material fatigue, which
generate possibilities for faults in the gearbox and bearings [1],
[2], [22]. Thus, it creates improper situations for the machines
and may cause downtime, economic loss, and maintenance
costs to the organizations [3], [4], [5]. Therefore, effective sig-
nal processing techniques can protect the gearbox and bearing
from the unforeseen situations mentioned above. Generally,
vibration signal analysis is an efﬁcient and viable approach
for detecting faults, as they have a high correlation with the
states of machine parts and organizations [6], [7]. There are
various learning methods, such as supervised classiﬁcation and
unsupervised clustering, for fault identiﬁcation. In addition,
the most fundamental exploratory, meta-learning data analysis
method, is clustering, which splits a set of data objects,
denoted as a feature or observation vector, into nonempty,
mutually exclusive subsets, groups, or clusters, such that
elements of the same group are similar to one another based
on some similarity metrics, whereas members of different
subsets are dissimilar [8]. Therefore, much consideration must
be paid to ﬁnding the obscure but imperative information in the
data, for example, insights, patterns, and rules. These primitive
data have no class information that represents the type of
unsupervised learning.
Some frequently employed clustering techniques in machine
fault detection are k-means, hierarchical, afﬁnity propagation,
fuzzy c-means (FCM), and kernel spectral. Shuqing et al. [9]
and Ramos et al. [10] used FCM for fault detection. How-
ever, it adopts the spherical distance data together with the
speciﬁcation and is only effective for homogeneous data dis-
tribution. An improved method built on FCM was Gustafson–
Kessel. After combining the adaptive distance rule and the
covariance matrix, it can handle data with subspace dispersion
in any direction [11]. Gustafson–Kessel was applied in the
fault detection of the roller bearing by Wang et al. [12].
1557-9662 © 2022 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
Liu et al. [13] presented a k-means clustering-based fault
identiﬁcation technique for wind turbines. A fuzzy rule-
based clustering approach was employed for the detection
of anomalies in wind turbines [14]. It was also adopted for
bearing fault detection [15]. An improved FCM clustering
approach was applied for dissolved gas analysis-data-based
transformer fault detection [16]. A hierarchical-based cluster-
ing method was adopted for the evaluation of the vibration
level and interior noise of vehicles [17]. Only a spherical
pattern dataset is suitable for fuzzy and Gustafson–Kessel
algorithms, but data obtained from practical systems have a
variety of structures and shapes. Consequently, a Gath–Geva
was developed to enhance the results. It follows the fuzzy
maximum likelihood estimator. It is appropriate for data from
variant orientations [18], [19]. In [20], afﬁnity propagation
clustering was implemented with adaptive feature selection
on vibration signals for the detection of bearing faults.
Langone et al. [21] introduced a spectral clustering-based
method to identify the normal and erroneous states of a
machine. A sparse subspace clustering technique using a com-
posite graph with a new distance was presented to diagnose
faults in machines [22]. Fong et al. [23] designed a mean
shift-based clustering approach for machinery diagnostics
on vibration signals. Hou et al. [24] presented the fuzzy
Gath–Geva clustering technique, linear discriminant analysis,
and ensemble empirical mode decomposition to diagnose
rolling bearing faults. Although the majority of the studies
mentioned above on intelligent defect identiﬁcation have
shown useful ﬁndings, they still have some obvious ﬂaws,
which are given as follows.
1) Most clustering algorithms for fault diagnosis rely on the
hypothesis that data comprise only numerical values.
2) Most previous works exploit the FCM to diagnose
machine faults. It means that, in the case of high-
dimensional data, the selection of the fuzziﬁer will
be crucial, and it may be trapped in local minima.
Generally, FCM-based fault diagnosis algorithms pre-
fer overlapping and spherical-shaped vibration signal
datasets.
3) Existing clustering-based fault diagnosis methods are not
sufﬁciently general and rely on the input parameters and
the number of clusters for fault types. Thus, there are
situations where they fail due to quite complicated actual
working conditions of the systems.
In
this study, we
explore the possibilities of using
density-based clustering approaches, such as DENCLUE,
OPTICS, and DBSCAN, for fault diagnosis to handle the
limitations stated above because they are suitable for arbitrary-
shaped clusters. Moreover, these algorithms can ﬁlter out
noise from data [25]. However, they are parameter-dependent.
In particular, DBSCAN relies on two parameters, i.e., the
minimum number of data objects in a neighborhood (MinPts)
and the radius of the neighborhood for a data object. The
values of MinPts and the radius of the neighborhood are
determined by users manually, which is intrinsically hard
to ﬁx [25]. Rodriguez and Laio [26] presented a density
peaks clustering (DPC) algorithm to detect arbitrary-shaped
clusters. Since then, DPC has received increased research
attention over the past few years. Generally, the DPC algo-
rithm assumes that the cluster’s center is farther from other
cluster centers and is in a zone with a higher local density
than its neighbors. For each data object or point, the DPC
algorithm computes the local density and the distance from
locations of higher density. Cluster centers are positioned in
the top-right corner of a decision graph that has been created.
Finally, all the data objects are assigned to one of the cluster
centers. However, reliable density estimation is a complex
problem. In their seminal paper, Rodriguez and Laio [26]
suggested estimating density irrespective of the dataset size.
However, small datasets are affected by the cutoff distance
while estimating local density [26]. The DPC algorithm’s
signiﬁcant beneﬁt is its capacity to locate nonspherical clusters
without prior knowledge of the number of classes. The
DPC does not involve an iterative process. However, DPC
might not automatically determine the correct number of
clusters.
A density reachable concept and a divide-and-conquer-
based 3DC clustering algorithm were given in [27] and [28],
respectively, to address the aforementioned problem. Yaohui
et al. [28] and Du et al. [29] investigated the concept of
c-nearest neighbors (c-NN) in DPC for estimating local
density. However, asymmetric edges are given the same
weight as symmetric ones in c-NN-based DPC. Moreover,
evidence from the literature has shown that data objects
with asymmetric edges may end up in different clusters
[30]. Furthermore, cluster representatives are selected based
on the decision graph using a parameter cutoff distance.
Thus, inappropriate selection of parameters may lead to
an inaccurate decision graph and, consequently, incorrect
cluster representatives. Furthermore, most of the clustering
algorithms work under the assumption of numerical or cat-
egorical attributes [25], [31], [32], [33], [34], [35], [36].
In reality, all datasets have categorical and numerical attributes,
which is known as a mixed-attribute dataset. As we will
explain later, clustering unlabeled-mixed datasets is thus a
tedious task. To deal with the latter issue, some clustering
algorithms transform the categorical attributes into numeric
attributes by performing binary encoding. Then, the similarity
between the transformed data objects is then determined
using the Euclidean distance. However, the obtained dis-
tances cannot capture the original structures of categorical
attributes.
Moreover, when it comes to categories with two possible
values, an associated binary representation of them is meaning-
less and hard to interpret [37]. Hsu [38] presented a weighted
distance tree structure with a distance hierarchy. However,
domain knowledge is required for both the creation of distance
hierarchies and the assignment of weights. The interested
readers are referred to [26], [29], [37], [39], [40], [41], [42],
[43], [44] for more information related to several similarity
measures for mixed data (MD) clustering. However, there is
a trend to introduce nonlinearity into similarity measures for
clustering [31]. Thus, clustering a dataset involving mixed
attributes is still a challenging task.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
This article suggests a novel adaptive mixture distance
(AD)-based DPC technique to diagnose mechanical system
gearbox failures. The following are some imperative contribu-
tions made by the proposed approach.
1) The inherent pattern of categorical characteristics is
squashed by most existing techniques, which convert
categorical attributes into sets of binary features. In other
words, transformed binary features have no use. More-
over, their values are difﬁcult to comprehend [37]. Thus,
an entropy-based distance is presented to categorical
features of the 13 UCI datasets and one real-world
dataset, which keeps the original pattern of categorical
attributes without transforming their representation. The
real-world dataset consists of nonstationary vibration
signals from a mechanical system for gearbox fault
diagnosis.
2) A novel AD metric is introduced in this study that
utilizes a weight parameter to merge the two similarity
metrics, S-distance and similarity index. The former is
deﬁned in the open cone of positive deﬁnite matrices
and is based on the concept of S-divergence [8], [31].
It is considered to calculate the separation between two
numerical properties of the datasets examined. The latter
is employed to determine how far apart categorized fea-
tures are from one another. If there are more categorical
features than numerical attributes, the similarity index is
given a higher weight and vice versa.
3) A relatively new local density metric is specially adopted
to deal with the noise that may be produced in real time
while recording nonstationary vibration signals from a
mechanical system. The local density metric relies on
a sequence of the weighted exponential kernel using
a symmetry-favored c-NN (SFCNN). It is capable of
overcoming the limitations of ﬁxed c-NN. Moreover,
it characterizes the implicit geometrical structures. Fur-
thermore, it increases the space in the density between
outliers and core objects, which helps in generating
efﬁcient and correct cluster representatives.
4) A new method for the selection of initial cluster centers
is presented, which assures correct cluster centers even
in the case of an unbalanced dataset and nonuniform
distribution of classes.
The modiﬁed DPC based on AD (MDPC-AD) is implemented
on a total of 13 UCI datasets and a real-world dataset
for gearbox fault diagnosis of a mechanical machine. Five
clustering validation indices, namely, accuracy (A), precision
(P), recall (R), F-Score (F), and the Jaccard index (JI), are
used to show the superiority of the MDPC-AD. However,
abbreviated forms of the validation indices mentioned above
will be used only in ﬁgures for better accommodation and
presentation. Moreover, two internal validation indices, for
example, average clustering error and ratio of separation and
compactness, are also adopted in this study. According to the
results, the MDPC-AD outranks 13 state-of-the-art (SOTA)
approaches.
The remaining work consists of the following. Section II
discusses pertinent related studies. In Section III, the proposed
distance metric deﬁnition is discussed, followed by MDPC-
AD. In Section IV, all experimental ﬁndings are presented.
The work is ﬁnally concluded in Section V.
II. THEORETICAL FOUNDATION OF DPC
A. Notations
Let O
= {O1, O2, . . . , Oi, . . . , On} be a dataset of n
MD objects. Each data object Oi ∈ℜd=|ψ|+|φ|, where 1 ≤
i
≤n, has d number of features or attributes in total.
However, each Oi has |ψ| and |φ| number of numerical
ψ and categorical φ attributes, respectively. Thus, Oψ
i,l is
the lth numerical feature of Oψ
i . Similarly, Oφ
i,l is the lth
categorical attribute of Oφ
i . The domain of lth categorical
feature dm(H φ
l ) = {hl,1, hl,2, . . . , hl,sl } has sl discrete values,
whereas domain of the lth numerical attribute dm(H ψ
l ) is
continuous. Therefore, each Oi is a combination of categorical
and numerical values and it is denoted by [Oψ
i , Oφ
i ] =
[Oψ
i,1, Oψ
i,2, . . . , Oψ
i,|ψ|, Oφ
i,|ψ|+1, . . . , Oφ
i,d={|ψ|+|φ|}].
B. Density Peaks Clustering
Fundamentally, DPC identiﬁes cluster representatives with
a higher density in comparison to their neighbors, and cluster
representatives are located at a relatively large distance from
each other. The two main parameters of this method are the
local density βi of each data object Oi and the distance
γi from objects with greater densities. Furthermore, two
hypotheses correspond to the cluster representatives: 1) cluster
representatives are located in higher density areas and their
neighbors have lower densities and 2) cluster representatives
are in relatively distant positions from each other or at a
relatively higher distance to the data objects of higher density.
The detailed discussion of the computation of βi and γi is
given as follows.
Generally, the DPC algorithm works on numerical values
and adopts the linear Euclidean distance function as a similar-
ity measure for numerical attributes in the clustering analysis.
The Euclidean distance λe between two data objects Oi and
O j is deﬁned by (1) with the assumption that data consist only
of numerical attributes
λ2
e

Oi, O j

=
l=d

l=1

Oi,l −O j,l
2.
(1)
The local density of a data object, Oi, is represented by βi
and is deﬁned by the following equation:
βi =

j
exp

−λ2
e

Oi, O j

αt

(2)
where αt denotes an adjustable variable, which controls the
weight decrease rate. αt is the single variable in (2), and it
relies on choosing the average number of neighbors of all
data objects in the dataset. Rodriguez and Laio [26] deﬁned
αt as given in the following equation:
αt = α⌈τ⌉
(3)
where α⌈τ⌉∈{α1, α2, . . . , α(
n
2)} and this set contains distances
between every pair of two data objects in the dataset, arranged
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
ascendingly. Another parameter γi is also computed using (4),
which shows the minimum distance between the data object
Oi and other data objects with larger density
γi =
⎧
⎨
⎩
min
j
λe
Oi, O j
,
if ∃s.t. βi < β j
max
j

λe

Oi, O j

, else.
(4)
When βi and γi for each data object have been computed,
large values of βi and γi are explored anomalously in this
method to identify the cluster representatives. Based on this
concept, cluster representatives are always located on the
decision graph’s top right side. Once cluster representatives
are identiﬁed, the remaining data objects are assigned to the
nearest cluster with a higher density.
III. PROPOSED METHOD
It is clear from the previous discussion that there are still
some limitations to DPC and its peer methods. Hence, the
DPC algorithm is improved in this study by introducing a
novel adaptive mixture similarity measure. A new method for
estimating the density of data points is introduced. Moreover,
we present a novel way to construct a decision graph. In this
section, we provide the details of the proposed clustering
algorithm, MDPC-AD, and its theoretical complexity analysis.
A. Similarity Measure of Numerical Attributes
For revealing the natural cluster structure in a given dataset,
which is a topic of active research, selecting an appropriate
similarity/dissimilarity metric is essential. Since its inception,
the proper selection of a similarity/difference metric has been
a challenge. Recently, there has been an upsurge of interest
in divergence-based nonlinear similarity measure [8], [31] for
clustering analysis as this type of distance is susceptible to
ﬁnding more appropriate complex cluster boundaries. Thus,
nonlinear S-distance λs is considered here for computing the
distance between two numerical data objects Oψ
i
and Oψ
j in
the |ψ|-dimensional Euclidean space ℜ|ψ|
+
using (5) [31].
Deﬁnition 1: Deﬁne λs : ℜ|ψ|
+ × ℜ|ψ|
+ →ℜ+ ∪{0} as
λ2
s

Oψ
i , Oψ
j

=
|ψ|

l=1

log


Oψ
i,l + Oψ
j,l

/2

−

log

Oψ
i,l

+ log

Oψ
j,l

/2

.
(5)
The fact that f is an injective function with the deﬁnition
f : ℜ|ψ|
+ →M|ψ| ensures that the S-distance is well-deﬁned.
In particular, Oψ
i
= f (Oψ
i ) = diag((Oψ
i,1, Oψ
i,2, . . . , Oψ
i,|ψ|)).
In this case, M|ψ| is a positive deﬁnite matrix with the
dimensions |ψ| × |ψ|. The notion of S-divergence [8], which
is described mathematically by (6), is used to derive the
S-distance
λ2
s

Oψ
i , Oψ
j

= log

Oψ
i + Oψ
j
2


−
log

Oψ
i


+ log

Oψ
j


2
(6)
where | · | is a determinant of a matrix and λ2
s(Oψ
i , Oψ
j ) =
λ2
s( f (Oψ
i ), f (Oψ
j )).
The S-distance satisﬁes all the metric properties. Moreover,
it also obeys the property of Hadamard product. It is also
neither Bregman divergence nor f-divergence. However, it is a
Burbea–Rao divergence. Thus, it is convex on ℜ|ψ|
+ . According
to a prior study [8], when two data objects are close to the
origin and have the same Euclidean distance, their S-distance
is bigger than when they are far from the origin. The
scope of this study does not include the various S-distance
characteristics. To learn more about these features, interested
readers are encouraged to explore [8], [31].
Now, the similarity between two data objects is computed
using a monotonically decreasing spatial generalization expo-
nential function [45]. Mathematically, the exponential function
is deﬁned by the following equation:
χψ

Oψ
i , Oψ
j

= exp
⎛
⎜⎝
−

λs

Oψ
i , Oψ
j
2
2
⎞
⎟⎠
(7)
where χψ ∈[0, 1]. A value of χψ close to 1 indicates that
two data objects Oψ
i
and Oψ
j are similar. On the other hand,
a value of χψ close to 0 indicates that two data objects Oψ
i
and Oψ
j are highly dissimilar.
B. Similarity Measure of Categorical Attributes
Now, it is time to calculate the similarity λφ between two
data objects, namely, Oφ
i and Oφ
j having categorical features
on H φ
l . Most of the existing approaches [39], [41], [43], [44]
transform categorical attributes into sets of binary attributes,
which squashes the native pattern of categorical features.
In other words, converted binary features are purposeless, and
their values are difﬁcult to understand. Thus, an entropy-based
distance is applied to categorical features, which keeps the
original pattern of categorical features without transforming
their representation in this study. First, the similarity between
the lth feature of Oφ
i and Oφ
j is computed by the following
equation:
λφ

Oφ
i,l, Oφ
j,l

=

1,
if Oφ
i,l = Oφ
j,l
0,
if Oφ
i,l ̸= Oφ
j,l.
(8)
Thus, the similarity between two data objects is estimated
by summing the signiﬁcance of each categorical attribute.
Mathematically, it is deﬁned by the following equation:
χφ

Oφ
i , Oφ
j

=
|φ|

l=1
ωlλφ

Oφ
i,l, Oφ
j,l

(9)
where ωl is known as the signiﬁcance of the lth feature. The
value of ωl varies from 0 and 1 and |φ|
l=1 ωl = 1. The
signiﬁcance of the lth attribute is computed with the help of
entropy in information theory by the following equation:
Gφ
l = −

hl,q∈dm

H φ
l
 p

hl,q

log

p

hl,q

(10)
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
where p(hl,q) represents the probability of hl,q feature and
is estimated as (n
i=1 λφ(Oφ
i,l, hl,q)/n). In other words, it is
a ratio of number of objects whose value is equal to
hl,q of categorical feature H φ
l
to the total number of objects
n in a given dataset. It is clear from (10) that if the number
of sl is very large, then the entropy of feature H φ
l will also be
large. However, this is not how things actually are. The entropy
of a categorical feature is reformulated by (11) to lessen the
impact of categorical characteristics having numerous unique
or distinct values, such as an ID number
G φ
l = −1
sl
sl

q=1
p

hl,q

log

p

hl,q

.
(11)
Thus, the weight assigned to each categorical feature H φ
l
is
computed by
ωl =
G φ
l
|φ|
l=1 G φ
l
.
(12)
The similarity measure of categorical attributes can be com-
puted by combining (9) and (12), which is shown in the
following equation:
χφ

Oφ
i , Oφ
j

=
|φ|

l=1
G φ
l
|φ|
l=1 G φ
l
λφ

Oφ
i,l, Oφ
j,l

.
(13)
C. Similarity Measure for MD
The similarity between two data points Oi and O j having
|ψ| number of numerical attributes and |φ| number of cate-
gorical features is computed by merging (7) and (13) with the
help of the more importance concept of information theory,
and the new equation is given by
χOi, O j
 =
|ψ|
|ψ| + |φ| exp
⎛
⎜⎝
−λs

Oψ
i , Oψ
j
2
2
⎞
⎟⎠
+
|φ|
|ψ| + |φ|
|φ|

l=1
G φ
l
|φ|
l=1 G φ
l
λφ

Oφ
i,l, Oφ
j,l

.
(14)
The value of the similarity measure lies between 0 and 1 due to
normalized coefﬁcients. Generally, a DPC algorithm requires
a distance function instead of a similarity measure. Hence,
a logarithmic function is applied to the negative exponent
of (14) as shown in (15). If two data objects are similar, then
the distance would be smaller
λm

Oi, O j

= log

χ

Oi, O j
−1
.
(15)
D. Local Density Metric
In this section, we present: 1) a new local density metric
based on SFCNN; 2) a new method to initialize the cluster
centers; and 3) a way to group density-reachable clusters.
For estimating the local density of a data object Xi in a
set of data, an SFCNN graph is built in this study instead
of a conventional c-NN graph since it is more resistant to
noise and outliers. Fig. 1 is used to explain the distinction
Fig. 1. (a) 3-NN graph’s differences from (b) symmetry-favored 3-NN graphs
(red edges show higher edge weights).
Fig. 2.
Decision graph of Statlog Heart dataset with αt = 0.54.
between a standard c-NN graph and one that favors symmetry.
The graph’s symmetric edges have heavier weights than its
asymmetric edges because the locations they connect are
located in the same submanifold [30], [46]. The underlying
manifold characteristics of the data space can also be used to
explain the SFCNN graph. It can describe implicit geometrical
structures. Moreover, it also increases the space in the density
between outliers and core objects, which helps in generating
efﬁcient and correct cluster representatives. Generally, density
metrics consider Gaussian kernels to estimate the local density
values. Data objects in DPC are represented as points in a
space, where cluster representatives are always on the top-right
part of the decision graph. Once the local density βi and
minimum distance γi from data points of higher density are
calculated for each data object, cluster representatives are
identiﬁed by searching the large parameters βi and γi for
anomalies. The parameter αt determines the average number
of neighbors of all data objects in a dataset. The value of
αt is computed by (16), which depends on the value of “c.”
Based on this idea, cluster centers for the Statlog Heart [47]
sample dataset is estimated, and they can be seen in the
top-right quadrant of the decision graph in Fig. 2. Here, circles
with red color are the initial cluster representatives that are
characterized relatively by the higher distance, γi, and larger
density, βi. They are computed based on the threshold value,
αt = 0.54 (dashed line). After the selection of the cluster
representatives, the remaining data objects are assigned to the
nearest cluster with a higher density. A decision graph assists
in taking a decision. The decision graph is a plot of γi as a
function of βi for each data object
αt = vc +
n
i=1
γ c
i −vc2
n −1
(16)
where γ c
i is the distance between SFCNN and a data object
i, deﬁned as γ c
i = max j∈SFCNNi (λi, j
m ), and vc is the average
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
value of γ c
i and is computed by (17). SFCNNi is a set of data
objects in an SFCNN to data object i
vc =
n
i=1 γ c
i
n
.
(17)
The second part in the right-hand side of (16) represents the
standard deviation of distance calculated between each data
object and its corresponding SFCNN. The local densities can
be estimated by the following equation:
βi =

j∈SFCNNi
exp
⎛
⎜⎝−

λi, j
m
2
(αt)2
⎞
⎟⎠.
(18)
Equation (18) illustrates the distribution information of the
SFCNN of a data object i and uses αt to estimate the local
density βi. Equation (18) considers the sum of all distances
using an exponential kernel. The previous studies [28] reveal
that the value of c in an SFCNN graph has a signiﬁcant impact
while estimating density, and it was ﬁxed to 5 because 2-NN,
3-NN, and 4-NN may be close to normal data objects. Thus,
an enhanced local density is proposed by combining a ﬁxed
SFCNN and a weighted sequence as shown in the following
equation:
βi =

j∈SFCNNi
exp
⎛
⎜⎝−

λi, j
m
2
(αt)2
⎞
⎟⎠
+

j /∈SFCNNi and j̸=i
exp

−

λi, j
m
2
max
j′∈SFCNNi

λ j′, j
m
 .
(19)
The ﬁrst part of (19) takes care of the symmetry-favored
5-NN estimation, which is inherited from (18). On the other
hand, the second part of (19) sums the weighted Gaussian
kernel sequence. This second part is a complement to the
ﬁrst part and compensates for the clustering performance
by overcoming the limitations of ﬁxed c-NN in density
estimation. The weights in the second part have a lesser value
in the case of data objects away from the c-NN and a higher
weightage near the c-NN.
In this work, the DPC algorithm is enhanced by considering
some of the concepts of DBSCAN and OPTICS, which are
given as follows.
Deﬁnition 2 (Core Distance γ e of a Cluster Ce): γ e of a
cluster Ce is computed by the following equation:
γ e =

Oi∈Ce λm(CPe, Oi)
|Ce|
(20)
where |Ce| represents the cardinality of a cluster set Ce and
CPe is the cluster center of Ce. γ e of a Ce is the average of
distances between all the data points belonging to Ce and CPe.
Deﬁnition 3 (Boundary-Data-Object-Pair Set ρx,y Between
Two Clusters, Namely, Cx and C y): ρx,y between Cx and C y
is expressed as follows:
ρx,y =

Oi, O j

|λm

Oi, O j

< min

γ x, γ y
,
Oi ∈Cx, O j ∈C y
(21)
where ρx,y is symmetric in nature.
Deﬁnition 4 (Border Density βe
ρ of Cluster Ce): βe
ρ of Ce
is computed by the following equation:
βe
ρ =
max
(Oi,O j)∈ρx

βi + β j

2
(22)
where ρx consists all boundary-data-objects-pairs between Cx
and other clusters such that ρx = ∪y̸=xρx,y.
Deﬁnition 5 (Density Directly Reachable): In terms of bor-
der density, a cluster Cx is density directly reachable from
another cluster C y if the following conditions hold.
1) ρx,y ̸= {Null}.
2) ∃(Oi, O j) ∈ρx,y, βi < βx
ρ and β j < β y
ρ
It also satisﬁes the symmetric property.
Deﬁnition 6 (Density Reachable): If there is a path con-
necting two clusters Cx and C y such that Cx = C1, C2,
. . . , Cn = C y, each Ci is directly reachable to Ci+1, then
the two clusters are said to be density reachable to one
another. Moreover, it obeys the symmetric as well as transitive
properties.
E. Improved DPC Algorithm and Its Complexity
In this section, the essential details of the MDPC-AD are
discussed with an analysis of its complexity. Algorithm 1 is a
logical step-by-step analysis of the MDPC-AD. The algorithm
of the MDPC-AD is presented to make it easy for the reader
to identify the process, major decision points, and variables
necessary to implement MDPC-AD.
Fig. 3 is employed to illustrate the detailed processes of the
MDPC-AD on a particular dataset named Wine [47] consisting
of numerical attributes only. The ﬁrst two principal compo-
nents of each data object of the Wine dataset are obtained
using PCA and are shown on a 2-D plane using pink color in
Fig. 3(a). Here, a dataset consisting of numerical features is
considered because PCA can only work on numerical attributes
to generate principal components. Three density peaks in
the top-right corner are automatically recognized as cluster
representatives in Fig. 3(b), which shows the decision graph
of γi as a function of βi for each data object and data objects in
red are initial cluster representatives above the threshold αt and
threshold αt is displayed as green dashed line. The remaining
data objects are then assigned to the closest clusters to obtain
the corresponding cluster, as shown in Fig. 3(c). Finally,
a grouping of the density reachable clusters is performed and
the ﬁnal obtained clusters are shown in Fig. 3(d).
The
following
factors
are
used
to
discuss
how
time-consuming
the
MDPC-AD
is.
First,
the
distance
between data objects is calculated with complexity O(n2E),
where E is the time required to compute λm() between two
data objects and n represents the number of data objects
in the dataset. Later, sorting of distance vector will require
O(n2 log(n)) complexity. An SFCNN graph will take O(cn)
times for calculation of βi, where c is smaller than n. The
calculation of distance γi for each data object requires O(n2)
steps. Furthermore, initial representatives for clusters are
selected and the assignment of data objects to clusters is
completed in O(n2) times. The calculation of core distance
γ e and border density βe
ρ will take only O(n). The estimation
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
Fig. 3.
Illustration of the MDPC AD that has been proposed. (a) Visualization of the wine dataset using the ﬁrst two principal components, showing the ﬁrst
and second corresponding vectors of the data matrix along the axes. (b) Decision graph for the wine dataset in (a). (c) Clustering result after nearest cluster
assignment. (d) Clustering result after grouping of density reachable clusters.
of boundary-data-object-pair sets will require approximately
O(n2) steps. In conclusion, the time complexity of the
MDPC-AD is O(n2 log(n)).
IV. EXPERIMENTAL RESULTS AND DISCUSSION
This work is done on a laptop running Windows 10 with an
Intel1 Core2 i7-2620M CPU clocked at 2.70 GHz and 8 GB
of RAM using the Spyder 3.2.8 Python development environ-
ment. This study does not include I/O costs.
A. Experimental Setup and Dataset Description
1) Dataset #1: Thirteen well-known real-world datasets
from the UCI repository are considered in this study. Table I
contains some statistical information, such as name, type, the
number of clusters (k), the total number of features (d), the
number of numerical features (Fψ), the number of categorical
features (Fφ), and the total number of samples (n) from
these datasets. Interested readers may discover more details
regarding these datasets in [47].
1Registered trademark.
2Trademarked.
TABLE I
STATISTICS OF UCI DATASETS USED IN THIS STUDY
2) Dataset #2: The proposed method’s efﬁciency is also
tested on machine fault diagnostics, with data containing three
categories of gearbox problems, such as missing teeth, tooth
wear, and root faults. As shown in Fig. 5, a test rig is
used to identify the faults in a gearbox that are shown in
Fig. 4 [22], [23]. The three defective gears, as well as one
healthy gear, are installed in the test setup. Then, using a
controller, it is powered at its rotational speed by a regulated
motor. A brake is used at the shaft’s end location to provide
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
Fig. 4.
Faults of the gears: (a) normal, (b) missing teeth, (c) wear in teeth, and (d) fault in root.
Algorithm 1 Proposed DPC Algorithm
Require: O = {O1, . . . , Oi, . . . , On}
▷where
Oi ∈ℜd=|ψ|+|φ|
Ensure: C = {C1, C2, . . . , Ck}
▷a set of resultant clusters
1: Calculate distance matrix and parameter αt using Eqs. 15
and16, respectively
2: Calculate βi and γi for all data objects Oi ∈O by Eqs. 16
to 19.
3: Choose all data objects whose γi is larger than the αt
cutoff distance in the decision graph and set k′ initial
representatives of clusters as C P = {C Pi|1 ≤i ≤k′}
and remaining data object will be O′ = O −C P.
4: for all Oi ∈O′ do
label =
min
CP j ∈C j &1≤j≤k′{λm(Oi, C P j)}; ▷nearest cluster
Clabel ←Clabel ∪Oi
5: end for
6: Compute the core distance γ e and boundary density βe
ρ of
each cluster e using Eqs. 20 to 22.
7: repeat
▷Group all density-reachable clusters
8:
for all Ci ∈C do
9:
for all C j ∈C −Ci do
10:
if Ci and C j satisfy Defs. 5 and 6 then
11:
Ci ←Ci ∪C j and update set C
12:
end if
13:
end for
14:
end for
15: until Grouping of density reachable clusters
16: Return C = {C1, . . . , Ck} as the set of the clusters.
a load to the system. As shown in Fig. 5, an experiment for
intelligent fault detection was carried out. The gearbox was not
loaded, and the motor’s speed was set to 1800 r/min. Three
acceleration sensors that were ﬁxed in the housing’s vertical,
horizontal, and axial directions and connected to its right end
were employed to collect vibration data at a sampling rate
of 12.8 kHz. However, categorical data, such as the number
of cylinders, the forwarding gear values, and the number
of carburetors, are discontinuous parameters. Four separate
conditions, namely, tooth wear, root defect, missing teeth, and
healthy, were used to collect vibration signals. As shown in
Fig. 6, the original vibration signal is split into 90 segments,
each of which contains 5023 samples.
The
MDPC-AD
method
is
presented
to
diagnose
machine
faults
via
vibration
signals,
and
categorical
features
are
obtained
to
determine
the
state
variation
due to faults [22], [23]. As discussed in Section II-A,
O = {O1, O2, . . . , Oi, . . . , On} is a dataset of n MD vectors.
Each data vector Oi ∈ℜd=|ψ|+|φ|, where 1 ≤i ≤n, has
a total of d features or attributes. However, each Oi has a
|ψ| and |φ| number of signal features ψ and categorical
φ attributes, respectively. One assumption is made in this
application that the number of data objects in each cluster
is equal. Let k be the number of clusters, and the data
objects from each cluster are n/k. The MDPC-AD method is
performed for the diagnosis of a faulty gearbox, as discussed
in Algorithm 1.
B. Evaluation Metrics
Accuracy is one of the most commonly reported evaluation
measures. It describes the percentage of accurate clustering
outcomes among all the outcomes a machine learning algo-
rithm produces. It is an intuitive and straightforward evaluation
metric. A machine learning algorithm is better and more
preferable if its percentage accuracy is near 100. On the other
hand, depending just on accuracy for unbalanced data can
be deceptive. In this situation, in addition to accuracy, other
assessment measures, including precision, recall, F-Score, and
JI, may be considered to determine how effective a model
is [25]. Moreover, two internal validation indices, for example,
the average clustering error and the ratio of separation to
compactness, are also adopted in this study.
C. Computational Protocol
This study compares the performance of the proposed
approach, MDPC-AD, with 13 SOTA methods.
1) K-PC: k-prototypes clustering algorithm for mixed
datasets [39].
2) EK-PC: An evolutionary k-prototypes clustering algo-
rithm for mixed-type datasets [41].
3) KL-FCM-GM:
An
FCM-type
clustering
algorithm
for mixed datasets with a probabilistic dissimilarity
function [42].
4) FK-PC: A fuzzy k-prototypes clustering algorithm for
MD [43].
5) IK-PC: An improved k-prototypes clustering algorithm
for mixed numerical and categorical data [44].
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
Fig. 5.
(a) Gear test rig and (b) accelerometers ﬁxed in the vertical, axial, and horizontal directions.
Fig. 6.
Vibration signal in four different conditions of the gear from the
experiment.
6) CAVE: A clustering algorithm based on variance and
entropy for mixed datasets [40].
7) SBAC:
A
similarity-based
agglomerative clustering
algorithm for data with mixed features [37].
8) SpectralCAT: Categorical spectral clustering for numer-
ical and nominal data [48].
9) DKFCM: A density-oriented kernel FCM algorithm for
fault diagnosis [10].
10) DPC-MD: A novel DPC method for MD using a
distance for MD [29].
11) PE-EEMD-GG:
A
method
based
on
permutation
entropy, ensemble empirical mode decomposition, and
the Gath–Geva clustering method for bearing fault diag-
nosis [24].
12) CG-SSC: A composite graph-based sparse subspace
clustering method for machine fault diagnosis [22].
13) MSC: A mean shift clustering-based approach with
a
spectral
preprocessing
technique
for
machinery
diagnostics [23].
Since the researchers have not given their works a name,
appropriate
nomenclatures
for
these
methodologies
are
employed. The scope of this study does not include a thor-
ough description of these techniques. However, we use the
precise procedures outlined in the original papers. As a result,
interested readers are directed to the source works for more
information.
D. Results and Comparison
In this study, a total of nine experiments are conducted to
validate the MDPC-AD. The ﬁrst eight experiments are carried
out on the UCI datasets using ﬁve external validation indices.
The last experiment is performed to identify the faults in the
gearbox of a rotary mechanical machine with the help of two
internal validation measures.
1) Experiment on Categorical Datasets: In the ﬁrst exper-
iment, the MDPC-AD is executed on datasets, namely, D1,
D2, and D3, having categorical attributes only. These datasets
do not possess numerical features. The second part of (14),
followed by (15), is considered while computing distance.
The clustering report obtained by the MDPC-AD is noted in
the last column of Table II. The clustering reports generated
by existing methods are also included in Table II. The best
clustering report produced by a method is marked by bold
characters. All the results of Table II demonstrate that the
MDPC-AD outperforms all the above-discussed 13 SOTA
methods. However, the performance of DPC-MD and MSC
on D3 is the same as that of the MDPC-AD.
2) Experiment on Numerical Datasets: In the second exper-
iment, the MDPC-AD is implemented on datasets, namely,
D4, D5, D6, and D7, having only numerical attributes. These
datasets do not have categorical features. Fig. 7 shows the
ﬁrst two principal components of D4, D5, D6, and D7 plotted
in 2D planes. It is clear from Table I and Fig. 7 that each
dataset consists of a varying number of data points. Moreover,
they have arbitrary shape clusters. Now, the ﬁrst part of (14),
followed by (15), is employed while computing distance.
The clustering reports of all the 14 methods, including the
MDPC-AD, are reported in Table III. The best performance
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
TABLE II
CLUSTERING REPORTS ON D1, D2, AND D3 USING FIVE VALIDATION INDICES
TABLE III
CLUSTERING REPORTS ON D4, D5, D6, AND D7 USING FIVE VALIDATION INDICES
TABLE IV
CLUSTERING REPORTS ON D8, D9, D10, D11, D12, AND D13 USING FIVE VALIDATION INDICES
achieved by a method is marked by a bold character. We can
conclude after observing all the results of Table III that the
MDPC-AD outperforms all 13 SOTA methods even when the
data points of D4, D5, D6, and D7 are varying and have
arbitrary shape clusters.
3) Experiment on Mixed Datasets: In the third experiment,
the MDPC-AD is executed on mixed datasets, namely, D8,
D9, D10, D11, D12, and D13. These datasets contain both
numerical as well as categorical variables. Here, (15) is used
to compute the distance between data objects. The clustering
reports produced are presented in Table IV. The best clustering
report generated by a method is marked by bold characters.
It is clear from Table IV that the MDPC-AD outperforms all
the above-discussed 13 SOTA methods.
In summary, we can say that the clustering reports in
terms of precision, recall, F-Score, JI, and accuracy obtained
by the proposed method named MDPC-AD are higher
than the other 13 SOTA existing approaches mentioned in
Section IV-C. The primary reason is that K-PC, EK-PC,
IK-PC, FK-PC, DKFCM, PE-EEMD, CG-SSC, MSC, and
DPC-MD are sensitive to the initialization of cluster rep-
resentatives and are improper for nonspherically distributed
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
Fig. 7.
First two principal components of the dataset on the left and its updated version with noise features as the number of genuine features on the
right were shown on a plane to display the ﬁrst and second matching vectors of the data matrix along the axes. Different colors indicate different data point
classiﬁcations. (a) D4. (b) D4 with noisy features. (c) D5. (d) D5 with noisy features. (e) D6. (f) D6 with noisy features. (g) D7. (h) D7 with noisy features.
data. Moreover, SBAC addresses similarity measures with the
assumption that the unusual matched feature values correspond
to higher weights. DKFCM adopts a fuzzy objective func-
tion that is designed based on several probabilistic theories
regarding the organization of the obtained clusters. CAVE
is sensitive to the procedure of sampling. The efﬁciency
of SpectralCAT depends on the selection of kernel func-
tion to compute the Markov matrix. On the other hand,
MDPC-AD overcomes some of the abovementioned issues.
Thus, MDPC-AD achieved good clustering results on the
above-discussed numerical, categorical, and mixed datasets.
4) Experiment on Noisy Datasets: The fourth experiment is
conducted on datasets, namely, D4, D5, D6, and D6, having
only numerical variables to know whether the MDPC-AD is
robust against the noisy features. After adding noisy features
produced by a uniform random distribution in the length and
size limit of the original dataset, the inﬂuence of noisy features
is examined. Therefore, a dataset’s number of features would
be twice as many as its initial number of attributes. The
ﬁrst two principal components of each of the aforementioned
datasets, as plotted on 2-D planes, are shown in Fig. 7 before
and after the addition of noisy features. Fig. 7 makes it obvious
that for a dataset; practically, all of the mapped locations have
signiﬁcant overlaps with one another. This simply means that
the existence of noisy features hurts these datasets. The results
obtained by all techniques after including noisy features are
shown in Fig. 8 against ﬁve assessment metrics, including
accuracy, precision, recall, F-Score, and Jaccard index on
D4–D7. The results show that the MDPC-AD performs better
than any other approach, from K-PC to SpectralCAT. For a
small number of datasets, clustering performance is dramati-
cally reduced. Nevertheless, the S-distance, which is utilized
to calculate the separations between numerical data items and
is invariant to the Hadamard product, makes the MDPC-AD
resilient [8].
5) Experiment for Knowing the Impact of “c” in Symmetric
Favored c-NN: In this work, local density is estimated based
on a sequence of the weighted exponential kernel using an
SFCNN. In the previous four experiments, the value of “c” is
considered 5, as suggested by the past studies [28]. However,
the ﬁfth experiment is conducted to verify the previous claim.
The value of “c” varies from 1 to 19 with a step size of 2.
The values of accuracy, precision, recall, F-Score, and Jaccard
index for each value of “c” over all 13 datasets are shown in
Fig. 9. The values of “c” are shown on the x-axis, and the
clustering results are shown on the y-axis. It is clear from
Fig. 9 that the values of clustering metrics are maximum
when the value of “c” varies from 1 to 5 on datasets, i.e.,
D3, D8, and D9. However, the performance increases slightly
on D6 when the value of “c” is beyond 5. On the other
hand, the performances remain consistent on D11 and D13.
The clustering performances deteriorate on D1, D2, D4, D5,
D7, D10, and D12 when the value of “c” is beyond 12.
It means that it is really difﬁcult to ﬁnd out the optimum
value of “c.” However, it relies on the characteristics of a
dataset.
6) Experiment on Order Sensitivity: In the ﬁnal experiment,
the order of the data objects in a dataset is changed while
still analyzing the clustering result. This sensitivity analysis
measures the stability of the algorithm due to randomness and
erroneous assessment. The MDPC-AD is executed ten times
on 13 datasets. However, the positions of data objects are
changed by shufﬂing them randomly, and the corresponding
clustering results are shown in Fig. 10. The x-axis and y-axis
of each plot in Fig. 10 denote, respectively, the number of
iterations and the value of the metric in question. It is clear
from Fig. 9 that the MDPC-AD is not sensitive to the position
of data objects or order since the performance is the same or
constant in all ten runs.
7) Experiment for Run-Time Comparison: All the methods
mentioned in Section IV-C are not only compared based on
their clustering reports but also compared based on their
execution time, which is measured and noted in Table V. It is
clear from Table V that most of the time MDPC-AD takes
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
Fig. 8.
Comparison of clustering results on numerical datasets with noisy features. (a) Precision. (b) Recall. (c) F-Score. (d) Jaccard index. (e) Accuracy.
TABLE V
METHODS RUN TIME (UNIT: s)
less time compared to K-PC, EK-PC, KL-FCM-GM, FK-PC,
IK-PC, CAVE, DKFCM, DPC-MD, SpectralCAT, PE-EEMD,
CG-SSC, MSC, and SBAC. However, in some cases, K-PC
has a lesser execution time compared to the MDPC-AD,
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
Fig. 9.
Evaluation of MDPC-AD for different values of “c” values on all the datasets. (a) Precision. (b) Recall. (c) F-Score. (d) Jaccard index. (e) Accuracy.
Fig. 10.
Evaluation of MDPC-AD for testing sensitivity on 13 datasets. (a) Precision. (b) Recall. (c) F-Score. (d) Jaccard index. (e) Accuracy.
whereas MDPC-AD has a lesser execution time than EK-PC,
KL-FCM-GM, IK-PC, CAVE, DKFCM, SpectralCAT, PE-
EEMD, CG-SSC, MSC, and SBAC. Overall, the proposed
MDPC-AD executes in lesser time and outperforms other
methods. Moreover, the best execution times are bold in
Table V.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
TABLE VI
ABLATION STUDY ON D8, D9, D10, D11, D12, AND D13
TABLE VII
GEARBOX FAULT DIAGNOSIS USING TWO
INTERNAL VALIDATION INDICES
8) Ablation Study: The steps of MDPC-AD are determined
after conducting an ablation study on mixed datasets only.
DPC presented by Rodriguez and Laio [26] is implemented
in the ﬁrst analysis. In the second analysis, the impact of the
proposed AD mentioned in (12) is evaluated by incorporating
it in DPC and renaming the modiﬁed algorithm as DPC-
AD. In the third analysis, a new method to estimate local
density is adopted, which relies on a sequence of the weighted
exponential kernel using an SFCNN to overcome the limitation
of ﬁxed c-NN and names the method DPC-AD-SFCNN. In the
fourth study, a method for automatic selection of the initial
cluster representatives is utilized from MDPC-AD and merged
with DPC-AD-SFCNN and marked as DPC-AD-SFCNN-
CR. The MDPC-CNN-MD considers the c-NN in place of
an SFCNN for estimating local density. It also adopts the
presented distance from [29]. The MDPC-CNN-AD is similar
to the MDPC-CNN-MD, except that instead of using the
presented distance in [29], it employs the proposed distance.
Finally, CNN in MDPC-CNN-MD is substituted with SFCNN,
which is now called MDPC-SFCNN-MD. Furthermore, the
results of these studies are noted in Table VI to validate the
superiority of the proposed method, MDPC-AD. All the results
demonstrate that the proposed method, MDPC-AD, is superior
to other combinations of the DPC algorithm.
9) Case Study for Gearbox Fault Diagnosis Using Clus-
tering: In this section, MDPC-AD is compared with DPC,
DPC-AD, DPC-AD-SFCNN, and DPC-AD-SFCNN-CR. This
experiment is performed to group the state of the gears of
a mechanical machine. For the same, features of the data
obtained in 1 s are considered as a sample, and 90 samples/data
objects are analyzed. A quantitative clustering analysis is
conducted using two internal validation indices. First, a ratio
of separation SP and compactness CM is computed, and their
ratio ID1 = SP/CM is used as the metric for comparison. For
this metric, a high value of SP is desired, and a low value
of CM is suitable for good clusters. Thus, a high value of
ID1 indicates effective clustering results. Second, a clustering
error, ID2, is adopted for comparison and a smaller value of
clustering error shows the most effective. A comparison of
ID1 index on the above discussed ﬁve methods is shown in
Table VII. In the case of MDPC-AD, SP has a high value, and
CM obtained the ideal value equal to zero; thus, the value of
ID1 is extremely large or tends to inﬁnity, which shows that
MDPC-AD outperforms other SOTA methods. It indicates that
MDPC-AD can yield well-separated and most compact clus-
ters. Second, a comparison is shown using ID2 where all the
methods are executed 50 times, and the average error is com-
puted and presented in Table VII. As mentioned in Table VII,
MDPC-AD achieved the lowest value equal to zero, meaning
that there was nil clustering error in the proposed method while
diagnosing the faults in a gearbox. Therefore, the proposed
study is an effective method for gearbox fault diagnosis.
V. CONCLUSION
This study introduces the DPC-based clustering technique
named MDPC-AD for gearbox fault diagnostics. An ablation
study is conducted to demonstrate the effectiveness of each
part of the MDPC-AD. The obtained results illustrate that the
novel AD can more clearly reveal the structure of the 13 real-
world datasets from UCI under examination. To calculate the
global parameter and the local density of each data object, the
MDPC-AD employs the idea of a series of weighted Gaussian
kernels based on an SFCNN. In addition, the MDPC-AD is
easier to control than DBSCAN and DPC since it can choose
the initial cluster representatives automatically by establishing
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING
3528716
the cutoff distance as a function of parameter c. The ﬁrst
cluster representatives’ computation, however, ensures the
inclusion of genuine initial cluster representatives. The con-
cept of grouping density reachable clusters is employed to
solve this problem in subsequent iterations, even though our
method may initially choose incorrect cluster representatives.
According to experiments on different real-world datasets, the
MDPC-AD outperforms the 13 SOTA approaches mentioned
in this article. Even though an experiment is run to see how ‘c’
affects things, more research is still required. Finding the ideal
value for “c” and understanding the relationship between the
parameters αt and “c” call for more investigation. It would also
be intriguing to expand the capabilities of the current algorithm
to manage large datasets with mixed attributes. Although
MDPC-AD improves clustering efﬁciency, the decreased efﬁ-
ciency of MDPC-AD compared to DPC is due to the high
computational complexity of density estimation. Therefore,
it is essential to reduce the computational complexity of
density estimation, a subject that merits more study. Finally,
in mechanical systems, clustering algorithms have proven to
be more reliable, particularly for fault diagnosis. The names
of two faults that could affect gearboxes, bearings, and wind
turbines, are mentioned in this study. The last two, which merit
additional research, have not been covered in this article.
ACKNOWLEDGMENT
The authors would like to thank the support of Ph.D. student
Michal Dobrovolny for consultations.
REFERENCES
[1] J. Sun, C. Yan, and J. Wen, “Intelligent bearing fault diagnosis method
combining compressed data acquisition and deep learning,” IEEE Trans.
Instrum. Meas., vol. 67, no. 1, pp. 185–195, Jan. 2018.
[2] C. Sun, M. Ma, Z. B. Zhao, and X. Chen, “Sparse deep stacking network
for fault diagnosis of motor,” IEEE Trans. Ind. Informat., vol. 14, no. 7,
pp. 3261–3270, Mar. 2018.
[3] S. B. Wang, X. F. Chen, C. W. Tong, and Z. B. Zhao, “Matching syn-
chrosqueezing wavelet transform and application to aeroengine vibration
monitoring,” IEEE Trans. Instrum. Meas., vol. 66, no. 2, pp. 360–372,
Feb. 2017.
[4] Y. Chen and M. J. Zuo, “A sparse multivariate time series model-based
fault detection method for gearboxes under variable speed condition,”
Mech. Syst. Signal Process., vol. 167, Mar. 2022, Art. no. 108539.
[5] Y. Liu, B. Liu, X. Zhao, and M. Xie, “A mixture of variational
canonical correlation analysis for nonlinear and quality-relevant process
monitoring,” IEEE Trans. Ind. Electron., vol. 65, no. 8, pp. 6478–6486,
Aug. 2018.
[6] W. Teng, Y. Liu, Y. Huang, L. Song, Y. Liu, and Z. Ma, “Fault detection
of planetary subassemblies in a wind turbine gearbox using TQWT
based sparse representation,” J. Sound Vibrat., vol. 490, Jan. 2021,
Art. no. 115707.
[7] Y. Liao, L. Zhang, and W. Li, “Regrouping particle swarm optimization
based variable neural network for gearbox fault diagnosis,” J. Intell.
Fuzzy Syst., vol. 34, no. 6, pp. 3671–3680, 2018.
[8] S. Chakraborty and S. Das, “K—Means clustering with a new
divergence-based distance metric: Convergence and performance analy-
sis,” Pattern Recognit. Lett., vol. 100, pp. 67–73, Dec. 2017.
[9] Z. Shuqing, S. Guoxiu, L. Liang, L. Xinxin, and J. Xiong, “Study on
mechanical fault diagnosis method based on LMD approximate entropy
and fuzzy C-means clustering,” Chinese J. Sci. Instrum., vol. 34, no. 3,
pp. 714–720, 2013.
[10] A. R. Ramos et al., “A novel fault diagnosis scheme applying fuzzy clus-
tering algorithms,” Appl. Soft Comput., vol. 58, pp. 605–619, Sep. 2017.
[11] D. Gustafson and W. Kessel, “Fuzzy clustering with a fuzzy covariance
matrix,” in Proc. IEEE Conf. Decis. Control including 17th Symp. Adapt.
Processes, Jan. 1978, pp. 761–766.
[12] S. Wang, L. Li, S. Zhang, and G. Sun, “Mechanical fault diagnosis
method based on EEMD sample entropy and GK fuzzy clustering,”
China Mech. Eng., vol. 24, no. 22, p. 3036, 2013.
[13] X. Liu, M. Li, S. Qin, X. Ma, and W. Wang, “A predictive fault
diagnose method of wind turbine based on K-means clustering and
neural networks,” J. Internet Technol., vol. 17, no. 7, pp. 1521–1528,
2016.
[14] P. Baraldi, F. D. Maio, M. Rigamonti, E. Zio, and R. Seraoui, “Unsuper-
vised clustering of vibration signals for identifying anomalous conditions
in a nuclear turbine,” J. Intell. Fuzzy Syst., vol. 28, no. 4, pp. 1723–1731,
2015.
[15] S. Fu, K. Liu, Y. Xu, and Y. Liu, “Rolling bearing diagnosing method
based on time domain analysis and adaptive fuzzy C-means clustering,”
Shock Vibrat., vol. 2016, pp. 1–8, Jan. 2016.
[16] E. Li, L. Wang, B. Song, and S. Jian, “Improved fuzzy C-means
clustering for transformer fault diagnosis using dissolved gas analysis
data,” Energies, vol. 11, no. 9, p. 2344, Sep. 2018.
[17] Z. M. Nopiah, A. K. Junoh, and A. K. Arifﬁn, “Vehicle interior noise
and vibration level assessment through the data clustering and hybrid
classiﬁcation model,” Appl. Acoust., vol. 87, pp. 9–22, Jan. 2015.
[18] I. Gath and A. B. Geva, “Unsupervised optimal fuzzy clustering,” IEEE
Trans. Pattern Anal. Mach. Intell., vol. 11, no. 7, pp. 773–780, Jul. 1989.
[19] J. C. Bezdek and J. C. Dunn, “Optimal fuzzy partitions: A heuristic for
estimating the parameters in a mixture of normal distributions,” IEEE
Trans. Comput., vol. C-24, no. 8, pp. 835–838, Aug. 1975.
[20] Z. X. Wei, Y. X. Wang, S. L. He, and J. D. Bao, “A novel intelli-
gent method for bearing fault diagnosis based on afﬁnity propagation
clustering and adaptive feature selection,” Knowl.-Based Syst., vol. 116,
pp. 1–12, Jan. 2017.
[21] R. Langone, C. Alzate, B. D. Ketelaere, J. Vlasselaerc, W. Meertc, and
J. A. K. Suykensa, “LS-SVM based spectral clustering and regression
for predicting maintenance of industrial machines,” Eng. Appl. Artif.
Intell., vol. 37, pp. 268–278, Jan. 2015.
[22] C. Sun, X. Chen, R. Yan, and R. X. Gao, “Composite-graph-based sparse
subspace clustering for machine fault diagnosis,” IEEE Trans. Instrum.
Meas., vol. 69, no. 5, pp. 1850–1859, May 2020.
[23] S. Fong, J. Harmouche, S. Narasimhan, and J. Antoni, “Mean
shift clustering-based analysis of nonstationary vibration signals for
machinery diagnostics,” IEEE Trans. Instrum. Meas., vol. 69, no. 7,
pp. 4056–4066, Jul. 2020.
[24] J. Hou, Y. Wu, H. Gong, A. S. Ahmad, and L. Liu, “A novel intelligent
method for bearing fault diagnosis based on EEMD permutation entropy
and GG clustering,” Appl. Sci., vol. 10, no. 1, p. 386, Jan. 2020.
[25] A. Fahad et al., “A survey of clustering algorithms for big data:
Taxonomy and empirical analysis,” IEEE Trans. Emerg. Topics Comput.,
vol. 2, no. 3, pp. 267–279, Sep. 2014.
[26] A. Rodriguez and A. Laio, “Clustering by fast search and ﬁnd of density
peaks,” Science, vol. 344, no. 6191, pp. 1492–1496, Jun. 2014.
[27] Z. Liang and P. Chen, “Delta-density based clustering with a divide-
and-conquer strategy: 3DC clustering,” Pattern Recognit. Lett., vol. 73,
pp. 52–59, Apr. 2016.
[28] L. Yaohui, M. Zhengming, and Y. Fang, “Adaptive density peak
clustering based on K-nearest neighbors with aggregating strategy,”
Knowl.-Based Syst., vol. 133, pp. 208–220, Oct. 2017.
[29] M. Du, S. Ding, and Y. Xue, “A novel density peaks clustering algorithm
for mixed data,” Pattern Recognit. Lett., vol. 97, pp. 46–53, Oct. 2017.
[30] L. C. Jiao, F. Shang, F. Wang, and Y. Liu, “Fast semi-supervised clus-
tering with enhanced spectral embedding,” Pattern Recognit., vol. 45,
no. 12, pp. 4358–4369, 2012.
[31] A. Karlekar, A. Seal, O. Krejcar, and C. Gonzalo-Martín, “Fuzzy
K-means
using
non-linear
S-distance,”
IEEE
Access,
vol.
7,
pp. 55121–55131, 2019.
[32] F. Cao, J. Z. Huang, and J. Liang, “A fuzzy SV-K-modes algorithm
for clustering categorical data with set-valued attributes,” Appl. Math.
Comput., vol. 295, pp. 1–15, Feb. 2017.
[33] U. Maulik, S. Bandyopadhyay, and I. Saha, “Integrating clustering and
supervised learning for categorical data analysis,” IEEE Trans. Syst.,
Man, Cybern. A, Syst. Humans, vol. 40, no. 4, pp. 664–675, Jul. 2010.
[34] I. Saha and U. Maulik, “Incremental learning based multiobjective fuzzy
clustering for categorical data,” Inf. Sci., vol. 267, pp. 35–57, May 2014.
[35] I. T. R. Yanto, M. A. Ismail, and T. Herawan, “A modiﬁed fuzzy K-
partition based on indiscernibility relation for categorical data cluster-
ing,” Eng. Appl. Artif. Intell., vol. 53, pp. 41–52, Aug. 2016.
[36] M. Li, S. Deng, L. Wang, S. Feng, and J. Fan, “Hierarchical clustering
algorithm for categorical data using a probabilistic rough set model,”
Knowl.-Based Syst., vol. 65, pp. 60–71, Jul. 2014.
[37] C. Li and G. Biswas, “Unsupervised learning with mixed numeric
and nominal data,” IEEE Trans. Knowl. Data Eng., vol. 14, no. 4,
pp. 673–690, Jul./Aug. 2002.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
 3528716
IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022
[38] C.-C. Hsu, “Generalizing self-organizing map for categorical data,”
IEEE Trans. Neural Netw., vol. 17, no. 2, pp. 294–304, Mar. 2006.
[39] Z. Huang, “Clustering large data sets with mixed numeric and categorical
values,” in Proc. 1st Paciﬁc–Asia Conf. Knowl. Discovery Data Mining,
1997, pp. 21–34.
[40] C.-C. Hsu and Y.-C. Chen, “Mining of mixed data with application to
catalog marketing,” Exp. Syst. Appl., vol. 32, no. 1, pp. 12–23, 2007.
[41] Z. Zheng, M. Gong, J. Ma, L. Jiao, and Q. Wu, “Unsupervised
evolutionary clustering algorithm for mixed type data,” in Proc. IEEE
Congr. Evol. Comput., Jul. 2010, pp. 1–8.
[42] S. P. Chatzis, “A fuzzy C-means-type algorithm for clustering of data
with mixed numeric and categorical attributes employing a probabilistic
dissimilarity functional,” Exp. Syst. Appl., vol. 38, no. 7, pp. 8684–8689,
2011.
[43] J. Ji, W. Pang, C. Zhou, X. Han, and Z. Wang, “A fuzzy K-prototype
clustering algorithm for mixed numeric and categorical data,” Knowl.-
Based Syst., vol. 30, pp. 129–135, Jun. 2012.
[44] J. Ji, T. Bai, C. Zhou, C. Ma, and Z. Wang, “An improved K-
prototypes clustering algorithm for mixed numeric and categorical data,”
Neurocomputing, vol. 120, pp. 590–596, Nov. 2013.
[45] S. Santini and R. Jain, “Similarity measures,” IEEE Trans. Pattern Anal.
Mach. Intell., vol. 21, no. 9, pp. 871–883, Sep. 1999.
[46] J. Jiang, Y. Chen, X. Meng, L. Wang, and K. Li, “A novel density
peaks clustering algorithm based on K nearest neighbors for improving
assignment process,” Phys. A, Stat. Mech. Appl., vol. 523, pp. 702–713,
Jun. 2019.
[47] D. Dheeru and E. K. Taniskidou. (2017). UCI Machine Learning
Repository. [Online]. Available: http://archive.ics.uci.edu/ml
[48] G. David and A. Averbuch, “SpectralCAT: Categorical spectral cluster-
ing of numerical and nominal data,” Pattern Recognit., vol. 45, no. 1,
pp. 416–433, 2012.
Krishna Kumar Sharma received the M.Tech.
(Information
Technology)
degree
from
IIIT
Allahabad, Allahabad, India, in 2011, and the
Ph.D. degree from the Department of Computer
Science and Engineering, PDPM Indian Institute of
Information Technology, Design and Manufacturing
Jabalpur, Jabalpur, India, in 2021.
He is currently an Assistant Professor with the
Department of Computer Science and Informatics,
University of Kota, Kota, India. His current research
interests include pattern recognition.
Ayan Seal (Senior Member, IEEE) received the
Ph.D. degree in engineering from Jadavpur Univer-
sity, Kolkata, India, in 2014.
He is currently an Assistant Professor with the
Department of Computer Science and Engineer-
ing, PDPM Indian Institute of Information Technol-
ogy, Design and Manufacturing Jabalpur, Jabalpur,
India. He has visited the Universidad Politécnica
de Madrid, Madrid, Spain, as a Visiting Research
Scholar. He has authored or coauthored several
journals, conferences, and book chapters in the area
of biometric and medical image processing. His current research interests
include image processing and pattern recognition.
Dr. Seal was a recipient of several awards. Recently, he received the Sir
Visvesvaraya Young Faculty Research Fellowship from Media Lab Asia,
Ministry of Electronics and Information Technology, Government of India.
Anis Yazidi (Senior Member, IEEE) received the
M.Sc. and Ph.D. degrees from the University of
Agder, Grimstad,
Norway, in 2008 and 2012,
respectively.
He was a Researcher with Teknova AS, Grimstad.
From 2014 to 2019, he was an Associate Pro-
fessor with the Department of Computer Science,
Oslo Metropolitan University, Oslo, Norway. He is
currently a Full Professor with the Department of
Computer Science, Oslo Metropolitan University,
where he is leading the research group in applied
artiﬁcial intelligence. He is also a Professor II with the Norwegian University
of Science and Technology (NTNU), Trondheim, Norway, and a Senior
Researcher with Oslo University Hospital, Oslo. His current research interests
include machine learning, learning automata, stochastic optimization, and
autonomous computing.
Ondrej Krejcar received the Ph.D. degree in tech-
nical cybernetics from the Technical University of
Ostrava, Ostrava, Czechia, in 2008.
He is currently a Full Professor in systems engi-
neering and informatics with the University of
Hradec Kralove (UHK), Hradec Kralove, Czechia,
and the Faculty of Informatics and Management,
Center for Basic and Applied Research, UHK; and
a Research Fellow with the Malaysia-Japan Interna-
tional Institute of Technology, University of Tech-
nology Malaysia, Kuala Lumpur, Malaysia. Since
June 2020, he has been a Vice-Rector for science and creative activities of the
UHK. He is also the Director of the Center for Basic and Applied Research,
UHK. From 2016 to 2020, he was the Vice-Dean for science and research
with the Faculty of Informatics and Management, UHK. His H-index is 21,
with more than 1800 citations received in the Web of Science, where more
than 120 IF journal articles are indexed in JCR index.
Dr. Krejcar has been a Management Committee Member substitute at Project
COST CA16226 since 2017. In 2018, he was the 14th top peer Reviewer in
Multidisciplinary in the World according to Publons and a Top Reviewer in
the Global Peer Review Awards 2019 by Publons. He is currently on the
Editorial Board of the MDPI Sensors IF journal (Q1/Q2 at JCR) and several
other ESCI-indexed journals. Since 2018, he has also been a Vice-Leader
and a Management Committee Member at WG4 at project COST CA17136.
Since 2019, he has been the Chairperson of the Program Committee of
the KAPPA Program, Technological Agency of the Czech Republic as a
regulator of the EEA/Norwegian Financial Mechanism in the Czech Republic
for the term 2019–2024. Since 2020, he has been the Chairperson of
Panel 1 (Computer, Physical and Chemical Sciences) of the ZETA Program,
Technological Agency of the Czech Republic. From 2014 to 2019, he has
been the Deputy Chairperson of Panel 7 (Processing Industry, Robotics, and
Electrical Engineering) of the Epsilon Program, Technological Agency of the
Czech Republic. He is also a guarantee of the doctoral study program in
applied informatics with UHK, where he is focusing on lecturing on smart
approaches to the development of information systems and applications in
ubiquitous computing environments.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore.  Restrictions apply. 
",10.1109/TIM.2022.3216366,doc22,"—With the rapid development of sensors and mechan-
ical systems, we produce an exponentially large amount of data
daily. Usually, faults are prevalent in these sensory systems due
to harsh operational conditions. Thus, detecting and diagnosing
faults in the gearbox of mechanical systems are done by analyzing
an exponentially large amount of data in the form of vibration
signals and categorical features. However, the automatic fault
detection method can match the increasing requirement for
high-quality products in the course of intelligent manufacture.
Thus, to acquire more distinguishable fault features under varied
conditions, a new adaptive mixture distance-based simple and
efﬁcient density peaks clustering algorithm is proposed for
handling mixed data as real-world datasets encompassing both
numerical and categorical attributes. Our approach revolves
around the concept of a sequence of the weighted exponential ker-
nel using a symmetry-favored c-nearest neighbor to estimate the
global parameter and the local density of each data point. Then,
the initial clusters are extracted from a decision graph using an
adaptive threshold parameter. The ﬁnal step is to allocate the
remaining data objects, if they are density reachable, to either
of the initial groups. Thirteen UCI datasets and one real-world
dataset from a mechanical system for gearbox defect diagnosis
are employed to validate the proposed method. Five external and
two internal evaluation criteria are considered to gauge how well
the strategies are working. All of the ﬁndings indicate that the
proposed method outperforms 13 other approaches.
Manuscript
received
10
July
2022;
revised
16
September
2022;
accepted 9 October 2022. Date of publication 21 October 2022; date of current
version 9 November 2022. This work was supported in part by the SPEV
project “Smart Solutions in Ubiquitous Computing Environments” (under
ID: UHK-FIMSPEV-2022-2102), University of Hradec Kralove, Faculty of
Informatics and Management, Czech Republic. The Associate Editor coordi-
nating the review process was Dr. Xiaofeng Yuan. (Corresponding author:
Ayan Seal.)
Krishna Kumar Sharma is with the Department of Computer Science
and Informatics, University of Kota, Kota, Rajasthan 324005, India (e-mail:
krisshna.sharma@gmail.com).
Ayan Seal is with the Department of Computer Science and Engi-
neering, PDPM Indian Institute of Information Technology, Design and
Manufacturing Jabalpur, Jabalpur, Madhya Pradesh 482005, India (e-mail:
ayanseal30@ieee.org).
Anis Yazidi is with the Department of Computer Science, Oslo Metropol-
itan University (OsloMet), 0166 Oslo, Norway, also with the Department
of Computer Science, Norwegian University of Science and Technology
(NTNU), 7034 Trondheim, Norway, and also with the Department of Plastic
and Reconstructive Surgery, Oslo University Hospital (OuS), 460167 Oslo,
Norway (e-mail: anis.yazidi@oslomet.no).
Ondrej Krejcar is with the Center for Basic and Applied Science, Faculty of
Informatics and Management, University of Hradec Kralove, 500 03 Hradec
Kralove, Czech Republic, and also with the Malaysia-Japan International Insti-
tute of Technology (MJIIT), Universiti Teknologi Malaysia, Kuala Lumpur
54100 , Malaysia (e-mail: ondrej.krejcar@uhk.cz).
Digital Object Identiﬁer 10.1109/TIM.2022.3216366
Index Terms—Density peaks clustering (DPC), mixed data
(MD), S-distance, symmetric favored c-nearest neighbors (c-NN).
I.","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 3528716 A New Adaptive Mixture Distance-Based Improved Density Peaks Clustering for Gearbox Fault Diagnosis Krishna Kumar Sharma , Ayan Seal , Senior Member, IEEE, Anis Yazidi , Senior Member, IEEE, and Ondrej Krejcar Abstract INTRODUCTION A PPROPRIATE fault detection of the gearbox and bearing will be advantageous for the rotary machine, as they are indispensable components of it. Typically, rotary machines operate under harsh conditions, for example, uncertain or driving loads, up/variable speeds, and material fatigue, which generate possibilities for faults in the gearbox and bearings [1], [2], [22]. Thus, it creates improper situations for the machines and may cause downtime, economic loss, and maintenance costs to the organizations [3], [4], [5]. Therefore, effective sig- nal processing techniques can protect the gearbox and bearing from the unforeseen situations mentioned above. Generally, vibration signal analysis is an efﬁcient and viable approach for detecting faults, as they have a high correlation with the states of machine parts and organizations [6], [7]. There are various learning methods, such as supervised classiﬁcation and unsupervised clustering, for fault identiﬁcation. In addition, the most fundamental exploratory, meta-learning data analysis method, is clustering, which splits a set of data objects, denoted as a feature or observation vector, into nonempty, mutually exclusive subsets, groups, or clusters, such that elements of the same group are similar to one another based on some similarity metrics, whereas members of different subsets are dissimilar [8]. Therefore, much consideration must be paid to ﬁnding the obscure but imperative information in the data, for example, insights, patterns, and rules. These primitive data have no class information that represents the type of unsupervised learning. Some frequently employed clustering techniques in machine fault detection are k-means, hierarchical, afﬁnity propagation, fuzzy c-means (FCM), and kernel spectral. Shuqing et al. [9] and Ramos et al. [10] used FCM for fault detection. How- ever, it adopts the spherical distance data together with the speciﬁcation and is only effective for homogeneous data dis- tribution. An improved method built on FCM was Gustafson– Kessel. After combining the adaptive distance rule and the covariance matrix, it can handle data with subspace dispersion in any direction [11]. Gustafson–Kessel was applied in the fault detection of the roller bearing by Wang et al. [12]. 1557-9662 © 2022 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 Liu et al. [13] presented a k-means clustering-based fault identiﬁcation technique for wind turbines. A fuzzy rule- based clustering approach was employed for the detection of anomalies in wind turbines [14]. It was also adopted for bearing fault detection [15]. An improved FCM clustering approach was applied for dissolved gas analysis-data-based transformer fault detection [16]. A hierarchical-based cluster- ing method was adopted for the evaluation of the vibration level and interior noise of vehicles [17]. Only a spherical pattern dataset is suitable for fuzzy and Gustafson–Kessel algorithms, but data obtained from practical systems have a variety of structures and shapes. Consequently, a Gath–Geva was developed to enhance the results. It follows the fuzzy maximum likelihood estimator. It is appropriate for data from variant orientations [18], [19]. In [20], afﬁnity propagation clustering was implemented with adaptive feature selection on vibration signals for the detection of bearing faults. Langone et al. [21] introduced a spectral clustering-based method to identify the normal and erroneous states of a machine. A sparse subspace clustering technique using a com- posite graph with a new distance was presented to diagnose faults in machines [22]. Fong et al. [23] designed a mean shift-based clustering approach for machinery diagnostics on vibration signals. Hou et al. [24] presented the fuzzy Gath–Geva clustering technique, linear discriminant analysis, and ensemble empirical mode decomposition to diagnose rolling bearing faults. Although the majority of the studies mentioned above on intelligent defect identiﬁcation have shown useful ﬁndings, they still have some obvious ﬂaws, which are given as follows. 1) Most clustering algorithms for fault diagnosis rely on the hypothesis that data comprise only numerical values. 2) Most previous works exploit the FCM to diagnose machine faults. It means that, in the case of high- dimensional data, the selection of the fuzziﬁer will be crucial, and it may be trapped in local minima. Generally, FCM-based fault diagnosis algorithms pre- fer overlapping and spherical-shaped vibration signal datasets. 3) Existing clustering-based fault diagnosis methods are not sufﬁciently general and rely on the input parameters and the number of clusters for fault types. Thus, there are situations where they fail due to quite complicated actual working conditions of the systems. In this study, we explore the possibilities of using density-based clustering approaches, such as DENCLUE, OPTICS, and DBSCAN, for fault diagnosis to handle the limitations stated above because they are suitable for arbitrary- shaped clusters. Moreover, these algorithms can ﬁlter out noise from data [25]. However, they are parameter-dependent. In particular, DBSCAN relies on two parameters, i.e., the minimum number of data objects in a neighborhood (MinPts) and the radius of the neighborhood for a data object. The values of MinPts and the radius of the neighborhood are determined by users manually, which is intrinsically hard to ﬁx [25]. Rodriguez and Laio [26] presented a density peaks clustering (DPC) algorithm to detect arbitrary-shaped clusters. Since then, DPC has received increased research attention over the past few years. Generally, the DPC algo- rithm assumes that the cluster’s center is farther from other cluster centers and is in a zone with a higher local density than its neighbors. For each data object or point, the DPC algorithm computes the local density and the distance from locations of higher density. Cluster centers are positioned in the top-right corner of a decision graph that has been created. Finally, all the data objects are assigned to one of the cluster centers. However, reliable density estimation is a complex problem. In their seminal paper, Rodriguez and Laio [26] suggested estimating density irrespective of the dataset size. However, small datasets are affected by the cutoff distance while estimating local density [26]. The DPC algorithm’s signiﬁcant beneﬁt is its capacity to locate nonspherical clusters without prior knowledge of the number of classes. The DPC does not involve an iterative process. However, DPC might not automatically determine the correct number of clusters. A density reachable concept and a divide-and-conquer- based 3DC clustering algorithm were given in [27] and [28], respectively, to address the aforementioned problem. Yaohui et al. [28] and Du et al. [29] investigated the concept of c-nearest neighbors (c-NN) in DPC for estimating local density. However, asymmetric edges are given the same weight as symmetric ones in c-NN-based DPC. Moreover, evidence from the literature has shown that data objects with asymmetric edges may end up in different clusters [30]. Furthermore, cluster representatives are selected based on the decision graph using a parameter cutoff distance. Thus, inappropriate selection of parameters may lead to an inaccurate decision graph and, consequently, incorrect cluster representatives. Furthermore, most of the clustering algorithms work under the assumption of numerical or cat- egorical attributes [25], [31], [32], [33], [34], [35], [36]. In reality, all datasets have categorical and numerical attributes, which is known as a mixed-attribute dataset. As we will explain later, clustering unlabeled-mixed datasets is thus a tedious task. To deal with the latter issue, some clustering algorithms transform the categorical attributes into numeric attributes by performing binary encoding. Then, the similarity between the transformed data objects is then determined using the Euclidean distance. However, the obtained dis- tances cannot capture the original structures of categorical attributes. Moreover, when it comes to categories with two possible values, an associated binary representation of them is meaning- less and hard to interpret [37]. Hsu [38] presented a weighted distance tree structure with a distance hierarchy. However, domain knowledge is required for both the creation of distance hierarchies and the assignment of weights. The interested readers are referred to [26], [29], [37], [39], [40], [41], [42], [43], [44] for more information related to several similarity measures for mixed data (MD) clustering. However, there is a trend to introduce nonlinearity into similarity measures for clustering [31]. Thus, clustering a dataset involving mixed attributes is still a challenging task. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 This article suggests a novel adaptive mixture distance (AD)-based DPC technique to diagnose mechanical system gearbox failures. The following are some imperative contribu- tions made by the proposed approach. 1) The inherent pattern of categorical characteristics is squashed by most existing techniques, which convert categorical attributes into sets of binary features. In other words, transformed binary features have no use. More- over, their values are difﬁcult to comprehend [37]. Thus, an entropy-based distance is presented to categorical features of the 13 UCI datasets and one real-world dataset, which keeps the original pattern of categorical attributes without transforming their representation. The real-world dataset consists of nonstationary vibration signals from a mechanical system for gearbox fault diagnosis. 2) A novel AD metric is introduced in this study that utilizes a weight parameter to merge the two similarity metrics, S-distance and similarity index. The former is deﬁned in the open cone of positive deﬁnite matrices and is based on the concept of S-divergence [8], [31]. It is considered to calculate the separation between two numerical properties of the datasets examined. The latter is employed to determine how far apart categorized fea- tures are from one another. If there are more categorical features than numerical attributes, the similarity index is given a higher weight and vice versa. 3) A relatively new local density metric is specially adopted to deal with the noise that may be produced in real time while recording nonstationary vibration signals from a mechanical system. The local density metric relies on a sequence of the weighted exponential kernel using a symmetry-favored c-NN (SFCNN). It is capable of overcoming the limitations of ﬁxed c-NN. Moreover, it characterizes the implicit geometrical structures. Fur- thermore, it increases the space in the density between outliers and core objects, which helps in generating efﬁcient and correct cluster representatives. 4) A new method for the selection of initial cluster centers is presented, which assures correct cluster centers even in the case of an unbalanced dataset and nonuniform distribution of classes. The modiﬁed DPC based on AD (MDPC-AD) is implemented on a total of 13 UCI datasets and a real-world dataset for gearbox fault diagnosis of a mechanical machine. Five clustering validation indices, namely, accuracy (A), precision (P), recall (R), F-Score (F), and the Jaccard index (JI), are used to show the superiority of the MDPC-AD. However, abbreviated forms of the validation indices mentioned above will be used only in ﬁgures for better accommodation and presentation. Moreover, two internal validation indices, for example, average clustering error and ratio of separation and compactness, are also adopted in this study. According to the results, the MDPC-AD outranks 13 state-of-the-art (SOTA) approaches. The remaining work consists of the following. Section II discusses pertinent related studies. In Section III, the proposed distance metric deﬁnition is discussed, followed by MDPC- AD. In Section IV, all experimental ﬁndings are presented. The work is ﬁnally concluded in Section V. II. THEORETICAL FOUNDATION OF DPC A. Notations Let O = {O1, O2, . . . , Oi, . . . , On} be a dataset of n MD objects. Each data object Oi ∈ℜd=|ψ|+|φ|, where 1 ≤ i ≤n, has d number of features or attributes in total. However, each Oi has |ψ| and |φ| number of numerical ψ and categorical φ attributes, respectively. Thus, Oψ i,l is the lth numerical feature of Oψ i . Similarly, Oφ i,l is the lth categorical attribute of Oφ i . The domain of lth categorical feature dm(H φ l ) = {hl,1, hl,2, . . . , hl,sl } has sl discrete values, whereas domain of the lth numerical attribute dm(H ψ l ) is continuous. Therefore, each Oi is a combination of categorical and numerical values and it is denoted by [Oψ i , Oφ i ] = [Oψ i,1, Oψ i,2, . . . , Oψ i,|ψ|, Oφ i,|ψ|+1, . . . , Oφ i,d={|ψ|+|φ|}]. B. Density Peaks Clustering Fundamentally, DPC identiﬁes cluster representatives with a higher density in comparison to their neighbors, and cluster representatives are located at a relatively large distance from each other. The two main parameters of this method are the local density βi of each data object Oi and the distance γi from objects with greater densities. Furthermore, two hypotheses correspond to the cluster representatives: 1) cluster representatives are located in higher density areas and their neighbors have lower densities and 2) cluster representatives are in relatively distant positions from each other or at a relatively higher distance to the data objects of higher density. The detailed discussion of the computation of βi and γi is given as follows. Generally, the DPC algorithm works on numerical values and adopts the linear Euclidean distance function as a similar- ity measure for numerical attributes in the clustering analysis. The Euclidean distance λe between two data objects Oi and O j is deﬁned by with the assumption that data consist only of numerical attributes λ2 e  Oi, O j  = l=d  l=1  Oi,l −O j,l 2. The local density of a data object, Oi, is represented by βi and is deﬁned by the following equation: βi =  j exp  −λ2 e  Oi, O j  αt  where αt denotes an adjustable variable, which controls the weight decrease rate. αt is the single variable in , and it relies on choosing the average number of neighbors of all data objects in the dataset. Rodriguez and Laio [26] deﬁned αt as given in the following equation: αt = α⌈τ⌉ where α⌈τ⌉∈{α1, α2, . . . , α( n 2)} and this set contains distances between every pair of two data objects in the dataset, arranged Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 ascendingly. Another parameter γi is also computed using , which shows the minimum distance between the data object Oi and other data objects with larger density γi = ⎧ ⎨ ⎩ min j λe Oi, O j , if ∃s.t. βi < β j max j  λe  Oi, O j  , else. When βi and γi for each data object have been computed, large values of βi and γi are explored anomalously in this method to identify the cluster representatives. Based on this concept, cluster representatives are always located on the decision graph’s top right side. Once cluster representatives are identiﬁed, the remaining data objects are assigned to the nearest cluster with a higher density. III. PROPOSED METHOD It is clear from the previous discussion that there are still some limitations to DPC and its peer methods. Hence, the DPC algorithm is improved in this study by introducing a novel adaptive mixture similarity measure. A new method for estimating the density of data points is introduced. Moreover, we present a novel way to construct a decision graph. In this section, we provide the details of the proposed clustering algorithm, MDPC-AD, and its theoretical complexity analysis. A. Similarity Measure of Numerical Attributes For revealing the natural cluster structure in a given dataset, which is a topic of active research, selecting an appropriate similarity/dissimilarity metric is essential. Since its inception, the proper selection of a similarity/difference metric has been a challenge. Recently, there has been an upsurge of interest in divergence-based nonlinear similarity measure [8], [31] for clustering analysis as this type of distance is susceptible to ﬁnding more appropriate complex cluster boundaries. Thus, nonlinear S-distance λs is considered here for computing the distance between two numerical data objects Oψ i and Oψ j in the |ψ|-dimensional Euclidean space ℜ|ψ| + using [31]. Deﬁnition 1: Deﬁne λs : ℜ|ψ| + × ℜ|ψ| + →ℜ+ ∪{0} as λ2 s Oψ i , Oψ j = |ψ|  l=1 log Oψ i,l + Oψ j,l /2 − log Oψ i,l + log Oψ j,l /2 . The fact that f is an injective function with the deﬁnition f : ℜ|ψ| + →M|ψ| ensures that the S-distance is well-deﬁned. In particular, Oψ i = f (Oψ i ) = diag((Oψ i,1, Oψ i,2, . . . , Oψ i,|ψ|)). In this case, M|ψ| is a positive deﬁnite matrix with the dimensions |ψ| × |ψ|. The notion of S-divergence [8], which is described mathematically by , is used to derive the S-distance λ2 s Oψ i , Oψ j = log  Oψ i + Oψ j 2   − log Oψ i  + log Oψ j  2 where | · | is a determinant of a matrix and λ2 s(Oψ i , Oψ j ) = λ2 s( f (Oψ i ), f (Oψ j )). The S-distance satisﬁes all the metric properties. Moreover, it also obeys the property of Hadamard product. It is also neither Bregman divergence nor f-divergence. However, it is a Burbea–Rao divergence. Thus, it is convex on ℜ|ψ| + . According to a prior study [8], when two data objects are close to the origin and have the same Euclidean distance, their S-distance is bigger than when they are far from the origin. The scope of this study does not include the various S-distance characteristics. To learn more about these features, interested readers are encouraged to explore [8], [31]. Now, the similarity between two data objects is computed using a monotonically decreasing spatial generalization expo- nential function [45]. Mathematically, the exponential function is deﬁned by the following equation: χψ Oψ i , Oψ j = exp ⎛ ⎜⎝ − λs Oψ i , Oψ j 2 2 ⎞ ⎟⎠ where χψ ∈[0, 1]. A value of χψ close to 1 indicates that two data objects Oψ i and Oψ j are similar. On the other hand, a value of χψ close to 0 indicates that two data objects Oψ i and Oψ j are highly dissimilar. B. Similarity Measure of Categorical Attributes Now, it is time to calculate the similarity λφ between two data objects, namely, Oφ i and Oφ j having categorical features on H φ l . Most of the existing approaches [39], [41], [43], [44] transform categorical attributes into sets of binary attributes, which squashes the native pattern of categorical features. In other words, converted binary features are purposeless, and their values are difﬁcult to understand. Thus, an entropy-based distance is applied to categorical features, which keeps the original pattern of categorical features without transforming their representation in this study. First, the similarity between the lth feature of Oφ i and Oφ j is computed by the following equation: λφ Oφ i,l, Oφ j,l =  1, if Oφ i,l = Oφ j,l 0, if Oφ i,l ̸= Oφ j,l. Thus, the similarity between two data objects is estimated by summing the signiﬁcance of each categorical attribute. Mathematically, it is deﬁned by the following equation: χφ Oφ i , Oφ j = |φ|  l=1 ωlλφ Oφ i,l, Oφ j,l where ωl is known as the signiﬁcance of the lth feature. The value of ωl varies from 0 and 1 and |φ| l=1 ωl = 1. The signiﬁcance of the lth attribute is computed with the help of entropy in information theory by the following equation: Gφ l = −  hl,q∈dm H φ l p  hl,q  log  p  hl,q  Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 where p(hl,q) represents the probability of hl,q feature and is estimated as (n i=1 λφ(Oφ i,l, hl,q)/n). In other words, it is a ratio of number of objects whose value is equal to hl,q of categorical feature H φ l to the total number of objects n in a given dataset. It is clear from that if the number of sl is very large, then the entropy of feature H φ l will also be large. However, this is not how things actually are. The entropy of a categorical feature is reformulated by to lessen the impact of categorical characteristics having numerous unique or distinct values, such as an ID number G φ l = −1 sl sl  q=1 p  hl,q  log  p  hl,q  . Thus, the weight assigned to each categorical feature H φ l is computed by ωl = G φ l |φ| l=1 G φ l . The similarity measure of categorical attributes can be com- puted by combining and , which is shown in the following equation: χφ Oφ i , Oφ j = |φ|  l=1 G φ l |φ| l=1 G φ l λφ Oφ i,l, Oφ j,l . C. Similarity Measure for MD The similarity between two data points Oi and O j having |ψ| number of numerical attributes and |φ| number of cate- gorical features is computed by merging and with the help of the more importance concept of information theory, and the new equation is given by χOi, O j  = |ψ| |ψ| + |φ| exp ⎛ ⎜⎝ −λs Oψ i , Oψ j 2 2 ⎞ ⎟⎠ + |φ| |ψ| + |φ| |φ|  l=1 G φ l |φ| l=1 G φ l λφ Oφ i,l, Oφ j,l . The value of the similarity measure lies between 0 and 1 due to normalized coefﬁcients. Generally, a DPC algorithm requires a distance function instead of a similarity measure. Hence, a logarithmic function is applied to the negative exponent of as shown in . If two data objects are similar, then the distance would be smaller λm  Oi, O j  = log χ  Oi, O j −1 . D. Local Density Metric In this section, we present: 1) a new local density metric based on SFCNN; 2) a new method to initialize the cluster centers; and 3) a way to group density-reachable clusters. For estimating the local density of a data object Xi in a set of data, an SFCNN graph is built in this study instead of a conventional c-NN graph since it is more resistant to noise and outliers. Fig. 1 is used to explain the distinction Fig. 1. (a) 3-NN graph’s differences from (b) symmetry-favored 3-NN graphs (red edges show higher edge weights). Fig. 2. Decision graph of Statlog Heart dataset with αt = 0.54. between a standard c-NN graph and one that favors symmetry. The graph’s symmetric edges have heavier weights than its asymmetric edges because the locations they connect are located in the same submanifold [30], [46]. The underlying manifold characteristics of the data space can also be used to explain the SFCNN graph. It can describe implicit geometrical structures. Moreover, it also increases the space in the density between outliers and core objects, which helps in generating efﬁcient and correct cluster representatives. Generally, density metrics consider Gaussian kernels to estimate the local density values. Data objects in DPC are represented as points in a space, where cluster representatives are always on the top-right part of the decision graph. Once the local density βi and minimum distance γi from data points of higher density are calculated for each data object, cluster representatives are identiﬁed by searching the large parameters βi and γi for anomalies. The parameter αt determines the average number of neighbors of all data objects in a dataset. The value of αt is computed by , which depends on the value of “c.” Based on this idea, cluster centers for the Statlog Heart [47] sample dataset is estimated, and they can be seen in the top-right quadrant of the decision graph in Fig. 2. Here, circles with red color are the initial cluster representatives that are characterized relatively by the higher distance, γi, and larger density, βi. They are computed based on the threshold value, αt = 0.54 (dashed line). After the selection of the cluster representatives, the remaining data objects are assigned to the nearest cluster with a higher density. A decision graph assists in taking a decision. The decision graph is a plot of γi as a function of βi for each data object αt = vc + n i=1 γ c i −vc2 n −1 where γ c i is the distance between SFCNN and a data object i, deﬁned as γ c i = max j∈SFCNNi (λi, j m ), and vc is the average Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 value of γ c i and is computed by . SFCNNi is a set of data objects in an SFCNN to data object i vc = n i=1 γ c i n . The second part in the right-hand side of represents the standard deviation of distance calculated between each data object and its corresponding SFCNN. The local densities can be estimated by the following equation: βi =  j∈SFCNNi exp ⎛ ⎜⎝− λi, j m 2 (αt)2 ⎞ ⎟⎠. Equation illustrates the distribution information of the SFCNN of a data object i and uses αt to estimate the local density βi. Equation considers the sum of all distances using an exponential kernel. The previous studies [28] reveal that the value of c in an SFCNN graph has a signiﬁcant impact while estimating density, and it was ﬁxed to 5 because 2-NN, 3-NN, and 4-NN may be close to normal data objects. Thus, an enhanced local density is proposed by combining a ﬁxed SFCNN and a weighted sequence as shown in the following equation: βi =  j∈SFCNNi exp ⎛ ⎜⎝− λi, j m 2 (αt)2 ⎞ ⎟⎠ +  j /∈SFCNNi and j̸=i exp  − λi, j m 2 max j′∈SFCNNi λ j′, j m . The ﬁrst part of takes care of the symmetry-favored 5-NN estimation, which is inherited from . On the other hand, the second part of sums the weighted Gaussian kernel sequence. This second part is a complement to the ﬁrst part and compensates for the clustering performance by overcoming the limitations of ﬁxed c-NN in density estimation. The weights in the second part have a lesser value in the case of data objects away from the c-NN and a higher weightage near the c-NN. In this work, the DPC algorithm is enhanced by considering some of the concepts of DBSCAN and OPTICS, which are given as follows. Deﬁnition 2 (Core Distance γ e of a Cluster Ce): γ e of a cluster Ce is computed by the following equation: γ e =  Oi∈Ce λm(CPe, Oi) |Ce| where |Ce| represents the cardinality of a cluster set Ce and CPe is the cluster center of Ce. γ e of a Ce is the average of distances between all the data points belonging to Ce and CPe. Deﬁnition 3 (Boundary-Data-Object-Pair Set ρx,y Between Two Clusters, Namely, Cx and C y): ρx,y between Cx and C y is expressed as follows: ρx,y =  Oi, O j  |λm  Oi, O j  < min  γ x, γ y , Oi ∈Cx, O j ∈C y where ρx,y is symmetric in nature. Deﬁnition 4 (Border Density βe ρ of Cluster Ce): βe ρ of Ce is computed by the following equation: βe ρ = max (Oi,O j)∈ρx  βi + β j  2 where ρx consists all boundary-data-objects-pairs between Cx and other clusters such that ρx = ∪y̸=xρx,y. Deﬁnition 5 (Density Directly Reachable): In terms of bor- der density, a cluster Cx is density directly reachable from another cluster C y if the following conditions hold. 1) ρx,y ̸= {Null}. 2) ∃(Oi, O j) ∈ρx,y, βi < βx ρ and β j < β y ρ It also satisﬁes the symmetric property. Deﬁnition 6 (Density Reachable): If there is a path con- necting two clusters Cx and C y such that Cx = C1, C2, . . . , Cn = C y, each Ci is directly reachable to Ci+1, then the two clusters are said to be density reachable to one another. Moreover, it obeys the symmetric as well as transitive properties. E. Improved DPC Algorithm and Its Complexity In this section, the essential details of the MDPC-AD are discussed with an analysis of its complexity. Algorithm 1 is a logical step-by-step analysis of the MDPC-AD. The algorithm of the MDPC-AD is presented to make it easy for the reader to identify the process, major decision points, and variables necessary to implement MDPC-AD. Fig. 3 is employed to illustrate the detailed processes of the MDPC-AD on a particular dataset named Wine [47] consisting of numerical attributes only. The ﬁrst two principal compo- nents of each data object of the Wine dataset are obtained using PCA and are shown on a 2-D plane using pink color in Fig. 3(a). Here, a dataset consisting of numerical features is considered because PCA can only work on numerical attributes to generate principal components. Three density peaks in the top-right corner are automatically recognized as cluster representatives in Fig. 3(b), which shows the decision graph of γi as a function of βi for each data object and data objects in red are initial cluster representatives above the threshold αt and threshold αt is displayed as green dashed line. The remaining data objects are then assigned to the closest clusters to obtain the corresponding cluster, as shown in Fig. 3(c). Finally, a grouping of the density reachable clusters is performed and the ﬁnal obtained clusters are shown in Fig. 3(d). The following factors are used to discuss how time-consuming the MDPC-AD is. First, the distance between data objects is calculated with complexity O(n2E), where E is the time required to compute λm() between two data objects and n represents the number of data objects in the dataset. Later, sorting of distance vector will require O(n2 log(n)) complexity. An SFCNN graph will take O(cn) times for calculation of βi, where c is smaller than n. The calculation of distance γi for each data object requires O(n2) steps. Furthermore, initial representatives for clusters are selected and the assignment of data objects to clusters is completed in O(n2) times. The calculation of core distance γ e and border density βe ρ will take only O(n). The estimation Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 Fig. 3. Illustration of the MDPC AD that has been proposed. (a) Visualization of the wine dataset using the ﬁrst two principal components, showing the ﬁrst and second corresponding vectors of the data matrix along the axes. (b) Decision graph for the wine dataset in (a). (c) Clustering result after nearest cluster assignment. (d) Clustering result after grouping of density reachable clusters. of boundary-data-object-pair sets will require approximately O(n2) steps. In conclusion, the time complexity of the MDPC-AD is O(n2 log(n)). IV. EXPERIMENTAL RESULTS AND DISCUSSION This work is done on a laptop running Windows 10 with an Intel1 Core2 i7-2620M CPU clocked at 2.70 GHz and 8 GB of RAM using the Spyder 3.2.8 Python development environ- ment. This study does not include I/O costs. A. Experimental Setup and Dataset Description 1) Dataset #1: Thirteen well-known real-world datasets from the UCI repository are considered in this study. Table I contains some statistical information, such as name, type, the number of clusters (k), the total number of features (d), the number of numerical features (Fψ), the number of categorical features (Fφ), and the total number of samples (n) from these datasets. Interested readers may discover more details regarding these datasets in [47]. 1Registered trademark. 2Trademarked. TABLE I STATISTICS OF UCI DATASETS USED IN THIS STUDY 2) Dataset #2: The proposed method’s efﬁciency is also tested on machine fault diagnostics, with data containing three categories of gearbox problems, such as missing teeth, tooth wear, and root faults. As shown in Fig. 5, a test rig is used to identify the faults in a gearbox that are shown in Fig. 4 [22], [23]. The three defective gears, as well as one healthy gear, are installed in the test setup. Then, using a controller, it is powered at its rotational speed by a regulated motor. A brake is used at the shaft’s end location to provide Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 Fig. 4. Faults of the gears: (a) normal, (b) missing teeth, (c) wear in teeth, and (d) fault in root. Algorithm 1 Proposed DPC Algorithm Require: O = {O1, . . . , Oi, . . . , On} ▷where Oi ∈ℜd=|ψ|+|φ| Ensure: C = {C1, C2, . . . , Ck} ▷a set of resultant clusters 1: Calculate distance matrix and parameter αt using Eqs. 15 and16, respectively 2: Calculate βi and γi for all data objects Oi ∈O by Eqs. 16 to 19. 3: Choose all data objects whose γi is larger than the αt cutoff distance in the decision graph and set k′ initial representatives of clusters as C P = {C Pi|1 ≤i ≤k′} and remaining data object will be O′ = O −C P. 4: for all Oi ∈O′ do label = min CP j ∈C j &1≤j≤k′{λm(Oi, C P j)}; ▷nearest cluster Clabel ←Clabel ∪Oi 5: end for 6: Compute the core distance γ e and boundary density βe ρ of each cluster e using Eqs. 20 to 22. 7: repeat ▷Group all density-reachable clusters 8: for all Ci ∈C do 9: for all C j ∈C −Ci do 10: if Ci and C j satisfy Defs. 5 and 6 then 11: Ci ←Ci ∪C j and update set C 12: end if 13: end for 14: end for 15: until Grouping of density reachable clusters 16: Return C = {C1, . . . , Ck} as the set of the clusters. a load to the system. As shown in Fig. 5, an experiment for intelligent fault detection was carried out. The gearbox was not loaded, and the motor’s speed was set to 1800 r/min. Three acceleration sensors that were ﬁxed in the housing’s vertical, horizontal, and axial directions and connected to its right end were employed to collect vibration data at a sampling rate of 12.8 kHz. However, categorical data, such as the number of cylinders, the forwarding gear values, and the number of carburetors, are discontinuous parameters. Four separate conditions, namely, tooth wear, root defect, missing teeth, and healthy, were used to collect vibration signals. As shown in Fig. 6, the original vibration signal is split into 90 segments, each of which contains 5023 samples. The MDPC-AD method is presented to diagnose machine faults via vibration signals, and categorical features are obtained to determine the state variation due to faults [22], [23]. As discussed in Section II-A, O = {O1, O2, . . . , Oi, . . . , On} is a dataset of n MD vectors. Each data vector Oi ∈ℜd=|ψ|+|φ|, where 1 ≤i ≤n, has a total of d features or attributes. However, each Oi has a |ψ| and |φ| number of signal features ψ and categorical φ attributes, respectively. One assumption is made in this application that the number of data objects in each cluster is equal. Let k be the number of clusters, and the data objects from each cluster are n/k. The MDPC-AD method is performed for the diagnosis of a faulty gearbox, as discussed in Algorithm 1. B. Evaluation Metrics Accuracy is one of the most commonly reported evaluation measures. It describes the percentage of accurate clustering outcomes among all the outcomes a machine learning algo- rithm produces. It is an intuitive and straightforward evaluation metric. A machine learning algorithm is better and more preferable if its percentage accuracy is near 100. On the other hand, depending just on accuracy for unbalanced data can be deceptive. In this situation, in addition to accuracy, other assessment measures, including precision, recall, F-Score, and JI, may be considered to determine how effective a model is [25]. Moreover, two internal validation indices, for example, the average clustering error and the ratio of separation to compactness, are also adopted in this study. C. Computational Protocol This study compares the performance of the proposed approach, MDPC-AD, with 13 SOTA methods. 1) K-PC: k-prototypes clustering algorithm for mixed datasets [39]. 2) EK-PC: An evolutionary k-prototypes clustering algo- rithm for mixed-type datasets [41]. 3) KL-FCM-GM: An FCM-type clustering algorithm for mixed datasets with a probabilistic dissimilarity function [42]. 4) FK-PC: A fuzzy k-prototypes clustering algorithm for MD [43]. 5) IK-PC: An improved k-prototypes clustering algorithm for mixed numerical and categorical data [44]. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 Fig. 5. (a) Gear test rig and (b) accelerometers ﬁxed in the vertical, axial, and horizontal directions. Fig. 6. Vibration signal in four different conditions of the gear from the experiment. 6) CAVE: A clustering algorithm based on variance and entropy for mixed datasets [40]. 7) SBAC: A similarity-based agglomerative clustering algorithm for data with mixed features [37]. 8) SpectralCAT: Categorical spectral clustering for numer- ical and nominal data [48]. 9) DKFCM: A density-oriented kernel FCM algorithm for fault diagnosis [10]. 10) DPC-MD: A novel DPC method for MD using a distance for MD [29]. 11) PE-EEMD-GG: A method based on permutation entropy, ensemble empirical mode decomposition, and the Gath–Geva clustering method for bearing fault diag- nosis [24]. 12) CG-SSC: A composite graph-based sparse subspace clustering method for machine fault diagnosis [22]. 13) MSC: A mean shift clustering-based approach with a spectral preprocessing technique for machinery diagnostics [23]. Since the researchers have not given their works a name, appropriate nomenclatures for these methodologies are employed. The scope of this study does not include a thor- ough description of these techniques. However, we use the precise procedures outlined in the original papers. As a result, interested readers are directed to the source works for more information. D. Results and Comparison In this study, a total of nine experiments are conducted to validate the MDPC-AD. The ﬁrst eight experiments are carried out on the UCI datasets using ﬁve external validation indices. The last experiment is performed to identify the faults in the gearbox of a rotary mechanical machine with the help of two internal validation measures. 1) Experiment on Categorical Datasets: In the ﬁrst exper- iment, the MDPC-AD is executed on datasets, namely, D1, D2, and D3, having categorical attributes only. These datasets do not possess numerical features. The second part of , followed by , is considered while computing distance. The clustering report obtained by the MDPC-AD is noted in the last column of Table II. The clustering reports generated by existing methods are also included in Table II. The best clustering report produced by a method is marked by bold characters. All the results of Table II demonstrate that the MDPC-AD outperforms all the above-discussed 13 SOTA methods. However, the performance of DPC-MD and MSC on D3 is the same as that of the MDPC-AD. 2) Experiment on Numerical Datasets: In the second exper- iment, the MDPC-AD is implemented on datasets, namely, D4, D5, D6, and D7, having only numerical attributes. These datasets do not have categorical features. Fig. 7 shows the ﬁrst two principal components of D4, D5, D6, and D7 plotted in 2D planes. It is clear from Table I and Fig. 7 that each dataset consists of a varying number of data points. Moreover, they have arbitrary shape clusters. Now, the ﬁrst part of , followed by , is employed while computing distance. The clustering reports of all the 14 methods, including the MDPC-AD, are reported in Table III. The best performance Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 TABLE II CLUSTERING REPORTS ON D1, D2, AND D3 USING FIVE VALIDATION INDICES TABLE III CLUSTERING REPORTS ON D4, D5, D6, AND D7 USING FIVE VALIDATION INDICES TABLE IV CLUSTERING REPORTS ON D8, D9, D10, D11, D12, AND D13 USING FIVE VALIDATION INDICES achieved by a method is marked by a bold character. We can conclude after observing all the results of Table III that the MDPC-AD outperforms all 13 SOTA methods even when the data points of D4, D5, D6, and D7 are varying and have arbitrary shape clusters. 3) Experiment on Mixed Datasets: In the third experiment, the MDPC-AD is executed on mixed datasets, namely, D8, D9, D10, D11, D12, and D13. These datasets contain both numerical as well as categorical variables. Here, is used to compute the distance between data objects. The clustering reports produced are presented in Table IV. The best clustering report generated by a method is marked by bold characters. It is clear from Table IV that the MDPC-AD outperforms all the above-discussed 13 SOTA methods. In summary, we can say that the clustering reports in terms of precision, recall, F-Score, JI, and accuracy obtained by the proposed method named MDPC-AD are higher than the other 13 SOTA existing approaches mentioned in Section IV-C. The primary reason is that K-PC, EK-PC, IK-PC, FK-PC, DKFCM, PE-EEMD, CG-SSC, MSC, and DPC-MD are sensitive to the initialization of cluster rep- resentatives and are improper for nonspherically distributed Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 Fig. 7. First two principal components of the dataset on the left and its updated version with noise features as the number of genuine features on the right were shown on a plane to display the ﬁrst and second matching vectors of the data matrix along the axes. Different colors indicate different data point classiﬁcations. (a) D4. (b) D4 with noisy features. (c) D5. (d) D5 with noisy features. (e) D6. (f) D6 with noisy features. (g) D7. (h) D7 with noisy features. data. Moreover, SBAC addresses similarity measures with the assumption that the unusual matched feature values correspond to higher weights. DKFCM adopts a fuzzy objective func- tion that is designed based on several probabilistic theories regarding the organization of the obtained clusters. CAVE is sensitive to the procedure of sampling. The efﬁciency of SpectralCAT depends on the selection of kernel func- tion to compute the Markov matrix. On the other hand, MDPC-AD overcomes some of the abovementioned issues. Thus, MDPC-AD achieved good clustering results on the above-discussed numerical, categorical, and mixed datasets. 4) Experiment on Noisy Datasets: The fourth experiment is conducted on datasets, namely, D4, D5, D6, and D6, having only numerical variables to know whether the MDPC-AD is robust against the noisy features. After adding noisy features produced by a uniform random distribution in the length and size limit of the original dataset, the inﬂuence of noisy features is examined. Therefore, a dataset’s number of features would be twice as many as its initial number of attributes. The ﬁrst two principal components of each of the aforementioned datasets, as plotted on 2-D planes, are shown in Fig. 7 before and after the addition of noisy features. Fig. 7 makes it obvious that for a dataset; practically, all of the mapped locations have signiﬁcant overlaps with one another. This simply means that the existence of noisy features hurts these datasets. The results obtained by all techniques after including noisy features are shown in Fig. 8 against ﬁve assessment metrics, including accuracy, precision, recall, F-Score, and Jaccard index on D4–D7. The results show that the MDPC-AD performs better than any other approach, from K-PC to SpectralCAT. For a small number of datasets, clustering performance is dramati- cally reduced. Nevertheless, the S-distance, which is utilized to calculate the separations between numerical data items and is invariant to the Hadamard product, makes the MDPC-AD resilient [8]. 5) Experiment for Knowing the Impact of “c” in Symmetric Favored c-NN: In this work, local density is estimated based on a sequence of the weighted exponential kernel using an SFCNN. In the previous four experiments, the value of “c” is considered 5, as suggested by the past studies [28]. However, the ﬁfth experiment is conducted to verify the previous claim. The value of “c” varies from 1 to 19 with a step size of 2. The values of accuracy, precision, recall, F-Score, and Jaccard index for each value of “c” over all 13 datasets are shown in Fig. 9. The values of “c” are shown on the x-axis, and the clustering results are shown on the y-axis. It is clear from Fig. 9 that the values of clustering metrics are maximum when the value of “c” varies from 1 to 5 on datasets, i.e., D3, D8, and D9. However, the performance increases slightly on D6 when the value of “c” is beyond 5. On the other hand, the performances remain consistent on D11 and D13. The clustering performances deteriorate on D1, D2, D4, D5, D7, D10, and D12 when the value of “c” is beyond 12. It means that it is really difﬁcult to ﬁnd out the optimum value of “c.” However, it relies on the characteristics of a dataset. 6) Experiment on Order Sensitivity: In the ﬁnal experiment, the order of the data objects in a dataset is changed while still analyzing the clustering result. This sensitivity analysis measures the stability of the algorithm due to randomness and erroneous assessment. The MDPC-AD is executed ten times on 13 datasets. However, the positions of data objects are changed by shufﬂing them randomly, and the corresponding clustering results are shown in Fig. 10. The x-axis and y-axis of each plot in Fig. 10 denote, respectively, the number of iterations and the value of the metric in question. It is clear from Fig. 9 that the MDPC-AD is not sensitive to the position of data objects or order since the performance is the same or constant in all ten runs. 7) Experiment for Run-Time Comparison: All the methods mentioned in Section IV-C are not only compared based on their clustering reports but also compared based on their execution time, which is measured and noted in Table V. It is clear from Table V that most of the time MDPC-AD takes Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 Fig. 8. Comparison of clustering results on numerical datasets with noisy features. (a) Precision. (b) Recall. (c) F-Score. (d) Jaccard index. (e) Accuracy. TABLE V METHODS RUN TIME (UNIT: s) less time compared to K-PC, EK-PC, KL-FCM-GM, FK-PC, IK-PC, CAVE, DKFCM, DPC-MD, SpectralCAT, PE-EEMD, CG-SSC, MSC, and SBAC. However, in some cases, K-PC has a lesser execution time compared to the MDPC-AD, Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 Fig. 9. Evaluation of MDPC-AD for different values of “c” values on all the datasets. (a) Precision. (b) Recall. (c) F-Score. (d) Jaccard index. (e) Accuracy. Fig. 10. Evaluation of MDPC-AD for testing sensitivity on 13 datasets. (a) Precision. (b) Recall. (c) F-Score. (d) Jaccard index. (e) Accuracy. whereas MDPC-AD has a lesser execution time than EK-PC, KL-FCM-GM, IK-PC, CAVE, DKFCM, SpectralCAT, PE- EEMD, CG-SSC, MSC, and SBAC. Overall, the proposed MDPC-AD executes in lesser time and outperforms other methods. Moreover, the best execution times are bold in Table V. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 TABLE VI ABLATION STUDY ON D8, D9, D10, D11, D12, AND D13 TABLE VII GEARBOX FAULT DIAGNOSIS USING TWO INTERNAL VALIDATION INDICES 8) Ablation Study: The steps of MDPC-AD are determined after conducting an ablation study on mixed datasets only. DPC presented by Rodriguez and Laio [26] is implemented in the ﬁrst analysis. In the second analysis, the impact of the proposed AD mentioned in is evaluated by incorporating it in DPC and renaming the modiﬁed algorithm as DPC- AD. In the third analysis, a new method to estimate local density is adopted, which relies on a sequence of the weighted exponential kernel using an SFCNN to overcome the limitation of ﬁxed c-NN and names the method DPC-AD-SFCNN. In the fourth study, a method for automatic selection of the initial cluster representatives is utilized from MDPC-AD and merged with DPC-AD-SFCNN and marked as DPC-AD-SFCNN- CR. The MDPC-CNN-MD considers the c-NN in place of an SFCNN for estimating local density. It also adopts the presented distance from [29]. The MDPC-CNN-AD is similar to the MDPC-CNN-MD, except that instead of using the presented distance in [29], it employs the proposed distance. Finally, CNN in MDPC-CNN-MD is substituted with SFCNN, which is now called MDPC-SFCNN-MD. Furthermore, the results of these studies are noted in Table VI to validate the superiority of the proposed method, MDPC-AD. All the results demonstrate that the proposed method, MDPC-AD, is superior to other combinations of the DPC algorithm. 9) Case Study for Gearbox Fault Diagnosis Using Clus- tering: In this section, MDPC-AD is compared with DPC, DPC-AD, DPC-AD-SFCNN, and DPC-AD-SFCNN-CR. This experiment is performed to group the state of the gears of a mechanical machine. For the same, features of the data obtained in 1 s are considered as a sample, and 90 samples/data objects are analyzed. A quantitative clustering analysis is conducted using two internal validation indices. First, a ratio of separation SP and compactness CM is computed, and their ratio ID1 = SP/CM is used as the metric for comparison. For this metric, a high value of SP is desired, and a low value of CM is suitable for good clusters. Thus, a high value of ID1 indicates effective clustering results. Second, a clustering error, ID2, is adopted for comparison and a smaller value of clustering error shows the most effective. A comparison of ID1 index on the above discussed ﬁve methods is shown in Table VII. In the case of MDPC-AD, SP has a high value, and CM obtained the ideal value equal to zero; thus, the value of ID1 is extremely large or tends to inﬁnity, which shows that MDPC-AD outperforms other SOTA methods. It indicates that MDPC-AD can yield well-separated and most compact clus- ters. Second, a comparison is shown using ID2 where all the methods are executed 50 times, and the average error is com- puted and presented in Table VII. As mentioned in Table VII, MDPC-AD achieved the lowest value equal to zero, meaning that there was nil clustering error in the proposed method while diagnosing the faults in a gearbox. Therefore, the proposed study is an effective method for gearbox fault diagnosis. V. CONCLUSION This study introduces the DPC-based clustering technique named MDPC-AD for gearbox fault diagnostics. An ablation study is conducted to demonstrate the effectiveness of each part of the MDPC-AD. The obtained results illustrate that the novel AD can more clearly reveal the structure of the 13 real- world datasets from UCI under examination. To calculate the global parameter and the local density of each data object, the MDPC-AD employs the idea of a series of weighted Gaussian kernels based on an SFCNN. In addition, the MDPC-AD is easier to control than DBSCAN and DPC since it can choose the initial cluster representatives automatically by establishing Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. SHARMA et al.: NEW ADAPTIVE MIXTURE DISTANCE-BASED IMPROVED DENSITY PEAKS CLUSTERING 3528716 the cutoff distance as a function of parameter c. The ﬁrst cluster representatives’ computation, however, ensures the inclusion of genuine initial cluster representatives. The con- cept of grouping density reachable clusters is employed to solve this problem in subsequent iterations, even though our method may initially choose incorrect cluster representatives. According to experiments on different real-world datasets, the MDPC-AD outperforms the 13 SOTA approaches mentioned in this article. Even though an experiment is run to see how ‘c’ affects things, more research is still required. Finding the ideal value for “c” and understanding the relationship between the parameters αt and “c” call for more investigation. It would also be intriguing to expand the capabilities of the current algorithm to manage large datasets with mixed attributes. Although MDPC-AD improves clustering efﬁciency, the decreased efﬁ- ciency of MDPC-AD compared to DPC is due to the high computational complexity of density estimation. Therefore, it is essential to reduce the computational complexity of density estimation, a subject that merits more study. Finally, in mechanical systems, clustering algorithms have proven to be more reliable, particularly for fault diagnosis. The names of two faults that could affect gearboxes, bearings, and wind turbines, are mentioned in this study. The last two, which merit additional research, have not been covered in this article. ACKNOWLEDGMENT The authors would like to thank the support of Ph.D. student Michal Dobrovolny for consultations. REFERENCES [1] J. Sun, C. Yan, and J. Wen, “Intelligent bearing fault diagnosis method combining compressed data acquisition and deep learning,” IEEE Trans. Instrum. Meas., vol. 67, no. 1, pp. 185–195, Jan. 2018. [2] C. Sun, M. Ma, Z. B. Zhao, and X. Chen, “Sparse deep stacking network for fault diagnosis of motor,” IEEE Trans. Ind. Informat., vol. 14, no. 7, pp. 3261–3270, Mar. 2018. [3] S. B. Wang, X. F. Chen, C. W. Tong, and Z. B. Zhao, “Matching syn- chrosqueezing wavelet transform and application to aeroengine vibration monitoring,” IEEE Trans. Instrum. Meas., vol. 66, no. 2, pp. 360–372, Feb. 2017. [4] Y. Chen and M. J. Zuo, “A sparse multivariate time series model-based fault detection method for gearboxes under variable speed condition,” Mech. Syst. Signal Process., vol. 167, Mar. 2022, Art. no. 108539. [5] Y. Liu, B. Liu, X. Zhao, and M. Xie, “A mixture of variational canonical correlation analysis for nonlinear and quality-relevant process monitoring,” IEEE Trans. Ind. Electron., vol. 65, no. 8, pp. 6478–6486, Aug. 2018. [6] W. Teng, Y. Liu, Y. Huang, L. Song, Y. Liu, and Z. Ma, “Fault detection of planetary subassemblies in a wind turbine gearbox using TQWT based sparse representation,” J. Sound Vibrat., vol. 490, Jan. 2021, Art. no. 115707. [7] Y. Liao, L. Zhang, and W. Li, “Regrouping particle swarm optimization based variable neural network for gearbox fault diagnosis,” J. Intell. Fuzzy Syst., vol. 34, no. 6, pp. 3671–3680, 2018. [8] S. Chakraborty and S. Das, “K—Means clustering with a new divergence-based distance metric: Convergence and performance analy- sis,” Pattern Recognit. Lett., vol. 100, pp. 67–73, Dec. 2017. [9] Z. Shuqing, S. Guoxiu, L. Liang, L. Xinxin, and J. Xiong, “Study on mechanical fault diagnosis method based on LMD approximate entropy and fuzzy C-means clustering,” Chinese J. Sci. Instrum., vol. 34, no. 3, pp. 714–720, 2013. [10] A. R. Ramos et al., “A novel fault diagnosis scheme applying fuzzy clus- tering algorithms,” Appl. Soft Comput., vol. 58, pp. 605–619, Sep. 2017. [11] D. Gustafson and W. Kessel, “Fuzzy clustering with a fuzzy covariance matrix,” in Proc. IEEE Conf. Decis. Control including 17th Symp. Adapt. Processes, Jan. 1978, pp. 761–766. [12] S. Wang, L. Li, S. Zhang, and G. Sun, “Mechanical fault diagnosis method based on EEMD sample entropy and GK fuzzy clustering,” China Mech. Eng., vol. 24, no. 22, p. 3036, 2013. [13] X. Liu, M. Li, S. Qin, X. Ma, and W. Wang, “A predictive fault diagnose method of wind turbine based on K-means clustering and neural networks,” J. Internet Technol., vol. 17, no. 7, pp. 1521–1528, 2016. [14] P. Baraldi, F. D. Maio, M. Rigamonti, E. Zio, and R. Seraoui, “Unsuper- vised clustering of vibration signals for identifying anomalous conditions in a nuclear turbine,” J. Intell. Fuzzy Syst., vol. 28, no. 4, pp. 1723–1731, 2015. [15] S. Fu, K. Liu, Y. Xu, and Y. Liu, “Rolling bearing diagnosing method based on time domain analysis and adaptive fuzzy C-means clustering,” Shock Vibrat., vol. 2016, pp. 1–8, Jan. 2016. [16] E. Li, L. Wang, B. Song, and S. Jian, “Improved fuzzy C-means clustering for transformer fault diagnosis using dissolved gas analysis data,” Energies, vol. 11, no. 9, p. 2344, Sep. 2018. [17] Z. M. Nopiah, A. K. Junoh, and A. K. Arifﬁn, “Vehicle interior noise and vibration level assessment through the data clustering and hybrid classiﬁcation model,” Appl. Acoust., vol. 87, pp. 9–22, Jan. 2015. [18] I. Gath and A. B. Geva, “Unsupervised optimal fuzzy clustering,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 11, no. 7, pp. 773–780, Jul. 1989. [19] J. C. Bezdek and J. C. Dunn, “Optimal fuzzy partitions: A heuristic for estimating the parameters in a mixture of normal distributions,” IEEE Trans. Comput., vol. C-24, no. 8, pp. 835–838, Aug. 1975. [20] Z. X. Wei, Y. X. Wang, S. L. He, and J. D. Bao, “A novel intelli- gent method for bearing fault diagnosis based on afﬁnity propagation clustering and adaptive feature selection,” Knowl.-Based Syst., vol. 116, pp. 1–12, Jan. 2017. [21] R. Langone, C. Alzate, B. D. Ketelaere, J. Vlasselaerc, W. Meertc, and J. A. K. Suykensa, “LS-SVM based spectral clustering and regression for predicting maintenance of industrial machines,” Eng. Appl. Artif. Intell., vol. 37, pp. 268–278, Jan. 2015. [22] C. Sun, X. Chen, R. Yan, and R. X. Gao, “Composite-graph-based sparse subspace clustering for machine fault diagnosis,” IEEE Trans. Instrum. Meas., vol. 69, no. 5, pp. 1850–1859, May 2020. [23] S. Fong, J. Harmouche, S. Narasimhan, and J. Antoni, “Mean shift clustering-based analysis of nonstationary vibration signals for machinery diagnostics,” IEEE Trans. Instrum. Meas., vol. 69, no. 7, pp. 4056–4066, Jul. 2020. [24] J. Hou, Y. Wu, H. Gong, A. S. Ahmad, and L. Liu, “A novel intelligent method for bearing fault diagnosis based on EEMD permutation entropy and GG clustering,” Appl. Sci., vol. 10, no. 1, p. 386, Jan. 2020. [25] A. Fahad et al., “A survey of clustering algorithms for big data: Taxonomy and empirical analysis,” IEEE Trans. Emerg. Topics Comput., vol. 2, no. 3, pp. 267–279, Sep. 2014. [26] A. Rodriguez and A. Laio, “Clustering by fast search and ﬁnd of density peaks,” Science, vol. 344, no. 6191, pp. 1492–1496, Jun. 2014. [27] Z. Liang and P. Chen, “Delta-density based clustering with a divide- and-conquer strategy: 3DC clustering,” Pattern Recognit. Lett., vol. 73, pp. 52–59, Apr. 2016. [28] L. Yaohui, M. Zhengming, and Y. Fang, “Adaptive density peak clustering based on K-nearest neighbors with aggregating strategy,” Knowl.-Based Syst., vol. 133, pp. 208–220, Oct. 2017. [29] M. Du, S. Ding, and Y. Xue, “A novel density peaks clustering algorithm for mixed data,” Pattern Recognit. Lett., vol. 97, pp. 46–53, Oct. 2017. [30] L. C. Jiao, F. Shang, F. Wang, and Y. Liu, “Fast semi-supervised clus- tering with enhanced spectral embedding,” Pattern Recognit., vol. 45, no. 12, pp. 4358–4369, 2012. [31] A. Karlekar, A. Seal, O. Krejcar, and C. Gonzalo-Martín, “Fuzzy K-means using non-linear S-distance,” IEEE Access, vol. 7, pp. 55121–55131, 2019. [32] F. Cao, J. Z. Huang, and J. Liang, “A fuzzy SV-K-modes algorithm for clustering categorical data with set-valued attributes,” Appl. Math. Comput., vol. 295, pp. 1–15, Feb. 2017. [33] U. Maulik, S. Bandyopadhyay, and I. Saha, “Integrating clustering and supervised learning for categorical data analysis,” IEEE Trans. Syst., Man, Cybern. A, Syst. Humans, vol. 40, no. 4, pp. 664–675, Jul. 2010. [34] I. Saha and U. Maulik, “Incremental learning based multiobjective fuzzy clustering for categorical data,” Inf. Sci., vol. 267, pp. 35–57, May 2014. [35] I. T. R. Yanto, M. A. Ismail, and T. Herawan, “A modiﬁed fuzzy K- partition based on indiscernibility relation for categorical data cluster- ing,” Eng. Appl. Artif. Intell., vol. 53, pp. 41–52, Aug. 2016. [36] M. Li, S. Deng, L. Wang, S. Feng, and J. Fan, “Hierarchical clustering algorithm for categorical data using a probabilistic rough set model,” Knowl.-Based Syst., vol. 65, pp. 60–71, Jul. 2014. [37] C. Li and G. Biswas, “Unsupervised learning with mixed numeric and nominal data,” IEEE Trans. Knowl. Data Eng., vol. 14, no. 4, pp. 673–690, Jul./Aug. 2002. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply. 3528716 IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 71, 2022 [38] C.-C. Hsu, “Generalizing self-organizing map for categorical data,” IEEE Trans. Neural Netw., vol. 17, no. 2, pp. 294–304, Mar. 2006. [39] Z. Huang, “Clustering large data sets with mixed numeric and categorical values,” in Proc. 1st Paciﬁc–Asia Conf. Knowl. Discovery Data Mining, 1997, pp. 21–34. [40] C.-C. Hsu and Y.-C. Chen, “Mining of mixed data with application to catalog marketing,” Exp. Syst. Appl., vol. 32, no. 1, pp. 12–23, 2007. [41] Z. Zheng, M. Gong, J. Ma, L. Jiao, and Q. Wu, “Unsupervised evolutionary clustering algorithm for mixed type data,” in Proc. IEEE Congr. Evol. Comput., Jul. 2010, pp. 1–8. [42] S. P. Chatzis, “A fuzzy C-means-type algorithm for clustering of data with mixed numeric and categorical attributes employing a probabilistic dissimilarity functional,” Exp. Syst. Appl., vol. 38, no. 7, pp. 8684–8689, 2011. [43] J. Ji, W. Pang, C. Zhou, X. Han, and Z. Wang, “A fuzzy K-prototype clustering algorithm for mixed numeric and categorical data,” Knowl.- Based Syst., vol. 30, pp. 129–135, Jun. 2012. [44] J. Ji, T. Bai, C. Zhou, C. Ma, and Z. Wang, “An improved K- prototypes clustering algorithm for mixed numeric and categorical data,” Neurocomputing, vol. 120, pp. 590–596, Nov. 2013. [45] S. Santini and R. Jain, “Similarity measures,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 21, no. 9, pp. 871–883, Sep. 1999. [46] J. Jiang, Y. Chen, X. Meng, L. Wang, and K. Li, “A novel density peaks clustering algorithm based on K nearest neighbors for improving assignment process,” Phys. A, Stat. Mech. Appl., vol. 523, pp. 702–713, Jun. 2019. [47] D. Dheeru and E. K. Taniskidou. . UCI Machine Learning Repository. [Online]. Available: [48] G. David and A. Averbuch, “SpectralCAT: Categorical spectral cluster- ing of numerical and nominal data,” Pattern Recognit., vol. 45, no. 1, pp. 416–433, 2012. Krishna Kumar Sharma received the M.Tech. (Information Technology) degree from IIIT Allahabad, Allahabad, India, in 2011, and the Ph.D. degree from the Department of Computer Science and Engineering, PDPM Indian Institute of Information Technology, Design and Manufacturing Jabalpur, Jabalpur, India, in 2021. He is currently an Assistant Professor with the Department of Computer Science and Informatics, University of Kota, Kota, India. His current research interests include pattern recognition. Ayan Seal (Senior Member, IEEE) received the Ph.D. degree in engineering from Jadavpur Univer- sity, Kolkata, India, in 2014. He is currently an Assistant Professor with the Department of Computer Science and Engineer- ing, PDPM Indian Institute of Information Technol- ogy, Design and Manufacturing Jabalpur, Jabalpur, India. He has visited the Universidad Politécnica de Madrid, Madrid, Spain, as a Visiting Research Scholar. He has authored or coauthored several journals, conferences, and book chapters in the area of biometric and medical image processing. His current research interests include image processing and pattern recognition. Dr. Seal was a recipient of several awards. Recently, he received the Sir Visvesvaraya Young Faculty Research Fellowship from Media Lab Asia, Ministry of Electronics and Information Technology, Government of India. Anis Yazidi (Senior Member, IEEE) received the M.Sc. and Ph.D. degrees from the University of Agder, Grimstad, Norway, in 2008 and 2012, respectively. He was a Researcher with Teknova AS, Grimstad. From 2014 to 2019, he was an Associate Pro- fessor with the Department of Computer Science, Oslo Metropolitan University, Oslo, Norway. He is currently a Full Professor with the Department of Computer Science, Oslo Metropolitan University, where he is leading the research group in applied artiﬁcial intelligence. He is also a Professor II with the Norwegian University of Science and Technology (NTNU), Trondheim, Norway, and a Senior Researcher with Oslo University Hospital, Oslo. His current research interests include machine learning, learning automata, stochastic optimization, and autonomous computing. Ondrej Krejcar received the Ph.D. degree in tech- nical cybernetics from the Technical University of Ostrava, Ostrava, Czechia, in 2008. He is currently a Full Professor in systems engi- neering and informatics with the University of Hradec Kralove (UHK), Hradec Kralove, Czechia, and the Faculty of Informatics and Management, Center for Basic and Applied Research, UHK; and a Research Fellow with the Malaysia-Japan Interna- tional Institute of Technology, University of Tech- nology Malaysia, Kuala Lumpur, Malaysia. Since June 2020, he has been a Vice-Rector for science and creative activities of the UHK. He is also the Director of the Center for Basic and Applied Research, UHK. From 2016 to 2020, he was the Vice-Dean for science and research with the Faculty of Informatics and Management, UHK. His H-index is 21, with more than 1800 citations received in the Web of Science, where more than 120 IF journal articles are indexed in JCR index. Dr. Krejcar has been a Management Committee Member substitute at Project COST CA16226 since 2017. In 2018, he was the 14th top peer Reviewer in Multidisciplinary in the World according to Publons and a Top Reviewer in the Global Peer Review Awards 2019 by Publons. He is currently on the Editorial Board of the MDPI Sensors IF journal (Q1/Q2 at JCR) and several other ESCI-indexed journals. Since 2018, he has also been a Vice-Leader and a Management Committee Member at WG4 at project COST CA17136. Since 2019, he has been the Chairperson of the Program Committee of the KAPPA Program, Technological Agency of the Czech Republic as a regulator of the EEA/Norwegian Financial Mechanism in the Czech Republic for the term 2019–2024. Since 2020, he has been the Chairperson of Panel 1 (Computer, Physical and Chemical Sciences) of the ZETA Program, Technological Agency of the Czech Republic. From 2014 to 2019, he has been the Deputy Chairperson of Panel 7 (Processing Industry, Robotics, and Electrical Engineering) of the Epsilon Program, Technological Agency of the Czech Republic. He is also a guarantee of the doctoral study program in applied informatics with UHK, where he is focusing on lecturing on smart approaches to the development of information systems and applications in ubiquitous computing environments. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:05:19 UTC from IEEE Xplore. Restrictions apply.","—With the rapid development of sensors and mechan- ical systems, we produce an exponentially large amount of data daily. Usually, faults are prevalent in these sensory systems due to harsh operational conditions. Thus, detecting and diagnosing faults in the gearbox of mechanical systems are done by analyzing an exponentially large amount of data in the form of vibration signals and categorical features. However, the automatic fault detection method can match the increasing requirement for high-quality products in the course of intelligent manufacture. Thus, to acquire more distinguishable fault features under varied conditions, a new adaptive mixture distance-based simple and efﬁcient density peaks clustering algorithm is proposed for handling mixed data as real-world datasets encompassing both numerical and categorical attributes. Our approach revolves around the concept of a sequence of the weighted exponential ker- nel using a symmetry-favored c-nearest neighbor to estimate the global parameter and the local density of each data point. Then, the initial clusters are extracted from a decision graph using an adaptive threshold parameter. The ﬁnal step is to allocate the remaining data objects, if they are density reachable, to either of the initial groups. Thirteen UCI datasets and one real-world dataset from a mechanical system for gearbox defect diagnosis are employed to validate the proposed method. Five external and two internal evaluation criteria are considered to gauge how well the strategies are working. All of the ﬁndings indicate that the proposed method outperforms 13 other approaches. Manuscript received 10 July 2022; revised 16 September 2022; accepted 9 October 2022. Date of publication 21 October 2022; date of current version 9 November 2022. This work was supported in part by the SPEV project “Smart Solutions in Ubiquitous Computing Environments” (under ID: UHK-FIMSPEV-2022-2102), University of Hradec Kralove, Faculty of Informatics and Management, Czech Republic. The Associate Editor coordi- nating the review process was Dr. Xiaofeng Yuan. (Corresponding author: Ayan Seal.) Krishna Kumar Sharma is with the Department of Computer Science and Informatics, University of Kota, Kota, Rajasthan 324005, India (e-mail: krisshna.sharma@gmail.com). Ayan Seal is with the Department of Computer Science and Engi- neering, PDPM Indian Institute of Information Technology, Design and Manufacturing Jabalpur, Jabalpur, Madhya Pradesh 482005, India (e-mail: ayanseal30@ieee.org). Anis Yazidi is with the Department of Computer Science, Oslo Metropol- itan University (OsloMet), 0166 Oslo, Norway, also with the Department of Computer Science, Norwegian University of Science and Technology (NTNU), 7034 Trondheim, Norway, and also with the Department of Plastic and Reconstructive Surgery, Oslo University Hospital (OuS), 460167 Oslo, Norway (e-mail: anis.yazidi@oslomet.no). Ondrej Krejcar is with the Center for Basic and Applied Science, Faculty of Informatics and Management, University of Hradec Kralove, 500 03 Hradec Kralove, Czech Republic, and also with the Malaysia-Japan International Insti- tute of Technology (MJIIT), Universiti Teknologi Malaysia, Kuala Lumpur 54100 , Malaysia (e-mail: ondrej.krejcar@uhk.cz). Digital Object Identiﬁer 10.1109/TIM.2022.3216366 Index Terms—Density peaks clustering (DPC), mixed data (MD), S-distance, symmetric favored c-nearest neighbors (c-NN). I.","['Krishna Kumar Sharma', 'Ayan Seal', 'Anis Yazidi', 'Ondrej Krejcar']"
A sensitivity analysis of cellular automata and heterogeneous topology networks: partially-local cellular automata and homogeneous homogeneous random boolean networks,"Tom Eivind Glover, Ruben Jahren, Francesco Martinuzzi, Pedro Gonçalves Lind and Stefano Nichele",2025,1.0,40,"International Journal of Parallel, Emergent and Distributed Systems",article,"International Journal of Parallel, Emergent and
Distributed Systems
ISSN: (Print) (Online) Journal homepage: www.tandfonline.com/journals/gpaa20
A sensitivity analysis of cellular automata and
heterogeneous topology networks: partially-local cellular
automata and homogeneous homogeneous random
boolean networks
Tom Eivind Glover, Ruben Jahren, Francesco Martinuzzi, Pedro Gonçalves
Lind & Stefano Nichele
To cite this article: Tom Eivind Glover, Ruben Jahren, Francesco Martinuzzi, Pedro Gonçalves
Lind & Stefano Nichele (2025) A sensitivity analysis of cellular automata and heterogeneous
topology networks: partially-local cellular automata and homogeneous homogeneous random
boolean networks, International Journal of Parallel, Emergent and Distributed Systems, 40:1,
59-99, DOI: 10.1080/17445760.2024.2396334
To link to this article:  https://doi.org/10.1080/17445760.2024.2396334
© 2024 The Author(s). Published by Informa
UK Limited, trading as Taylor & Francis
Group.
Published online: 02 Sep 2024.
Submit your article to this journal 
Article views: 474
View related articles 
View Crossmark data
Full Terms & Conditions of access and use can be found at
https://www.tandfonline.com/action/journalInformation?journalCode=gpaa20
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
2025, VOL. 40, NO. 1, 59–99
https://doi.org/10.1080/17445760.2024.2396334
A sensitivity analysis of cellular automata and heterogeneous
topology networks: partially-local cellular automata and
homogeneous homogeneous random boolean networks
Tom Eivind Glovera, Ruben Jahrena, Francesco Martinuzzib,c,d, Pedro Gonçalves Linda,e and
Stefano Nichelea,f
aDepartment of Computer Science, OsloMet – Oslo Metropolitan University, Oslo, Norway; bCenter for Scalable Data
Analytics and Artiﬁcial Intelligence, Leipzig University, Leipzig, Germany; cInstitute for Earth System Science &
Remote Sensing, Leipzig University, Leipzig, Germany; dRemote Sensing Centre for Earth System Research, Leipzig
University, Leipzig, Germany; eNumerical Analysis and Scientiﬁc Computing, Simula Research Laboratory, Oslo,
Norway; fDepartment of Computer Science and Communication, Østfold University College, Halden, Norway
ABSTRACT

KEYWORDS
Reservoir computing; cellular
automata; ReCA; sensitivity;
chaos
CONTACT Tom Eivind Glover
tomglove@oslomet.no
OsloMet – Oslo Metropolitan University, P.O. Box 4, St. Olavs plass
N-0130, Oslo, Norway
© 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.
This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/),
which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. The terms on which this
article has been published allow the posting of the Accepted Manuscript in a repository by the author(s) or with their consent.
 60
T. E. GLOVER ET AL.
1. Introduction
Standard Artificial Intelligence (AI) approaches rely on high-performance computing such as with
cloud or cluster computing. However, these are very energy-intensive resources, and many popular
models are energy-intensive in training [1] and inference [2]. Conversely, biological intelligence has
made highly energy-effective solutions, e.g. the brain. Despite operating under conditions such as
increased decentralisation, asynchronisation, and slower signal propagation, biological intelligence
has achieved highly energy-efficient solutions, with the human brain operating at approximately
25–30 watts [3,4]. These observations indicate that there is still much to learn and gain from studying
biological intelligence.
In this work, we focus on unconventional computational models, such as Cellular Automata (CA) or
Random Boolean Networks (RBN), which utilise Boolean logic between local cells (nodes). This reliance
on Boolean logic enables easy hardware implementation, as the operations can be implemented in cir-
cuitry or an FPGA, allowing energy-efficient inference of the model. It is possible to create an abstract
pathway from CA to Biological Neural Networks (BNN); one example can be seen in Figure 1, and this
pathway would require many steps. CA is a special case of RBN where the neighbour connections are
entirely regular, and every cell has the same activation function. Viewed from the other direction, RBN
is a CA with random neighbourhood and random rules per cell (node). RBN is a well-known simple
biological model of the Gene regulatory network [5,6], which is an intelligence- and computational
space used for solving, among other things, morphological problems. Though there are multiple dis-
crete steps between CA and RBN, as can be seen in Figure 1, we limit ourselves to exploring substrates
between CA and Homogeneous Homogeneous RBN (HHRBN); these are the substrates that have the
same rule (Homogeneous) in every cell. Essentially, we compare homogeneous topology networks to
heterogeneous topology networks.
Note that many of the modern directions of these CA and RBN computational models are mov-
ing into the continuous domain, such as for CA, the continuous models of Lenia [7] and Neural CA
[8] are having much success modelling biological processes and biological like behaviours. Similarly,
Random Boolean Networks (RBN) are moving into the continuous domain, such as continuous RBN
[9] or stochastic RBN [10,11], and they are argued to be more biologically plausible models. Although
we want to encourage these explorations and essential directions, relying on the continuous domain
currently means either running on specialised hardware or taking an energy efficiency loss, as floating
point calculations are much more costly than integer or, even further, binary calculations. The future
Figure 1. There is a big diﬀerence between CA and BNN. The diﬀerence can be viewed as a series of discrete steps between sub-
strates, but even between RBN and CA, there are many discrete steps. This ﬁgure illustrates the diﬀerent substrates as a direct path,
but note that the steps from CA to RBN could have been done diﬀerently than illustrated. Also note, that this is a simpliﬁed imperfect
model of the substrate space between ECA and BNN.
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
61
is still being determined, but when it comes to specialised hardware like neuromorphic chips [12],
they are not expected to replace traditional hardware. Unless there is a significant breakthrough, spe-
cialised hardware like neuromorphic chips or quantum computing will likely exist alongside and in
cooperation with conventional computational systems. Therefore, the energy-efficient binary models
are still worth developing.
In this work, we stay within the binary domain for energy efficiency. We explore and compare three
binary models for computation, namely CA and models intermediate to RBN (PLCA, HHRBN). We do
this mainly to understand them as computational models better. Firstly, We combine them with Reser-
voir Computing (RC), an energy-efficient ‘substrate-independent’ training method. The combination
can potentially be an energy-efficient model in training and inference. We run these models on a sim-
ple 5-bit memory benchmark and find that ECA generally performs better. We follow up by measuring
the sensitivity (a necessary but not sufficient condition of chaos) of the networks using a Temporal Der-
rida plot. We find that, in general, HHRBN and PLCA slightly increase the sensitivity. Yet, by analysing
the defect collapse rate, we find that the substrates as a whole also skew towards ordered behaviour
as there are mitigating circumstances like how the random topology leads to imperfect connectiv-
ity that leads to a stronger attractor. This signifies that we observe a shrinking critical range in PLCA
and HHRBN. Though HHRBN are disordered in the topology, the behaviour of the network from these
effects is not as disordered as it might be natural to assume. This means counter-intuitively that regular
connections can more reliably reach a higher level of disorder.
2. Background and related work
Inthissection,wewilldetailthebackground,relatedwork,andtheoryrelevanttothispaper.Thispaper
connects many fields, uses several substrates, and relies on several empirical and theoretical methods.
This has made this section necessarily extensive to provide a comprehensive overview. In general this
sections begins by explaining the different substrates, followed by more theoretical overview of said
substrates as well as relevant concepts. Finally, the relevant related work is presented.
2.1. Cellular automata
Cellular Automata (CA) are a simple model consisting of a grid of cells possessing a limited set of k dis-
crete states placed on a uniformly connected grid, typically in 1 or 2 dimensions. The cell state changes
iteratively, depending on the state of the neighbours. Which neighbour state combination results in
which next state is determined by a lookup table, typically called the Transition Table (TT). CA was
first used to study self-replication by John von Neumann in 1940 but published in 1966 [3]. It can be
considered an idealised system for parallel and decentralised computation [13].
2.1.1. Elementary cellular automata (ECA)
Elementary Cellular automata (ECA) is a subset of CA in 1-dimension, binary states (S = 2) and 3 neigh-
bours (K = 3) (left, right and centre). Therefore, ECA only has SSK = 223 = 256 possible rules, and the
whole set of these is often named the rule-space. It is a convention to name individual rules in a
rule-space after the output states of the TT Binary(01011010) = Decimal(90). CA is deterministic, and
the rule, together with the initial condition, leads the CA into a set of subsequent states called the
trajectory. An example of rule 90 can be seen in Figure 2. Rule 110 has even been shown to be compu-
tationally universal [14], but one can question whether that is a useful definition of computation for a
parallel and distributed computational substrate [15].
2.1.2. Two dimensional CA (2D CA)
Beyond ECA are many other types of CA, such as 2-dimensional CA, where instead of configuring
the cells in a 1-dimensional line, they are now configured as a 2D surface. In 2D CA, the most typical
neighbourhood scheme is one of two configurations in Figure 3.
 62
T. E. GLOVER ET AL.
Figure 2. Example of 1 dimensional CA with rule 90 with TT, starting from a central cell on, executing 7 time-steps.
Figure 3. Common 2-dimensional neighbourhood schemes.
The Rule space of 2D CA is quite large, especially with a Moore neighbourhood. This space have
229 = 1.32 ∗10154 different Rules. It is too large to search exhaustively, but explorations into 2D CA
are often limited to totalistic or outer-totalistic rules. Totalistic rules mean the rule does not distinguish
whichneighboursareinwhichstate,butrather‘counts’thenumberofneighbourswithaspecificstate.
2D CA, with a Moore neighbourhoods, has only ten states to differentiate 0, 1, . . . 9 alive neighbours.
Only 210 = 1024 totalistic rules exist in this rule-space. Outer-totalistic does the same but differs on
the central cell. This means if the central cell is ‘dead’ there are 9 (0, 1, . . . 8) different totalistic states
the outer neighbours can be in and likewise, if the central cell is ‘alive’. This means there are 2 ∗9 = 18
states for outer-totalistic rules to differentiate. Therefore, there are 218 = 262,144 different rules in this
rule-space, though this can be somewhat reduced with symmetry equivalence classes [16].
The most famous version of 2D CA is Game of Life (GoL) [17], Figure 4. GoL is an outer-totalistic
rule, and it works in the following manner: at each CA step, the next state changes depending on the
following rules
• Any living cell dies if it has two or fewer living neighbours.
• Any Living cell persists if it has two or three living neighbours.
• Any living cell dies if it has more than three live neighbours.
• Any dead cell becomes alive if it has exactly three living neighbours.
In [18], it was also demonstrated that Game of Life is Turing complete. GoL can be expressed in a
more general form, which is the convention for the outer-totalistic 2D CA. GoL would be in the form
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
63
Figure 4. Single time-step of a 2-dimensional CA with Conway’s Game of Life rules. It features an oscillating blinker, a stable block,
and a spaceship glider.
of B3/S23, where the Birth ‘B’ component expresses the sum of neighbours needed to come alive, and
the Survives ‘S’ component expresses the sum of neighbours needed to stay alive. If a sum falls outside
this value, the cell will die or remain dead.
2.1.3. ‘Life-Like’ rules
The 2D outer-totalistic binary CA rule space is often called the ‘life-like’ [19] rules-space, and beyond
GoL, there are several other rules that are said to have ‘life-like’ properties. In [20], the goal was to
identify rules that could support similar ‘life-like’ structures that can be constructed in GoL. In addition
to identifying new ones, this article also provides an overview of many previously studied life-like rules
that support structures such as replicators, oscillators, and spaceships.
2.2. Random Boolean networks
The RBN is similar to a CA yet has two key differences. Firstly, in the RBN, the grid neighbour connec-
tions are not regular but randomly set up. Secondly, every node (cell) typically has a random TT, often
called an Activation function or Boolean function. This type of RBN is also sometimes called Classical
RBN (CRBN) [21]. The number of direct neighbours can be random, semi-random or constant. The latter
is called homogeneous RBN [21], an example is given in Figure 5.
As with CAs, several extensions exist beyond the original RBN, such as Continuous RBN [9] or
stochastic RBN [10,11]. While Kauffman first developed the CRBN to model gene regulatory networks,
these more modern extensions to the RBN model better emulate the biological activity of develop-
ment [9,11]. However, the CRBN were discovered early on [22] to contain a limited number of stable
states, or attractors, from which the system would settle down to following a random initialisation. The
basin of attraction reduces numerous initial states to a few stable cycles or fixed points.
RBN can be defined as the following. A set of N nodes connected randomly to K number of other
nodes, the specific connections for a given node can be denoted by KN. The nodes can be in one of
the two binary states, and every N has the a random activation function fa (TT), out of 22K possible rule
setups.
 64
T. E. GLOVER ET AL.
Figure 5. Example of an RBN with 7 Nodes and 3 neighbours, with a transition Table in two forms and a short execution example.
2.3. RBN classification
ECA is often partitioned and classified into several different categories or traits. In [23], a good overview
of many common or well-known ones can be found.
Similarly, RBN can be classified by their behaviour, i.e. ordered, complex or chaotic [21,24]. Depend-
ing on the value of N and K, the behaviour might differ, and one alternative name for RBN is the NK
model. In [25], Kauffmann added another parameter P, which can organise the rule-space. The rule has
a given P parameter value based on the number of neighbourhood combinations resulting in a 1 or
a 0. In later work [24], the larger distribution dominates, meaning P ≥0.5. Figure 5 has P = 0.5. One
can use this parameter to control the behaviour. P close to 1 would likely result in ordered behaviour,
and P close to 0.5 would likely result in chaotic behaviour. In between these, a critical (complex) Pc
behaviour might be found in the phase transition between order and chaos. This point or border is
often also called the edge of chaos. The work is reminiscent of CA work in [26], which we will intro-
duce later. The P is the same as λ is in Langton’s work, and in this work, we will use the λ notation for
both.
Another way to categorise RBN and CA is to look at the basin of attraction. Wuensche et al. [27]
and Wuensche [28–30] did extensive work in both RBN and CA and their basin of attractions. What
opened up this possibility was a method that could calculate backwards from a state. Take a cell in a
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
65
state and consider what possible local neighbourhood configurations would result in this state. These
are the possible previous states (preimage) for the neighbourhood. Finally, this can be applied to all
the cells and limit the possibilities between cells by constraining satisfaction. The possible preimages
often collapse to very few, making it possible to calculate the basin of attraction quickly.
2.4. Intermediate substrates
A system can be in a range of possible states that would be somewhere between CA and RBN. This
paper will discuss a substrate with homogeneous rules but random neighbour wiring. This is what we
define as HHRBN. HHRBN to distinguish it from what is in [21] called HRBN. It is called HHRBN rather
than non-local CA because the substrate seems to behave more like RBN than CA, and the equivalence
in this substrate is more applicable in RBN than CA.
In [31], Li worked with systems where all cells had the same activation function (TT), but the neigh-
bour connections were in various configurations. In this work Li classified the different connection
schemes as between non-local (random) and partially-local (central self-reference) as well as non-
distinct and distinct input/output (uniform number of outputs). Li then classifies the rule-space for
these substrates using mean field approximation and shows they are very neatly classified, particularly
non-local CA (HHRBN).
Much earlier [32–34] studied a system that Li would classify as partially-local CA.
HHRBN has additional commonly used names beyond non-local CA [31], such as Graph CA [35,36]
or (Cellular) Automata Networks [37]
In [28], Wuensche examined substrates between CA and RBN, including non-local CA and other
disordered CA. He defines disordered CA as a super-set of CA, which includes non-local CA and mixed
ruleCA.Furthermore,Wuenschecalculatesthesenetworks’basinofattractionfieldsanddemonstrates
how rewiring the network can train or modify the basin of attraction.
Mixed rule CA is also known as Non-uniform CA [37,38] or hybrid CA [37].
2.5. Minimum equivalent (ME)
InECA,RBNandeverythinginbetween,wefindequivalenceclassesthateffectivelyreducethenumber
of unique rules for a given substrate. The List of rules that make up the minimum set of unique rules is
called the Minimum equivalent (ME). These rules can be used as a smaller replacement for the entire
computational space of a specific substrate.
2.5.1. Minimum equivalence (ME) in elementary cellular automata (ECA)
ECA consists of 223 = 256 rules, but due to symmetries and other properties, there are only 88 rules
that are considered unique. The reason is that all excluded rules can be transformed into one of the 88
unique rules by one of the following trivial methods.
• reflection: switching left and right
• complement: switching 0 and 1
• reflection and complement: the combination of both transformations
An overview of the 88 rules can be found in Table 1. Figures 6 and 7 show examples of the
transformed rules.
The concept of reflection and complement seems to originate already in [32, p. 51, p. 176], and
more densely explained by the same author in [33]. In the previous source, the concept originated in
an intermediate substrate between ECA and RBN, with two random neighbours and itself, aka (PL CA).
The ME concept works the same in such a substrate, but the concept is perhaps best known when
applied to ECA in [27,39–41].
 66
T. E. GLOVER ET AL.
Figure 6. Reﬂection,complementandreﬂectioncomplementtransformationofrule110andequivalentwithrandominitialisation.
The reﬂection rule is initialised with a mirrored state and the complement rule with a ﬂipped value state.
Figure 7. Reﬂection,complementandreﬂectioncomplementtransformationofrule110andequivalentwithcentroidinitialisation.
The reﬂection rule is initialised with a mirrored state and the complement rule with a ﬂipped value state.
2.5.2. Minimum equivalence (ME) in homogeneous homogeneous random Boolean networks
In HHRBN, there is also an ME set, but the mirror complement changes in this substrate. Essentially,
the mirror complement changes to a switching complement. In ECA, the transformation between left
and right forms an equivalence class; in HHRBN, the transformation between any combination and
set of combinations between left, centre and right forms an equivalence class. This new equivalence
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
67
Table 1. The group of equivalent rules for ECA.
Rule
Equivalent
Rule
Equivalent
Rule
Equivalent
0
255
35
49, 59, 115
108
201
1
127
36
219
110
124, 137, 193
2
16, 191, 247
37
91
122
161
3
17, 63, 119
38
52, 155, 211
126
129
4
223
40
96, 235, 249
128
254
5
95
41
97, 107, 121
130
144, 190, 246
6
20, 159, 215
42
112, 171, 241
132
222
7
21, 31, 87
43
113
134
148, 158, 214
8
64, 239, 253
44
100, 203, 217
136
192, 238, 252
9
65, 111, 125
45
75, 89, 101
138
174, 208, 244
10
80, 175, 245
46
116, 139, 209
140
196, 206, 220
11
47, 81, 117
50
179
142
212
12
68, 207, 221
51
146
182
13
69, 79, 93
54
147
150
14
84, 143, 213
56
98, 185, 227
152
188, 194, 230
15
85
57
99
154
166, 180, 210
18
183
58
114, 163, 177
156
198
19
55
60
102, 153, 195
160
250
22
151
62
118, 131, 145
162
176, 186, 242
23
72
237
164
218
24
66, 189, 231
73
109
168
224, 234, 248
25
61, 67, 103
74
88, 173, 229
170
240
26
82, 167, 181
76
205
172
202, 216, 228
27
39, 53, 83
77
178
28
70, 157, 199
78
92, 141, 197
184
226
29
71
90
165
200
236
30
86, 135, 149
94
133
204
32
251
104
233
232
33
123
105
34
48, 187, 243
106
120, 169, 225
class further reduces the computational space to just 46 rules. The equivalence classes can be seen in
Table 2.
A more in-depth explanation of this transformation can be found in [16].
2.5.3. Rule dependency
Due to the properties of the ECA rule space, that space also includes rules that are invariant to one
or more of their neighbours, therefore they strictly do not compute on 3 neighbours. Essentially, they
do not differentiate on all the cells in the neighbourhood; e.g. rule 170 only differentiates on the left
neighbour and is indifferent to the values of the right and central neighbour, or similarly, rule 90 only
differentiates on the left and right neighbour, but not the central neighbour. This is called the rule
dependency, and the 3 neighbour rules can be of either 0,1,2 or 3-dependency. An overview of the ME
can be found in Table 3 and a complete overview in [40,42].
2.6. Definition of chaotic behaviour in nonlinear systems
To this day, the definition of chaotic behaviour is not mathematically univocal [43,44]. Still, we will
work with a well-accepted definition of chaotic function. The definition is as follows (see. [45, sub-
section 1.8]): a function or map f : V →V, on a vector space V, is chaotic if it satisfies the following
conditions:
• f has a sensitivity to initial conditions,
• f must be topologically transitive,
• has dense periodic orbits (periodic points are dense in V).
 68
T. E. GLOVER ET AL.
Table 2. The ME set for K = 3, for the switching and complement transformations.
Rule
Equivalent
Rule
Equivalent
0
255
44
56, 74, 88, 98, 100, 173, 185, 203, 217, 227, 229
1
127
45
57, 75, 89, 99, 101
2
4, 16, 191, 223, 247
46
58, 78, 92, 114, 116, 139, 141, 163, 177, 197, 209
3
5, 17, 63, 95, 119
60
90, 102, 153, 165, 195
6
18, 20, 159, 183, 215
62
94, 118, 131, 133, 145
7
19, 21, 31, 55, 87
104
233
8
32, 64, 239, 251, 253
105
9
33, 65, 111, 123, 125
106
108, 120, 169, 201, 225
10
12, 34, 48, 68, 80, 175, 187, 207, 221, 243, 245
110
122, 124, 137, 161, 193
11
13, 35, 47, 49, 59, 69, 79, 81, 93, 115, 117
126
129
14
50, 84, 143, 179, 213
128
254
15
51, 85
130
132, 144, 190, 222, 246
22
151
134
146, 148, 158, 182, 214
23
136
160, 192, 238, 250, 252
24
36, 66, 189, 219, 231
138
140, 162, 174, 176, 186, 196, 206, 208, 220, 242, 244
25
37, 61, 67, 91, 103
142
178, 212
26
28, 38, 52, 70, 82, 155, 157, 167, 181, 199, 211
150
27
29, 39, 53, 71, 83
152
164, 188, 194, 218, 230
30
54, 86, 135, 147, 149
154
156, 166, 180, 198, 210
40
72, 96, 235, 237, 249
168
200, 224, 234, 236, 248
41
73, 97, 107, 109, 121
170
204, 240
42
76, 112, 171, 205, 241
172
184, 202, 216, 226, 228
43
77, 113
232
Table 3. The ECA ME rules by neighbour dependency.
Rule Dependency
Rules
0 dep.
0
1 dep.
15,51,170,204
2 dep.
3,5,10,12,34,60,90,136,160
3 dep.
the 74 Rules not included in the previous rows
In essence, a function or map is unpredictable as it is sensitive to initial condition, indecompos-
able (can not be decomposed into two or more subsystems) as it is topological transitive, and yet has
an element of regularity as it has regular periodic orbits that are dense. Devaney also notes [45] that
while there are stronger definitions of chaotic function, the one above is a good definition in that it is
generally easy to verify and applies to a larger number of important examples.
Indeed, if a system is topologically transitive and has dense periodic orbits, then it also has sensi-
tivity to initial condition [46]. This means one should view sensitivity to initial condition as a necessary
condition for f to be chaotic, whereas topological transitivity and the existence of dense periodic orbits
together are sufficient conditions. This implication means it is possible to drop the first condition of
Devaney’s definition. We will, however, keep it as part of the definition of chaotic function since it is
easy to check in practice.
As mentioned above, the definition of chaotic behaviour usually applies to continuous variables.
However, it can be adapted to systems whose time-evolution is intrinsically discrete, as is the case of
CAs and RBNs. Chaotic behaviour can be considered in eight different situations, taking all possible
combinations of continuous and discrete time, continuous and discrete space, and continuous and
discrete state variables. We will consider the most common cases of such combinations, aiming to
introduce the concept of chaotic behaviour in CA and RBN.
2.6.1. Chaotic behaviour in continuous space, time and states
The definition of chaotic function when space, time, and states are continuous variables is given
above, as this is the common situation when defining chaotic behaviour. The prototypical example
of a chaotic system in such conditions is a turbulent fluid, described by the so-called Navier-Stokes
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
69
equations [47], which are partial differential equations, having therefore continuous time and space
variables as well as continuous state functions (velocity of the fluid).
2.6.2. Chaotic behaviour with continuous time and states and discrete space
The most well-known example of a chaotic system is the Lorenz system. This system comprehends
a set of three ordinary differential equations to model forced dissipative hydrodynamic flow [48]. It
is defined by ˙x = −σx + σy, ˙y = −xz + rx −y and ˙z = xy −bz. For the choice of parameter values
σ = 10, b = 8/3, r = 28 [49], one gets an orbit resembling a butterfly when plotting the x against z.
Due to its odd features, this orbit was classified as a ‘strange attractor,’ a stable orbit showing chaotic
behaviour. One such feature is that arbitrarily small difference in the initial condition leads to large
deviations in the following orbits over time. In other words, the Lorenz system shows sensitivity to
initial conditions.
Note that this system does not have a space dimension – in our classification with time, space and
state, the phase space, accounts for the state dimension. It is rather a low-dimensional example of
chaos [50, subsection 3.2.2], not an example of spatiotemporal chaos.
Yet, the same definition can be used when space is discrete. Indeed, a spatially extended (contin-
uous) system can be discretised into a mesh or grid of points, each governed by a set of differential
equations where both dependent and independent variables – state variable and time, respectively
– are continuous. This would be the case of a (discrete) set of coupled Lorenz systems distributed in
space, each described by continuous states and time.
2.6.3. Chaotic behaviour with continuous states and discrete time and space
Another famous example of chaos but with discrete time is the logistic map xt+1 = axt(1 −xt), used as
a simple mathematical model to population dynamics [49,51]. Yet, this simple equation is capable of
producing chaotic dynamics. From 3 < a < 3.57, the population starts to oscillate between more and
more values until it reaches the parameter region of about 3.57 < a < 4 where the oscillation explodes
into the infinite (no longer oscillating). For this region, small initial values for the population yield large
variations over time (sensitive to initial condition) [5, Chapter 2]. To note that this is not true for all
regions of 3.57 < a < 4, e.g. at a = 1 +
√
8 there is a period-3 cycle.
Similarly to the Lorenz system, the logistic map does not have an explicit space, but space can be
introduced by considering again a discrete set of coupled maps for a so-called coupled map lattice
[50, subsection 3.2.2].
2.6.4. ‘Chaotic’ behaviour with discrete time, space and states
This is the case of chaotic behaviour observed in CAs and RBNs, which have discrete state space (dis-
crete number of accessible states, e.g. a binary set of ‘0’ and ‘1’), evolve iteratively (discrete time),
and are composed of a discrete set of (spatially localised) nodes or cells. We, therefore, call them fully
discrete systems.
In a strict sense, taking the definition of chaotic function introduced above, this case can not show
chaotic behaviour. To understand this, we can consider the concept of dense periodic orbits. The
definition of dense can be stated as follows:
Let A be a subset of a topological space X. Then A is said to be dense in X if:
∀x ∈X,
∀ϵ > 0, ∃a ∈A : d(x, a) < ϵ,
where d(x, a) is the Euclidean distance between x and a. This means that in order to be dense, it must
be possible that elements of the two sets X and A are arbitrarily close. This feature can not occur in
intrinsically discrete systems, as distances are always multiples of an elementary (the smallest posi-
tive) distance between two distinct instants, states or spatially distributed nodes. We shall continue
this discussion in Subsection 5.6. In the rest of this paper, we will assume an ‘analogue’ of chaotic
behaviour based on the comparison of the number of accessible global states (set of individual states)
 70
T. E. GLOVER ET AL.
and the periodicity of the overall trajectories. More precisely, in the particular case of having a CA with
N cells, each one taking values {0, 1} (binary states), and then there are 2N accessible configurations
(global states). Being a finite number of accessible configurations, chaotic orbits can not occur strictly,
as defined above: all orbits will be periodic with a period not larger than 2N. In this context, we define
‘chaotic’ behaviour as the one typical of rules for which the periodicity scales geometrically with the
size of the system. In particular, a CA of size N is considered to show ‘chaotic’ behaviour if, when dou-
bling its size to 2N, the periodicity of its orbits increases quadratically, from 2N to 22N. Henceforth,
behaviours observed in ECA are called ‘chaotic’ with the quotation marks to more clearly separate it
as an analogy of chaos in other systems. However, these quotation marks are often omitted.
Perhaps the most famous example of ‘chaos’ in systems with discrete time, space and states is the
ECA Rule 30. Despite being a simple substrate (ECA) configuration, it can produce very complex and
pseudo-random behaviour. In Mathematica, the central column of rule 30 is used for the pRNG [52,
p. 317].
WorkhasalsobeendoneforasubsetofCAcalledlinearCA,in[53]itisclaimedthatforlinearCAover
Zm that ergodicity is equivalent to topological transitivity and that dense periodic orbits (regularity)
are equivalent to surjectivity.
In [54] Martinez worked on a method to determine if a linear CA over Zm has a behaviour that is
equicontinutity, sensitive to initial condition, strong transitivity or is positive expansive. They take a
hierarchical view of the definitions of chaos, from positively expansive to strong transitive to transitive
to sensitive, being the weakest.
2.6.5. Chaos in terms of computational utility
Beyond a scientific interest in the computational aspect of chaos, it has some very useful applications.
Like rule 30, many other chaotic systems, such as the logistic map [5, Chapter 2], can be used as a
pseudorandom number generator (pRNG).
To understand why, we begin with Shannon’s concepts of confusion and diffusion [55]. To miti-
gate simple statistical analysis, a cipher must have properties of confusion and diffusion. Confusion, as
in the input and the output, should have a very complicated relation. Diffusion means that the input
should affect the whole output. These concepts are also important for pRNG. Let’s view this in terms of
chaotic behaviour; a system sensitive to initial conditions would mean that small changes to the initial
condition would lead to large changes in the output. Therefore, one can not use a similar output to
predict the input, enhancing confusion. Further, a topologically transitive system (cannot be decou-
pled) ensures that one cannot decouple the solution, leading over time to an effect on every part of
the system, enhancing diffusion. Finally, a dense periodic orbit means the system can return to close
but not the same configurations, ensuring a rich set of values that are close in output but distant in
input, enhancing confusion and diffusion.
Typically, when testing systems for pRNG, one does many statistical tests such as the ones in [56].
Note that one of the tests in this article is non-linearity, which would imply that the exploration of
linear CA as chaotic systems would unlikely result in a good pRNG. Furthermore, theoretical reasoning
states that highest capacity computation lies on the edge of chaos (see Subsection 2.7). Assuming this
is true, identifying chaotic behaviour is important for identifying useful computational substrates.
2.7. Identifying the edge of chaos and with a parameter
The parameter space of a complex system often has a phase transition between order and disorder;
this phase transition region is often called ‘Edge of Chaos’ It is theorised that this region commonly
contains the highest capacity for computation defined as transformation, manipulation and storage
of information.
Langton [26] explored this theory in 1-dimensional multi-state CA with enlarged neighbourhoods
and found that the CA rule-space forms a phase transition between order and chaos when organised
over a λ (Lambda) parameter. The λ parameter starts by defining a state as the quiescent state. To
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
71
Figure 8. RC as a substrate-independent framework.
generate a Transition Table (TT) with a given λ value, one allocates to each TT entry a random number
α uniformlydistributedbetween0and1andattributesthequiescentstatetoallentrieswithα < λand
a non-quiescent state to the other. Using this method, Langton generated different candidate rules in
several regions of the rule-space over the λ parameter. He showed that the rules-space organises into
a phase transition between order and chaos and that strong candidates for computation are more
likely to be found there. Notably, this lambda method does not seem to work in the ECA rule space, as
mentioned in [26] and previous work.
2.8. Reservoir computing (RC)
Reservoir Computing (RC) is a substrate-independent framework for computing. RC is independent
because it works on many different substrates, but to be clear, different substrates would, of course,
have different capabilities. The RC framework consists of 3 parts: the input, the untrained reservoir and
the output.
The input part encodes some information into the untrained reservoir and typically into higher
dimensions.Theuntrainedreservoirtypicallyexpands,modifiesorchangestheinformation,butcould,
in the context of the framework, be considered a black box as seen in Figure 8. The output part is
typically linear, does dimensional reduction, and extracts useful features.
The RC concept originated in echo state networks (ESN) using recurrent neural networks as a sub-
strate (Figure 9) [57] and in liquid state machines (LSM) using a spiking neural network for a substrate
[58]. Since then, both ESM and LSM and a host of other substrates have been put under the umbrella
term of RC. Due to RC substrate-independent nature, many different substrates have been explored
and/or compared [59]. Some explore different topology configurations as in [60], where a deep lay-
ered sub-reservoirs were analysed instead of the typical one big reservoir. RC is also a very popular
method with physical reservoirs [59], as an extreme example in [61] it was demonstrated that RC can
use the surface waves on a bucket of water as a reservoir and they successfully solved speech recog-
nition and xor tasks using this substrate. One interesting substrate is real biological neural networks
(BNN), specifically disassociated neurons that self-organise over a microelectronic array [62].
There is also evidence that reservoir computing is a useful trick for computation (one of many) used
in biology. Nikolic et al. [63] shows that a linear classifier can extract information about the short-term
past stimulus (images, xor) from the primary visual cortex of an anaesthetised cat. Additionally, there
is some evidence of RC in other biological and computational processes. In [64], the ESN (RC) model
was used to simulate an example of a known genetic regulation network (GRN) process and performed
satisfactorily. Similarly, in [65], the LSM (RC) model was used.
 72
T. E. GLOVER ET AL.
Figure 9. Basic network Architecture of an ESN.
2.9. Reservoir properties
An important property in ESN is the Echo State Property (ESP). Given some input signal, the reservoir
must asymptotically remove the initial condition information to have this property. In [57], it is shown
that for a reservoir with specified conditions, it violates the ESP if the spectral radius of the weight
matrix is larger than 1, and it was empirically observed that for Spectral radius below 1, the ESP is
given. Note that in [66] Jaeger warns that this does not mean that ESP is granted for any system with
a spectral radius of below 1 (asymptotically stable). It is not a necessary nor a sufficient condition.
Similar to the ESP is the concept of the fading memory property. It states that an input/output
system is said to have fading memory when the outputs associated with inputs that are close in the
recent past are close, even when those inputs may be very different in the distant past. Grigoryeva and
Ortega [67] and Tanaka et al. [59].
Maass et al. [58] determines two conditions for real-time computation on perturbations. The sep-
aration property (SP) is a necessary condition, and the approximation property (AP) is a sufficient
condition. SP refers to the separation between trajectories based on differences in perturbations. AP
refers to the capabilities of the readout mechanism.
2.10. Reservoir computing with CA (ReCA)
The first study that introduced CA as a substrate in reservoir computing is [68]. This study investigated
Game of Life and several ECA rules as reservoir substrates and tested on a 5-bit and 20-bit memory
benchmark. In addition, it presents a theoretical comparison of CA vs ESN, using the metric of the
number of operations needed to solve the benchmark, which documents a clear advantage of using
CA.
As an ECA reservoir only relies on simple discrete binary interactions between cells (see [69] for
details), it affords a hardware-friendly substrate implementation. The problem (perhaps ironically)
becomes how to implement the readout layer in hardware. In [70], ReCA using ECA with a max-pooling
and softmax strategy was implemented on a Field Programmable Gate Array (FPGA). In [71], a CA was
implemented on Complementary metal-oxide-semiconductor (CMOS) combined with a custom hard-
ware SVM implemented in resistive random-access memory (ReRAM). In [72], a synthesised hardware
implementation of ReCA using ECA with a max-pooling and ensemble bloom filter classifier. Show-
ing impressive results compared to ‘state-of-the-art’ in terms of energy efficiency, memory usage and
area(number of gates) usage, but with comparably poor accuracy [70].
Other works have also studied ReCA using the 5-bit memory benchmark. Nichele and Molund [73]
changed the structure of the CA to a deep-layered architecture and compared it to a single layer, which
resulted in noticeable performance improvements. Additionally, in [74] the authors organised the CA
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
73
substrate as consisting of two regions of different ECA rules. Different combinations of rules were
explored, and some showed great promise. In [75], an exploration was conducted of different cell his-
tory selection methods for the classification model on the 5-bit memory task, a temporal order task
and arithmetic and logic operation tasks. In [76], CA rules with multiple states and larger neighbour-
hoods were evolved and then tested on the 5-bit memory benchmark. In [77] ECA and asynchronous
ECA is tested and compared on the 5-bit memory benchmark, mainly in the context of the distractor
period.
In [78], it was pointed out that the benchmark has no train test split. They modified the benchmark
by training on just a few (2 or 3) of the 32 possible input streams, and some of the rules with more
ordered behaviour could still solve this version of the benchmark.
In [79], the full ECA set was tested using key parameters of number of bits (Nb), redundancies (R)
and Grid size. Glover et al. [80] extended this work to include more parameters such as Iterations (I)
and Distractor Period (Dp). This paper also explained many of the unexpected results in the previous
study, but perhaps as important, it similarly to [78] pointed out some weaknesses in the 5-bit memory
benchmark.
ReCA is also used on other benchmarks than the 5-bit memory benchmark. Morán et al. [70], Liang
et al. [72], and Glover et al. [81] implemented ReCA in hardware and tested using MNIST. An addi-
tional example is [82], where the authors solved tasks of sine and square wave classification, non-linear
channel equalisation, Santa Fe Laser Data and iris classification.
In [83] an method for Rule Selection for ReCA was presented. Limiting the search-space to only
Linear rules that obey a list of specific mathematical properties (see paper for details), the paper
demonstrates the method selects for rules in the high performance (95-80 percentile) bracket on sev-
eral time-series prediction benchmarks compared to the full Linear CA space of same neighbourhood
and number of states.
2.11. Reservoir computing with random Boolean networks (ReRBN)
In [84,85], ReRBN was explored on temporal parity and temporal density (temporal majority task). For
the tasks and parameters explored, it was found that the heterogeneous RBN (different in-degree RBN)
reservoir worked best at a critical connectivity K = 2 (in-degree of 2). In contrast, [86] found that for
homogeneous RBN, criticality was instead found at K = 3. Burkow [87] extended this work, explor-
ing different reservoir properties such as perturbation percentage, the relationship with attractor and
performance and comparing a subset reading from a larger reservoir to a subset equal reservoir.
In [88], the relationship between N and K was also studied with a balance b between excitatory and
inhibitory nodes. They find that K is the most important of the control parameters, as it affords simpler
fine tuning of the other parameters.
2.12. Reservoir computing with intermediate substrates
RC explorations Between CA and RBN substrates are less common. This paper reports and extends on
work done in a master thesis [89], where Life-like CA, ECA, PLCA and HHRBN were explored using the
5-bit memory benchmark.
In another master thesis [90], Reservoir computing with cellular automata networks where explored
on a simple text classification task. The study explores and compares different ways to construct the
network and how that affects performance. The cellular automata networks described include fixed
predecessors (in-degree); from the description, it seems they explored PLCA, confirmed by the lack of
the same score for rules 204 and 170. Yet, we can not directly compare it with the work in this paper,
as the study constructs the transitions rule differently.
 74
T. E. GLOVER ET AL.
Table 4. Example of the 5-bit memory task with distractor period of 200 and Input of the number 25 in binary form.
Step
Input
Output
Stage
1
1
0
0
0
0
0
1
Input bits to memorise
2
1
0
0
0
0
0
1
3
0
1
0
0
0
0
1
4
0
1
0
0
0
0
1
5
1
0
0
0
0
0
1
6
0
0
1
0
0
0
1
Distractor period
...
0
0
1
0
0
0
1
204
0
0
1
0
0
0
1
205
0
0
0
1
0
0
1
Cue signal
206
0
0
1
0
1
0
0
Output bits to memorise
207
0
0
1
0
1
0
0
208
0
0
1
0
0
1
0
209
0
0
1
0
0
1
0
210
0
0
1
0
1
0
0
Notes: Artefact inspired by Babson and Teuscher [76].
2.13. 5-bit memory benchmark
The 5-bit memory benchmark traces its root to the short long-term memory task introduced in [91].
Although often cited as the source [68,73,74,76], none of the benchmarks in [91] are the 5-bit memory
benchmark, but some of them are very similar in intention. The earliest source where the 5-bit mem-
ory benchmark is recognisable is in [92], but named ‘noiseless memorisation,’ corroborated with the
clearer and more detailed explanation of the benchmark in [93, p. 47] and in [94].
The 5-bit memory benchmark’s goal is to test whether a system is capable of memorising a 5-bit
and reproducing it at a later stage. Table 4 shows an example of the memory task. The benchmark
has 4 input channels where only a single channel can be active at the same time. The first two input
channels are dedicated to the 5-bits. The bits are fed into the system sequentially over 5 steps. One
can view the first input channel as the ‘pure’ 5-bits and the second as the reversed 5-bits. The 3rd input
channel is dedicated to constantly feeding input into the system during the distractor period and the
output stage. The 4th input channel is dedicated to the cue signal, signalling that the output is to be
given. The benchmark has 3 output channels where one and only one should be active simultaneously.
Note that some earlier examples have 4 output channels but one is dropped as it is never intended
to give output. The first two are dedicated to the original 5-bits inserted into the system and should
sequentially output them following the cue signal, the final output channel should give a signal in all
other cases. Due to this output’s nature, one can abstract and view the task as a temporal classification
problem.
In this paper, we often call it the x-bit memory benchmark, as we have varied the number of bits
to be memorised. Also, note that the 20-bit memory benchmark mentioned in some of the previous
sources is not the same as the 5-bit memory benchmark but with 20 bits to memorise. The 20-bit
memory benchmark uses 7 input channels, 5 for the input and a bit length of 10.
2.14. Small-world
In [95], they explored graphs varying on p value where p = 1 meant random connectivity and p = 0
is regular connectivity. They demonstrated that small worldliness was achieved with a relatively low
p-value. However, in relation to this work, they have a larger neighbour degree. Additionally, we work
with fixed in-degree networks (all cells have 3 neighbours). For these reasons, we might not see the
same level of small-worldness in our topologies, but naturally, in contrast to ECA, some is expected in
PLCA and HHRBN.
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
75
2.15. Derrida plots and the derrida coefficient
Derrida Plots is named after the author of its origin in [96]. It is a tool primarily used to identify the
behaviourofaparticularRBN(critical,chaoticorordered(frozen)).Derridaoriginallyusedittocompare
a classical RBN (quenched) and an ‘annealed’ RBN, in which every connection and activation function
is randomly reassigned after each iteration. To construct a Derrida plot, one compares different initial
conditions on the same system. Start with a random initial condition, flip 1-bit for one of the initial
conditions, then evolve both the RBN one step, and calculate the Dh. Then do the same but for two
flipped bits in the original initial condition, and so on until N bits. One plots the Dh as a function of
the number of flips in the initial condition. Typically, the hamming distance increases linearly with the
number of flips until it saturates. If the linear increase has a slope larger than one, the behaviour is
considered to be chaotic; if the slope is below one, the behaviour is ordered (frozen); and if it is exactly
one, the behaviour is critical (‘complex’) [97], [98, p. 246].
This behaviour classification can be formalised with the Derrida coefficient, Dc, given the angle θ
of the initial slope, namely Dc = log2 (tan θ). For θ > π/4, Dc is positive and negative for θ < π/4 [98,
p. 250].
In [99] the Derrida coefficient of ECA was mapped together with the Generative morphological
diversity µ, to classify ECA on a spectrum of autistic, schizophrenic, and creative personality.
3. Methodology and experimental setup
This section will detail the specific methods and experimental setup used in this paper. We begin with
the experimental methods by documenting the x-bit memory benchmark details used for the 2D life-
like (CA, HHRBN) and the 1D (CA, PLCA, HHRBN). Then, we will explain the details of the Temporal
Derrida Plots (TDP) used to analyse the sensitivity. Then, we will give details on how we measured the
rate of defect collapse (collapse rate). We continue with the network analysis method of the longest
simple cycle and how it is estimated. Finally, we will document the source code and the dependencies
with which the code was built.
3.1. x-bit memory benchmark
The 2D life-like experiments use the same setup as [100]. It uses a parameter of R, which in this specific
experiment is the grid size, and in terms of full grid size, it is R × R. The Iterations I represent the number
of iterations between encoding steps and the number of steps fed into the classifying model, chose to
be a ridge regression model. The projection ratio Pr is the ratio of cells that the input is encoded into,
set to Pr = 0.6.
For the 1D substrates 5-bit memory benchmarks, the experimental setup and the default parame-
tersarethesamein[80].RedundancyR = 4isthenumberofconnected‘sub-reservoirs’withindividual
mapped input. Note how R in the life like experiment and in the 1D experiment signifies different
things. The Iterations I = 2 represent the number of iterations between encoding steps and the num-
ber of iterations the classifying model had access to. The sub reservoir grid size Ld = 40, meaning the
total number of cells(nodes) where Ld ∗R = 160. An example demonstrating R, Ld and I can be seen in
Figure 10. The classifying model, in this case, was an SVM with a linear kernel.
3.2. Temporal derrida plots (TDP)
In this work, we introduce a variant of Derrida plots: Instead of introducing a new defect at each step
(see Subsection 2.15), we follow the development of one or a few defects starting at t = 0 and see how
Dh changes throughout time (i.e. as a function of iterations). In this way, one follows how Dh diverges or
converges to a specific value over multiple iterations. Henceforth, we call these plots ‘temporal Derrida
 76
T. E. GLOVER ET AL.
Figure 10. ReCA example showing R, I and Ld. Additionally, the top streams is an example of how input is encoded temporarily into
the reservoir.
plots’ (TDP). Derrida plots retrieve approximately the Lyapunov exponent in state space, whereas the
temporal Derrida plot retrieves the Lyapunov exponent in time.
If we take the simple example of the rules 204 and 170, a simple inspection of these rules would
tell you they are very ordered in their behaviour, simply propagating the initial condition. Yet, using
the original method [96] and as described in [98] (cf. [99, Appendix A]), Derrida plots for rule 204 and
170 yields Dc = 0, meaning that they follow the 45 angle line. This interpretation is that rules 204
and 170 are complex/ critical in the Derrida Plot method. This is not the case with our TDP. Therefore,
we argue that the Derrida plot method’s weaknesses in ECA substrates are solved with our variant of
TDP. Furthermore, if one is identifying chaotic features for the purpose of harvesting the chaos for
something directly useful, e.g. a Random Number Generator (as they are being used for [52, p. 317]).
Then, it would be more beneficial to know the development through the substrate over time, as a
single step would not be enough to diffuse the seed value. In contrast, a strength of using the Derrida
plot rather than the TDP is that it allows one to sample a larger number of initial states of the state
space.
In addition to the Dh, we plot the Damerau–Levenshtein distance (Ddl). This can catch deceptive
different-looking configurations like the aether in rule 110; this effect has a marked impact later in the
results section with Figure 14(b).
Furthermore, we run these TDP beyond N steps as we also want to see where the substrates settle.
Which we argue tells us something of how ‘chaotic’ the substrate truly is; a substrate that is ‘chaotic’
to the idea of using it as an RNG should not have any preference for 1 or 0 (balanced), and where the
substrate settles tells us this experimentally. If a system is ‘ergodic’ to the sense that it covers the entire
state space, then it should find every state equally likely and settle at a Dh of half the grid size (half-max
distance).
We run this for five configurations, 1, 5 and 9-bit changed in the centre, and 5 and 9-bits changed
randomly. The randomly placed defects are coded such that there are no collisions in placements, as
introducing a defect in the same place twice would cancel each other out. Note that there is, in effect,
little difference between centre and random in PLCA and HHRBN; the random defects were introduced
to better compare between the substrates and kept throughout the experiments for PLCA and HHRBN
for consistency. All the TDP experiments use grid size of 100 cells (N = 100).
3.3. Defect collapse
We explore whether the systems tend to collapse into the same attractor after a defect is introduced.
This can happen in CA because the attractor basin is large enough to encompass the defect. However,
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
77
inPLCAandHHRBN,thiscanalsooccurduetotheneighbourhooditself,e.g.ifyouencodetheinforma-
tion into a node that is not the in-node of any other cell, the information can not propagate anywhere.
We inspect the substrate in two ways: via the Defect plots when all collapsed defects have been
excluded from the data in Subsection 4.3, and we look at the statistic of collapsing in Subsection 4.4.
3.4. Longest simple cycle
The difference between CA, PLCA, and HHRBN is essentially that of the topology. All the topologies
can be reduced to graphs, and therefore, it is natural to apply some graph theory, yet the graph theory
sub-field is broad, and the scope of this paper is already large. Therefore, we limit ourselves to finding
the longest simple cycle in the topology. The longest simple cycle is the longest cycle without any
repeating node (except the first and last). We picked this metric because it indicates how much infor-
mation can be encoded into the network, as any oscillating pattern in the substrate would be limited
by the longest simple cycle. Note that the longest simple cycle in CA would be equal to the number of
cells (N) due to its regular neighbourhood configuration. It is Therefore, it is not necessary to run this
analysis on CA.
3.5. Source code and dependencies
The source code for the project can be found at [101]. The code relies primarily on Evodynamics [102]
to run the ECA, PLCA and HHRBN and on scikit-learn [103] for the classification models. A more detailed
list of dependencies can be found in [101].
4. Results
In this section, we present the results of this paper in chronological order. Starting with the 5 bit mem-
ory benchmark experiments, then the TDP and collapse rate results, followed by the network analyse
and finally a extended 3 and 4 bit memory benchmark results are presented.
4.1. Life-like 5-bit memory benchmark
We begin with a smaller experiment between 2D outer totalistic CA (life-like CA) and HHRBN (note that
the concept of 2D breaks down in HHRBN). There are 218 = 262144 different rules in the ‘life-like’ rule
space (see Subsection 2.1.3). Therefore, an exhaustive search was not practical. A subset of interesting
behaving rules were selected from [100,104,105]. The results can be found in Table 5, and we see here
that many of the rules perform well in the CA case but not in the HHRBN case, except for B368/S12578.
We can quite clearly see from Figure 11(a,b) that the behaviour of said rule changes. It is important
to point out that there is a bias as these rules have been selected for their behaviour in a CA context.
Therefore one can not conclude about the greater scope of ECA, and HHRBN reservoirs, we can at
least say that the topology changes the behaviour. The CA results are better overall than in [100,104],
though not of a different scale, this might be explained by the difference in hyper-parameter or other
implementation detail of the ridge regression model as one was implemented in Julia and the other
in Python, we therefore still consider it a successful replication of the previous study.
4.2. ECA 5-bit memory benchmark
A similar exploration of the full ME set of ECA rules for ECA, PLCA, and HHRBN was also conducted.
The bias of selecting rules is removed by exploring the entire rule space. The rules have different ME
sets [16], but the ECA ME set is a super-set of the HHRBN ME set. Therefore, we use the ECA ME set
by default. In Figure 12, we see these results. There is a clear trend that general performance goes
down from CA to PLCA to HHRBN. In the perfect run metric, only three rules scored any perfect run for
 78
T. E. GLOVER ET AL.
Figure 11. B368/S12578 reservoir with Nb = 1 and Dp = 10. Reservoir is ﬂattened. We can still see some shadows and ﬂashes of
the same behaviour, but clearly, the CA and HHRBN behave diﬀerently. (a) CA and (b) HHRBN.
Table 5. Results from the replicated reservoir architecture of [100,104] with the addition of
Dynamic Life (B356/S23) [105].
CA
HHRBN
CA
HHRBN
CA
HHRBN
Model (R, I)
(24, 8)
(28, 8)
(30, 6)
B3/S23
2%
0%
100%
0%
91%
0%
B35/S236
72%
0%
100%
0%
100%
0%
B368/S12578
60%
48%
100%
100%
100%
100%
B356/S23
67%
0%
100%
0%
100%
0%
Notes: Cross-referenced with the RBN reservoir architecture. (R, I) where R is the reservoirwidth, and
I is both the length of the reservoir feature vector and the number of iterations between inputs.
HHRBN (108, 170, 204). We see a similar trend in the weighted average metric. Note that these rules
(108, 170, 204) are all ordered in behaviour and that rules 170 and 204 are equivalent in the HHRBN
ME set, meaning in effect, only 2 behaviours of the 46 unique HHRBN managed to solve the task. More
details and results can be found in [89].
4.3. Temporal derrida plots
In this subsection, we will present the TDP, all plots except Figure 17(a) have the collapsed runs
removed; the tally of the collapsed runs can be found later in Tables 6–8. They are separated because
thecollapsecangreatlyimpactthetemporalDerridaplots.Inshort,westillseethisimpactbyremoving
them and displaying them alone, but we can compare sensitivity independent of collapse rate.
We begin with an example of the ideal ‘chaotic’ ECA rule 30 in Figure 13(a). In ECA, we see as we
expect, the randomly placed defects to be quicker to permute the substrate. The central defects nat-
urally take longer to permute the substrate as they are limited by the CA’s ‘speed of light’ (in CA,
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
79
Figure 12. Breakdown of individual rule performance with 5-bit memory.
Table 6. ECA Rule collapse rate of individual rules.
defect
Rule 30
Rule 90
Rule 54
rule 110
rule 170
rule 184
1-bit c
0%
0%
2%
3%
0%
0%
5-bit c
0%
0%
2%
1%
0%
0%
9-bit c
0%
0%
2%
0%
0%
0%
5-bit r
0%
0%
0%
0%
0%
0%
9-bit r
0%
0%
0%
0%
0%
0%
Table 7. PLCA Rule collapse rate of individual rules.
defect
Rule 30
Rule 90
Rule 54
rule 110
rule 170
rule 184
1-bit c
33%
14%
1%
29%
91%
72%
5-bit c
0%
0%
0%
0%
62%
29%
9-bit c
0%
0%
0%
0%
41%
19%
5-bit r
0%
0%
0%
0%
56%
28%
9-bit r
0%
0%
0%
0%
41%
21%
Table 8. HHRBN Rule collapse rate of individual rules.
defect
Rule 30
Rule 90
Rule 54
rule 110
rule 170
rule 184
1-bit c
21%
21%
17%
21%
91%
59%
5-bit c
0%
0%
0%
0%
56%
29%
9-bit c
0%
0%
0%
0%
35%
26%
5-bit r
0%
0%
0%
0%
61%
31%
9-bit r
0%
0%
0%
0%
46%
21%
information can only flow to direct neighbouring cells at every step, creating a speed limit for infor-
mation often called the ‘speed of light’). For PLCA and HHRBN, much is the same, except the defects
permute the substrates faster. The CA ‘speed of light’ does not apply similarly to a random topology
of PLCA and HHRBN; the random topology creates a certain level of ‘small worldness’. We will dis-
cuss this further in Subsection 2.14 The defect configuration for many substrates settles towards the
same Dh of 50 (half-max distance), the normal average distance two random binary vectors would
have between each other. That they all settle at the same distance is also a test of sensitivity, as the
differences between configurations have expanded to the maximum probabilistic difference.
For rule 90, seen in Figure 13(b), it’s clear that the ECA behaviour is very different. The distance
might look erratic at first but is quite regular, and it is due to rule 90s additive behaviour. In rule 90
 80
T. E. GLOVER ET AL.
Figure 13. Rule (left) 30 displaying ideal ‘chaotic’ behaviour. Rule 90 (right) displays additive behaviour in CA and more ideal
‘chaotic’ behaviour in PLCA and HHRBN. (a) Rule 30 and (b) Rule 90.
and all the other additive ECA, the defects permute in a way that is invariant to the initial condition of
the different cells see [80, subsubsections: 2.1.2–3 and 5.5.5–6 ] for more detail. The PLCA and HHRBN
behave much closer to rule 30 and ‘chaotic’ behaviour.
However, reflecting on this, we hypothesise that this is due to every run having a random topology
rather than the regular Rule 90 behaviour somehow becoming ‘chaotic’ in PLCA and HHRBN. We also
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
81
Figure 14. Rule 110 and 54 displaying more complex behaviour in CA, and more sensitivity in PLCA and HHRBN. (a) Rule 54 and (b)
Rule 110.
see that the trajectories settle at roughly the same place but with a slightly higher amplitude in rule
90 than in rule 30, indicating a more significant variance.
Figure 14(a) shows one of the ‘complex’ rule 54. Its behaviour would seem to fit such a classification
as the defects permute the substrate but in a prolonged manner; even after 500 steps, it seems it has
not fully settled at a distance in some runs. Fitting with the edge of chaos theorem, this behaviour
 82
T. E. GLOVER ET AL.
Figure 15. Example of 200x200 rule 110 displaying an example of aether
matches expectations that its behaviour should not be trivial (ordered) and not quite chaotic. In PLCA,
the effect is closer to the chaotic behaviour, yet we can see that 1-bit defects settle at different distance
then the other defects. Though typically 1, bit defects are more likely to collapse, as this result excludes
runs that have collapsed, that is not the reason. As this does not happen in HHRBN, we hypothesise
this must have something to do with the computation of the central cell. It might be able to erect, at
the very least, a weak local barrier.
In Figure 14(b), we see another ‘complex’ rule 110 that, similarly to rule 54, takes long to saturate
the difference distance. In contrast to rule 54, rule 110 in the Ddl distance first grows but then shrinks
again. We hypothesise this is due to the feature of Rule 110 settling in large regions ‘aether’ as seen
in Figure 15. The aether in rule 110 is regions of regular small triangles, as the CA develops the more
likely they are to show up and the larger they will be. If two configurations of CA have large regions
of this aether, the configurations can be shifted to line up with each other. A shift operation is not
possible in simple Dh, but with Ddl, a shift can be constructed using a delete and insert operation. This
way, the Ddl can create a significantly shorter edit distance than the Dh. Rule 54 similarly has an aether,
but in contrast to rule 110, the aether areas are smaller and local in space. See [106] for an example.
Therefore, we don’t seem to see the same effect there. Similarly to Rule 54, we see a separation in PLCA
where 1-bit defects do not settle on the same distance.
In Figure 16(a), we see rule 170. For ECA, as we expect, the distance does not change in relation
to time. In Rule 170, every cell updates based on a copy of the left neighbour, which simply shifts the
previous configuration one step to the left every iteration. Therefore, a fixed distance is expected. The
small blips in the Ddl are caused by the defect hitting the CA boundary, making it less effective to use
the insert-delete shift method explained earlier in rule 110 to shorten the edit distance. In rule 170s
PLCA and HHRBN results, we see something unexpected. Firstly, there are different results between
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
83
Figure 16. Rule 170 and 184 displaying more ordered behaviour. (a) Rule 170 and (b) Rule 184.
PLCA and HHRBN, as rule 170 only computationally depends on its right neighbour (1 cell depen-
dant); there should be no difference. Secondly, there seems to be a separation between the random
and the central defects; thirdly, in HHRBN 9, 9-bit random is lower in distance than 5-bit random. This
can at least partly be explained with Tables 7 and 8. As there are many collapsed runs, the remaining
runs do not have as much statistical power, causing larger variance. This is further enforced by how
1-dependant rules are more vulnerable to imperfect topology.
 84
T. E. GLOVER ET AL.
Figure 17. TDTcomparingwithorwithoutcollapseoftherun.ThereisanoticeableincreaseinDh andDdl whenexcludingcollapsed
runs, especially with the 1-bit defect. (a) TDT including collapsed runs and (b) TDT excluding collapsed runs.
In Figure 16(b), we see rule 184. We see very ordered behaviour in ECA, though not quite as trivial
as Rule 170. Rule 184, similarly to rule 110, often forms large aether regions, so we see a shrinking Ddl
here. In PLCA and HHRBN, we see more dynamic behaviour, yet the distances do not settle at a half-
max distance. Interestingly rule 184 has a λ = 4
8 yet settle below half-max and rule 110 has a λ = 5
8
yet settle at roughly half-max. This decorrelation indicates that if it is useful for a rule to be balanced
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
85
in output, it is not sufficient for a rule to be balanced in the TT. Still, it also needs to be balanced at the
computational scale independently of its λ.
4.4. Collapse rate
We will begin with the collapse rate for the selection of rules in the previous section; these are found
in Tables 6–8.
We see that for these rules, there is almost no collapse in ECA, but for PLCA, 1-bit defects regularly
collapse except for Rule 54. In contrast, rules 170 and 184 have a large number of collapses. In the
case of rule 170, we will explain, in Subsection 4.5, how the rule dependency is one reason for the
high collapse rate. For the HHRBN, much is the same compared to PLCA, except for rule 54, which
has a higher collapse rate for 1-bit defects. In Figure 17(b), we see the TDP for the full ECA ME results
with and without collapsed runs included. Firstly, we can see that the additive rules, such as rule 90
and its frequencies, impact the data such that it is still visible in the total data consisting of all the 88
ME rules. We can also separate the different defect initialisations in inclusive and exclusive collapsed
runs. Similarly, in PLCA, we see a separation between the defect sizes but not the defect types (random,
central); this is as expected as they are functionally the same in PLCA and HHRBN substrates. In HHRBN,
excluding collapsed runs, we see something that looks mainly like sensitive behaviour, though it does
not settle at a roughly half-max distance. This might be due to how the ME set is derived because of
the complement transformation many of the later rules in the rule-set are excluded, and the later rules
have on average a higher λ, in fact, the average λ = 0.386. See Table 9 for why that is. Additionally, we
observed that a 1-bit defect has a slightly higher settling distance. Looking at many individual rules, a
few rules, such as rule 140, have this effect of a significantly higher average for the 1-bit difference.
Table 10 provides a comprehensive overview of the collapsed runs by substrate. The data reveals a
clear trend: the likelihood of collapse increases from ECA to PLCA to HHRBN and from more defects to
less. In Table 11, we see the same ECA data but grouped by dependencies. See Table 3 for details on
whichrulebelongswhere.FortheECA,wecan,withthesupportoftheory,understandtheresultsquite
reliably. 0-dependency always collapses as rule 0 (the only 0-dependency rule in the ME) always has
the same attractor of an entirely quiescent configuration (all cells become 0 state). For 1-dependency
(rule 15, 51, 170, 204), they will never collapse in ECA because they are all of a simple behaviour that
propagates the information without much (if any) transformation. Rules 170 and 204 are additive and
rules 15 and 51 are negative versions of additive rules. Negative transformation is simply changing the
output bit of the TT to the opposite (not to be confused with complement transformation). This trans-
formation leads to similar behaviour but is not typically considered part of the ME transformations. The
2-dependency rules are 3, 5, 10, 12, 34, 60, 90, 136, 160. For these rules, rules 136 and 160 dominate the
collapse rate as they always collapse. These rules are such that they always turn quiescent after a fixed
number of iterations. As is for rule 0, it is more accurate to describe it as all initial conditions collapse
rather than the defects collapse. In contrast, rules 60 and 90 should almost never collapse due to their
additive nature. However, some configurations will collapse for these rules, such as for specific grid
sizes [80, Subsubsecton 5.5.5]. Similarly, we can go through the 3-dependency rules, but for the sake
of brevity, we will not.
In PLCA and HHRBN, we expected a strong trend of lower dependency, meaning more collapse,
mainly due to network properties, which we discuss in Subsection 4.5. In Tables 12 and 13, we see
some trend towards more collapse the lower the dependency, but only if we ignore the 2-dependency
results. Except for 1-bit defects, 2-dependency has a higher collapse rate than 1-dependency in both
cases. One hypothesis is that because the rules in 1-dependency are all λ = 4
8 (balanced), this domi-
nates the dependency effect in 1-dependency rules, and all of the 2-dependency rules except rules 60
and 90 are λ = 2
8. This could be tested by grouping by λ.
In Tables 14–16 we do just this. Group our results by λ value of the TT. In this case, we see a clear
trend of the balance of the rule affecting the collapse rate. This λ value organise the collapse rate
 86
T. E. GLOVER ET AL.
Table 9. The ECA ME rules by λ.
Rule λ
Rules
λ = 0
8
0
λ = 1
8
1, 2, 4, 8, 32, 128
λ = 2
8
3, 5, 6, 9, 10, 12, 18, 24, 33, 34, 36, 40, 72, 130, 132, 136, 160
λ = 3
8
7, 11, 13, 14, 19, 22, 25, 26, 28, 35, 37, 38, 41, 42, 44, 50, 56,
73, 74, 76, 104, 134, 138, 140, 146, 152,162, 164, 168, 200
λ = 4
8
15, 23, 27, 29, 30, 43, 45, 46, 51, 54, 57, 58, 60, 77, 78, 90, 105,
106, 108, 142, 150, 154, 156, 170, 172, 178, 184, 204, 232
λ = 5
8
62, 94, 110, 122
λ = 6
8
126
λ = 7
8
λ = 8
8
Table 10. The number of times in the whole 8800 runs (100 runs for 88 rules)
per substrate rule population that collapsed.
init
ECA
PLCA
HHRBN
1 central
2450 (27.8%)
4722 (53.7%)
5253 (59.7%)
5 central
1352 (15.4%)
2338 (26.6%)
3328 (37.8%)
9 central
1123 (12.8%)
1918 (21.8%)
3049 (34.6%)
5 random
872 (9.9%)
2295 (26.1%)
3355 (38.1%)
9 random
828 (9.4%)
1919 (21.8%)
3043 (34.6%)
Table 11. Number of times the ECA rules diﬀerence died out grouped by
neighbour dependencies.
init.
0 dep.
1 dep.
2 dep.
3 dep.
1 central
100 (100.0%)
0 (0.0%)
315 (35.0%)
2035 (27.5%)
5 central
100 (100.0%)
0 (0.0%)
204 (22.7%)
1048 (14.2%)
9 central
100 (100.0%)
0 (0.0%)
200 (22.2%)
823 (11.1%)
5 random
100 (100.0%)
0 (0.0%)
200 (22.2%)
573 (7.7%)
9 random
100 (100.0%)
0 (0.0%)
200 (22.2%)
528 (7.1%)
Table 12. Number of times the PLCA rules diﬀerence died out grouped by neighbour dependen-
cies.
init.
0 dep.
1 dep.
2 dep.
3 dep.
1 central
100 (100.0%)
182 (45.5%)
626 (59.6%)
3814 (51.5%)
5 central
100 (100.0%)
112 (28.0%)
487 (54.1%)
1639 (22.1%)
9 central
100 (100.0%)
68 (17.0%)
424 (47.1%)
1326 (17.9%)
5 random
100 (100.0%)
104 (26.0%)
476 (52.9%)
1615 (21.8%)
9 random
100 (100.0%)
72 (18.0%)
414 (46.0%)
1333 (18.0%)
clearly, for all parameters the collapse rate grows when the λ is closer to the edge values 0 and 1. This
also gives some reason as to why the dependency value was not so neatly described.
4.5. Network topology, longest simple cycle
We can see from examples such as Figure 13(a) that the original ECA ‘speed of light’ is still there in
a sense also for PLCA and HHRBN, though vastly different. Defects can still only affect neighbouring
cells, but the pathways through the network that the defects can propagate are more small-world
than ECA. This is unsurprising as they are randomly generated in contrast to ECA. We want to create
a sense of how this affects the computations. We do this by finding a network’s longest simple cycle.
The longest simple cycle indicates the theoretical memory size that can be encoded into the network
and the substrate’s ability to retain a memory in the cycle.
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
87
Table 13. Number of times the HHRBN rules diﬀerence died out grouped by
neighbour dependencies.
init.
0 dep.
1 dep.
2 dep.
3 dep.
1 central
100 (100.0%)
354 (88.5%)
715 (79.4%)
4084 (55.2%)
5 central
100 (100.0%)
217 (54.3%)
618 (68.7%)
2393 (32.3%)
9 central
100 (100.0%)
152 (38.0%)
583 (64.8%)
2214 (29.9%)
5 random
100 (100.0%)
210 (52.5%)
621 (69.0%)
2424 (32.8%)
9 random
100 (100.0%)
151 (37.8%)
572 (63.5%)
2220 (30.0%)
Table 14. Number of times the ECA rules diﬀerence died out group by Lambda.
init.
λ = 0
8 ∨8
8
λ = 1
8 ∨7
8
λ = 2
8 ∨6
8
λ = 3
8 ∨5
8
λ = 4
8
1 central
100 (100.0%)
422 (70.3%)
655 (36.4%)
787 (23.1%)
486 (16.8%)
5 central
100 (100.0%)
342 (57.0%)
420 (23.3%)
337 (9.9%)
153 (5.3%)
9 central
100 (100.0%)
318 (53.0%)
378 (21.0%)
224 (6.6%)
103 (3.6%)
5 random
100 (100.0%)
307 (51.2%)
312 (17.3%)
131 (3.9%)
23 (0.8%)
9 random
100 (100.0%)
300 (50.0%)
302 (16.8%)
108 (3.2%)
18 (0.6%)
Table 15. Number of times the PLCA rules diﬀerence died out group by Lambda.
init.
λ = 0
8 ∨8
8
λ = 1
8 ∨7
8
λ = 2
8 ∨6
8
λ = 3
8 ∨5
8
λ = 4
8
1 central
100 (100.0%)
542 (90.3%)
1236 (68.7%)
1739 (51.1%)
1105 (38.1%)
5 central
100 (100.0%)
481 (80.2%)
783 (43.5%)
662 (19.5%)
312 (10.8%)
9 central
100 (100.0%)
463 (77.2%)
679 (37.7%)
489 (14.4%)
187 (6.4%)
5 random
100 (100.0%)
470 (78.3%)
777 (43.2%)
652 (19.2%)
296 (10.2%)
9 random
100 (100.0%)
459 (76.5%)
679 (37.7%)
494 (14.5%)
187 (6.4%)
Table 16. Number of times the HHRBN rules diﬀerence died out group by Lambda.
init.
λ = 0
8 ∨8
8
λ = 1
8 ∨7
8
λ = 2
8 ∨6
8
λ = 3
8 ∨5
8
λ = 4
8
1 central
100 (100.0%)
593 (98.8%)
1404 (78.0%)
1873 (55.1%)
1283 (44.2%)
5 central
100 (100.0%)
566 (94.3%)
1091 (60.6%)
1070 (31.5%)
501 (17.3%)
9 central
100 (100.0%)
562 (93.7%)
1026 (57.0%)
940 (27.6%)
421 (14.5%)
5 random
100 (100.0%)
576 (96.5%)
1096 (60.9%)
1064 (31.3%)
519 (17.9%)
9 random
100 (100.0%)
544 (90.7%)
1023 (56.8%)
950 (27.9%)
426 (14.7%)
We begin by considering a 1-dependency rule, such as rule 170. A ECA rule that depends only on 1
neighbour means by definition that 2 of the neighbours do not affect the computation. This effectively
reduces the in-degree from 3 to just 1. Though our collapse results do not show a clear trend based on
this dependency, we still argue that it must affect the computation because the network properties of
a 1-in-degree network are majorly different from a 3-in-degree network. The following evidence may
persuade the reader of this conclusion.
We take the first topology generated for rule 170 from the data in Figure 12 and only keep the nodes
that compute (the third in node neighbour). The network can be seen in Figures 18 and 19. We see that
there are 4 isolated subgraphs in this topology and very few and very short cycles. 63% of the networks
generated had at least one isolated subgraph. On average, the networks had 2.26 isolated subgraphs.
Note, that this means the example is skewed towards a more affected network, it still demonstrates
well the issues with the networks.
We made many networks with 1-in-degree for N (3 ...160) nodes and found the longest simple cycle
in these networks; see Figure 20. The computing cost of running this for 1-in-degree is trivial. There-
fore, we run this 10,000 per N. This data shows that the trend is asymptotic and that for N = 100, the
average longest simple cycle is about 8 and 10 for N = 160. For 2-in-degree networks, finding the val-
ues for 100 and 160 nodes is vastly different; the number of cycles in this graph grows quickly, and the
times to compute them were exponential. Therefore, we only computed for 3 to 50 nodes. Assuming
 88
T. E. GLOVER ET AL.
Figure 18. Tree graph visualisation of an example of a generated connection graph for Rule 170 PL CA. Showing four isolated
subgraphs and very few cycles.
this is asymptotic in the same manner as for 1-in-degree, we can fit a line to the data and know that
the true values for the longest simple cycle are below that line. This can be seen in Figure 21. From this
estimate, the longest simple cycle should be below 70 for N = 100 and below 110 for N = 160. This is
substantially larger than 1-in-degree, but still significantly below ECA, which the longest simple cycle
will always equal the number of cells(nodes). For 3-in-degree, see Figure 22. It is still below the max,
as for N = 100, it must be below 95 and for N = 160, it must be below 150. Note that this is a theo-
retical max, and assuming the data is asymptotic, the true value must be below this value. To be clear,
even if they are not asymptotic and simply linear, we still expect this to have some effect on the com-
putation. Also, note that we could have fitted these values to an asymptotic curve but opted not to.
This is because the asymptotic degree would greatly affect where the curve ends up even with minor
changes, and we do not know what it is for 2 and 3 degrees. Therefore, we opted for a theoretical max
with linear fitting of the form y = mx + b.
4.6. Sensitivity in the x-bit memory benchmark
As was established in [80], the 5-bit memory benchmark can be solved with a simple random vector
given sufficient dimensions. Therefore, it would be interesting to see if, as we compare CA, PLCA and
HHRBN, as the tasks become easier, more and more rules can solve this issue and whether that would
be true for HHRBN than for PLCA and PLCA compared to ECA. We expect HHRBN and PLCA to be more
sensitive, and we expect them to perform better on the 3 and 4-bit memory benchmarks. We see from
Figures 12, 23 and 24 that yes, more rules are capable of solving the easier tasks, but it is not entirely
clear that a more significant portion of the rule-space of HHRBN or PLCA is finding the task trivial. If
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
89
Figure 19. Circle graph visualisation of an example of a generated connection graph for Rule 170 PL CA. Showing four isolated
subgraphs.
Table 17. The Average and standard deviation performance over the rule-space in
percentage.
Nb
Substrate
W.avg
Perf. runs
5
ECA
47.42 ± 33.29
8.67 ± 24.72
5
PLCA
35.64 ± 27.60
2.89 ± 9.17
5
HHRBN
15.83 ± 16.65
0.15 ± 1.01
5
(ME) HHRBN
14.00 ± 15.90
0.20 ± 1.31
4
ECA
60.89 ± 35.42
27.40 ± 40.93
4
PLCA
59.11 ± 35.02
29.13 ± 42.58
4
HHRBN
63.30 ± 38.93
39.58 ± 45.70
4
(ME) HHRBN
60.01 ± 41.28
39.78 ± 46.03
3
ECA
67.16 ± 35.77
39.36 ± 41.96
3
PLCA
62.53 ± 35.12
32.81 ± 43.56
3
HHRBN
66.01 ± 38.24
49.78 ± 47.49
3
(ME) HHRBN
62.47 ± 40.93
48.87 ± 47.69
Notes: (ME) HHRBN is the average over only the HHRBN ME set (not the ECA ME set)
we view this through the average performance across the rule space, as seen in Table 17, there does
seem to be a degree of this behaviour, but there are clear exceptions such as 3-bit W.avg. The results
corroborate the previous presented topology effects for the longest simple cycle and collapse rate in
PLCA and HHRBN.
 90
T. E. GLOVER ET AL.
Figure 20. From samples of random graphs between 2 and 160 nodes with in-degree of 1. Every x value is the average of 10,000
random graphs. We ﬁt this data to a linear function using linear regression for the sake of comparison to Figures 21 and 22
5. Discussion
Thissectionfocusesondiscussingtheresultsand,howtheyrelatetoeachother,andhowtheyrelateto
the field in a larger context. We will also give a short account of how we would approach the problem
of a more natural definition of fully discrete chaos.
5.1. A complicated relationship between disordered topology and its computation
We see through the collapse rate that in random topologies, the collapse rate significantly increases in
PLCA and HHRBN, meaning random topology leads instead to more orderly computation. In contrast,
if we look at results that don’t collapse, we see a significant increase in sensitivity; we, in other words,
have conflicting computational ‘forces.’ If we look at our results that would be affected by both ‘forces,’
we still see a slight trend towards disorder. However, if we consider individual rules such as rule 30, we
would argue that as the collapse rate goes from 0% to 33% (PLCA) and 21% (HHRBN), this rule, on
average, becomes more orderly. Therefore, this relationship is complicated.
5.2. Implications for RBN and RBN reservoirs
Our HHRBN has the same topology as Classical RBN, so implications beyond HHRBN can be derived.
We demonstrated how different fixed in-degree networks should have a lower than max longest sim-
ple cycle. As RBN has random rules per node, the average dependency of RBN is slightly less than
three. Therefore, the degree of RBN is also, in practice, less than three. This means that when applied to
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
91
Figure 21. Predicted average length of the longest simple cycle using Simple linear regression ﬁtting. From samples of random
graphs between 2 and 50 nodes with in-degree of 2. Every x value is the average of 100 random graphs. Assuming the true function
is asymptotic as in Figure 20, the true value for the portion after the data should be somewhere below the ﬁtted line.
RBN, the results of the 3-in-degree random networks are, in practice, overestimates. It is likely already
overestimated as we fit a line to a (hypothesised) asymptotic function. Therefore, the RBN’s longest
simple cycle in practice should be even smaller. We also see a significant collapse rate even in the
most ‘chaotic’ rule (rule 30). The natural assumption would be to see similar effects when applied to
RBN. Therefore, we see many effects that reduce the sensitivity or disorderly nature of the computation
that we would also hypothesise to apply RBN.
5.3. Weaknesses of this study
Though this work is quite extensive, the work has some limitations. Due to computational constraints,
we limit ourselves to CA grid sizes of a specific size, and we know that CA can exhibit significant
behaviour changes on different grid sizes [80].
5.4. Size of the edge of chaos
In [107,108] several examples where introducing more heterogeneity extended the critical area. As
we introduce topological heterogeneity to our networks, it would be interesting to consider if we are
observing the same phenomenon of an increasing critical range. We begin by considering Wolfram’s
well-known ECA classification [23,109]; there are only 11/88 rules in the ‘chaotic’ class. We might also
argue that the additive rules 60, 90 and 150 should not be considered ‘chaotic,’ making the space even
smaller. Also, consider that there are only 4 complex rules, indicating that the ECA rule space is skewed
 92
T. E. GLOVER ET AL.
Figure 22. Predicted average length of the longest simple cycle using Simple linear regression ﬁtting. From samples of random
graphs between 3 and 30 nodes with in-degree of 3. Every x value is the average of 100 random graphs. Assuming the true function
is asymptotic as in Figure 20, the true value for the portion after the data should be somewhere below the ﬁtted line.
Figure 23. Breakdown of individual rule performance with 4-bit memory.
towards ordered behaviour. As we see a small indication that introducing heterogeneity moves the
space towards more sensitive ‘chaotic’ behaviour, we should also expect to see more rules exhibit crit-
ical behaviour. Nevertheless, the same evidence indicates the opposite of an extended criticality: a
shrinking criticality. If we go by the collapse rate, we can say that the region of ordered behaviour has
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
93
Figure 24. Breakdown of individual rule performance with 3-bit memory.
extended. If we control for the collapse rate, the remaining runs behave closer to sensitive ‘chaotic’
behaviour; this indicates a shrunk critical range. If we go by the 5-bit memory benchmark, we again
see signs of a shrunk criticality as very few runs managed to solve the benchmark. If we go by indi-
vidual rules, one can argue that rules 170 and 184 behaved closer to critical, though the collapse rate
is highly significant for these rules. As our experiments were not specifically designed to identify the
size of the critical area, we can not definitively conclude that our findings apply universally. A thor-
ough examination of all individual rules might yield a different conclusion. It would not be surprising
if heterogeneity could extend criticality. Still, the study of complexity often reveals that the relation-
ship between critical behaviour, substrates, and hyper-parameters is intricate and complex. This rather
indicates a rich field worthy of much study.
5.5. Implications for ReCA, ReRBN and intermediates
We can consider some implications for reservoir computing with CA, PLCA, and HHRBN reservoirs from
our results. If one considers the tool in practical terms, the ECA substrate seems superior as its regular
topology lends reliability to the implementation, but also the localised neighbourhood affords easier
implementation into FPGA, as the other substrates would naturally create more issues with the transfer
of information due to the placement of neighbours.
It is common practice in RC to have redundant mappings for encoding the input. As we observe
a higher collapse rate in PLCA and HHRBN, reservoir usage of these substrates will benefit more from
higher input redundancy than the ECA. Alternatively, one could more carefully select encoding place-
ment into the network as there are likely to be nodes that afford better distribution of the perturbation
than others.
5.6. A ‘discrete’ version of chaos
In this paper, we pointed out that the definition of chaos breaks down when applied to fully discrete
systems, i.e. systems intrinsically discrete in space and time and with a discrete number of accessible
states. The sensitivity on initial conditions required in the definition of chaotic function has a natural
analogy for discrete systems, but what about the concept of dense periodic orbits and topological
transitivity?
Here, we propose a definition of the meaning of a dense set of trajectories of a discrete system,
with some additional mathematical formalism. The set of accessible trajectories of a discrete system is
dense in the full phase space of possible configurations if, for each configuration in phase space, the
 94
T. E. GLOVER ET AL.
Figure 25. The contribution graph based on recommended categories from [110]. Contributions are based on degree of involve-
ment.
minimal Hamming distance, min (Dh) to an accessible trajectory converges to zero not slower than the
size N of the system:
lim
N→∞N min (Dh) = 1.
(1)
In practice, this definition can be read as
min (Dh) ∼1
N,
(2)
so graphically, plotting minimum Hamming distances as a function of the inverse of the system’s size
should hold a line with a unitary slope. If we consider the orbit, the natural analogy is the attractor in
binary systems, A cyclic trajectory that the deterministic discrete system must eventually converge to.
Therefore, we conclude that a natural analogy for a dense periodic orbit is a long attractor that period-
ically expands and contracts the Dh between previous states without finding the exact previous state.
Expanding and contracting are important because a long attractor does not necessarily mean chaos.
Consider the example of a binary vector that does iterative counting upwards by 1. This would have
full coverage over the state space and the longest possible attractor, but it should not be considered
chaotic behaviour.
As for the topological transitivity, it is similarly defined in continuous space [45, subsection 1.8]: an
iterative map f : J →J is said to be topological transitivity if, for any pair of non-empty sets U, V ⊂J,
there exists k ≥0 such that f k(U) ∩V ̸= ∅. In other words, it still implies that a system can not be
decomposedintotwosubsystems.Italsomeansthatitmustbepossiblefromagivenstatetotransition
to any other state in the system. This condition is again reflected in the attractor, where there should
be only one possible attractor in the system. The presence of two separate attractors would imply that
the system can be decomposed, contradicting the notion of topological transitivity.
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
95
6. Conclusion
This work investigated computational differences between ECA, PLCA, and HHRBN. It explores what
happens with the simplest computational universe when introducing topological heterogeneity. We
investigated using a simple 5-bit memory benchmark, sensitivity metric and collapse rate of the dif-
ferent substrates. We see how, in PLCA and HHRBN, performance on the 5-bit memory benchmark is
substantially worse. That collapse rate increases substantially, which counterintuitively means that a
more disordered topology can sometimes mean more ordered computation. In general, we see a weak
sign of increased sensitivity, and if the collapse rate is controlled for, we see a strong sign of increased
sensitivity. This indicates that we are observing a shrinking critical range. We see evidence consistent
with the previous observations when we make the 5-bit memory benchmark easier by solving a 4 and
3-bit memory benchmark. Our results conclude that ECA is, at least with current hardware, the better
reservoir for edge AI. We also try to address the issue of ‘chaos’ in a fully discrete system and attempt
to define a condition for the natural analogy.
7. Future work
Many future work projects can naturally extend this work. As we identified in the intro (Figure 1), there
are many steps between ECA and BBN, which can be explored. Additionally, there are different paths
between ECA and BNN, so other orders of steps could be explored. For example, would we get the
same results if we introduce other forms of heterogeneity, such as mixed-rule CA? Furthermore, our
networks have a random topology beyond what is typically true in most biological systems. It would be
interesting to see how the regular topology (ECA) and the irregular topology (HHRBN) perform when
compared to evolved networks such as the connectome of a C. elegans. Alternatively, if we explore
networks with increasing locality of connections, this might even be a suitable control parameter for
reservoir quality.
8. Contributions
A contribution graph based on the CRediT author statement 110, can be seen in Figure 25.
Disclosure statement
No potential conflict of interest was reported by the author(s).
Funding
This work was partially financed by the Research Council of Norway’s DeepCA project, grant agreement 286558.
References
[1] Strubell E, Ganesh A, McCallum A. Energy and policy considerations for deep learning in NLP. arXiv preprint
arXiv:1906.02243. 2019.
[2] Luccioni AS, Jernite Y, Strubell E. Power hungry processing: watts driving the cost of ai deployment? arXiv preprint
arXiv:2311.16863. 2023.
[3] von Neumann J. Theory of self-reproducing automata. Math Comput. 1966;21:745.
[4] Howard N. Energy paradox of the brain. Brain Sci. 2012;1:35.
[5] Mitchell M. Complexity: a guided tour. New York, NY: Oxford University Press; 2009.
[6] Kauffman SA. Metabolic stability and epigenesis in randomly constructed genetic nets.
J Theor Biol. 1969
Mar;22(3):437–467. doi: 10.1016/0022-5193(69)90015-0
[7] Chan BW-C. Lenia: biology of artificial life. Complex Syst. 2019;28(3):251–286. doi: 10.25088/ComplexSystems
[8] Mordvintsev A, Randazzo E, Niklasson E, et al. Growing neural cellular automata. Distill. 2020;5. 10.23915/distill.
00023.
[9] Vohradsky J. Neural network model of gene expression. FASEB J. 2001;15(3):846–854. doi: 10.1096/fsb2.v15.3
[10] Ribeiro A, Zhu R, Kauffman SA. A general modeling strategy for gene regulatory networks with stochastic dynamics.
J Comput Biol. 2006;13(9):1630–1639. doi: 10.1089/cmb.2006.13.1630
 96
T. E. GLOVER ET AL.
[11] Elowitz MB, Levine AJ, Siggia ED, et al. Stochastic gene expression in a single cell. Science. 2002;297(5584):1183–
1186. doi: 10.1126/science.1070919
[12] Orchard G, Frady EP, Rubin DBD, et al. Efficient neuromorphic signal processing with loihi 2. In: 2021 IEEE Workshop
on Signal Processing Systems (SiPS). IEEE; 2021. p. 254–259.
[13] Mitchell M. Life and evolution in computers. Hist Philos Life Sci. 2001;23(3/4):361–383.
[14] Cook M. Universality in elementary cellular automata. Complex Syst. 2004;15(1):1–40.
[15] Hudcová B, Mikolov T. Computational hierarchy of elementary cellular automata. In: ALIFE 2021: The 2021 Confer-
ence on Artificial Life. MIT Press; 2021. doi: 10.1162/isal_a_00447
[16] Glover TE, Jahren R, Huse Ramstad O, et al. Minimum equivalence in random boolean networks, elementary cellular
automata, and beyond. In: Artificial Life Conference Proceedings 35. Cambridge, MA: MIT Press; One Rogers Street,
02142-1209, USA journals-info ..., 2023.
[17] Gardner M. The fantastic combinations of john conway’s new solitaire game “life”. Sci Am. 1970;223:120–123. doi:
10.1038/scientificamerican1070-120
[18] Rendell P. A universal turing machine in conway’s game of life. In: 2011 International Conference on High
Performance Computing & Simulation. IEEE; 2011. p. 764–772.
[19] The Life Lexicon. Life-like cellular automata. 2024. [accessed 2024 February 23]. Available from: https://conwaylife.
com/wiki/Cellular_automaton#Life-like_cellular_automata.
[20] Eppstein D. Growth and Decay in Life–Like Cellular Automata. Game of Life Cellular Automata. London: Springer;
2010. p. 71–97.
[21] Gershenson C. Classification of random boolean networks. arXiv preprint cs/0208001. 2002.
[22] Kauffman SA. Cellular homeostasis, epigenesis and replication in randomly aggregated macromolecular systems.
J Cybern. 1971;1(1):71–96. doi: 10.1080/01969727108545830
[23] Martinez GJ. A note on elementary cellular automata classification. arXiv preprint arXiv:1306.5577. 2013.
[24] Kauffman SA. The origins of order: self-organization and selection in evolution. Oxford: Oxford University Press;
1993.
[25] Kauffman SA. Requirements for evolvability in complex systems: orderly dynamics and frozen components. Phys D
Nonlinear Phenom. 1990;42(1-3):135–152. doi: 10.1016/0167-2789(90)90071-V
[26] Langton CG. Computation at the edge of chaos: phase transitions and emergent computation. Phys D Nonlinear
Phenom. 1990;42(1-3):12–37. doi: 10.1016/0167-2789(90)90064-V
[27] WuenscheA,LesserM.Globaldynamicsofcellularautomata:anatlasofbasinofattractionfieldsofone-dimensional
cellular automata. Vol. 1. Boca Raton, FL: CRC Press; 1992.
[28] Wuensche A. Basin of attraction fields of disordered cellular automata networks. 1992. Available from:
http://www.ddlab.com/publications.html.
[29] Wuensche A. The Ghost in the Machine: Basins of Attraction of Random Boolean NetworksIn Artificial Life III Vol.
XVII. Boston: Addison-Wesley; 1994.
[30] Wuensche A. 1997. Attractor basins of discrete networks Cognitive Science Research Paper 461, Doctoral Disserta-
tion, University of Sussex.
[31] LiW.Phenomenologyofnonlocalcellularautomata. JStatPhys.1992Sept;68(5):829–882.doi:10.1007/BF01048877
[32] Walker CC. A study of a family of complex systems–an approach to the investigation of organisms’ behavior [Ph.D.].
University of Illinois at Urbana-Champaign, United States – Illinois, 1965. URL https://www.proquest.com/docview/
302133130/citation/38D4271784FF4B1EPQ/1.
[33] Walker CC. Behavior of a class of complex systems: the effect of system size on properties of terminal cycles. J
Cybern. 1971 Jan;1(4):55–67. doi: 10.1080/01969727108542902
[34] Walker CC, Ashby WR. On temporal characteristics of behavior in certain complex systems. Kybernetik. 1966
May;3(2):100–108. doi: 10.1007/BF00299903
[35] Marr C, Hütt M-T. Outer-totalistic cellular automata on graphs. Phys Lett A. 2009;373(5):546–549. doi: 10.1016/j.phy
sleta.2008.12.013
[36] Grattarola D, Livi L, Alippi C. Learning graph cellular automata. Adv Neural Inf Process Syst. 2021;34:20983–20994.
[37] Bhattacharjee K, Naskar N, Roy S, et al. A survey of cellular automata: types, dynamics, non-uniformity and
applications. Nat Comput. 2020;19:433–461. doi: 10.1007/s11047-018-9696-8
[38] Cattaneo G, Dennunzio A, Formenti E, et al. Non-uniform cellular automata. In: Language and Automata Theory and
Applications: Third International Conference, LATA 2009, Tarragona, Spain, April 2-8, 2009. Proceedings 3. Springer;
2009. p. 302–313.
[39] Wolfram S. Theory and applications of cellular automata. Singapore: World Scientific; 1986.
[40] Wolfram S. Tables of cellular automaton properties. Singapore: World Scientific; 1986
[41] Li W, Packard N. The structure of the elementary cellular automata rule space. Complex Systems. 1990;4(3):281–297.
[42] Wolfram Research. Wolfram atlas of the dependancies of neighbours for ECA. 2024. [accessed 2024 February 8].
Available from: https://atlas.wolfram.com/01/01/views/177/TableView.html.
[43] Kolesov AY, Rozov NK. On the definition of’chaos’. Russ Math Surv. 2009;64(4):701. doi: 10.1070/RM2009v064n04
ABEH004631
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
97
[44] Touhey P. Yet another definition of chaos. Am Math Mon. 1997;104(5):411–414. doi: 10.1080/00029890.1997.1199
0658
[45] Devaney R. An introduction to chaotic dynamical systems. 3rd ed. Boca Raton, FL: CRC Press; 2022.
[46] Banks J, Brooks J, Cairns G, et al. On devaney’s definition of chaos. Am Math Mon. 1992;99(4):332–334. doi:
10.1080/00029890.1992.11995856
[47] Pope SB. Turbulent flows. Cambridge: Cambride University Press; 2000.
[48] Lorenz EN. Deterministic nonperiodic flow. J Atmos Sci. 1963;20(2):130–141. doi: 10.1175/1520-0469(1963)020¡
0130:DNF¿2.0.CO;2
[49] Elaydi SN. Discrete chaos: with applications in science and engineering. Boca Raton, FL: Chapman and Hall/CRC;
2007.
[50] Kaneko K, Tsuda I. Complex systems: chaos and beyond: chaos and beyond: A constructive approach with
applications in life sciences. Berlin, Germany: Springer Science & Business Media; 2001.
[51] May RM. Simple mathematical models with very complicated dynamics. Nature. 1976;261(5560):459–467. doi:
10.1038/261459a0
[52] Wolfram S, Gad-el Hak M. A new kind of science. Appl Mech Rev. 2003;56(2):B18–B19. doi: 10.1115/1.1553433
[53] Cattaneo G, Formenti E, Manzini G, et al. Ergodicity, transitivity, and regularity for linear cellular automata over zm.
Theor Comput Sci. 2000;233(1-2):147–164. doi: 10.1016/S0304-3975(98)00005-X
[54] Manzini G, Margara L. A complete and efficiently computable topological classification of d-dimensional linear
cellular automata over zm. Theor Comput Sci. 1999;221(1-2):157–177. doi: 10.1016/S0304-3975(99)00031-6
[55] ShannonCE.Amathematicaltheoryofcryptography.1945.Availablefrom:https://www.iacr.org/museum/shannon
45.html
[56] Bhattacharjee K, Paul D, Das S. Pseudo-random number generation using a 3-state cellular automaton. Int J Modern
Phys C. 2017;28(06):1750078.
[57] Jaeger H. The “echo state” approach to analysing and training recurrent neural networks-with an erratum note.
Bonn Germany: Ger Nat Res Center Inf Technol GMD Tech Rep. 2001;148(34):13.
[58] Maass W, Natschläger T, Markram H. Real-time computing without stable states: A new framework for neural
computation based on perturbations. Neural Comput. 2002;14(11):2531–2560. doi: 10.1162/089976602760407955
[59] Tanaka G, Yamane T, Héroux JB, et al. Recent advances in physical reservoir computing: a review. Neural Netw.
2019;115:100–123. doi: 10.1016/j.neunet.2019.03.005
[60] Gallicchio C, Micheli A. Deep reservoir computing: A critical analysis. In: Proceedings of the 24th European
Symposium on Artificial Neural Networks (ESANN), Bruges, Belgium; 27–29 April 2016. p. 497–502.
[61] Fernando C, Sojakka S. Pattern recognition in a bucket. In: European Conference on Artificial Life. Springer; 2003. p.
588–597.
[62] Aaser P, Knudsen M, Ramstad OH, et al. Towards making a cyborg: a closed-loop reservoir-neuro system. In: Artificial
Life Conference Proceedings 14. MIT Press; 2017. p. 430–437.
[63] Nikolic D, Haeusler S, Singer W, et al. Temporal dynamics of information content carried by neurons in the primary
visual cortex. In: Proc. of NIPS 2006, Advances in Neural Information Processing Systems, volume 19. MIT Press; 2007.
p. 1041–1048.
[64] Dai X. Genetic regulatory systems modeled by recurrent neural network. In: International Symposium on Neural
Networks. Springer; 2004. p. 519–524.
[65] Jones B, Stekel D, Rowe J, et al. Is there a liquid state machine in the bacterium escherichia coli? In: 2007 IEEE
Symposium on Artificial Life. IEEE; 2007. p. 187–191.
[66] Jaeger H. Echo state network. Scholarpedia. 2007;2(9):2330. doi: 10.4249/scholarpedia.2330. revision #196567
[67] Grigoryeva L, Ortega J-P. Echo state networks are universal. Neural Netw. 2018;108:495–508. doi: 10.1016/j.neunet.
2018.08.025
[68] Yilmaz O. Reservoir computing using cellular automata. arXiv preprint arXiv:1410.0162. 2014.
[69] Wolfram Research. Wolfram atlas of the boolean form of ECA. 2024. [accessed 2024 June 19]. Available from:
https://atlas.wolfram.com/01/01/views/172/TableView.html.
[70] MoránA,FrasserCF,RocaM,etal.Energy-efficientpatternrecognitionhardwarewithelementarycellularautomata.
IEEE Trans Comput. 2019;69(3):392–401.
[71] Olin-Ammentorp W, Beckmann K, Cady NC. Cellular memristive-output reservoir (CMOR). arXiv preprint
arXiv:1906.06414, 2019.
[72] LiangD,HashimotoM,AwanoH.Bloomca:amemoryefficientreservoircomputinghardwareimplementationusing
cellular automata and ensemble bloom filter. In: 2021 Design, Automation & Test in Europe Conference & Exhibition
(DATE). IEEE; 2021. p. 587–590.
[73] Nichele S, Molund A. Deep learning with cellular automaton-based reservoir computing. Compl Syst. 2017;26(4):
319–339. doi: 10.25088/ComplexSystems
[74] Nichele S, Gundersen MS. Reservoir computing using non-uniform binary cellular automata. arXiv preprint
arXiv:1702.03812. 2017.
[75] Margem M, Gedik OS. Reservoir computing based on cellular automata (RECA) in sequence learning. Journal of
Cellular Automata. 2019;14(1-2):153–170.
 98
T. E. GLOVER ET AL.
[76] Babson N, Teuscher C. Reservoir computing with complex cellular automata. Compl Syst. 2019;28(4):433–455. doi:
10.25088/ComplexSystems
[77] Uragami D, Gunji Y-P. Universal criticality in reservoir computing using asynchronous cellular automata. Compl
Syst. 2022;31(1):103–121.
[78] Margem M, Gedik OS. Feed-forward versus recurrent architecture and local versus cellular automata distributed
representation in reservoir computing for sequence memory learning. Artif Intell Rev. 2020;53(7):5083–5112. doi:
10.1007/s10462-020-09815-8
[79] GloverTE,LindP,YazidiA,etal.Thedynamicallandscapeofreservoircomputingwithelementarycellularautomata.
In: ALIFE 2021: The 2021 Conference on Artificial Life. MIT Press; 2021.
[80] Glover TE, Lind P, Yazidi A, et al. Investigating rules and parameters of reservoir computing with elementary cellular
automata, with a criticism of rule 90 and the five-bit memory benchmark. Compl Syst. 2023;32(3):309–351.
[81] Glover T, Osipov E, Nichele S. On when is reservoir computing with cellular automata beneficial? arXiv preprint
arXiv:2407.09501. 2024.
[82] McDonald N. Reservoir computing & extreme learning machines using pairs of cellular automata rules. In: 2017
International Joint Conference on Neural Networks (IJCNN). IEEE; 2017. p. 2429–2436.
[83] Kantic J, Legl FC, Stechele W, et al. Relicada: reservoir computing using linear cellular automata design algorithm.
Compl Intell Syst. 2024;10(3):3593–3616.
[84] Snyder D, Goudarzi A, Teuscher C. Finding optimal random boolean networks for reservoir computing. In: Artificial
Life Conference Proceedings. Citeseer; 2012. p. 259–266.
[85] Snyder D, Goudarzi A, Teuscher C. Computational capabilities of random automata networks for reservoir comput-
ing. Phys Rev E. 2013;87(4):042808. doi: 10.1103/PhysRevE.87.042808
[86] Burkow AV. Evolving functionally equivalent reservoirs for rbn reservoir computing systems. Orwegian University
of Science and Technology (NTNU). 2015. (Technical report).
[87] Burkow AV. Exploring physical reservoir computing using random boolean networks [Master’s thesis]. NTNU; 2016.
[88] Calvet E, Reulet B, Rouat J. The connectivity degree controls the difficulty in reservoir design of random boolean
networks. Front Comput Neurosci. 2024;18:1348138. doi: 10.3389/fncom.2024.1348138
[89] Jahren R. Comparison and benchmarking of reservoir computing using cellular automata and random Boolean
networks as substrates [Master’s thesis]. OsloMet-storbyuniversitetet; 2022.
[90] Johansson O. Text classification with cellular automata networks [Master’s thesis]. Chalmers University of Technol-
ogy; 2024.
[91] Hochreiter S, Schmidhuber J. Long short-term memory. Neural Comput. 1997;9(8):1735–1780. doi: 10.1162/neco.
1997.9.8.1735
[92] Martens J, Sutskever I. Learning recurrent neural networks with Hessian-free optimization. In: Proceedings of the
28th International Conference on Machine Learning (ICML). Bellevue, Washington, USA; 2011. p.1033–1040.
[93] Sutskever I. Training recurrent neural networks. Toronto (ON): University of Toronto; 2013.
[94] Jaeger H. Long short-term memory in echo state networks: details of a simulation study. Jacobs University Bremen;
2012. (Technical report).
[95] Watts DJ, Strogatz SH. Collective dynamics of ‘small-world’networks. Nature. 1998;393(6684):440–442. doi:
10.1038/30918
[96] Derrida B, Weisbuch G. Evolution of overlaps between configurations in random boolean networks. J Phys.
1986;47(8):1297–1303. doi: 10.1051/jphys:019860047080129700
[97] Fretter C, Szejka A, Drossel B. Perturbation propagation in random and evolved boolean networks. New J Phys.
2009;11(3):033005. doi: 10.1088/1367-2630/11/3/033005
[98] Wuensche A. Exploring discrete dynamics. Bristol, England: Luniver Press; 2011.
[99] Adamatzky A, Wuensche A. On creativity and elementary cellular automata. Compl Syst. 2013;22(4):361–375.
[100] Martinuzzi F. Reservoir computing with two dimensional cellular automata. 2020. [accessed 2024 June 26].
https://martinuzzifrancesco.github.io/posts/08_gsoc_week/.
[101] GloverTE,JahrenR.linkforsourcecodeandresults,2024Jul.https://osf.io/stxd7/?view_only = 0a637000ced0453eb
78ef2f2365701a0.
[102] Pontes-Filho S, Lind P, Yazidi A, et al. Evodynamic: a framework for the evolution of generally represented dynamical
systems and its application to self-organized criticality. EasyChair; 2019. (Technical report).
[103] Pedregosa F, Varoquaux G, Gramfort A, et al. Scikit-learn: machine learning in python. J Mach Learn Res.
2011;12:2825–2830.
[104] Martinuzzi F. Life-like cellular automata as a substrate for computation. Early access to a pre-print version of the
paper. 2022.
[105] Peña E, Sayama H. Life worth mentioning: complexity in life-like cellular automata. Artif Life. 2021;27(2):105–112.
doi: 10.1162/artl_a_00348
[106] Research W. Wolfram atlas example of rule 54. 2024. [accessed 2024 June 24]. Available from: https://atlas.wolfram.
com/01/01/54/01_01_22_54.gif.
[107] Sánchez-Puig F, Zapata O, Pineda OK, et al. Heterogeneity extends criticality. arXiv preprint arXiv:2208.06439. 2022.
 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS
99
[108] Jafet López-Díaz A, Sánchez-Puig F, Gershenson C. Temporal, structural, and functional heterogeneities extend
criticality and antifragility in random boolean networks. Entropy. 2023;25(2):254. doi: 10.3390/e25020254
[109] Wolfram S. Universality and complexity in cellular automata. Phys D Nonlinear Phenom. 1984;10(1-2):1–35. doi:
10.1016/0167-2789(84)90245-8
[110] Credit author statement. 2024. [accessed 2024 July 3]. https://www.elsevier.com/researcher/author/policies-and-
guidelines/credit-author-statement.
",10.1080/17445760.2024.2396334,doc34,"Elementary Cellular Automata (ECA) are well-studied computational uni-
verses capable of impressive computational variety, but harnessing their
potential has been challenging. When combined with Reservoir Comput-
ing (RC), harnessing this computation becomes feasible, and furthermore
enables energy efficient AI. This study compares ECA reservoirs to topolog-
ical heterogeneous and more biological plausible counterparts of Partially-
Local CA (PLCA) and Homogeneous Homogeneous Random Boolean Net-
works (HHRBN). Using the 5-bit memory benchmark, Temporal Derrida
plots and collapse rate, finding are that more disordered topology does
not equate to more disordered computation and moreover the evidence
suggest this heterogeneity shrinks the critical range.
ARTICLE HISTORY
Received 12 August 2024
Accepted 21 August 2024","International Journal of Parallel, Emergent and Distributed Systems (Online) Journal homepage: A sensitivity analysis of cellular automata and heterogeneous topology networks: partially-local cellular automata and homogeneous homogeneous random boolean networks Tom Eivind Glover, Ruben Jahren, Francesco Martinuzzi, Pedro Gonçalves Lind & Stefano Nichele To cite this article: Tom Eivind Glover, Ruben Jahren, Francesco Martinuzzi, Pedro Gonçalves Lind & Stefano Nichele A sensitivity analysis of cellular automata and heterogeneous topology networks: partially-local cellular automata and homogeneous homogeneous random boolean networks, International Journal of Parallel, Emergent and Distributed Systems, 40:1, 59-99, DOI: 10.1080/17445760.2024.2396334 To link to this article: © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group. Published online: 02 Sep 2024. Submit your article to this journal Article views: 474 View related articles View Crossmark data Full Terms & Conditions of access and use can be found at INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 2025, VOL. 40, NO. 1, 59–99 A sensitivity analysis of cellular automata and heterogeneous topology networks: partially-local cellular automata and homogeneous homogeneous random boolean networks Tom Eivind Glovera, Ruben Jahrena, Francesco Martinuzzib,c,d, Pedro Gonçalves Linda,e and Stefano Nichelea,f aDepartment of Computer Science, OsloMet – Oslo Metropolitan University, Oslo, Norway; bCenter for Scalable Data Analytics and Artiﬁcial Intelligence, Leipzig University, Leipzig, Germany; cInstitute for Earth System Science & Remote Sensing, Leipzig University, Leipzig, Germany; dRemote Sensing Centre for Earth System Research, Leipzig University, Leipzig, Germany; eNumerical Analysis and Scientiﬁc Computing, Simula Research Laboratory, Oslo, Norway; fDepartment of Computer Science and Communication, Østfold University College, Halden, Norway ABSTRACT KEYWORDS Reservoir computing; cellular automata; ReCA; sensitivity; chaos CONTACT Tom Eivind Glover tomglove@oslomet.no OsloMet – Oslo Metropolitan University, P.O. Box 4, St. Olavs plass N-0130, Oslo, Norway © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group. This is an Open Access article distributed under the terms of the Creative Commons Attribution License ( which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. The terms on which this article has been published allow the posting of the Accepted Manuscript in a repository by the author(s) or with their consent. 60 T. E. GLOVER ET AL. 1. Introduction Standard Artificial Intelligence (AI) approaches rely on high-performance computing such as with cloud or cluster computing. However, these are very energy-intensive resources, and many popular models are energy-intensive in training [1] and inference [2]. Conversely, biological intelligence has made highly energy-effective solutions, e.g. the brain. Despite operating under conditions such as increased decentralisation, asynchronisation, and slower signal propagation, biological intelligence has achieved highly energy-efficient solutions, with the human brain operating at approximately 25–30 watts [3,4]. These observations indicate that there is still much to learn and gain from studying biological intelligence. In this work, we focus on unconventional computational models, such as Cellular Automata (CA) or Random Boolean Networks (RBN), which utilise Boolean logic between local cells (nodes). This reliance on Boolean logic enables easy hardware implementation, as the operations can be implemented in cir- cuitry or an FPGA, allowing energy-efficient inference of the model. It is possible to create an abstract pathway from CA to Biological Neural Networks (BNN); one example can be seen in Figure 1, and this pathway would require many steps. CA is a special case of RBN where the neighbour connections are entirely regular, and every cell has the same activation function. Viewed from the other direction, RBN is a CA with random neighbourhood and random rules per cell (node). RBN is a well-known simple biological model of the Gene regulatory network [5,6], which is an intelligence- and computational space used for solving, among other things, morphological problems. Though there are multiple dis- crete steps between CA and RBN, as can be seen in Figure 1, we limit ourselves to exploring substrates between CA and Homogeneous Homogeneous RBN (HHRBN); these are the substrates that have the same rule (Homogeneous) in every cell. Essentially, we compare homogeneous topology networks to heterogeneous topology networks. Note that many of the modern directions of these CA and RBN computational models are mov- ing into the continuous domain, such as for CA, the continuous models of Lenia [7] and Neural CA [8] are having much success modelling biological processes and biological like behaviours. Similarly, Random Boolean Networks (RBN) are moving into the continuous domain, such as continuous RBN [9] or stochastic RBN [10,11], and they are argued to be more biologically plausible models. Although we want to encourage these explorations and essential directions, relying on the continuous domain currently means either running on specialised hardware or taking an energy efficiency loss, as floating point calculations are much more costly than integer or, even further, binary calculations. The future Figure 1. There is a big diﬀerence between CA and BNN. The diﬀerence can be viewed as a series of discrete steps between sub- strates, but even between RBN and CA, there are many discrete steps. This ﬁgure illustrates the diﬀerent substrates as a direct path, but note that the steps from CA to RBN could have been done diﬀerently than illustrated. Also note, that this is a simpliﬁed imperfect model of the substrate space between ECA and BNN. INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 61 is still being determined, but when it comes to specialised hardware like neuromorphic chips [12], they are not expected to replace traditional hardware. Unless there is a significant breakthrough, spe- cialised hardware like neuromorphic chips or quantum computing will likely exist alongside and in cooperation with conventional computational systems. Therefore, the energy-efficient binary models are still worth developing. In this work, we stay within the binary domain for energy efficiency. We explore and compare three binary models for computation, namely CA and models intermediate to RBN (PLCA, HHRBN). We do this mainly to understand them as computational models better. Firstly, We combine them with Reser- voir Computing (RC), an energy-efficient ‘substrate-independent’ training method. The combination can potentially be an energy-efficient model in training and inference. We run these models on a sim- ple 5-bit memory benchmark and find that ECA generally performs better. We follow up by measuring the sensitivity (a necessary but not sufficient condition of chaos) of the networks using a Temporal Der- rida plot. We find that, in general, HHRBN and PLCA slightly increase the sensitivity. Yet, by analysing the defect collapse rate, we find that the substrates as a whole also skew towards ordered behaviour as there are mitigating circumstances like how the random topology leads to imperfect connectiv- ity that leads to a stronger attractor. This signifies that we observe a shrinking critical range in PLCA and HHRBN. Though HHRBN are disordered in the topology, the behaviour of the network from these effects is not as disordered as it might be natural to assume. This means counter-intuitively that regular connections can more reliably reach a higher level of disorder. 2. Background and related work Inthissection,wewilldetailthebackground,relatedwork,andtheoryrelevanttothispaper.Thispaper connects many fields, uses several substrates, and relies on several empirical and theoretical methods. This has made this section necessarily extensive to provide a comprehensive overview. In general this sections begins by explaining the different substrates, followed by more theoretical overview of said substrates as well as relevant concepts. Finally, the relevant related work is presented. 2.1. Cellular automata Cellular Automata (CA) are a simple model consisting of a grid of cells possessing a limited set of k dis- crete states placed on a uniformly connected grid, typically in 1 or 2 dimensions. The cell state changes iteratively, depending on the state of the neighbours. Which neighbour state combination results in which next state is determined by a lookup table, typically called the Transition Table (TT). CA was first used to study self-replication by John von Neumann in 1940 but published in 1966 [3]. It can be considered an idealised system for parallel and decentralised computation [13]. 2.1.1. Elementary cellular automata (ECA) Elementary Cellular automata (ECA) is a subset of CA in 1-dimension, binary states (S = 2) and 3 neigh- bours (K = 3) (left, right and centre). Therefore, ECA only has SSK = 223 = 256 possible rules, and the whole set of these is often named the rule-space. It is a convention to name individual rules in a rule-space after the output states of the TT Binary = Decimal. CA is deterministic, and the rule, together with the initial condition, leads the CA into a set of subsequent states called the trajectory. An example of rule 90 can be seen in Figure 2. Rule 110 has even been shown to be compu- tationally universal [14], but one can question whether that is a useful definition of computation for a parallel and distributed computational substrate [15]. 2.1.2. Two dimensional CA (2D CA) Beyond ECA are many other types of CA, such as 2-dimensional CA, where instead of configuring the cells in a 1-dimensional line, they are now configured as a 2D surface. In 2D CA, the most typical neighbourhood scheme is one of two configurations in Figure 3. 62 T. E. GLOVER ET AL. Figure 2. Example of 1 dimensional CA with rule 90 with TT, starting from a central cell on, executing 7 time-steps. Figure 3. Common 2-dimensional neighbourhood schemes. The Rule space of 2D CA is quite large, especially with a Moore neighbourhood. This space have 229 = 1.32 ∗10154 different Rules. It is too large to search exhaustively, but explorations into 2D CA are often limited to totalistic or outer-totalistic rules. Totalistic rules mean the rule does not distinguish whichneighboursareinwhichstate,butrather‘counts’thenumberofneighbourswithaspecificstate. 2D CA, with a Moore neighbourhoods, has only ten states to differentiate 0, 1, . . . 9 alive neighbours. Only 210 = 1024 totalistic rules exist in this rule-space. Outer-totalistic does the same but differs on the central cell. This means if the central cell is ‘dead’ there are 9 (0, 1, . . . 8) different totalistic states the outer neighbours can be in and likewise, if the central cell is ‘alive’. This means there are 2 ∗9 = 18 states for outer-totalistic rules to differentiate. Therefore, there are 218 = 262,144 different rules in this rule-space, though this can be somewhat reduced with symmetry equivalence classes [16]. The most famous version of 2D CA is Game of Life (GoL) [17], Figure 4. GoL is an outer-totalistic rule, and it works in the following manner: at each CA step, the next state changes depending on the following rules • Any living cell dies if it has two or fewer living neighbours. • Any Living cell persists if it has two or three living neighbours. • Any living cell dies if it has more than three live neighbours. • Any dead cell becomes alive if it has exactly three living neighbours. In [18], it was also demonstrated that Game of Life is Turing complete. GoL can be expressed in a more general form, which is the convention for the outer-totalistic 2D CA. GoL would be in the form INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 63 Figure 4. Single time-step of a 2-dimensional CA with Conway’s Game of Life rules. It features an oscillating blinker, a stable block, and a spaceship glider. of B3/S23, where the Birth ‘B’ component expresses the sum of neighbours needed to come alive, and the Survives ‘S’ component expresses the sum of neighbours needed to stay alive. If a sum falls outside this value, the cell will die or remain dead. 2.1.3. ‘Life-Like’ rules The 2D outer-totalistic binary CA rule space is often called the ‘life-like’ [19] rules-space, and beyond GoL, there are several other rules that are said to have ‘life-like’ properties. In [20], the goal was to identify rules that could support similar ‘life-like’ structures that can be constructed in GoL. In addition to identifying new ones, this article also provides an overview of many previously studied life-like rules that support structures such as replicators, oscillators, and spaceships. 2.2. Random Boolean networks The RBN is similar to a CA yet has two key differences. Firstly, in the RBN, the grid neighbour connec- tions are not regular but randomly set up. Secondly, every node (cell) typically has a random TT, often called an Activation function or Boolean function. This type of RBN is also sometimes called Classical RBN (CRBN) [21]. The number of direct neighbours can be random, semi-random or constant. The latter is called homogeneous RBN [21], an example is given in Figure 5. As with CAs, several extensions exist beyond the original RBN, such as Continuous RBN [9] or stochastic RBN [10,11]. While Kauffman first developed the CRBN to model gene regulatory networks, these more modern extensions to the RBN model better emulate the biological activity of develop- ment [9,11]. However, the CRBN were discovered early on [22] to contain a limited number of stable states, or attractors, from which the system would settle down to following a random initialisation. The basin of attraction reduces numerous initial states to a few stable cycles or fixed points. RBN can be defined as the following. A set of N nodes connected randomly to K number of other nodes, the specific connections for a given node can be denoted by KN. The nodes can be in one of the two binary states, and every N has the a random activation function fa (TT), out of 22K possible rule setups. 64 T. E. GLOVER ET AL. Figure 5. Example of an RBN with 7 Nodes and 3 neighbours, with a transition Table in two forms and a short execution example. 2.3. RBN classification ECA is often partitioned and classified into several different categories or traits. In [23], a good overview of many common or well-known ones can be found. Similarly, RBN can be classified by their behaviour, i.e. ordered, complex or chaotic [21,24]. Depend- ing on the value of N and K, the behaviour might differ, and one alternative name for RBN is the NK model. In [25], Kauffmann added another parameter P, which can organise the rule-space. The rule has a given P parameter value based on the number of neighbourhood combinations resulting in a 1 or a 0. In later work [24], the larger distribution dominates, meaning P ≥0.5. Figure 5 has P = 0.5. One can use this parameter to control the behaviour. P close to 1 would likely result in ordered behaviour, and P close to 0.5 would likely result in chaotic behaviour. In between these, a critical (complex) Pc behaviour might be found in the phase transition between order and chaos. This point or border is often also called the edge of chaos. The work is reminiscent of CA work in [26], which we will intro- duce later. The P is the same as λ is in Langton’s work, and in this work, we will use the λ notation for both. Another way to categorise RBN and CA is to look at the basin of attraction. Wuensche et al. [27] and Wuensche [28–30] did extensive work in both RBN and CA and their basin of attractions. What opened up this possibility was a method that could calculate backwards from a state. Take a cell in a INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 65 state and consider what possible local neighbourhood configurations would result in this state. These are the possible previous states (preimage) for the neighbourhood. Finally, this can be applied to all the cells and limit the possibilities between cells by constraining satisfaction. The possible preimages often collapse to very few, making it possible to calculate the basin of attraction quickly. 2.4. Intermediate substrates A system can be in a range of possible states that would be somewhere between CA and RBN. This paper will discuss a substrate with homogeneous rules but random neighbour wiring. This is what we define as HHRBN. HHRBN to distinguish it from what is in [21] called HRBN. It is called HHRBN rather than non-local CA because the substrate seems to behave more like RBN than CA, and the equivalence in this substrate is more applicable in RBN than CA. In [31], Li worked with systems where all cells had the same activation function (TT), but the neigh- bour connections were in various configurations. In this work Li classified the different connection schemes as between non-local (random) and partially-local (central self-reference) as well as non- distinct and distinct input/output (uniform number of outputs). Li then classifies the rule-space for these substrates using mean field approximation and shows they are very neatly classified, particularly non-local CA (HHRBN). Much earlier [32–34] studied a system that Li would classify as partially-local CA. HHRBN has additional commonly used names beyond non-local CA [31], such as Graph CA [35,36] or (Cellular) Automata Networks [37] In [28], Wuensche examined substrates between CA and RBN, including non-local CA and other disordered CA. He defines disordered CA as a super-set of CA, which includes non-local CA and mixed ruleCA.Furthermore,Wuenschecalculatesthesenetworks’basinofattractionfieldsanddemonstrates how rewiring the network can train or modify the basin of attraction. Mixed rule CA is also known as Non-uniform CA [37,38] or hybrid CA [37]. 2.5. Minimum equivalent (ME) InECA,RBNandeverythinginbetween,wefindequivalenceclassesthateffectivelyreducethenumber of unique rules for a given substrate. The List of rules that make up the minimum set of unique rules is called the Minimum equivalent (ME). These rules can be used as a smaller replacement for the entire computational space of a specific substrate. 2.5.1. Minimum equivalence (ME) in elementary cellular automata (ECA) ECA consists of 223 = 256 rules, but due to symmetries and other properties, there are only 88 rules that are considered unique. The reason is that all excluded rules can be transformed into one of the 88 unique rules by one of the following trivial methods. • reflection: switching left and right • complement: switching 0 and 1 • reflection and complement: the combination of both transformations An overview of the 88 rules can be found in Table 1. Figures 6 and 7 show examples of the transformed rules. The concept of reflection and complement seems to originate already in [32, p. 51, p. 176], and more densely explained by the same author in [33]. In the previous source, the concept originated in an intermediate substrate between ECA and RBN, with two random neighbours and itself, aka (PL CA). The ME concept works the same in such a substrate, but the concept is perhaps best known when applied to ECA in [27,39–41]. 66 T. E. GLOVER ET AL. Figure 6. Reﬂection,complementandreﬂectioncomplementtransformationofrule110andequivalentwithrandominitialisation. The reﬂection rule is initialised with a mirrored state and the complement rule with a ﬂipped value state. Figure 7. Reﬂection,complementandreﬂectioncomplementtransformationofrule110andequivalentwithcentroidinitialisation. The reﬂection rule is initialised with a mirrored state and the complement rule with a ﬂipped value state. 2.5.2. Minimum equivalence (ME) in homogeneous homogeneous random Boolean networks In HHRBN, there is also an ME set, but the mirror complement changes in this substrate. Essentially, the mirror complement changes to a switching complement. In ECA, the transformation between left and right forms an equivalence class; in HHRBN, the transformation between any combination and set of combinations between left, centre and right forms an equivalence class. This new equivalence INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 67 Table 1. The group of equivalent rules for ECA. Rule Equivalent Rule Equivalent Rule Equivalent 0 255 35 49, 59, 115 108 201 1 127 36 219 110 124, 137, 193 2 16, 191, 247 37 91 122 161 3 17, 63, 119 38 52, 155, 211 126 129 4 223 40 96, 235, 249 128 254 5 95 41 97, 107, 121 130 144, 190, 246 6 20, 159, 215 42 112, 171, 241 132 222 7 21, 31, 87 43 113 134 148, 158, 214 8 64, 239, 253 44 100, 203, 217 136 192, 238, 252 9 65, 111, 125 45 75, 89, 101 138 174, 208, 244 10 80, 175, 245 46 116, 139, 209 140 196, 206, 220 11 47, 81, 117 50 179 142 212 12 68, 207, 221 51 146 182 13 69, 79, 93 54 147 150 14 84, 143, 213 56 98, 185, 227 152 188, 194, 230 15 85 57 99 154 166, 180, 210 18 183 58 114, 163, 177 156 198 19 55 60 102, 153, 195 160 250 22 151 62 118, 131, 145 162 176, 186, 242 23 72 237 164 218 24 66, 189, 231 73 109 168 224, 234, 248 25 61, 67, 103 74 88, 173, 229 170 240 26 82, 167, 181 76 205 172 202, 216, 228 27 39, 53, 83 77 178 28 70, 157, 199 78 92, 141, 197 184 226 29 71 90 165 200 236 30 86, 135, 149 94 133 204 32 251 104 233 232 33 123 105 34 48, 187, 243 106 120, 169, 225 class further reduces the computational space to just 46 rules. The equivalence classes can be seen in Table 2. A more in-depth explanation of this transformation can be found in [16]. 2.5.3. Rule dependency Due to the properties of the ECA rule space, that space also includes rules that are invariant to one or more of their neighbours, therefore they strictly do not compute on 3 neighbours. Essentially, they do not differentiate on all the cells in the neighbourhood; e.g. rule 170 only differentiates on the left neighbour and is indifferent to the values of the right and central neighbour, or similarly, rule 90 only differentiates on the left and right neighbour, but not the central neighbour. This is called the rule dependency, and the 3 neighbour rules can be of either 0,1,2 or 3-dependency. An overview of the ME can be found in Table 3 and a complete overview in [40,42]. 2.6. Definition of chaotic behaviour in nonlinear systems To this day, the definition of chaotic behaviour is not mathematically univocal [43,44]. Still, we will work with a well-accepted definition of chaotic function. The definition is as follows (see. [45, sub- section 1.8]): a function or map f : V →V, on a vector space V, is chaotic if it satisfies the following conditions: • f has a sensitivity to initial conditions, • f must be topologically transitive, • has dense periodic orbits (periodic points are dense in V). 68 T. E. GLOVER ET AL. Table 2. The ME set for K = 3, for the switching and complement transformations. Rule Equivalent Rule Equivalent 0 255 44 56, 74, 88, 98, 100, 173, 185, 203, 217, 227, 229 1 127 45 57, 75, 89, 99, 101 2 4, 16, 191, 223, 247 46 58, 78, 92, 114, 116, 139, 141, 163, 177, 197, 209 3 5, 17, 63, 95, 119 60 90, 102, 153, 165, 195 6 18, 20, 159, 183, 215 62 94, 118, 131, 133, 145 7 19, 21, 31, 55, 87 104 233 8 32, 64, 239, 251, 253 105 9 33, 65, 111, 123, 125 106 108, 120, 169, 201, 225 10 12, 34, 48, 68, 80, 175, 187, 207, 221, 243, 245 110 122, 124, 137, 161, 193 11 13, 35, 47, 49, 59, 69, 79, 81, 93, 115, 117 126 129 14 50, 84, 143, 179, 213 128 254 15 51, 85 130 132, 144, 190, 222, 246 22 151 134 146, 148, 158, 182, 214 23 136 160, 192, 238, 250, 252 24 36, 66, 189, 219, 231 138 140, 162, 174, 176, 186, 196, 206, 208, 220, 242, 244 25 37, 61, 67, 91, 103 142 178, 212 26 28, 38, 52, 70, 82, 155, 157, 167, 181, 199, 211 150 27 29, 39, 53, 71, 83 152 164, 188, 194, 218, 230 30 54, 86, 135, 147, 149 154 156, 166, 180, 198, 210 40 72, 96, 235, 237, 249 168 200, 224, 234, 236, 248 41 73, 97, 107, 109, 121 170 204, 240 42 76, 112, 171, 205, 241 172 184, 202, 216, 226, 228 43 77, 113 232 Table 3. The ECA ME rules by neighbour dependency. Rule Dependency Rules 0 dep. 0 1 dep. 15,51,170,204 2 dep. 3,5,10,12,34,60,90,136,160 3 dep. the 74 Rules not included in the previous rows In essence, a function or map is unpredictable as it is sensitive to initial condition, indecompos- able (can not be decomposed into two or more subsystems) as it is topological transitive, and yet has an element of regularity as it has regular periodic orbits that are dense. Devaney also notes [45] that while there are stronger definitions of chaotic function, the one above is a good definition in that it is generally easy to verify and applies to a larger number of important examples. Indeed, if a system is topologically transitive and has dense periodic orbits, then it also has sensi- tivity to initial condition [46]. This means one should view sensitivity to initial condition as a necessary condition for f to be chaotic, whereas topological transitivity and the existence of dense periodic orbits together are sufficient conditions. This implication means it is possible to drop the first condition of Devaney’s definition. We will, however, keep it as part of the definition of chaotic function since it is easy to check in practice. As mentioned above, the definition of chaotic behaviour usually applies to continuous variables. However, it can be adapted to systems whose time-evolution is intrinsically discrete, as is the case of CAs and RBNs. Chaotic behaviour can be considered in eight different situations, taking all possible combinations of continuous and discrete time, continuous and discrete space, and continuous and discrete state variables. We will consider the most common cases of such combinations, aiming to introduce the concept of chaotic behaviour in CA and RBN. 2.6.1. Chaotic behaviour in continuous space, time and states The definition of chaotic function when space, time, and states are continuous variables is given above, as this is the common situation when defining chaotic behaviour. The prototypical example of a chaotic system in such conditions is a turbulent fluid, described by the so-called Navier-Stokes INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 69 equations [47], which are partial differential equations, having therefore continuous time and space variables as well as continuous state functions (velocity of the fluid). 2.6.2. Chaotic behaviour with continuous time and states and discrete space The most well-known example of a chaotic system is the Lorenz system. This system comprehends a set of three ordinary differential equations to model forced dissipative hydrodynamic flow [48]. It is defined by ˙x = −σx + σy, ˙y = −xz + rx −y and ˙z = xy −bz. For the choice of parameter values σ = 10, b = 8/3, r = 28 [49], one gets an orbit resembling a butterfly when plotting the x against z. Due to its odd features, this orbit was classified as a ‘strange attractor,’ a stable orbit showing chaotic behaviour. One such feature is that arbitrarily small difference in the initial condition leads to large deviations in the following orbits over time. In other words, the Lorenz system shows sensitivity to initial conditions. Note that this system does not have a space dimension – in our classification with time, space and state, the phase space, accounts for the state dimension. It is rather a low-dimensional example of chaos [50, subsection 3.2.2], not an example of spatiotemporal chaos. Yet, the same definition can be used when space is discrete. Indeed, a spatially extended (contin- uous) system can be discretised into a mesh or grid of points, each governed by a set of differential equations where both dependent and independent variables – state variable and time, respectively – are continuous. This would be the case of a (discrete) set of coupled Lorenz systems distributed in space, each described by continuous states and time. 2.6.3. Chaotic behaviour with continuous states and discrete time and space Another famous example of chaos but with discrete time is the logistic map xt+1 = axt(1 −xt), used as a simple mathematical model to population dynamics [49,51]. Yet, this simple equation is capable of producing chaotic dynamics. From 3 < a < 3.57, the population starts to oscillate between more and more values until it reaches the parameter region of about 3.57 < a < 4 where the oscillation explodes into the infinite (no longer oscillating). For this region, small initial values for the population yield large variations over time (sensitive to initial condition) [5, Chapter 2]. To note that this is not true for all regions of 3.57 < a < 4, e.g. at a = 1 + √ 8 there is a period-3 cycle. Similarly to the Lorenz system, the logistic map does not have an explicit space, but space can be introduced by considering again a discrete set of coupled maps for a so-called coupled map lattice [50, subsection 3.2.2]. 2.6.4. ‘Chaotic’ behaviour with discrete time, space and states This is the case of chaotic behaviour observed in CAs and RBNs, which have discrete state space (dis- crete number of accessible states, e.g. a binary set of ‘0’ and ‘1’), evolve iteratively (discrete time), and are composed of a discrete set of (spatially localised) nodes or cells. We, therefore, call them fully discrete systems. In a strict sense, taking the definition of chaotic function introduced above, this case can not show chaotic behaviour. To understand this, we can consider the concept of dense periodic orbits. The definition of dense can be stated as follows: Let A be a subset of a topological space X. Then A is said to be dense in X if: ∀x ∈X, ∀ϵ > 0, ∃a ∈A : d(x, a) < ϵ, where d(x, a) is the Euclidean distance between x and a. This means that in order to be dense, it must be possible that elements of the two sets X and A are arbitrarily close. This feature can not occur in intrinsically discrete systems, as distances are always multiples of an elementary (the smallest posi- tive) distance between two distinct instants, states or spatially distributed nodes. We shall continue this discussion in Subsection 5.6. In the rest of this paper, we will assume an ‘analogue’ of chaotic behaviour based on the comparison of the number of accessible global states (set of individual states) 70 T. E. GLOVER ET AL. and the periodicity of the overall trajectories. More precisely, in the particular case of having a CA with N cells, each one taking values {0, 1} (binary states), and then there are 2N accessible configurations (global states). Being a finite number of accessible configurations, chaotic orbits can not occur strictly, as defined above: all orbits will be periodic with a period not larger than 2N. In this context, we define ‘chaotic’ behaviour as the one typical of rules for which the periodicity scales geometrically with the size of the system. In particular, a CA of size N is considered to show ‘chaotic’ behaviour if, when dou- bling its size to 2N, the periodicity of its orbits increases quadratically, from 2N to 22N. Henceforth, behaviours observed in ECA are called ‘chaotic’ with the quotation marks to more clearly separate it as an analogy of chaos in other systems. However, these quotation marks are often omitted. Perhaps the most famous example of ‘chaos’ in systems with discrete time, space and states is the ECA Rule 30. Despite being a simple substrate (ECA) configuration, it can produce very complex and pseudo-random behaviour. In Mathematica, the central column of rule 30 is used for the pRNG [52, p. 317]. WorkhasalsobeendoneforasubsetofCAcalledlinearCA,in[53]itisclaimedthatforlinearCAover Zm that ergodicity is equivalent to topological transitivity and that dense periodic orbits (regularity) are equivalent to surjectivity. In [54] Martinez worked on a method to determine if a linear CA over Zm has a behaviour that is equicontinutity, sensitive to initial condition, strong transitivity or is positive expansive. They take a hierarchical view of the definitions of chaos, from positively expansive to strong transitive to transitive to sensitive, being the weakest. 2.6.5. Chaos in terms of computational utility Beyond a scientific interest in the computational aspect of chaos, it has some very useful applications. Like rule 30, many other chaotic systems, such as the logistic map [5, Chapter 2], can be used as a pseudorandom number generator (pRNG). To understand why, we begin with Shannon’s concepts of confusion and diffusion [55]. To miti- gate simple statistical analysis, a cipher must have properties of confusion and diffusion. Confusion, as in the input and the output, should have a very complicated relation. Diffusion means that the input should affect the whole output. These concepts are also important for pRNG. Let’s view this in terms of chaotic behaviour; a system sensitive to initial conditions would mean that small changes to the initial condition would lead to large changes in the output. Therefore, one can not use a similar output to predict the input, enhancing confusion. Further, a topologically transitive system (cannot be decou- pled) ensures that one cannot decouple the solution, leading over time to an effect on every part of the system, enhancing diffusion. Finally, a dense periodic orbit means the system can return to close but not the same configurations, ensuring a rich set of values that are close in output but distant in input, enhancing confusion and diffusion. Typically, when testing systems for pRNG, one does many statistical tests such as the ones in [56]. Note that one of the tests in this article is non-linearity, which would imply that the exploration of linear CA as chaotic systems would unlikely result in a good pRNG. Furthermore, theoretical reasoning states that highest capacity computation lies on the edge of chaos (see Subsection 2.7). Assuming this is true, identifying chaotic behaviour is important for identifying useful computational substrates. 2.7. Identifying the edge of chaos and with a parameter The parameter space of a complex system often has a phase transition between order and disorder; this phase transition region is often called ‘Edge of Chaos’ It is theorised that this region commonly contains the highest capacity for computation defined as transformation, manipulation and storage of information. Langton [26] explored this theory in 1-dimensional multi-state CA with enlarged neighbourhoods and found that the CA rule-space forms a phase transition between order and chaos when organised over a λ (Lambda) parameter. The λ parameter starts by defining a state as the quiescent state. To INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 71 Figure 8. RC as a substrate-independent framework. generate a Transition Table (TT) with a given λ value, one allocates to each TT entry a random number α uniformlydistributedbetween0and1andattributesthequiescentstatetoallentrieswithα < λand a non-quiescent state to the other. Using this method, Langton generated different candidate rules in several regions of the rule-space over the λ parameter. He showed that the rules-space organises into a phase transition between order and chaos and that strong candidates for computation are more likely to be found there. Notably, this lambda method does not seem to work in the ECA rule space, as mentioned in [26] and previous work. 2.8. Reservoir computing (RC) Reservoir Computing (RC) is a substrate-independent framework for computing. RC is independent because it works on many different substrates, but to be clear, different substrates would, of course, have different capabilities. The RC framework consists of 3 parts: the input, the untrained reservoir and the output. The input part encodes some information into the untrained reservoir and typically into higher dimensions.Theuntrainedreservoirtypicallyexpands,modifiesorchangestheinformation,butcould, in the context of the framework, be considered a black box as seen in Figure 8. The output part is typically linear, does dimensional reduction, and extracts useful features. The RC concept originated in echo state networks (ESN) using recurrent neural networks as a sub- strate (Figure 9) [57] and in liquid state machines (LSM) using a spiking neural network for a substrate [58]. Since then, both ESM and LSM and a host of other substrates have been put under the umbrella term of RC. Due to RC substrate-independent nature, many different substrates have been explored and/or compared [59]. Some explore different topology configurations as in [60], where a deep lay- ered sub-reservoirs were analysed instead of the typical one big reservoir. RC is also a very popular method with physical reservoirs [59], as an extreme example in [61] it was demonstrated that RC can use the surface waves on a bucket of water as a reservoir and they successfully solved speech recog- nition and xor tasks using this substrate. One interesting substrate is real biological neural networks (BNN), specifically disassociated neurons that self-organise over a microelectronic array [62]. There is also evidence that reservoir computing is a useful trick for computation (one of many) used in biology. Nikolic et al. [63] shows that a linear classifier can extract information about the short-term past stimulus (images, xor) from the primary visual cortex of an anaesthetised cat. Additionally, there is some evidence of RC in other biological and computational processes. In [64], the ESN (RC) model was used to simulate an example of a known genetic regulation network (GRN) process and performed satisfactorily. Similarly, in [65], the LSM (RC) model was used. 72 T. E. GLOVER ET AL. Figure 9. Basic network Architecture of an ESN. 2.9. Reservoir properties An important property in ESN is the Echo State Property (ESP). Given some input signal, the reservoir must asymptotically remove the initial condition information to have this property. In [57], it is shown that for a reservoir with specified conditions, it violates the ESP if the spectral radius of the weight matrix is larger than 1, and it was empirically observed that for Spectral radius below 1, the ESP is given. Note that in [66] Jaeger warns that this does not mean that ESP is granted for any system with a spectral radius of below 1 (asymptotically stable). It is not a necessary nor a sufficient condition. Similar to the ESP is the concept of the fading memory property. It states that an input/output system is said to have fading memory when the outputs associated with inputs that are close in the recent past are close, even when those inputs may be very different in the distant past. Grigoryeva and Ortega [67] and Tanaka et al. [59]. Maass et al. [58] determines two conditions for real-time computation on perturbations. The sep- aration property (SP) is a necessary condition, and the approximation property (AP) is a sufficient condition. SP refers to the separation between trajectories based on differences in perturbations. AP refers to the capabilities of the readout mechanism. 2.10. Reservoir computing with CA (ReCA) The first study that introduced CA as a substrate in reservoir computing is [68]. This study investigated Game of Life and several ECA rules as reservoir substrates and tested on a 5-bit and 20-bit memory benchmark. In addition, it presents a theoretical comparison of CA vs ESN, using the metric of the number of operations needed to solve the benchmark, which documents a clear advantage of using CA. As an ECA reservoir only relies on simple discrete binary interactions between cells (see [69] for details), it affords a hardware-friendly substrate implementation. The problem (perhaps ironically) becomes how to implement the readout layer in hardware. In [70], ReCA using ECA with a max-pooling and softmax strategy was implemented on a Field Programmable Gate Array (FPGA). In [71], a CA was implemented on Complementary metal-oxide-semiconductor (CMOS) combined with a custom hard- ware SVM implemented in resistive random-access memory (ReRAM). In [72], a synthesised hardware implementation of ReCA using ECA with a max-pooling and ensemble bloom filter classifier. Show- ing impressive results compared to ‘state-of-the-art’ in terms of energy efficiency, memory usage and area(number of gates) usage, but with comparably poor accuracy [70]. Other works have also studied ReCA using the 5-bit memory benchmark. Nichele and Molund [73] changed the structure of the CA to a deep-layered architecture and compared it to a single layer, which resulted in noticeable performance improvements. Additionally, in [74] the authors organised the CA INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 73 substrate as consisting of two regions of different ECA rules. Different combinations of rules were explored, and some showed great promise. In [75], an exploration was conducted of different cell his- tory selection methods for the classification model on the 5-bit memory task, a temporal order task and arithmetic and logic operation tasks. In [76], CA rules with multiple states and larger neighbour- hoods were evolved and then tested on the 5-bit memory benchmark. In [77] ECA and asynchronous ECA is tested and compared on the 5-bit memory benchmark, mainly in the context of the distractor period. In [78], it was pointed out that the benchmark has no train test split. They modified the benchmark by training on just a few (2 or 3) of the 32 possible input streams, and some of the rules with more ordered behaviour could still solve this version of the benchmark. In [79], the full ECA set was tested using key parameters of number of bits (Nb), redundancies (R) and Grid size. Glover et al. [80] extended this work to include more parameters such as Iterations (I) and Distractor Period (Dp). This paper also explained many of the unexpected results in the previous study, but perhaps as important, it similarly to [78] pointed out some weaknesses in the 5-bit memory benchmark. ReCA is also used on other benchmarks than the 5-bit memory benchmark. Morán et al. [70], Liang et al. [72], and Glover et al. [81] implemented ReCA in hardware and tested using MNIST. An addi- tional example is [82], where the authors solved tasks of sine and square wave classification, non-linear channel equalisation, Santa Fe Laser Data and iris classification. In [83] an method for Rule Selection for ReCA was presented. Limiting the search-space to only Linear rules that obey a list of specific mathematical properties (see paper for details), the paper demonstrates the method selects for rules in the high performance (95-80 percentile) bracket on sev- eral time-series prediction benchmarks compared to the full Linear CA space of same neighbourhood and number of states. 2.11. Reservoir computing with random Boolean networks (ReRBN) In [84,85], ReRBN was explored on temporal parity and temporal density (temporal majority task). For the tasks and parameters explored, it was found that the heterogeneous RBN (different in-degree RBN) reservoir worked best at a critical connectivity K = 2 (in-degree of 2). In contrast, [86] found that for homogeneous RBN, criticality was instead found at K = 3. Burkow [87] extended this work, explor- ing different reservoir properties such as perturbation percentage, the relationship with attractor and performance and comparing a subset reading from a larger reservoir to a subset equal reservoir. In [88], the relationship between N and K was also studied with a balance b between excitatory and inhibitory nodes. They find that K is the most important of the control parameters, as it affords simpler fine tuning of the other parameters. 2.12. Reservoir computing with intermediate substrates RC explorations Between CA and RBN substrates are less common. This paper reports and extends on work done in a master thesis [89], where Life-like CA, ECA, PLCA and HHRBN were explored using the 5-bit memory benchmark. In another master thesis [90], Reservoir computing with cellular automata networks where explored on a simple text classification task. The study explores and compares different ways to construct the network and how that affects performance. The cellular automata networks described include fixed predecessors (in-degree); from the description, it seems they explored PLCA, confirmed by the lack of the same score for rules 204 and 170. Yet, we can not directly compare it with the work in this paper, as the study constructs the transitions rule differently. 74 T. E. GLOVER ET AL. Table 4. Example of the 5-bit memory task with distractor period of 200 and Input of the number 25 in binary form. Step Input Output Stage 1 1 0 0 0 0 0 1 Input bits to memorise 2 1 0 0 0 0 0 1 3 0 1 0 0 0 0 1 4 0 1 0 0 0 0 1 5 1 0 0 0 0 0 1 6 0 0 1 0 0 0 1 Distractor period ... 0 0 1 0 0 0 1 204 0 0 1 0 0 0 1 205 0 0 0 1 0 0 1 Cue signal 206 0 0 1 0 1 0 0 Output bits to memorise 207 0 0 1 0 1 0 0 208 0 0 1 0 0 1 0 209 0 0 1 0 0 1 0 210 0 0 1 0 1 0 0 Notes: Artefact inspired by Babson and Teuscher [76]. 2.13. 5-bit memory benchmark The 5-bit memory benchmark traces its root to the short long-term memory task introduced in [91]. Although often cited as the source [68,73,74,76], none of the benchmarks in [91] are the 5-bit memory benchmark, but some of them are very similar in intention. The earliest source where the 5-bit mem- ory benchmark is recognisable is in [92], but named ‘noiseless memorisation,’ corroborated with the clearer and more detailed explanation of the benchmark in [93, p. 47] and in [94]. The 5-bit memory benchmark’s goal is to test whether a system is capable of memorising a 5-bit and reproducing it at a later stage. Table 4 shows an example of the memory task. The benchmark has 4 input channels where only a single channel can be active at the same time. The first two input channels are dedicated to the 5-bits. The bits are fed into the system sequentially over 5 steps. One can view the first input channel as the ‘pure’ 5-bits and the second as the reversed 5-bits. The 3rd input channel is dedicated to constantly feeding input into the system during the distractor period and the output stage. The 4th input channel is dedicated to the cue signal, signalling that the output is to be given. The benchmark has 3 output channels where one and only one should be active simultaneously. Note that some earlier examples have 4 output channels but one is dropped as it is never intended to give output. The first two are dedicated to the original 5-bits inserted into the system and should sequentially output them following the cue signal, the final output channel should give a signal in all other cases. Due to this output’s nature, one can abstract and view the task as a temporal classification problem. In this paper, we often call it the x-bit memory benchmark, as we have varied the number of bits to be memorised. Also, note that the 20-bit memory benchmark mentioned in some of the previous sources is not the same as the 5-bit memory benchmark but with 20 bits to memorise. The 20-bit memory benchmark uses 7 input channels, 5 for the input and a bit length of 10. 2.14. Small-world In [95], they explored graphs varying on p value where p = 1 meant random connectivity and p = 0 is regular connectivity. They demonstrated that small worldliness was achieved with a relatively low p-value. However, in relation to this work, they have a larger neighbour degree. Additionally, we work with fixed in-degree networks (all cells have 3 neighbours). For these reasons, we might not see the same level of small-worldness in our topologies, but naturally, in contrast to ECA, some is expected in PLCA and HHRBN. INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 75 2.15. Derrida plots and the derrida coefficient Derrida Plots is named after the author of its origin in [96]. It is a tool primarily used to identify the behaviourofaparticularRBN(critical,chaoticorordered(frozen)).Derridaoriginallyusedittocompare a classical RBN (quenched) and an ‘annealed’ RBN, in which every connection and activation function is randomly reassigned after each iteration. To construct a Derrida plot, one compares different initial conditions on the same system. Start with a random initial condition, flip 1-bit for one of the initial conditions, then evolve both the RBN one step, and calculate the Dh. Then do the same but for two flipped bits in the original initial condition, and so on until N bits. One plots the Dh as a function of the number of flips in the initial condition. Typically, the hamming distance increases linearly with the number of flips until it saturates. If the linear increase has a slope larger than one, the behaviour is considered to be chaotic; if the slope is below one, the behaviour is ordered (frozen); and if it is exactly one, the behaviour is critical (‘complex’) [97], [98, p. 246]. This behaviour classification can be formalised with the Derrida coefficient, Dc, given the angle θ of the initial slope, namely Dc = log2 (tan θ). For θ > π/4, Dc is positive and negative for θ < π/4 [98, p. 250]. In [99] the Derrida coefficient of ECA was mapped together with the Generative morphological diversity µ, to classify ECA on a spectrum of autistic, schizophrenic, and creative personality. 3. Methodology and experimental setup This section will detail the specific methods and experimental setup used in this paper. We begin with the experimental methods by documenting the x-bit memory benchmark details used for the 2D life- like (CA, HHRBN) and the 1D (CA, PLCA, HHRBN). Then, we will explain the details of the Temporal Derrida Plots (TDP) used to analyse the sensitivity. Then, we will give details on how we measured the rate of defect collapse (collapse rate). We continue with the network analysis method of the longest simple cycle and how it is estimated. Finally, we will document the source code and the dependencies with which the code was built. 3.1. x-bit memory benchmark The 2D life-like experiments use the same setup as [100]. It uses a parameter of R, which in this specific experiment is the grid size, and in terms of full grid size, it is R × R. The Iterations I represent the number of iterations between encoding steps and the number of steps fed into the classifying model, chose to be a ridge regression model. The projection ratio Pr is the ratio of cells that the input is encoded into, set to Pr = 0.6. For the 1D substrates 5-bit memory benchmarks, the experimental setup and the default parame- tersarethesamein[80].RedundancyR = 4isthenumberofconnected‘sub-reservoirs’withindividual mapped input. Note how R in the life like experiment and in the 1D experiment signifies different things. The Iterations I = 2 represent the number of iterations between encoding steps and the num- ber of iterations the classifying model had access to. The sub reservoir grid size Ld = 40, meaning the total number of cells(nodes) where Ld ∗R = 160. An example demonstrating R, Ld and I can be seen in Figure 10. The classifying model, in this case, was an SVM with a linear kernel. 3.2. Temporal derrida plots (TDP) In this work, we introduce a variant of Derrida plots: Instead of introducing a new defect at each step (see Subsection 2.15), we follow the development of one or a few defects starting at t = 0 and see how Dh changes throughout time (i.e. as a function of iterations). In this way, one follows how Dh diverges or converges to a specific value over multiple iterations. Henceforth, we call these plots ‘temporal Derrida 76 T. E. GLOVER ET AL. Figure 10. ReCA example showing R, I and Ld. Additionally, the top streams is an example of how input is encoded temporarily into the reservoir. plots’ (TDP). Derrida plots retrieve approximately the Lyapunov exponent in state space, whereas the temporal Derrida plot retrieves the Lyapunov exponent in time. If we take the simple example of the rules 204 and 170, a simple inspection of these rules would tell you they are very ordered in their behaviour, simply propagating the initial condition. Yet, using the original method [96] and as described in [98] (cf. [99, Appendix A]), Derrida plots for rule 204 and 170 yields Dc = 0, meaning that they follow the 45 angle line. This interpretation is that rules 204 and 170 are complex/ critical in the Derrida Plot method. This is not the case with our TDP. Therefore, we argue that the Derrida plot method’s weaknesses in ECA substrates are solved with our variant of TDP. Furthermore, if one is identifying chaotic features for the purpose of harvesting the chaos for something directly useful, e.g. a Random Number Generator (as they are being used for [52, p. 317]). Then, it would be more beneficial to know the development through the substrate over time, as a single step would not be enough to diffuse the seed value. In contrast, a strength of using the Derrida plot rather than the TDP is that it allows one to sample a larger number of initial states of the state space. In addition to the Dh, we plot the Damerau–Levenshtein distance (Ddl). This can catch deceptive different-looking configurations like the aether in rule 110; this effect has a marked impact later in the results section with Figure 14(b). Furthermore, we run these TDP beyond N steps as we also want to see where the substrates settle. Which we argue tells us something of how ‘chaotic’ the substrate truly is; a substrate that is ‘chaotic’ to the idea of using it as an RNG should not have any preference for 1 or 0 (balanced), and where the substrate settles tells us this experimentally. If a system is ‘ergodic’ to the sense that it covers the entire state space, then it should find every state equally likely and settle at a Dh of half the grid size (half-max distance). We run this for five configurations, 1, 5 and 9-bit changed in the centre, and 5 and 9-bits changed randomly. The randomly placed defects are coded such that there are no collisions in placements, as introducing a defect in the same place twice would cancel each other out. Note that there is, in effect, little difference between centre and random in PLCA and HHRBN; the random defects were introduced to better compare between the substrates and kept throughout the experiments for PLCA and HHRBN for consistency. All the TDP experiments use grid size of 100 cells (N = 100). 3.3. Defect collapse We explore whether the systems tend to collapse into the same attractor after a defect is introduced. This can happen in CA because the attractor basin is large enough to encompass the defect. However, INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 77 inPLCAandHHRBN,thiscanalsooccurduetotheneighbourhooditself,e.g.ifyouencodetheinforma- tion into a node that is not the in-node of any other cell, the information can not propagate anywhere. We inspect the substrate in two ways: via the Defect plots when all collapsed defects have been excluded from the data in Subsection 4.3, and we look at the statistic of collapsing in Subsection 4.4. 3.4. Longest simple cycle The difference between CA, PLCA, and HHRBN is essentially that of the topology. All the topologies can be reduced to graphs, and therefore, it is natural to apply some graph theory, yet the graph theory sub-field is broad, and the scope of this paper is already large. Therefore, we limit ourselves to finding the longest simple cycle in the topology. The longest simple cycle is the longest cycle without any repeating node (except the first and last). We picked this metric because it indicates how much infor- mation can be encoded into the network, as any oscillating pattern in the substrate would be limited by the longest simple cycle. Note that the longest simple cycle in CA would be equal to the number of cells (N) due to its regular neighbourhood configuration. It is Therefore, it is not necessary to run this analysis on CA. 3.5. Source code and dependencies The source code for the project can be found at [101]. The code relies primarily on Evodynamics [102] to run the ECA, PLCA and HHRBN and on scikit-learn [103] for the classification models. A more detailed list of dependencies can be found in [101]. 4. Results In this section, we present the results of this paper in chronological order. Starting with the 5 bit mem- ory benchmark experiments, then the TDP and collapse rate results, followed by the network analyse and finally a extended 3 and 4 bit memory benchmark results are presented. 4.1. Life-like 5-bit memory benchmark We begin with a smaller experiment between 2D outer totalistic CA (life-like CA) and HHRBN (note that the concept of 2D breaks down in HHRBN). There are 218 = 262144 different rules in the ‘life-like’ rule space (see Subsection 2.1.3). Therefore, an exhaustive search was not practical. A subset of interesting behaving rules were selected from [100,104,105]. The results can be found in Table 5, and we see here that many of the rules perform well in the CA case but not in the HHRBN case, except for B368/S12578. We can quite clearly see from Figure 11(a,b) that the behaviour of said rule changes. It is important to point out that there is a bias as these rules have been selected for their behaviour in a CA context. Therefore one can not conclude about the greater scope of ECA, and HHRBN reservoirs, we can at least say that the topology changes the behaviour. The CA results are better overall than in [100,104], though not of a different scale, this might be explained by the difference in hyper-parameter or other implementation detail of the ridge regression model as one was implemented in Julia and the other in Python, we therefore still consider it a successful replication of the previous study. 4.2. ECA 5-bit memory benchmark A similar exploration of the full ME set of ECA rules for ECA, PLCA, and HHRBN was also conducted. The bias of selecting rules is removed by exploring the entire rule space. The rules have different ME sets [16], but the ECA ME set is a super-set of the HHRBN ME set. Therefore, we use the ECA ME set by default. In Figure 12, we see these results. There is a clear trend that general performance goes down from CA to PLCA to HHRBN. In the perfect run metric, only three rules scored any perfect run for 78 T. E. GLOVER ET AL. Figure 11. B368/S12578 reservoir with Nb = 1 and Dp = 10. Reservoir is ﬂattened. We can still see some shadows and ﬂashes of the same behaviour, but clearly, the CA and HHRBN behave diﬀerently. (a) CA and (b) HHRBN. Table 5. Results from the replicated reservoir architecture of [100,104] with the addition of Dynamic Life (B356/S23) [105]. CA HHRBN CA HHRBN CA HHRBN Model (R, I) (24, 8) (28, 8) (30, 6) B3/S23 2% 0% 100% 0% 91% 0% B35/S236 72% 0% 100% 0% 100% 0% B368/S12578 60% 48% 100% 100% 100% 100% B356/S23 67% 0% 100% 0% 100% 0% Notes: Cross-referenced with the RBN reservoir architecture. (R, I) where R is the reservoirwidth, and I is both the length of the reservoir feature vector and the number of iterations between inputs. HHRBN (108, 170, 204). We see a similar trend in the weighted average metric. Note that these rules (108, 170, 204) are all ordered in behaviour and that rules 170 and 204 are equivalent in the HHRBN ME set, meaning in effect, only 2 behaviours of the 46 unique HHRBN managed to solve the task. More details and results can be found in [89]. 4.3. Temporal derrida plots In this subsection, we will present the TDP, all plots except Figure 17(a) have the collapsed runs removed; the tally of the collapsed runs can be found later in Tables 6–8. They are separated because thecollapsecangreatlyimpactthetemporalDerridaplots.Inshort,westillseethisimpactbyremoving them and displaying them alone, but we can compare sensitivity independent of collapse rate. We begin with an example of the ideal ‘chaotic’ ECA rule 30 in Figure 13(a). In ECA, we see as we expect, the randomly placed defects to be quicker to permute the substrate. The central defects nat- urally take longer to permute the substrate as they are limited by the CA’s ‘speed of light’ (in CA, INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 79 Figure 12. Breakdown of individual rule performance with 5-bit memory. Table 6. ECA Rule collapse rate of individual rules. defect Rule 30 Rule 90 Rule 54 rule 110 rule 170 rule 184 1-bit c 0% 0% 2% 3% 0% 0% 5-bit c 0% 0% 2% 1% 0% 0% 9-bit c 0% 0% 2% 0% 0% 0% 5-bit r 0% 0% 0% 0% 0% 0% 9-bit r 0% 0% 0% 0% 0% 0% Table 7. PLCA Rule collapse rate of individual rules. defect Rule 30 Rule 90 Rule 54 rule 110 rule 170 rule 184 1-bit c 33% 14% 1% 29% 91% 72% 5-bit c 0% 0% 0% 0% 62% 29% 9-bit c 0% 0% 0% 0% 41% 19% 5-bit r 0% 0% 0% 0% 56% 28% 9-bit r 0% 0% 0% 0% 41% 21% Table 8. HHRBN Rule collapse rate of individual rules. defect Rule 30 Rule 90 Rule 54 rule 110 rule 170 rule 184 1-bit c 21% 21% 17% 21% 91% 59% 5-bit c 0% 0% 0% 0% 56% 29% 9-bit c 0% 0% 0% 0% 35% 26% 5-bit r 0% 0% 0% 0% 61% 31% 9-bit r 0% 0% 0% 0% 46% 21% information can only flow to direct neighbouring cells at every step, creating a speed limit for infor- mation often called the ‘speed of light’). For PLCA and HHRBN, much is the same, except the defects permute the substrates faster. The CA ‘speed of light’ does not apply similarly to a random topology of PLCA and HHRBN; the random topology creates a certain level of ‘small worldness’. We will dis- cuss this further in Subsection 2.14 The defect configuration for many substrates settles towards the same Dh of 50 (half-max distance), the normal average distance two random binary vectors would have between each other. That they all settle at the same distance is also a test of sensitivity, as the differences between configurations have expanded to the maximum probabilistic difference. For rule 90, seen in Figure 13(b), it’s clear that the ECA behaviour is very different. The distance might look erratic at first but is quite regular, and it is due to rule 90s additive behaviour. In rule 90 80 T. E. GLOVER ET AL. Figure 13. Rule (left) 30 displaying ideal ‘chaotic’ behaviour. Rule 90 (right) displays additive behaviour in CA and more ideal ‘chaotic’ behaviour in PLCA and HHRBN. (a) Rule 30 and (b) Rule 90. and all the other additive ECA, the defects permute in a way that is invariant to the initial condition of the different cells see [80, subsubsections: 2.1.2–3 and 5.5.5–6 ] for more detail. The PLCA and HHRBN behave much closer to rule 30 and ‘chaotic’ behaviour. However, reflecting on this, we hypothesise that this is due to every run having a random topology rather than the regular Rule 90 behaviour somehow becoming ‘chaotic’ in PLCA and HHRBN. We also INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 81 Figure 14. Rule 110 and 54 displaying more complex behaviour in CA, and more sensitivity in PLCA and HHRBN. (a) Rule 54 and (b) Rule 110. see that the trajectories settle at roughly the same place but with a slightly higher amplitude in rule 90 than in rule 30, indicating a more significant variance. Figure 14(a) shows one of the ‘complex’ rule 54. Its behaviour would seem to fit such a classification as the defects permute the substrate but in a prolonged manner; even after 500 steps, it seems it has not fully settled at a distance in some runs. Fitting with the edge of chaos theorem, this behaviour 82 T. E. GLOVER ET AL. Figure 15. Example of 200x200 rule 110 displaying an example of aether matches expectations that its behaviour should not be trivial (ordered) and not quite chaotic. In PLCA, the effect is closer to the chaotic behaviour, yet we can see that 1-bit defects settle at different distance then the other defects. Though typically 1, bit defects are more likely to collapse, as this result excludes runs that have collapsed, that is not the reason. As this does not happen in HHRBN, we hypothesise this must have something to do with the computation of the central cell. It might be able to erect, at the very least, a weak local barrier. In Figure 14(b), we see another ‘complex’ rule 110 that, similarly to rule 54, takes long to saturate the difference distance. In contrast to rule 54, rule 110 in the Ddl distance first grows but then shrinks again. We hypothesise this is due to the feature of Rule 110 settling in large regions ‘aether’ as seen in Figure 15. The aether in rule 110 is regions of regular small triangles, as the CA develops the more likely they are to show up and the larger they will be. If two configurations of CA have large regions of this aether, the configurations can be shifted to line up with each other. A shift operation is not possible in simple Dh, but with Ddl, a shift can be constructed using a delete and insert operation. This way, the Ddl can create a significantly shorter edit distance than the Dh. Rule 54 similarly has an aether, but in contrast to rule 110, the aether areas are smaller and local in space. See [106] for an example. Therefore, we don’t seem to see the same effect there. Similarly to Rule 54, we see a separation in PLCA where 1-bit defects do not settle on the same distance. In Figure 16(a), we see rule 170. For ECA, as we expect, the distance does not change in relation to time. In Rule 170, every cell updates based on a copy of the left neighbour, which simply shifts the previous configuration one step to the left every iteration. Therefore, a fixed distance is expected. The small blips in the Ddl are caused by the defect hitting the CA boundary, making it less effective to use the insert-delete shift method explained earlier in rule 110 to shorten the edit distance. In rule 170s PLCA and HHRBN results, we see something unexpected. Firstly, there are different results between INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 83 Figure 16. Rule 170 and 184 displaying more ordered behaviour. (a) Rule 170 and (b) Rule 184. PLCA and HHRBN, as rule 170 only computationally depends on its right neighbour (1 cell depen- dant); there should be no difference. Secondly, there seems to be a separation between the random and the central defects; thirdly, in HHRBN 9, 9-bit random is lower in distance than 5-bit random. This can at least partly be explained with Tables 7 and 8. As there are many collapsed runs, the remaining runs do not have as much statistical power, causing larger variance. This is further enforced by how 1-dependant rules are more vulnerable to imperfect topology. 84 T. E. GLOVER ET AL. Figure 17. TDTcomparingwithorwithoutcollapseoftherun.ThereisanoticeableincreaseinDh andDdl whenexcludingcollapsed runs, especially with the 1-bit defect. (a) TDT including collapsed runs and (b) TDT excluding collapsed runs. In Figure 16(b), we see rule 184. We see very ordered behaviour in ECA, though not quite as trivial as Rule 170. Rule 184, similarly to rule 110, often forms large aether regions, so we see a shrinking Ddl here. In PLCA and HHRBN, we see more dynamic behaviour, yet the distances do not settle at a half- max distance. Interestingly rule 184 has a λ = 4 8 yet settle below half-max and rule 110 has a λ = 5 8 yet settle at roughly half-max. This decorrelation indicates that if it is useful for a rule to be balanced INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 85 in output, it is not sufficient for a rule to be balanced in the TT. Still, it also needs to be balanced at the computational scale independently of its λ. 4.4. Collapse rate We will begin with the collapse rate for the selection of rules in the previous section; these are found in Tables 6–8. We see that for these rules, there is almost no collapse in ECA, but for PLCA, 1-bit defects regularly collapse except for Rule 54. In contrast, rules 170 and 184 have a large number of collapses. In the case of rule 170, we will explain, in Subsection 4.5, how the rule dependency is one reason for the high collapse rate. For the HHRBN, much is the same compared to PLCA, except for rule 54, which has a higher collapse rate for 1-bit defects. In Figure 17(b), we see the TDP for the full ECA ME results with and without collapsed runs included. Firstly, we can see that the additive rules, such as rule 90 and its frequencies, impact the data such that it is still visible in the total data consisting of all the 88 ME rules. We can also separate the different defect initialisations in inclusive and exclusive collapsed runs. Similarly, in PLCA, we see a separation between the defect sizes but not the defect types (random, central); this is as expected as they are functionally the same in PLCA and HHRBN substrates. In HHRBN, excluding collapsed runs, we see something that looks mainly like sensitive behaviour, though it does not settle at a roughly half-max distance. This might be due to how the ME set is derived because of the complement transformation many of the later rules in the rule-set are excluded, and the later rules have on average a higher λ, in fact, the average λ = 0.386. See Table 9 for why that is. Additionally, we observed that a 1-bit defect has a slightly higher settling distance. Looking at many individual rules, a few rules, such as rule 140, have this effect of a significantly higher average for the 1-bit difference. Table 10 provides a comprehensive overview of the collapsed runs by substrate. The data reveals a clear trend: the likelihood of collapse increases from ECA to PLCA to HHRBN and from more defects to less. In Table 11, we see the same ECA data but grouped by dependencies. See Table 3 for details on whichrulebelongswhere.FortheECA,wecan,withthesupportoftheory,understandtheresultsquite reliably. 0-dependency always collapses as rule 0 (the only 0-dependency rule in the ME) always has the same attractor of an entirely quiescent configuration (all cells become 0 state). For 1-dependency (rule 15, 51, 170, 204), they will never collapse in ECA because they are all of a simple behaviour that propagates the information without much (if any) transformation. Rules 170 and 204 are additive and rules 15 and 51 are negative versions of additive rules. Negative transformation is simply changing the output bit of the TT to the opposite (not to be confused with complement transformation). This trans- formation leads to similar behaviour but is not typically considered part of the ME transformations. The 2-dependency rules are 3, 5, 10, 12, 34, 60, 90, 136, 160. For these rules, rules 136 and 160 dominate the collapse rate as they always collapse. These rules are such that they always turn quiescent after a fixed number of iterations. As is for rule 0, it is more accurate to describe it as all initial conditions collapse rather than the defects collapse. In contrast, rules 60 and 90 should almost never collapse due to their additive nature. However, some configurations will collapse for these rules, such as for specific grid sizes [80, Subsubsecton 5.5.5]. Similarly, we can go through the 3-dependency rules, but for the sake of brevity, we will not. In PLCA and HHRBN, we expected a strong trend of lower dependency, meaning more collapse, mainly due to network properties, which we discuss in Subsection 4.5. In Tables 12 and 13, we see some trend towards more collapse the lower the dependency, but only if we ignore the 2-dependency results. Except for 1-bit defects, 2-dependency has a higher collapse rate than 1-dependency in both cases. One hypothesis is that because the rules in 1-dependency are all λ = 4 8 (balanced), this domi- nates the dependency effect in 1-dependency rules, and all of the 2-dependency rules except rules 60 and 90 are λ = 2 8. This could be tested by grouping by λ. In Tables 14–16 we do just this. Group our results by λ value of the TT. In this case, we see a clear trend of the balance of the rule affecting the collapse rate. This λ value organise the collapse rate 86 T. E. GLOVER ET AL. Table 9. The ECA ME rules by λ. Rule λ Rules λ = 0 8 0 λ = 1 8 1, 2, 4, 8, 32, 128 λ = 2 8 3, 5, 6, 9, 10, 12, 18, 24, 33, 34, 36, 40, 72, 130, 132, 136, 160 λ = 3 8 7, 11, 13, 14, 19, 22, 25, 26, 28, 35, 37, 38, 41, 42, 44, 50, 56, 73, 74, 76, 104, 134, 138, 140, 146, 152,162, 164, 168, 200 λ = 4 8 15, 23, 27, 29, 30, 43, 45, 46, 51, 54, 57, 58, 60, 77, 78, 90, 105, 106, 108, 142, 150, 154, 156, 170, 172, 178, 184, 204, 232 λ = 5 8 62, 94, 110, 122 λ = 6 8 126 λ = 7 8 λ = 8 8 Table 10. The number of times in the whole 8800 runs (100 runs for 88 rules) per substrate rule population that collapsed. init ECA PLCA HHRBN 1 central 2450 (27.8%) 4722 (53.7%) 5253 (59.7%) 5 central 1352 (15.4%) 2338 (26.6%) 3328 (37.8%) 9 central 1123 (12.8%) 1918 (21.8%) 3049 (34.6%) 5 random 872 (9.9%) 2295 (26.1%) 3355 (38.1%) 9 random 828 (9.4%) 1919 (21.8%) 3043 (34.6%) Table 11. Number of times the ECA rules diﬀerence died out grouped by neighbour dependencies. init. 0 dep. 1 dep. 2 dep. 3 dep. 1 central 100 (100.0%) 0 (0.0%) 315 (35.0%) 2035 (27.5%) 5 central 100 (100.0%) 0 (0.0%) 204 (22.7%) 1048 (14.2%) 9 central 100 (100.0%) 0 (0.0%) 200 (22.2%) 823 (11.1%) 5 random 100 (100.0%) 0 (0.0%) 200 (22.2%) 573 (7.7%) 9 random 100 (100.0%) 0 (0.0%) 200 (22.2%) 528 (7.1%) Table 12. Number of times the PLCA rules diﬀerence died out grouped by neighbour dependen- cies. init. 0 dep. 1 dep. 2 dep. 3 dep. 1 central 100 (100.0%) 182 (45.5%) 626 (59.6%) 3814 (51.5%) 5 central 100 (100.0%) 112 (28.0%) 487 (54.1%) 1639 (22.1%) 9 central 100 (100.0%) 68 (17.0%) 424 (47.1%) 1326 (17.9%) 5 random 100 (100.0%) 104 (26.0%) 476 (52.9%) 1615 (21.8%) 9 random 100 (100.0%) 72 (18.0%) 414 (46.0%) 1333 (18.0%) clearly, for all parameters the collapse rate grows when the λ is closer to the edge values 0 and 1. This also gives some reason as to why the dependency value was not so neatly described. 4.5. Network topology, longest simple cycle We can see from examples such as Figure 13(a) that the original ECA ‘speed of light’ is still there in a sense also for PLCA and HHRBN, though vastly different. Defects can still only affect neighbouring cells, but the pathways through the network that the defects can propagate are more small-world than ECA. This is unsurprising as they are randomly generated in contrast to ECA. We want to create a sense of how this affects the computations. We do this by finding a network’s longest simple cycle. The longest simple cycle indicates the theoretical memory size that can be encoded into the network and the substrate’s ability to retain a memory in the cycle. INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 87 Table 13. Number of times the HHRBN rules diﬀerence died out grouped by neighbour dependencies. init. 0 dep. 1 dep. 2 dep. 3 dep. 1 central 100 (100.0%) 354 (88.5%) 715 (79.4%) 4084 (55.2%) 5 central 100 (100.0%) 217 (54.3%) 618 (68.7%) 2393 (32.3%) 9 central 100 (100.0%) 152 (38.0%) 583 (64.8%) 2214 (29.9%) 5 random 100 (100.0%) 210 (52.5%) 621 (69.0%) 2424 (32.8%) 9 random 100 (100.0%) 151 (37.8%) 572 (63.5%) 2220 (30.0%) Table 14. Number of times the ECA rules diﬀerence died out group by Lambda. init. λ = 0 8 ∨8 8 λ = 1 8 ∨7 8 λ = 2 8 ∨6 8 λ = 3 8 ∨5 8 λ = 4 8 1 central 100 (100.0%) 422 (70.3%) 655 (36.4%) 787 (23.1%) 486 (16.8%) 5 central 100 (100.0%) 342 (57.0%) 420 (23.3%) 337 (9.9%) 153 (5.3%) 9 central 100 (100.0%) 318 (53.0%) 378 (21.0%) 224 (6.6%) 103 (3.6%) 5 random 100 (100.0%) 307 (51.2%) 312 (17.3%) 131 (3.9%) 23 (0.8%) 9 random 100 (100.0%) 300 (50.0%) 302 (16.8%) 108 (3.2%) 18 (0.6%) Table 15. Number of times the PLCA rules diﬀerence died out group by Lambda. init. λ = 0 8 ∨8 8 λ = 1 8 ∨7 8 λ = 2 8 ∨6 8 λ = 3 8 ∨5 8 λ = 4 8 1 central 100 (100.0%) 542 (90.3%) 1236 (68.7%) 1739 (51.1%) 1105 (38.1%) 5 central 100 (100.0%) 481 (80.2%) 783 (43.5%) 662 (19.5%) 312 (10.8%) 9 central 100 (100.0%) 463 (77.2%) 679 (37.7%) 489 (14.4%) 187 (6.4%) 5 random 100 (100.0%) 470 (78.3%) 777 (43.2%) 652 (19.2%) 296 (10.2%) 9 random 100 (100.0%) 459 (76.5%) 679 (37.7%) 494 (14.5%) 187 (6.4%) Table 16. Number of times the HHRBN rules diﬀerence died out group by Lambda. init. λ = 0 8 ∨8 8 λ = 1 8 ∨7 8 λ = 2 8 ∨6 8 λ = 3 8 ∨5 8 λ = 4 8 1 central 100 (100.0%) 593 (98.8%) 1404 (78.0%) 1873 (55.1%) 1283 (44.2%) 5 central 100 (100.0%) 566 (94.3%) 1091 (60.6%) 1070 (31.5%) 501 (17.3%) 9 central 100 (100.0%) 562 (93.7%) 1026 (57.0%) 940 (27.6%) 421 (14.5%) 5 random 100 (100.0%) 576 (96.5%) 1096 (60.9%) 1064 (31.3%) 519 (17.9%) 9 random 100 (100.0%) 544 (90.7%) 1023 (56.8%) 950 (27.9%) 426 (14.7%) We begin by considering a 1-dependency rule, such as rule 170. A ECA rule that depends only on 1 neighbour means by definition that 2 of the neighbours do not affect the computation. This effectively reduces the in-degree from 3 to just 1. Though our collapse results do not show a clear trend based on this dependency, we still argue that it must affect the computation because the network properties of a 1-in-degree network are majorly different from a 3-in-degree network. The following evidence may persuade the reader of this conclusion. We take the first topology generated for rule 170 from the data in Figure 12 and only keep the nodes that compute (the third in node neighbour). The network can be seen in Figures 18 and 19. We see that there are 4 isolated subgraphs in this topology and very few and very short cycles. 63% of the networks generated had at least one isolated subgraph. On average, the networks had 2.26 isolated subgraphs. Note, that this means the example is skewed towards a more affected network, it still demonstrates well the issues with the networks. We made many networks with 1-in-degree for N (3 ...160) nodes and found the longest simple cycle in these networks; see Figure 20. The computing cost of running this for 1-in-degree is trivial. There- fore, we run this 10,000 per N. This data shows that the trend is asymptotic and that for N = 100, the average longest simple cycle is about 8 and 10 for N = 160. For 2-in-degree networks, finding the val- ues for 100 and 160 nodes is vastly different; the number of cycles in this graph grows quickly, and the times to compute them were exponential. Therefore, we only computed for 3 to 50 nodes. Assuming 88 T. E. GLOVER ET AL. Figure 18. Tree graph visualisation of an example of a generated connection graph for Rule 170 PL CA. Showing four isolated subgraphs and very few cycles. this is asymptotic in the same manner as for 1-in-degree, we can fit a line to the data and know that the true values for the longest simple cycle are below that line. This can be seen in Figure 21. From this estimate, the longest simple cycle should be below 70 for N = 100 and below 110 for N = 160. This is substantially larger than 1-in-degree, but still significantly below ECA, which the longest simple cycle will always equal the number of cells(nodes). For 3-in-degree, see Figure 22. It is still below the max, as for N = 100, it must be below 95 and for N = 160, it must be below 150. Note that this is a theo- retical max, and assuming the data is asymptotic, the true value must be below this value. To be clear, even if they are not asymptotic and simply linear, we still expect this to have some effect on the com- putation. Also, note that we could have fitted these values to an asymptotic curve but opted not to. This is because the asymptotic degree would greatly affect where the curve ends up even with minor changes, and we do not know what it is for 2 and 3 degrees. Therefore, we opted for a theoretical max with linear fitting of the form y = mx + b. 4.6. Sensitivity in the x-bit memory benchmark As was established in [80], the 5-bit memory benchmark can be solved with a simple random vector given sufficient dimensions. Therefore, it would be interesting to see if, as we compare CA, PLCA and HHRBN, as the tasks become easier, more and more rules can solve this issue and whether that would be true for HHRBN than for PLCA and PLCA compared to ECA. We expect HHRBN and PLCA to be more sensitive, and we expect them to perform better on the 3 and 4-bit memory benchmarks. We see from Figures 12, 23 and 24 that yes, more rules are capable of solving the easier tasks, but it is not entirely clear that a more significant portion of the rule-space of HHRBN or PLCA is finding the task trivial. If INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 89 Figure 19. Circle graph visualisation of an example of a generated connection graph for Rule 170 PL CA. Showing four isolated subgraphs. Table 17. The Average and standard deviation performance over the rule-space in percentage. Nb Substrate W.avg Perf. runs 5 ECA 47.42 ± 33.29 8.67 ± 24.72 5 PLCA 35.64 ± 27.60 2.89 ± 9.17 5 HHRBN 15.83 ± 16.65 0.15 ± 1.01 5 (ME) HHRBN 14.00 ± 15.90 0.20 ± 1.31 4 ECA 60.89 ± 35.42 27.40 ± 40.93 4 PLCA 59.11 ± 35.02 29.13 ± 42.58 4 HHRBN 63.30 ± 38.93 39.58 ± 45.70 4 (ME) HHRBN 60.01 ± 41.28 39.78 ± 46.03 3 ECA 67.16 ± 35.77 39.36 ± 41.96 3 PLCA 62.53 ± 35.12 32.81 ± 43.56 3 HHRBN 66.01 ± 38.24 49.78 ± 47.49 3 (ME) HHRBN 62.47 ± 40.93 48.87 ± 47.69 Notes: (ME) HHRBN is the average over only the HHRBN ME set (not the ECA ME set) we view this through the average performance across the rule space, as seen in Table 17, there does seem to be a degree of this behaviour, but there are clear exceptions such as 3-bit W.avg. The results corroborate the previous presented topology effects for the longest simple cycle and collapse rate in PLCA and HHRBN. 90 T. E. GLOVER ET AL. Figure 20. From samples of random graphs between 2 and 160 nodes with in-degree of 1. Every x value is the average of 10,000 random graphs. We ﬁt this data to a linear function using linear regression for the sake of comparison to Figures 21 and 22 5. Discussion Thissectionfocusesondiscussingtheresultsand,howtheyrelatetoeachother,andhowtheyrelateto the field in a larger context. We will also give a short account of how we would approach the problem of a more natural definition of fully discrete chaos. 5.1. A complicated relationship between disordered topology and its computation We see through the collapse rate that in random topologies, the collapse rate significantly increases in PLCA and HHRBN, meaning random topology leads instead to more orderly computation. In contrast, if we look at results that don’t collapse, we see a significant increase in sensitivity; we, in other words, have conflicting computational ‘forces.’ If we look at our results that would be affected by both ‘forces,’ we still see a slight trend towards disorder. However, if we consider individual rules such as rule 30, we would argue that as the collapse rate goes from 0% to 33% (PLCA) and 21% (HHRBN), this rule, on average, becomes more orderly. Therefore, this relationship is complicated. 5.2. Implications for RBN and RBN reservoirs Our HHRBN has the same topology as Classical RBN, so implications beyond HHRBN can be derived. We demonstrated how different fixed in-degree networks should have a lower than max longest sim- ple cycle. As RBN has random rules per node, the average dependency of RBN is slightly less than three. Therefore, the degree of RBN is also, in practice, less than three. This means that when applied to INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 91 Figure 21. Predicted average length of the longest simple cycle using Simple linear regression ﬁtting. From samples of random graphs between 2 and 50 nodes with in-degree of 2. Every x value is the average of 100 random graphs. Assuming the true function is asymptotic as in Figure 20, the true value for the portion after the data should be somewhere below the ﬁtted line. RBN, the results of the 3-in-degree random networks are, in practice, overestimates. It is likely already overestimated as we fit a line to a (hypothesised) asymptotic function. Therefore, the RBN’s longest simple cycle in practice should be even smaller. We also see a significant collapse rate even in the most ‘chaotic’ rule (rule 30). The natural assumption would be to see similar effects when applied to RBN. Therefore, we see many effects that reduce the sensitivity or disorderly nature of the computation that we would also hypothesise to apply RBN. 5.3. Weaknesses of this study Though this work is quite extensive, the work has some limitations. Due to computational constraints, we limit ourselves to CA grid sizes of a specific size, and we know that CA can exhibit significant behaviour changes on different grid sizes [80]. 5.4. Size of the edge of chaos In [107,108] several examples where introducing more heterogeneity extended the critical area. As we introduce topological heterogeneity to our networks, it would be interesting to consider if we are observing the same phenomenon of an increasing critical range. We begin by considering Wolfram’s well-known ECA classification [23,109]; there are only 11/88 rules in the ‘chaotic’ class. We might also argue that the additive rules 60, 90 and 150 should not be considered ‘chaotic,’ making the space even smaller. Also, consider that there are only 4 complex rules, indicating that the ECA rule space is skewed 92 T. E. GLOVER ET AL. Figure 22. Predicted average length of the longest simple cycle using Simple linear regression ﬁtting. From samples of random graphs between 3 and 30 nodes with in-degree of 3. Every x value is the average of 100 random graphs. Assuming the true function is asymptotic as in Figure 20, the true value for the portion after the data should be somewhere below the ﬁtted line. Figure 23. Breakdown of individual rule performance with 4-bit memory. towards ordered behaviour. As we see a small indication that introducing heterogeneity moves the space towards more sensitive ‘chaotic’ behaviour, we should also expect to see more rules exhibit crit- ical behaviour. Nevertheless, the same evidence indicates the opposite of an extended criticality: a shrinking criticality. If we go by the collapse rate, we can say that the region of ordered behaviour has INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 93 Figure 24. Breakdown of individual rule performance with 3-bit memory. extended. If we control for the collapse rate, the remaining runs behave closer to sensitive ‘chaotic’ behaviour; this indicates a shrunk critical range. If we go by the 5-bit memory benchmark, we again see signs of a shrunk criticality as very few runs managed to solve the benchmark. If we go by indi- vidual rules, one can argue that rules 170 and 184 behaved closer to critical, though the collapse rate is highly significant for these rules. As our experiments were not specifically designed to identify the size of the critical area, we can not definitively conclude that our findings apply universally. A thor- ough examination of all individual rules might yield a different conclusion. It would not be surprising if heterogeneity could extend criticality. Still, the study of complexity often reveals that the relation- ship between critical behaviour, substrates, and hyper-parameters is intricate and complex. This rather indicates a rich field worthy of much study. 5.5. Implications for ReCA, ReRBN and intermediates We can consider some implications for reservoir computing with CA, PLCA, and HHRBN reservoirs from our results. If one considers the tool in practical terms, the ECA substrate seems superior as its regular topology lends reliability to the implementation, but also the localised neighbourhood affords easier implementation into FPGA, as the other substrates would naturally create more issues with the transfer of information due to the placement of neighbours. It is common practice in RC to have redundant mappings for encoding the input. As we observe a higher collapse rate in PLCA and HHRBN, reservoir usage of these substrates will benefit more from higher input redundancy than the ECA. Alternatively, one could more carefully select encoding place- ment into the network as there are likely to be nodes that afford better distribution of the perturbation than others. 5.6. A ‘discrete’ version of chaos In this paper, we pointed out that the definition of chaos breaks down when applied to fully discrete systems, i.e. systems intrinsically discrete in space and time and with a discrete number of accessible states. The sensitivity on initial conditions required in the definition of chaotic function has a natural analogy for discrete systems, but what about the concept of dense periodic orbits and topological transitivity? Here, we propose a definition of the meaning of a dense set of trajectories of a discrete system, with some additional mathematical formalism. The set of accessible trajectories of a discrete system is dense in the full phase space of possible configurations if, for each configuration in phase space, the 94 T. E. GLOVER ET AL. Figure 25. The contribution graph based on recommended categories from [110]. Contributions are based on degree of involve- ment. minimal Hamming distance, min (Dh) to an accessible trajectory converges to zero not slower than the size N of the system: lim N→∞N min (Dh) = 1. In practice, this definition can be read as min (Dh) ∼1 N, so graphically, plotting minimum Hamming distances as a function of the inverse of the system’s size should hold a line with a unitary slope. If we consider the orbit, the natural analogy is the attractor in binary systems, A cyclic trajectory that the deterministic discrete system must eventually converge to. Therefore, we conclude that a natural analogy for a dense periodic orbit is a long attractor that period- ically expands and contracts the Dh between previous states without finding the exact previous state. Expanding and contracting are important because a long attractor does not necessarily mean chaos. Consider the example of a binary vector that does iterative counting upwards by 1. This would have full coverage over the state space and the longest possible attractor, but it should not be considered chaotic behaviour. As for the topological transitivity, it is similarly defined in continuous space [45, subsection 1.8]: an iterative map f : J →J is said to be topological transitivity if, for any pair of non-empty sets U, V ⊂J, there exists k ≥0 such that f k(U) ∩V ̸= ∅. In other words, it still implies that a system can not be decomposedintotwosubsystems.Italsomeansthatitmustbepossiblefromagivenstatetotransition to any other state in the system. This condition is again reflected in the attractor, where there should be only one possible attractor in the system. The presence of two separate attractors would imply that the system can be decomposed, contradicting the notion of topological transitivity. INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 95 6. Conclusion This work investigated computational differences between ECA, PLCA, and HHRBN. It explores what happens with the simplest computational universe when introducing topological heterogeneity. We investigated using a simple 5-bit memory benchmark, sensitivity metric and collapse rate of the dif- ferent substrates. We see how, in PLCA and HHRBN, performance on the 5-bit memory benchmark is substantially worse. That collapse rate increases substantially, which counterintuitively means that a more disordered topology can sometimes mean more ordered computation. In general, we see a weak sign of increased sensitivity, and if the collapse rate is controlled for, we see a strong sign of increased sensitivity. This indicates that we are observing a shrinking critical range. We see evidence consistent with the previous observations when we make the 5-bit memory benchmark easier by solving a 4 and 3-bit memory benchmark. Our results conclude that ECA is, at least with current hardware, the better reservoir for edge AI. We also try to address the issue of ‘chaos’ in a fully discrete system and attempt to define a condition for the natural analogy. 7. Future work Many future work projects can naturally extend this work. As we identified in the intro (Figure 1), there are many steps between ECA and BBN, which can be explored. Additionally, there are different paths between ECA and BNN, so other orders of steps could be explored. For example, would we get the same results if we introduce other forms of heterogeneity, such as mixed-rule CA? Furthermore, our networks have a random topology beyond what is typically true in most biological systems. It would be interesting to see how the regular topology (ECA) and the irregular topology (HHRBN) perform when compared to evolved networks such as the connectome of a C. elegans. Alternatively, if we explore networks with increasing locality of connections, this might even be a suitable control parameter for reservoir quality. 8. Contributions A contribution graph based on the CRediT author statement 110, can be seen in Figure 25. Disclosure statement No potential conflict of interest was reported by the author(s). Funding This work was partially financed by the Research Council of Norway’s DeepCA project, grant agreement 286558. References [1] Strubell E, Ganesh A, McCallum A. Energy and policy considerations for deep learning in NLP. arXiv preprint arXiv:1906.02243. 2019. [2] Luccioni AS, Jernite Y, Strubell E. Power hungry processing: watts driving the cost of ai deployment? arXiv preprint arXiv:2311.16863. 2023. [3] von Neumann J. Theory of self-reproducing automata. Math Comput. 1966;21:745. [4] Howard N. Energy paradox of the brain. Brain Sci. 2012;1:35. [5] Mitchell M. Complexity: a guided tour. New York, NY: Oxford University Press; 2009. [6] Kauffman SA. Metabolic stability and epigenesis in randomly constructed genetic nets. J Theor Biol. 1969 Mar;22:437–467. doi: 10.1016/0022-519390015-0 [7] Chan BW-C. Lenia: biology of artificial life. Complex Syst. 2019;28:251–286. doi: 10.25088/ComplexSystems [8] Mordvintsev A, Randazzo E, Niklasson E, et al. Growing neural cellular automata. Distill. 2020;5. 10.23915/distill. 00023. [9] Vohradsky J. Neural network model of gene expression. FASEB J. 2001;15:846–854. doi: 10.1096/fsb2.v15.3 [10] Ribeiro A, Zhu R, Kauffman SA. A general modeling strategy for gene regulatory networks with stochastic dynamics. J Comput Biol. 2006;13:1630–1639. doi: 10.1089/cmb.2006.13.1630 96 T. E. GLOVER ET AL. [11] Elowitz MB, Levine AJ, Siggia ED, et al. Stochastic gene expression in a single cell. Science. 2002;297:1183– 1186. doi: 10.1126/science.1070919 [12] Orchard G, Frady EP, Rubin DBD, et al. Efficient neuromorphic signal processing with loihi 2. In: 2021 IEEE Workshop on Signal Processing Systems (SiPS). IEEE; 2021. p. 254–259. [13] Mitchell M. Life and evolution in computers. Hist Philos Life Sci. 2001;23(3/4):361–383. [14] Cook M. Universality in elementary cellular automata. Complex Syst. 2004;15:1–40. [15] Hudcová B, Mikolov T. Computational hierarchy of elementary cellular automata. In: ALIFE 2021: The 2021 Confer- ence on Artificial Life. MIT Press; 2021. doi: 10.1162/isal_a_00447 [16] Glover TE, Jahren R, Huse Ramstad O, et al. Minimum equivalence in random boolean networks, elementary cellular automata, and beyond. In: Artificial Life Conference Proceedings 35. Cambridge, MA: MIT Press; One Rogers Street, 02142-1209, USA journals-info ..., 2023. [17] Gardner M. The fantastic combinations of john conway’s new solitaire game “life”. Sci Am. 1970;223:120–123. doi: 10.1038/scientificamerican1070-120 [18] Rendell P. A universal turing machine in conway’s game of life. In: 2011 International Conference on High Performance Computing & Simulation. IEEE; 2011. p. 764–772. [19] The Life Lexicon. Life-like cellular automata. 2024. [accessed 2024 February 23]. Available from: com/wiki/Cellular_automaton#Life-like_cellular_automata. [20] Eppstein D. Growth and Decay in Life–Like Cellular Automata. Game of Life Cellular Automata. London: Springer; 2010. p. 71–97. [21] Gershenson C. Classification of random boolean networks. arXiv preprint cs/0208001. 2002. [22] Kauffman SA. Cellular homeostasis, epigenesis and replication in randomly aggregated macromolecular systems. J Cybern. 1971;1:71–96. doi: 10.1080/01969727108545830 [23] Martinez GJ. A note on elementary cellular automata classification. arXiv preprint arXiv:1306.5577. 2013. [24] Kauffman SA. The origins of order: self-organization and selection in evolution. Oxford: Oxford University Press; 1993. [25] Kauffman SA. Requirements for evolvability in complex systems: orderly dynamics and frozen components. Phys D Nonlinear Phenom. 1990;42(1-3):135–152. doi: 10.1016/0167-278990071-V [26] Langton CG. Computation at the edge of chaos: phase transitions and emergent computation. Phys D Nonlinear Phenom. 1990;42(1-3):12–37. doi: 10.1016/0167-278990064-V [27] WuenscheA,LesserM.Globaldynamicsofcellularautomata:anatlasofbasinofattractionfieldsofone-dimensional cellular automata. Vol. 1. Boca Raton, FL: CRC Press; 1992. [28] Wuensche A. Basin of attraction fields of disordered cellular automata networks. 1992. Available from: [29] Wuensche A. The Ghost in the Machine: Basins of Attraction of Random Boolean NetworksIn Artificial Life III Vol. XVII. Boston: Addison-Wesley; 1994. [30] Wuensche A. 1997. Attractor basins of discrete networks Cognitive Science Research Paper 461, Doctoral Disserta- tion, University of Sussex. [31] LiW.Phenomenologyofnonlocalcellularautomata. JStatPhys.1992Sept;68:829–882.doi:10.1007/BF01048877 [32] Walker CC. A study of a family of complex systems–an approach to the investigation of organisms’ behavior [Ph.D.]. University of Illinois at Urbana-Champaign, United States – Illinois, 1965. URL 302133130/citation/38D4271784FF4B1EPQ/1. [33] Walker CC. Behavior of a class of complex systems: the effect of system size on properties of terminal cycles. J Cybern. 1971 Jan;1:55–67. doi: 10.1080/01969727108542902 [34] Walker CC, Ashby WR. On temporal characteristics of behavior in certain complex systems. Kybernetik. 1966 May;3:100–108. doi: 10.1007/BF00299903 [35] Marr C, Hütt M-T. Outer-totalistic cellular automata on graphs. Phys Lett A. 2009;373:546–549. doi: 10.1016/j.phy sleta.2008.12.013 [36] Grattarola D, Livi L, Alippi C. Learning graph cellular automata. Adv Neural Inf Process Syst. 2021;34:20983–20994. [37] Bhattacharjee K, Naskar N, Roy S, et al. A survey of cellular automata: types, dynamics, non-uniformity and applications. Nat Comput. 2020;19:433–461. doi: 10.1007/s11047-018-9696-8 [38] Cattaneo G, Dennunzio A, Formenti E, et al. Non-uniform cellular automata. In: Language and Automata Theory and Applications: Third International Conference, LATA 2009, Tarragona, Spain, April 2-8, 2009. Proceedings 3. Springer; 2009. p. 302–313. [39] Wolfram S. Theory and applications of cellular automata. Singapore: World Scientific; 1986. [40] Wolfram S. Tables of cellular automaton properties. Singapore: World Scientific; 1986 [41] Li W, Packard N. The structure of the elementary cellular automata rule space. Complex Systems. 1990;4:281–297. [42] Wolfram Research. Wolfram atlas of the dependancies of neighbours for ECA. 2024. [accessed 2024 February 8]. Available from: [43] Kolesov AY, Rozov NK. On the definition of’chaos’. Russ Math Surv. 2009;64:701. doi: 10.1070/RM2009v064n04 ABEH004631 INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 97 [44] Touhey P. Yet another definition of chaos. Am Math Mon. 1997;104:411–414. doi: 10.1080/00029890.1997.1199 0658 [45] Devaney R. An introduction to chaotic dynamical systems. 3rd ed. Boca Raton, FL: CRC Press; 2022. [46] Banks J, Brooks J, Cairns G, et al. On devaney’s definition of chaos. Am Math Mon. 1992;99:332–334. doi: 10.1080/00029890.1992.11995856 [47] Pope SB. Turbulent flows. Cambridge: Cambride University Press; 2000. [48] Lorenz EN. Deterministic nonperiodic flow. J Atmos Sci. 1963;20:130–141. doi: 10.1175/1520-0469020¡ 0130:DNF¿2.0.CO;2 [49] Elaydi SN. Discrete chaos: with applications in science and engineering. Boca Raton, FL: Chapman and Hall/CRC; 2007. [50] Kaneko K, Tsuda I. Complex systems: chaos and beyond: chaos and beyond: A constructive approach with applications in life sciences. Berlin, Germany: Springer Science & Business Media; 2001. [51] May RM. Simple mathematical models with very complicated dynamics. Nature. 1976;261:459–467. doi: 10.1038/261459a0 [52] Wolfram S, Gad-el Hak M. A new kind of science. Appl Mech Rev. 2003;56:B18–B19. doi: 10.1115/1.1553433 [53] Cattaneo G, Formenti E, Manzini G, et al. Ergodicity, transitivity, and regularity for linear cellular automata over zm. Theor Comput Sci. 2000;233(1-2):147–164. doi: 10.1016/S0304-397500005-X [54] Manzini G, Margara L. A complete and efficiently computable topological classification of d-dimensional linear cellular automata over zm. Theor Comput Sci. 1999;221(1-2):157–177. doi: 10.1016/S0304-397500031-6 [55] ShannonCE.Amathematicaltheoryofcryptography.1945.Availablefrom: 45.html [56] Bhattacharjee K, Paul D, Das S. Pseudo-random number generation using a 3-state cellular automaton. Int J Modern Phys C. 2017;28:1750078. [57] Jaeger H. The “echo state” approach to analysing and training recurrent neural networks-with an erratum note. Bonn Germany: Ger Nat Res Center Inf Technol GMD Tech Rep. 2001;148:13. [58] Maass W, Natschläger T, Markram H. Real-time computing without stable states: A new framework for neural computation based on perturbations. Neural Comput. 2002;14:2531–2560. doi: 10.1162/089976602760407955 [59] Tanaka G, Yamane T, Héroux JB, et al. Recent advances in physical reservoir computing: a review. Neural Netw. 2019;115:100–123. doi: 10.1016/j.neunet.2019.03.005 [60] Gallicchio C, Micheli A. Deep reservoir computing: A critical analysis. In: Proceedings of the 24th European Symposium on Artificial Neural Networks (ESANN), Bruges, Belgium; 27–29 April 2016. p. 497–502. [61] Fernando C, Sojakka S. Pattern recognition in a bucket. In: European Conference on Artificial Life. Springer; 2003. p. 588–597. [62] Aaser P, Knudsen M, Ramstad OH, et al. Towards making a cyborg: a closed-loop reservoir-neuro system. In: Artificial Life Conference Proceedings 14. MIT Press; 2017. p. 430–437. [63] Nikolic D, Haeusler S, Singer W, et al. Temporal dynamics of information content carried by neurons in the primary visual cortex. In: Proc. of NIPS 2006, Advances in Neural Information Processing Systems, volume 19. MIT Press; 2007. p. 1041–1048. [64] Dai X. Genetic regulatory systems modeled by recurrent neural network. In: International Symposium on Neural Networks. Springer; 2004. p. 519–524. [65] Jones B, Stekel D, Rowe J, et al. Is there a liquid state machine in the bacterium escherichia coli? In: 2007 IEEE Symposium on Artificial Life. IEEE; 2007. p. 187–191. [66] Jaeger H. Echo state network. Scholarpedia. 2007;2:2330. doi: 10.4249/scholarpedia.2330. revision #196567 [67] Grigoryeva L, Ortega J-P. Echo state networks are universal. Neural Netw. 2018;108:495–508. doi: 10.1016/j.neunet. 2018.08.025 [68] Yilmaz O. Reservoir computing using cellular automata. arXiv preprint arXiv:1410.0162. 2014. [69] Wolfram Research. Wolfram atlas of the boolean form of ECA. 2024. [accessed 2024 June 19]. Available from: [70] MoránA,FrasserCF,RocaM,etal.Energy-efficientpatternrecognitionhardwarewithelementarycellularautomata. IEEE Trans Comput. 2019;69:392–401. [71] Olin-Ammentorp W, Beckmann K, Cady NC. Cellular memristive-output reservoir (CMOR). arXiv preprint arXiv:1906.06414, 2019. [72] LiangD,HashimotoM,AwanoH.Bloomca:amemoryefficientreservoircomputinghardwareimplementationusing cellular automata and ensemble bloom filter. In: 2021 Design, Automation & Test in Europe Conference & Exhibition (DATE). IEEE; 2021. p. 587–590. [73] Nichele S, Molund A. Deep learning with cellular automaton-based reservoir computing. Compl Syst. 2017;26: 319–339. doi: 10.25088/ComplexSystems [74] Nichele S, Gundersen MS. Reservoir computing using non-uniform binary cellular automata. arXiv preprint arXiv:1702.03812. 2017. [75] Margem M, Gedik OS. Reservoir computing based on cellular automata (RECA) in sequence learning. Journal of Cellular Automata. 2019;14(1-2):153–170. 98 T. E. GLOVER ET AL. [76] Babson N, Teuscher C. Reservoir computing with complex cellular automata. Compl Syst. 2019;28:433–455. doi: 10.25088/ComplexSystems [77] Uragami D, Gunji Y-P. Universal criticality in reservoir computing using asynchronous cellular automata. Compl Syst. 2022;31:103–121. [78] Margem M, Gedik OS. Feed-forward versus recurrent architecture and local versus cellular automata distributed representation in reservoir computing for sequence memory learning. Artif Intell Rev. 2020;53:5083–5112. doi: 10.1007/s10462-020-09815-8 [79] GloverTE,LindP,YazidiA,etal.Thedynamicallandscapeofreservoircomputingwithelementarycellularautomata. In: ALIFE 2021: The 2021 Conference on Artificial Life. MIT Press; 2021. [80] Glover TE, Lind P, Yazidi A, et al. Investigating rules and parameters of reservoir computing with elementary cellular automata, with a criticism of rule 90 and the five-bit memory benchmark. Compl Syst. 2023;32:309–351. [81] Glover T, Osipov E, Nichele S. On when is reservoir computing with cellular automata beneficial? arXiv preprint arXiv:2407.09501. 2024. [82] McDonald N. Reservoir computing & extreme learning machines using pairs of cellular automata rules. In: 2017 International Joint Conference on Neural Networks (IJCNN). IEEE; 2017. p. 2429–2436. [83] Kantic J, Legl FC, Stechele W, et al. Relicada: reservoir computing using linear cellular automata design algorithm. Compl Intell Syst. 2024;10:3593–3616. [84] Snyder D, Goudarzi A, Teuscher C. Finding optimal random boolean networks for reservoir computing. In: Artificial Life Conference Proceedings. Citeseer; 2012. p. 259–266. [85] Snyder D, Goudarzi A, Teuscher C. Computational capabilities of random automata networks for reservoir comput- ing. Phys Rev E. 2013;87:042808. doi: 10.1103/PhysRevE.87.042808 [86] Burkow AV. Evolving functionally equivalent reservoirs for rbn reservoir computing systems. Orwegian University of Science and Technology (NTNU). 2015. (Technical report). [87] Burkow AV. Exploring physical reservoir computing using random boolean networks [Master’s thesis]. NTNU; 2016. [88] Calvet E, Reulet B, Rouat J. The connectivity degree controls the difficulty in reservoir design of random boolean networks. Front Comput Neurosci. 2024;18:1348138. doi: 10.3389/fncom.2024.1348138 [89] Jahren R. Comparison and benchmarking of reservoir computing using cellular automata and random Boolean networks as substrates [Master’s thesis]. OsloMet-storbyuniversitetet; 2022. [90] Johansson O. Text classification with cellular automata networks [Master’s thesis]. Chalmers University of Technol- ogy; 2024. [91] Hochreiter S, Schmidhuber J. Long short-term memory. Neural Comput. 1997;9:1735–1780. doi: 10.1162/neco. 1997.9.8.1735 [92] Martens J, Sutskever I. Learning recurrent neural networks with Hessian-free optimization. In: Proceedings of the 28th International Conference on Machine Learning (ICML). Bellevue, Washington, USA; 2011. p.1033–1040. [93] Sutskever I. Training recurrent neural networks. Toronto (ON): University of Toronto; 2013. [94] Jaeger H. Long short-term memory in echo state networks: details of a simulation study. Jacobs University Bremen; 2012. (Technical report). [95] Watts DJ, Strogatz SH. Collective dynamics of ‘small-world’networks. Nature. 1998;393:440–442. doi: 10.1038/30918 [96] Derrida B, Weisbuch G. Evolution of overlaps between configurations in random boolean networks. J Phys. 1986;47:1297–1303. doi: 10.1051/jphys:019860047080129700 [97] Fretter C, Szejka A, Drossel B. Perturbation propagation in random and evolved boolean networks. New J Phys. 2009;11:033005. doi: 10.1088/1367-2630/11/3/033005 [98] Wuensche A. Exploring discrete dynamics. Bristol, England: Luniver Press; 2011. [99] Adamatzky A, Wuensche A. On creativity and elementary cellular automata. Compl Syst. 2013;22:361–375. [100] Martinuzzi F. Reservoir computing with two dimensional cellular automata. 2020. [accessed 2024 June 26]. [101] GloverTE,JahrenR.linkforsourcecodeandresults,2024Jul. = 0a637000ced0453eb 78ef2f2365701a0. [102] Pontes-Filho S, Lind P, Yazidi A, et al. Evodynamic: a framework for the evolution of generally represented dynamical systems and its application to self-organized criticality. EasyChair; 2019. (Technical report). [103] Pedregosa F, Varoquaux G, Gramfort A, et al. Scikit-learn: machine learning in python. J Mach Learn Res. 2011;12:2825–2830. [104] Martinuzzi F. Life-like cellular automata as a substrate for computation. Early access to a pre-print version of the paper. 2022. [105] Peña E, Sayama H. Life worth mentioning: complexity in life-like cellular automata. Artif Life. 2021;27:105–112. doi: 10.1162/artl_a_00348 [106] Research W. Wolfram atlas example of rule 54. 2024. [accessed 2024 June 24]. Available from: com/01/01/54/01_01_22_54.gif. [107] Sánchez-Puig F, Zapata O, Pineda OK, et al. Heterogeneity extends criticality. arXiv preprint arXiv:2208.06439. 2022. INTERNATIONAL JOURNAL OF PARALLEL, EMERGENT AND DISTRIBUTED SYSTEMS 99 [108] Jafet López-Díaz A, Sánchez-Puig F, Gershenson C. Temporal, structural, and functional heterogeneities extend criticality and antifragility in random boolean networks. Entropy. 2023;25:254. doi: 10.3390/e25020254 [109] Wolfram S. Universality and complexity in cellular automata. Phys D Nonlinear Phenom. 1984;10(1-2):1–35. doi: 10.1016/0167-278990245-8 [110] Credit author statement. 2024. [accessed 2024 July 3]. guidelines/credit-author-statement.","Elementary Cellular Automata (ECA) are well-studied computational uni- verses capable of impressive computational variety, but harnessing their potential has been challenging. When combined with Reservoir Comput- ing (RC), harnessing this computation becomes feasible, and furthermore enables energy efficient AI. This study compares ECA reservoirs to topolog- ical heterogeneous and more biological plausible counterparts of Partially- Local CA (PLCA) and Homogeneous Homogeneous Random Boolean Net- works (HHRBN). Using the 5-bit memory benchmark, Temporal Derrida plots and collapse rate, finding are that more disordered topology does not equate to more disordered computation and moreover the evidence suggest this heterogeneity shrinks the critical range. ARTICLE HISTORY Received 12 August 2024 Accepted 21 August 2024","['Tom Eivind Glover', 'Ruben Jahren', 'Francesco Martinuzzi', 'Pedro Gonçalves Lind', 'Stefano Nichele']"
Influence of neural network bursts on functional development,"Ramstad, Ola Huse and Sandvig, Axel and Nichele, Stefano and Sandvig, Ioanna",2025,missing,missing,bioRxiv,article,"1 
 
 
Influence of neural network bursts on 
functional development 
Ola Huse Ramstad1, Axel Sandvig1,2,3, Stefano Nichele4,5, Ioanna Sandvig1 
 
1Department of Neuromedicine and Movement Science, Faculty of Medicine, Norwegian University of Science 
and Technology, Trondheim, Norway 
2Department of Pharmacology and Clinical Neurosciences, Division of Neuro, Head and Neck, Umeå University 
Hospital, Umeå, Sweden, 
3Department of Community Medicine and Rehabilitation, Division of Neuro, Head and Neck, Umeå University 
Hospital, Umeå, Sweden 
4Department of Computer Science, Oslo Metropolitan University, Oslo, Norway 
5Department of Computer Science and Communication, Østfold University College, Halden, Norway 
 
Keywords: self-organization, wetware computing, electrophysiology, network dynamics, in 
vitro 
 
1 Abstract 
 Introduction 
2.1 
Background 
Neural networks in vitro almost invariably trend towards the propagation of network bursts [1]–
[7]. These network bursts, also termed population bursts [8] or synchronized burst events, are 
a common feature of maturation in dissociated in vitro networks across multiple cell types and 
experimental conditions [3], [6], [9]–[12]. Multiple hypotheses persist as to the origin of these 
network bursts including coupling of intrinsic oscillations [6], calcium transients [1], [13], 
hypometabolic responses [14], topological features, [15], [16] and pacemaker neurons [2], [10], 
[13], [16]–[19]. As dissociated neurons develop in vitro, mechanisms of self-organization and 
Hebbian plasticity increase both synchrony and the propagation of network bursts to the point 
where mature networks frequently contain most spiking activity within these population events 
.
CC-BY-NC-ND 4.0 International license
perpetuity. It is made available under a
preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in 
The copyright holder for this
this version posted January 22, 2025. 
; 
https://doi.org/10.1101/2025.01.21.633559
doi: 
bioRxiv preprint 
 2 
 
 
[13], [20], [21]. This prevalence of network bursting can thus dominate the activity of the in 
vitro network, pushing out more varied and complex activity [22]–[24], and in turn reduce its 
information capacity in terms of short-term computations [25]–[27].  
A better understanding of network bursts and, thereby, our ability to control them can 
significantly improve the validity of in vitro neural networks as computational substrates [23]. 
As others have posited [3], [20], [23], [28], this form of continuous bursting activity represents 
a key step in the normal development of cortical neurons in vivo by creating an increased 
synchrony between the neurons in the network. However, the lack of thalamic input, or indeed 
any external input to drive the in vitro networks beyond this activity is a challenge. Arguably 
the only input provided to developing in vitro neural networks is mechanical perturbation 
during media change and recording. Thus, the network burst persistence likely represents a form 
of arrested development, though the cause of this developmental plateau is still unknown. 
2.2 
Problem 
We posit that the network bursts, originating from pacemakers or burst initiation zones [2], act 
as the main drivers of the network’s functional development. Ultimately, this will be 
represented in the connectivity as an increasing efficiency towards propagation of signals from 
these pacemakers, decreasing the pathlength between this and all other nodes in the network. 
To show this we have utilized all dense network recordings provided by the Wagenaar, Pine & 
Potter dataset [3] to track both the initiation of network bursts, their stability and how the 
connectivity or propagation pattern of each network burst stabilizes to ensure this synchrony 
and ease of propagation. We have detected each network burst in the recordings, its origin point, 
spatiotemporal propagation pattern, the within and between recording stability of these patterns, 
and compared these to the developing functional connectivity and network metrics. We discuss 
identifying and selectively targeting such pacemakers during network development to enable 
more complex behaviour that better reflects the functional dynamics of in vivo networks. 
3 Methods 
3.1 
Dataset 
All data was obtained from Wagenaar et al., (2006), please see original article for details on 
experimental setup and spike detection. For this analysis, spike times from all dense (seeding 
density of 2.5 ± 1.5*103 cells per mm2) recordings of the dataset (n=521) were selected. All 
analysis was performed using MATLAB (R2021b, Mathworks). As detailed in the original 
article, recordings were affected by artefacts due to movement from the incubator to the 
recording stage. To remove the artefacts and reduce noise in the burst detection, the initial 200 
seconds of each recording were removed prior to analysis. Further, brief recordings (<5 minutes 
following artefact removal) were excluded to keep recordings of comparable length. In total, 
recordings from 30 microelectrode arrays (MEAs) across 8 batches were included, spanning 
DIV 3-39. 
3.2 
Burst detection 
Bursts were detected on a per electrode basis using the log interspike interval (logISI) method 
detailed by [29]. In brief, using a base 10 logISI histograms, bursts can be detected using 
adaptive interspike interval (ISI) thresholding as spikes in bursts typically display shorter ISI 
from those not contained in bursts. This divergence can be used to find a recording specific 
.
CC-BY-NC-ND 4.0 International license
perpetuity. It is made available under a
preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in 
The copyright holder for this
this version posted January 22, 2025. 
; 
https://doi.org/10.1101/2025.01.21.633559
doi: 
bioRxiv preprint 
 3 
 
 
maximum ISI for burst detection as the last local minima (or 100 ms if exceeded) on a logISI 
histograms and a minimum of 4 spikes within each interval. For burst centers, given a 100ms 
bin, the center of mass/activity is the weighted sum of firing rates for each neuron in the array. 
The distance between burst centers and the center of the array is given by the Euclidean distance 
between the cartesian coordinates of the center of mass and the coordinates [4.5, 4.5] in the 8x8 
array. 
3.3 
Network burst detection 
For network burst detection an adaptation was made to this method. Based on the bursts 
detected, a vector of burst times was generated for each recording. As each recording displayed 
a different burst length and profile which consistently changed across DIV, an adaptive binning 
for the network burst detection was used. Bursts were binned using the mode of the burst 
durations creating a bursts per bin vector. Taking the derivative of the bursts per bin allows the 
detection of network bursts as the positive peaks above the median burst rate or 3, whichever 
is higher. This number was selected to correspond to a minimum number of electrodes 
necessary for a network burst as well as differentiate those recordings with a high non-network 
burst rate. To find the start and end time of each network burst, the first bin before and after the 
peak with a derivative burst rate below the median was selected. As network bursts at early (10- 
14) and late (25+) DIV display greatly differing burst durations and shapes, this adaptive 
approach was necessary to detect and compare multiple types. 
3.4 
Burstiness index and pacemaker detection 
Burstiness index (BI) was calculated with a population (all electrodes) spike binning of bin size 
1s sorted in order of highest to lowest spike count and calculating fraction of spikes contained 
in the top 15% (f15) of the bins. This is then normalized as (f15-0.15)/0.85 [23]. Finally, 
pacemakers or burst initiation zones were selected as follows: the first electrode to burst 
following the start time of a detected network burst as noted, disregarding spurious 
electrodes with less than 2 activations per recording. Then we summed the number of times 
each electrode initiated a network burst across all recordings per MEA and defined pacemakers 
as those electrodes initiating at least 4% of network bursts [18], [30].  
3.5 
Similarity of network bursts  
For network burst alignment we created a vector of the time delay between the start of a network 
burst and the first spike which occurs at each electrode. That is, given a network burst lasting 
from time t(s) to t(e) what is the time delay to the first spike in this duration for each electrode. 
Time delays exceeding 1 second were discarded to better ensure spikes were related to the onset 
of the network burst. For each network burst a 1x59 vector of time delays was used to assess 
similarity. Once vectors of time delays are given for each network burst the similarity can be 
estimated giving a similarity matrix across all bursts. For all network bursts recorded per MEA 
the Euclidian distance between network bursts was estimated with missing values accounted 
for by using the root of squared distances scaled by the ratio of all electrodes to valid pairs.  
.
CC-BY-NC-ND 4.0 International license
perpetuity. It is made available under a
preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in 
The copyright holder for this
this version posted January 22, 2025. 
; 
https://doi.org/10.1101/2025.01.21.633559
doi: 
bioRxiv preprint 
 4 
 
 
 
Figure 1: LogISI plot and burstiness index across network development. (a) Early burst ISI (blue) show a peak 
(right) at longer intervals than late bursts (yellow) indicating that burst spiking becomes more rapid as the network 
matures. (b) The burstiness of the networks also increase with DIV (r = 0.62, p < 0.0001) across all batches and 
MEAs. 
3.6 
Functional connectivity 
Functional connectivity was estimated using cross-correlation and mutual information. First, 
spikes were binned in 100ms bins, and an initial correlation was estimated using Spearman’s 
rank correlation then filtered to discard correlations with p > 0.01 and r < 0.1. Remaining 
correlations were assessed using normalized cross-correlation with a bin size of 1ms and a 
maximum lag of ±100ms. Optimal lag times were selected based on the maximum correlation 
within the tested delays. Mutual information was calculated using 100ms bins, and each 
potential connection was tested for significance by comparing the initial mutual information to 
the mutual information of a randomly shuffled binning for the same connection. This shuffling 
was performed 100 times with connections deemed significant if the initial mutual information 
exceeded 95% of the shuffled cases. In comparing the effect of network burst propagation on 
network formation, the pacemakers were first detected as described in section 3.4. Using 
the detected pacemakers, the contribution of these nodes to the network development could be 
described. 
3.7 
Network metrics 
The characteristic path length is defined as the mean of the shortest path length between all 
pairwise nodes, where the distance between nodes i and j is defined as 1/wij using the 
optimal lag time. Betweenness and degree centrality were calculated using the path lengths as 
described. Clustering and modularity were estimated using mutual information. The clustering 
coefficient of a node was defined as the ratio of the number of connections between the node's 
neighbors to the maximum number of possible connections between them. The local coefficient 
of each node is calculated using the method by Onnela et al. [32] for weighted networks (Brain 
Connectivity toolbox, BCT). Modularity q was estimated using the Louvain method [33] as 
implemented in the BCT. For each network the modularity was calculated 20 times to account 
for variability in the community detection, with the q being given as the median of the 20 
estimates. Correlations between development (DIV), BI, and network metrics were performed 
with repeated measures correlation [34] to account for within-MEA associations across time. 
Correlation p-values below 0.0001 are reported as 0.0001.  
.
CC-BY-NC-ND 4.0 International license
perpetuity. It is made available under a
preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in 
The copyright holder for this
this version posted January 22, 2025. 
; 
https://doi.org/10.1101/2025.01.21.633559
doi: 
bioRxiv preprint 
 5 
 
 
 
Figure 2: Center of burst activity and stability over time. (a) Burst centers ordered from early (blue) to late (yellow) 
DIV. Marker size given by total spike count per 10ms burst frame. (b) As network bursts increase in spike count 
and electrode recruitment the burst centers weakly shift from peripheral to central locations on the array as seen 
by the decreasing mean distance from center (r = -0.25, p < 0.0001, mean shown in grey). (c) Network burst 
duration varies across MEA batches and time. Early (5-13) DIV network bursts show varied durations and shapes 
compared to later DIV though this differs between batches. (d) The starting electrodes of the network bursts are 
located on the outlying electrodes with a weak shift away from the central electrodes as the networks mature (r = 
0.26, p < 0.0001, mean shown in grey). 
4 Results 
4.1 
Burst development and stability 
As described, in vitro networks trend towards increased network bursting as they mature. By 
assessing the burstiness index (figure 1b) across DIV a clear trend (r = 0.62, p < 0.0001) 
towards increased bursting is evident across almost all batches. Yet as noted by [3] there is a 
more consistent trend within batches than between, with some batches (1,5,8) showing mostly 
burst confined spikes and others (3) only moderate increases. In addition to the increase in 
network burst prevalence the duration between spikes within bursts increases across 
development. By plotting the ISI between every spike t and t+10 we can see the shift in both 
burst contained and tonic firing across development (figure 1a). As the network matures the ISI 
within bursts decrease, as do ISI non-burst spikes. 
.
CC-BY-NC-ND 4.0 International license
perpetuity. It is made available under a
preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in 
The copyright holder for this
this version posted January 22, 2025. 
; 
https://doi.org/10.1101/2025.01.21.633559
doi: 
bioRxiv preprint 
 6 
 
 
This reduction in burst ISI does not necessarily mean that the durations of the network bursts 
themselves decrease at the same rate (figure 2c). The duration of network bursts is highly 
variable in the initial onset period between DIV 5-14 before they stabilize on brief durations 
between DIV 15-20 then gradually increase in length from DIV 20 onwards. These trends are 
also highly batch dependent with some MEAs showing short and stable network bursts from 
their onset. 
While spiking activity in general is evenly distributed across the electrode array, the bursting 
activity and especially network bursting is dependent on the network age (figure 2a). Initially 
the center of activity during bursting is confined to the edge of the array, near pacemakers or 
the initial electrode activated during a detected network burst. These centers of activity 
gradually shift (r = -0.25, p < 0.0001) towards the middle of the array as more electrodes are 
recruited during each network burst and the average spiking is more evenly distributed across 
the array (figure 2b). The initial electrode activated during network bursts stays consistent at 
the edge of the array (figure 2d) with a small change away from the center across the maturation 
of the network (r = 0.26, p < 0.0001). The reason for this is likely twofold, as network bursts 
originate outside the array they will first be detected at the edge, secondly, persistent paths 
develop along already active electrodes. The difference in pacemaker and non-pacemaker-
initiated network bursts were not significantly different (figure 3a) and burst alignment did 
not change across DIV (r = -0.04, p = 0.44). 
4.2 
Impact of pacemakers on network development 
Lag time pathlengths from pacemakers are consistently low across development in contrast to 
the giant component which decreases gradually (figure 4a). However, pacemakers are not 
Figure 3: Network burst alignment across DIV. (a) The alignment of time to first spike network burst patterns per 
day are not significantly different in bursts originating from pacemakers. (b) The network burst alignment is 
dependent on batch, with some batches trending towards increasing alignment across DIV (lower distance per 
day) while some remain stable. Overall burst alignment did not change across DIV (r = -0.04, p = 0.44). Mean 
alignment across all batches shown in grey. 
.
CC-BY-NC-ND 4.0 International license
perpetuity. It is made available under a
preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in 
The copyright holder for this
this version posted January 22, 2025. 
; 
https://doi.org/10.1101/2025.01.21.633559
doi: 
bioRxiv preprint 
 7 
 
 
central in the network nor connected to most nodes as both the degree (figure 4b) and 
betweenness (figure 4c) centrality are lower than the mean of the giant component. The 
mutual information and clustering coefficient increase over time (figure 4d-e) for the giant 
component while pacemakers show a small initial increase before plateauing. The modularity 
(figure 4f) started high early in development before decreasing between 5-15 DIV and plateauing 
from 20 DIV onwards. While the increase in mutual information (r = 0.53, p < 0.0001), 
clustering (r = 0.57, p < 0.0001) and BI (r = 0.62, p < 0.0001) over DIV is significant, there is 
only a weak correlation between mutual information and BI (r = 0.15, p < 0.0001). The decrease 
in modularity and increase in BI show a strong negative correlation (r = -0.45, p < 0.0001), 
contrasting the relationship with mutual information and BI. 
5 Discussion 
We hypothesized that network bursts, originating from areas of the network called pacemakers 
or burst initiation zones, act as a main driver of the in vitro network's functional development. 
To investigate this hypothesis, we utilized dense network recordings provided by the Wagenaar 
dataset to track the initiation, stability, and connectivity of network bursts. As the network 
develops, the efficiency of signal propagation increases, resulting in decreasing path 
lengths and increasing mutual information yet this only weakly corresponded with the BI. 
Further, the pathlengths of pacemakers were consistently lower than the network mean, 
however pacemakers were not central in the network as per betweenness and degree centrality. 
Considering that bursting networks show increasing levels of integration, network bursting may 
be enabling information to propagate more effectively across the network. However, without 
sufficient segregation, typically in the form of hierarchical modularity, this high integration 
Figure 4: Comparison of network characteristics on pacemakers (yellow) and giant component (blue). a-c 
calculated using lag times, d-f calculated using mutual information. Pathlengths (a) between pacemakers and 
other network nodes are shorter on average than random nodes, yet betweenness (b) and degree (c) centrality is 
lower than the network mean consistently across development. Clustering (d) and mutual information (e) increases 
for the giant component over time, while remaining low for pacemakers. Modularity (f) for the giant component 
begins high but rapidly declines until DIV 15 and plateaus from DIV 20 onwards.  
.
CC-BY-NC-ND 4.0 International license
perpetuity. It is made available under a
preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in 
The copyright holder for this
this version posted January 22, 2025. 
; 
https://doi.org/10.1101/2025.01.21.633559
doi: 
bioRxiv preprint 
 8 
 
 
does not lend itself to an increase in input separability. In this study we found a rapid initial 
decrease from high to low modularity before the q stabilized. Given the modularity 
maximization of the Louvain method, small size of the network, and homogeneity of the culture 
vessel it is possible this high initial modularity stemmed from spurious modules of a few 
interconnected electrodes which shifted to more stable modules which encompass the majority 
of the array. On larger MEAs and CMOS arrays,  Okujeni and Egert [2], [20], [35] 
demonstrated well the increased segregation which arises from physical neural aggregation, 
with subsequent increases in variability of activity and reduced recruitment from network 
bursts. The issue with continuous network bursts is twofold in terms of computation [36], firstly, 
the increase in synchrony reduces the network segregation and eventual diversity of activity. 
Secondly, the onset of a network burst typically means ongoing spiking activity is superseded by 
the network burst, thus putting a limit on short term computations, including fading memory, 
equivalent to the length of interburst intervals. Note that the term computation is often non-
specific and context dependent, we use the term here specifically to denote the use of in vitro 
networks for applied computational tasks, such as performance in robot/animat control [37]–
[40], or in terms of physical reservoir computing [41]–[44]. 
To increase the computational viability of in vitro culture it is necessary to find approaches that 
reduce the long term impact of network bursts [23]. Though certain neurons in a network are 
likely more intrinsically active [10], it is probable that the network burst initiation seen in vitro 
arises from self-organization as detailed by Penn et al. [45] and Lonardoni et al. [46]. 
Disrupting the development of network bursts therefore would mean disrupting the self-
organization itself, either through perturbing neurite growth [20], establishing compartments 
[47], [48], complex cell composition [49], [50] or altering the inhibitory–excitatory balance 
[51]. In our previous work we have impeded the propagation of network bursts by the addition 
of global GABAergic inhibition to the cultures [52], though this method is transient due to the 
rapid uptake and recycling of free GABA. A more long-term solution based on the excitation-
inhibition ratio will entail altering the prevalence of interneurons or their connectivity in the 
networks [50]. Future studies may benefit from further exploring the role of the excitation-
inhibition ratio in this context [53]. 
Most studies on MEAs using dissociated neurons perform recordings in the period 14 to 40 
DIV, regardless of species of origin or cell type. Synchronizing population bursting also occurs 
in vivo in rodents during late embryonic and early postnatal cortical development before 
typically declining as non-local input increases [54], [55]. The timescale for this initiation and 
decline of population bursting therefore occurs on shorter timescales than the typical recording 
period of MEA studies. Yet as reductionist models, dissociated cultures are lacking key features 
of neural development including glial cell and extracellular matrix (ECM) composition, three- 
dimensional structure, and gradient compartmentalization. Induced pluripotent stem cells 
(IPSCs) do recapture some of these factors in terms of their cell composition and matrix 
complexity, but more importantly studies on IPSCs frequently extend across months and up to 
a year in length [49], [56], [57]. While IPSCs do show a similar trend in network bursting early 
in development, some IPSC networks eventually stabilize and decline in burstiness depending 
on the differentiation protocol in contrast to rat cortical neurons which can sustain bursting up 
to two years [3], [58]. Extending recording periods beyond the standard 30-40 DIV may 
therefore capture more variable activity depending on the cell type. 
.
CC-BY-NC-ND 4.0 International license
perpetuity. It is made available under a
preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in 
The copyright holder for this
this version posted January 22, 2025. 
; 
https://doi.org/10.1101/2025.01.21.633559
doi: 
bioRxiv preprint 
 9 
 
 
In studies utilizing in vitro networks for computations, stimulations or inputs to the networks 
are usually applied to random electrodes to reduce bias, or central electrodes to capture as much 
of the resulting response as possible[38], [40], [58], [59]. Some studies improve upon this by 
selecting more active electrodes, yet the network structure itself is rarely considered in terms 
of input and output selection [38], [60]. Given that neural networks in vitro self-organize to 
propagate network bursts, either due to developmental set points or as a function of culture 
conditions, more care should be taken to both optimize integration and segregation of inputs by 
considering the network structure. Utilizing pacemakers as input points while concurrently 
increasing the heterogeneity and complexity of in vitro networks should enable better 
computational capacity than is currently achievable with these networks. 
 
Data availability: All 
original 
data 
is 
available 
on 
https://neurodatasharing.bme.gatech.edu/development-data/html/index.html 
 
Acknowledgements: Funding was provided by the DeepCA project (Research Council of 
Norway, Young Research Talent grant agreement 286558). 
 
Author contributions: OHR: conceptualization, methodology, data and statistical analysis 
writing. SN, AS, IS: conceptualization, writing, review, and editing. All authors contributed to 
the article and approved the submitted version. 
6 References 
[1] 
T. Opitz, A. D. De Lima, and T. Voigt, “Spontaneous development of synchronous 
oscillatory activity during maturation of cortical networks in vitro,” J. Neurophysiol., 
vol. 88, no. 5, pp. 2196–2206, 2002, doi: 10.1152/jn.00316.2002. 
[2] 
S. Okujeni and U. Egert, “Inhomogeneities in network structure and excitability govern 
initiation and propagation of spontaneous burst activity,” Front. Neurosci., vol. 13, no. 
MAY, pp. 1–14, 2019, doi: 10.3389/fnins.2019.00543. 
[3] 
D. A. Wagenaar, J. Pine, and S. M. Potter, “An extremely rich repertoire of bursting 
patterns during the development of cortical cultures,” BMC Neurosci., vol. 7, pp. 1–18, 
Feb. 2006, doi: 10.1186/1471-2202-7-11. 
[4] 
D. A. Wagenaar, Z. Nadasdy, and S. M. Potter, “Persistent dynamic attractors in activity 
patterns of cultured neuronal networks,” Phys. Rev. E - Stat. Nonlinear, Soft Matter 
Phys., vol. 73, no. 5, 2006, doi: 10.1103/PhysRevE.73.051907. 
[5] 
M. Chiappalone, M. Bove, A. Vato, M. Tedesco, and S. Martinoia, “Dissociated cortical 
networks show spontaneously correlated activity patterns during in vitro development,” 
Brain Res., vol. 1093, no. 1, pp. 41–53, Jun. 2006, doi: 10.1016/j.brainres.2006.03.049. 
[6] 
Y. Penn, M. Segal, and E. Moses, “Network synchronization in hippocampal neurons,” 
Proc. Natl. Acad. Sci. U. S. A., vol. 113, no. 12, pp. 3341–3346, Mar. 2016, doi: 
10.1073/pnas.1515105113. 
[7] 
J. Van Pelt, M. A. Corner, P. S. Wolters, W. L. C. Rutten, and G. J. A. Ramakers, 
“Longterm stability and developmental changes in spontaneous network burst firing 
patterns in dissociated rat cerebral cortex cell cultures on multielectrode arrays,” 
Neurosci. 
Lett., 
vol. 
361, 
no. 
1–3, 
pp. 
86–89, 
May 
2004, 
doi: 
10.1016/j.neulet.2003.12.062. 
[8] 
J. H. Kim, H. J. Lee, W. Choi, and K. J. Lee, “Encoding information into autonomously 
bursting neural network with pairs of time-delayed pulses,” Sci. Rep., vol. 9, no. 1, pp. 
.
CC-BY-NC-ND 4.0 International license
perpetuity. It is made available under a
preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in 
The copyright holder for this
this version posted January 22, 2025. 
; 
https://doi.org/10.1101/2025.01.21.633559
doi: 
bioRxiv preprint 
 10 
 
 
1–11, 2019, doi: 10.1038/s41598-018-37915-7. 
[9] 
P. Darbon, L. Scicluna, A. Tscherter, and J. Streit, “Mechanisms controlling bursting 
activity induced by disinhibition in spinal cord networks,” Eur. J. Neurosci., vol. 15, no. 
4, pp. 671–683, 2002, doi: 10.1046/j.1460-9568.2002.01904.x. 
[10] S. Illes et al., “Intrinsically active and pacemaker neurons in pluripotent stem cell-
derived neuronal populations,” Stem Cell Reports, vol. 2, no. 3, pp. 323–336, 2014, doi: 
10.1016/j.stemcr.2014.01.006. 
[11] S. Dauth et al., “Neurons derived from different brain regions are inherently different in 
vitro: a novel multiregional brain-on-a-chip,” J. Neurophysiol., vol. 117, no. 3, pp. 1320–
1341, 2017, doi: 10.1152/jn.00575.2016. 
[12] M. Brofiga, F. Callegari, L. Cerutti, M. Tedesco, and P. Massobrio, “Cortical, striatal, 
and thalamic populations self-organize into a functionally connected circuit with long-
term memory properties,” Biosens. Bioelectron., vol. 267, no. June 2024, p. 116840, 
2025, doi: 10.1016/j.bios.2024.116840. 
[13] S. Okujeni and U. Egert, “Self-organization of modular network architecture by activity-
dependent neuronal migration and outgrowth,” Elife, vol. 8, Sep. 2019, doi: 
10.7554/eLife.47996. 
[14] P. Joo, H. Lee, S. Wang, S. Kim, and A. G. Hudetz, “Network Model With Reduced 
Metabolic Rate Predicts Spatial Synchrony of Neuronal Activity,” Front. Comput. 
Neurosci., vol. 15, no. October, pp. 1–12, Oct. 2021, doi: 10.3389/fncom.2021.738362. 
[15] D. Eytan and S. Marom, “Dynamics and effective topology underlying synchronization 
in networks of cortical neurons,” J. Neurosci., vol. 26, no. 33, pp. 8465–8476, Aug. 2006, 
doi: 10.1523/JNEUROSCI.1627-06.2006. 
[16] T. A. Gritsun, J. le Feber, and W. L. C. Rutten, “Growth Dynamics Explain the 
Development of Spatiotemporal Burst Activity of Young Cultured Neuronal Networks 
in Detail,” PLoS One, vol. 7, no. 9, Sep. 2012, doi: 10.1371/journal.pone.0043352. 
[17] T. A. Gritsun, J. Le Feber, J. Stegenga, and W. L. C. Rutten, “Network bursts in cortical 
cultures are best simulated using pacemaker neurons and adaptive synapses,” Biol. 
Cybern., vol. 102, no. 4, pp. 293–310, Apr. 2010, doi: 10.1007/s00422-010-0366-x. 
[18] M. I. Ham, L. M. Bettencourt, F. D. McDaniel, and G. W. Gross, “Spontaneous 
coordinated activity in cultured networks: Analysis of multiple ignition sites, primary 
circuits, and burst phase delay distributions,” J. Comput. Neurosci., vol. 24, no. 3, pp. 
346–357, 2008, doi: 10.1007/s10827-007-0059-1. 
[19] M. Brofiga et al., “Multiple neuron clusters on Micro-Electrode Arrays as an in vitro 
model of brain network,” Sci. Rep., vol. 13, no. 1, pp. 1–15, 2023, doi: 10.1038/s41598-
023-42168-0. 
[20] S. Okujeni, S. Kandler, and U. Egert, “Mesoscale architecture shapes initiation and 
richness of spontaneous network activity,” J. Neurosci., vol. 37, no. 14, pp. 3972–3987, 
Apr. 2017, doi: 10.1523/JNEUROSCI.2552-16.2017. 
[21] A. El Hady et al., “Optogenetic stimulation effectively enhances intrinsically generated 
network synchrony.,” Front. Neural Circuits, vol. 7, no. October, p. 167, 2013, doi: 
10.3389/fncir.2013.00167. 
[22] I. Colombi, T. Nieus, M. Massimini, and M. Chiappalone, “Spontaneous and 
perturbational complexity in cortical cultures,” Brain Sci., vol. 11, no. 11, Nov. 2021, 
doi: 10.3390/brainsci11111453. 
[23] D. A. Wagenaar, R. Madhavan, J. Pine, and S. M. Potter, “Controlling bursting in cortical 
cultures with closed-loop multi-electrode stimulation,” J. Neurosci., vol. 25, no. 3, pp. 
680–688, Jan. 2005, doi: 10.1523/JNEUROSCI.4209-04.2005. 
[24] K. Heiney, O. Huse Ramstad, V. Fiskum, A. Sandvig, I. Sandvig, and S. Nichele, 
“Neuronal avalanche dynamics and functional connectivity elucidate information 
.
CC-BY-NC-ND 4.0 International license
perpetuity. It is made available under a
preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in 
The copyright holder for this
this version posted January 22, 2025. 
; 
https://doi.org/10.1101/2025.01.21.633559
doi: 
bioRxiv preprint 
 11 
 
 
propagation 
in 
vitro,” 
Front. 
Neural 
Circuits, 
vol. 
16, 
2022, 
doi: 
10.3389/fncir.2022.980631. 
[25] M. R. Dranias, H. Ju, E. Rajaram, and A. M. J. VanDongen, “Short-term memory in 
networks of dissociated cortical neurons,” J. Neurosci., vol. 33, no. 5, pp. 1940–1953, 
2013, doi: 10.1523/JNEUROSCI.2718-12.2013. 
[26] H. Ju, M. R. Dranias, G. Banumurthy, and A. M. J. Vandongen, “Spatiotemporal memory 
is an intrinsic property of networks of dissociated cortical neurons,” J. Neurosci., vol. 
35, no. 9, pp. 4040–4051, 2015, doi: 10.1523/JNEUROSCI.3793-14.2015. 
[27] M. R. Dranias, M. B. Westover, S. Cash, and A. M. J. Vandongen, “Stimulus information 
stored in lasting active and hidden network states is destroyed by network bursts,” Front. 
Integr. Neurosci., vol. 9, no. FEB, pp. 1–17, 2015, doi: 10.3389/fnint.2015.00014. 
[28] I. Colombi, F. Tinarelli, V. Pasquale, V. Tucci, and M. Chiappalone, “A simplified in 
vitro experimental model encompasses the essential features of sleep,” Front. Neurosci., 
vol. 10, no. JUL, 2016, doi: 10.3389/fnins.2016.00315. 
[29] D. J. Bakkum, M. Radivojevic, U. Frey, F. Franke, A. Hierlemann, and H. Takahashi, 
“Parameters for burst detection,” Front. Comput. Neurosci., vol. 7, no. January, pp. 1–
12, 2014, doi: 10.3389/fncom.2013.00193. 
[30] V. Pasquale, S. Martinoia, and M. Chiappalone, “Stimulation triggers endogenous 
activity patterns in cultured cortical networks,” Sci. Rep., vol. 7, no. 1, pp. 1–16, 2017, 
doi: 10.1038/s41598-017-08369-0. 
[31] V. Pasquale, S. Martinoia, and M. Chiappalone, “Stimulation triggers endogenous 
activity patterns in cultured cortical networks,” Sci. Rep., vol. 7, no. 1, p. 9080, Dec. 
2017, doi: 10.1038/s41598-017-08369-0. 
[32] J.-P. Onnela, J. Saramäki, J. Kertész, and K. Kaski, “Intensity and coherence of motifs 
in weighted complex networks,” Phys. Rev. E, vol. 71, no. 6, p. 065103, Jun. 2005, doi: 
10.1103/PhysRevE.71.065103. 
[33] V. D. Blondel, J. L. Guillaume, R. Lambiotte, and E. Lefebvre, “Fast unfolding of 
communities in large networks,” J. Stat. Mech. Theory Exp., vol. 2008, no. 10, 2008, doi: 
10.1088/1742-5468/2008/10/P10008. 
[34] J. Z. Bakdash and L. R. Marusich, “Repeated measures correlation,” Front. Psychol., 
vol. 8, no. MAR, pp. 1–13, 2017, doi: 10.3389/fpsyg.2017.00456. 
[35] S. Okujeni and U. Egert, “Self-organization of modular network architecture by activity-
dependent neuronal migration and outgrowth,” Elife, vol. 8, Sep. 2019, doi: 
10.7554/eLife.47996. 
[36] G. Tanaka et al., “Recent advances in physical reservoir computing: A review,” Neural 
Networks, vol. 115, pp. 100–123, 2019, doi: 10.1016/j.neunet.2019.03.005. 
[37] A. Novellino, P. D’Angelo, L. Cozzi, M. Chiappalone, V. Sanguineti, and S. Martinoia, 
“Connecting neurons to a mobile robot: An in vitro bidirectional neural interface,” 
Comput. Intell. Neurosci., vol. 2007, pp. 1–13, 2007, doi: 10.1155/2007/12725. 
[38] J. Tessadori and M. Chiappalone, “Closed-loop neuro-robotic experiments to test 
computational properties of neuronal networks,” J. Vis. Exp., vol. 2015, no. 97, 2015, 
doi: 10.3791/52341. 
[39] D. J. Bakkum, P. M. Gamblen, G. Ben-Ary, Z. C. Chao, and S. M. Potter, “MEART: 
The Semi-Living Artist.,” Front. Neurorobot., vol. 1, p. 5, Jan. 2007, doi: 
10.3389/neuro.12.005.2007. 
[40] S. M. Potter, D. A. Wagenaar, and T. B. DeMarse, “Closing the Loop: Stimulation 
Feedback Systems for Embodied MEA Cultures,” in Advances in Network 
Electrophysiology, vol. 9780387258, Springer US, 2006, pp. 215–242. 
[41] M. Dale, S. Stepney, J. F. Miller, and M. Trefzer, “Reservoir computing in materio: A 
computational framework for in materio computing,” Proc. Int. Jt. Conf. Neural 
.
CC-BY-NC-ND 4.0 International license
perpetuity. It is made available under a
preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in 
The copyright holder for this
this version posted January 22, 2025. 
; 
https://doi.org/10.1101/2025.01.21.633559
doi: 
bioRxiv preprint 
 12 
 
 
Networks, vol. 2017-May, pp. 2178–2185, 2017, doi: 10.1109/IJCNN.2017.7966119. 
[42] T. Gürel, S. Rotter, and U. Egert, “Functional identification of biological neural networks 
using reservoir adaptation for point processes,” J. Comput. Neurosci., vol. 29, no. 1–2, 
pp. 279–299, Aug. 2010, doi: 10.1007/s10827-009-0176-0. 
[43] W. Maass, T. Natschla, and H. Markram, “Fading memory and kernel properties of 
generic cortical microcircuit models q,” vol. 98, pp. 315–330, 2004, doi: 
10.1016/j.jphysparis.2005.09.020. 
[44] W. Maass, T. Natschläger, and H. Markram, “Real-Time Computing Without Stable 
States: A New Framework for Neural Computation Based on Perturbations,” Neural 
Comput., 
vol. 
14, 
no. 
11, 
pp. 
2531–2560, 
Nov. 
2002, 
doi: 
10.1162/089976602760407955. 
[45] Y. Penn, M. Segal, and E. Moses, “Network synchronization in hippocampal neurons,” 
Proc. Natl. Acad. Sci. U. S. A., vol. 113, no. 12, pp. 3341–3346, 2016, doi: 
10.1073/pnas.1515105113. 
[46] D. Lonardoni, H. Amin, S. Di Marco, A. Maccione, L. Berdondini, and T. Nieus, 
“Recurrently connected and localized neuronal communities initiate coordinated 
spontaneous activity in neuronal networks,” PLoS Comput. Biol., vol. 13, no. 7, Jul. 
2017, doi: 10.1371/journal.pcbi.1005672. 
[47] I. Baruchi, V. Volman, N. Raichman, M. Shein, and E. Ben-Jacob, “The emergence and 
properties of mutual synchronization in in vitro coupled cortical networks.,” Eur. J. 
Neurosci., vol. 28, no. 9, pp. 1825–35, Nov. 2008, doi: 10.1111/j.1460-
9568.2008.06487.x. 
[48] G. J. Brewer et al., “Toward a self-wired active reconstruction of the hippocampal 
trisynaptic loop: DG-CA3,” Front. Neural Circuits, vol. 7, no. OCT, pp. 1–8, 2013, doi: 
10.3389/fncir.2013.00165. 
[49] A. Odawara, H. Katoh, N. Matsuda, and I. Suzuki, “Induction of long-term potentiation 
and depression phenomena in human induced pluripotent stem cell-derived cortical 
neurons,” Biochem. Biophys. Res. Commun., vol. 469, no. 4, pp. 856–862, 2016, doi: 
10.1016/j.bbrc.2015.12.087. 
[50] S. Iida, K. Shimba, K. Sakai, K. Kotani, and Y. Jimbo, “Synchronous firing patterns of 
induced pluripotent stem cell-derived cortical neurons depend on the network structure 
consisting of excitatory and inhibitory neurons,” Biochem. Biophys. Res. Commun., vol. 
501, no. 1, pp. 152–157, Jun. 2018, doi: 10.1016/j.bbrc.2018.04.197. 
[51] H. Teppola, J. Aćimović, and M. L. Linne, “Unique Features of Network Bursts Emerge 
From the Complex Interplay of Excitatory and Inhibitory Receptors in Rat Neocortical 
Networks,” Front. Cell. Neurosci., vol. 13, Sep. 2019, doi: 10.3389/fncel.2019.00377. 
[52] K. Heiney, O. H. Ramstad, I. Sandvig, A. Sandvig, and S. Nichele, “Assessment and 
manipulation of the computational capacity of in vitro neuronal networks through 
criticality in neuronal avalanches,” in 2019 IEEE Symposium Series on Computational 
Intelligence, SSCI 2019, 2019, pp. 247–254, doi: 10.1109/SSCI44817.2019.9002693. 
[53] J. S. Weir, N. Christiansen, A. Sandvig, and I. Sandvig, “Selective inhibition of 
excitatory synaptic transmission alters the emergent bursting dynamics of in vitro neural 
networks,” Front. Neural Circuits, vol. 17, no. February, pp. 1–17, 2023, doi: 
10.3389/fncir.2023.1020487. 
[54] A. K. McCabe, S. L. Chisholm, H. L. Picken-Bahrey, and W. J. Moody, “The self-
regulating nature of spontaneous synchronized activity in developing mouse cortical 
neurones,” 
J. 
Physiol., 
vol. 
577, 
no. 
1, 
pp. 
155–167, 
2006, 
doi: 
10.1113/jphysiol.2006.117523. 
[55] R. Corlew, M. M. Bosma, and W. J. Moody, “Spontaneous, synchronous electrical 
activity in neonatal mouse cortical neurones,” J. Physiol., vol. 560, no. 2, pp. 377–390, 
.
CC-BY-NC-ND 4.0 International license
perpetuity. It is made available under a
preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in 
The copyright holder for this
this version posted January 22, 2025. 
; 
https://doi.org/10.1101/2025.01.21.633559
doi: 
bioRxiv preprint 
 13 
 
 
2004, doi: 10.1113/jphysiol.2004.071621. 
[56] A. Odawara, Y. Saitoh, A. H. Alhebshi, M. Gotoh, and I. Suzuki, “Long-term 
electrophysiological activity and pharmacological response of a human induced 
pluripotent stem cell-derived neuron and astrocyte co-culture.,” Biochem. Biophys. Res. 
Commun., vol. 443, no. 4, pp. 1176–81, Jan. 2014, doi: 10.1016/j.bbrc.2013.12.142. 
[57] K. Shimba, K. Sakai, Y. Takayama, K. Kotani, and Y. Jimbo, “Recording axonal 
conduction to evaluate the integration of pluripotent cell-derived neurons into a neuronal 
network.,” Biomed. Microdevices, vol. 17, no. 5, p. 94, Oct. 2015, doi: 10.1007/s10544-
015-9997-y. 
[58] S. M. Potter and T. B. DeMarse, “A new approach to neural cell culture for long-term 
studies,” J. Neurosci. Methods, vol. 110, no. 1–2, pp. 17–24, Sep. 2001, doi: 
10.1016/S0165-0270(01)00412-5. 
[59] A. Bruzzone, V. Pasquale, P. Nowak, J. Tessadori, P. Massobrio, and M. Chiappalone, 
“Interfacing in silico and in vitro neuronal networks,” in 2015 37th Annual International 
Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Aug. 
2015, vol. 2015-Novem, pp. 3391–3394, doi: 10.1109/EMBC.2015.7319120. 
[60] L. L. Bologna, T. Nieus, M. Tedesco, M. Chiappalone, F. Benfenati, and S. Martinoia, 
“Low-frequency stimulation enhances burst activity in cortical cultures during 
development,” 
Neuroscience, 
vol. 
165, 
no. 
3, 
pp. 
692–704, 
2010, 
doi: 
10.1016/j.neuroscience.2009.11.018. 
 
.
CC-BY-NC-ND 4.0 International license
perpetuity. It is made available under a
preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in 
The copyright holder for this
this version posted January 22, 2025. 
; 
https://doi.org/10.1101/2025.01.21.633559
doi: 
bioRxiv preprint 
",10.1101/2025.01.21.633559,doc35,"Network bursts or synchronized burst events are a typical activity seen in most in vitro neural 
networks. Network bursts arise early in development and as networks mature, activity becomes 
dominated by bursts propagating across the entirety of the network. The reason for this 
developmental plateau in vitro is unknown, but to bypass it would confer a significant 
advantage in the use of in vitro networks for computation. As most neurons in a network 
participate in network bursts, burst onset supersedes any ongoing activity thereby placing a 
limit on short term computations equal to the recovery period between bursts. By assessing 521 
multielectrode array recordings from day 4-39 in vitro we find that network bursts influence 
the connectivity, but this change is only weakly associated with the origin of the network bursts. 
The impacts of bursts on functional integration and segregation in neural networks are discussed 
along with approaches to mitigate the development and propagation of network bursts in vitro. 
Additionally, we hypothesize that burst initiation zones or pacemakers are viable targets for 
stimulation for computation in the context of control and reservoir computing. 
2","1 Influence of neural network bursts on functional development Ola Huse Ramstad1, Axel Sandvig1,2,3, Stefano Nichele4,5, Ioanna Sandvig1 1Department of Neuromedicine and Movement Science, Faculty of Medicine, Norwegian University of Science and Technology, Trondheim, Norway 2Department of Pharmacology and Clinical Neurosciences, Division of Neuro, Head and Neck, Umeå University Hospital, Umeå, Sweden, 3Department of Community Medicine and Rehabilitation, Division of Neuro, Head and Neck, Umeå University Hospital, Umeå, Sweden 4Department of Computer Science, Oslo Metropolitan University, Oslo, Norway 5Department of Computer Science and Communication, Østfold University College, Halden, Norway Keywords: self-organization, wetware computing, electrophysiology, network dynamics, in vitro 1 Abstract Introduction 2.1 Background Neural networks in vitro almost invariably trend towards the propagation of network bursts [1]– [7]. These network bursts, also termed population bursts [8] or synchronized burst events, are a common feature of maturation in dissociated in vitro networks across multiple cell types and experimental conditions [3], [6], [9]–[12]. Multiple hypotheses persist as to the origin of these network bursts including coupling of intrinsic oscillations [6], calcium transients [1], [13], hypometabolic responses [14], topological features, [15], [16] and pacemaker neurons [2], [10], [13], [16]–[19]. As dissociated neurons develop in vitro, mechanisms of self-organization and Hebbian plasticity increase both synchrony and the propagation of network bursts to the point where mature networks frequently contain most spiking activity within these population events . CC-BY-NC-ND 4.0 International license perpetuity. It is made available under a preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in The copyright holder for this this version posted January 22, 2025. ; doi: bioRxiv preprint 2 [13], [20], [21]. This prevalence of network bursting can thus dominate the activity of the in vitro network, pushing out more varied and complex activity [22]–[24], and in turn reduce its information capacity in terms of short-term computations [25]–[27]. A better understanding of network bursts and, thereby, our ability to control them can significantly improve the validity of in vitro neural networks as computational substrates [23]. As others have posited [3], [20], [23], [28], this form of continuous bursting activity represents a key step in the normal development of cortical neurons in vivo by creating an increased synchrony between the neurons in the network. However, the lack of thalamic input, or indeed any external input to drive the in vitro networks beyond this activity is a challenge. Arguably the only input provided to developing in vitro neural networks is mechanical perturbation during media change and recording. Thus, the network burst persistence likely represents a form of arrested development, though the cause of this developmental plateau is still unknown. 2.2 Problem We posit that the network bursts, originating from pacemakers or burst initiation zones [2], act as the main drivers of the network’s functional development. Ultimately, this will be represented in the connectivity as an increasing efficiency towards propagation of signals from these pacemakers, decreasing the pathlength between this and all other nodes in the network. To show this we have utilized all dense network recordings provided by the Wagenaar, Pine & Potter dataset [3] to track both the initiation of network bursts, their stability and how the connectivity or propagation pattern of each network burst stabilizes to ensure this synchrony and ease of propagation. We have detected each network burst in the recordings, its origin point, spatiotemporal propagation pattern, the within and between recording stability of these patterns, and compared these to the developing functional connectivity and network metrics. We discuss identifying and selectively targeting such pacemakers during network development to enable more complex behaviour that better reflects the functional dynamics of in vivo networks. 3 Methods 3.1 Dataset All data was obtained from Wagenaar et al., , please see original article for details on experimental setup and spike detection. For this analysis, spike times from all dense (seeding density of 2.5 ± 1.5*103 cells per mm2) recordings of the dataset (n=521) were selected. All analysis was performed using MATLAB (R2021b, Mathworks). As detailed in the original article, recordings were affected by artefacts due to movement from the incubator to the recording stage. To remove the artefacts and reduce noise in the burst detection, the initial 200 seconds of each recording were removed prior to analysis. Further, brief recordings (<5 minutes following artefact removal) were excluded to keep recordings of comparable length. In total, recordings from 30 microelectrode arrays (MEAs) across 8 batches were included, spanning DIV 3-39. 3.2 Burst detection Bursts were detected on a per electrode basis using the log interspike interval (logISI) method detailed by [29]. In brief, using a base 10 logISI histograms, bursts can be detected using adaptive interspike interval (ISI) thresholding as spikes in bursts typically display shorter ISI from those not contained in bursts. This divergence can be used to find a recording specific . CC-BY-NC-ND 4.0 International license perpetuity. It is made available under a preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in The copyright holder for this this version posted January 22, 2025. ; doi: bioRxiv preprint 3 maximum ISI for burst detection as the last local minima (or 100 ms if exceeded) on a logISI histograms and a minimum of 4 spikes within each interval. For burst centers, given a 100ms bin, the center of mass/activity is the weighted sum of firing rates for each neuron in the array. The distance between burst centers and the center of the array is given by the Euclidean distance between the cartesian coordinates of the center of mass and the coordinates [4.5, 4.5] in the 8x8 array. 3.3 Network burst detection For network burst detection an adaptation was made to this method. Based on the bursts detected, a vector of burst times was generated for each recording. As each recording displayed a different burst length and profile which consistently changed across DIV, an adaptive binning for the network burst detection was used. Bursts were binned using the mode of the burst durations creating a bursts per bin vector. Taking the derivative of the bursts per bin allows the detection of network bursts as the positive peaks above the median burst rate or 3, whichever is higher. This number was selected to correspond to a minimum number of electrodes necessary for a network burst as well as differentiate those recordings with a high non-network burst rate. To find the start and end time of each network burst, the first bin before and after the peak with a derivative burst rate below the median was selected. As network bursts at early (10- 14) and late (25+) DIV display greatly differing burst durations and shapes, this adaptive approach was necessary to detect and compare multiple types. 3.4 Burstiness index and pacemaker detection Burstiness index (BI) was calculated with a population (all electrodes) spike binning of bin size 1s sorted in order of highest to lowest spike count and calculating fraction of spikes contained in the top 15% (f15) of the bins. This is then normalized as (f15-0.15)/0.85 [23]. Finally, pacemakers or burst initiation zones were selected as follows: the first electrode to burst following the start time of a detected network burst as noted, disregarding spurious electrodes with less than 2 activations per recording. Then we summed the number of times each electrode initiated a network burst across all recordings per MEA and defined pacemakers as those electrodes initiating at least 4% of network bursts [18], [30]. 3.5 Similarity of network bursts For network burst alignment we created a vector of the time delay between the start of a network burst and the first spike which occurs at each electrode. That is, given a network burst lasting from time t(s) to t(e) what is the time delay to the first spike in this duration for each electrode. Time delays exceeding 1 second were discarded to better ensure spikes were related to the onset of the network burst. For each network burst a 1x59 vector of time delays was used to assess similarity. Once vectors of time delays are given for each network burst the similarity can be estimated giving a similarity matrix across all bursts. For all network bursts recorded per MEA the Euclidian distance between network bursts was estimated with missing values accounted for by using the root of squared distances scaled by the ratio of all electrodes to valid pairs. . CC-BY-NC-ND 4.0 International license perpetuity. It is made available under a preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in The copyright holder for this this version posted January 22, 2025. ; doi: bioRxiv preprint 4 Figure 1: LogISI plot and burstiness index across network development. (a) Early burst ISI (blue) show a peak (right) at longer intervals than late bursts (yellow) indicating that burst spiking becomes more rapid as the network matures. (b) The burstiness of the networks also increase with DIV (r = 0.62, p < 0.0001) across all batches and MEAs. 3.6 Functional connectivity Functional connectivity was estimated using cross-correlation and mutual information. First, spikes were binned in 100ms bins, and an initial correlation was estimated using Spearman’s rank correlation then filtered to discard correlations with p > 0.01 and r < 0.1. Remaining correlations were assessed using normalized cross-correlation with a bin size of 1ms and a maximum lag of ±100ms. Optimal lag times were selected based on the maximum correlation within the tested delays. Mutual information was calculated using 100ms bins, and each potential connection was tested for significance by comparing the initial mutual information to the mutual information of a randomly shuffled binning for the same connection. This shuffling was performed 100 times with connections deemed significant if the initial mutual information exceeded 95% of the shuffled cases. In comparing the effect of network burst propagation on network formation, the pacemakers were first detected as described in section 3.4. Using the detected pacemakers, the contribution of these nodes to the network development could be described. 3.7 Network metrics The characteristic path length is defined as the mean of the shortest path length between all pairwise nodes, where the distance between nodes i and j is defined as 1/wij using the optimal lag time. Betweenness and degree centrality were calculated using the path lengths as described. Clustering and modularity were estimated using mutual information. The clustering coefficient of a node was defined as the ratio of the number of connections between the node's neighbors to the maximum number of possible connections between them. The local coefficient of each node is calculated using the method by Onnela et al. [32] for weighted networks (Brain Connectivity toolbox, BCT). Modularity q was estimated using the Louvain method [33] as implemented in the BCT. For each network the modularity was calculated 20 times to account for variability in the community detection, with the q being given as the median of the 20 estimates. Correlations between development (DIV), BI, and network metrics were performed with repeated measures correlation [34] to account for within-MEA associations across time. Correlation p-values below 0.0001 are reported as 0.0001. . CC-BY-NC-ND 4.0 International license perpetuity. It is made available under a preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in The copyright holder for this this version posted January 22, 2025. ; doi: bioRxiv preprint 5 Figure 2: Center of burst activity and stability over time. (a) Burst centers ordered from early (blue) to late (yellow) DIV. Marker size given by total spike count per 10ms burst frame. (b) As network bursts increase in spike count and electrode recruitment the burst centers weakly shift from peripheral to central locations on the array as seen by the decreasing mean distance from center (r = -0.25, p < 0.0001, mean shown in grey). (c) Network burst duration varies across MEA batches and time. Early (5-13) DIV network bursts show varied durations and shapes compared to later DIV though this differs between batches. (d) The starting electrodes of the network bursts are located on the outlying electrodes with a weak shift away from the central electrodes as the networks mature (r = 0.26, p < 0.0001, mean shown in grey). 4 Results 4.1 Burst development and stability As described, in vitro networks trend towards increased network bursting as they mature. By assessing the burstiness index (figure 1b) across DIV a clear trend (r = 0.62, p < 0.0001) towards increased bursting is evident across almost all batches. Yet as noted by [3] there is a more consistent trend within batches than between, with some batches (1,5,8) showing mostly burst confined spikes and others only moderate increases. In addition to the increase in network burst prevalence the duration between spikes within bursts increases across development. By plotting the ISI between every spike t and t+10 we can see the shift in both burst contained and tonic firing across development (figure 1a). As the network matures the ISI within bursts decrease, as do ISI non-burst spikes. . CC-BY-NC-ND 4.0 International license perpetuity. It is made available under a preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in The copyright holder for this this version posted January 22, 2025. ; doi: bioRxiv preprint 6 This reduction in burst ISI does not necessarily mean that the durations of the network bursts themselves decrease at the same rate (figure 2c). The duration of network bursts is highly variable in the initial onset period between DIV 5-14 before they stabilize on brief durations between DIV 15-20 then gradually increase in length from DIV 20 onwards. These trends are also highly batch dependent with some MEAs showing short and stable network bursts from their onset. While spiking activity in general is evenly distributed across the electrode array, the bursting activity and especially network bursting is dependent on the network age (figure 2a). Initially the center of activity during bursting is confined to the edge of the array, near pacemakers or the initial electrode activated during a detected network burst. These centers of activity gradually shift (r = -0.25, p < 0.0001) towards the middle of the array as more electrodes are recruited during each network burst and the average spiking is more evenly distributed across the array (figure 2b). The initial electrode activated during network bursts stays consistent at the edge of the array (figure 2d) with a small change away from the center across the maturation of the network (r = 0.26, p < 0.0001). The reason for this is likely twofold, as network bursts originate outside the array they will first be detected at the edge, secondly, persistent paths develop along already active electrodes. The difference in pacemaker and non-pacemaker- initiated network bursts were not significantly different (figure 3a) and burst alignment did not change across DIV (r = -0.04, p = 0.44). 4.2 Impact of pacemakers on network development Lag time pathlengths from pacemakers are consistently low across development in contrast to the giant component which decreases gradually (figure 4a). However, pacemakers are not Figure 3: Network burst alignment across DIV. (a) The alignment of time to first spike network burst patterns per day are not significantly different in bursts originating from pacemakers. (b) The network burst alignment is dependent on batch, with some batches trending towards increasing alignment across DIV (lower distance per day) while some remain stable. Overall burst alignment did not change across DIV (r = -0.04, p = 0.44). Mean alignment across all batches shown in grey. . CC-BY-NC-ND 4.0 International license perpetuity. It is made available under a preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in The copyright holder for this this version posted January 22, 2025. ; doi: bioRxiv preprint 7 central in the network nor connected to most nodes as both the degree (figure 4b) and betweenness (figure 4c) centrality are lower than the mean of the giant component. The mutual information and clustering coefficient increase over time (figure 4d-e) for the giant component while pacemakers show a small initial increase before plateauing. The modularity (figure 4f) started high early in development before decreasing between 5-15 DIV and plateauing from 20 DIV onwards. While the increase in mutual information (r = 0.53, p < 0.0001), clustering (r = 0.57, p < 0.0001) and BI (r = 0.62, p < 0.0001) over DIV is significant, there is only a weak correlation between mutual information and BI (r = 0.15, p < 0.0001). The decrease in modularity and increase in BI show a strong negative correlation (r = -0.45, p < 0.0001), contrasting the relationship with mutual information and BI. 5 Discussion We hypothesized that network bursts, originating from areas of the network called pacemakers or burst initiation zones, act as a main driver of the in vitro network's functional development. To investigate this hypothesis, we utilized dense network recordings provided by the Wagenaar dataset to track the initiation, stability, and connectivity of network bursts. As the network develops, the efficiency of signal propagation increases, resulting in decreasing path lengths and increasing mutual information yet this only weakly corresponded with the BI. Further, the pathlengths of pacemakers were consistently lower than the network mean, however pacemakers were not central in the network as per betweenness and degree centrality. Considering that bursting networks show increasing levels of integration, network bursting may be enabling information to propagate more effectively across the network. However, without sufficient segregation, typically in the form of hierarchical modularity, this high integration Figure 4: Comparison of network characteristics on pacemakers (yellow) and giant component (blue). a-c calculated using lag times, d-f calculated using mutual information. Pathlengths (a) between pacemakers and other network nodes are shorter on average than random nodes, yet betweenness (b) and degree (c) centrality is lower than the network mean consistently across development. Clustering (d) and mutual information (e) increases for the giant component over time, while remaining low for pacemakers. Modularity (f) for the giant component begins high but rapidly declines until DIV 15 and plateaus from DIV 20 onwards. . CC-BY-NC-ND 4.0 International license perpetuity. It is made available under a preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in The copyright holder for this this version posted January 22, 2025. ; doi: bioRxiv preprint 8 does not lend itself to an increase in input separability. In this study we found a rapid initial decrease from high to low modularity before the q stabilized. Given the modularity maximization of the Louvain method, small size of the network, and homogeneity of the culture vessel it is possible this high initial modularity stemmed from spurious modules of a few interconnected electrodes which shifted to more stable modules which encompass the majority of the array. On larger MEAs and CMOS arrays, Okujeni and Egert [2], [20], [35] demonstrated well the increased segregation which arises from physical neural aggregation, with subsequent increases in variability of activity and reduced recruitment from network bursts. The issue with continuous network bursts is twofold in terms of computation [36], firstly, the increase in synchrony reduces the network segregation and eventual diversity of activity. Secondly, the onset of a network burst typically means ongoing spiking activity is superseded by the network burst, thus putting a limit on short term computations, including fading memory, equivalent to the length of interburst intervals. Note that the term computation is often non- specific and context dependent, we use the term here specifically to denote the use of in vitro networks for applied computational tasks, such as performance in robot/animat control [37]– [40], or in terms of physical reservoir computing [41]–[44]. To increase the computational viability of in vitro culture it is necessary to find approaches that reduce the long term impact of network bursts [23]. Though certain neurons in a network are likely more intrinsically active [10], it is probable that the network burst initiation seen in vitro arises from self-organization as detailed by Penn et al. [45] and Lonardoni et al. [46]. Disrupting the development of network bursts therefore would mean disrupting the self- organization itself, either through perturbing neurite growth [20], establishing compartments [47], [48], complex cell composition [49], [50] or altering the inhibitory–excitatory balance [51]. In our previous work we have impeded the propagation of network bursts by the addition of global GABAergic inhibition to the cultures [52], though this method is transient due to the rapid uptake and recycling of free GABA. A more long-term solution based on the excitation- inhibition ratio will entail altering the prevalence of interneurons or their connectivity in the networks [50]. Future studies may benefit from further exploring the role of the excitation- inhibition ratio in this context [53]. Most studies on MEAs using dissociated neurons perform recordings in the period 14 to 40 DIV, regardless of species of origin or cell type. Synchronizing population bursting also occurs in vivo in rodents during late embryonic and early postnatal cortical development before typically declining as non-local input increases [54], [55]. The timescale for this initiation and decline of population bursting therefore occurs on shorter timescales than the typical recording period of MEA studies. Yet as reductionist models, dissociated cultures are lacking key features of neural development including glial cell and extracellular matrix (ECM) composition, three- dimensional structure, and gradient compartmentalization. Induced pluripotent stem cells (IPSCs) do recapture some of these factors in terms of their cell composition and matrix complexity, but more importantly studies on IPSCs frequently extend across months and up to a year in length [49], [56], [57]. While IPSCs do show a similar trend in network bursting early in development, some IPSC networks eventually stabilize and decline in burstiness depending on the differentiation protocol in contrast to rat cortical neurons which can sustain bursting up to two years [3], [58]. Extending recording periods beyond the standard 30-40 DIV may therefore capture more variable activity depending on the cell type. . CC-BY-NC-ND 4.0 International license perpetuity. It is made available under a preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in The copyright holder for this this version posted January 22, 2025. ; doi: bioRxiv preprint 9 In studies utilizing in vitro networks for computations, stimulations or inputs to the networks are usually applied to random electrodes to reduce bias, or central electrodes to capture as much of the resulting response as possible[38], [40], [58], [59]. Some studies improve upon this by selecting more active electrodes, yet the network structure itself is rarely considered in terms of input and output selection [38], [60]. Given that neural networks in vitro self-organize to propagate network bursts, either due to developmental set points or as a function of culture conditions, more care should be taken to both optimize integration and segregation of inputs by considering the network structure. Utilizing pacemakers as input points while concurrently increasing the heterogeneity and complexity of in vitro networks should enable better computational capacity than is currently achievable with these networks. Data availability: All original data is available on Acknowledgements: Funding was provided by the DeepCA project (Research Council of Norway, Young Research Talent grant agreement 286558). Author contributions: OHR: conceptualization, methodology, data and statistical analysis writing. SN, AS, IS: conceptualization, writing, review, and editing. All authors contributed to the article and approved the submitted version. 6 References [1] T. Opitz, A. D. De Lima, and T. Voigt, “Spontaneous development of synchronous oscillatory activity during maturation of cortical networks in vitro,” J. Neurophysiol., vol. 88, no. 5, pp. 2196–2206, 2002, doi: 10.1152/jn.00316.2002. [2] S. Okujeni and U. Egert, “Inhomogeneities in network structure and excitability govern initiation and propagation of spontaneous burst activity,” Front. Neurosci., vol. 13, no. MAY, pp. 1–14, 2019, doi: 10.3389/fnins.2019.00543. [3] D. A. Wagenaar, J. Pine, and S. M. Potter, “An extremely rich repertoire of bursting patterns during the development of cortical cultures,” BMC Neurosci., vol. 7, pp. 1–18, Feb. 2006, doi: 10.1186/1471-2202-7-11. [4] D. A. Wagenaar, Z. Nadasdy, and S. M. Potter, “Persistent dynamic attractors in activity patterns of cultured neuronal networks,” Phys. Rev. E - Stat. Nonlinear, Soft Matter Phys., vol. 73, no. 5, 2006, doi: 10.1103/PhysRevE.73.051907. [5] M. Chiappalone, M. Bove, A. Vato, M. Tedesco, and S. Martinoia, “Dissociated cortical networks show spontaneously correlated activity patterns during in vitro development,” Brain Res., vol. 1093, no. 1, pp. 41–53, Jun. 2006, doi: 10.1016/j.brainres.2006.03.049. [6] Y. Penn, M. Segal, and E. Moses, “Network synchronization in hippocampal neurons,” Proc. Natl. Acad. Sci. U. S. A., vol. 113, no. 12, pp. 3341–3346, Mar. 2016, doi: 10.1073/pnas.1515105113. [7] J. Van Pelt, M. A. Corner, P. S. Wolters, W. L. C. Rutten, and G. J. A. Ramakers, “Longterm stability and developmental changes in spontaneous network burst firing patterns in dissociated rat cerebral cortex cell cultures on multielectrode arrays,” Neurosci. Lett., vol. 361, no. 1–3, pp. 86–89, May 2004, doi: 10.1016/j.neulet.2003.12.062. [8] J. H. Kim, H. J. Lee, W. Choi, and K. J. Lee, “Encoding information into autonomously bursting neural network with pairs of time-delayed pulses,” Sci. Rep., vol. 9, no. 1, pp. . CC-BY-NC-ND 4.0 International license perpetuity. It is made available under a preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in The copyright holder for this this version posted January 22, 2025. ; doi: bioRxiv preprint 10 1–11, 2019, doi: 10.1038/s41598-018-37915-7. [9] P. Darbon, L. Scicluna, A. Tscherter, and J. Streit, “Mechanisms controlling bursting activity induced by disinhibition in spinal cord networks,” Eur. J. Neurosci., vol. 15, no. 4, pp. 671–683, 2002, doi: 10.1046/j.1460-9568.2002.01904.x. [10] S. Illes et al., “Intrinsically active and pacemaker neurons in pluripotent stem cell- derived neuronal populations,” Stem Cell Reports, vol. 2, no. 3, pp. 323–336, 2014, doi: 10.1016/j.stemcr.2014.01.006. [11] S. Dauth et al., “Neurons derived from different brain regions are inherently different in vitro: a novel multiregional brain-on-a-chip,” J. Neurophysiol., vol. 117, no. 3, pp. 1320– 1341, 2017, doi: 10.1152/jn.00575.2016. [12] M. Brofiga, F. Callegari, L. Cerutti, M. Tedesco, and P. Massobrio, “Cortical, striatal, and thalamic populations self-organize into a functionally connected circuit with long- term memory properties,” Biosens. Bioelectron., vol. 267, no. June 2024, p. 116840, 2025, doi: 10.1016/j.bios.2024.116840. [13] S. Okujeni and U. Egert, “Self-organization of modular network architecture by activity- dependent neuronal migration and outgrowth,” Elife, vol. 8, Sep. 2019, doi: 10.7554/eLife.47996. [14] P. Joo, H. Lee, S. Wang, S. Kim, and A. G. Hudetz, “Network Model With Reduced Metabolic Rate Predicts Spatial Synchrony of Neuronal Activity,” Front. Comput. Neurosci., vol. 15, no. October, pp. 1–12, Oct. 2021, doi: 10.3389/fncom.2021.738362. [15] D. Eytan and S. Marom, “Dynamics and effective topology underlying synchronization in networks of cortical neurons,” J. Neurosci., vol. 26, no. 33, pp. 8465–8476, Aug. 2006, doi: 10.1523/JNEUROSCI.1627-06.2006. [16] T. A. Gritsun, J. le Feber, and W. L. C. Rutten, “Growth Dynamics Explain the Development of Spatiotemporal Burst Activity of Young Cultured Neuronal Networks in Detail,” PLoS One, vol. 7, no. 9, Sep. 2012, doi: 10.1371/journal.pone.0043352. [17] T. A. Gritsun, J. Le Feber, J. Stegenga, and W. L. C. Rutten, “Network bursts in cortical cultures are best simulated using pacemaker neurons and adaptive synapses,” Biol. Cybern., vol. 102, no. 4, pp. 293–310, Apr. 2010, doi: 10.1007/s00422-010-0366-x. [18] M. I. Ham, L. M. Bettencourt, F. D. McDaniel, and G. W. Gross, “Spontaneous coordinated activity in cultured networks: Analysis of multiple ignition sites, primary circuits, and burst phase delay distributions,” J. Comput. Neurosci., vol. 24, no. 3, pp. 346–357, 2008, doi: 10.1007/s10827-007-0059-1. [19] M. Brofiga et al., “Multiple neuron clusters on Micro-Electrode Arrays as an in vitro model of brain network,” Sci. Rep., vol. 13, no. 1, pp. 1–15, 2023, doi: 10.1038/s41598- 023-42168-0. [20] S. Okujeni, S. Kandler, and U. Egert, “Mesoscale architecture shapes initiation and richness of spontaneous network activity,” J. Neurosci., vol. 37, no. 14, pp. 3972–3987, Apr. 2017, doi: 10.1523/JNEUROSCI.2552-16.2017. [21] A. El Hady et al., “Optogenetic stimulation effectively enhances intrinsically generated network synchrony.,” Front. Neural Circuits, vol. 7, no. October, p. 167, 2013, doi: 10.3389/fncir.2013.00167. [22] I. Colombi, T. Nieus, M. Massimini, and M. Chiappalone, “Spontaneous and perturbational complexity in cortical cultures,” Brain Sci., vol. 11, no. 11, Nov. 2021, doi: 10.3390/brainsci11111453. [23] D. A. Wagenaar, R. Madhavan, J. Pine, and S. M. Potter, “Controlling bursting in cortical cultures with closed-loop multi-electrode stimulation,” J. Neurosci., vol. 25, no. 3, pp. 680–688, Jan. 2005, doi: 10.1523/JNEUROSCI.4209-04.2005. [24] K. Heiney, O. Huse Ramstad, V. Fiskum, A. Sandvig, I. Sandvig, and S. Nichele, “Neuronal avalanche dynamics and functional connectivity elucidate information . CC-BY-NC-ND 4.0 International license perpetuity. It is made available under a preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in The copyright holder for this this version posted January 22, 2025. ; doi: bioRxiv preprint 11 propagation in vitro,” Front. Neural Circuits, vol. 16, 2022, doi: 10.3389/fncir.2022.980631. [25] M. R. Dranias, H. Ju, E. Rajaram, and A. M. J. VanDongen, “Short-term memory in networks of dissociated cortical neurons,” J. Neurosci., vol. 33, no. 5, pp. 1940–1953, 2013, doi: 10.1523/JNEUROSCI.2718-12.2013. [26] H. Ju, M. R. Dranias, G. Banumurthy, and A. M. J. Vandongen, “Spatiotemporal memory is an intrinsic property of networks of dissociated cortical neurons,” J. Neurosci., vol. 35, no. 9, pp. 4040–4051, 2015, doi: 10.1523/JNEUROSCI.3793-14.2015. [27] M. R. Dranias, M. B. Westover, S. Cash, and A. M. J. Vandongen, “Stimulus information stored in lasting active and hidden network states is destroyed by network bursts,” Front. Integr. Neurosci., vol. 9, no. FEB, pp. 1–17, 2015, doi: 10.3389/fnint.2015.00014. [28] I. Colombi, F. Tinarelli, V. Pasquale, V. Tucci, and M. Chiappalone, “A simplified in vitro experimental model encompasses the essential features of sleep,” Front. Neurosci., vol. 10, no. JUL, 2016, doi: 10.3389/fnins.2016.00315. [29] D. J. Bakkum, M. Radivojevic, U. Frey, F. Franke, A. Hierlemann, and H. Takahashi, “Parameters for burst detection,” Front. Comput. Neurosci., vol. 7, no. January, pp. 1– 12, 2014, doi: 10.3389/fncom.2013.00193. [30] V. Pasquale, S. Martinoia, and M. Chiappalone, “Stimulation triggers endogenous activity patterns in cultured cortical networks,” Sci. Rep., vol. 7, no. 1, pp. 1–16, 2017, doi: 10.1038/s41598-017-08369-0. [31] V. Pasquale, S. Martinoia, and M. Chiappalone, “Stimulation triggers endogenous activity patterns in cultured cortical networks,” Sci. Rep., vol. 7, no. 1, p. 9080, Dec. 2017, doi: 10.1038/s41598-017-08369-0. [32] J.-P. Onnela, J. Saramäki, J. Kertész, and K. Kaski, “Intensity and coherence of motifs in weighted complex networks,” Phys. Rev. E, vol. 71, no. 6, p. 065103, Jun. 2005, doi: 10.1103/PhysRevE.71.065103. [33] V. D. Blondel, J. L. Guillaume, R. Lambiotte, and E. Lefebvre, “Fast unfolding of communities in large networks,” J. Stat. Mech. Theory Exp., vol. 2008, no. 10, 2008, doi: 10.1088/1742-5468/2008/10/P10008. [34] J. Z. Bakdash and L. R. Marusich, “Repeated measures correlation,” Front. Psychol., vol. 8, no. MAR, pp. 1–13, 2017, doi: 10.3389/fpsyg.2017.00456. [35] S. Okujeni and U. Egert, “Self-organization of modular network architecture by activity- dependent neuronal migration and outgrowth,” Elife, vol. 8, Sep. 2019, doi: 10.7554/eLife.47996. [36] G. Tanaka et al., “Recent advances in physical reservoir computing: A review,” Neural Networks, vol. 115, pp. 100–123, 2019, doi: 10.1016/j.neunet.2019.03.005. [37] A. Novellino, P. D’Angelo, L. Cozzi, M. Chiappalone, V. Sanguineti, and S. Martinoia, “Connecting neurons to a mobile robot: An in vitro bidirectional neural interface,” Comput. Intell. Neurosci., vol. 2007, pp. 1–13, 2007, doi: 10.1155/2007/12725. [38] J. Tessadori and M. Chiappalone, “Closed-loop neuro-robotic experiments to test computational properties of neuronal networks,” J. Vis. Exp., vol. 2015, no. 97, 2015, doi: 10.3791/52341. [39] D. J. Bakkum, P. M. Gamblen, G. Ben-Ary, Z. C. Chao, and S. M. Potter, “MEART: The Semi-Living Artist.,” Front. Neurorobot., vol. 1, p. 5, Jan. 2007, doi: 10.3389/neuro.12.005.2007. [40] S. M. Potter, D. A. Wagenaar, and T. B. DeMarse, “Closing the Loop: Stimulation Feedback Systems for Embodied MEA Cultures,” in Advances in Network Electrophysiology, vol. 9780387258, Springer US, 2006, pp. 215–242. [41] M. Dale, S. Stepney, J. F. Miller, and M. Trefzer, “Reservoir computing in materio: A computational framework for in materio computing,” Proc. Int. Jt. Conf. Neural . CC-BY-NC-ND 4.0 International license perpetuity. It is made available under a preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in The copyright holder for this this version posted January 22, 2025. ; doi: bioRxiv preprint 12 Networks, vol. 2017-May, pp. 2178–2185, 2017, doi: 10.1109/IJCNN.2017.7966119. [42] T. Gürel, S. Rotter, and U. Egert, “Functional identification of biological neural networks using reservoir adaptation for point processes,” J. Comput. Neurosci., vol. 29, no. 1–2, pp. 279–299, Aug. 2010, doi: 10.1007/s10827-009-0176-0. [43] W. Maass, T. Natschla, and H. Markram, “Fading memory and kernel properties of generic cortical microcircuit models q,” vol. 98, pp. 315–330, 2004, doi: 10.1016/j.jphysparis.2005.09.020. [44] W. Maass, T. Natschläger, and H. Markram, “Real-Time Computing Without Stable States: A New Framework for Neural Computation Based on Perturbations,” Neural Comput., vol. 14, no. 11, pp. 2531–2560, Nov. 2002, doi: 10.1162/089976602760407955. [45] Y. Penn, M. Segal, and E. Moses, “Network synchronization in hippocampal neurons,” Proc. Natl. Acad. Sci. U. S. A., vol. 113, no. 12, pp. 3341–3346, 2016, doi: 10.1073/pnas.1515105113. [46] D. Lonardoni, H. Amin, S. Di Marco, A. Maccione, L. Berdondini, and T. Nieus, “Recurrently connected and localized neuronal communities initiate coordinated spontaneous activity in neuronal networks,” PLoS Comput. Biol., vol. 13, no. 7, Jul. 2017, doi: 10.1371/journal.pcbi.1005672. [47] I. Baruchi, V. Volman, N. Raichman, M. Shein, and E. Ben-Jacob, “The emergence and properties of mutual synchronization in in vitro coupled cortical networks.,” Eur. J. Neurosci., vol. 28, no. 9, pp. 1825–35, Nov. 2008, doi: 10.1111/j.1460- 9568.2008.06487.x. [48] G. J. Brewer et al., “Toward a self-wired active reconstruction of the hippocampal trisynaptic loop: DG-CA3,” Front. Neural Circuits, vol. 7, no. OCT, pp. 1–8, 2013, doi: 10.3389/fncir.2013.00165. [49] A. Odawara, H. Katoh, N. Matsuda, and I. Suzuki, “Induction of long-term potentiation and depression phenomena in human induced pluripotent stem cell-derived cortical neurons,” Biochem. Biophys. Res. Commun., vol. 469, no. 4, pp. 856–862, 2016, doi: 10.1016/j.bbrc.2015.12.087. [50] S. Iida, K. Shimba, K. Sakai, K. Kotani, and Y. Jimbo, “Synchronous firing patterns of induced pluripotent stem cell-derived cortical neurons depend on the network structure consisting of excitatory and inhibitory neurons,” Biochem. Biophys. Res. Commun., vol. 501, no. 1, pp. 152–157, Jun. 2018, doi: 10.1016/j.bbrc.2018.04.197. [51] H. Teppola, J. Aćimović, and M. L. Linne, “Unique Features of Network Bursts Emerge From the Complex Interplay of Excitatory and Inhibitory Receptors in Rat Neocortical Networks,” Front. Cell. Neurosci., vol. 13, Sep. 2019, doi: 10.3389/fncel.2019.00377. [52] K. Heiney, O. H. Ramstad, I. Sandvig, A. Sandvig, and S. Nichele, “Assessment and manipulation of the computational capacity of in vitro neuronal networks through criticality in neuronal avalanches,” in 2019 IEEE Symposium Series on Computational Intelligence, SSCI 2019, 2019, pp. 247–254, doi: 10.1109/SSCI44817.2019.9002693. [53] J. S. Weir, N. Christiansen, A. Sandvig, and I. Sandvig, “Selective inhibition of excitatory synaptic transmission alters the emergent bursting dynamics of in vitro neural networks,” Front. Neural Circuits, vol. 17, no. February, pp. 1–17, 2023, doi: 10.3389/fncir.2023.1020487. [54] A. K. McCabe, S. L. Chisholm, H. L. Picken-Bahrey, and W. J. Moody, “The self- regulating nature of spontaneous synchronized activity in developing mouse cortical neurones,” J. Physiol., vol. 577, no. 1, pp. 155–167, 2006, doi: 10.1113/jphysiol.2006.117523. [55] R. Corlew, M. M. Bosma, and W. J. Moody, “Spontaneous, synchronous electrical activity in neonatal mouse cortical neurones,” J. Physiol., vol. 560, no. 2, pp. 377–390, . CC-BY-NC-ND 4.0 International license perpetuity. It is made available under a preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in The copyright holder for this this version posted January 22, 2025. ; doi: bioRxiv preprint 13 2004, doi: 10.1113/jphysiol.2004.071621. [56] A. Odawara, Y. Saitoh, A. H. Alhebshi, M. Gotoh, and I. Suzuki, “Long-term electrophysiological activity and pharmacological response of a human induced pluripotent stem cell-derived neuron and astrocyte co-culture.,” Biochem. Biophys. Res. Commun., vol. 443, no. 4, pp. 1176–81, Jan. 2014, doi: 10.1016/j.bbrc.2013.12.142. [57] K. Shimba, K. Sakai, Y. Takayama, K. Kotani, and Y. Jimbo, “Recording axonal conduction to evaluate the integration of pluripotent cell-derived neurons into a neuronal network.,” Biomed. Microdevices, vol. 17, no. 5, p. 94, Oct. 2015, doi: 10.1007/s10544- 015-9997-y. [58] S. M. Potter and T. B. DeMarse, “A new approach to neural cell culture for long-term studies,” J. Neurosci. Methods, vol. 110, no. 1–2, pp. 17–24, Sep. 2001, doi: 10.1016/S0165-027000412-5. [59] A. Bruzzone, V. Pasquale, P. Nowak, J. Tessadori, P. Massobrio, and M. Chiappalone, “Interfacing in silico and in vitro neuronal networks,” in 2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), Aug. 2015, vol. 2015-Novem, pp. 3391–3394, doi: 10.1109/EMBC.2015.7319120. [60] L. L. Bologna, T. Nieus, M. Tedesco, M. Chiappalone, F. Benfenati, and S. Martinoia, “Low-frequency stimulation enhances burst activity in cortical cultures during development,” Neuroscience, vol. 165, no. 3, pp. 692–704, 2010, doi: 10.1016/j.neuroscience.2009.11.018. . CC-BY-NC-ND 4.0 International license perpetuity. It is made available under a preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in The copyright holder for this this version posted January 22, 2025. ; doi: bioRxiv preprint","Network bursts or synchronized burst events are a typical activity seen in most in vitro neural networks. Network bursts arise early in development and as networks mature, activity becomes dominated by bursts propagating across the entirety of the network. The reason for this developmental plateau in vitro is unknown, but to bypass it would confer a significant advantage in the use of in vitro networks for computation. As most neurons in a network participate in network bursts, burst onset supersedes any ongoing activity thereby placing a limit on short term computations equal to the recovery period between bursts. By assessing 521 multielectrode array recordings from day 4-39 in vitro we find that network bursts influence the connectivity, but this change is only weakly associated with the origin of the network bursts. The impacts of bursts on functional integration and segregation in neural networks are discussed along with approaches to mitigate the development and propagation of network bursts in vitro. Additionally, we hypothesize that burst initiation zones or pacemakers are viable targets for stimulation for computation in the context of control and reservoir computing. 2","['Ola Huse Ramstad', 'Axel Sandvig', 'Stefano Nichele', 'Ioanna Sandvig']"
Hadoop MapReduce scheduling paradigms,"Johannessen, Roger and Yazidi, Anis and Boning Feng",2017,missing,missing,missing,inproceedings,"2017 the 2nd IEEE International Conference on Cloud Computing and Big Data Analysis 
Hadoop MapReduce Scheduling Paradigms 
Roger Johannessen, Anis Yazidi, Boning Feng 
Department of Computer Science 
Oslo and Akershus University College of Applied Sciences 
Oslo, Norway 
e-mail: anis.yazidi@hioa.no.boning.feng@hioa.no 
Abstract 
Keywords-Apache 
Hadoop; 
MapReduce; 
scheduling 
paradigms 
I. 
INTRODUCTION 
Bollier stated, ""Big websites can generate terabytes of 
raw log data every day. The sheer size of its data set has 
led 
to 
the 
emergence 
of 
new 
cloud 
infrastructures, 
characterized by 
the 
ability 
to scale 
to 
thousands 
of 
nodes, fault tolerance and relaxed consistency"" [1]. From 
2005 to 2020, the digital universe is expected to grow 
dramatically by a factor of 300, from 130 exabytes to 40 
trillion gigabytes, i.e. more than 5,200 gigabytes per person 
in 2020. Moreover, the digital universe is expected to 
double every two years [2]. A big part of the growth is a 
defining trait of our current technology landscape -
the 
Internet of Things, quickly evolving into: ""The Internet of 
Everything"" 
[3]. 
The 
benefits 
of 
""all 
interconnected"" 
devices is immense in tenns of potentially huge increase 
in quality of life. In the same time, it brings along the 
challenge of handling extreme amounts of data. Devices 
generate nowadays vast amounts logging data, but also 
functional data such as media streams that are key to the 
sole purpose of the device. Data is becoming the world's 
new natural resource [4]. The challenges represented by 
big data handling can be divided into three groups: 
• 
Velocity 
• 
Volume 
• 
Variety 
Hadoop possesses a sophisticated set of methods that 
handle the above challenges elegantly through the use of: 
• 
Hadoop Common (a set of utilities and libraries) 
• 
The file system called HDFS (Hadoop File System) 
• 
YARN (Yet Another Resource Negotiator) 
• 
MapReduce (a framework for distributing tasks and 
parallel processing) 
978-1-5090-4499-3/17/$31.00 ©20 17 IEEE 
175 
II. 
RELATED WORK 
In this section, we will survey some promIsmg new 
scheduling algorithms, as well as some highly-cited and well 
established ones. We have categorized those scheduling 
algorithms by the type of the scheduling priority. 
A. 
Deadline Prioritization 
(1) 
Deadline 
Constraint 
Scheduler: 
Prioritizing 
deadline in a Hadoop clusters is done by predicting the 
completion time of jobs/tasks and then allocating them to 
nodes capable of processing them within a time limit where 
the data is actually useful. The research reported in [5] was 
motivated by the fact that FIFO, the default scheduling 
algorithm of Hadoop clusters, has some visible drawbacks 
due to its rigid prioritization scheme. The paper explores real 
time cluster scheduling based on user specified deadlines. 
The authors give a preliminary evaluation of their algorithm 
reckoned as Deadline Constraint Scheduler, which is a 
scheduler that simply ignores new tasks that cannot be 
processed 
within 
their 
deadline. 
This 
is 
achieved 
by 
calculating the deadline and comparing it to the execution 
time. The latter approach performs well in a homogeneous 
cluster, but is invalidated in a heterogeneous cluster where 
execution times might vary across nodes. In this case, the 
algorithm relaxes some of its parameters so that to allow 
processing times to be decoupled from the slowest node. 
However, this might lead to under-utilization of certain 
nodes in the cluster. The authors concede that they will 
address this issue in future work. To calculate schedulability, 
the work calculates the minimum amount of map tasks to get 
a job done, and compares it to the maximum amount of 
reduce tasks. If there is less available reduce slots than the 
maximum amount of possible reduce tasks in the job, the 
task is dropped. Experimental results show greater task 
efficiency during MapReduce phases [5]. 
(2) Cloud Least Laxity First: In another approach 
introduced in the paper entitled ""A Deadline Scheduler for 
Jobs in Distributed Systems"" [6], the authors propose an 
interesting deadline scheduler for Hadoop called Cloud Least 
Laxity First (CLLF), that orders tasks based on laxity (time 
left over to deadline, after task is [mished). They argue that 
by using this technique one can reduce the amount of nodes 
needed while maintaining total execution time at acceptable 
levels. This was proven by comparing the algorithm to Time 
Shared 
and 
Space 
Shared 
scheduling 
in 
a 
controlled 
environment. The devised scheduler handles soft deadlines 
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore.  Restrictions apply. 
 by introducing a penalty tenn as a function of the lateness 
(lateness defmed as completion time minus deadline). The 
authors describe a system in which each worker node uses a 
FIFO-queue and notifies the master as soon as it has an idle 
processor. The master has the role of hosting the CLLF­
algorithm and allocating tasks. As the authors themselves 
describe it: ""The general idea of the algorithm is to sort the 
cloudlets by laxities (the fust has the lowest one). Giving this 
sorted list, the algorithm takes the fust element of this list 
and looks for a host that locally have the data of the cloudlet 
and which also have at least one free slot. If one matching 
host is found, the task is ran on it; otherwise, the algorithm 
restarts the same procedure using the second element of the 
list"" [6]. As in the case of the algorithm reported in [5] which 
falls in this category, this algorithm 
[6] is limited to 
homogeneous environments. In line with goal of reducing 
the amount of virtual nodes needed for job executions, the 
work [6] shows a considerable decrease in missed deadlines 
compared to Time Shared and Space Shared algorithms, thus, 
increasing the disparity in effectiveness of the latter two 
algorithms. 
B. 
Resource Prioritization 
(1) Coupling Scheduler: 
Algorithms 
delving 
into 
resource allocation and optimization of utilization of worker 
nodes are perhaps the most investigated topic within the field 
of MapReduce. As processing and handling of data is getting 
more and more centralized, virtualized Hadoop clusters seem 
to be the future of MapReduce and has emerged as enabler 
for business ventures through the cloud. In [7], it was argued 
that the widely used Fair Scheduler has a starvation problem 
involving the Map and Reduce operations. The paper focuses 
on coupling the two progresses, instead of treating them 
separately. The authors [7] also performed a performance 
comparison, 
proving 
that Coupling 
Scheduler 
performs 
better than Fair Scheduler in handling tasks with varying 
map service times. The main effect this has on resource 
usage is that reducers are gradually launched as more and 
more maps are completed, instead of allocating a quantity of 
reducers based on predicted need, i.e. as seen in [5]. The 
benefits is that there is virtually no under-utilization of 
resources in the cluster, making the approach [5] energy 
efficient. However, Coupling Scheduler ignores job sizes and 
can therefore be inefficient when processing jobs with large 
map service times. This is due to the coupling nature of 
""sticky processor sharing"" [7], where a map task gradually 
gets the amount of reducers it needs, disregarding task 
completion time, potentially allowing huge tasks to complete 
before allocating resources to smaller tasks [7]. 
(2) Triple-Queue Scheduler and MR-predict: While [7] 
preemptively couples mappers and reducers regardless of 
task 
size, 
the 
authors 
behind 
the 
paper 
""A Dynamic 
MapReduce Scheduler for Heterogeneous Workloads"" [8] 
have devised a prediction method called MR-predict to 
detect workloads in real time. MR-predict focuses on 
optimizing the utilization and balance between I/O-bound vs 
CPU-bound applications, which is not a concern in legacy 
Hadoop MapReduce. Based on MR-Predict, which classifies 
a type of workload, they propose Triple-Queue Scheduler to 
176 
serve tasks based on the predicted workload. The standard 
First Come First Served strategy would not be able to handle 
scheduling different task types, as it has a single queue. With 
the Triple-Queue Scheduler the authors solve this issue by 
paralleling queues, and delivering I/O bound tasks to nodes 
with I/O resources to spare, while at the same time serving 
CPU bound tasks to fitting nodes. MR-predict checks the 
history of a job to predict the future tasks, and from there 
describe the workload type. If a new job is received with no 
previous history, the job is sent to a waiting queue within 
Triple-Queue Scheduler, where the scheduler will assign one 
map task of that job to every TaskTracker whenever it has 
idle slots. When the map tasks finish, MR-predict calculates 
the MTCT (Map Task Completed Time), MID (Map Input 
Data) and MOD (Map Output Data) based on the data 
gathered from these tasks. The type of workload then gets 
determined, and the job is moved into either an I/O-Bound 
queue, or a CPU-Bound queue. Furthermore, the scheduler 
monitors tasks assigned to queues, checking if MTCT 
increases. If MTCT increase passes the threshold of 140%, 
the scheduler determines that the task was assigned to the 
wrong queue, and moves the task to an alternative queue. 
The tests were run on a native Hadoop cluster, running 
TeraSort, GrepCount and WordCount. The authors observed 
a 20% increase in resource utilization and an impressive 30% 
increase in throughput. This is naturally only meant for 
heterogeneous workloads, as there would be little use to 
predict a homogeneous job flow. The algorithm is also 
exclusively useful in a homogeneous environment [8]. 
(3) Workload Characteristic and Resource Aware 
Scheduler: In this paper, the authors propose WCRA­
scheduling 
of 
Hadoop 
clusters 
[9]. 
WCRA-scheduling 
checks the CPU, RAM and I/O-load on the nodes fust. 
Afterwards, all the tasks are sorted based on Estimated 
Completion Time then scheduled on the most fitting nodes. 
The work bears some similarity to [8], but also embraces 
RAM as an important parameter, ensuring that more than 
25% of the primary memory is always available before 
scheduling a job. The authors argue that ""is critical in case of 
CPU and Disk I/O bound tasks"" [9]. It was found that 
""compute node works significantly if it has the available 
physical memory greater than 25%. Tasks are assigned to the 
node if the memory availability is greater than 25%"" [9]. 
WRCA-scheduling has the benefit of being specifically 
designed to handle heterogeneous clusters. In a similar 
manner to [8], WRCA works by fust completing a set of 
sample tasks for a new job in order to determine predicted 
type of workload, and then classifies the job as either CPU­
bound or I/O-bound. Compared to [8], more extensive testing 
with more jobs were reported, albeit on a smaller cluster 
environment, and actually reached the same amount of 
increase in throughput (30%) when compared to FIFO, Fair­
scheduler and Capacity scheduler. 
(4) Adaptive resource allocation schedulers: 
By 
defmition, an adaptive resource allocation scheduler adapts 
to the capabilities and performance of each node in the 
cluster individually. In [10], the authors argued that legacy 
resource-aware schedulers give nodes a fixed amount of 
resources for each job, 
potentially causing over/under-
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore.  Restrictions apply. 
 utilization of resources, in contrast to their devised scheduler 
[10] which dynamically adapts its resource allocation over 
the course of the job. Based on the estimated amount of tasks 
that can be processed concurrently on each node, the devised 
algorithm shrinks/extends the amount of resources over the 
run time. This algorithm is also designed to optimize a 
heterogeneous cluster as in [8]. Instead of predicting tasks 
and queueing the workloads, the authors propose a strategy 
where the worker nodes and their ""available/lack resources 
(CPU and memory) are monitored, and based on this, the 
scheduler will extend/shrink the capacity of the TaskTracker 
by increasing/decreasing the number of map/reduce slots of 
the TaskTracker"" 
[10]. The approach was tested using 
different benchmarks including TeraSort, PiEstimator and 
WordCound, in a similar manner to the main stream of 
papers in this category. According to the experimental 
fmdings, 
it 
was 
observed an 
average 
increase of 
the 
completion time of all tasks by around 30%. As in the case 
of [6], this approach also yields an increased effectiveness 
with reduced nodes/slots in the cluster, compared to native 
algorithms like FIFO and Fair-scheduler [10]. 
e. 
Job Size 
(1) Size-Based Scheduling: As was remarked in a series 
of papers such as in [7], ignoring the job size might halt 
throughput in cluster, although it is very resource-effective. 
Weighing job-size first should then logically considerably 
increase throughput in the cluster and is claimed to achieve 
""near-optimal system response times"" [11]. The hard part 
about designing an algorithm focused on size is that it has to 
prioritize jobs/tasks with the shortest remaining completion 
time to be effective. This can lead to bigger tasks starving to 
get resources. The authors introduce HFSP (Size-based 
Scheduling for Hadoop) [11], a scheduler that lets Hadoop 
determine job size during execution in real time. They claim 
that 
their 
approach 
""satisfies 
both 
the 
interactivity 
requirements of small jobs and the performance requirements 
of large jobs, which can thus coexist in a cluster without 
requiring manual setups and complex tuning"" [11]. To be 
able to schedule tasks with short completion times without 
forcing starvation of larger tasks, the author implement a 
common aging policy, where the cost of a task in the queue 
gets gradually decremented as it waits for resources. They 
call 
the 
technique 
""Shortest 
Remaining 
Virtual 
Time 
(SRVT)"" [11]. SRVT results in a slight increase in average 
throughput time, at the benefit of virtually eliminating errors 
and starvation in the queue. By applying a size-based 
scheduling 
algorithm, 
the 
authors 
also 
argue 
that 
the 
scheduler has significantly reduced overhead, as its only 
concern is the direct size of the job, and no additional 
calculations are necessary. As seen in [9] and [8], this 
scheduler determines size by running a small set of sample 
tasks from a job. The approach [11] is endowed with a 
preemptive estimation module that sets a coarse size value 
for the job before the samples are processed, which gets 
gradually refmed as samples are completed. The authors 
have measured the perfonnance of their approach in a 
benchmarking suite, and found a significant decrease in 
system response times. Contrary to 
[6] and [10], this 
177 
effectiveness disparity increased in larger jobs and larger 
clusters [12]. 
(2) LsPS (Leveraging size Patterns Scheduler): The 
work reported in [11] proposes an algorithm that specializes 
in handling bursty workloads in a multi-user environment, by 
tuning resource shares among users, and even the scheduling 
algorithm for each user, based on job size. The authors have 
tested their algorithm both in a controlled environment and 
in a production cluster: Amazon EC2, and observed reduced 
MapReduce job response times. The job tracker calculates 
how many slots and resources each user should have based 
on the history of task completion, and predicted completion 
time based on job size. Every time a task is finished, the 
statistics of that particular user are updated. Based on all this 
data, the Job Tracker continually sorts users instead of tasks, 
making sure to let the most efficient users get the most slots, 
without starving other users. This is done by granting a slot 
share ratio to the users that is inversely proportional to their 
job average sizes. In the case of new users entering the 
cluster 
have 
no 
history 
for 
determining 
average job 
size/completion time, predefined job profIles are added to the 
scheduler, and assigned to users based on a couple of user­
defmed criteria. The authors have chosen a FIFO-algorithm 
as a fallback, in case of tasks getting the same cost and 
confusing LsPS, making sure that the first task submitted 
simply is processed. The experimental results show huge 
promise in enterprise environments, with multiple users, 
heterogeneous clusters and heterogeneous workloads. For 
smaller clusters and predictable workloads however, the 
overhead cost might be too high [11]. 
D. Improving Native Hadoop 
(1) 
Fair 
and 
Efficient 
Slot 
Configuration 
and 
Scheduling: In many cases, enterprises just want to use 
Hadoop for parallel big data processing out-of-the-box, 
without much configuration by experts. This frequently leads 
to using native Hadoop schedulers which may be inefficient. 
The team behind FRESH (FaiR and Efficient Slot scheduling 
for Hadoop) [13] argue that Hadoop is far too complex to 
tweak 
for 
many 
users. 
They 
propose 
FRESH 
that 
dynamically configures slots and assign tasks to achieve 
optimal performance from a cluster. They introduce two 
different algorithms, one which statically assigns slots for 
each job submitted, and one that dynamically alters the 
amounts of slots for a job during run time. The static 
algorithm calculates optimal amounts of slots for each job, 
allocates slots for nodes, and then hands the jobs over to Fair 
Scheduler to server tasks to the nodes. The dynamic 
algorithm takes the whole process without help for Fair 
Scheduler, and acts as both back end slot allocator and task 
server for nodes, dynamically monitoring each node and 
making sure all tasks are processed with optimal fairness. 
The authors present their own novel definition of fairness, 
named 
overall 
fairness 
with 
an 
algorithm 
that 
more 
accurately disperses resources between jobs. The reported 
tests show a significant improvement, especially with the 
dynamic slot allocation, increasing makespan by up to 30% 
compared to Fair scheduler across all types of workloads 
[13]. 
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore.  Restrictions apply. 
 (2) Chronos: Instead of creating a totally new ""default"" 
scheduler from scratch, a different approach for enhancing 
the native Hadoop scheduler is proposed by the authors of 
Chronos: 
Failure-A ware 
Scheduling 
in 
Shared 
Hadoop 
Clusters [14]. The authors argue that the performance of 
Hadoop systems in part depends on how failures are handled. 
Hadoop handles failures by re-executing all the tasks of the 
failed machines. In this case, the machines need to wait for 
resources to execute recovery tasks. They argue that the fact 
that this is black-boxed from Hadoop schedulers (not visible 
or configurable for schedulers) may hinder the schedulers 
from optimizing the workflow according to the scheduling 
goal efficiently, and thus significantly reducing performance 
of the cluster. In order to counter this problem, the authors 
introduce Chronos, a failure-aware scheduling strategy that 
preemptively allocates resources to nodes with task failures, 
and also considers data locality for optimized performance. 
Chronos 
is 
an 
optional 
component 
independent 
from 
schedulers, and works together with the scheduler of a users 
choice (like native Hadoop - FIFO or Fair). Chronos works 
basically by listening to heartbeats from Hadoop. Upon a 
failure, Chronos queries the Job Tracker for the nodes that 
has task failures. Chronos then attempts to ""inject"" the 
recovery tasks into the front of the task queue, based on an 
algorithm working 
together with the scheduler goal to 
determine priorities of tasks. When it finds an appropriate 
slot, it then allocates resources away from less important 
tasks in the queue and on to the recovering node. The latter 
strategy allows the failed slots to preemptively be freed, 
instead of waiting in starvation for recovery resources. The 
authors tested Chronos in combination with FIFO and Fair­
scheduler and experienced a reduction in job completion 
times by up to an astonishing percentage of 55%. 
E. 
Hybrid Approach 
(1) Resource and Deadline-aware Job Scheduling: As 
aforementioned, there is a vast variety of interesting and 
effective scheduling algorithms with different prioritization, 
and different drawbacks. In general term, hybrid approaches 
aspire to combine one or more different approaches so that to 
distill the best of their combination [15]. In [15], the authors 
introduce a hybrid algorithm that takes both task deadlines 
and a predicted future resource availability into account 
when allocating tasks. To achieve this they apply a receding 
horizon control algorithm in combination with a self-learning 
model that learns to predict an estimate of future resource 
availability and job completion times. They do this by 
introducing control intervals in which actual resources and 
job sizes and predicted resources and job sizes are calculated, 
and 
based 
on 
this 
they 
optimize 
the 
schedule 
while 
evaluating 
deadlines. 
This 
is 
especially 
useful 
in 
an 
environment 
where 
resources 
are 
dynamic 
and 
heterogeneous, as resources can be added or taken away 
during run time, and the controls will catch the updates and 
optimize for it. Tested in a controlled environment against 
Fair Scheduler, the authors were able to reduce the penalty of 
deadline misses by 36%, and against Earliest Deadline First 
scheduler they show a reduced penalty of 10% [15]. 
178 
(2) Classification and Optimization based Scheduler: 
A truly hybrid solution is introduced in [16]. The authors 
analyze the performance of widely used schedulers like FIFO 
and Fair Share Scheduler, and an algorithm reckoned as 
COSHH (Classification and Optimization based Scheduler 
for 
Heterogeneous 
Hadoop) 
scheduler. 
Based 
on 
the 
performances of these algorithms, the paper introduces a 
hybrid solution where all three algorithms are used in the 
same cluster based on different system loads. ""When the 
system is underloaded, and the number of free slots is greater 
than the number of waiting tasks, the scheduler switches to 
the FIFO algorithm. Here, the simple FIFO algorithm can 
improve 
the 
average 
completion 
time 
with 
minimum 
scheduling overhead. However, as the system load increases 
such that the available number of slots is less than the 
number of waiting tasks, the hybrid scheduler selects the Fair 
Sharing algorithm. When the load increases such that the 
system is overloaded, and the number of waiting tasks in job 
queues is quickly increasing, the Fair Sharing algorithm can 
greatly increase the average completion time. Therefore, the 
scheduler switches to the COSHH algorithm which improves 
the average completion time, while avoiding considerable 
degradation 
in 
the 
fairness 
metric"" 
[16]. 
The 
hybrid 
scheduler chooses the best scheduling algorithm for different 
scales of jobs and resources to address average completion 
time and fairness [16]. The results of the experiments are 
thoroughly documented, showing that the approach works, in 
numerous cases cutting scheduling and completion-time by 
half [16]. 
III. 
CONCLUSION 
After reviewing a number of related works on Hadoop 
scheduling, the conclusion that stands out is the potential for 
improvement in the default Hadoop scheduling algorithms. 
Almost all the surveyed schedulers in this paper have 
advantages 
in 
terms 
of 
fairness 
and 
completion 
time 
compared 
to 
the 
default 
Hadoop 
scheduling 
policy. 
Interestingly, FRESH [13] and COSHH-hybrid [16] have the 
potential to become a native part of Hadoop, replacing FIFO 
and Fair sharing, as well as Chronos [14] which holds a lot 
of promise while still needing further testing. When it comes 
to large enterprise environments, LsPS [11] represents a 
promising 
approach 
as 
it 
delivered 
unprecedented 
performance and user control in a scalable and dynamic 
cluster, vastly improving upon default schedulers. 
REFERENCES 
[I] 
Bollier, D., & Firestone, C. M. (2010). The promise and peril of big 
data (p. 1). Washington, DC: Aspen Institute, Communications and 
Society Program. 
[2] 
Gantz, J., & Reinsel, D. (2012). The digital universe in 2020: Big 
data, bigger digital shadows, and biggest growth in the far east. 
IDC iView: IDC Analyze the future, 2007, 1-16, 
[3] 
Richards, N. M., & King, 1. H. (2013). Three paradoxes of big 
data. 
[4] 
Huang, G., He, J., Chi, C. H., Zhou, w., & Zhang, Y. (2015, 
June). A Data as a Product Model for Future Consumption of Big 
Stream Data in Clouds. In 2015 IEEE International Conference on 
Services Computing (SCC), (pp. 256-263). IEEE. 
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore.  Restrictions apply. 
 [5] 
Kc, K., & Anyanwu, K. (2010, November). Scheduling hadoop 
jobs to meet deadlines. In 2010 IEEE Second International 
Conference 
on 
Cloud 
Computing 
Technology 
and 
Science 
(CloudCom) (pp. 388-392). IEEE. 
[6] 
Perret, Q., Charlemagne, G., Sotiriadis, S., & Bessis, N. (2013, 
March). A deadline scheduler for jobs in distributed systems. In 2013 
27th International Conference on Advanced Information Networking 
and Applications Workshops (WAINA) (pp. 757-764). IEEE. 
[7] 
Tan, J., Meng, X., & Zhang, L. (2012, March). Performance 
analysis 
of 
coupling 
scheduler 
for 
mapreduce/hadoop. 
In 
INFOCOM, 2012 Proceedings IEEE (pp. 2586-2590). IEEE. 
[8] 
Tian, c., Zhou, H., He, Y., & Zha, L. (2009, August). A dynamic 
mapreduce scheduler for heterogeneous workloads. In 2009 Eighth 
International Conference on Grid and Cooperative Computing (pp. 
218-224). IEEE. 
[9] 
Divya, M., & Annappa, B. (2015, July). Workload characteristics 
and resource 
aware Hadoop scheduler. In 2015 IEEE 2nd 
International Conference on Recent Trends in Information Systems 
(ReTIS) (pp. 163-168). IEEE. 
[10] Elkholy, A. M., & Sail am, E. A. (2014, December). Self adaptive Hadoop 
scheduler 
for 
heterogeneous resources. 
In 2014 9th 
International 
Conference on Computer Engineering & Systems (lCCES) (pp. 427-432). 
IEEE 
179 
[II] Yao, Y., Tai, J., Sheng, B., & Mi, N. (2015). LsPS: A Job Size­
Based Scheduler for Efficient Task Assignments in Hadoop. IEEE 
Transactions on Cloud Computing, 3(4), 411-424. 
[12] Pastorelli, M., Barbuzzi, A., Carra, D., Dell' Amico, M., 
& 
Michiardi, P. (2013, October). HFSP: size-based scheduling for 
Hadoop. In 2013 IEEE International Conference on Big Data (pp. 
51-59). IEEE. 
[13] Wang, J., Yao, Y., Mao, Y., Sheng, B., & Mi, N. (2014, June). 
Fresh: Fair and efficient slot configuration and scheduling for 
hadoop clusters. In 2014 IEEE 7th International Conference on 
Cloud Computing (pp. 761-768). IEEE. ISO 690 
[14] Yildiz, 0., Ibrahim, S., Phuong, T. A., & Antoniu, G. (2015, 
October). Chronos: Failure-aware scheduling in shared hadoop 
clusters. In 2015 IEEE International Conference on Big Data (Big 
Data) (pp. 313-318). IEEE. 
[15] Cheng, D., Rao, J., Jiang, C., & Zhou, X. (2015, May). Resource 
and deadline-aware job scheduling in dynamic hadoop clusters. In 
2015 IEEE International Parallel and Distributed Processing 
Symposium (IPDPS) (pp. 956-965). IEEE. 
[16] Rasooli, A., & Down, D. G. (2012, November). A hybrid scheduling 
approach for scalable heterogeneous hadoop systems. In High 
Performance Computing, Networking, Storage and Analysis (SCC), 
2012 SC Companion: (pp. 1284-1291). IEEE. 
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore.  Restrictions apply. 
",10.1109/ICCCBDA.2017.7951906,doc31,"-Apache Hadoop is one of the most prominent and 
early technologies for handling big data. Different scheduling 
algorithms within the framework of Apache Hadoop were 
developed in the last decade. In this paper, we attempt to 
provide 
a 
comprehensive 
overview 
over 
the 
different 
paradigms for scheduling in Apache Hadoop. The surveyed 
approaches fall under different categories, namely, Deadline 
prioritization, Resource prioritization, Job size prioritization, 
Hybrid approaches and recent trends for improvements upon 
default schedulers.","2017 the 2nd IEEE International Conference on Cloud Computing and Big Data Analysis Hadoop MapReduce Scheduling Paradigms Roger Johannessen, Anis Yazidi, Boning Feng Department of Computer Science Oslo and Akershus University College of Applied Sciences Oslo, Norway e-mail: anis.yazidi@hioa.no.boning.feng@hioa.no Abstract Keywords-Apache Hadoop; MapReduce; scheduling paradigms I. INTRODUCTION Bollier stated, ""Big websites can generate terabytes of raw log data every day. The sheer size of its data set has led to the emergence of new cloud infrastructures, characterized by the ability to scale to thousands of nodes, fault tolerance and relaxed consistency"" [1]. From 2005 to 2020, the digital universe is expected to grow dramatically by a factor of 300, from 130 exabytes to 40 trillion gigabytes, i.e. more than 5,200 gigabytes per person in 2020. Moreover, the digital universe is expected to double every two years [2]. A big part of the growth is a defining trait of our current technology landscape - the Internet of Things, quickly evolving into: ""The Internet of Everything"" [3]. The benefits of ""all interconnected"" devices is immense in tenns of potentially huge increase in quality of life. In the same time, it brings along the challenge of handling extreme amounts of data. Devices generate nowadays vast amounts logging data, but also functional data such as media streams that are key to the sole purpose of the device. Data is becoming the world's new natural resource [4]. The challenges represented by big data handling can be divided into three groups: • Velocity • Volume • Variety Hadoop possesses a sophisticated set of methods that handle the above challenges elegantly through the use of: • Hadoop Common (a set of utilities and libraries) • The file system called HDFS (Hadoop File System) • YARN (Yet Another Resource Negotiator) • MapReduce (a framework for distributing tasks and parallel processing) 978-1-5090-4499-3/17/$31.00 ©20 17 IEEE 175 II. RELATED WORK In this section, we will survey some promIsmg new scheduling algorithms, as well as some highly-cited and well established ones. We have categorized those scheduling algorithms by the type of the scheduling priority. A. Deadline Prioritization Deadline Constraint Scheduler: Prioritizing deadline in a Hadoop clusters is done by predicting the completion time of jobs/tasks and then allocating them to nodes capable of processing them within a time limit where the data is actually useful. The research reported in [5] was motivated by the fact that FIFO, the default scheduling algorithm of Hadoop clusters, has some visible drawbacks due to its rigid prioritization scheme. The paper explores real time cluster scheduling based on user specified deadlines. The authors give a preliminary evaluation of their algorithm reckoned as Deadline Constraint Scheduler, which is a scheduler that simply ignores new tasks that cannot be processed within their deadline. This is achieved by calculating the deadline and comparing it to the execution time. The latter approach performs well in a homogeneous cluster, but is invalidated in a heterogeneous cluster where execution times might vary across nodes. In this case, the algorithm relaxes some of its parameters so that to allow processing times to be decoupled from the slowest node. However, this might lead to under-utilization of certain nodes in the cluster. The authors concede that they will address this issue in future work. To calculate schedulability, the work calculates the minimum amount of map tasks to get a job done, and compares it to the maximum amount of reduce tasks. If there is less available reduce slots than the maximum amount of possible reduce tasks in the job, the task is dropped. Experimental results show greater task efficiency during MapReduce phases [5]. Cloud Least Laxity First: In another approach introduced in the paper entitled ""A Deadline Scheduler for Jobs in Distributed Systems"" [6], the authors propose an interesting deadline scheduler for Hadoop called Cloud Least Laxity First (CLLF), that orders tasks based on laxity (time left over to deadline, after task is [mished). They argue that by using this technique one can reduce the amount of nodes needed while maintaining total execution time at acceptable levels. This was proven by comparing the algorithm to Time Shared and Space Shared scheduling in a controlled environment. The devised scheduler handles soft deadlines Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore. Restrictions apply. by introducing a penalty tenn as a function of the lateness (lateness defmed as completion time minus deadline). The authors describe a system in which each worker node uses a FIFO-queue and notifies the master as soon as it has an idle processor. The master has the role of hosting the CLLF­ algorithm and allocating tasks. As the authors themselves describe it: ""The general idea of the algorithm is to sort the cloudlets by laxities (the fust has the lowest one). Giving this sorted list, the algorithm takes the fust element of this list and looks for a host that locally have the data of the cloudlet and which also have at least one free slot. If one matching host is found, the task is ran on it; otherwise, the algorithm restarts the same procedure using the second element of the list"" [6]. As in the case of the algorithm reported in [5] which falls in this category, this algorithm [6] is limited to homogeneous environments. In line with goal of reducing the amount of virtual nodes needed for job executions, the work [6] shows a considerable decrease in missed deadlines compared to Time Shared and Space Shared algorithms, thus, increasing the disparity in effectiveness of the latter two algorithms. B. Resource Prioritization Coupling Scheduler: Algorithms delving into resource allocation and optimization of utilization of worker nodes are perhaps the most investigated topic within the field of MapReduce. As processing and handling of data is getting more and more centralized, virtualized Hadoop clusters seem to be the future of MapReduce and has emerged as enabler for business ventures through the cloud. In [7], it was argued that the widely used Fair Scheduler has a starvation problem involving the Map and Reduce operations. The paper focuses on coupling the two progresses, instead of treating them separately. The authors [7] also performed a performance comparison, proving that Coupling Scheduler performs better than Fair Scheduler in handling tasks with varying map service times. The main effect this has on resource usage is that reducers are gradually launched as more and more maps are completed, instead of allocating a quantity of reducers based on predicted need, i.e. as seen in [5]. The benefits is that there is virtually no under-utilization of resources in the cluster, making the approach [5] energy efficient. However, Coupling Scheduler ignores job sizes and can therefore be inefficient when processing jobs with large map service times. This is due to the coupling nature of ""sticky processor sharing"" [7], where a map task gradually gets the amount of reducers it needs, disregarding task completion time, potentially allowing huge tasks to complete before allocating resources to smaller tasks [7]. Triple-Queue Scheduler and MR-predict: While [7] preemptively couples mappers and reducers regardless of task size, the authors behind the paper ""A Dynamic MapReduce Scheduler for Heterogeneous Workloads"" [8] have devised a prediction method called MR-predict to detect workloads in real time. MR-predict focuses on optimizing the utilization and balance between I/O-bound vs CPU-bound applications, which is not a concern in legacy Hadoop MapReduce. Based on MR-Predict, which classifies a type of workload, they propose Triple-Queue Scheduler to 176 serve tasks based on the predicted workload. The standard First Come First Served strategy would not be able to handle scheduling different task types, as it has a single queue. With the Triple-Queue Scheduler the authors solve this issue by paralleling queues, and delivering I/O bound tasks to nodes with I/O resources to spare, while at the same time serving CPU bound tasks to fitting nodes. MR-predict checks the history of a job to predict the future tasks, and from there describe the workload type. If a new job is received with no previous history, the job is sent to a waiting queue within Triple-Queue Scheduler, where the scheduler will assign one map task of that job to every TaskTracker whenever it has idle slots. When the map tasks finish, MR-predict calculates the MTCT (Map Task Completed Time), MID (Map Input Data) and MOD (Map Output Data) based on the data gathered from these tasks. The type of workload then gets determined, and the job is moved into either an I/O-Bound queue, or a CPU-Bound queue. Furthermore, the scheduler monitors tasks assigned to queues, checking if MTCT increases. If MTCT increase passes the threshold of 140%, the scheduler determines that the task was assigned to the wrong queue, and moves the task to an alternative queue. The tests were run on a native Hadoop cluster, running TeraSort, GrepCount and WordCount. The authors observed a 20% increase in resource utilization and an impressive 30% increase in throughput. This is naturally only meant for heterogeneous workloads, as there would be little use to predict a homogeneous job flow. The algorithm is also exclusively useful in a homogeneous environment [8]. Workload Characteristic and Resource Aware Scheduler: In this paper, the authors propose WCRA­ scheduling of Hadoop clusters [9]. WCRA-scheduling checks the CPU, RAM and I/O-load on the nodes fust. Afterwards, all the tasks are sorted based on Estimated Completion Time then scheduled on the most fitting nodes. The work bears some similarity to [8], but also embraces RAM as an important parameter, ensuring that more than 25% of the primary memory is always available before scheduling a job. The authors argue that ""is critical in case of CPU and Disk I/O bound tasks"" [9]. It was found that ""compute node works significantly if it has the available physical memory greater than 25%. Tasks are assigned to the node if the memory availability is greater than 25%"" [9]. WRCA-scheduling has the benefit of being specifically designed to handle heterogeneous clusters. In a similar manner to [8], WRCA works by fust completing a set of sample tasks for a new job in order to determine predicted type of workload, and then classifies the job as either CPU­ bound or I/O-bound. Compared to [8], more extensive testing with more jobs were reported, albeit on a smaller cluster environment, and actually reached the same amount of increase in throughput (30%) when compared to FIFO, Fair­ scheduler and Capacity scheduler. Adaptive resource allocation schedulers: By defmition, an adaptive resource allocation scheduler adapts to the capabilities and performance of each node in the cluster individually. In [10], the authors argued that legacy resource-aware schedulers give nodes a fixed amount of resources for each job, potentially causing over/under- Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore. Restrictions apply. utilization of resources, in contrast to their devised scheduler [10] which dynamically adapts its resource allocation over the course of the job. Based on the estimated amount of tasks that can be processed concurrently on each node, the devised algorithm shrinks/extends the amount of resources over the run time. This algorithm is also designed to optimize a heterogeneous cluster as in [8]. Instead of predicting tasks and queueing the workloads, the authors propose a strategy where the worker nodes and their ""available/lack resources (CPU and memory) are monitored, and based on this, the scheduler will extend/shrink the capacity of the TaskTracker by increasing/decreasing the number of map/reduce slots of the TaskTracker"" [10]. The approach was tested using different benchmarks including TeraSort, PiEstimator and WordCound, in a similar manner to the main stream of papers in this category. According to the experimental fmdings, it was observed an average increase of the completion time of all tasks by around 30%. As in the case of [6], this approach also yields an increased effectiveness with reduced nodes/slots in the cluster, compared to native algorithms like FIFO and Fair-scheduler [10]. e. Job Size Size-Based Scheduling: As was remarked in a series of papers such as in [7], ignoring the job size might halt throughput in cluster, although it is very resource-effective. Weighing job-size first should then logically considerably increase throughput in the cluster and is claimed to achieve ""near-optimal system response times"" [11]. The hard part about designing an algorithm focused on size is that it has to prioritize jobs/tasks with the shortest remaining completion time to be effective. This can lead to bigger tasks starving to get resources. The authors introduce HFSP (Size-based Scheduling for Hadoop) [11], a scheduler that lets Hadoop determine job size during execution in real time. They claim that their approach ""satisfies both the interactivity requirements of small jobs and the performance requirements of large jobs, which can thus coexist in a cluster without requiring manual setups and complex tuning"" [11]. To be able to schedule tasks with short completion times without forcing starvation of larger tasks, the author implement a common aging policy, where the cost of a task in the queue gets gradually decremented as it waits for resources. They call the technique ""Shortest Remaining Virtual Time (SRVT)"" [11]. SRVT results in a slight increase in average throughput time, at the benefit of virtually eliminating errors and starvation in the queue. By applying a size-based scheduling algorithm, the authors also argue that the scheduler has significantly reduced overhead, as its only concern is the direct size of the job, and no additional calculations are necessary. As seen in [9] and [8], this scheduler determines size by running a small set of sample tasks from a job. The approach [11] is endowed with a preemptive estimation module that sets a coarse size value for the job before the samples are processed, which gets gradually refmed as samples are completed. The authors have measured the perfonnance of their approach in a benchmarking suite, and found a significant decrease in system response times. Contrary to [6] and [10], this 177 effectiveness disparity increased in larger jobs and larger clusters [12]. LsPS (Leveraging size Patterns Scheduler): The work reported in [11] proposes an algorithm that specializes in handling bursty workloads in a multi-user environment, by tuning resource shares among users, and even the scheduling algorithm for each user, based on job size. The authors have tested their algorithm both in a controlled environment and in a production cluster: Amazon EC2, and observed reduced MapReduce job response times. The job tracker calculates how many slots and resources each user should have based on the history of task completion, and predicted completion time based on job size. Every time a task is finished, the statistics of that particular user are updated. Based on all this data, the Job Tracker continually sorts users instead of tasks, making sure to let the most efficient users get the most slots, without starving other users. This is done by granting a slot share ratio to the users that is inversely proportional to their job average sizes. In the case of new users entering the cluster have no history for determining average job size/completion time, predefined job profIles are added to the scheduler, and assigned to users based on a couple of user­ defmed criteria. The authors have chosen a FIFO-algorithm as a fallback, in case of tasks getting the same cost and confusing LsPS, making sure that the first task submitted simply is processed. The experimental results show huge promise in enterprise environments, with multiple users, heterogeneous clusters and heterogeneous workloads. For smaller clusters and predictable workloads however, the overhead cost might be too high [11]. D. Improving Native Hadoop Fair and Efficient Slot Configuration and Scheduling: In many cases, enterprises just want to use Hadoop for parallel big data processing out-of-the-box, without much configuration by experts. This frequently leads to using native Hadoop schedulers which may be inefficient. The team behind FRESH (FaiR and Efficient Slot scheduling for Hadoop) [13] argue that Hadoop is far too complex to tweak for many users. They propose FRESH that dynamically configures slots and assign tasks to achieve optimal performance from a cluster. They introduce two different algorithms, one which statically assigns slots for each job submitted, and one that dynamically alters the amounts of slots for a job during run time. The static algorithm calculates optimal amounts of slots for each job, allocates slots for nodes, and then hands the jobs over to Fair Scheduler to server tasks to the nodes. The dynamic algorithm takes the whole process without help for Fair Scheduler, and acts as both back end slot allocator and task server for nodes, dynamically monitoring each node and making sure all tasks are processed with optimal fairness. The authors present their own novel definition of fairness, named overall fairness with an algorithm that more accurately disperses resources between jobs. The reported tests show a significant improvement, especially with the dynamic slot allocation, increasing makespan by up to 30% compared to Fair scheduler across all types of workloads [13]. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore. Restrictions apply. Chronos: Instead of creating a totally new ""default"" scheduler from scratch, a different approach for enhancing the native Hadoop scheduler is proposed by the authors of Chronos: Failure-A ware Scheduling in Shared Hadoop Clusters [14]. The authors argue that the performance of Hadoop systems in part depends on how failures are handled. Hadoop handles failures by re-executing all the tasks of the failed machines. In this case, the machines need to wait for resources to execute recovery tasks. They argue that the fact that this is black-boxed from Hadoop schedulers (not visible or configurable for schedulers) may hinder the schedulers from optimizing the workflow according to the scheduling goal efficiently, and thus significantly reducing performance of the cluster. In order to counter this problem, the authors introduce Chronos, a failure-aware scheduling strategy that preemptively allocates resources to nodes with task failures, and also considers data locality for optimized performance. Chronos is an optional component independent from schedulers, and works together with the scheduler of a users choice (like native Hadoop - FIFO or Fair). Chronos works basically by listening to heartbeats from Hadoop. Upon a failure, Chronos queries the Job Tracker for the nodes that has task failures. Chronos then attempts to ""inject"" the recovery tasks into the front of the task queue, based on an algorithm working together with the scheduler goal to determine priorities of tasks. When it finds an appropriate slot, it then allocates resources away from less important tasks in the queue and on to the recovering node. The latter strategy allows the failed slots to preemptively be freed, instead of waiting in starvation for recovery resources. The authors tested Chronos in combination with FIFO and Fair­ scheduler and experienced a reduction in job completion times by up to an astonishing percentage of 55%. E. Hybrid Approach Resource and Deadline-aware Job Scheduling: As aforementioned, there is a vast variety of interesting and effective scheduling algorithms with different prioritization, and different drawbacks. In general term, hybrid approaches aspire to combine one or more different approaches so that to distill the best of their combination [15]. In [15], the authors introduce a hybrid algorithm that takes both task deadlines and a predicted future resource availability into account when allocating tasks. To achieve this they apply a receding horizon control algorithm in combination with a self-learning model that learns to predict an estimate of future resource availability and job completion times. They do this by introducing control intervals in which actual resources and job sizes and predicted resources and job sizes are calculated, and based on this they optimize the schedule while evaluating deadlines. This is especially useful in an environment where resources are dynamic and heterogeneous, as resources can be added or taken away during run time, and the controls will catch the updates and optimize for it. Tested in a controlled environment against Fair Scheduler, the authors were able to reduce the penalty of deadline misses by 36%, and against Earliest Deadline First scheduler they show a reduced penalty of 10% [15]. 178 Classification and Optimization based Scheduler: A truly hybrid solution is introduced in [16]. The authors analyze the performance of widely used schedulers like FIFO and Fair Share Scheduler, and an algorithm reckoned as COSHH (Classification and Optimization based Scheduler for Heterogeneous Hadoop) scheduler. Based on the performances of these algorithms, the paper introduces a hybrid solution where all three algorithms are used in the same cluster based on different system loads. ""When the system is underloaded, and the number of free slots is greater than the number of waiting tasks, the scheduler switches to the FIFO algorithm. Here, the simple FIFO algorithm can improve the average completion time with minimum scheduling overhead. However, as the system load increases such that the available number of slots is less than the number of waiting tasks, the hybrid scheduler selects the Fair Sharing algorithm. When the load increases such that the system is overloaded, and the number of waiting tasks in job queues is quickly increasing, the Fair Sharing algorithm can greatly increase the average completion time. Therefore, the scheduler switches to the COSHH algorithm which improves the average completion time, while avoiding considerable degradation in the fairness metric"" [16]. The hybrid scheduler chooses the best scheduling algorithm for different scales of jobs and resources to address average completion time and fairness [16]. The results of the experiments are thoroughly documented, showing that the approach works, in numerous cases cutting scheduling and completion-time by half [16]. III. CONCLUSION After reviewing a number of related works on Hadoop scheduling, the conclusion that stands out is the potential for improvement in the default Hadoop scheduling algorithms. Almost all the surveyed schedulers in this paper have advantages in terms of fairness and completion time compared to the default Hadoop scheduling policy. Interestingly, FRESH [13] and COSHH-hybrid [16] have the potential to become a native part of Hadoop, replacing FIFO and Fair sharing, as well as Chronos [14] which holds a lot of promise while still needing further testing. When it comes to large enterprise environments, LsPS [11] represents a promising approach as it delivered unprecedented performance and user control in a scalable and dynamic cluster, vastly improving upon default schedulers. REFERENCES [I] Bollier, D., & Firestone, C. M. . The promise and peril of big data (p. 1). Washington, DC: Aspen Institute, Communications and Society Program. [2] Gantz, J., & Reinsel, D. . The digital universe in 2020: Big data, bigger digital shadows, and biggest growth in the far east. IDC iView: IDC Analyze the future, 2007, 1-16, [3] Richards, N. M., & King, 1. H. . Three paradoxes of big data. [4] Huang, G., He, J., Chi, C. H., Zhou, w., & Zhang, Y. (2015, June). A Data as a Product Model for Future Consumption of Big Stream Data in Clouds. In 2015 IEEE International Conference on Services Computing (SCC), (pp. 256-263). IEEE. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore. Restrictions apply. [5] Kc, K., & Anyanwu, K. (2010, November). Scheduling hadoop jobs to meet deadlines. In 2010 IEEE Second International Conference on Cloud Computing Technology and Science (CloudCom) (pp. 388-392). IEEE. [6] Perret, Q., Charlemagne, G., Sotiriadis, S., & Bessis, N. (2013, March). A deadline scheduler for jobs in distributed systems. In 2013 27th International Conference on Advanced Information Networking and Applications Workshops (WAINA) (pp. 757-764). IEEE. [7] Tan, J., Meng, X., & Zhang, L. (2012, March). Performance analysis of coupling scheduler for mapreduce/hadoop. In INFOCOM, 2012 Proceedings IEEE (pp. 2586-2590). IEEE. [8] Tian, c., Zhou, H., He, Y., & Zha, L. (2009, August). A dynamic mapreduce scheduler for heterogeneous workloads. In 2009 Eighth International Conference on Grid and Cooperative Computing (pp. 218-224). IEEE. [9] Divya, M., & Annappa, B. (2015, July). Workload characteristics and resource aware Hadoop scheduler. In 2015 IEEE 2nd International Conference on Recent Trends in Information Systems (ReTIS) (pp. 163-168). IEEE. [10] Elkholy, A. M., & Sail am, E. A. (2014, December). Self adaptive Hadoop scheduler for heterogeneous resources. In 2014 9th International Conference on Computer Engineering & Systems (lCCES) (pp. 427-432). IEEE 179 [II] Yao, Y., Tai, J., Sheng, B., & Mi, N. . LsPS: A Job Size­ Based Scheduler for Efficient Task Assignments in Hadoop. IEEE Transactions on Cloud Computing, 3, 411-424. [12] Pastorelli, M., Barbuzzi, A., Carra, D., Dell' Amico, M., & Michiardi, P. (2013, October). HFSP: size-based scheduling for Hadoop. In 2013 IEEE International Conference on Big Data (pp. 51-59). IEEE. [13] Wang, J., Yao, Y., Mao, Y., Sheng, B., & Mi, N. (2014, June). Fresh: Fair and efficient slot configuration and scheduling for hadoop clusters. In 2014 IEEE 7th International Conference on Cloud Computing (pp. 761-768). IEEE. ISO 690 [14] Yildiz, 0., Ibrahim, S., Phuong, T. A., & Antoniu, G. (2015, October). Chronos: Failure-aware scheduling in shared hadoop clusters. In 2015 IEEE International Conference on Big Data (Big Data) (pp. 313-318). IEEE. [15] Cheng, D., Rao, J., Jiang, C., & Zhou, X. (2015, May). Resource and deadline-aware job scheduling in dynamic hadoop clusters. In 2015 IEEE International Parallel and Distributed Processing Symposium (IPDPS) (pp. 956-965). IEEE. [16] Rasooli, A., & Down, D. G. (2012, November). A hybrid scheduling approach for scalable heterogeneous hadoop systems. In High Performance Computing, Networking, Storage and Analysis (SCC), 2012 SC Companion: (pp. 1284-1291). IEEE. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:17:31 UTC from IEEE Xplore. Restrictions apply.","-Apache Hadoop is one of the most prominent and early technologies for handling big data. Different scheduling algorithms within the framework of Apache Hadoop were developed in the last decade. In this paper, we attempt to provide a comprehensive overview over the different paradigms for scheduling in Apache Hadoop. The surveyed approaches fall under different categories, namely, Deadline prioritization, Resource prioritization, Job size prioritization, Hybrid approaches and recent trends for improvements upon default schedulers.","['Roger Johannessen', 'Anis Yazidi', 'Boning Feng']"
An Intelligent Collaborative Image-Sensing System for Disease Detection,"Djenouri, Youcef and Belhadi, Asma and Yazidi, Anis and Srivastava, Gautam and Chatterjee, Pushpita and Lin, Jerry Chun-Wei",2023,2.0,23,IEEE Sensors Journal,article,"IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023
947
An Intelligent Collaborative Image-Sensing
System for Disease Detection
Youcef Djenouri
, Asma Belhadi, Anis Yazidi
, Gautam Srivastava
, Senior Member, IEEE,
Pushpita Chatterjee
, and Jerry Chun-Wei Lin
, Senior Member, IEEE
Abstract INTRODUCTION
S
MART healthcare is a framework that leverages wear-
able devices, the Internet of Medical Things (IoMT),
powerful machine learning algorithms, and wireless commu-
nication technology to connect people, resources, and orga-
nizations as well as then intelligently manage and respond
Manuscript received 21 April 2022; revised 9 July 2022; accepted
13 August 2022. Date of publication 2 September 2022; date of current
version 12 January 2023. The associate editor coordinating the review
of this article and approving it for publication was Dr. Hari P. Gupta.
(Corresponding author: Jerry Chun-Wei Lin.)
Youcef Djenouri is with SINTEF Digital, 0610 Oslo, Norway (e-mail:
youcef.djenouri@sintef.no).
Asma Belhadi is with the School of Economics, Innovation and
Technology, Kristiania University College, 0107 Oslo, Norway (e-mail:
asma.belhadi@kristiania.no).
Anis Yazidi is with the Department of Computer Science, OsloMet-Oslo
Metropolitan University, 0167 Oslo, Norway, also with the Department of
Neurosurgery, Oslo University Hospital, 0450 Oslo, Norway, and also with
the Department of Computer Science, Norwegian University of Science
and Technology, 7491 Trondheim, Norway (e-mail: anisy@oslomet.no).
Gautam Srivastava is with the Department of Math and Computer
Science, Brandon University, Brandon, MB R7A 6A9, Canada, also with
Research Centre for Interneural Computing, China Medical University,
Taichung 404, Taiwan, and also with the Department of Computer
Science and Math, Lebanese American University, Beirut 1102, Lebanon
(e-mail: SRIVASTAVAG@brandonu.ca).
Pushpita Chatterjee is with the Department of Computer Science, Ten-
nessee State University, Nashville, TN 37209 USA (e-mail: pushpita.c@
ieee.org).
Jerry Chun-Wei Lin is with the Department of Computer Sci-
ence, Electrical Engineering and Mathematical Sciences, Western Nor-
way University of Applied Sciences, 5063 Bergen, Norway (e-mail:
jerrylin@ieee.org).
Digital Object Identiﬁer 10.1109/JSEN.2022.3202437
to healthcare needs [1], [2]. Medical sensors, often referred
to as IoMT, are a critical component of smart healthcare.
IoMT may be able to be driving today’s smart healthcare
by leveraging cutting-edge technologies, such as artiﬁcial
intelligence (AI), cloud computing, coupled with the emer-
gent sixth generation (6G) mobile networks. The increasing
use of IoMT devices, as well as data-driven apps, may
be able to be contributing to positive effects ranging from
improved user-health attitudes and early disease detection to
higher-quality care and a more cost-effective smart healthcare
ecosystem.
It may be expected that the integration of the Internet of
the Things (IoT) with medical devices in a smart healthcare
system will increase the quality and the efﬁciency of services
for patients, especially for patients with chronic diseases who
need continuous care. With the support of Internet communica-
tions, IoMT enables continuous monitoring of important phys-
iological functions in, otherwise, healthy individuals, so that
diseases may be able to be detected, and appropriate action
may be able to be taken immediately. This may be able to be
particularly important during pandemics, such as the recent
Coronavirus-disease pandemic that raged globally [3], [4],
where taking into account our advanced and technologically
advanced healthcare systems, which tend to include both
medical personnel with support systems, saw themselves under
an absurd amount of stress [5]. The demand for a remote,
autonomous, and ubiquitous IoMT architecture may be able
to be greater than ever [6].
1558-1748 © 2022 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 948
IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023
The integration of smart sensors and controls within the
Internet also has turned any and all “so-called” cyber-physical
systems (CPSs) into IoMT, which has recently emerged as
one of the main driving forces behind the fourth industrial
revolution nicknamed Industry 4.0 [7]. In these directions,
healthcare itself may be able to be also undergoing a digital
revolution through the integration of smart devices. On the
other hand, the number of IoMT devices is expected to
increase signiﬁcantly over the next few years. Furthermore,
the heterogeneity of the various IoMT components (network
interfaces, data format, data semantics, and communication
protocols) will lead to difﬁculties in interoperability and data
protection [7]. In this regard, a ubiquitous, and collaborative
health platform for all smart devices must be adaptable enough
to accommodate all these concepts.
A. Motivation
Technologies based on AI are very promising in this regard
and in medical applications in general [8], [9]. These include
techniques, such as multiagent systems (MASs), networks
that incorporate deep learning (DL), and advanced computa-
tional techniques, such as evolutionary computation (EC) or
other well-known ones. DL is a well-known branch of AI
that can involve the creation of complicated but complete
models with a high number of layers and a large number
of hyperparameters. These models are not only capable of
learning from large amounts of data, but they can also
directly extract important aspects from these huge amounts of
data. Medical data analysis, especially disease detection, is a
fascinating area of DL [10], [11], [12], [13]. For example,
Coronavirus-disease pandemic samples were used to build
an intelligent model to calculate infection rates [10]. The
latter work uses both supervised and unsupervised learning
methods, resulting in a 40% increase in detection speed.
Transfer learning was used to evaluate pathogen frames and
validate Coronavirus-disease pandemic instances with typical
virus-based pneumonia [11]. The result highlights the value of
using intelligent approaches for Coronavirus-disease pandemic
diagnosis.
We may be able to also observe examples that have been
substantially explored in the newer, fresh ﬁeld of distributed
DL [14], [15], [16], [17], [18] by studying various types of DL
models that are well established in medicine as well as disease
detection. The identiﬁcation of illnesses is the primary objec-
tive of these technologies, particularly the distributed ones.
This will assist medical professionals in making decisions that
are acceptable and fair within the realm of medicine. The
intricacy of the data is the single most critical barrier that
makes disease detection more difﬁcult than it would otherwise
be. Indeed, diseases may be able to have different forms and
manifestations that are difﬁcult to detect. We are researching
the possibility of developing a comprehensive framework
that makes use of DL to get beyond these disadvantages
and MASs.
The large number of hyperparameters provided by DL
models is another signiﬁcant obstacle to the disease detection
process. The random selection of these values leads to a
signiﬁcant decrease in the overall performance during the
learning phase. Moreover, the process of setting the para-
meters for such frameworks takes a long time, and there
is no guarantee of satisfactory convergence. The effective-
ness of EC in tackling complicated problems [19], [20] has
led this research to tune the parameters of the proposed
framework.
B. Contributions
To the best of our knowledge, this is the ﬁrst paper to take
an in-depth look at combining MASs, EC, and DL for disease
detection. Below is a list of the major contributions.
1) We provide an collaborative system for disease detec-
tion (ALMOST), a new paradigm that uses DL, MAS,
and EC to identify diseases. To learn from medical
training data and different diseases, each and every
agent uses its DL architecture. Each iteration of the
architecture establishes communication between agents
to share information and reduce the error learning rate.
2) We
show
how
many
convolutional
neural
net-
works (CNNs) may be able to work together to process
large amounts of data in the medical domain. Several
optimizations, such as batch normalization and dropout
algorithms, ensure that the CNN processes medical data
with great accuracy.
3) To intelligently explore the conﬁguration space of dif-
ferent hyper parameter values, we propose a new evo-
lutionary computational technique based on a genetic
behavior. This approach improves the convergence of
ALMOST in predicting diseases from medical data.
4) Extensive testing was conducted to demonstrate the
applicability
of
ALMOST.
The
ﬁndings
demon-
strated that the ALMOST performs better than other
well-known illness identiﬁcation algorithms in terms of
the quality of the information and also in terms of
computation time when training large medical data.
From here on, this article is arranged as follows. Section II
provides an in-depth examination of related studies on disease
detection. Section III provides a comprehensive understanding
of the ALMOST methodology. A performance evaluation
of ALMOST is shown in Section IV. Section V discusses
the major consequences of using ALMOST on medical data
and the prospects for the future of the research. Section VI
concludes this article.
II. LITERATURE REVIEW
A. AI-Based Solutions
Pattern mining [21], [22], [23] is one of the approaches
to derive and reveal the potential relationships of the items
in the databases. Nawaz et al. [24] investigated the use of
pattern mining in the analysis of medical diseases. The set of
Coronavirus-disease pandemic patient data is converted into a
set of transactions, where each and every patient is represented
by a transaction, and each Coronavirus-disease pandemic-
based information related to the patient is represented by an
item. A pattern mining algorithm is then applied to the set
of transactions to extract relevant patterns. The latter was
used to identify diseases based on the correlation between
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 DJENOURI et al.: INTELLIGENT COLLABORATIVE IMAGE-SENSING SYSTEM FOR DISEASE DETECTION
949
medical data features. Wang et al. [10] automated the process
of image assessment by exploring the segmentation as well
as classiﬁcation of DL-based architectures. Thus, we may be
able to achieve a reasonable estimate of the always illusory
Coronavirus-disease pandemic infection rate. Wang et al. [11]
found viral pneumonia from more than 1000 images of
pathogens. The experiments showed a clear beneﬁt of using
intelligent methods for disease diagnosis. Yan et al. [25] used
a topological approach to analyze nonlinear dynamics to exam-
ine gait complexity ﬂuctuations in Parkinson’s disease patients
to detect the Freezing-of-Gait episode. The 3-D acceleration
data from eight individuals with symptoms are used to extract
relevant features from the acceleration signals using topo-
logical analysis of the reconstructed process. Jain et al. [26]
demonstrated the performances of using Inception-V3 for
Coronavirus-disease pandemic disease identiﬁcation through
data enrichment. Sedik et al. [27] demonstrated the efﬁciency
of using CNN in Coronavirus-disease pandemic identiﬁca-
tion. This article also demonstrated the importance of multi-
modal data, in which the authors collected medical data from
multiple sources, including tomographic and X-ray images.
Manoj et al. [28] took a look at an incentive-based system,
where the Coronavirus pandemic could be better planned for
using an incentive system using block chain. In this solution,
governments globally can prepare and plan better strategies
for ﬁghting the virus using the availability of data from
both a geographic point of view but also qualitative data
around the disease. By being able to have more accurate
and better data around the pandemic, and have it available
in a decentralized fashion being managed by block chain,
will allow a faster response time to virus outbreaks in the
future.
B. Hybrid-Based Solutions
Chae et al. [29] predicted infectious diseases by success-
fully exploring long-term short-term memory with autoregres-
sive moving average. The proposed model is improved by
the ensemble learning mechanism. Therefore, more sources
of information were collected and extracted from social net-
works. Ahuja et al. [30] implemented four DL architectures
(ResNet18, ResNet50, ResNet101, and SqueezeNet) to capture
Coronavirus-disease pandemic from medical lung CT-scan
data. The models are pretrained using a large collection of
images from different domains. The transfer learning mech-
anism is used to learn the Coronavirus-disease pandemic
cases from the medical data. Wong et al. [31] analyzed the
effect of data-driven solutions for infectious diseases. They
explored the combination of various data management as well
as AI techniques to help healthcare professionals mitigate
the risk of disease detection and enable better diagnosis in
a smart healthcare environment. Hirano et al. [32] classiﬁed
the various diseases using the model for use in DL. The
classiﬁcation models developed are based on three types of
medical images: photographic images, X-ray chest images, and
retinopathy images. Three applications are then investigated,
including skin cancer, transmissible diabetics, and pneumonia.
Transfer learning with the adversarial neural network has been
implemented. The transfer learning mechanism allows the
model developed from various medical sources to be trained,
and the adversarial network, which may be able to handle both
non-targeted and targeted attacks and identify fake medical
images. Jamshidi et al. [33] process multiple sources of med-
ical data by exploring generative adversarial networks, extreme
learning, and long-term short-term memory. This combination
not only enables the handling of heterogeneous medical data
but also increases the disease detection rate. Singh et al. [34]
worked on developing a hybrid model based on both decom-
positions and DL for disease detection. Segments are created
by applying the k-means algorithm to medical data. These
segments are then fed into the CNN to predict diseases based
on the original medical images. Shalbaf et al. [35] imple-
mented 15 pre-trained DL models to automatically identify
the Coronavirus-disease pandemic. These models are based on
three well-known classiﬁcation-based architectures, including
Inception, ResNet, and DenseNet. Ensemble learning is then
explored to merge the results obtained from these models using
the majority voting strategy.
III. ALMOST: AN COLLABORATIVE SYSTEM
FOR DISEASE DETECTION
A. Principle
We begin by explaining the most important aspects of
ALMOST. ALMOST is a combination of many intelligent
strategies for solving disease detection problems. The CNN
is used for disease diagnosis. To correctly execute ALMOST
in a distributed environment where each agent can beneﬁt from
the environment through the reinforcement learning paradigm,
the use of an MAS is investigated. Since DL requires setting
a large number of parameters, up to a million for some
architectures, EC is used to determine the best settings for real-
time processing. The components of ALMOST are discussed
in the next parts.
B. Learning Phase
The learning phase is done with the help of CNNs [36].
CNN is a common type of deep architecture in computer
vision applications, such as object detection and identiﬁcation.
In recent years, the adaptability of this method has helped
both time series and text data. CNN is based on the concept
of extracting features from matrix data using convolutional
ﬁlters. Convolutional ﬁlters create a new image by applying
a series of weights to the matrix data of each pixel in the
image. As a result, a new image is generated. In addition, well-
known operators for DL models, such as batch normalization
and dropout, are used during training to increase the accuracy
of the proposed framework. This was achieved using the
dropout method. Batch normalization is one of the factors
that help the network to converge faster, while the dropout
method acts as a regulator that prevents the network from
overﬁtting. These two methods are necessary for the network
to achieve high accuracy. Below is a complete description of
these components.
1) Batch Normalization: To efﬁciently train a large number
of layers, we used the batch normalization technique in
all steps of the training phase. With only a few epochs,
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 950
IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023
the learning process may be able to converge better.
Batch normalization is performed after each and every
convolutional layer in the CNN.
2) Dropout: It is a technique that allows you to avoid over
adaptation during training. In each and every phase,
the outputs of the neurons in the hidden layers are
randomly skipped. Propagating a deep network with a
constrained number of weights may be thought of as a
straightforward method for bringing about convergence
of predictions during the inference phase.
C. Multiagents Systems
The MAS is used to learn the different diseases in the
training phase. The agents collaborate using the reinforcement
learning process. Consider the tuple ⟨A, S, U, R⟩, an MAS is
deﬁned by A. There are Aagents in total, and for the purposes
of this discussion, each of them is treated as if it were an
independent Markov decision process. A ﬁnite collection of
environmental states is represented by the variable S, a set
of actions by the variable U, and a reward function by the
variable R. The methods presented in A describe not only how
each agent should behave given the current situation, but also
how it should decide on the appropriate actions. For instance,
in the process of disease detection, the mission of each agent is
to identify the most effective tactic that maximizes the value
of the target objective function, which may be the number
of diseases that are accurately identiﬁed. We will discuss the
many parts that make up the MAS that we have designed by
the sections as follows.
1) Environment: The environment may be thought of as
a collection of databases that hold a massive quantity
of data that were gathered by various intelligent sensor
devices. As a result, the environment is able to create
certain conditions for training the agents and determine
the optimal actions.
2) State: The next action of each and every agent is deter-
mined by the decisions made in earlier phases. The state
of each agent is, thus, composed of two distinct parts:
the data being processed and a collection of actions
completed in the past. When calculating the size of the
state space S, the number of observations contained in
the database is taken into account.
3) Action: It is the assignment of each and every obser-
vation in the database’s decision-making behavior. For
instance, a detection task is the assignment of each and
every disease category.
4) Reward: It is essential to decide on an acceptable reward
function. It makes it possible for each agent in A to
have a more fruitful learning experience. Using data that
included ground truths, we crafted a reward in response
to the behaviors of the agent.
Therefore, the ﬁrst thing each agent does is to perform
a scan of the data collected by the ith intelligent sensor.
This is denoted by the notation Ai. It then computes the
ﬁrst observation of the ith intelligent sensor, and all future
observations of that sensor. The ground truth for the ﬁrst
observation is used in the creation of a reward function speciﬁc
to that choice. This approach is repeated for each of the ith
smart sensor observations. As a result, a set of local options,
denoted LDi, is generated for each agent Ai. The agents then
learn from the local decisions {LDi} to optimally ﬁnd the
global decision. This learning is realized through the process
of reinforcement learning, where the best agents that have a
high score for their local decisions receive a reward.
D. Hyperparameters Optimization
To achieve optimal performance, we apply an evolutionary-
based technique to optimize hyperparameters. The adaptation
of the genetic algorithm is proposed due to its known balance
of intensiﬁcation and diversiﬁcation. A complete description
of the proposed algorithm is given for solving our hyper
parameter optimization problem.
Let HP = {HP1, HP2, . . . , HPr} be the set of hyperpa-
rameters, where r is the number of hyperparameters in the
evolved ALMOST. Each HPi represents a set of the possible
values of the hyperparameter in question. The conﬁguration
space C is then deﬁned by the set of all possible conﬁgurations,
where each and every conﬁguration is a vector. The possible
values of all hyperparameters belong to HP. When it comes
to hyperparameter optimization, our methodology focuses on
determining the ideal conﬁguration that provides the highest
level of accuracy. The conﬁguration space is deﬁned by the
total number of possible hyper parameter values, as given in
|C| =
r
i=1
|HPi|.
(1)
Because of the vastness of the conﬁguration space, ﬁnding
the ideal solutions requires considerable computational effort.
Consider the epoch parameter, which has a max value of
1000, the error rate, which has a max value of 100, as well
as the number of agents in the evolved model, which has
a max value of 100; then, the search space will include
ten million conﬁgurations, so it is not possible to apply
exhaustive search methods in this case. To solve this challenge,
evolutionary computational methods are used. Below are the
main components of our solution.
1) Population Initialization: We are trying to distribute |P|,
which is the initial population, noted P. This initial population
should be uniformly distributed in the conﬁguration space C.
Proper examination of each and every of the numerous alter-
native conﬁgurations that tend to cover most locations within
C may be able to then be performed using this uniform
distribution technique. We must ﬁrst create the population,
taking diversity into account.
This process begins with the random generation of an indi-
vidual represented by a single C conﬁguration. It is possible
that after starting with this individual, we can generate more
|P|−1, assuming that each newly formed individual is differ-
ent from the previously generated individuals. We could use
a distance measure between two successive conﬁgurations to
evaluate dissimilarity based on the individuals formed in those
conﬁgurations. This would be done based on the individuals
generated in those conﬁgurations. The original population,
denoted by the variable P, should, in turn, be able to maximize
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 DJENOURI et al.: INTELLIGENT COLLABORATIVE IMAGE-SENSING SYSTEM FOR DISEASE DETECTION
951
the diversiﬁcation function shown in
Diversify(P) =
|P|

i=1
|P|

j=1
Distance(Ci, C j)
(2)
where Distance(Ci, C j) is the distance between the conﬁgura-
tions of the ith and the jth individuals, respectively.
2) Crossover: To produce new offspring, each and every of
the two individuals in the current population goes through the
following steps.
1) We start at 1 and work our way up to r, creating a
random sequence of crossing points. At each of these
points, we divide the intersection into its left and right
halves, respectively.
2) Both the left-hand side of the original, which is copied
to the left-hand side of the ﬁrst descendant, and the
right-hand side of the original, which is copied to the
right-hand side of the second descendant, are descen-
dants of each other.
3) The right-hand side of the second person is inherited
by the ﬁrst generation, while the left-hand side of the
second individual is inherited by the second generation.
3) Mutation: Mutation facilitates the search for diversity.
We use a strategy in which the value of a single parameter
is randomly varied in every single one of the conﬁgurations
currently in use. The mutation point is chosen randomly and
can have a value between 1 and r, depending on the method.
At each iteration, the value of the mutation point is changed
in the descendants generated by the crossover operator.
4) Fitness Function: Identifying diseases with the highest
possible degree of precision is the goal of the ALMOST
framework. Therefore, to assign points to individuals within
populations, we use the following function:
Fitness(Ci) = DetectionALMOST(Ci).
(3)
Note that the following hold.
1) Ci
is a representation of the conﬁguration of the
ith individual in the population.
2) DetectionALMOST(Ci) indicates the ratio for disease
detection using the developed ALMOST based on the Ci.
Based on these actions, we presented the following method
for optimizing hyperparameter values. In the beginning, the
initial population size, deﬁned as |P|, is randomly gener-
ated. Then, each and every individual is constructed using
population initialization. Then, mutation, and crossover with
mutation and crossover rates (Mr and Cr), is used to generate
conﬁgurations from C. To keep the population size constant,
each individual is evaluated against the ﬁtness function, focus-
ing on maintaining the highest quality |P| individuals. All
others are now deleted. This procedure is then continued
endlessly until the max number of iterations (IMAX) is
reached.
E. Description
Algorithm 1 shows the pseudocode of ALMOST for each
and every agent. The process begins by building the model for
use in DL represented by the CNN with batch normalization
and dropout layers (from lines 4 to 5). The batches of data
Algorithm 1 ALMOST Pseudocode for Each Agent
1: Input: I = {I1, I2, . . . , Im}: the set of m images collected
from sensors.
2: Output: model: The trained model to detect the disease;
DD: the set of the disease detected from I.
3: model ←C N N();
4: model ←model ∪BatchNormalization();
5: model ←model ∪Dropout()
6: Batches ←CreatingBatches(D);
7: Hyper_Param ←G A( f it(model, Batches));
8: DD ←In f erence(Inew, model, Hyper_Param);
9: return < model, DD >.
are created from the input images I in line 6. Then, the
genetic algorithm is applied to optimize the hyperparameters
of the model for use in DL by performing the training phase
on the created batches (line 7). The inference phase is then
run on the trained model to identify the disease of the new
image (line 8). The output of the algorithm is the set of
detected diseases DD and the trained disease detection model
(line 11).
IV. PERFORMANCE EVALUATION
Extensive testing was performed on known medical datasets
speciﬁcally designed for disease detection applications to
validate the use of the proposed ALMOST framework. Exper-
iments were conducted using a desktop computer equipped
with 16 GB of primary memory and an Intel Core i7 processor
for optimal performance. PythonTorch was used for the actual
implementation of each algorithm. We used the Kvasir [37]
medical database to validate the applicability of ALMOST in
disease detection, for disease data for the human digestive
system. The aim is to automate the detection of endoscopic
ﬁndings in the esophagus, stomach, intestines, and rectum. It is
available in two versions. The ﬁrst version, called Kvasir (v1),
consists of 4000 images grouped into eight classes showing
anatomical landmarks, pathological ﬁndings, or endoscopic
procedures. The second version, called Kvasir (v2), expands
on the ﬁrst version and consists of 8000 images with the same
number of classes.
A. Parameter Setting
In ALMOST, several parameters need to be optimized,
including the number of agents, the number of generations, the
crossover and mutation rates, and the population size. Choos-
ing optimal values for these parameters is critical for better
performance of the ALMOST framework. In this experiment,
we analyze the behavior of ALMOST at different values for
the number of agents, number of generations, crossover rate,
and the mutation rate. We varied the number of agents from
2 to 20, the number of generations and population size from
10 to 100, and the crossover rate and mutation rate from
0.01 to 0.99. The behavior of ALMOST may be able to be
summarized as follows.
1) Number of Agents: The experiments showed that when
we vary the number of agents from 2 to 20, the accuracy
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 952
IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023
TABLE I
SUMMARY OF PARAMETER SETTING OF ALMOST
TABLE II
ALMOST VERSUS DISEASE DETECTION SOLUTIONS
of ALMOST increases until ﬁve agents for Kvasir (V1)
and eight agents for Kvasir (V2) where stabilization of
the accuracy is observed.
2) Number Generations: The experiments showed that
when we vary the number of generations from 10 to 100,
the accuracy of ALMOST increases until 45 generations
for Kvasir (V1), and 58 generations for Kvasir (V2)
where stabilization of the accuracy is observed.
3) Population Size: The experiments showed that when we
vary the population size from 10 to 100, the accuracy of
ALMOST increases until 85 individuals for Kvasir (V1),
and 93 individuals for Kvasir (V2) where stabilization
of the accuracy is observed.
4) Crossover Rate: The experiments showed that when we
vary the crossover from 0.01 to 0.99, the accuracy of
ALMOST increases until 0.35 for Kvasir (V1), as well
as 0.47 for Kvasir (V2) where stabilization of the
accuracy is observed.
5) Mutation Rate: The experiments showed when we
vary the mutation from 0.01 to 0.99, the accuracy of
ALMOST increases until 0.53 for Kvasir (V1), as well
as 0.61 for Kvasir (V2) where the stabilization of the
accuracy is observed.
Table I gives the optimal values of the parameters used in
ALMOST for both Kvasir (v1) and Kvasir (v2). The next
experiments aim to validate the usefulness of the proposed
ALMOST framework for disease detection. To reach this
conclusion, an intensive analysis was performed by comparing
ALMOST with the baseline solutions InceptionResNet [34]
and DenseNet [35]). The detailed results with a full explana-
tion are shown below.
B. Quality of Outputs
Table II shows the quality of results from ALMOST and
the baseline solutions: InceptionResNet, DenseNet on Kvasir
(V1), and Kvasir (V2). We varied the percentage of images
used for training from 1000 to 4000 for Kvasir (V1) and
from 1000 to 8000 images for Kvasir (V2). We then calculate
Fig. 1.
ALMOST versus advanced disease detection solutions with
different numbers of error loss values (0.10, 0.08, 0.05, 0.02, and 0.01).
the quality of the results represented by the F1 and accu-
racy formulas. The results show the superiority of ALMOST
compared with the baseline solutions for all scenarios. Thus,
the accuracy of ALMOST is 0.96 when all the data from
Kvasir (V2) are processed, while the accuracy of the two
solutions is less than 0.80 when the same data are trained.
This great performance is due to the efﬁcient components
of ALMOST represented by the DL solution and the MASs,
and the accurate way of the hyperoptimization process. Fig. 2
shows a case study of ALMOST. The ﬁrst three images are
considered as esophagitis disease, and the second three images
are considered as polyps disease, where the last three images
are considered as ulcerative colitis disease.
C. ALMOST for Large-Scale Data
In the next experiment, we will examine the scalability of
ALMOST compared with the baseline solutions when it comes
to processing large amounts of data. For comparison, we will
use Xception [38] and SqueezeNet [39]. These algorithms
have proven their usefulness in a variety of different contexts,
including training huge datasets. Different training scenarios
with different data sizes of Kvasir (v1) and Kvasir (v2) are
run. Data duplication is generated by multiplying Kvasir (v1)
and Kvasir (v2) multiple times (1000, 10000, and 100000).
For each and every redundant sample, changes are generated
using a generative adversarial network. We varied the error
loss to be optimized from 0.10 to 0.01, and the results are
given in Fig. 1. From these results, we may be able to see the
clear superiority of ALMOST over the other two solutions in
terms of training time. This performance may be able to be
explained by the fact that ALMOST is optimized DL where
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 DJENOURI et al.: INTELLIGENT COLLABORATIVE IMAGE-SENSING SYSTEM FOR DISEASE DETECTION
953
Fig. 2.
Case study of ALMOST: the ﬁrst three images are considered as esophagitis disease, and the second three images are considered as
polyps disease, where the last three images are considered as ulcerative colitis disease.
the collaboration between the different agents accelerates the
training process.
V. DISCUSSION AND FUTURE DIRECTION
The primary beneﬁts of applying ALMOST to disease
detection data are presented in this section. We also make
some recommendations for how to improve the ALMOST
framework.
1) The effective combination of intelligent technologies in
the form of DL, MASs, and metaheuristics leads to
a high level of precision. For real-time medical data
management and disease detection, runtime performance
is still a challenge. The development of hybrid systems
that combine evolutionary and exact approaches [40]
to improve the performance of ALMOST could be an
interesting avenue.
2) The proposed methodology provides better results than
previous approaches. It would extremely fascinating to
study the results of ALMOST for other smart healthcare
applications, such as brain tumor detection [41], as well
as surgery [42].
3) Output interpretation is a challenge in ALMOST.
It relies on black-box models that do not implicitly
explain the process of output interpretation. Health-
care practitioners need to understand how the given
output is produced to trust it. This problem is being
addressed by the emerging discipline of explainable
AI (XAI). We intend to incorporate XAI approaches
into ALMOST. This will allow for a more accurate
interpretation of the results from ALMOST.
VI. CONCLUSION
In this article, an intelligent collaborative system for dis-
ease detection is proposed. It studied the different interac-
tions between the medical data using intelligent agents with
an efﬁcient reinforcement learning mechanism. This enables
signiﬁcant determination of various diseases in healthcare
systems. The proposed system was tested on different medical
datasets. The initial results showed the usefulness of using
intelligent agents for healthcare diagnosis. The numerical
results can be seen to also clearly visualize the strength of our
proposed framework when directly compared with baseline
methodologies when focusing on the rate of disease detection.
REFERENCES
[1] R. Yadav et al., “Smart healthcare: RL-based task ofﬂoading scheme
for edge-enable sensor networks,” IEEE Sensors J., vol. 21, no. 22,
pp. 24910–24918, Nov. 2021.
[2] L. Babangida, T. Perumal, N. Mustapha, and R. Yaakob, “Internet of
Things (IoT) based activity recognition strategies in smart homes: A
review,” IEEE Sensors J., vol. 22, no. 9, pp. 8327–8336, May 2022.
[3] Y. Han and H. Yang, “The transmission and diagnosis of 2019 novel
coronavirus infection disease (COVID-19): A Chinese perspective,”
J. Med. Virol., vol. 92, no. 6, pp. 639–644, 2020.
[4] J. He, Y. Guo, R. Mao, and J. Zhang, “Proportion of asymptomatic
coronavirus disease 2019: A systematic review and meta-analysis,”
J. Med. Virol., vol. 93, no. 2, pp. 820–830, 2021.
[5] E. J. Emanuel et al., “Fair allocation of scarce medical resources in
the time of COVID-19,” New England J. Med., vol. 382, no. 21,
pp. 2049–2055, May 2020.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
 954
IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023
[6] T. Yang, M. Gentile, C.-F. Shen, and C.-M. Cheng, “Combining point-
of-care diagnostics and internet of medical things (IoMT) to combat the
COVID-19 pandemic,” Diagnostics, vol. 10, no. 4, p. 224, Apr. 2020.
[7] L. M. Camarinha-Matos, R. Fornasiero, and H. Afsarmanesh, “Collabo-
rative networks as a core enabler of industry 4.0,” in Collaboration in a
Data-Rich World (PRO-VE) (IFIP Advances in Information and Commu-
nication Technology), vol. 506, L. Camarinha-Matos, H. Afsarmanesh,
and R. Fornasiero, Eds. Cham, Switzerland: Springer, 2017, doi:
10.1007/978-3-319-65151-4_1.
[8] S. Pouyanfar et al., “A survey on deep learning: Algorithms, tech-
niques, and applications,” ACM Comput. Surv., vol. 51, no. 5, pp. 1–36,
Sep. 2018.
[9] A. Sharma et al., “Multi-agent system applications to ﬁght COVID-19
pandemic,” Apollo Med., vol. 17, no. 5, p. 41, 2020.
[10] B. Wang et al., “AI-assisted CT imaging analysis for COVID-19
screening: Building and deploying a medical AI system,” Appl. Soft
Comput., vol. 98, Jan. 2021, Art. no. 106897.
[11] S. Wang et al., “A deep learning algorithm using CT images to screen for
corona virus disease (COVID-19),” Eur. Radiol., vol. 31, pp. 6096–6104,
Feb. 2021.
[12] D. M. Khan, K. Masroor, M. F. M. Jailani, N. Yahya, M. Z. Yusoff, and
S. M. Khan, “Development of wavelet coherence EEG as a biomarker
for diagnosis of major depressive disorder,” IEEE Sensors J., vol. 22,
no. 5, pp. 4315–4325, Mar. 2022.
[13] R. Wang et al., “A standalone and portable microﬂuidic imaging detec-
tion system with embedded computing for point-of-care diagnostics,”
IEEE Sensors J., vol. 22, no. 6, pp. 6116–6123, Mar. 2022.
[14] N. Balachandar, K. Chang, J. Kalpathy-Cramer, and D. L. Rubin,
“Accounting for data variability in multi-institutional distributed deep
learning for medical imaging,” J. Amer. Med. Inform. Assoc., vol. 27,
no. 5, pp. 700–708, May 2020.
[15] S. S. Roy, K. Samanta, S. Modak, S. Chatterjee, and R. Bose, “Cross
spectrum aided deep feature extraction based neuromuscular disease
detection framework,” IEEE Sensors Lett., vol. 4, no. 6, pp. 1–4,
Jun. 2020.
[16] H. Ku, W. Susilo, Y. Zhang, W. Liu, and M. Zhang, “Privacy-
preserving federated learning in medical diagnosis with homomorphic
re-encryption,” Comput. Standards Interfaces, vol. 80, Mar. 2022,
Art. no. 103583.
[17] X. Xu, H. Tian, X. Zhang, L. Qi, Q. He, and W. Dou, “DisCOV: Dis-
tributed COVID-19 detection on X-ray images with edge-cloud collab-
oration,” IEEE Trans. Services Comput., vol. 15, no. 3, pp. 1206–1219,
May 2022.
[18] R. Dwivedi, S. Dey, C. Chakraborty, and S. Tiwari, “Grape disease
detection network based on multi-task learning and attention features,”
IEEE Sensors J., vol. 21, no. 16, pp. 17573–17580, Aug. 2021.
[19] U. Ahmed, J. C.-W. Lin, G. Srivastava, R. Yasin, and Y. Djenouri,
“An evolutionary model to mine high expected utility patterns from
uncertain databases,” IEEE Trans. Emerg. Topics Comput. Intell., vol. 5,
no. 1, pp. 19–28, Feb. 2021.
[20] P. Srinivas and R. Katarya, “HyOPTXg: OPTUNA hyper-parameter
optimization framework for predicting cardiovascular disease using
XGBoost,” Biomed. Signal Process. Control, vol. 73, Mar. 2022,
Art. no. 103456.
[21] C.-W. Lin, T.-P. Hong, G.-C. Lan, J.-W. Han, and W.-Y. Lin, “Incre-
mentally mining high utility patterns based on pre-large concept,” Appl.
Intell., vol. 40, no. 2, pp. 343–357, Mar. 2014.
[22] J. C.-W. Lin, W. Gan, P. Fournier-Viger, T.-P. Hong, and J. Zhan,
“Efﬁcient mining of high-utility itemsets using multiple minimum utility
thresholds,” Knowl.-Based Syst., vol. 113, pp. 100–115, Dec. 2016.
[23] W. Gan, J. C.-W. Lin, J. Zhang, P. Fournier-Viger, H.-C. Chao, and
P. S. Yu, “Fast utility mining on sequence data,” IEEE Trans. Cybern.,
vol. 51, no. 2, pp. 487–500, Feb. 2021.
[24] M.
S.
Nawaz,
P.
Fournier-Viger,
A.
Shojaee,
and
H.
Fujita,
“Using artiﬁcial intelligence techniques for COVID-19 genome analy-
sis,”
Int.
J.
Speech
Technol.,
vol.
51,
no.
5,
pp. 3086–3103,
May 2021.
[25] Y. Yan et al., “Topological descriptors of gait nonlinear dynamics
toward freezing-of-gait episodes recognition in Parkinson’s disease,”
IEEE Sensors J., vol. 22, no. 5, pp. 4294–4304, Mar. 2022.
[26] R. Jain, M. Gupta, S. Taneja, and D. J. Hemanth, “Deep learning based
detection and analysis of COVID-19 on chest X-ray images,” Appl.
Intell., vol. 51, pp. 1690–1700, Oct. 22021.
[27] A. Sedik, M. Hammad, F. E. Abd El-Samie, B. B. Gupta, and
A. A. Abd El-Latif, “Efﬁcient deep learning approach for augmented
detection of Coronavirus disease,” Neural Comput. Appl., vol. 34,
pp. 11423–11440, Jan. 2021.
[28] M. Manoj, G. Srivastava, S. R. K. Somayaji, T. R. Gadekallu,
P. K. R. Maddikunta, and S. Bhattacharya, “An incentive based
approach
for
COVID-19
planning
using
blockchain
technology,”
in Proc. IEEE Globecom
Workshops (GC Wkshps), Dec. 2020,
pp. 1–6.
[29] S. Chae, S. Kwon, and D. Lee, “Predicting infectious disease using deep
learning and big data,” Int. J. Environ. Res. Public Health, vol. 15, no. 8,
p. 1596, Jul. 2018.
[30] S. Ahuja, B. K. Panigrahi, N. Dey, V. Rajinikanth, and T. K. Gandhi,
“Deep transfer learning-based automated detection of COVID-19 from
lung CT scan slices,” Appl. Intell., vol. 51, no. 1, pp. 571–585,
2021.
[31] Z. S. Y. Wong, J. Zhou, and Q. Zhang, “Artiﬁcial intelligence for
infectious disease big data analytics,” Infection, Disease Health, vol. 24,
no. 1, pp. 44–48, Feb. 2019.
[32] H. Hirano, A. Minagi, and K. Takemoto, “Universal adversarial attacks
on deep neural networks for medical image classiﬁcation,” BMC Med.
Imag., vol. 21, no. 1, pp. 1–13, Dec. 2021.
[33] M. Jamshidi et al., “Artiﬁcial intelligence and COVID-19: Deep learn-
ing approaches for diagnosis and treatment,” IEEE Access, vol. 8,
pp. 109581–109595, 2020.
[34] P. Singh, A. Verma, and J. S. R. Alex, “Disease and pest infection
detection in coconut tree through deep learning techniques,” Comput.
Electron. Agricult., vol. 182, Mar. 2021, Art. no. 105986.
[35] P. Gifani, A. Shalbaf, and M. Vafaeezadeh, “Automated detection of
COVID-19 using ensemble of transfer learning with deep convolutional
neural network based on CT scans,” Int. J. Comput. Assist. Radiol.
Surgery, vol. 16, no. 1, pp. 115–123, Jan. 2021.
[36] D. Moolchandani, A. Kumar, and S. R. Sarangi, “Accelerating CNN
inference on ASICs: A survey,” J. Syst. Archit., vol. 113, Feb. 2021,
Art. no. 101887.
[37] K. Pogorelov et al., “Kvasir: A multi-class image dataset for computer
aided gastrointestinal disease detection,” in Proc. 8th ACM Multimedia
Syst. Conf., 2017, pp. 164–169.
[38] F. Chollet, “Xception: Deep learning with depthwise separable convo-
lutions,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR),
Jul. 2017, pp. 1251–1258.
[39] F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally,
and K. Keutzer, “SqueezeNet: AlexNet-level accuracy with 50x fewer
parameters and <0.5 MB model size,” 2016, arXiv:1602.07360.
[40] Y. Djenouri and M. Comuzzi, “Combining Apriori heuristic and bio-
inspired algorithms for solving the frequent itemsets mining problem,”
Inf. Sci., vol. 420, pp. 1–15, Dec. 2017.
[41] M. Wo´zniak, J. Siłka, and M. Wieczorek, “Deep neural network correla-
tion learning mechanism for CT brain tumor detection,” Neural Comput.
Appl., vol. 1, pp. 1–16, Mar. 2021, doi: 10.1007/s00521-021-05841-x.
[42] P. N. Ramkumar et al., “Clinical and research medical applications
of artiﬁcial intelligence,” Arthroscopy: J. Arthroscopic Related Surg.,
vol. 37, no. 5, pp. 1694–1697, 2021.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore.  Restrictions apply. 
",10.1109/JSEN.2022.3202437,doc24,"—With the growth of smart medical devices and
applications in smart hospitals, home care facilities, nursing,
and the Internet of Medical Things (IoMT) are becoming more
ubiquitous. It uses smart medical devices and cloud comput-
ing services, and basic Internet of Things (IoT) technology,
to detect key body indicators, monitor health situations, and
generate multivariate data to provide just-in-time healthcare
services. In this article, we present a novel collaborative
disease detection system based on IoMT amalgamated with
captured image data. The system can be based on intelligent
agents, where every agent explores the interaction between
different medical data obtained by smart sensor devicesusing reinforcementlearning as well as targets to detectdiseases.
The agents then collaborate to make a reliable conclusion about the detected diseases. Intensive experiments were
conducted using medical data. The results show the importance of using intelligent agents for disease detection in
healthcare decision-making. Moreover, collaboration increases the detection rate, with numerical results showing the
superiority of the proposed framework compared with baseline solutions for disease detection.
Index Terms— Communicable disease, correlation, multiagent system (MAS), smart sensor data.
I.","IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023 947 An Intelligent Collaborative Image-Sensing System for Disease Detection Youcef Djenouri , Asma Belhadi, Anis Yazidi , Gautam Srivastava , Senior Member, IEEE, Pushpita Chatterjee , and Jerry Chun-Wei Lin , Senior Member, IEEE Abstract INTRODUCTION S MART healthcare is a framework that leverages wear- able devices, the Internet of Medical Things (IoMT), powerful machine learning algorithms, and wireless commu- nication technology to connect people, resources, and orga- nizations as well as then intelligently manage and respond Manuscript received 21 April 2022; revised 9 July 2022; accepted 13 August 2022. Date of publication 2 September 2022; date of current version 12 January 2023. The associate editor coordinating the review of this article and approving it for publication was Dr. Hari P. Gupta. (Corresponding author: Jerry Chun-Wei Lin.) Youcef Djenouri is with SINTEF Digital, 0610 Oslo, Norway (e-mail: youcef.djenouri@sintef.no). Asma Belhadi is with the School of Economics, Innovation and Technology, Kristiania University College, 0107 Oslo, Norway (e-mail: asma.belhadi@kristiania.no). Anis Yazidi is with the Department of Computer Science, OsloMet-Oslo Metropolitan University, 0167 Oslo, Norway, also with the Department of Neurosurgery, Oslo University Hospital, 0450 Oslo, Norway, and also with the Department of Computer Science, Norwegian University of Science and Technology, 7491 Trondheim, Norway (e-mail: anisy@oslomet.no). Gautam Srivastava is with the Department of Math and Computer Science, Brandon University, Brandon, MB R7A 6A9, Canada, also with Research Centre for Interneural Computing, China Medical University, Taichung 404, Taiwan, and also with the Department of Computer Science and Math, Lebanese American University, Beirut 1102, Lebanon (e-mail: SRIVASTAVAG@brandonu.ca). Pushpita Chatterjee is with the Department of Computer Science, Ten- nessee State University, Nashville, TN 37209 USA (e-mail: pushpita.c@ ieee.org). Jerry Chun-Wei Lin is with the Department of Computer Sci- ence, Electrical Engineering and Mathematical Sciences, Western Nor- way University of Applied Sciences, 5063 Bergen, Norway (e-mail: jerrylin@ieee.org). Digital Object Identiﬁer 10.1109/JSEN.2022.3202437 to healthcare needs [1], [2]. Medical sensors, often referred to as IoMT, are a critical component of smart healthcare. IoMT may be able to be driving today’s smart healthcare by leveraging cutting-edge technologies, such as artiﬁcial intelligence (AI), cloud computing, coupled with the emer- gent sixth generation (6G) mobile networks. The increasing use of IoMT devices, as well as data-driven apps, may be able to be contributing to positive effects ranging from improved user-health attitudes and early disease detection to higher-quality care and a more cost-effective smart healthcare ecosystem. It may be expected that the integration of the Internet of the Things (IoT) with medical devices in a smart healthcare system will increase the quality and the efﬁciency of services for patients, especially for patients with chronic diseases who need continuous care. With the support of Internet communica- tions, IoMT enables continuous monitoring of important phys- iological functions in, otherwise, healthy individuals, so that diseases may be able to be detected, and appropriate action may be able to be taken immediately. This may be able to be particularly important during pandemics, such as the recent Coronavirus-disease pandemic that raged globally [3], [4], where taking into account our advanced and technologically advanced healthcare systems, which tend to include both medical personnel with support systems, saw themselves under an absurd amount of stress [5]. The demand for a remote, autonomous, and ubiquitous IoMT architecture may be able to be greater than ever [6]. 1558-1748 © 2022 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. 948 IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023 The integration of smart sensors and controls within the Internet also has turned any and all “so-called” cyber-physical systems (CPSs) into IoMT, which has recently emerged as one of the main driving forces behind the fourth industrial revolution nicknamed Industry 4.0 [7]. In these directions, healthcare itself may be able to be also undergoing a digital revolution through the integration of smart devices. On the other hand, the number of IoMT devices is expected to increase signiﬁcantly over the next few years. Furthermore, the heterogeneity of the various IoMT components (network interfaces, data format, data semantics, and communication protocols) will lead to difﬁculties in interoperability and data protection [7]. In this regard, a ubiquitous, and collaborative health platform for all smart devices must be adaptable enough to accommodate all these concepts. A. Motivation Technologies based on AI are very promising in this regard and in medical applications in general [8], [9]. These include techniques, such as multiagent systems (MASs), networks that incorporate deep learning (DL), and advanced computa- tional techniques, such as evolutionary computation (EC) or other well-known ones. DL is a well-known branch of AI that can involve the creation of complicated but complete models with a high number of layers and a large number of hyperparameters. These models are not only capable of learning from large amounts of data, but they can also directly extract important aspects from these huge amounts of data. Medical data analysis, especially disease detection, is a fascinating area of DL [10], [11], [12], [13]. For example, Coronavirus-disease pandemic samples were used to build an intelligent model to calculate infection rates [10]. The latter work uses both supervised and unsupervised learning methods, resulting in a 40% increase in detection speed. Transfer learning was used to evaluate pathogen frames and validate Coronavirus-disease pandemic instances with typical virus-based pneumonia [11]. The result highlights the value of using intelligent approaches for Coronavirus-disease pandemic diagnosis. We may be able to also observe examples that have been substantially explored in the newer, fresh ﬁeld of distributed DL [14], [15], [16], [17], [18] by studying various types of DL models that are well established in medicine as well as disease detection. The identiﬁcation of illnesses is the primary objec- tive of these technologies, particularly the distributed ones. This will assist medical professionals in making decisions that are acceptable and fair within the realm of medicine. The intricacy of the data is the single most critical barrier that makes disease detection more difﬁcult than it would otherwise be. Indeed, diseases may be able to have different forms and manifestations that are difﬁcult to detect. We are researching the possibility of developing a comprehensive framework that makes use of DL to get beyond these disadvantages and MASs. The large number of hyperparameters provided by DL models is another signiﬁcant obstacle to the disease detection process. The random selection of these values leads to a signiﬁcant decrease in the overall performance during the learning phase. Moreover, the process of setting the para- meters for such frameworks takes a long time, and there is no guarantee of satisfactory convergence. The effective- ness of EC in tackling complicated problems [19], [20] has led this research to tune the parameters of the proposed framework. B. Contributions To the best of our knowledge, this is the ﬁrst paper to take an in-depth look at combining MASs, EC, and DL for disease detection. Below is a list of the major contributions. 1) We provide an collaborative system for disease detec- tion (ALMOST), a new paradigm that uses DL, MAS, and EC to identify diseases. To learn from medical training data and different diseases, each and every agent uses its DL architecture. Each iteration of the architecture establishes communication between agents to share information and reduce the error learning rate. 2) We show how many convolutional neural net- works (CNNs) may be able to work together to process large amounts of data in the medical domain. Several optimizations, such as batch normalization and dropout algorithms, ensure that the CNN processes medical data with great accuracy. 3) To intelligently explore the conﬁguration space of dif- ferent hyper parameter values, we propose a new evo- lutionary computational technique based on a genetic behavior. This approach improves the convergence of ALMOST in predicting diseases from medical data. 4) Extensive testing was conducted to demonstrate the applicability of ALMOST. The ﬁndings demon- strated that the ALMOST performs better than other well-known illness identiﬁcation algorithms in terms of the quality of the information and also in terms of computation time when training large medical data. From here on, this article is arranged as follows. Section II provides an in-depth examination of related studies on disease detection. Section III provides a comprehensive understanding of the ALMOST methodology. A performance evaluation of ALMOST is shown in Section IV. Section V discusses the major consequences of using ALMOST on medical data and the prospects for the future of the research. Section VI concludes this article. II. LITERATURE REVIEW A. AI-Based Solutions Pattern mining [21], [22], [23] is one of the approaches to derive and reveal the potential relationships of the items in the databases. Nawaz et al. [24] investigated the use of pattern mining in the analysis of medical diseases. The set of Coronavirus-disease pandemic patient data is converted into a set of transactions, where each and every patient is represented by a transaction, and each Coronavirus-disease pandemic- based information related to the patient is represented by an item. A pattern mining algorithm is then applied to the set of transactions to extract relevant patterns. The latter was used to identify diseases based on the correlation between Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. DJENOURI et al.: INTELLIGENT COLLABORATIVE IMAGE-SENSING SYSTEM FOR DISEASE DETECTION 949 medical data features. Wang et al. [10] automated the process of image assessment by exploring the segmentation as well as classiﬁcation of DL-based architectures. Thus, we may be able to achieve a reasonable estimate of the always illusory Coronavirus-disease pandemic infection rate. Wang et al. [11] found viral pneumonia from more than 1000 images of pathogens. The experiments showed a clear beneﬁt of using intelligent methods for disease diagnosis. Yan et al. [25] used a topological approach to analyze nonlinear dynamics to exam- ine gait complexity ﬂuctuations in Parkinson’s disease patients to detect the Freezing-of-Gait episode. The 3-D acceleration data from eight individuals with symptoms are used to extract relevant features from the acceleration signals using topo- logical analysis of the reconstructed process. Jain et al. [26] demonstrated the performances of using Inception-V3 for Coronavirus-disease pandemic disease identiﬁcation through data enrichment. Sedik et al. [27] demonstrated the efﬁciency of using CNN in Coronavirus-disease pandemic identiﬁca- tion. This article also demonstrated the importance of multi- modal data, in which the authors collected medical data from multiple sources, including tomographic and X-ray images. Manoj et al. [28] took a look at an incentive-based system, where the Coronavirus pandemic could be better planned for using an incentive system using block chain. In this solution, governments globally can prepare and plan better strategies for ﬁghting the virus using the availability of data from both a geographic point of view but also qualitative data around the disease. By being able to have more accurate and better data around the pandemic, and have it available in a decentralized fashion being managed by block chain, will allow a faster response time to virus outbreaks in the future. B. Hybrid-Based Solutions Chae et al. [29] predicted infectious diseases by success- fully exploring long-term short-term memory with autoregres- sive moving average. The proposed model is improved by the ensemble learning mechanism. Therefore, more sources of information were collected and extracted from social net- works. Ahuja et al. [30] implemented four DL architectures (ResNet18, ResNet50, ResNet101, and SqueezeNet) to capture Coronavirus-disease pandemic from medical lung CT-scan data. The models are pretrained using a large collection of images from different domains. The transfer learning mech- anism is used to learn the Coronavirus-disease pandemic cases from the medical data. Wong et al. [31] analyzed the effect of data-driven solutions for infectious diseases. They explored the combination of various data management as well as AI techniques to help healthcare professionals mitigate the risk of disease detection and enable better diagnosis in a smart healthcare environment. Hirano et al. [32] classiﬁed the various diseases using the model for use in DL. The classiﬁcation models developed are based on three types of medical images: photographic images, X-ray chest images, and retinopathy images. Three applications are then investigated, including skin cancer, transmissible diabetics, and pneumonia. Transfer learning with the adversarial neural network has been implemented. The transfer learning mechanism allows the model developed from various medical sources to be trained, and the adversarial network, which may be able to handle both non-targeted and targeted attacks and identify fake medical images. Jamshidi et al. [33] process multiple sources of med- ical data by exploring generative adversarial networks, extreme learning, and long-term short-term memory. This combination not only enables the handling of heterogeneous medical data but also increases the disease detection rate. Singh et al. [34] worked on developing a hybrid model based on both decom- positions and DL for disease detection. Segments are created by applying the k-means algorithm to medical data. These segments are then fed into the CNN to predict diseases based on the original medical images. Shalbaf et al. [35] imple- mented 15 pre-trained DL models to automatically identify the Coronavirus-disease pandemic. These models are based on three well-known classiﬁcation-based architectures, including Inception, ResNet, and DenseNet. Ensemble learning is then explored to merge the results obtained from these models using the majority voting strategy. III. ALMOST: AN COLLABORATIVE SYSTEM FOR DISEASE DETECTION A. Principle We begin by explaining the most important aspects of ALMOST. ALMOST is a combination of many intelligent strategies for solving disease detection problems. The CNN is used for disease diagnosis. To correctly execute ALMOST in a distributed environment where each agent can beneﬁt from the environment through the reinforcement learning paradigm, the use of an MAS is investigated. Since DL requires setting a large number of parameters, up to a million for some architectures, EC is used to determine the best settings for real- time processing. The components of ALMOST are discussed in the next parts. B. Learning Phase The learning phase is done with the help of CNNs [36]. CNN is a common type of deep architecture in computer vision applications, such as object detection and identiﬁcation. In recent years, the adaptability of this method has helped both time series and text data. CNN is based on the concept of extracting features from matrix data using convolutional ﬁlters. Convolutional ﬁlters create a new image by applying a series of weights to the matrix data of each pixel in the image. As a result, a new image is generated. In addition, well- known operators for DL models, such as batch normalization and dropout, are used during training to increase the accuracy of the proposed framework. This was achieved using the dropout method. Batch normalization is one of the factors that help the network to converge faster, while the dropout method acts as a regulator that prevents the network from overﬁtting. These two methods are necessary for the network to achieve high accuracy. Below is a complete description of these components. 1) Batch Normalization: To efﬁciently train a large number of layers, we used the batch normalization technique in all steps of the training phase. With only a few epochs, Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. 950 IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023 the learning process may be able to converge better. Batch normalization is performed after each and every convolutional layer in the CNN. 2) Dropout: It is a technique that allows you to avoid over adaptation during training. In each and every phase, the outputs of the neurons in the hidden layers are randomly skipped. Propagating a deep network with a constrained number of weights may be thought of as a straightforward method for bringing about convergence of predictions during the inference phase. C. Multiagents Systems The MAS is used to learn the different diseases in the training phase. The agents collaborate using the reinforcement learning process. Consider the tuple ⟨A, S, U, R⟩, an MAS is deﬁned by A. There are Aagents in total, and for the purposes of this discussion, each of them is treated as if it were an independent Markov decision process. A ﬁnite collection of environmental states is represented by the variable S, a set of actions by the variable U, and a reward function by the variable R. The methods presented in A describe not only how each agent should behave given the current situation, but also how it should decide on the appropriate actions. For instance, in the process of disease detection, the mission of each agent is to identify the most effective tactic that maximizes the value of the target objective function, which may be the number of diseases that are accurately identiﬁed. We will discuss the many parts that make up the MAS that we have designed by the sections as follows. 1) Environment: The environment may be thought of as a collection of databases that hold a massive quantity of data that were gathered by various intelligent sensor devices. As a result, the environment is able to create certain conditions for training the agents and determine the optimal actions. 2) State: The next action of each and every agent is deter- mined by the decisions made in earlier phases. The state of each agent is, thus, composed of two distinct parts: the data being processed and a collection of actions completed in the past. When calculating the size of the state space S, the number of observations contained in the database is taken into account. 3) Action: It is the assignment of each and every obser- vation in the database’s decision-making behavior. For instance, a detection task is the assignment of each and every disease category. 4) Reward: It is essential to decide on an acceptable reward function. It makes it possible for each agent in A to have a more fruitful learning experience. Using data that included ground truths, we crafted a reward in response to the behaviors of the agent. Therefore, the ﬁrst thing each agent does is to perform a scan of the data collected by the ith intelligent sensor. This is denoted by the notation Ai. It then computes the ﬁrst observation of the ith intelligent sensor, and all future observations of that sensor. The ground truth for the ﬁrst observation is used in the creation of a reward function speciﬁc to that choice. This approach is repeated for each of the ith smart sensor observations. As a result, a set of local options, denoted LDi, is generated for each agent Ai. The agents then learn from the local decisions {LDi} to optimally ﬁnd the global decision. This learning is realized through the process of reinforcement learning, where the best agents that have a high score for their local decisions receive a reward. D. Hyperparameters Optimization To achieve optimal performance, we apply an evolutionary- based technique to optimize hyperparameters. The adaptation of the genetic algorithm is proposed due to its known balance of intensiﬁcation and diversiﬁcation. A complete description of the proposed algorithm is given for solving our hyper parameter optimization problem. Let HP = {HP1, HP2, . . . , HPr} be the set of hyperpa- rameters, where r is the number of hyperparameters in the evolved ALMOST. Each HPi represents a set of the possible values of the hyperparameter in question. The conﬁguration space C is then deﬁned by the set of all possible conﬁgurations, where each and every conﬁguration is a vector. The possible values of all hyperparameters belong to HP. When it comes to hyperparameter optimization, our methodology focuses on determining the ideal conﬁguration that provides the highest level of accuracy. The conﬁguration space is deﬁned by the total number of possible hyper parameter values, as given in |C| = r i=1 |HPi|. Because of the vastness of the conﬁguration space, ﬁnding the ideal solutions requires considerable computational effort. Consider the epoch parameter, which has a max value of 1000, the error rate, which has a max value of 100, as well as the number of agents in the evolved model, which has a max value of 100; then, the search space will include ten million conﬁgurations, so it is not possible to apply exhaustive search methods in this case. To solve this challenge, evolutionary computational methods are used. Below are the main components of our solution. 1) Population Initialization: We are trying to distribute |P|, which is the initial population, noted P. This initial population should be uniformly distributed in the conﬁguration space C. Proper examination of each and every of the numerous alter- native conﬁgurations that tend to cover most locations within C may be able to then be performed using this uniform distribution technique. We must ﬁrst create the population, taking diversity into account. This process begins with the random generation of an indi- vidual represented by a single C conﬁguration. It is possible that after starting with this individual, we can generate more |P|−1, assuming that each newly formed individual is differ- ent from the previously generated individuals. We could use a distance measure between two successive conﬁgurations to evaluate dissimilarity based on the individuals formed in those conﬁgurations. This would be done based on the individuals generated in those conﬁgurations. The original population, denoted by the variable P, should, in turn, be able to maximize Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. DJENOURI et al.: INTELLIGENT COLLABORATIVE IMAGE-SENSING SYSTEM FOR DISEASE DETECTION 951 the diversiﬁcation function shown in Diversify(P) = |P|  i=1 |P|  j=1 Distance(Ci, C j) where Distance(Ci, C j) is the distance between the conﬁgura- tions of the ith and the jth individuals, respectively. 2) Crossover: To produce new offspring, each and every of the two individuals in the current population goes through the following steps. 1) We start at 1 and work our way up to r, creating a random sequence of crossing points. At each of these points, we divide the intersection into its left and right halves, respectively. 2) Both the left-hand side of the original, which is copied to the left-hand side of the ﬁrst descendant, and the right-hand side of the original, which is copied to the right-hand side of the second descendant, are descen- dants of each other. 3) The right-hand side of the second person is inherited by the ﬁrst generation, while the left-hand side of the second individual is inherited by the second generation. 3) Mutation: Mutation facilitates the search for diversity. We use a strategy in which the value of a single parameter is randomly varied in every single one of the conﬁgurations currently in use. The mutation point is chosen randomly and can have a value between 1 and r, depending on the method. At each iteration, the value of the mutation point is changed in the descendants generated by the crossover operator. 4) Fitness Function: Identifying diseases with the highest possible degree of precision is the goal of the ALMOST framework. Therefore, to assign points to individuals within populations, we use the following function: Fitness(Ci) = DetectionALMOST(Ci). Note that the following hold. 1) Ci is a representation of the conﬁguration of the ith individual in the population. 2) DetectionALMOST(Ci) indicates the ratio for disease detection using the developed ALMOST based on the Ci. Based on these actions, we presented the following method for optimizing hyperparameter values. In the beginning, the initial population size, deﬁned as |P|, is randomly gener- ated. Then, each and every individual is constructed using population initialization. Then, mutation, and crossover with mutation and crossover rates (Mr and Cr), is used to generate conﬁgurations from C. To keep the population size constant, each individual is evaluated against the ﬁtness function, focus- ing on maintaining the highest quality |P| individuals. All others are now deleted. This procedure is then continued endlessly until the max number of iterations (IMAX) is reached. E. Description Algorithm 1 shows the pseudocode of ALMOST for each and every agent. The process begins by building the model for use in DL represented by the CNN with batch normalization and dropout layers (from lines 4 to 5). The batches of data Algorithm 1 ALMOST Pseudocode for Each Agent 1: Input: I = {I1, I2, . . . , Im}: the set of m images collected from sensors. 2: Output: model: The trained model to detect the disease; DD: the set of the disease detected from I. 3: model ←C N N(); 4: model ←model ∪BatchNormalization(); 5: model ←model ∪Dropout() 6: Batches ←CreatingBatches(D); 7: Hyper_Param ←G A( f it(model, Batches)); 8: DD ←In f erence(Inew, model, Hyper_Param); 9: return < model, DD >. are created from the input images I in line 6. Then, the genetic algorithm is applied to optimize the hyperparameters of the model for use in DL by performing the training phase on the created batches (line 7). The inference phase is then run on the trained model to identify the disease of the new image (line 8). The output of the algorithm is the set of detected diseases DD and the trained disease detection model (line 11). IV. PERFORMANCE EVALUATION Extensive testing was performed on known medical datasets speciﬁcally designed for disease detection applications to validate the use of the proposed ALMOST framework. Exper- iments were conducted using a desktop computer equipped with 16 GB of primary memory and an Intel Core i7 processor for optimal performance. PythonTorch was used for the actual implementation of each algorithm. We used the Kvasir [37] medical database to validate the applicability of ALMOST in disease detection, for disease data for the human digestive system. The aim is to automate the detection of endoscopic ﬁndings in the esophagus, stomach, intestines, and rectum. It is available in two versions. The ﬁrst version, called Kvasir (v1), consists of 4000 images grouped into eight classes showing anatomical landmarks, pathological ﬁndings, or endoscopic procedures. The second version, called Kvasir (v2), expands on the ﬁrst version and consists of 8000 images with the same number of classes. A. Parameter Setting In ALMOST, several parameters need to be optimized, including the number of agents, the number of generations, the crossover and mutation rates, and the population size. Choos- ing optimal values for these parameters is critical for better performance of the ALMOST framework. In this experiment, we analyze the behavior of ALMOST at different values for the number of agents, number of generations, crossover rate, and the mutation rate. We varied the number of agents from 2 to 20, the number of generations and population size from 10 to 100, and the crossover rate and mutation rate from 0.01 to 0.99. The behavior of ALMOST may be able to be summarized as follows. 1) Number of Agents: The experiments showed that when we vary the number of agents from 2 to 20, the accuracy Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. 952 IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023 TABLE I SUMMARY OF PARAMETER SETTING OF ALMOST TABLE II ALMOST VERSUS DISEASE DETECTION SOLUTIONS of ALMOST increases until ﬁve agents for Kvasir (V1) and eight agents for Kvasir (V2) where stabilization of the accuracy is observed. 2) Number Generations: The experiments showed that when we vary the number of generations from 10 to 100, the accuracy of ALMOST increases until 45 generations for Kvasir (V1), and 58 generations for Kvasir (V2) where stabilization of the accuracy is observed. 3) Population Size: The experiments showed that when we vary the population size from 10 to 100, the accuracy of ALMOST increases until 85 individuals for Kvasir (V1), and 93 individuals for Kvasir (V2) where stabilization of the accuracy is observed. 4) Crossover Rate: The experiments showed that when we vary the crossover from 0.01 to 0.99, the accuracy of ALMOST increases until 0.35 for Kvasir (V1), as well as 0.47 for Kvasir (V2) where stabilization of the accuracy is observed. 5) Mutation Rate: The experiments showed when we vary the mutation from 0.01 to 0.99, the accuracy of ALMOST increases until 0.53 for Kvasir (V1), as well as 0.61 for Kvasir (V2) where the stabilization of the accuracy is observed. Table I gives the optimal values of the parameters used in ALMOST for both Kvasir (v1) and Kvasir (v2). The next experiments aim to validate the usefulness of the proposed ALMOST framework for disease detection. To reach this conclusion, an intensive analysis was performed by comparing ALMOST with the baseline solutions InceptionResNet [34] and DenseNet [35]). The detailed results with a full explana- tion are shown below. B. Quality of Outputs Table II shows the quality of results from ALMOST and the baseline solutions: InceptionResNet, DenseNet on Kvasir (V1), and Kvasir (V2). We varied the percentage of images used for training from 1000 to 4000 for Kvasir (V1) and from 1000 to 8000 images for Kvasir (V2). We then calculate Fig. 1. ALMOST versus advanced disease detection solutions with different numbers of error loss values (0.10, 0.08, 0.05, 0.02, and 0.01). the quality of the results represented by the F1 and accu- racy formulas. The results show the superiority of ALMOST compared with the baseline solutions for all scenarios. Thus, the accuracy of ALMOST is 0.96 when all the data from Kvasir (V2) are processed, while the accuracy of the two solutions is less than 0.80 when the same data are trained. This great performance is due to the efﬁcient components of ALMOST represented by the DL solution and the MASs, and the accurate way of the hyperoptimization process. Fig. 2 shows a case study of ALMOST. The ﬁrst three images are considered as esophagitis disease, and the second three images are considered as polyps disease, where the last three images are considered as ulcerative colitis disease. C. ALMOST for Large-Scale Data In the next experiment, we will examine the scalability of ALMOST compared with the baseline solutions when it comes to processing large amounts of data. For comparison, we will use Xception [38] and SqueezeNet [39]. These algorithms have proven their usefulness in a variety of different contexts, including training huge datasets. Different training scenarios with different data sizes of Kvasir (v1) and Kvasir (v2) are run. Data duplication is generated by multiplying Kvasir (v1) and Kvasir (v2) multiple times (1000, 10000, and 100000). For each and every redundant sample, changes are generated using a generative adversarial network. We varied the error loss to be optimized from 0.10 to 0.01, and the results are given in Fig. 1. From these results, we may be able to see the clear superiority of ALMOST over the other two solutions in terms of training time. This performance may be able to be explained by the fact that ALMOST is optimized DL where Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. DJENOURI et al.: INTELLIGENT COLLABORATIVE IMAGE-SENSING SYSTEM FOR DISEASE DETECTION 953 Fig. 2. Case study of ALMOST: the ﬁrst three images are considered as esophagitis disease, and the second three images are considered as polyps disease, where the last three images are considered as ulcerative colitis disease. the collaboration between the different agents accelerates the training process. V. DISCUSSION AND FUTURE DIRECTION The primary beneﬁts of applying ALMOST to disease detection data are presented in this section. We also make some recommendations for how to improve the ALMOST framework. 1) The effective combination of intelligent technologies in the form of DL, MASs, and metaheuristics leads to a high level of precision. For real-time medical data management and disease detection, runtime performance is still a challenge. The development of hybrid systems that combine evolutionary and exact approaches [40] to improve the performance of ALMOST could be an interesting avenue. 2) The proposed methodology provides better results than previous approaches. It would extremely fascinating to study the results of ALMOST for other smart healthcare applications, such as brain tumor detection [41], as well as surgery [42]. 3) Output interpretation is a challenge in ALMOST. It relies on black-box models that do not implicitly explain the process of output interpretation. Health- care practitioners need to understand how the given output is produced to trust it. This problem is being addressed by the emerging discipline of explainable AI (XAI). We intend to incorporate XAI approaches into ALMOST. This will allow for a more accurate interpretation of the results from ALMOST. VI. CONCLUSION In this article, an intelligent collaborative system for dis- ease detection is proposed. It studied the different interac- tions between the medical data using intelligent agents with an efﬁcient reinforcement learning mechanism. This enables signiﬁcant determination of various diseases in healthcare systems. The proposed system was tested on different medical datasets. The initial results showed the usefulness of using intelligent agents for healthcare diagnosis. The numerical results can be seen to also clearly visualize the strength of our proposed framework when directly compared with baseline methodologies when focusing on the rate of disease detection. REFERENCES [1] R. Yadav et al., “Smart healthcare: RL-based task ofﬂoading scheme for edge-enable sensor networks,” IEEE Sensors J., vol. 21, no. 22, pp. 24910–24918, Nov. 2021. [2] L. Babangida, T. Perumal, N. Mustapha, and R. Yaakob, “Internet of Things (IoT) based activity recognition strategies in smart homes: A review,” IEEE Sensors J., vol. 22, no. 9, pp. 8327–8336, May 2022. [3] Y. Han and H. Yang, “The transmission and diagnosis of 2019 novel coronavirus infection disease (COVID-19): A Chinese perspective,” J. Med. Virol., vol. 92, no. 6, pp. 639–644, 2020. [4] J. He, Y. Guo, R. Mao, and J. Zhang, “Proportion of asymptomatic coronavirus disease 2019: A systematic review and meta-analysis,” J. Med. Virol., vol. 93, no. 2, pp. 820–830, 2021. [5] E. J. Emanuel et al., “Fair allocation of scarce medical resources in the time of COVID-19,” New England J. Med., vol. 382, no. 21, pp. 2049–2055, May 2020. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply. 954 IEEE SENSORS JOURNAL, VOL. 23, NO. 2, 15 JANUARY 2023 [6] T. Yang, M. Gentile, C.-F. Shen, and C.-M. Cheng, “Combining point- of-care diagnostics and internet of medical things (IoMT) to combat the COVID-19 pandemic,” Diagnostics, vol. 10, no. 4, p. 224, Apr. 2020. [7] L. M. Camarinha-Matos, R. Fornasiero, and H. Afsarmanesh, “Collabo- rative networks as a core enabler of industry 4.0,” in Collaboration in a Data-Rich World (PRO-VE) (IFIP Advances in Information and Commu- nication Technology), vol. 506, L. Camarinha-Matos, H. Afsarmanesh, and R. Fornasiero, Eds. Cham, Switzerland: Springer, 2017, doi: 10.1007/978-3-319-65151-4_1. [8] S. Pouyanfar et al., “A survey on deep learning: Algorithms, tech- niques, and applications,” ACM Comput. Surv., vol. 51, no. 5, pp. 1–36, Sep. 2018. [9] A. Sharma et al., “Multi-agent system applications to ﬁght COVID-19 pandemic,” Apollo Med., vol. 17, no. 5, p. 41, 2020. [10] B. Wang et al., “AI-assisted CT imaging analysis for COVID-19 screening: Building and deploying a medical AI system,” Appl. Soft Comput., vol. 98, Jan. 2021, Art. no. 106897. [11] S. Wang et al., “A deep learning algorithm using CT images to screen for corona virus disease (COVID-19),” Eur. Radiol., vol. 31, pp. 6096–6104, Feb. 2021. [12] D. M. Khan, K. Masroor, M. F. M. Jailani, N. Yahya, M. Z. Yusoff, and S. M. Khan, “Development of wavelet coherence EEG as a biomarker for diagnosis of major depressive disorder,” IEEE Sensors J., vol. 22, no. 5, pp. 4315–4325, Mar. 2022. [13] R. Wang et al., “A standalone and portable microﬂuidic imaging detec- tion system with embedded computing for point-of-care diagnostics,” IEEE Sensors J., vol. 22, no. 6, pp. 6116–6123, Mar. 2022. [14] N. Balachandar, K. Chang, J. Kalpathy-Cramer, and D. L. Rubin, “Accounting for data variability in multi-institutional distributed deep learning for medical imaging,” J. Amer. Med. Inform. Assoc., vol. 27, no. 5, pp. 700–708, May 2020. [15] S. S. Roy, K. Samanta, S. Modak, S. Chatterjee, and R. Bose, “Cross spectrum aided deep feature extraction based neuromuscular disease detection framework,” IEEE Sensors Lett., vol. 4, no. 6, pp. 1–4, Jun. 2020. [16] H. Ku, W. Susilo, Y. Zhang, W. Liu, and M. Zhang, “Privacy- preserving federated learning in medical diagnosis with homomorphic re-encryption,” Comput. Standards Interfaces, vol. 80, Mar. 2022, Art. no. 103583. [17] X. Xu, H. Tian, X. Zhang, L. Qi, Q. He, and W. Dou, “DisCOV: Dis- tributed COVID-19 detection on X-ray images with edge-cloud collab- oration,” IEEE Trans. Services Comput., vol. 15, no. 3, pp. 1206–1219, May 2022. [18] R. Dwivedi, S. Dey, C. Chakraborty, and S. Tiwari, “Grape disease detection network based on multi-task learning and attention features,” IEEE Sensors J., vol. 21, no. 16, pp. 17573–17580, Aug. 2021. [19] U. Ahmed, J. C.-W. Lin, G. Srivastava, R. Yasin, and Y. Djenouri, “An evolutionary model to mine high expected utility patterns from uncertain databases,” IEEE Trans. Emerg. Topics Comput. Intell., vol. 5, no. 1, pp. 19–28, Feb. 2021. [20] P. Srinivas and R. Katarya, “HyOPTXg: OPTUNA hyper-parameter optimization framework for predicting cardiovascular disease using XGBoost,” Biomed. Signal Process. Control, vol. 73, Mar. 2022, Art. no. 103456. [21] C.-W. Lin, T.-P. Hong, G.-C. Lan, J.-W. Han, and W.-Y. Lin, “Incre- mentally mining high utility patterns based on pre-large concept,” Appl. Intell., vol. 40, no. 2, pp. 343–357, Mar. 2014. [22] J. C.-W. Lin, W. Gan, P. Fournier-Viger, T.-P. Hong, and J. Zhan, “Efﬁcient mining of high-utility itemsets using multiple minimum utility thresholds,” Knowl.-Based Syst., vol. 113, pp. 100–115, Dec. 2016. [23] W. Gan, J. C.-W. Lin, J. Zhang, P. Fournier-Viger, H.-C. Chao, and P. S. Yu, “Fast utility mining on sequence data,” IEEE Trans. Cybern., vol. 51, no. 2, pp. 487–500, Feb. 2021. [24] M. S. Nawaz, P. Fournier-Viger, A. Shojaee, and H. Fujita, “Using artiﬁcial intelligence techniques for COVID-19 genome analy- sis,” Int. J. Speech Technol., vol. 51, no. 5, pp. 3086–3103, May 2021. [25] Y. Yan et al., “Topological descriptors of gait nonlinear dynamics toward freezing-of-gait episodes recognition in Parkinson’s disease,” IEEE Sensors J., vol. 22, no. 5, pp. 4294–4304, Mar. 2022. [26] R. Jain, M. Gupta, S. Taneja, and D. J. Hemanth, “Deep learning based detection and analysis of COVID-19 on chest X-ray images,” Appl. Intell., vol. 51, pp. 1690–1700, Oct. 22021. [27] A. Sedik, M. Hammad, F. E. Abd El-Samie, B. B. Gupta, and A. A. Abd El-Latif, “Efﬁcient deep learning approach for augmented detection of Coronavirus disease,” Neural Comput. Appl., vol. 34, pp. 11423–11440, Jan. 2021. [28] M. Manoj, G. Srivastava, S. R. K. Somayaji, T. R. Gadekallu, P. K. R. Maddikunta, and S. Bhattacharya, “An incentive based approach for COVID-19 planning using blockchain technology,” in Proc. IEEE Globecom Workshops (GC Wkshps), Dec. 2020, pp. 1–6. [29] S. Chae, S. Kwon, and D. Lee, “Predicting infectious disease using deep learning and big data,” Int. J. Environ. Res. Public Health, vol. 15, no. 8, p. 1596, Jul. 2018. [30] S. Ahuja, B. K. Panigrahi, N. Dey, V. Rajinikanth, and T. K. Gandhi, “Deep transfer learning-based automated detection of COVID-19 from lung CT scan slices,” Appl. Intell., vol. 51, no. 1, pp. 571–585, 2021. [31] Z. S. Y. Wong, J. Zhou, and Q. Zhang, “Artiﬁcial intelligence for infectious disease big data analytics,” Infection, Disease Health, vol. 24, no. 1, pp. 44–48, Feb. 2019. [32] H. Hirano, A. Minagi, and K. Takemoto, “Universal adversarial attacks on deep neural networks for medical image classiﬁcation,” BMC Med. Imag., vol. 21, no. 1, pp. 1–13, Dec. 2021. [33] M. Jamshidi et al., “Artiﬁcial intelligence and COVID-19: Deep learn- ing approaches for diagnosis and treatment,” IEEE Access, vol. 8, pp. 109581–109595, 2020. [34] P. Singh, A. Verma, and J. S. R. Alex, “Disease and pest infection detection in coconut tree through deep learning techniques,” Comput. Electron. Agricult., vol. 182, Mar. 2021, Art. no. 105986. [35] P. Gifani, A. Shalbaf, and M. Vafaeezadeh, “Automated detection of COVID-19 using ensemble of transfer learning with deep convolutional neural network based on CT scans,” Int. J. Comput. Assist. Radiol. Surgery, vol. 16, no. 1, pp. 115–123, Jan. 2021. [36] D. Moolchandani, A. Kumar, and S. R. Sarangi, “Accelerating CNN inference on ASICs: A survey,” J. Syst. Archit., vol. 113, Feb. 2021, Art. no. 101887. [37] K. Pogorelov et al., “Kvasir: A multi-class image dataset for computer aided gastrointestinal disease detection,” in Proc. 8th ACM Multimedia Syst. Conf., 2017, pp. 164–169. [38] F. Chollet, “Xception: Deep learning with depthwise separable convo- lutions,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jul. 2017, pp. 1251–1258. [39] F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally, and K. Keutzer, “SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5 MB model size,” 2016, arXiv:1602.07360. [40] Y. Djenouri and M. Comuzzi, “Combining Apriori heuristic and bio- inspired algorithms for solving the frequent itemsets mining problem,” Inf. Sci., vol. 420, pp. 1–15, Dec. 2017. [41] M. Wo´zniak, J. Siłka, and M. Wieczorek, “Deep neural network correla- tion learning mechanism for CT brain tumor detection,” Neural Comput. Appl., vol. 1, pp. 1–16, Mar. 2021, doi: 10.1007/s00521-021-05841-x. [42] P. N. Ramkumar et al., “Clinical and research medical applications of artiﬁcial intelligence,” Arthroscopy: J. Arthroscopic Related Surg., vol. 37, no. 5, pp. 1694–1697, 2021. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:08:23 UTC from IEEE Xplore. Restrictions apply.","—With the growth of smart medical devices and applications in smart hospitals, home care facilities, nursing, and the Internet of Medical Things (IoMT) are becoming more ubiquitous. It uses smart medical devices and cloud comput- ing services, and basic Internet of Things (IoT) technology, to detect key body indicators, monitor health situations, and generate multivariate data to provide just-in-time healthcare services. In this article, we present a novel collaborative disease detection system based on IoMT amalgamated with captured image data. The system can be based on intelligent agents, where every agent explores the interaction between different medical data obtained by smart sensor devicesusing reinforcementlearning as well as targets to detectdiseases. The agents then collaborate to make a reliable conclusion about the detected diseases. Intensive experiments were conducted using medical data. The results show the importance of using intelligent agents for disease detection in healthcare decision-making. Moreover, collaboration increases the detection rate, with numerical results showing the superiority of the proposed framework compared with baseline solutions for disease detection. Index Terms— Communicable disease, correlation, multiagent system (MAS), smart sensor data. I.","['Youcef Djenouri', 'Asma Belhadi', 'Anis Yazidi', 'Gautam Srivastava', 'Pushpita Chatterjee', 'Jerry Chun-Wei Lin']"
Solving Two-Person Zero-Sum Stochastic Games With Incomplete Information Using Learning Automata With Artificial Barriers,"Yazidi, Anis and Silvestre, Daniel and Oommen, B. John",2023,2.0,34,IEEE Transactions on Neural Networks and Learning Systems,article,"650
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023
Solving Two-Person Zero-Sum Stochastic Games
With Incomplete Information Using Learning
Automata With Artiﬁcial Barriers
Anis Yazidi
, Senior Member, IEEE, Daniel Silvestre
, and B. John Oommen
, Life Fellow, IEEE
Abstract INTRODUCTION
T
HE term learning automata (LA) denotes a whole subﬁeld
of research within adaptive systems with several books
being dedicated to its study [2], [5], [6], [12], [14]. The work
on LA dates to the Soviet Union in the 1960s when the
mathematical giant Tsetlin et al. [15] devised the so-called
Tsetlin machine that is a learning mechanism with ﬁnite mem-
ory. Tsetlin’s learning machines were demonstrated to give
birth to self-organizing behavior through collective learning.
In his work, Tsetlin pioneered the Goore game, which is a
distributed coordination game with limited feedback that has
many practical applications, as shown by Tung and Kleinrock
[16]. The early works in the ﬁeld of LA, such as the Tsetlin
machine, fall under the family of ﬁxed structure LA. The
mainstream of current LA research concerns the family of
variable structure LA (VSLA) which, loosely speaking, differs
from ﬁxed structure LA in the fact that they operate with
a probability vector that is updated dynamically over time.
In ﬁxed structure LA, the choice is governed by a transition
matrix whose transitions do not depend on time and that
describes how the internal states of the LA are updated based
on the environment’s feedback. The term LA was coined for
the ﬁrst time by Narendra and Thathachar [6].
Markovian Representations of LA: LA can also be charac-
terized by their Markovian representations. They thus fall into
one of two families, being either ergodic or those that possess
absorbing barriers [8]. Such a characterization is crucial to
the tenets of this article. Absorbing automata have underlying
Markov chains that get absorbed or locked into a barrier
state. Sometimes, this can occur even after a relatively small,
ﬁnite number of iterations. The classic references [2], [5],
[6], [12], [14] report numerous LA families that contain such
absorbing barriers. On the other hand, as these same references
explain, the literature has also reported scores of ergodic
automata, which converge in distribution. In these cases,
the asymptotic distribution of the action probability vector
converges to a value that is independent of its initial vector.
Absorbing LA are usually designed to operate in stationary
environments. As opposed to these, ergodic LA are preferred
for nonstationary environments, namely those that possess
2162-237X © 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION
651
time-dependent reward probabilities. These characterizations,
and their corresponding implications for game playing, will
be explained presently.
Continuous or Discretized VSLA: VSLA can also be char-
acterized as being continuous or discretized. This depends on
the values that the action probabilities can take. Continuous
LA allow the action probabilities to assume any value in the
interval [0, 1]. Such algorithms have a relatively slow rate of
convergence. The problem with continuous LA is that they
approach a goal but never reach there. This was mitigated in
the 1980s by introducing the concept of discretization, where
if an action probability was close enough to zero or unity,
it could jump to that endpoint in a single step. This also ren-
dered the LA to have a faster convergence because one could
increase their speeds of convergence by incorporating this
phenomenon [3], [4], [9]. This is implemented by constraining
the action selection probability to be one of a ﬁnite number of
values in the interval [0, 1]. By incorporating discretization,
almost all of the reported VSLA of the continuous type have
also been discretized [9], [10], [19].
LA With Artiﬁcially Absorbing Barriers: LA with artiﬁ-
cially introduced absorbing barriers were a novelty in the
1980s. These yielded machines, which had properties that
were previously unknown. This was due to the fact that a
discretized machine, even though it was ergodic, could be
rendered absorbing by forcing the machine to stay at one of the
absorbing barriers [8]. Ironically, this simple step introduced
families of new LA, with properties that were previously
unknown. For example, ADLR−P and ADLI−P are absorbing
versions of their corresponding ergodic counterparts but have
been proven to be ϵ-optimal in all random environments. This
phenomenon, of including artiﬁcially absorbing barriers, has
been recently applied to the family of pursuit LA [18].
Estimator LA With Artiﬁcial Barriers: The concept of
introducing absorbing barriers is also central to the proofs
of estimator algorithms. For three decades, these pursuit
algorithms were “proven” to be ϵ-optimal by virtue of the
monotonicity property. However, recently, these proofs have
been shown to be ﬂawed. To remedy this, absorbing barriers
have been introduced in continuous estimator algorithms so
that the proofs could follow a martingale property, as opposed
to monotonicity. Consequently, Zhang et al. [18]–[20] have
shown that one can invoke this weaker property, namely,
the martingale property, by artiﬁcially providing such an
absorbing barrier. Thus, whenever an action probability is
close enough to unity, the LA is forced to jump to this
absorbing barrier.
Applications of LA: LA have boasted scores of applica-
tions. These include theoretical problems, such as the graph
partitioning problem. They have been used in controlling intel-
ligent vehicles. When it concerns neural networks and hidden
Markov models, Meybodi et al. have used them in adapting
the former, and others have applied them in training the latter.
Network call admission, trafﬁc control, and quality-of-service
routing have been resolved using LA, while others have also
found applications in tackling problems involving network and
communications issues. Apart from these, the entire ﬁeld of
LA and stochastic learning has had a myriad of applications
listed in the reference books [2], [5], [6], [14]. In the interest
of the page-limit constraints, the citations to these applications
are not included. However, they can be easily found by
executing a simple search, and many are included in the above
benchmark references.
Game Playing With LA: While artiﬁcially introduced barri-
ers have been shown to have powerful theoretical and design
implications, the applications of them are few. This is where
this article ﬁnds its place—it presents one such application.
LA have also been used to resolve stochastic games with
incomplete information. This article pioneers a merge of the
above two issues. First of all, we present a mechanism by
which LA can be augmented with artiﬁcial barriers, but unlike
the state of the art, these barriers are nonabsorbing. We then
proceed to use these to play zero-sum games with incomplete
information. Games of this type were studied four decades ago
for scenarios when the game matrix had a saddle point using
traditional L R−I and L R−P LA [13]. Our results generalize
those when the game does not possess the Nash equilibrium.
Rather, we propose the nontrivial use of LA with artiﬁcial
nonabsorbing barriers to resolve such games. This article
contains the theoretical results and those from simulations
using the corresponding benchmark games.
Landscape of Our Present Work: In this article, we pro-
pose an algorithm addressing zero-sum games, which can be
generalized to nonzero-sum games in a manner similar to the
principle by which the method in [1] was generalized in [17].
In the latter, Xing and Chandramouli [17] proved that the linear
reward−ϵpenalty (L R−ϵP) algorithm, devised in [1], is able to
work in nonzero-sum games. Thus, without further elaborating
on this,1 our results are generalizable to nonzero-sum games.
Since the game is zero-sum, the outcomes are either a
loss for player A, with reward −1, and the corresponding
win for player B with value +1, or the converse for the
case of a win for player A. We emphasize that this is a
limited information game where each player is unaware of
both the mixed strategy and the selected action of the other
player. The available information to each player is whether its
action resulted in a win or a loss. The reader should note that
either/both players might not even be aware of the existence
of another player and be working with the assumption that
he is playing against nature, as in the classical multiarmed
bandit algorithms. However, if both players learn using our
algorithm based on the assumption that they are operating
in an adversarial environment, we show that they will both
converge to the desired equilibrium. Our proposed scheme has
players adjusting their strategy whenever it obtains a “win”
for that round. This conforms to the linear reward-inaction
(L R−I) paradigm, described in detail, presently. It is thus,
unarguably, radically different from the mechanism proposed
by Lakshmivarahan and Narendra [1], where the probability
updates are performed upon receiving both reward and penalty
responses, which thus renders changes to occur at every time
instant.
1Some preliminary unpublished work is being conducted for extending this
work to nonzero-sum games.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 652
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023
Objective and Contribution of This Article: Based on the
above discussion, one can summarize the objective of this
article as to study the behavior of a nonabsorbing barrier-based
L R−I mechanism in a stochastic zero-sum game played by two
players A and B, with two actions each, as earlier done in [1].
Each player uses an LA to decide his strategy, where the only
received feedback from the environment is the reward of the
joint actions of both players. The game is played iteratively
and the players are able to revise their mixed strategies.
Applications of the Proposed Method: Learning within the
context of games has a natural application in the realm of
game theory. However, in the context of multiagent systems
(MASs), this has been shown to be suitable for the cooperative
control of robotic systems [21]. In such a design, it is assumed
that the mission can be fully described as a potential game,
where the utility function measures how well the nodes in
the network are complying with the objectives. Nevertheless,
having robots converging to pure strategies means that the
network designer is favoring exploitation and disregarding
exploration. If the environment changes and causes a different
payoff matrix, the agent would be locked into repeatedly
playing the same strategy. Moreover, this assumes that the
utility must be known and deterministic. Therefore, instead of
designing application-speciﬁc algorithms, the proposed learn-
ing algorithm can be used to address problems in cooperative
control such as the so-called “rendezvous” problem for a ﬂeet
of robots [26], [27], the desynchronization of the use of a
shared medium [22], [23], and a consensus algorithm to have
the agents agree on a common value [24] or to solve distributed
computation such as the PageRank [25], by only considering
the current stochastic payoff.
It is also pertinent to mention that the mechanism that we
propose here can be used by the agents to learn how to act if
the payoff corresponds to how successful they are in following
the objectives of the “mission.” Much can be said about this,
but we terminate these discussions here in the interest of
brevity and due to space limitations. However, with respect
to future research, it is wise to mention that the question
of whether they can be applied to synchronization, as in the
analysis of the family of so-called “Fireﬂy” algorithms, is yet
open.
A. Notation Used
Most of the notations that we use are well established from
the theory of matrices and in the ﬁeld of LA [2], [6], and
stating them would trivialize this article. However, we mention
that apart from the well-established notations used in these
areas, we will use the notation that the conditional expectation
of some variable v with respect to w is written as E[v|w] and
the partial derivative of a variable v(t) with respect to time t
is denoted by (∂v(t)/∂t).
II. GAME MODEL
To initiate discussions, we formalize the game model that
is being investigated. Let P(t)
=
p1(t) p2(t)⊺denote
the mixed strategy of player A at time instant t, where
p1(t) accounts for the probability of adopting strategy 1
and, conversely, p2(t) stands for the probability of adopting
strategy 2. Thus, P(t) describes the distribution over the
strategies of player A. Similarly, we can deﬁne the mixed
strategy of player B at time t as Q(t) =
q1(t) q2(t)⊺.
The extension to more than two actions per player is
straightforward following the method analogous to what was
used by Papavassilopoulos [11], which extended the work of
Lakshmivarahan and Narendra [1].
Let αA(t) ∈{1, 2} be the action chosen by player A at time
instant t and αB(t) ∈{1, 2} be the one chosen by player B,
following the probability distributions P(t) and Q(t), respec-
tively. The pair (αA(t), αB(t)) constitutes the joint action at
time t and is pure strategy. Speciﬁcally, if (αA(t), αB(t)) =
(i, j), the probability of gain for player A is determined by di j,
as formalized in [1]. We thus construct a matrix with the set
of probabilities D = [di j], 1 ≤i ≤2, which is the so-called
payoff matrix associated with the game.
The matrix D is given by
D =
d11
d12
d21
d22

(1)
where all the entries are probabilities.
Clearly, the actual game matrix G is given by gi j = 2 di j−1,
with entries in the interval [−1, 1]. Without loss of generality,
player A corresponds to the row player, whereas B is the
column player. Furthermore, when referring to a “gain,” we
are seeing this from the perspective of player A.
In zero-sum games, Nash equilibria are equivalently called
the “saddle points” for the game. Since the outcome for a given
joint action is stochastic, the game is the stochastic form of a
zero-sum game. The “zero-sum” property implies that at any
time t, there is only one winning player.2
In the interest of completeness, we present the original
scheme proposed in [1] based on the L R−ϵP rule. It uses two
parameters θR and θP as the learning rates associated with
the reward and penalty responses, respectively. When player
A gains at time instant t by playing action i, he updates his
mixed strategy as
pi(t + 1) = pi(t) + θR(1 −pi(t))
ps(t + 1) = ps(t) −θP ps(t)
for
s ̸= i.
However, if player A loses after using action i, his mixed
strategy is updated by the following:
pi(t + 1) = pi(t) −θP pi(t)
ps(t + 1) = ps(t) + θR(1 −ps(t))
for s ̸= i.
The exact update mechanism for player B is obtained by
replacing the corresponding p(t) by q(t) and by recalling that
a gain for A maps onto a loss scenario for player B. We now
introduce our novel solution that is proposed to learn a new
mixed strategy.
2The results inferred from this article can be extended to nonzero-sum
games. However, for the sake of simplicity, we only consider the case of
zero-sum games.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION
653
III. LA ALGORITHM BASED ON L R−I WITH
ARTIFICIAL BARRIERS
A. Nonabsorbing Artiﬁcial Barriers
We have earlier seen that an ergodic LA can be made
absorbing by artiﬁcially rendering the end states to become
absorbing. This was brieﬂy addressed above. However, what
has not been discussed in the literature is a strategy by which a
scheme which is, in and of itself, absorbing, can be rendered to
be ergodic. In other words, the LA are allowed to move within
the probability simplex by utilizing an absorbing scheme.
However, when it enters an absorbing barrier, the scheme
is forced to go back into the simplex in order to render it
to be ergodic. No such scheme has ever been reported in
the literature, and the advantage of having such a scheme
is that one does not get locked into a suboptimal absorbing
barrier. Rather, we can permit it to move around so that it can
migrate stochastically toward an optimal mixed strategy. This
is, precisely, what we shall do.
B. Nonabsorbing Game Playing
We now present our strategic LA-based game algorithm
together with a formal analysis that demonstrates the conver-
gence to the saddle points of the game even if the saddle point
corresponds to a mixed Nash equilibrium. Our LA solution is
based on the L R−I scheme, but as alluded to earlier, it has
been modiﬁed in order to nontrivially provide nonabsorbing
barriers. The proof of convergence is based on Norman’s
theory for learning processes characterized by small learning
steps [6], [7].
Considering that pmax denotes an artiﬁcial barrier, we use
the notation that pmin = 1 −pmax. We further constrain
the probability for each action by restricting it, by design,
to belong to the interval [pmin, pmax] if p1(0) and q1(0) are
initially chosen to belong to the same interval. If the outcome
from the environment is a gain at a time t for action i ∈{1, 2},
the update rule is given by
pi(t + 1) = pi(t) + θ(pmax −pi(t))
ps(t + 1) = ps(t) + θ(pmin −ps(t)) for s ̸= i.
(2)
The reader will observe that this update mechanism is
identical to the well-established linear schemes, except that
pmin and pmax replace the values zero and unity, respectively.
When the player receives a loss, the probabilities are not
updated, which translates into
pi(t + 1) = pi(t)
ps(t + 1) = ps(t) for s ̸= i.
(3)
The update rules for the mixed strategy q(t +1) are deﬁned
in a similar fashion by recalling the dichotomy that whenever
player A gains, it corresponds to a loss for player B and vice
versa. Analogous to the L R−I paradigm, mixed strategies are
not changed in the case of a loss.
We now proceed to analyze the convergence properties of
the proposed algorithm. To aid in the analysis, we identify the
Nash equilibrium of the game by the pair (popt, qopt). To render
the presentation to be less cumbersome, we divide the analysis
into two cases.
1) Case 1 [Only One Mixed Nash Equilibrium Case (No
Saddle Point in Pure Strategies)]: The ﬁrst case depicts the
situation where no saddle point exists in pure strategies.
In other words, the only Nash equilibrium is a mixed one.
Based on the fundamentals of game theory, the optimal mixed
strategies can be easily shown to be the following:
popt = d22 −d21
L
,
qopt = d22 −d12
L
where L = (d11+d22)−(d12+d21). Without loss of generality,
we assume that
d11 > max{d12, d21}
and d22 > max {d12, d21}.
(4)
Notice that the above inequalities are not restrictive,
as games not satisfying them can be mapped in a symmetric
manner by reindexing the actions of the players and/or the
indices of the players.
2) Case 2 (There Is a Saddle Point in Pure Strategies): The
case where the game matrix has saddle points in pure strategies
corresponds to either: 1) d11 > d12, d12 < d21, d21 > d22, and
d22 < d11 or 2) in the symmetric case, where d11 < d12,
d12 > d21, d21 < d22, and d22 > d11.
Since the other cases can be proven in identical manners,
in the interest of brevity, we consider only the case where
d21 < d11 < d12.
(5)
In this case, popt = 1 and qopt = 1. The other subcases
within Case 2 can be obtained by reindexing the actions of
the players and/or the indices of the players, as in Case 1.
Let the vector X(t) =
p1(t) q1(t)⊺. We introduce the
notation that X(t) = X(t + 1) −X(t). We also represent
the conditional expected value operator by E[·|·]. Using these,
we claim the next theorem.
Theorem 1: Consider a zero-sum game with a payoff matrix
as in (1) and a learning algorithm deﬁned by (2) and (3)
for both players A and B, with learning rate θ. Then,
E[X(t)|X(t)] = θW(x), and for every ϵ
> 0, there
exists a unique stationary point X∗=
p∗
1 q∗
1
⊺satisfying the
following conditions.
1) W(X∗) = 0.
2) |X∗−Xopt| < ϵ.
Proof:
Let us ﬁrst compute the conditional expected
value3 of the increment X(t)
E[X(t)|X(t)] = E[X(t + 1) −X(t)|X(t)]
=
 E[p1(t + 1) −p1(t)|X(t)]
E[q1(t + 1) −q1(t)|X(t)])

= θ
W1(X(t))
W2(X(t))

= θW(X(t))
where the above format is possible since all possible updates
share the form X(t) = θW(t), for some W(t), as given
in (2).
3Computing the “expected value of the increment” is a standard procedure
in the theory of LA. This is because the increment, in and of itself, is a random
variable, which is sometimes positive and sometimes negative. Quantifying the
latter is not possible due to the randomness of the updating rule. However,
the conditional expected value of the increment can be determined, whence
(by invoking the “Law of the Unconscious Statistician”), one can determine
the expected value of the increment itself.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 654
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023
For ease of notation, we drop the dependence on t with
the implicit assumption that all occurrences of X, p1, and q1
represent X(t), p1(t), and q1(t), respectively. W1(x) is then
W1(X)
= p1q1d11(pmax −p1) + p1(1 −q1)d12(pmax −p1)
+(1 −p1)q1d21(pmin −p1)
+(1 −p1)(1 −q1)d22(pmin −p1)
= p1[q1d11 + (1 −q1)d12](pmax −p1)
+(1 −p1)[q1d21 + (1 −q1)d22](pmin −p1)
= p1(pmax −p1)D A
1 (q1) + (1 −p1)(pmin −p1)D A
2 (q1)
(6)
where
D A
1 (q1) = q1d11 + (1 −q1)d12
(7)
D A
2 (q1) = q1d21 + (1 −q1)d22.
(8)
By replacing pmax = 1 −pmin and rearranging the expres-
sion, we get
W1(X) = p1(1 −p1)D A
1 (q1) −p1 pminD A
1 (q1)
+(1 −p1)pminD A
2 (q1) −p1(1 −p1)D A
2 (q1)
= p1(1 −p1)

D A
1 (q1) −D A
2 (q1)

−pmin

p1 D A
1 (q1) −(1 −p1)D A
2 (q1)

.
Similarly, we can get
W2(X)
= q1 p1(1 −d11)(pmax −q1)
+q1(1 −p1)(1 −d12)(pmax −q1)
+(1 −q1)p1(1 −d21)(pmin −q1)
+(1 −q1)(1 −p1)(1 −d22)(pmin −q1)
= q1[p1(1 −d11) + (1 −p1)(1 −d12)](pmax −q1)
+(1 −q1)[p1(1 −d21) + (1 −p1)(1 −d22)](pmin −q1)
= q1(pmax −q1)

1 −DB
1 (p1)

+(1 −q1)(pmin −q1)
1 −DB
2 (p1)

(9)
where
DB
1 (p1) = p1d11 + (1 −p1)d21
(10)
DB
2 (p1) = p1d12 + (1 −p1)d22.
(11)
By replacing pmax = 1 −pmin and rearranging the expres-
sion, we get
W2(X)
= q1(1 −q1)
 1 −DB
1 (p1)
 −q1 pmin
 1 −DB
1 (p1)
+(1 −q1)pmin
 
1 −DB
2 (p1) −q1(1 −q1)
 
1 −DB
2 (p1)
 
= −q1(1 −q1)

DB
1 (p1) −DB
2 (p1)

+pmin

−q1
 
1 −DB
1 (p1)
 
+ (1 −q1)
 
1 −DB
2 (p1)
 
= −q1(1 −q1)

DB
1 (p1) −DB
2 (p1)

+pmin
q1DB
1 (p1) −(1 −q1)DB
2 (p1) + (1 −2q1)
.
(12)
We need to address the two identiﬁed cases. Consider
Case 1), where there is only a single mixed equilibrium.
According to (4), we get
D A
12(q1) = D A
1 (q1) −D A
2 (q1)
= (d12 −d22) + Lq1.
(13)
Given that L > 0, since d11 > d12 and d22 > d21, D A
12(q1)
is an increasing function of q1 and
⎧
⎪⎨
⎪⎩
D A
12(q1) < 0, if q1 < qopt
D A
12(q1) = 0, if q1 = qopt
D A
12(q1) > 0, if q1 > qopt.
(14)
For a given q1, W1(X) is quadratic in p1. Also, we have
W1
 0
q1

= pminD A
2 (q1) > 0
W1
 1
q1

= −pminD A
1 (q1) < 0.
(15)
Since W1(X) is quadratic with a negative second derivative
with respect to p1 and the inequalities in (15) are strict,
it admits a single root p1 for p1 ∈[0, 1]. Moreover, we have
W1(X) = 0 for some p1 such that
⎧
⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎩
p1 < 1
2, if q1 < qopt
p1 = 1
2, if q1 = qopt
p1 > 1
2, if q1 > qopt.
(16)
Using a similar argument, we can see that there exists a
single solution for each p1, and as pmin →0, we conclude
that W1(X) = 0 whenever p1 ∈{0, popt, 1}. Arguing in a
similar manner, we see that W2(X) = 0 when
X ∈
0
0

,
0
1

,
1
0

,
popt
qopt

.
Thus, there exists a small enough value for pmin such that
X∗= [p∗, q∗]⊺satisﬁes W2(X∗) = 0, proving Case 1).
In the proof of Case 1), we have utilized the fact that for
small enough pmin, the learning algorithm admits a stationary
point and also identiﬁed the corresponding possible values for
this point. It is thus always possible to select a small enough
pmin > 0 such that X∗approaches Xopt, concluding the proof
for Case 1).
Case 2) can be derived in a similar manner, and the details
are omitted to avoid repetition.
□
In the next theorem, we show that the expected value of
X(t) has a negative deﬁnite gradient.
Theorem 2: The
matrix
of
partial
derivatives,
((∂W(X∗))/∂x), is negative deﬁnite.
Proof: We start the proof by writing the explicit format
for
∂W(X)
∂X
=
⎡
⎢⎢⎣
∂W1(X)
∂p1
∂W1(X)
∂q1
∂W2(X)
∂p1
∂W2(X)
∂q1
⎤
⎥⎥⎦
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION
655
and then computing each of the entries as follows:
∂W1(X)
∂p1
= (1 −2p1)
 
D A
1 (q1) −D A
2 (q1)
 
−pmin
 
D A
1 (q1) + D A
2 (q1)
 
= (1 −2p1)D A
12(q1)
−pmin
 D A
1 (q1) + D A
2 (q1)
 
∂W1(X)
∂q1
= p1(1 −p1)L −pmin(p1(d11 −d12)
+(1 −p1)(d22 −d21))
∂W2(X)
∂p1
= −q1(1 −q1)L + pmin((q1(d11 −d21)
−(1 −q1)(d12 −d22))
∂W2(X)
∂q1
= −(1 −2q1)
 
DB
1 (p1) −DB
2 (p1)
 
+pmin
 
DB
1 (p1) + DB
2 (p1) −2
 
.
As seen in Theorem 1, for a small enough value for pmin,
we can ignore the terms that are weighted by pmin, and we
will thus have ((∂W(X∗))/∂X) ≈((∂W(Xopt))/∂X). We now
subdivide the analysis in the two cases identiﬁed as above,
which are equivalent to the following.
1) Case 1: No saddle point in pure strategies.
2) Case 2: There is a saddle point in pure strategies.
3) Case 1 (No Saddle Point in Pure Strategies): In this case,
we have
D A
1
 
qopt
 
= D A
2
 
qopt
 
and DB
1
 
popt
 
= DB
2
 
popt
 
which makes
∂W1
 
Xopt
 
∂p1
= −2pminD A
1
 
qopt
 
.
(17)
Similarly, we can compute
∂W1
 
Xopt
 
∂q1
= (1 −2pmin)popt
 1 −popt
 L.
(18)
The entry ((∂W2(Xopt))/∂p1) can be simpliﬁed to
∂W2
 Xopt
 
∂p1
= −(1 −2pmin)qopt
 
1 −qopt
 
L
(19)
and
∂W2
 
Xopt
 
∂q1
= −2pmin
 
1 −DB
1
 
popt
  
(20)
resulting in (21), as shown at the bottom of the page.
The matrix given in (21) satisﬁes
det

∂W
 
Xopt
 
∂x

> 0 , trace

∂W
 
Xopt
 
∂x

< 0
(22)
which implies that the 2 × 2 matrix is negative deﬁnite.
4) Case 2 (There Is a Saddle Point in Pure Strategies):
In Theorem 1, Case 2 reduces to considering qopt = 1 and
popt = 1.
Computing the entries of the matrix for this case yields
∂W1
 
Xopt
 
∂p1
= −(d11 −d21) −pmin(d11 + d21)
(23)
and
∂W1
 
Xopt
 
∂q1
= −pmin(d11 −d12).
(24)
The entry ((∂W2(Xopt))/∂p1) can be simpliﬁed to
∂W2
 
Xopt
 
∂p1
= pmin(d11 −d21)
(25)
and
∂W2
 
Xopt
 
∂q1
= (d11 −d12) −pmin(2 −d11 −d12)
(26)
resulting in (27), as shown at the bottom of the next page.
The matrix in (27) satisﬁes
det

∂W
 
Xopt
 
∂X

> 0 , trace

∂W
 
Xopt
 
∂X

< 0
(28)
for a sufﬁciently small value of pmin, which again implies that
the 2 × 2 matrix is negative deﬁnite.
□
Theorem 3: Let V be the von Neumann value of the game
given by matrix D. Let p(t) = [p1, p2] and q(t) = [q1, q2].
For a sufﬁciently small pmin approaching 0, η(t) converges to
V as θ →0 where
η(t) ≜Ep(t)
DEqT (t)
.
(29)
Proof: The proof of these results requires a classic result
due to Norman [7], given in the Appendix, in the interest of
completeness.
The convergence of
E(p1(t)) E(q1(t))
to
p∗
opt q∗
opt

is
a consequence of this theorem. Interestingly enough, this
theorem is a classical fundamental result that has been used
to prove many of the convergence results in LA. It has, for
example, been used by the seminal paper by Lakshmivarahan
and Narendra [1] to derive similar convergence properties of
the L R−ϵP, applicable for the same game settings as ours.
Indeed, it is easy to verify that Assumptions (1)–(6) required
for Norman’s result are satisﬁed. Thus, by further invoking
Theorem 1 and Theorem 2, the result follows.
□
We conclude this section by mentioning that like all LA
algorithms, the computational complexity of our scheme is
linear in the size of the action probability vector. This is
because, at the most, all the action probabilities are updated
at every time instant.
For the beneﬁt of future researchers, we believe that it
will be proﬁtable to record the hurdles we encountered in
∂W
 
Xopt
 
∂X
=

−2pminD A
1
 
qopt
 
(1 −2pmin)popt
 
1 −popt
 
L
−(1 −2pmin)qopt
 
1 −qopt
 
L
−2pmin
 
1 −DB
1
 
popt
  

.
(21)
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 656
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023
this research. The breakthrough came when we were able
to devise/design LA systems that possessed no-absorbing
barriers. In other words, it involved the concept of forcing the
LA back into the probability space when it was close enough to
the absorbing barriers. This was a phenomenon that we had not
earlier seen in the literature. The consequent problem was the
analysis. The underlying Markov process could not be easily
analyzed using the properties of absorbing chains. Neither
could it be trivially modeled as an ergodic chain converging
to an equilibrium distribution. The analysis that we presented
here came as a “brain wave,” and once the building blocks
were established, everything naturally seemed to fall in place.
These few sentences, requested by an anonymous referee,
should clarify the difﬁculties encountered in this research,
in order to show that the present research is pioneering and
this is not a trivial extension of existing methodologies.
IV. SIMULATIONS
In this section, we present simulations to conﬁrm the
abovementioned theoretical properties of the proposed learning
algorithm. In the interest of maintaining benchmarks, we adopt
the same examples as those reported in [1]. Also, by using
different instances of the payoff matrix D, we are able to
experimentally cover the two cases referred to in Section III.
Again, we refer to those cases as Cases 1 and 2, as done in [1].
A. Convergence in Case 1
We consider an instance of the game where only one mixed
Nash equilibrium exists, i.e., there is no saddle point in pure
strategies. We adopt the same game matrix D as in [1] given
by
D =
 0.6
0.2
0.35
0.9

(30)
which admits popt = 0.5789 and qopt = 0.7368.
In order to eliminate the Monte Carlo error, we ran our
scheme for 5 × 106 iterations and report the error in Table I
for different values of pmax and θ as the difference between
Xopt and the mean over time of X(t) after convergence.4
An important remark is that the error decreases as pmax
approaches 1 (i.e., when pmin →0). Please observe that in
this case, we have particularly chosen to not let pmax be unity.
If we allow it to be precisely unity, it would mean that we
would not require an
artiﬁcial barrier close to unity (for
example, between 0.990 and 0.999 as in Table I). In fact, for
pmax = 0.999 and θ = 0.001, the method achieves an error of
2.1621 × 10−3, and further reducing θ = 0.0001 leads to an
error of 1.6820 × 10−3.
To better visualize the scheme, Fig. 1 shows the evolution
over time of the mixed strategies for both players (given by
4The mean is taken over the last 10% of the total number of iterations.
TABLE I
ERROR FOR DIFFERENT VALUES OF θ AND pMAX WHEN pOPT = 0.5789 AND
qOPT = 0.7368 FOR THE GAME SPECIFIED BY THE D MATRIX GIVEN
BY (30). THE POINT THAT YOU HAVE RAISED IS PERTINENT
Fig. 1.
Time evolution of [p1(t), q1(t)]⊺for the same settings as in Fig. 2.
X(t)) for an ensemble of 1000 runs using θ = 0.01 and
pmax = 0.999.
The trajectory of the ensemble allows us to perceive the
mean evolution of the mixed strategies. The spiral pattern is
caused by one of the players adapting to the strategy being
used by the other before the former learns by overcorrecting
its strategy. The procedure is continued leading to smaller
corrections until the players reach the Nash equilibrium.
The abovementioned behavior can also be visualized
in Fig. 2 that presents the trajectory for a single experiment
with pmax = 0.99 and θ = 0.00001 over 3 × 107 steps. The
described oscillatory behavior is attenuated as the players play
for more iterations. The reader should particularly observe
that a larger value of θ will cause more steady-state error
(as speciﬁed in Theorem 1), but it will also perturb this
behavior as the nodes take larger updates whenever they win.
On the other hand, further decreasing θ results in a smaller
error of the stationary point of the method but also decreases
the convergence speed. This well-established inherent tradeoff
between the steady-state error and rate of convergence can be
better visualized by comparing Fig. 1 with θ = 0.001 against
Fig. 3 for a smaller value of θ = 10−5.
∂W
 
Xopt
 
∂X
=
−(d11 −d21) −pmin(d11 + d21)
−pmin(d11 −d12)
pmin(d11 −d21)
(d11 −d12) −pmin(2 −d11 −d12)

.
(27)
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION
657
Fig. 2.
Trajectory of X(t) for the case of the D matrix given by (30) with
popt = 0.5789 and qopt = 0.7368 and using pmax = 0.99 and θ = 0.00001.
Fig. 3.
Time evolution of X(t) where popt = 0.5789 and qopt = 0.7368
using pmax = 0.99 and θ = 0.00001.
Fig. 4.
Trajectory of X(t) for the case of the D matrix given by (30) and
using an absorbing barrier pmax = 1 and θ = 0.00001.
Furthermore, in order to clearly emphasize the necessity of
using an artiﬁcial barrier, we have speciﬁcally repeated the
same experiment except that we have included an absorbing
barrier instead, i.e., set pmax = 1. The result is shown in Fig. 4.
In this case, we expect that the scheme enters an absorbing
barrier. Since it is impossible for the human eye to detect
whether or not we entered an absorbing barrier by merely
examining the graph, we also manually checked the log of
TABLE II
ERROR FOR DIFFERENT VALUES OF θ AND pMAX FOR D1
TABLE III
ERROR FOR DIFFERENT VALUES OF θ AND pMAX FOR D2
the experiment and veriﬁed that the probabilities became
exactly unity after around 6798000 iterations. Although the
theoretical convergence should have occurred in the limit and
not after a ﬁnite number of iterations, the machine limited
accuracy rounded the probabilities to unity after this juncture.
B. Pure Equilibrium
In order to assess the performance of the proposed learning
algorithm on cases with a pure equilibrium, we consider two
instances of games falling in the category of Case 2 with
popt = 1 and qopt = 1. The payoff matrices D1 and D2 for the
two games are given by
D1 =
 0.6
0.8
0.35
0.9

D2 =
0.7
0.9
0.6
0.8

.
We ﬁrst show the convergence errors of our method for both
games D1 and D2 in Tables II and III, respectively. As in the
previous simulation for Case 1, the errors are on the order
to 10−3 for larger values of pmax. However, given that our
algorithm uses artiﬁcial barriers to prevent absorbing states,
the error is lower bounded by pmin. A similar issue is present
in game D2. We have also included this simulation since it is
a more challenging game to learn with our method for a larger
steady-state error, even for very small values of θ.
In Fig. 5, we depict the time evolution of the two compo-
nents of the vector X(t) using the proposed algorithm for an
ensemble of 1000 runs. In the case of having a pure Nash
equilibrium, there is no oscillatory behavior as when a player
assigns more probability to an action since the other player
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 658
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023
Fig. 5.
(a) Evolution over time of X(t) for θ = 0.01 and Pmax = 0.999 when
applied to game with payoffs D1. (b) Zoomed version around the steady-state
value.
Fig. 6.
(a) Evolution over time of X(t) for θ = 0.01 and Pmax = 0.999 when
applied to game with payoffs D2. (b) Zoomed version around the steady-state
value.
reinforces the strategy. However, Fig. 5(a) could lead make
one believe that the LA method has converged to a pure
strategy. Fig. 5(b) zooms around the point where the strategies
have converged to showcase that their maximum value is
limited by pmax, as per the design of our updating rule. This
mechanism is particularly favorable to prevent players from
converging to absorbing states for games with time-varying
payoff matrices. However, the study of such a scenario is left
for future research, namely that of determining how to design
pmax and θ that represent a good tradeoff between learning the
game and adapting to a change in the payoffs.
Game D2 presents a harder challenge for our method as
we can see from its larger steady-state error. Fig. 6 shows the
time evolution of the probabilities for each player when the
algorithm is applied to D2 with θ = 0.01, Pmax = 0.999 and
for an ensemble with 1000 runs.
The main remark regarding the results presented in Fig. 6(a)
is that the convergence is much slower when compared to
game D1. This behavior is governed by the fact that the entries
in matrix D2 are closer to each other, unlike in D1 where there
is a clear disadvantage for player A when selecting action 2.
There will, thus, be much fewer updates for player A where
it increases the probability of action 2 in game D1—which is
not pertinent in game D2. Fig. 6(b) further emphasizes this
remark by displaying a zoom, depicting a sharper change in
the probabilities in comparison with the smooth behavior in
game D1.
C. Comparisons With Related Works
Now that we have explained our new techniques and estab-
lished its theoretical basis, we continue this discussion with a
brief comparison with some of the prior art.5
First of all, one possible alternative when the payoff matrix
is known can be to consider the problem as that of designing
a local controller for each of the agents. One alternative is
to explore the results in [28] and further investigated in [29].
However, this is only possible when D is known, which is not
the scenario that we have assumed in this article.
It is not out of place to review some of the relevant works
in game theory that are not necessarily solved using LA.
However, in the interest of space and brevity, we will not aim
at submitting an extensive review of the ﬁeld of game theory.
Rather, we shall cite some pertinent works inasmuch as our
main contribution in this article centers on advancing the ﬁeld
of LA-based solutions and, more speciﬁcally, those dealing
with the special case of games with “incomplete information.”
There are different variants of zero-sum stochastic games in
the literature. Flesch et al. [30] have proven the general result
that every positive zero-sum stochastic game with countable
state and action spaces admits a value if at least one player
has a ﬁnite action space. A similar value-existence result
was obtained for a zero-sum stochastic game [31] with a
continuous-time Markov chain, where the players have also
the possibility of stopping the game. Ziliotto [32] considered
weighted-average stochastic games, that is, stochastic games
where Player 1 maximizes (in expectation) a ﬁxed weighted
average of the sequence of rewards. A so-called pumping
algorithm was proposed in [33] for two-person zero-sum
undiscounted stochastic games. Other approaches map the
game onto a dynamic programming problem and solve it based
on Bellman’s optimal principle using concepts from the theory
of optimal control [34].
The research on game theoretical learning with incomplete
information [13] is scarce in the literature. Incomplete infor-
mation is a taxonomy used within the ﬁeld of LA games to
denote the case where the players do not observe the action of
the opponent players and where each player does not know his
own payoff function but only observes outcomes in the form
of a reward or a penalty. The informed reader would observe
that the games we deal with in this article fall under this class
of games characterized by such incomplete information.
The case of incomplete information is not usually treated
by the mainstream of literature in game theory. Indeed,
5We are thankful to the anonymous referee who requested this comprehen-
sive section. It signiﬁcantly adds to the quality of this article.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION
659
the main game learning algorithms available in the literature,
such as ﬁctitious play [35], best response dynamics, and
gradient-based learning approaches, deal with the complete
knowledge case, where the players know their own payoff
function and observe the history of the choices of other
players. Fictitious play is one of the few algorithms that can
converge to a mixed strategy equilibrium by maintaining var-
ious frequency-based beliefs over the action of the opponent
players, and using those beliefs, for deciding the next action to
be played. However, the ﬁctitious play algorithm cannot solve
our settings of incomplete information.
When it comes to games with incomplete information,
different algorithms have been suggested, which are based
on the Bush–Mosteller learning paradigm. Notable examples
include the ones reported in [36]–[39]. All those algorithms
share a similar structure to our proposed LA, in particular, and
to VSLA in general, in the sense, that the action probabilities
are updated iteratively based on feedback and using some
learning parameter. In this context, one should note that many
LA models can be seen as extensions of Bush–Mosteller
learning. However, the difference with our work is the fact that
all the aforementioned algorithms have absorbing barriers. The
theoretical analyses of the convergence to pure equilibria for
this family of algorithms rely usually on the theory replicator
dynamics.
Another family of methods that can operate with limited
information includes the Erev–Roth algorithm [40] and the
Arthur algorithm [41], which in turn can be seen as a
variant of the Erev–Roth algorithm. The Erev–Roth algo-
rithm is alternatively called the Erev–Roth payoff matching
algorithm and relies on updating the so-called “propensity”
for each action, which is, loosely speaking, the cumulative
payoff for that action. Thereafter, each action is played in a
manner proportional to its corresponding relative propensity.
The Erev–Roth algorithm is one of the few examples of
limited-information game learning approaches that converge
to unique mixed strategy equilibria. However, the Erev–Roth
algorithm requires storing the entire history of rewards and
penalties for each action. Furthermore, we have not been able
to locate any research study that reports the analysis of the
Erev–Roth algorithm for the case of our stochastic zero-sum
game. We therefore opted to implement it for our game.
Experimental results (not reported here, in the interest of not
distracting from the main contribution of this article) show
that it neither converges to the desired equilibrium nor does it
possess consistent convergence results.
D. Real-Life Application Scenarios
One referee had requested a brief explanation of a complex
environment, or different scenarios in a game, by which we
could utilize our newly proposed solution. We agree that
providing an insightful discussion could be insightful for
interested readers and active researchers. This, of course, can
be open-ended, but to satisfy the referee, we present the
following brief example.
Our learning algorithm admits potential applications in
many security games as well as in communication problems.
The intersection between game theory and security is an
emerging ﬁeld of research. Algorithms that can converge to
mixed equilibria are of great interest to the security community
because mixed equilibria are usually preferred over pure ones.
In fact, randomization gives less predictive ability to the
attacker to guess the deployed strategy of the defender [42].
For instance, let us take a repetitive game involving a jammer
and a transmitter, which, in turn, constitute our players [43].
The jammer aims to disturb and block communication between
a transmitter and its associated receiver. The transmitter can
choose the channel over which his message is communicated,
while the jammer chooses a channel to attack. We suppose
that the outcome is stochastic depending on the choice of the
attacker (jammer) and defender (transmitter) and the stochastic
characteristics of the channel. Both the jammer and transmitter
can observe whether the attack was successful or not, and
for instance, this common observation can be due to the
receiver acknowledging the correct reception of the message
over a wireless channel that both the attacker and jammer can
overhear. Thus, the game is stochastic zero-sum.
V. CONCLUSION
The theoretical applications LA with artiﬁcially absorbing
barriers have been reported since the 1980s [8] and, more
recently, in Estimator LA [18]–[20]. This article pioneers the
study of LA with artiﬁcial nonabsorbing barriers. LA have
been previously used [13] to design algorithms capable of
converging to the game’s Nash equilibrium under limited
information. The majority of the LA algorithms used for
games are absorbing in the probability simplex space, and they
converge to an exclusive choice of a single action. These LA
are, thus, unable to converge to other mixed Nash equilibria
when the game possesses no saddle point for a pure strategy.
As opposed to these, we propose an LA solution that is able to
converge to an optimal mixed Nash equilibrium even though
there may be no saddle point when a pure strategy is invoked.
The scheme is inherently of the absorbing L R−I paradigm.
However, by introducing reﬂecting barriers, we prevent it from
being “stuck” or getting absorbed in pure strategies. Unlike the
linear reward-ϵpenalty (L R−ϵP) scheme proposed in [1], our
new scheme achieves the same goal with much less parameter
tuning and in a more elegant manner.
As far as know, our method is only the second reported
algorithm in the literature capable of ﬁnding mixed strategies
whenever no saddle point exists for pure strategies. If a
saddle point exists for pure strategies, the scheme converges
to a near-optimal solution close to the pure strategies in the
probability simplex. This article includes the nontrial proofs
of the theoretical results characterizing the convergence and
stability of the algorithm. These are presented and illustrated
through simulations for benchmark games presented in the
literature.
With regard to future work, we believe that it will be
useful in real-life applications that can be modeled using such
game-like behavior.
APPENDIX
NORMAN THEOREM
Theorem 4: Let X(t) be a stationary Markov process
dependent on a constant parameter θ ∈[0, 1]. Each X(t) ∈I,
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 660
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023
where I is a subset of the real line. Let X(t) = X(t + 1) −
X(t). The following are assumed to hold.
1) I is compact.
2) E[X(t)|X(t) = y] = θw(y) + O
 
θ2 
.
3) V ar[X(t)|X(t) = y] = θ2 s(y) + o
 
θ2 
.
4) EX(t)3|X(t) = y = O θ3 . where supy∈I
 O θk /
θk 
< ∞for K = 2, 3 and supy∈I
 
o
 
θ2 
/θ2 
→0 as
θ →0.
5) w(y) has a Lipschitz derivative in I.
6) s(y) is Lipschitz I.
If Assumptions (1)–(6) hold, w(y) has a unique root y∗in
I and (dw/dy)

y=y∗≤0; then, the following conditions hold.
1) var[X(t)|X(0) = x] = 0(θ) uniformly for all x ∈I
and t ≥0. For any x ∈I, the differential equation
(dy(τ)/dτ) = w(y(t)) has a unique solution y(τ) =
y(τ, x) with y(0) = x and E[δX(t)|X(0) = x] =
y(tθ) + O(θ) uniformly for all x ∈I and t ≥0.
2)
 
(X(t) −y(tθ))/
√
θ
 
has a normal distribution with
zero mean and ﬁnite variance as θ →0 and tθ →∞.
ACKNOWLEDGMENT
The authors are very grateful for the feedback from the
anonymous Referees of the original submission. Their input
signiﬁcantly improved the quality of this ﬁnal version.
REFERENCES
[1] S. Lakshmivarahan and K. S. Narendra, “Learning algorithms for two-
person zero-sum stochastic games with incomplete information: A
uniﬁed approach,” SIAM J. Control Optim., vol. 20, no. 4, pp. 541–552,
1982.
[2] S. Lakshmivarahan, Learning Algorithms Theory and Applications:
Theory and Applications. New York, NY, USA: Springer, 2012.
[3] J. K. Lanctot and B. J. Oommen, “On discretizing estimator-based
learning algorithms,” IEEE Trans. Syst., Man, Cybern., B, Cybern.,
vol. 2, pp. 1417–1422, 1991.
[4] J. K. Lanctot and B. J. Oommen, “Discretized estimator learn-
ing automata,” IEEE Trans. Syst., Man, Cybern., vol. 22, no. 6,
pp. 1473–1483, Nov./Dec. 1992.
[5] K. Najim and A. S. Poznyak, Learning Automata: Theory and Applica-
tions. Amsterdam, The Netherlands: Elsevier, 2014.
[6] K. S. Narendra and M. A. Thathachar, Learning Automata: An Intro-
duction. North Chelmsford, MA, USA: Courier Corporation, 2012.
[7] M. F. Norman, Markov Processes and Learning Models, vol. 84.
New York, NY, USA: Academic, 1972.
[8] B. Johnoommen, “Absorbing and ergodic discretized two-action learning
automata,” IEEE Trans. Syst., Man, Cybern., vol. 16, no. 2, pp. 282–293,
Mar. 1986.
[9] B. J. Oommen and J. K. Lanctot, “Discretized pursuit learning
automata,” IEEE Trans. Syst., Man, Cybern., vol. 20, no. 4, pp. 931–938,
Jul./Aug. 1990.
[10] B. J. Oommen and M. Agache, “Continuous and discretized pursuit
learning schemes: Various algorithms and their comparison,” IEEE
Trans. Syst., Man, Cybern., B (Cybern.), vol. 31, no. 3, pp. 277–287,
Jun. 2001.
[11] G. P. Papavassilopoulos, “Learning algorithms for repeated bimatrix
Nash games with incomplete information,” J. Optim. Theory Appl.,
vol. 62, no. 3, pp. 467–488, 1989.
[12] A. Rezvanian, A. M. Saghiri, S. M. Vahidipour, M. Esnaashari, and
M. R. Meybodi, Recent Advances in Learning Automata, vol. 754.
New York, NY, USA: Springer, 2018.
[13] P. S. Sastry, V. V. Phansalkar, and M. A. L. Thathachar, “Decentralized
learning of Nash equilibria in multi-person stochastic games with
incomplete information,” IEEE Trans. Syst., Man Cybern., vol. 24, no. 5,
pp. 769–777, May 1994.
[14] M. A. L. Thathachar and P. S. Sastry, Networks of Learning Automata:
Techniques for Online Stochastic Optimization. Boston, MA, USA:
Kluwer, 2003.
[15] M. L. Tsetlin et al., Automaton Theory and Modeling of Biological
Systems. New York, NY, USA: Academic, 1973.
[16] B. Tung and L. Kleinrock, “Using ﬁnite state automata to produce self-
optimization and self-control,” IEEE Trans. Parallel Distrib. Syst., vol. 7,
no. 4, pp. 439–448, Apr. 1996.
[17] Y. Xing and R. Chandramouli, “Stochastic learning solution for distrib-
uted discrete power control game in wireless data networks,” IEEE/ACM
Trans. Netw., vol. 16, no. 4, pp. 932–944, Aug. 2008.
[18] X. Zhang, O. C. Granmo, B. J. Oommen, and L. Jiao, “A formal proof
of the ε-optimality of absorbing continuous pursuit algorithms using
the theory of regular functions,” Appl. Intell., vol. 41, pp. 974–985,
May 2014.
[19] X. Zhang, B. J. Oommen, O. C. Granmo, and L. Jiao, “A formal proof of
the ε-optimality of discretized pursuit algorithms,” Appl. Intell., vol. 44,
pp. 282–294, 2016, doi: 10.1007/s10489-015-0670-1.
[20] X. Zhang, B. J. Oommen, and O. C. Granmo, “The design of absorb-
ing Bayesian pursuit algorithms and the formal analyses of their ε-
optimality,” Pattern Anal. Appl., vol. 20, no. 3, pp. 797–808, 2015.
[21] J. R. Marden, G. Arslan, and J. S. Shamma, “Cooperative control and
potential games,” IEEE Trans. Syst., Man, Cybern. B. Cybern., vol. 39,
no. 6, pp. 1393–1407, Dec. 2009, doi: 10.1109/TSMCB.2009.2017273.
[22] D. Silvestre, J. P. Hespanha, and C. Silvestre, “Resilient desyn-
chronization for decentralized medium access control,” IEEE Con-
trol
Syst.
Lett.,
vol.
5,
no.
3,
pp. 803–808,
Jul.
2021,
doi:
10.1109/LCSYS.2020.3005819.
[23] D. Silvestre, J. Hespanha, and C. Silvestre, “Desynchronization for
decentralized medium access control based on gauss-seidel iterations,”
in Proc. Amer. Control Conf. (ACC), Jul. 2019, pp. 4049–4054, doi:
10.23919/ACC.2019.8814471.
[24] D. Silvestre, J. P. Hespanha, and C. Silvestre, “Broadcast and gossip
stochastic average consensus algorithms in directed topologies,” IEEE
Trans. Control Netw. Syst., vol. 6, no. 2, pp. 474–486, Jun. 2019, doi:
10.1109/TCNS.2018.2839341.
[25] D. Silvestre, J. Hespanha, and C. Silvestre, “A PageRank algorithm
based on asynchronous gauss-seidel iterations,” in Proc. Annu. Amer.
Control Conf. (ACC), Milwaukee, WI, USA, Jun. 2018, pp. 484–489,
doi: 10.23919/ACC.2018.8431212.
[26] R. Ribeiro, D. Silvestre, and C. Silvestre, “A rendezvous algorithm
for multi-agent systems in disconnected network topologies,” in Proc.
28th Medit. Conf. Control Autom. (MED), Sep. 2020, pp. 592–597, doi:
10.1109/MED48518.2020.9183093.
[27] R. Ribeiro, D. Silvestre, and C. Silvestre, “Decentralized control for
multi-agent missions based on ﬂocking rules,” CONTROLO ( Lec-
ture Notes in Electrical Engineering), vol. 695, J. A. Gonçalves,
M. Braz-César, and J. P. Coelho, Eds. Cham, Switzerland: Springer,
2021, pp. 445–454, doi: 10.1007/978-3-030-58653-9_43.
[28] Y. Wu and R. Lu, “Output synchronization and L2-gain analysis for
network systems,” IEEE Trans. Syst., Man, Cybern., Syst., vol. 48,
no. 12, pp. 2105–2114, Dec. 2018, doi: 10.1109/TSMC.2017.2754544.
[29] Y. Wu, A. Isidori, R. Lu, and H. K. Khalil, “Performance recovery
of dynamic feedback-linearization methods for multivariable nonlinear
systems,” IEEE Trans. Autom. Control, vol. 65, no. 4, pp. 1365–1380,
Apr. 2020, doi: 10.1109/TAC.2019.2924176.
[30] J. Flesch, A. Predtetchinski, and W. Sudderth, “Positive zero-sum
stochastic games with countable state and action spaces,” Appl. Math.
Optim., vol. 82, pp. 499–516, Nov. 2018.
[31] C. Pal and S. Saha, “Continuous-time zero-sum stochastic game with
stopping and control,” Operations Res. Lett., vol. 48, no. 6, pp. 715–719,
Nov. 2020.
[32] B. Ziliotto, “A tauberian theorem for nonexpansive operators and appli-
cations to zero-sum stochastic games,” Math. Operations Res., vol. 41,
no. 4, pp. 1522–1534, Nov. 2016.
[33] E. Boros, K. Elbassioni, V. Gurvich, and K. Makino, “A potential
reduction algorithm for two-person zero-sum mean payoff stochastic
games,” Dyn. Games Appl., vol. 8, no. 1, pp. 22–41, Mar. 2018.
[34] K. Du, R. Song, Q. Wei, and B. Zhao, “A solution of two-person zero
sum differential games with incomplete state information,” in Advances
in Neural Networks—ISNN 2019 (Lecture Notes in Computer Science),
vol. 11554, H. Lu, H. Tang, and Z. Wang, Eds. Cham, Switzerland:
Springer, 2019, doi: 10.1007/978-3-030-22796-8_46.
[35] J. Hofbauer and W. H. Sandholm, “On the global convergence of
stochastic ﬁctitious play,” Econometrica, vol. 70, no. 6, pp. 2265–2294,
Nov. 2002.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION
661
[36] T. Börgers and R. Sarin, “Learning through reinforcement and replicator
dynamics,” J. Econ. Theory, vol. 77, no. 1, pp. 1–14, Nov. 1997.
[37] L. R. Izquierdo, S. S. Izquierdo, N. M. Gotts, and J. G. Polhill, “Tran-
sient and asymptotic dynamics of reinforcement learning in games,”
Games Econ. Behav., vol. 61, no. 2, pp. 259–276, Nov. 2007.
[38] A. S. Poznyak and K. Najim, “Bush-Mosteller learning for a zero-sum
repeated game with random pay-offs,” Int. J. Syst. Sci., vol. 32, no. 10,
pp. 1251–1260, 2001.
[39] Q. Zhu, H. Tembine, and T. Basar, “Heterogeneous learning in zero-
sum stochastic games with incomplete information,” in Proc. 49th IEEE
Conf. Decis. Control (CDC), Dec. 2010, pp. 219–224.
[40] I. Erev and A. E. Roth, “Multi-agent learning and the descriptive value
of simple models,” Artif. Intell., vol. 171, no. 7, pp. 423–428, May 2007.
[41] W. B. Arthur, “On designing economic agents that behave like human
agents,” J. Evol. Econ., vol. 3, no. 1, pp. 1–22, Mar. 1993.
[42] M. H. Manshaei, Q. Zhu, T. Alpcan, T. Bac¸sar, and J.-P. Hubaux, “Game
theory meets network security and privacy,” ACM Comput. Surv., vol. 45,
no. 3, pp. 1–39, Jun. 2013.
[43] V. Vadori, M. Scalabrin, A. V. Guglielmi, and L. Badia, “Jamming in
underwater sensor networks as a Bayesian zero-sum game with position
uncertainty,” in Proc. IEEE Global Commun. Conf. (GLOBECOM),
Dec. 2014, pp. 1–6.
Anis Yazidi (Senior Member, IEEE) received the
M.Sc. and Ph.D. degrees from the University of
Agder, Grimstad,
Norway, in 2008 and 2012,
respectively.
He was a Researcher with Teknova AS, Grimstad.
From 2014 to 2019, he was an Associate Pro-
fessor with the Department of Computer Science,
Oslo Metropolitan University, Oslo, Norway. He is
currently a Full Professor with the Department of
Computer Science, where he is leading the research
group in applied artiﬁcial intelligence. He is also
a Professor II with the Norwegian University of Science and Technol-
ogy (NTNU), Trondheim, Norway. His current research interests include
machine learning, learning automata, stochastic optimization, and autonomous
computing.
Daniel
Silvestre
received the B.Sc. degree in
computer networks
from the Instituto Superior
Técnico (IST), Lisbon, Portugal, in 2008, and the
M.Sc. degree in advanced computing and the Ph.D.
degree (Hons.) in electrical and computer engineer-
ing from Imperial College London, London, U.K.,
in 2009 and 2017, respectively.
He was a Visiting Scholar at the University of
California at Santa Barbara, Santa Barbara, CA,
USA. He is currently with the Institute for Systems
and Robotics, IST. He holds a research assistant
appointment with the University of Macau, Macau. His research interests span
the ﬁelds of fault detection and isolation, distributed systems, network control
systems, computer networks, set-valued estimation and control methods, and
randomized algorithms.
B. John Oommen (Life Fellow, IEEE) was born
in India, in 1953. He received the Bachelor of
Technology degree in electrical engineering from
IIT Madras, Chennai, India, in 1975, the Master
of Engineering degree from the Indian Institute of
Science, Bengaluru, India, in 1977, and the Master
of Science degree and the Ph.D. degree in electrical
engineering from Purdue University, West Lafayette,
IN, USA, in 1979 and 1982, respectively.
He has been teaching at the School of Computer
Science, Carleton University, Ottawa, ON, Canada,
since 1981. He was elevated to be a Chancellor’s Professor at Carleton
University in 2006. He has published more than 485 refereed publications,
many of which have been award-winning.
Dr. Oommen was nominated as a fellow of the Institute of Electrical and
Electronic Engineers (IEEE) for research in a subﬁeld of artiﬁcial intelligence,
namely in learning automata in 2003. He was also nominated as a fellow of the
International Association of Pattern Recognition (IAPR) in August 2006 for
contributions to fundamental and applied problems in syntactic and statis-
tical pattern recognition. He
received the Carleton University’s Research
Achievement Award four times, in 1995, 2001, 2007, and 2015. At IIT
Madras and the Indian Institute of Science, he received the medal for being
the Best Graduating Student. He has served on the Editorial Board of the
IEEE TRANSACTIONS ON SYSTEMS, MAN AND CYBERNETICS and Pattern
Recognition.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore.  Restrictions apply. 
",10.1109/TNNLS.2021.3099095,doc30,"—Learning automata (LA) with artiﬁcially absorbing
barriers was a completely new horizon of research in the 1980s
(Oommen, 1986). These new machines yielded properties that
were previously unknown. More recently, absorbing barriers
have been introduced in continuous estimator algorithms so
that the proofs could follow a martingale property, as opposed
to monotonicity (Zhang et al., 2014), (Zhang et al., 2015).
However, the applications of LA with artiﬁcial barriers are almost
nonexistent. In that regard, this article is pioneering in that it
provides effective and accurate solutions to an extremely complex
application domain, namely that of solving two-person zero-sum
stochastic games that are provided with incomplete information.
LA have been previously used (Sastry et al., 1994) to design
algorithms capable of converging to the game’s Nash equilibrium
under limited information. Those algorithms have focused on
the case where the saddle point of the game exists in a pure
strategy. However, the majority of the LA algorithms used for
games are absorbing in the probability simplex space, and thus,
they converge to an exclusive choice of a single action. These
LA are thus unable to converge to other mixed Nash equilibria
when the game possesses no saddle point for a pure strategy.
The pioneering contribution of this article is that we propose
an LA solution that is able to converge to an optimal mixed
Nash equilibrium even though there may be no saddle point
when a pure strategy is invoked. The scheme, being of the linear
reward-inaction (L R−I) paradigm, is in and of itself, absorbing.
However, by incorporating artiﬁcial barriers, we prevent it
from being “stuck” or getting absorbed in pure strategies.
Unlike the linear reward-ϵpenalty (L R−ϵ P) scheme proposed by
Lakshmivarahan and Narendra almost four decades ago, our
new scheme achieves the same goal with much less parameter
tuning and in a more elegant manner. This article includes
Manuscript received 2 October 2020; revised 16 February 2021; accepted
18 May 2021. Date of publication 4 August 2021; date of current ver-
sion 6 February 2023. The work of Daniel Silvestre was supported in
part by the Portuguese Fundação para a Ciência e a Tecnologia (FCT)
through the Institute for Systems and Robotics (ISR), Laboratory for Robot-
ics and Engineering Systems (LARSyS), under Project UIDB/50009/2020,
through FirePuma Project under Grant PCIF/MPG/0156/2019, and through
COPELABS, University Lusófona, under Project UIDB/04111/2020. The
work of B. John Oommen was supported in part by the Natural Sciences
and Engineering Research Council of Canada (NSERC) and in part by the
Natural Sciences and Engineering Council of Canada. (Corresponding author:
B. John Oommen.)
Anis Yazidi is with the Department of Computer Science, Oslo Metropolitan
University, 0190 Oslo, Norway (e-mail: anis.yazidi@oslomet.no).
Daniel Silvestre is with Dynamical Systems and Ocean Robotics Laboratory
(DSOR), Department of Electrical and Computer Engineering, Lusófona Uni-
versity, 1749-024 Lisbon, Portugal, and also with the Institute for Systems and
Robotics, Instituto Superior Técnico, University of Lisbon, 1049-001 Lisbon,
Portugal (e-mail: dsilvestre@isr.tecnico.ulisboa.pt).
B. John Oommen is with the School of Computer Science, Carleton Univer-
sity, Ottawa, ON K1S 5B6, Canada, and also with the Department of IKT, Uni-
versity of Agder, 4879 Grimstad, Norway (e-mail: oommen@scs.carleton.ca).
Color versions of one or more ﬁgures in this article are available at
https://doi.org/10.1109/TNNLS.2021.3099095.
Digital Object Identiﬁer 10.1109/TNNLS.2021.3099095
the nontrial proofs of the theoretical results characterizing our
scheme and also contains experimental veriﬁcation that conﬁrms
our theoretical ﬁndings.
Index Terms—Games with incomplete information, learning
automata (LA), LA with artiﬁcial barriers.
I.","650 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023 Solving Two-Person Zero-Sum Stochastic Games With Incomplete Information Using Learning Automata With Artiﬁcial Barriers Anis Yazidi , Senior Member, IEEE, Daniel Silvestre , and B. John Oommen , Life Fellow, IEEE Abstract INTRODUCTION T HE term learning automata (LA) denotes a whole subﬁeld of research within adaptive systems with several books being dedicated to its study [2], [5], [6], [12], [14]. The work on LA dates to the Soviet Union in the 1960s when the mathematical giant Tsetlin et al. [15] devised the so-called Tsetlin machine that is a learning mechanism with ﬁnite mem- ory. Tsetlin’s learning machines were demonstrated to give birth to self-organizing behavior through collective learning. In his work, Tsetlin pioneered the Goore game, which is a distributed coordination game with limited feedback that has many practical applications, as shown by Tung and Kleinrock [16]. The early works in the ﬁeld of LA, such as the Tsetlin machine, fall under the family of ﬁxed structure LA. The mainstream of current LA research concerns the family of variable structure LA (VSLA) which, loosely speaking, differs from ﬁxed structure LA in the fact that they operate with a probability vector that is updated dynamically over time. In ﬁxed structure LA, the choice is governed by a transition matrix whose transitions do not depend on time and that describes how the internal states of the LA are updated based on the environment’s feedback. The term LA was coined for the ﬁrst time by Narendra and Thathachar [6]. Markovian Representations of LA: LA can also be charac- terized by their Markovian representations. They thus fall into one of two families, being either ergodic or those that possess absorbing barriers [8]. Such a characterization is crucial to the tenets of this article. Absorbing automata have underlying Markov chains that get absorbed or locked into a barrier state. Sometimes, this can occur even after a relatively small, ﬁnite number of iterations. The classic references [2], [5], [6], [12], [14] report numerous LA families that contain such absorbing barriers. On the other hand, as these same references explain, the literature has also reported scores of ergodic automata, which converge in distribution. In these cases, the asymptotic distribution of the action probability vector converges to a value that is independent of its initial vector. Absorbing LA are usually designed to operate in stationary environments. As opposed to these, ergodic LA are preferred for nonstationary environments, namely those that possess 2162-237X © 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION 651 time-dependent reward probabilities. These characterizations, and their corresponding implications for game playing, will be explained presently. Continuous or Discretized VSLA: VSLA can also be char- acterized as being continuous or discretized. This depends on the values that the action probabilities can take. Continuous LA allow the action probabilities to assume any value in the interval [0, 1]. Such algorithms have a relatively slow rate of convergence. The problem with continuous LA is that they approach a goal but never reach there. This was mitigated in the 1980s by introducing the concept of discretization, where if an action probability was close enough to zero or unity, it could jump to that endpoint in a single step. This also ren- dered the LA to have a faster convergence because one could increase their speeds of convergence by incorporating this phenomenon [3], [4], [9]. This is implemented by constraining the action selection probability to be one of a ﬁnite number of values in the interval [0, 1]. By incorporating discretization, almost all of the reported VSLA of the continuous type have also been discretized [9], [10], [19]. LA With Artiﬁcially Absorbing Barriers: LA with artiﬁ- cially introduced absorbing barriers were a novelty in the 1980s. These yielded machines, which had properties that were previously unknown. This was due to the fact that a discretized machine, even though it was ergodic, could be rendered absorbing by forcing the machine to stay at one of the absorbing barriers [8]. Ironically, this simple step introduced families of new LA, with properties that were previously unknown. For example, ADLR−P and ADLI−P are absorbing versions of their corresponding ergodic counterparts but have been proven to be ϵ-optimal in all random environments. This phenomenon, of including artiﬁcially absorbing barriers, has been recently applied to the family of pursuit LA [18]. Estimator LA With Artiﬁcial Barriers: The concept of introducing absorbing barriers is also central to the proofs of estimator algorithms. For three decades, these pursuit algorithms were “proven” to be ϵ-optimal by virtue of the monotonicity property. However, recently, these proofs have been shown to be ﬂawed. To remedy this, absorbing barriers have been introduced in continuous estimator algorithms so that the proofs could follow a martingale property, as opposed to monotonicity. Consequently, Zhang et al. [18]–[20] have shown that one can invoke this weaker property, namely, the martingale property, by artiﬁcially providing such an absorbing barrier. Thus, whenever an action probability is close enough to unity, the LA is forced to jump to this absorbing barrier. Applications of LA: LA have boasted scores of applica- tions. These include theoretical problems, such as the graph partitioning problem. They have been used in controlling intel- ligent vehicles. When it concerns neural networks and hidden Markov models, Meybodi et al. have used them in adapting the former, and others have applied them in training the latter. Network call admission, trafﬁc control, and quality-of-service routing have been resolved using LA, while others have also found applications in tackling problems involving network and communications issues. Apart from these, the entire ﬁeld of LA and stochastic learning has had a myriad of applications listed in the reference books [2], [5], [6], [14]. In the interest of the page-limit constraints, the citations to these applications are not included. However, they can be easily found by executing a simple search, and many are included in the above benchmark references. Game Playing With LA: While artiﬁcially introduced barri- ers have been shown to have powerful theoretical and design implications, the applications of them are few. This is where this article ﬁnds its place—it presents one such application. LA have also been used to resolve stochastic games with incomplete information. This article pioneers a merge of the above two issues. First of all, we present a mechanism by which LA can be augmented with artiﬁcial barriers, but unlike the state of the art, these barriers are nonabsorbing. We then proceed to use these to play zero-sum games with incomplete information. Games of this type were studied four decades ago for scenarios when the game matrix had a saddle point using traditional L R−I and L R−P LA [13]. Our results generalize those when the game does not possess the Nash equilibrium. Rather, we propose the nontrivial use of LA with artiﬁcial nonabsorbing barriers to resolve such games. This article contains the theoretical results and those from simulations using the corresponding benchmark games. Landscape of Our Present Work: In this article, we pro- pose an algorithm addressing zero-sum games, which can be generalized to nonzero-sum games in a manner similar to the principle by which the method in [1] was generalized in [17]. In the latter, Xing and Chandramouli [17] proved that the linear reward−ϵpenalty (L R−ϵP) algorithm, devised in [1], is able to work in nonzero-sum games. Thus, without further elaborating on this,1 our results are generalizable to nonzero-sum games. Since the game is zero-sum, the outcomes are either a loss for player A, with reward −1, and the corresponding win for player B with value +1, or the converse for the case of a win for player A. We emphasize that this is a limited information game where each player is unaware of both the mixed strategy and the selected action of the other player. The available information to each player is whether its action resulted in a win or a loss. The reader should note that either/both players might not even be aware of the existence of another player and be working with the assumption that he is playing against nature, as in the classical multiarmed bandit algorithms. However, if both players learn using our algorithm based on the assumption that they are operating in an adversarial environment, we show that they will both converge to the desired equilibrium. Our proposed scheme has players adjusting their strategy whenever it obtains a “win” for that round. This conforms to the linear reward-inaction (L R−I) paradigm, described in detail, presently. It is thus, unarguably, radically different from the mechanism proposed by Lakshmivarahan and Narendra [1], where the probability updates are performed upon receiving both reward and penalty responses, which thus renders changes to occur at every time instant. 1Some preliminary unpublished work is being conducted for extending this work to nonzero-sum games. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. 652 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023 Objective and Contribution of This Article: Based on the above discussion, one can summarize the objective of this article as to study the behavior of a nonabsorbing barrier-based L R−I mechanism in a stochastic zero-sum game played by two players A and B, with two actions each, as earlier done in [1]. Each player uses an LA to decide his strategy, where the only received feedback from the environment is the reward of the joint actions of both players. The game is played iteratively and the players are able to revise their mixed strategies. Applications of the Proposed Method: Learning within the context of games has a natural application in the realm of game theory. However, in the context of multiagent systems (MASs), this has been shown to be suitable for the cooperative control of robotic systems [21]. In such a design, it is assumed that the mission can be fully described as a potential game, where the utility function measures how well the nodes in the network are complying with the objectives. Nevertheless, having robots converging to pure strategies means that the network designer is favoring exploitation and disregarding exploration. If the environment changes and causes a different payoff matrix, the agent would be locked into repeatedly playing the same strategy. Moreover, this assumes that the utility must be known and deterministic. Therefore, instead of designing application-speciﬁc algorithms, the proposed learn- ing algorithm can be used to address problems in cooperative control such as the so-called “rendezvous” problem for a ﬂeet of robots [26], [27], the desynchronization of the use of a shared medium [22], [23], and a consensus algorithm to have the agents agree on a common value [24] or to solve distributed computation such as the PageRank [25], by only considering the current stochastic payoff. It is also pertinent to mention that the mechanism that we propose here can be used by the agents to learn how to act if the payoff corresponds to how successful they are in following the objectives of the “mission.” Much can be said about this, but we terminate these discussions here in the interest of brevity and due to space limitations. However, with respect to future research, it is wise to mention that the question of whether they can be applied to synchronization, as in the analysis of the family of so-called “Fireﬂy” algorithms, is yet open. A. Notation Used Most of the notations that we use are well established from the theory of matrices and in the ﬁeld of LA [2], [6], and stating them would trivialize this article. However, we mention that apart from the well-established notations used in these areas, we will use the notation that the conditional expectation of some variable v with respect to w is written as E[v|w] and the partial derivative of a variable v(t) with respect to time t is denoted by (∂v(t)/∂t). II. GAME MODEL To initiate discussions, we formalize the game model that is being investigated. Let P(t) = p1(t) p2(t)⊺denote the mixed strategy of player A at time instant t, where p1(t) accounts for the probability of adopting strategy 1 and, conversely, p2(t) stands for the probability of adopting strategy 2. Thus, P(t) describes the distribution over the strategies of player A. Similarly, we can deﬁne the mixed strategy of player B at time t as Q(t) = q1(t) q2(t)⊺. The extension to more than two actions per player is straightforward following the method analogous to what was used by Papavassilopoulos [11], which extended the work of Lakshmivarahan and Narendra [1]. Let αA(t) ∈{1, 2} be the action chosen by player A at time instant t and αB(t) ∈{1, 2} be the one chosen by player B, following the probability distributions P(t) and Q(t), respec- tively. The pair (αA(t), αB(t)) constitutes the joint action at time t and is pure strategy. Speciﬁcally, if (αA(t), αB(t)) = (i, j), the probability of gain for player A is determined by di j, as formalized in [1]. We thus construct a matrix with the set of probabilities D = [di j], 1 ≤i ≤2, which is the so-called payoff matrix associated with the game. The matrix D is given by D = d11 d12 d21 d22  where all the entries are probabilities. Clearly, the actual game matrix G is given by gi j = 2 di j−1, with entries in the interval [−1, 1]. Without loss of generality, player A corresponds to the row player, whereas B is the column player. Furthermore, when referring to a “gain,” we are seeing this from the perspective of player A. In zero-sum games, Nash equilibria are equivalently called the “saddle points” for the game. Since the outcome for a given joint action is stochastic, the game is the stochastic form of a zero-sum game. The “zero-sum” property implies that at any time t, there is only one winning player.2 In the interest of completeness, we present the original scheme proposed in [1] based on the L R−ϵP rule. It uses two parameters θR and θP as the learning rates associated with the reward and penalty responses, respectively. When player A gains at time instant t by playing action i, he updates his mixed strategy as pi(t + 1) = pi(t) + θR(1 −pi(t)) ps(t + 1) = ps(t) −θP ps(t) for s ̸= i. However, if player A loses after using action i, his mixed strategy is updated by the following: pi(t + 1) = pi(t) −θP pi(t) ps(t + 1) = ps(t) + θR(1 −ps(t)) for s ̸= i. The exact update mechanism for player B is obtained by replacing the corresponding p(t) by q(t) and by recalling that a gain for A maps onto a loss scenario for player B. We now introduce our novel solution that is proposed to learn a new mixed strategy. 2The results inferred from this article can be extended to nonzero-sum games. However, for the sake of simplicity, we only consider the case of zero-sum games. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION 653 III. LA ALGORITHM BASED ON L R−I WITH ARTIFICIAL BARRIERS A. Nonabsorbing Artiﬁcial Barriers We have earlier seen that an ergodic LA can be made absorbing by artiﬁcially rendering the end states to become absorbing. This was brieﬂy addressed above. However, what has not been discussed in the literature is a strategy by which a scheme which is, in and of itself, absorbing, can be rendered to be ergodic. In other words, the LA are allowed to move within the probability simplex by utilizing an absorbing scheme. However, when it enters an absorbing barrier, the scheme is forced to go back into the simplex in order to render it to be ergodic. No such scheme has ever been reported in the literature, and the advantage of having such a scheme is that one does not get locked into a suboptimal absorbing barrier. Rather, we can permit it to move around so that it can migrate stochastically toward an optimal mixed strategy. This is, precisely, what we shall do. B. Nonabsorbing Game Playing We now present our strategic LA-based game algorithm together with a formal analysis that demonstrates the conver- gence to the saddle points of the game even if the saddle point corresponds to a mixed Nash equilibrium. Our LA solution is based on the L R−I scheme, but as alluded to earlier, it has been modiﬁed in order to nontrivially provide nonabsorbing barriers. The proof of convergence is based on Norman’s theory for learning processes characterized by small learning steps [6], [7]. Considering that pmax denotes an artiﬁcial barrier, we use the notation that pmin = 1 −pmax. We further constrain the probability for each action by restricting it, by design, to belong to the interval [pmin, pmax] if p1 and q1 are initially chosen to belong to the same interval. If the outcome from the environment is a gain at a time t for action i ∈{1, 2}, the update rule is given by pi(t + 1) = pi(t) + θ(pmax −pi(t)) ps(t + 1) = ps(t) + θ(pmin −ps(t)) for s ̸= i. The reader will observe that this update mechanism is identical to the well-established linear schemes, except that pmin and pmax replace the values zero and unity, respectively. When the player receives a loss, the probabilities are not updated, which translates into pi(t + 1) = pi(t) ps(t + 1) = ps(t) for s ̸= i. The update rules for the mixed strategy q(t +1) are deﬁned in a similar fashion by recalling the dichotomy that whenever player A gains, it corresponds to a loss for player B and vice versa. Analogous to the L R−I paradigm, mixed strategies are not changed in the case of a loss. We now proceed to analyze the convergence properties of the proposed algorithm. To aid in the analysis, we identify the Nash equilibrium of the game by the pair (popt, qopt). To render the presentation to be less cumbersome, we divide the analysis into two cases. 1) Case 1 [Only One Mixed Nash Equilibrium Case (No Saddle Point in Pure Strategies)]: The ﬁrst case depicts the situation where no saddle point exists in pure strategies. In other words, the only Nash equilibrium is a mixed one. Based on the fundamentals of game theory, the optimal mixed strategies can be easily shown to be the following: popt = d22 −d21 L , qopt = d22 −d12 L where L = (d11+d22)−(d12+d21). Without loss of generality, we assume that d11 > max{d12, d21} and d22 > max {d12, d21}. Notice that the above inequalities are not restrictive, as games not satisfying them can be mapped in a symmetric manner by reindexing the actions of the players and/or the indices of the players. 2) Case 2 (There Is a Saddle Point in Pure Strategies): The case where the game matrix has saddle points in pure strategies corresponds to either: 1) d11 > d12, d12 < d21, d21 > d22, and d22 < d11 or 2) in the symmetric case, where d11 < d12, d12 > d21, d21 < d22, and d22 > d11. Since the other cases can be proven in identical manners, in the interest of brevity, we consider only the case where d21 < d11 < d12. In this case, popt = 1 and qopt = 1. The other subcases within Case 2 can be obtained by reindexing the actions of the players and/or the indices of the players, as in Case 1. Let the vector X(t) = p1(t) q1(t)⊺. We introduce the notation that X(t) = X(t + 1) −X(t). We also represent the conditional expected value operator by E[·|·]. Using these, we claim the next theorem. Theorem 1: Consider a zero-sum game with a payoff matrix as in and a learning algorithm deﬁned by and for both players A and B, with learning rate θ. Then, E[X(t)|X(t)] = θW(x), and for every ϵ > 0, there exists a unique stationary point X∗= p∗ 1 q∗ 1 ⊺satisfying the following conditions. 1) W(X∗) = 0. 2) |X∗−Xopt| < ϵ. Proof: Let us ﬁrst compute the conditional expected value3 of the increment X(t) E[X(t)|X(t)] = E[X(t + 1) −X(t)|X(t)] =  E[p1(t + 1) −p1(t)|X(t)] E[q1(t + 1) −q1(t)|X(t)])  = θ W1(X(t)) W2(X(t))  = θW(X(t)) where the above format is possible since all possible updates share the form X(t) = θW(t), for some W(t), as given in . 3Computing the “expected value of the increment” is a standard procedure in the theory of LA. This is because the increment, in and of itself, is a random variable, which is sometimes positive and sometimes negative. Quantifying the latter is not possible due to the randomness of the updating rule. However, the conditional expected value of the increment can be determined, whence (by invoking the “Law of the Unconscious Statistician”), one can determine the expected value of the increment itself. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. 654 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023 For ease of notation, we drop the dependence on t with the implicit assumption that all occurrences of X, p1, and q1 represent X(t), p1(t), and q1(t), respectively. W1(x) is then W1(X) = p1q1d11(pmax −p1) + p1(1 −q1)d12(pmax −p1) +(1 −p1)q1d21(pmin −p1) +(1 −p1)(1 −q1)d22(pmin −p1) = p1[q1d11 + (1 −q1)d12](pmax −p1) +(1 −p1)[q1d21 + (1 −q1)d22](pmin −p1) = p1(pmax −p1)D A 1 (q1) + (1 −p1)(pmin −p1)D A 2 (q1) where D A 1 (q1) = q1d11 + (1 −q1)d12 D A 2 (q1) = q1d21 + (1 −q1)d22. By replacing pmax = 1 −pmin and rearranging the expres- sion, we get W1(X) = p1(1 −p1)D A 1 (q1) −p1 pminD A 1 (q1) +(1 −p1)pminD A 2 (q1) −p1(1 −p1)D A 2 (q1) = p1(1 −p1)  D A 1 (q1) −D A 2 (q1)  −pmin  p1 D A 1 (q1) −(1 −p1)D A 2 (q1)  . Similarly, we can get W2(X) = q1 p1(1 −d11)(pmax −q1) +q1(1 −p1)(1 −d12)(pmax −q1) +(1 −q1)p1(1 −d21)(pmin −q1) +(1 −q1)(1 −p1)(1 −d22)(pmin −q1) = q1[p1(1 −d11) + (1 −p1)(1 −d12)](pmax −q1) +(1 −q1)[p1(1 −d21) + (1 −p1)(1 −d22)](pmin −q1) = q1(pmax −q1)  1 −DB 1 (p1)  +(1 −q1)(pmin −q1) 1 −DB 2 (p1)  where DB 1 (p1) = p1d11 + (1 −p1)d21 DB 2 (p1) = p1d12 + (1 −p1)d22. By replacing pmax = 1 −pmin and rearranging the expres- sion, we get W2(X) = q1(1 −q1) 1 −DB 1 (p1) −q1 pmin 1 −DB 1 (p1) +(1 −q1)pmin 1 −DB 2 (p1) −q1(1 −q1) 1 −DB 2 (p1) = −q1(1 −q1)  DB 1 (p1) −DB 2 (p1)  +pmin  −q1 1 −DB 1 (p1) + (1 −q1) 1 −DB 2 (p1)  = −q1(1 −q1)  DB 1 (p1) −DB 2 (p1)  +pmin q1DB 1 (p1) −(1 −q1)DB 2 (p1) + (1 −2q1) . We need to address the two identiﬁed cases. Consider Case 1), where there is only a single mixed equilibrium. According to , we get D A 12(q1) = D A 1 (q1) −D A 2 (q1) = (d12 −d22) + Lq1. Given that L > 0, since d11 > d12 and d22 > d21, D A 12(q1) is an increasing function of q1 and ⎧ ⎪⎨ ⎪⎩ D A 12(q1) < 0, if q1 < qopt D A 12(q1) = 0, if q1 = qopt D A 12(q1) > 0, if q1 > qopt. For a given q1, W1(X) is quadratic in p1. Also, we have W1  0 q1  = pminD A 2 (q1) > 0 W1  1 q1  = −pminD A 1 (q1) < 0. Since W1(X) is quadratic with a negative second derivative with respect to p1 and the inequalities in are strict, it admits a single root p1 for p1 ∈[0, 1]. Moreover, we have W1(X) = 0 for some p1 such that ⎧ ⎪⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎪⎩ p1 < 1 2, if q1 < qopt p1 = 1 2, if q1 = qopt p1 > 1 2, if q1 > qopt. Using a similar argument, we can see that there exists a single solution for each p1, and as pmin →0, we conclude that W1(X) = 0 whenever p1 ∈{0, popt, 1}. Arguing in a similar manner, we see that W2(X) = 0 when X ∈ 0 0  , 0 1  , 1 0  , popt qopt  . Thus, there exists a small enough value for pmin such that X∗= [p∗, q∗]⊺satisﬁes W2(X∗) = 0, proving Case 1). In the proof of Case 1), we have utilized the fact that for small enough pmin, the learning algorithm admits a stationary point and also identiﬁed the corresponding possible values for this point. It is thus always possible to select a small enough pmin > 0 such that X∗approaches Xopt, concluding the proof for Case 1). Case 2) can be derived in a similar manner, and the details are omitted to avoid repetition. □ In the next theorem, we show that the expected value of X(t) has a negative deﬁnite gradient. Theorem 2: The matrix of partial derivatives, ((∂W(X∗))/∂x), is negative deﬁnite. Proof: We start the proof by writing the explicit format for ∂W(X) ∂X = ⎡ ⎢⎢⎣ ∂W1(X) ∂p1 ∂W1(X) ∂q1 ∂W2(X) ∂p1 ∂W2(X) ∂q1 ⎤ ⎥⎥⎦ Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION 655 and then computing each of the entries as follows: ∂W1(X) ∂p1 = (1 −2p1) D A 1 (q1) −D A 2 (q1) −pmin D A 1 (q1) + D A 2 (q1) = (1 −2p1)D A 12(q1) −pmin D A 1 (q1) + D A 2 (q1) ∂W1(X) ∂q1 = p1(1 −p1)L −pmin(p1(d11 −d12) +(1 −p1)(d22 −d21)) ∂W2(X) ∂p1 = −q1(1 −q1)L + pmin((q1(d11 −d21) −(1 −q1)(d12 −d22)) ∂W2(X) ∂q1 = −(1 −2q1) DB 1 (p1) −DB 2 (p1) +pmin DB 1 (p1) + DB 2 (p1) −2 . As seen in Theorem 1, for a small enough value for pmin, we can ignore the terms that are weighted by pmin, and we will thus have ((∂W(X∗))/∂X) ≈((∂W(Xopt))/∂X). We now subdivide the analysis in the two cases identiﬁed as above, which are equivalent to the following. 1) Case 1: No saddle point in pure strategies. 2) Case 2: There is a saddle point in pure strategies. 3) Case 1 (No Saddle Point in Pure Strategies): In this case, we have D A 1 qopt = D A 2 qopt and DB 1 popt = DB 2 popt which makes ∂W1 Xopt ∂p1 = −2pminD A 1 qopt . Similarly, we can compute ∂W1 Xopt ∂q1 = (1 −2pmin)popt 1 −popt L. The entry ((∂W2(Xopt))/∂p1) can be simpliﬁed to ∂W2 Xopt ∂p1 = −(1 −2pmin)qopt 1 −qopt L and ∂W2 Xopt ∂q1 = −2pmin 1 −DB 1 popt resulting in , as shown at the bottom of the page. The matrix given in satisﬁes det  ∂W Xopt ∂x  > 0 , trace  ∂W Xopt ∂x  < 0 which implies that the 2 × 2 matrix is negative deﬁnite. 4) Case 2 (There Is a Saddle Point in Pure Strategies): In Theorem 1, Case 2 reduces to considering qopt = 1 and popt = 1. Computing the entries of the matrix for this case yields ∂W1 Xopt ∂p1 = −(d11 −d21) −pmin(d11 + d21) and ∂W1 Xopt ∂q1 = −pmin(d11 −d12). The entry ((∂W2(Xopt))/∂p1) can be simpliﬁed to ∂W2 Xopt ∂p1 = pmin(d11 −d21) and ∂W2 Xopt ∂q1 = (d11 −d12) −pmin(2 −d11 −d12) resulting in , as shown at the bottom of the next page. The matrix in satisﬁes det  ∂W Xopt ∂X  > 0 , trace  ∂W Xopt ∂X  < 0 for a sufﬁciently small value of pmin, which again implies that the 2 × 2 matrix is negative deﬁnite. □ Theorem 3: Let V be the von Neumann value of the game given by matrix D. Let p(t) = [p1, p2] and q(t) = [q1, q2]. For a sufﬁciently small pmin approaching 0, η(t) converges to V as θ →0 where η(t) ≜Ep(t) DEqT (t) . Proof: The proof of these results requires a classic result due to Norman [7], given in the Appendix, in the interest of completeness. The convergence of E(p1(t)) E(q1(t)) to p∗ opt q∗ opt  is a consequence of this theorem. Interestingly enough, this theorem is a classical fundamental result that has been used to prove many of the convergence results in LA. It has, for example, been used by the seminal paper by Lakshmivarahan and Narendra [1] to derive similar convergence properties of the L R−ϵP, applicable for the same game settings as ours. Indeed, it is easy to verify that Assumptions – required for Norman’s result are satisﬁed. Thus, by further invoking Theorem 1 and Theorem 2, the result follows. □ We conclude this section by mentioning that like all LA algorithms, the computational complexity of our scheme is linear in the size of the action probability vector. This is because, at the most, all the action probabilities are updated at every time instant. For the beneﬁt of future researchers, we believe that it will be proﬁtable to record the hurdles we encountered in ∂W Xopt ∂X =  −2pminD A 1 qopt (1 −2pmin)popt 1 −popt L −(1 −2pmin)qopt 1 −qopt L −2pmin 1 −DB 1 popt  . Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. 656 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023 this research. The breakthrough came when we were able to devise/design LA systems that possessed no-absorbing barriers. In other words, it involved the concept of forcing the LA back into the probability space when it was close enough to the absorbing barriers. This was a phenomenon that we had not earlier seen in the literature. The consequent problem was the analysis. The underlying Markov process could not be easily analyzed using the properties of absorbing chains. Neither could it be trivially modeled as an ergodic chain converging to an equilibrium distribution. The analysis that we presented here came as a “brain wave,” and once the building blocks were established, everything naturally seemed to fall in place. These few sentences, requested by an anonymous referee, should clarify the difﬁculties encountered in this research, in order to show that the present research is pioneering and this is not a trivial extension of existing methodologies. IV. SIMULATIONS In this section, we present simulations to conﬁrm the abovementioned theoretical properties of the proposed learning algorithm. In the interest of maintaining benchmarks, we adopt the same examples as those reported in [1]. Also, by using different instances of the payoff matrix D, we are able to experimentally cover the two cases referred to in Section III. Again, we refer to those cases as Cases 1 and 2, as done in [1]. A. Convergence in Case 1 We consider an instance of the game where only one mixed Nash equilibrium exists, i.e., there is no saddle point in pure strategies. We adopt the same game matrix D as in [1] given by D =  0.6 0.2 0.35 0.9  which admits popt = 0.5789 and qopt = 0.7368. In order to eliminate the Monte Carlo error, we ran our scheme for 5 × 106 iterations and report the error in Table I for different values of pmax and θ as the difference between Xopt and the mean over time of X(t) after convergence.4 An important remark is that the error decreases as pmax approaches 1 (i.e., when pmin →0). Please observe that in this case, we have particularly chosen to not let pmax be unity. If we allow it to be precisely unity, it would mean that we would not require an artiﬁcial barrier close to unity (for example, between 0.990 and 0.999 as in Table I). In fact, for pmax = 0.999 and θ = 0.001, the method achieves an error of 2.1621 × 10−3, and further reducing θ = 0.0001 leads to an error of 1.6820 × 10−3. To better visualize the scheme, Fig. 1 shows the evolution over time of the mixed strategies for both players (given by 4The mean is taken over the last 10% of the total number of iterations. TABLE I ERROR FOR DIFFERENT VALUES OF θ AND pMAX WHEN pOPT = 0.5789 AND qOPT = 0.7368 FOR THE GAME SPECIFIED BY THE D MATRIX GIVEN BY . THE POINT THAT YOU HAVE RAISED IS PERTINENT Fig. 1. Time evolution of [p1(t), q1(t)]⊺for the same settings as in Fig. 2. X(t)) for an ensemble of 1000 runs using θ = 0.01 and pmax = 0.999. The trajectory of the ensemble allows us to perceive the mean evolution of the mixed strategies. The spiral pattern is caused by one of the players adapting to the strategy being used by the other before the former learns by overcorrecting its strategy. The procedure is continued leading to smaller corrections until the players reach the Nash equilibrium. The abovementioned behavior can also be visualized in Fig. 2 that presents the trajectory for a single experiment with pmax = 0.99 and θ = 0.00001 over 3 × 107 steps. The described oscillatory behavior is attenuated as the players play for more iterations. The reader should particularly observe that a larger value of θ will cause more steady-state error (as speciﬁed in Theorem 1), but it will also perturb this behavior as the nodes take larger updates whenever they win. On the other hand, further decreasing θ results in a smaller error of the stationary point of the method but also decreases the convergence speed. This well-established inherent tradeoff between the steady-state error and rate of convergence can be better visualized by comparing Fig. 1 with θ = 0.001 against Fig. 3 for a smaller value of θ = 10−5. ∂W Xopt ∂X = −(d11 −d21) −pmin(d11 + d21) −pmin(d11 −d12) pmin(d11 −d21) (d11 −d12) −pmin(2 −d11 −d12)  . Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION 657 Fig. 2. Trajectory of X(t) for the case of the D matrix given by with popt = 0.5789 and qopt = 0.7368 and using pmax = 0.99 and θ = 0.00001. Fig. 3. Time evolution of X(t) where popt = 0.5789 and qopt = 0.7368 using pmax = 0.99 and θ = 0.00001. Fig. 4. Trajectory of X(t) for the case of the D matrix given by and using an absorbing barrier pmax = 1 and θ = 0.00001. Furthermore, in order to clearly emphasize the necessity of using an artiﬁcial barrier, we have speciﬁcally repeated the same experiment except that we have included an absorbing barrier instead, i.e., set pmax = 1. The result is shown in Fig. 4. In this case, we expect that the scheme enters an absorbing barrier. Since it is impossible for the human eye to detect whether or not we entered an absorbing barrier by merely examining the graph, we also manually checked the log of TABLE II ERROR FOR DIFFERENT VALUES OF θ AND pMAX FOR D1 TABLE III ERROR FOR DIFFERENT VALUES OF θ AND pMAX FOR D2 the experiment and veriﬁed that the probabilities became exactly unity after around 6798000 iterations. Although the theoretical convergence should have occurred in the limit and not after a ﬁnite number of iterations, the machine limited accuracy rounded the probabilities to unity after this juncture. B. Pure Equilibrium In order to assess the performance of the proposed learning algorithm on cases with a pure equilibrium, we consider two instances of games falling in the category of Case 2 with popt = 1 and qopt = 1. The payoff matrices D1 and D2 for the two games are given by D1 =  0.6 0.8 0.35 0.9  D2 = 0.7 0.9 0.6 0.8  . We ﬁrst show the convergence errors of our method for both games D1 and D2 in Tables II and III, respectively. As in the previous simulation for Case 1, the errors are on the order to 10−3 for larger values of pmax. However, given that our algorithm uses artiﬁcial barriers to prevent absorbing states, the error is lower bounded by pmin. A similar issue is present in game D2. We have also included this simulation since it is a more challenging game to learn with our method for a larger steady-state error, even for very small values of θ. In Fig. 5, we depict the time evolution of the two compo- nents of the vector X(t) using the proposed algorithm for an ensemble of 1000 runs. In the case of having a pure Nash equilibrium, there is no oscillatory behavior as when a player assigns more probability to an action since the other player Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. 658 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023 Fig. 5. (a) Evolution over time of X(t) for θ = 0.01 and Pmax = 0.999 when applied to game with payoffs D1. (b) Zoomed version around the steady-state value. Fig. 6. (a) Evolution over time of X(t) for θ = 0.01 and Pmax = 0.999 when applied to game with payoffs D2. (b) Zoomed version around the steady-state value. reinforces the strategy. However, Fig. 5(a) could lead make one believe that the LA method has converged to a pure strategy. Fig. 5(b) zooms around the point where the strategies have converged to showcase that their maximum value is limited by pmax, as per the design of our updating rule. This mechanism is particularly favorable to prevent players from converging to absorbing states for games with time-varying payoff matrices. However, the study of such a scenario is left for future research, namely that of determining how to design pmax and θ that represent a good tradeoff between learning the game and adapting to a change in the payoffs. Game D2 presents a harder challenge for our method as we can see from its larger steady-state error. Fig. 6 shows the time evolution of the probabilities for each player when the algorithm is applied to D2 with θ = 0.01, Pmax = 0.999 and for an ensemble with 1000 runs. The main remark regarding the results presented in Fig. 6(a) is that the convergence is much slower when compared to game D1. This behavior is governed by the fact that the entries in matrix D2 are closer to each other, unlike in D1 where there is a clear disadvantage for player A when selecting action 2. There will, thus, be much fewer updates for player A where it increases the probability of action 2 in game D1—which is not pertinent in game D2. Fig. 6(b) further emphasizes this remark by displaying a zoom, depicting a sharper change in the probabilities in comparison with the smooth behavior in game D1. C. Comparisons With Related Works Now that we have explained our new techniques and estab- lished its theoretical basis, we continue this discussion with a brief comparison with some of the prior art.5 First of all, one possible alternative when the payoff matrix is known can be to consider the problem as that of designing a local controller for each of the agents. One alternative is to explore the results in [28] and further investigated in [29]. However, this is only possible when D is known, which is not the scenario that we have assumed in this article. It is not out of place to review some of the relevant works in game theory that are not necessarily solved using LA. However, in the interest of space and brevity, we will not aim at submitting an extensive review of the ﬁeld of game theory. Rather, we shall cite some pertinent works inasmuch as our main contribution in this article centers on advancing the ﬁeld of LA-based solutions and, more speciﬁcally, those dealing with the special case of games with “incomplete information.” There are different variants of zero-sum stochastic games in the literature. Flesch et al. [30] have proven the general result that every positive zero-sum stochastic game with countable state and action spaces admits a value if at least one player has a ﬁnite action space. A similar value-existence result was obtained for a zero-sum stochastic game [31] with a continuous-time Markov chain, where the players have also the possibility of stopping the game. Ziliotto [32] considered weighted-average stochastic games, that is, stochastic games where Player 1 maximizes (in expectation) a ﬁxed weighted average of the sequence of rewards. A so-called pumping algorithm was proposed in [33] for two-person zero-sum undiscounted stochastic games. Other approaches map the game onto a dynamic programming problem and solve it based on Bellman’s optimal principle using concepts from the theory of optimal control [34]. The research on game theoretical learning with incomplete information [13] is scarce in the literature. Incomplete infor- mation is a taxonomy used within the ﬁeld of LA games to denote the case where the players do not observe the action of the opponent players and where each player does not know his own payoff function but only observes outcomes in the form of a reward or a penalty. The informed reader would observe that the games we deal with in this article fall under this class of games characterized by such incomplete information. The case of incomplete information is not usually treated by the mainstream of literature in game theory. Indeed, 5We are thankful to the anonymous referee who requested this comprehen- sive section. It signiﬁcantly adds to the quality of this article. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION 659 the main game learning algorithms available in the literature, such as ﬁctitious play [35], best response dynamics, and gradient-based learning approaches, deal with the complete knowledge case, where the players know their own payoff function and observe the history of the choices of other players. Fictitious play is one of the few algorithms that can converge to a mixed strategy equilibrium by maintaining var- ious frequency-based beliefs over the action of the opponent players, and using those beliefs, for deciding the next action to be played. However, the ﬁctitious play algorithm cannot solve our settings of incomplete information. When it comes to games with incomplete information, different algorithms have been suggested, which are based on the Bush–Mosteller learning paradigm. Notable examples include the ones reported in [36]–[39]. All those algorithms share a similar structure to our proposed LA, in particular, and to VSLA in general, in the sense, that the action probabilities are updated iteratively based on feedback and using some learning parameter. In this context, one should note that many LA models can be seen as extensions of Bush–Mosteller learning. However, the difference with our work is the fact that all the aforementioned algorithms have absorbing barriers. The theoretical analyses of the convergence to pure equilibria for this family of algorithms rely usually on the theory replicator dynamics. Another family of methods that can operate with limited information includes the Erev–Roth algorithm [40] and the Arthur algorithm [41], which in turn can be seen as a variant of the Erev–Roth algorithm. The Erev–Roth algo- rithm is alternatively called the Erev–Roth payoff matching algorithm and relies on updating the so-called “propensity” for each action, which is, loosely speaking, the cumulative payoff for that action. Thereafter, each action is played in a manner proportional to its corresponding relative propensity. The Erev–Roth algorithm is one of the few examples of limited-information game learning approaches that converge to unique mixed strategy equilibria. However, the Erev–Roth algorithm requires storing the entire history of rewards and penalties for each action. Furthermore, we have not been able to locate any research study that reports the analysis of the Erev–Roth algorithm for the case of our stochastic zero-sum game. We therefore opted to implement it for our game. Experimental results (not reported here, in the interest of not distracting from the main contribution of this article) show that it neither converges to the desired equilibrium nor does it possess consistent convergence results. D. Real-Life Application Scenarios One referee had requested a brief explanation of a complex environment, or different scenarios in a game, by which we could utilize our newly proposed solution. We agree that providing an insightful discussion could be insightful for interested readers and active researchers. This, of course, can be open-ended, but to satisfy the referee, we present the following brief example. Our learning algorithm admits potential applications in many security games as well as in communication problems. The intersection between game theory and security is an emerging ﬁeld of research. Algorithms that can converge to mixed equilibria are of great interest to the security community because mixed equilibria are usually preferred over pure ones. In fact, randomization gives less predictive ability to the attacker to guess the deployed strategy of the defender [42]. For instance, let us take a repetitive game involving a jammer and a transmitter, which, in turn, constitute our players [43]. The jammer aims to disturb and block communication between a transmitter and its associated receiver. The transmitter can choose the channel over which his message is communicated, while the jammer chooses a channel to attack. We suppose that the outcome is stochastic depending on the choice of the attacker (jammer) and defender (transmitter) and the stochastic characteristics of the channel. Both the jammer and transmitter can observe whether the attack was successful or not, and for instance, this common observation can be due to the receiver acknowledging the correct reception of the message over a wireless channel that both the attacker and jammer can overhear. Thus, the game is stochastic zero-sum. V. CONCLUSION The theoretical applications LA with artiﬁcially absorbing barriers have been reported since the 1980s [8] and, more recently, in Estimator LA [18]–[20]. This article pioneers the study of LA with artiﬁcial nonabsorbing barriers. LA have been previously used [13] to design algorithms capable of converging to the game’s Nash equilibrium under limited information. The majority of the LA algorithms used for games are absorbing in the probability simplex space, and they converge to an exclusive choice of a single action. These LA are, thus, unable to converge to other mixed Nash equilibria when the game possesses no saddle point for a pure strategy. As opposed to these, we propose an LA solution that is able to converge to an optimal mixed Nash equilibrium even though there may be no saddle point when a pure strategy is invoked. The scheme is inherently of the absorbing L R−I paradigm. However, by introducing reﬂecting barriers, we prevent it from being “stuck” or getting absorbed in pure strategies. Unlike the linear reward-ϵpenalty (L R−ϵP) scheme proposed in [1], our new scheme achieves the same goal with much less parameter tuning and in a more elegant manner. As far as know, our method is only the second reported algorithm in the literature capable of ﬁnding mixed strategies whenever no saddle point exists for pure strategies. If a saddle point exists for pure strategies, the scheme converges to a near-optimal solution close to the pure strategies in the probability simplex. This article includes the nontrial proofs of the theoretical results characterizing the convergence and stability of the algorithm. These are presented and illustrated through simulations for benchmark games presented in the literature. With regard to future work, we believe that it will be useful in real-life applications that can be modeled using such game-like behavior. APPENDIX NORMAN THEOREM Theorem 4: Let X(t) be a stationary Markov process dependent on a constant parameter θ ∈[0, 1]. Each X(t) ∈I, Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. 660 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 34, NO. 2, FEBRUARY 2023 where I is a subset of the real line. Let X(t) = X(t + 1) − X(t). The following are assumed to hold. 1) I is compact. 2) E[X(t)|X(t) = y] = θw(y) + O θ2 . 3) V ar[X(t)|X(t) = y] = θ2 s(y) + o θ2 . 4) EX(t)3|X(t) = y = O θ3 . where supy∈I O θk / θk < ∞for K = 2, 3 and supy∈I o θ2 /θ2 →0 as θ →0. 5) w(y) has a Lipschitz derivative in I. 6) s(y) is Lipschitz I. If Assumptions – hold, w(y) has a unique root y∗in I and (dw/dy)  y=y∗≤0; then, the following conditions hold. 1) var[X(t)|X = x] = 0(θ) uniformly for all x ∈I and t ≥0. For any x ∈I, the differential equation (dy(τ)/dτ) = w(y(t)) has a unique solution y(τ) = y(τ, x) with y = x and E[δX(t)|X = x] = y(tθ) + O(θ) uniformly for all x ∈I and t ≥0. 2) (X(t) −y(tθ))/ √ θ has a normal distribution with zero mean and ﬁnite variance as θ →0 and tθ →∞. ACKNOWLEDGMENT The authors are very grateful for the feedback from the anonymous Referees of the original submission. Their input signiﬁcantly improved the quality of this ﬁnal version. REFERENCES [1] S. Lakshmivarahan and K. S. Narendra, “Learning algorithms for two- person zero-sum stochastic games with incomplete information: A uniﬁed approach,” SIAM J. Control Optim., vol. 20, no. 4, pp. 541–552, 1982. [2] S. Lakshmivarahan, Learning Algorithms Theory and Applications: Theory and Applications. New York, NY, USA: Springer, 2012. [3] J. K. Lanctot and B. J. Oommen, “On discretizing estimator-based learning algorithms,” IEEE Trans. Syst., Man, Cybern., B, Cybern., vol. 2, pp. 1417–1422, 1991. [4] J. K. Lanctot and B. J. Oommen, “Discretized estimator learn- ing automata,” IEEE Trans. Syst., Man, Cybern., vol. 22, no. 6, pp. 1473–1483, Nov./Dec. 1992. [5] K. Najim and A. S. Poznyak, Learning Automata: Theory and Applica- tions. Amsterdam, The Netherlands: Elsevier, 2014. [6] K. S. Narendra and M. A. Thathachar, Learning Automata: An Intro- duction. North Chelmsford, MA, USA: Courier Corporation, 2012. [7] M. F. Norman, Markov Processes and Learning Models, vol. 84. New York, NY, USA: Academic, 1972. [8] B. Johnoommen, “Absorbing and ergodic discretized two-action learning automata,” IEEE Trans. Syst., Man, Cybern., vol. 16, no. 2, pp. 282–293, Mar. 1986. [9] B. J. Oommen and J. K. Lanctot, “Discretized pursuit learning automata,” IEEE Trans. Syst., Man, Cybern., vol. 20, no. 4, pp. 931–938, Jul./Aug. 1990. [10] B. J. Oommen and M. Agache, “Continuous and discretized pursuit learning schemes: Various algorithms and their comparison,” IEEE Trans. Syst., Man, Cybern., B (Cybern.), vol. 31, no. 3, pp. 277–287, Jun. 2001. [11] G. P. Papavassilopoulos, “Learning algorithms for repeated bimatrix Nash games with incomplete information,” J. Optim. Theory Appl., vol. 62, no. 3, pp. 467–488, 1989. [12] A. Rezvanian, A. M. Saghiri, S. M. Vahidipour, M. Esnaashari, and M. R. Meybodi, Recent Advances in Learning Automata, vol. 754. New York, NY, USA: Springer, 2018. [13] P. S. Sastry, V. V. Phansalkar, and M. A. L. Thathachar, “Decentralized learning of Nash equilibria in multi-person stochastic games with incomplete information,” IEEE Trans. Syst., Man Cybern., vol. 24, no. 5, pp. 769–777, May 1994. [14] M. A. L. Thathachar and P. S. Sastry, Networks of Learning Automata: Techniques for Online Stochastic Optimization. Boston, MA, USA: Kluwer, 2003. [15] M. L. Tsetlin et al., Automaton Theory and Modeling of Biological Systems. New York, NY, USA: Academic, 1973. [16] B. Tung and L. Kleinrock, “Using ﬁnite state automata to produce self- optimization and self-control,” IEEE Trans. Parallel Distrib. Syst., vol. 7, no. 4, pp. 439–448, Apr. 1996. [17] Y. Xing and R. Chandramouli, “Stochastic learning solution for distrib- uted discrete power control game in wireless data networks,” IEEE/ACM Trans. Netw., vol. 16, no. 4, pp. 932–944, Aug. 2008. [18] X. Zhang, O. C. Granmo, B. J. Oommen, and L. Jiao, “A formal proof of the ε-optimality of absorbing continuous pursuit algorithms using the theory of regular functions,” Appl. Intell., vol. 41, pp. 974–985, May 2014. [19] X. Zhang, B. J. Oommen, O. C. Granmo, and L. Jiao, “A formal proof of the ε-optimality of discretized pursuit algorithms,” Appl. Intell., vol. 44, pp. 282–294, 2016, doi: 10.1007/s10489-015-0670-1. [20] X. Zhang, B. J. Oommen, and O. C. Granmo, “The design of absorb- ing Bayesian pursuit algorithms and the formal analyses of their ε- optimality,” Pattern Anal. Appl., vol. 20, no. 3, pp. 797–808, 2015. [21] J. R. Marden, G. Arslan, and J. S. Shamma, “Cooperative control and potential games,” IEEE Trans. Syst., Man, Cybern. B. Cybern., vol. 39, no. 6, pp. 1393–1407, Dec. 2009, doi: 10.1109/TSMCB.2009.2017273. [22] D. Silvestre, J. P. Hespanha, and C. Silvestre, “Resilient desyn- chronization for decentralized medium access control,” IEEE Con- trol Syst. Lett., vol. 5, no. 3, pp. 803–808, Jul. 2021, doi: 10.1109/LCSYS.2020.3005819. [23] D. Silvestre, J. Hespanha, and C. Silvestre, “Desynchronization for decentralized medium access control based on gauss-seidel iterations,” in Proc. Amer. Control Conf. (ACC), Jul. 2019, pp. 4049–4054, doi: 10.23919/ACC.2019.8814471. [24] D. Silvestre, J. P. Hespanha, and C. Silvestre, “Broadcast and gossip stochastic average consensus algorithms in directed topologies,” IEEE Trans. Control Netw. Syst., vol. 6, no. 2, pp. 474–486, Jun. 2019, doi: 10.1109/TCNS.2018.2839341. [25] D. Silvestre, J. Hespanha, and C. Silvestre, “A PageRank algorithm based on asynchronous gauss-seidel iterations,” in Proc. Annu. Amer. Control Conf. (ACC), Milwaukee, WI, USA, Jun. 2018, pp. 484–489, doi: 10.23919/ACC.2018.8431212. [26] R. Ribeiro, D. Silvestre, and C. Silvestre, “A rendezvous algorithm for multi-agent systems in disconnected network topologies,” in Proc. 28th Medit. Conf. Control Autom. (MED), Sep. 2020, pp. 592–597, doi: 10.1109/MED48518.2020.9183093. [27] R. Ribeiro, D. Silvestre, and C. Silvestre, “Decentralized control for multi-agent missions based on ﬂocking rules,” CONTROLO ( Lec- ture Notes in Electrical Engineering), vol. 695, J. A. Gonçalves, M. Braz-César, and J. P. Coelho, Eds. Cham, Switzerland: Springer, 2021, pp. 445–454, doi: 10.1007/978-3-030-58653-9_43. [28] Y. Wu and R. Lu, “Output synchronization and L2-gain analysis for network systems,” IEEE Trans. Syst., Man, Cybern., Syst., vol. 48, no. 12, pp. 2105–2114, Dec. 2018, doi: 10.1109/TSMC.2017.2754544. [29] Y. Wu, A. Isidori, R. Lu, and H. K. Khalil, “Performance recovery of dynamic feedback-linearization methods for multivariable nonlinear systems,” IEEE Trans. Autom. Control, vol. 65, no. 4, pp. 1365–1380, Apr. 2020, doi: 10.1109/TAC.2019.2924176. [30] J. Flesch, A. Predtetchinski, and W. Sudderth, “Positive zero-sum stochastic games with countable state and action spaces,” Appl. Math. Optim., vol. 82, pp. 499–516, Nov. 2018. [31] C. Pal and S. Saha, “Continuous-time zero-sum stochastic game with stopping and control,” Operations Res. Lett., vol. 48, no. 6, pp. 715–719, Nov. 2020. [32] B. Ziliotto, “A tauberian theorem for nonexpansive operators and appli- cations to zero-sum stochastic games,” Math. Operations Res., vol. 41, no. 4, pp. 1522–1534, Nov. 2016. [33] E. Boros, K. Elbassioni, V. Gurvich, and K. Makino, “A potential reduction algorithm for two-person zero-sum mean payoff stochastic games,” Dyn. Games Appl., vol. 8, no. 1, pp. 22–41, Mar. 2018. [34] K. Du, R. Song, Q. Wei, and B. Zhao, “A solution of two-person zero sum differential games with incomplete state information,” in Advances in Neural Networks—ISNN 2019 (Lecture Notes in Computer Science), vol. 11554, H. Lu, H. Tang, and Z. Wang, Eds. Cham, Switzerland: Springer, 2019, doi: 10.1007/978-3-030-22796-8_46. [35] J. Hofbauer and W. H. Sandholm, “On the global convergence of stochastic ﬁctitious play,” Econometrica, vol. 70, no. 6, pp. 2265–2294, Nov. 2002. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: SOLVING TWO-PERSON ZERO-SUM STOCHASTIC GAMES WITH INCOMPLETE INFORMATION 661 [36] T. Börgers and R. Sarin, “Learning through reinforcement and replicator dynamics,” J. Econ. Theory, vol. 77, no. 1, pp. 1–14, Nov. 1997. [37] L. R. Izquierdo, S. S. Izquierdo, N. M. Gotts, and J. G. Polhill, “Tran- sient and asymptotic dynamics of reinforcement learning in games,” Games Econ. Behav., vol. 61, no. 2, pp. 259–276, Nov. 2007. [38] A. S. Poznyak and K. Najim, “Bush-Mosteller learning for a zero-sum repeated game with random pay-offs,” Int. J. Syst. Sci., vol. 32, no. 10, pp. 1251–1260, 2001. [39] Q. Zhu, H. Tembine, and T. Basar, “Heterogeneous learning in zero- sum stochastic games with incomplete information,” in Proc. 49th IEEE Conf. Decis. Control (CDC), Dec. 2010, pp. 219–224. [40] I. Erev and A. E. Roth, “Multi-agent learning and the descriptive value of simple models,” Artif. Intell., vol. 171, no. 7, pp. 423–428, May 2007. [41] W. B. Arthur, “On designing economic agents that behave like human agents,” J. Evol. Econ., vol. 3, no. 1, pp. 1–22, Mar. 1993. [42] M. H. Manshaei, Q. Zhu, T. Alpcan, T. Bac¸sar, and J.-P. Hubaux, “Game theory meets network security and privacy,” ACM Comput. Surv., vol. 45, no. 3, pp. 1–39, Jun. 2013. [43] V. Vadori, M. Scalabrin, A. V. Guglielmi, and L. Badia, “Jamming in underwater sensor networks as a Bayesian zero-sum game with position uncertainty,” in Proc. IEEE Global Commun. Conf. (GLOBECOM), Dec. 2014, pp. 1–6. Anis Yazidi (Senior Member, IEEE) received the M.Sc. and Ph.D. degrees from the University of Agder, Grimstad, Norway, in 2008 and 2012, respectively. He was a Researcher with Teknova AS, Grimstad. From 2014 to 2019, he was an Associate Pro- fessor with the Department of Computer Science, Oslo Metropolitan University, Oslo, Norway. He is currently a Full Professor with the Department of Computer Science, where he is leading the research group in applied artiﬁcial intelligence. He is also a Professor II with the Norwegian University of Science and Technol- ogy (NTNU), Trondheim, Norway. His current research interests include machine learning, learning automata, stochastic optimization, and autonomous computing. Daniel Silvestre received the B.Sc. degree in computer networks from the Instituto Superior Técnico (IST), Lisbon, Portugal, in 2008, and the M.Sc. degree in advanced computing and the Ph.D. degree (Hons.) in electrical and computer engineer- ing from Imperial College London, London, U.K., in 2009 and 2017, respectively. He was a Visiting Scholar at the University of California at Santa Barbara, Santa Barbara, CA, USA. He is currently with the Institute for Systems and Robotics, IST. He holds a research assistant appointment with the University of Macau, Macau. His research interests span the ﬁelds of fault detection and isolation, distributed systems, network control systems, computer networks, set-valued estimation and control methods, and randomized algorithms. B. John Oommen (Life Fellow, IEEE) was born in India, in 1953. He received the Bachelor of Technology degree in electrical engineering from IIT Madras, Chennai, India, in 1975, the Master of Engineering degree from the Indian Institute of Science, Bengaluru, India, in 1977, and the Master of Science degree and the Ph.D. degree in electrical engineering from Purdue University, West Lafayette, IN, USA, in 1979 and 1982, respectively. He has been teaching at the School of Computer Science, Carleton University, Ottawa, ON, Canada, since 1981. He was elevated to be a Chancellor’s Professor at Carleton University in 2006. He has published more than 485 refereed publications, many of which have been award-winning. Dr. Oommen was nominated as a fellow of the Institute of Electrical and Electronic Engineers (IEEE) for research in a subﬁeld of artiﬁcial intelligence, namely in learning automata in 2003. He was also nominated as a fellow of the International Association of Pattern Recognition (IAPR) in August 2006 for contributions to fundamental and applied problems in syntactic and statis- tical pattern recognition. He received the Carleton University’s Research Achievement Award four times, in 1995, 2001, 2007, and 2015. At IIT Madras and the Indian Institute of Science, he received the medal for being the Best Graduating Student. He has served on the Editorial Board of the IEEE TRANSACTIONS ON SYSTEMS, MAN AND CYBERNETICS and Pattern Recognition. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:16:30 UTC from IEEE Xplore. Restrictions apply.","—Learning automata (LA) with artiﬁcially absorbing barriers was a completely new horizon of research in the 1980s (Oommen, 1986). These new machines yielded properties that were previously unknown. More recently, absorbing barriers have been introduced in continuous estimator algorithms so that the proofs could follow a martingale property, as opposed to monotonicity (Zhang et al., 2014), (Zhang et al., 2015). However, the applications of LA with artiﬁcial barriers are almost nonexistent. In that regard, this article is pioneering in that it provides effective and accurate solutions to an extremely complex application domain, namely that of solving two-person zero-sum stochastic games that are provided with incomplete information. LA have been previously used (Sastry et al., 1994) to design algorithms capable of converging to the game’s Nash equilibrium under limited information. Those algorithms have focused on the case where the saddle point of the game exists in a pure strategy. However, the majority of the LA algorithms used for games are absorbing in the probability simplex space, and thus, they converge to an exclusive choice of a single action. These LA are thus unable to converge to other mixed Nash equilibria when the game possesses no saddle point for a pure strategy. The pioneering contribution of this article is that we propose an LA solution that is able to converge to an optimal mixed Nash equilibrium even though there may be no saddle point when a pure strategy is invoked. The scheme, being of the linear reward-inaction (L R−I) paradigm, is in and of itself, absorbing. However, by incorporating artiﬁcial barriers, we prevent it from being “stuck” or getting absorbed in pure strategies. Unlike the linear reward-ϵpenalty (L R−ϵ P) scheme proposed by Lakshmivarahan and Narendra almost four decades ago, our new scheme achieves the same goal with much less parameter tuning and in a more elegant manner. This article includes Manuscript received 2 October 2020; revised 16 February 2021; accepted 18 May 2021. Date of publication 4 August 2021; date of current ver- sion 6 February 2023. The work of Daniel Silvestre was supported in part by the Portuguese Fundação para a Ciência e a Tecnologia (FCT) through the Institute for Systems and Robotics (ISR), Laboratory for Robot- ics and Engineering Systems (LARSyS), under Project UIDB/50009/2020, through FirePuma Project under Grant PCIF/MPG/0156/2019, and through COPELABS, University Lusófona, under Project UIDB/04111/2020. The work of B. John Oommen was supported in part by the Natural Sciences and Engineering Research Council of Canada (NSERC) and in part by the Natural Sciences and Engineering Council of Canada. (Corresponding author: B. John Oommen.) Anis Yazidi is with the Department of Computer Science, Oslo Metropolitan University, 0190 Oslo, Norway (e-mail: anis.yazidi@oslomet.no). Daniel Silvestre is with Dynamical Systems and Ocean Robotics Laboratory (DSOR), Department of Electrical and Computer Engineering, Lusófona Uni- versity, 1749-024 Lisbon, Portugal, and also with the Institute for Systems and Robotics, Instituto Superior Técnico, University of Lisbon, 1049-001 Lisbon, Portugal (e-mail: dsilvestre@isr.tecnico.ulisboa.pt). B. John Oommen is with the School of Computer Science, Carleton Univer- sity, Ottawa, ON K1S 5B6, Canada, and also with the Department of IKT, Uni- versity of Agder, 4879 Grimstad, Norway (e-mail: oommen@scs.carleton.ca). Color versions of one or more ﬁgures in this article are available at Digital Object Identiﬁer 10.1109/TNNLS.2021.3099095 the nontrial proofs of the theoretical results characterizing our scheme and also contains experimental veriﬁcation that conﬁrms our theoretical ﬁndings. Index Terms—Games with incomplete information, learning automata (LA), LA with artiﬁcial barriers. I.","['Anis Yazidi', 'Daniel Silvestre', 'B. John Oommen']"
Artificial intelligence in dry eye disease,Andrea M. Storås and Inga Strümke and Michael A. Riegler and Jakob Grauslund and Hugo L. Hammer and Anis Yazidi and Pål Halvorsen and Kjell G. Gundersen and Tor P. Utheim and Catherine J. Jackson,2022,missing,23,The Ocular Surface,article,"The Ocular Surface 23 (2022) 74–86
Available online 27 November 2021
1542-0124/© 2021 Elsevier Inc. All rights reserved.
Review Article 
Artificial intelligence in dry eye disease 
Andrea M. Storås a,e,*, Inga Strümke a, Michael A. Riegler a, Jakob Grauslund b,c,d, 
Hugo L. Hammer a,e, Anis Yazidi e, Pål Halvorsen a,e, Kjell G. Gundersen h, Tor P. Utheim e,f,g, 
Catherine J. Jackson h 
a SimulaMet, Oslo, Norway 
b Department of Ophthalmology, Odense University Hospital, Odense, Denmark 
c Department of Clinical Research, University of Southern Denmark, Odense, Denmark 
d Department of Ophthalmology, Vestfold University Trust, Tønsberg, Norway 
e Department of Computer Science, Oslo Metropolitan University, Norway 
f Department of Medical Biochemistry, Oslo University Hospital, Norway 
g Department of Ophthalmology, Oslo University Hospital, Norway 
h Ifocus, Haugesund, Norway   
A R T I C L E  I N F O   
Keywords: 
Dry eye disease 
Artificial intelligence 
Machine learning 
A B S T R A C T   
Dry eye disease (DED) has a prevalence of between 5 and 50%, depending on the diagnostic criteria used and 
population under study. However, it remains one of the most underdiagnosed and undertreated conditions in 
ophthalmology. Many tests used in the diagnosis of DED rely on an experienced observer for image interpre­
tation, which may be considered subjective and result in variation in diagnosis. Since artificial intelligence (AI) 
systems are capable of advanced problem solving, use of such techniques could lead to more objective diagnosis. 
Although the term ‘AI’ is commonly used, recent success in its applications to medicine is mainly due to ad­
vancements in the sub-field of machine learning, which has been used to automatically classify images and 
predict medical outcomes. Powerful machine learning techniques have been harnessed to understand nuances in 
patient data and medical images, aiming for consistent diagnosis and stratification of disease severity. This is the 
first literature review on the use of AI in DED. We provide a brief introduction to AI, report its current use in DED 
research and its potential for application in the clinic. Our review found that AI has been employed in a wide 
range of DED clinical tests and research applications, primarily for interpretation of interferometry, slit-lamp and 
meibography images. While initial results are promising, much work is still needed on model development, 
clinical testing and standardisation.   
1. Introduction 
Dry eye disease (DED) is one of the most common eye diseases 
worldwide, with a prevalence of between 5 and 50%, depending on the 
diagnostic criteria used and study population [1]. Yet, although symp­
toms stemming from DED are reported as the most common reason to 
seek medical eye care [1], it is considered one of the most under­
diagnosed and undertreated conditions in ophthalmology [2]. Symp­
toms of DED include eye irritation, photophobia and fluctuating vision. 
The condition can be painful and might result in lasting damage to the 
cornea through irritation of the ocular surface. Epidemiological studies 
indicate that DED is most prevalent in women [3] and increases with age 
[1]. However, the incidence of DED is likely to increase in all age groups 
in coming years due to longer screen time and more prevalent use of 
contact lenses, which are both risk factors [4]. Other risk factors include 
diabetes mellitus [5] and exposure to air-pollution [6]. DED can have a 
substantial effect on the quality of life, and may impose significant direct 
and indirect public health costs as well as personal economic burden due 
to reduced work productivity. 
DED is divided into two subtypes defined by the underlying mech­
anism of the disease: (i) aqueous deficient DED, where tear production 
from the lacrimal gland is insufficient and (ii) evaporative DED (the 
most common form), which is typically caused by dysfunctional mei­
bomian glands in the eyelids. Meibomian glands are responsible for 
supplying meibum, which is a concentrated substance that normally 
covers the surface of the cornea to form a protective superficial lipid 
* Corresponding author. SimulaMet, Oslo, Norway. 
E-mail address: andrea@simula.no (A.M. Storås).  
Contents lists available at ScienceDirect 
The Ocular Surface 
journal homepage: www.elsevier.com/locate/jtos 
https://doi.org/10.1016/j.jtos.2021.11.004 
Received 9 July 2021; Received in revised form 8 November 2021; Accepted 9 November 2021   
 The Ocular Surface 23 (2022) 74–86
75
layer that guards against evaporation of the underlying tear film. The 
ability to reliably distinguish between aqueous deficient and evapora­
tive DED, their respective severity levels and mixed aqueous/evapora­
tive forms is important in deciding the ideal modality of treatment. A 
fast and accurate diagnosis relieves patient discomfort and also spares 
them unnecessary expense and exposure to potential side effects asso­
ciated with some treatments. A tailor made treatment plan can yield 
improved treatment response and maximize health provider efficiency. 
The main clinical signs of DED are decreased tear volume, more rapid 
break-up of the tear film (fluorescein tear break-up time (TBUT)) and 
microwounds of the ocular surface [7]. In the healthy eye, the tear film 
naturally ‘breaks up’ after 10 s and the protective tear film is reformed 
with blinking. Available diagnostic tests often do not correlate with the 
severity of clinical symptoms reported by the patient. No single clinical 
test is considered definitive in the diagnosis of DED [1]. Therefore, 
multiple tests are typically used in combination and supplemented by 
information gathered on patient symptoms, recorded through ques­
tionnaires. These tests demand a significant amount of time and re­
sources at the clinic. Tests for determining the physical parameters of 
tears include TBUT, the Schirmer’s test, tear osmolarity and tear 
meniscus height. Other useful tests in DED diagnosis include ocular 
surface staining, corneal sensibility, interblink frequency, corneal sur­
face topography, interferometry, aberrometry and imaging techniques 
such as meibography and in vivo confocal microscopy (IVCM), as well as 
visual function tests. 
Artificial intelligence (AI) was defined in 1955 as “the science and 
engineering of making intelligent ma-chines” [8], where intelligence is 
the “ability to achieve goals in a wide range of environments” [9]. 
Within AI, machine learning denotes a class of algorithms capable of 
learning from data rather than being programmed with explicit rules. AI, 
and particularly machine learning, is increasingly becoming an integral 
part of health care systems. The sub-field of machine learning known as 
deep learning uses deep artificial neural networks, and has gained 
increased attention in recent years, especially for its image and text 
recognition abilities. In the field of ophthalmology, deep learning has so 
far mainly been used in the analysis of data from the retina to segment 
regions of interest in images, automate diagnosis and predict disease 
outcomes [10]. For instance, the combination of deep learning and op­
tical coherence tomography (OCT) technologies has allowed reliable 
detection of retinal diseases and improved diagnosis [11]. Machine 
learning also has potential for use in the diagnosis and treatment of 
anterior segment diseases, such as DED and has already found its way 
into the field with methods such as presented by Ciezar et al. [12]. Many 
of the tests used for DED diagnosis and follow-up rely on the experience 
of the observer for interpretation of images, which may be considered 
subjective [13]. AI tools can be used to interpret images automatically 
and objectively, saving time and providing consistency in diagnosis. 
Several reviews have been published that discuss the application of 
AI in eye disease, including screening for diabetic retinopathy [14], 
detection of age-related macular degeneration [15] and diagnosis of 
retinopathy of prematurity [16]. We are, however, not aware of any 
review on AI in DED. In this article, we therefore provide a critical re­
view of the use of AI systems developed within the field of DED, discuss 
their current use and highlight future work. 
2. Artificial intelligence 
AI is informational technology capable of performing activities that 
require intelligence. It has gained substantial popularity within the field 
of medicine due to its ability to solve ubiquitous medical problems, such 
as classification of skin cancer [17], prediction of hypoxemia during 
surgeries [18], identification of diabetic retinopathy [19] and prediction 
of risk for future need of keratoplasty [20]. Machine learning is a 
sub-field of AI encompassing algorithms capable of learning from data, 
without being explicitly programmed. All AI systems used in the studies 
included in this review, fall within the class of machine learning. The 
process by which a machine learning algorithm learns from data is 
referred to as training. The outcome of the training process is a machine 
learning model, and the model’s output is referred to as predictions. 
Different learning algorithms are categorised according to the type of 
data they use, and referred to as supervised, unsupervised and rein­
forcement learning. The latter is excluded from this review, as none of 
the studies use it, while the two former are introduced in this section. A 
complete overview of the algorithms encountered in the reviewed 
studies is provided in Fig. 1, sorted according to the categories described 
below. 
2.1. Supervised learning 
Supervised learning denotes the learning process of an algorithm 
using labelled data, meaning data that contains the target value for each 
data instance, e.g., tear film lipid layer category. The learning process 
involves extracting patterns linking the input variables and the target 
outcome. The performance of the resulting model is evaluated by letting 
it predict on a previously unseen data set, and comparing the predictions 
to the true data labels. See Section 2.5 for a brief discussion of evaluation 
metrics. Supervised learning algorithms can perform regression and 
classification, where regression involves predicting a numerical value 
for a data instance, and classification involves assigning data instances 
to predefined categories. Fig. 1 contains an overview of supervised 
learning algorithms encountered in the reviewed studies. 
2.2. Unsupervised learning 
Unsupervised learning denotes the training process of an algorithm 
using unlabelled data, i.e., data not containing target values. The task of 
the learning algorithm is to find patterns or data groupings by con­
structing a compact representation of the data. This type of machine 
learning is commonly used for grouping observations together, detecting 
relationships between input variables, and for dimensionality reduction. 
As unsupervised learning data contains no labels, a measure of model 
performance depends on considerations outside the data [see 21, chap. 
14], e.g., how the task would have been solved by someone in the real 
world. For clustering algorithms, similarity or dissimilarity measures 
such as the distance between cluster points can be used to measure 
performance, but whether this is relevant depends on the task [22]. 
Unsupervised algorithms encountered in the reviewed studies can be 
divided into those performing clustering and those used for dimen­
sionality reduction, see Fig. 1 for an overview. 
2.3. Artificial neural networks and deep learning 
Artificial neural networks are loosely inspired by the neurological 
networks in the biological brain, and consist of artificial neurons 
organised in layers. How the layers are organised within the network is 
referred to as its architecture. Artificial neural networks have one input 
layer, responsible for passing the data to the network, and one or more 
hidden layers. Networks with more than one hidden layer are called 
deep neural networks. The final layer is the output layer, providing the 
output of the entire network. Deep learning is a sub-field of machine 
learning involving training deep neural networks, which can be done 
both in a supervised and unsupervised manner. We encounter several 
deep architectures in the reviewed studies. The two more advanced 
types are convolutional neural networks (CNNs) and generative adver­
sarial networks (GANs). CNN denotes the commonly used architecture 
for image analysis and object detection problems, named for having so- 
called convolutional layers that act as filters identifying relevant fea­
tures in images. CNNs have gained popularity recently and all of the 
reviewed studies that apply CNNs were published in 2019 or later. 
Advanced deep learning techniques will most likely replace the estab­
lished image analysis methods. This trend has been observed within 
other medical fields such as gastrointestinal diseases and radiology [23, 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
76
24]. A GAN is a combination of two neural networks: A generator and a 
discriminator competing against each other. The goal of the generator is 
to produce fake data similar to a set of real data. The discriminator re­
ceives both real data and the fake data from the generator, and its goal is 
to discriminate the two. GANs can among other things be used to 
generate synthetic medical data, alleviating privacy concerns [25]. 
2.4. Workflow for model development and validation 
The data used for developing machine learning models is ideally 
divided into three independent parts: A training set, a validation set and 
a test set. The training set is used to tune the model, the validation set to 
evaluate performance during training, and the test set to evaluate the 
final model. A more advanced form of training and validation, is k-fold 
cross-validation. Here, the data is split into k parts, of which one part is 
set aside for validation, while the model is trained on the remaining 
data. This is repeated k times, and each time a different part of the data is 
used for validation. The model performance can be calculated as the 
average performance for the k different models [see 21, chap. 7]. It is 
considered good practice to not use the test data during model devel­
opment and vice versa, the model should not be tuned further once it has 
been evaluated on the test data [see 21, chap.7]. In cases of class 
imbalance, i.e., unequal number of instances from the different classes, 
there is a risk of developing a model that favors the prevalent class. If the 
data is stratified for training and testing, this might not be captured 
during testing. Class imbalance is common in medical data sets, as there 
are for instance usually more healthy than ill people in the population 
[26]. Whether to choose a class distribution that represents the popu­
lation, a balanced or some other distribution depends on the objective. 
Various performance scores should regardless always be used to provide 
a full picture of the model’s performance. 
2.5. Performance scores 
In order to assess how well a machine learning model performs, its 
performance can be assigned a score. In supervised learning, this is 
based on the model’s output compared to the desired output. Here, we 
introduce scores used most frequently in the reviewed studies. Their 
definitions as well as the remaining scores used are provided in Ap­
pendix A.1. A commonly used performance score in classification is 
accuracy, Equation (A.3), which denotes the proportion of correctly 
predicted instances. Its use is inappropriate in cases of strong class 
imbalance, as it can reach high values if the model always predicts the 
prevalent class. The sensitivity, also known as recall, Equation (A.4), 
denotes the true positive rate. If the goal is to detect all positive in­
stances, a high sensitivity indicates success. The precision, Equation 
(A.5), denotes the positive predictive value. The specificity, Equation 
(A.6), denotes the true negative rate, and is the negative class version of 
the sensitivity. The F1 score, Equation (A.7), is the harmonic mean be­
tween the sensitivity and the precision. It is not symmetric between the 
classes, meaning it is dependent on which class is defined as positive. 
Image segmentation involves partitioning the pixels in an image into 
segments [27]. This can for example be used to place all pixels repre­
senting the pupil into the same segment while pixels representing the iris 
are placed in another segment. The identified segments can then be 
compared to manual annotations. Performance scores used include the 
Average Pompeiu-Hausdorff distance, (A.17), the Jaccard index and the 
support, all described in Appendix A.1. 
2.6. AI regulation 
Approved AI devices will be a major part of the medical service 
landscape in the future. Currently, many countries are actively working 
on releasing AI regulations for healthcare, including the European Union 
(EU), the United States, China, South Korea and Japan. On April 21, 
2021, the EU released a proposal for a regulatory framework for AI [28]. 
The US Food and Drug Administration (FDA) is also working on AI 
legislation for healthcare [29]. 
In the framework proposed by the EU, AI systems are divided into the 
four categories low risk, minimal risk, high risk and unacceptable risk 
[28]. AI systems that fall into the high risk category are expected to be 
subject to strict requirements, including data governance, technical 
documentation, transparency and provision of information to users, 
human oversight, robustness and cyber security, and accuracy. It is 
highly likely that medical devices using AI will end up in the high risk 
category. Looking at the legislation proposals [28,29] from an AI 
research perspective, it is clear that explainable AI, transparency, un­
certainty assessment, robustness against adversarial attacks, high qual­
ity of data sets, proper performance assessment, continuous 
post-deployment monitoring, human oversight and interaction be­
tween AI systems and humans, will be major research topics for the 
development of AI in healthcare. 
3. Methods 
3.1. Search methods 
A systematic literature search was performed in PubMed and Embase 
in the period between March 20 and May 21, 2021. The goal was to 
retrieve as many studies as possible applying machine learning to DED 
related data. The following keywords were used: All combinations of 
“dry eye” and “meibomian gland dysfunction” with “artificial intelli­
gence”, “machine learning”, “computer vision”, “image recognition”, 
“bayesian network”, “decision tree”, “neural network”, “image based 
Fig. 1. An overview of the machine learning algorithms used in the reviewed studies.  
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
77
analysis”, “gradient boosting”, “gradient boosting machine” and “auto­
matic detection”. In addition, searches for “ocular surface” combined 
with both “artificial intelligence” and “machine learning” were made. 
See also an overview of the search terms and combinations in Fig. 2. No 
time period limitations were applied for any of the searches. 
3.2. Selection criteria 
The studies to include in the review had to be available in English in 
full-text. Studies not investigating the medical aspects of DED were 
excluded (e.g., other ocular diseases and cost analyses of DED). More­
over, the studies had to describe the use of a machine learning model in 
order to be considered. Reviews were not considered. The studies were 
selected in a three-step process. One review author screened the titles on 
the basis of the inclusion criteria. The full-texts were then retrieved and 
studied for relevance. The search gave 640 studies in total, of which 111 
were regarded as relevant according to the selection criteria. After 
removing duplicates, 45 studies were left. The three-step process is 
shown in Fig. 3a. 
4. Artificial intelligence in dry eye disease 
4.1. Summary of the studies 
Most studies were published in recent years, especially after 2014, 
see Fig. 3b. An overview of the studies is provided in Tables 1-4 for the 
clinical, biochemical and demographical studies, respectively. Infor­
mation on the data used in each study is shown in Table 5. We grouped 
studies according to the type of clinical test or type of study: TBUT, 
interferometry and slit-lamp images, IVCM, meibography, tear osmo­
larity, proteomics analysis, OCT, population surveys and other clinical 
tests. We found most studies employed machine learning for interpre­
tation of interferometry, slit-lamp and meibography images. 
4.2. Fluorescein tear break-up time 
Shorter break-up time indicates an unstable tear film and higher 
probability of DED. Machine learning has been employed to detect dry 
areas in TBUT videos and estimate TBUT [13,59,60,65]. Use of the 
Levenberg-Marquardt algorithm to detect dry areas achieved an accu­
racy of 91% compared to assessments by an optometrist [13]. Applica­
tion of Markov random fields to label pixels based on degree of dryness 
was used to estimate TBUT resulting in an average difference of 2.34 s 
compared to clinician assessments [65]. Polynomial functions have also 
been used to determine dry areas, where threshold values were 
fine-tuned before estimation of TBUT [59]. This method resulted in 
more than 90% of the videos deviating by less than ±2.5 s compared to 
analyses done by four experts on videos not used for training [60]. Taken 
together, these studies indicate that TBUT values obtained using auto­
matic methods are within an acceptable range compared to experts. 
However, we only found four studies, all of them including a small 
number of subjects. Further studies are needed to verify the findings and 
to test models on external data. 
4.3. Interferometry and slit-lamp images 
Interferometry is a useful tool that gives a snapshot of the status of 
the tear film lipid layer, which can be used to aid diagnosis of DED. 
Machine learning systems have been applied to interferometry and slit- 
lamp images for lipid layer classification based on morphological 
properties [36,37,54,56,57,61,62], estimation of the lipid layer thick­
ness [38,52], diagnosis of DED [49,51], determination of ocular redness 
[63] and estimation of tear meniscus height [31,50]. 
Diagnosis of DED can be based on the following morphological 
properties: open meshwork, closed mesh-work, wave, amorphous and 
color fringe [76]. Most studies used these properties to automatically 
classify interferometer lipid layer images using machine learning. Garcia 
et al. used a K-nearest neighbors model trained to classify images 
resulting in an accuracy of 86.2% [62]. Remeseiro et al. explored various 
support vector machine (SVM) models for use in final classification [56, 
57,61]. In one of the studies, the same data was used for training and 
testing, which is not ideal [57]. Another study did not report the data 
their system was trained on [56]. Peteiro et al. evaluated images using 
five different machine learning models [54]. In this study, the amor­
phous property was not included as one of possible classifications, as 
opposed to the other studies. A simple neural network achieved the 
overall best performance with an accuracy of 96%. However, because 
leave-one-out cross validation was applied, the model may have over­
fitted on the training data [21]. da Cruz et al. compared six different 
machine learning models and found that the random forest was the best 
classifier, regardless of the pre-processing steps used [36,37]. The 
highest performance was achieved by application of Ripley’s K function 
in the image pre-processing phase, and Greedy Stepwise technique used 
simultaneously with the machine learning models for feature selection 
[37]. Since all models were evaluated with cross validation, the system 
should be externally evaluated on new images before being considered 
Fig. 2. Search term combinations used in the literature search. Three of the studies found in the searches including “ocular surface” were also found among the 
studies in the searches including “dry eye”. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
78
for routine use in the clinic. 
Hwang et al. investigated whether tear film lipid layer thickness can 
be used to distinguish meibomian gland dysfunction (MGD) severity 
groups [52]. Machine learning was used to estimate the thickness from 
Lipiscanner and slit-lamp videos with promising results. Images were 
pre-processed and the flood-fill algo-rithm and canny edge detection 
were applied to locate and extract the iris from the pupil. A significant 
difference between two MGD severity groups was detected, suggesting 
that the technique could be used for the evaluation of MGD. Keratograph 
images can also be used to determine tear film lipid layer thickness. 
Comparison of two different image analysis methods using a generalized 
linear model showed that there was a high correlation between the two 
techniques [38]. The authors concluded that the simple technique was 
sufficient for evaluation of tear film lipid layer thickness. However, only 
28 subjects were included in the study. 
The use of fractal dimension estimation techniques was investigated 
for feature extraction from interferometer videos for diagnosis of DED 
[51]. The technique was found to be fast and had an area under the 
receiver operating characteristic curve (AUC) value of 0.786, compared 
to a value of 0.824 for an established method (See Appendix A.1 and 
Figure A.4a for a description of the receiver operating characteristic 
curve). Tear film lipid interferometer images were analysed using an 
SVM [49]. Extracted features from the images were passed to the SVM 
model, which classified the images as either healthy, aqueous-deficient 
DED, or evaporative DED. The agreement between the model and a 
trained ophthalmologist was high, with a reported Kappa value of 0.82. 
The model performed best when detecting aqueous-deficient DED. 
Ocular redness is an important indicator of dry eyes. Only one of the 
reviewed studies described an auto-mated system for evaluation of 
ocular redness associated with DED [63]. Slit-lamp images were ac­
quired from 26 subjects with a history of DED. Features representing the 
ocular redness intensity and horizontal vascular component were 
extracted with a Sobel operator. A multiple linear regression model was 
trained to predict ocular redness based on the extracted features. The 
system achieved an accuracy of 100%. The authors suggested that an 
objective system like this could replace subjective gradings by clinicians 
in multicentered clinical studies. 
The tear meniscus contains 75-90% of the aqueous tear volume [77]. 
Consequently, the tear meniscus height can be used as a quantitative 
indicator for DED caused by aqueous deficiency. When connected 
component labelling was applied to slit-lamp images, the Pearson’s 
correlation between the predicted meniscus heights and an established 
software methodology (ImageJ [78]) was high, ranging between 0.626 
and 0.847 [50]. The machine learning system was found to be more 
accurate than four experienced ophthalmologists. The tear meniscus 
height can also be estimated from keratography images using a CNN 
[31]. The automatic machine learning system achieved an accuracy of 
82.5% and was found to be more effective and consistent than a 
well-trained clinician working with limited time. 
Many of the studies apply SVM as their type of machine learning 
model without testing how other machine learning models perform. 
However, three of the studies tested several types of models and found 
that SVM did not perform the best [36,37,54]. It is difficult to compare 
the studies due to different applications and evaluation metrics. Despite 
promising results, most of the studies [36-38,50-52,54,57,61-63] did not 
evaluate their systems on external data. The systems should be tested on 
independent data before they can be considered for clinical application. 
Moreover, some studies were small [38,63] or pilots [31,50], and the 
suggested models should be tested on a larger number of subjects. 
4.4. In vivo confocal microscopy 
IVCM is a valuable non-invasive tool used to examine the corneal 
nerves and other features of the cornea [79]. IVCM images were used in 
a small study to assess characteristics of the corneal subbasal nerve 
plexus for diagnosis of DED [44]. Application of random forest and a 
deep neural network [45] gave promising results with an AUC value of 
0.828 for detecting DED [44]. IVCM images of corneal nerves can also be 
analysed by machine learning models to estimate the length of the nerve 
fiber [43]. Authors used a CNN with a U-net architecture that had been 
pre-trained on more than 5, 000 IVCM images of corneal nerves. The 
model showed that nerve fiber length was significantly longer after 
intense pulsed light treatment in MGD patients, which agreed with 
manual annotations from an experienced investigator with an AUC 
value of 0.96 and a sensitivity of 0.96. High-resolution IVCM images 
were also used to detect obstructive MGD [40]. Combinations of nine 
different CNNs were trained and tested on the images using 5-fold cross 
validation. Classification by the models was compared to diagnosis 
made by three eyelid specialists. The best performance was achieved 
when four different models were combined, with high sensitivity, 
specificity and AUC values, see Table 1. These promising results suggest 
that CNNs can be useful for detection and evaluation of MGD. Deep 
learning methods such as CNNs have the advantage that feature 
extraction from the images prior to analysis is not required as this is 
performed automatically by the model. 
IVCM images have been investigated for changes in immune cells 
across different severities of DED for diagnostic purposes [30]. A 
generalized linear model showed significant differences in dendritic cell 
density and morphology between DED patients and healthy individuals, 
but not between the different DED subgroups, see Table 1. While results 
using machine learning to interpret IVCM images are promising, larger 
clinical studies are needed to validate findings before clinical use can be 
considered. 
4.5. Meibography 
The meibomian glands are responsible for producing meibum, 
important for protecting the tear fluid from evaporation. Reduced 
Fig. 3. (a) Illustration of the three steps in the study selection process and number of studies (N) included in each step, and (b) the number of studies published over 
time, counting the studies included in this review. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
79
Table 1 
Overview of the reviewed studies using clinical investigations, part 1 of 2.  
Study 
Objective 
N 
Clinical Tests 
Type of Data 
Type of Algorithm 
Performance Score(s) 
Aggarwal S 
et al. (2021) 
[30] 
DED mechanism, 
effect of therapy 
199 
Subjective symptoms, Schirmer’s 
test with anasthesia, TBUT, vital 
staining of cornea and 
conjunctiva, laser IVCM images, 
subbasal layer of cornea: DC 
density and morphology 
Images of cornea 
GLM, MLR 
GLM: p-values < 0.05 for DC 
density and number of DCs, MLR: 
p-values < 0.05 between DC 
density and CFS, number of DCs 
and CFS, DC size and CFS, DC 
density and conjunctival staining, 
number of DCs and TBUT, 
corresponding beta-coefficients =
0.20, −0.23, 0.36, 0.24 and −0.18 
Deng X et al. 
(2021) [31] 
Estimate tear 
meniscus height 
217 
Oculus Keratograph 
Tear meniscus 
images 
CNN (U-net) 
Accuracy = 82.5%, sensitivity =
0.899, precision = 0.911, F1 score 
= 0.901 
Elsawy A et al. 
(2021) [32] 
Diagnose DED 
547 
AS-OCT 
Ocular surface 
images 
Pretrained CNN 
(VGG19) 
AUCROC = 0.99 (model 1) and 
0.98 (model 2), AUCPRC = 0.96 
(model 1) and 0.94 (model 2), F1 
score = 0.90 (model 1) and 0.86 
(model 2)* 
Khan ZK et al. 
(2021) [33] 
Detect MGD 
112 
Meibomian gland 3D IR-images, 
lower and upper eyelid 
Meibomian gland 
images 
GAN 
F1 score = 0.825, P-HD = 4.611, 
aggregated JI = 0.664, r = 0.962 
(clincian1) and 0.968 (clinician2), 
p-values < 0.001, mean difference 
= 0.96 (clincian1) and 0.95 
(clincian2) 
Xiao P et al. 
(2021) [34] 
Detect MGD 
15 
(images) 
Oculus Keratograph 
IR meibography 
images 
Prewitt operator, 
Graham scan algorithm, 
fragmentation algorithm 
and SA (used 
sequentially) 
Gland area: KI = 0.94, FPR =
6.02%, FNR = 6.43%. Gland 
segmentation: KI = 0.87, FPR =
4.35%, FNR = 18.61%* 
Yeh C-H et al. 
(2021) [35] 
Detect MGD 
706 
(images) 
Oculus Keratograph 
IR meibography 
images 
Nonparametric instance 
discrimination, 
pretrained CNN 
(ImageNet), hierarchical 
clustering 
Accuracy: meiboscore grading =
80.9%, 2-class classification =
85.2%, 3-class classification =
81.3%, 4-class classification =
80.8%* 
da Cruz LB 
et al. (2020) 
[36] 
Classify tear film 
patterns 
106 
(images) 
Doane interferometer 
Tear film lipid layer 
images 
SVM, RF, RT, Naive 
Bayes, DNN, simple NN 
RF: accuracy = 97.54%, SD =
0.51%, F1 score = 0.97, KI = 0.96, 
AUCROC = 0.99*** 
da Cruz LB 
et al. (2020) 
[37] 
Classify tear film 
patterns 
106 
(images) 
Doane interferometer 
Tear film lipid layer 
images 
SVM, RF, RT, Naive 
Bayes, DNN, simple NN 
RF: accuracy = 99.622%, SD =
0.843%, F1 score = 0.996, KI =
0.995, AUCROC = 0.999*** 
Fu P-I et al. 
(2020) [38] 
Compare 2 methods 
28 
Oculus Keratograph 
Tear film lipid layer 
images (with and 
without 
preprocessing) 
GLM 
beta-coefficients = 0.6, 10 
Fujimoto K 
et al. (2020) 
[39] 
Compare 2 methods 
195 
Pentacam vs AS-OCT 
CCT, TCT, thinnest 
point of cornea 
Multivariable regression 
Severe DED: beta-coefficients =
7.029 (CCT) and 6.958 (TCT), p- 
values = 0.002 (CCT) and 0.049 
(TCT), 95% CI = 2.528-11.530 
(CCT) and 0.037-13.879 (TCT) 
Maruoka S 
et al. (2020) 
[40] 
Detect MGD 
221 
IVCM 
Meibomian gland 
images 
Combinations of 9 CNNs 
Single CNN: AUROC = 0.966, 
sensitivity = 0.942, specificity =
0.821, ensemble CNNs: AUROC =
0.981, sensitivity = 0.921, 
specificity = 0.988 
Prabhu SM 
et al. (2020) 
[41] 
Quantify and detect 
MGD 
400 
(images) 
Oculus Keratograph, digital 
camera 
Meibomian gland 
images 
CNN (U-net) 
p-values > 0.005 between model 
output and clinical experts 
Stegmann H 
et al. (2020) 
[42] 
Detect tear 
meniscus in images 
10 
Optical coherence tomography 
Tear meniscus 
images 
2 CNNs 
Meniscus localization: JI =
0.7885, sensitivity = 0.9999, 
meniscus segmentation best CNN: 
accuracy = 0.9995, sensitivity =
0.9636, specificity = 0.9998, JI =
0.9324, F1 score = 0.9644, 
support = 0.0071*, *** 
Wei S et al. 
(2020) [43] 
DED mechanism, 
effect of therapy 
53 
Corneal IVCM with anesthesia 
Images of cornea 
Pretrained CNN (U-net) 
AUROC = 0.96, sensitivity = 96% 
Giannaccare G 
et al. (2019) 
[44] 
Subbasal nerve 
plexus 
characteristics for 
diagnosing DED 
69 
IVCM 
Images of subbasal 
nerve plexus 
Earlier developed 
method involving RF 
and NN[45,46] 
Nan 
Abbreviations: N = number of subjects; DED = dry eye disease; IVCM = in vivo confocal microscopy; DC = dendritic cell; GLM = generalized linear model; MLR =
multiple linear regression; CFS = corneal fluorescein score; AS-OCT = anterior segment optical coherence tomography; CNN = convolutional neural network; AUROC 
= area under reciever operating characteristic curve; AUPRC = area under precision-recall curve; MGD = meibomian gland dysfunction; GAN = generative adversarial 
network; P-HD = average Pompeiu-Hausdorff distance; JI = Jaccard index; KI = Kappa index; CTRL = healthy; FPR = false positive rate; FNR = false negative rate; 
SVM = support vector machine; RF = random forest; RT = random tree; DNN = deep neural network; SD = standard deviation; CCT = central corneal thickness; TCT =
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
80
secretion of meibum due to a reduced number of functional meibomian 
glands and/or obstruction of the ducts is a major cause of evaporative 
DED and MGD. Meibography is a common technique for diagnosing 
MGD [80]. Classification of meibomian glands using meibography is 
routine for experienced experts, but this is not the case for all clinicians. 
Moreover, automatic methods can be faster than human assessment. 
Meibography images may require several pre-processing steps before 
they can be classified. One study trained an SVM on extracted features 
from the images [64]. Pre-processing included the dilation, flood-fill, 
skeletonization and pruning algorithms. The model achieved a sensi­
tivity of 0.979 and specificity of 0.961. However, in contrast to all other 
image analysis methods, this method is not completely automatic as the 
images need to be manipulated manually before they are passed on to 
the system. 
A combination of Otsu’s method and the skeletonization and 
watershed algorithms was useful in auto-matically quantifying meibo­
mian glands [55]. This method was faster than an ophthalmologist and 
achieved a sensitivity and specificity of 0.993 and 0.975, respectively. 
Another automatic method applied B´ezier curve fitting as part of the 
analysis [53]. The reported sensitivity was 1.0, while the specificity was 
0.98. Xiao et al. sequentially applied a Prewitt operator, Graham scan, 
fragmentation and skeletonization algorithms for image analysis to 
quantify meibomian glands [34]. The agreement between the model 
results and two ophthalmologists was high with Kappa values larger 
than 0.8 and low false positive rates (< 0.06). The false negative rate 
was 0.19, suggesting that some glands were missed by the method. A 
considerable weakness of this study was that only 15 images were used 
for model development, and consequently it might not work well on 
unseen data. Another study automatically graded MGD severity using a 
Sobel operator, polynomial functions, fragmentation algorithm and 
Otsu’s method [47]. While the method was found to be faster, the results 
were significantly different from clinician assessments. 
Deep learning approaches were used by four studies evaluating 
meibomian gland features [33,35,41,48]. These systems are fully auto­
mated and apply some of the latest technologies within image analysis. 
Wang et al. used four different CNNs to determine meibomian gland 
atrophy [48]. The CNNs were trained to identify meibomian gland 
drop-out areas and estimate the percentage atrophy in a set of images. 
Comparison of model predictions with experienced clinicians indicated 
that the best CNN (ResNet50 architecture) was superior. Yeh et al. 
developed a method to evaluate meibomian gland atrophy by extracting 
features from meibography images with a special type of unsupervised 
CNN before application of a K-nearest neighbors model to allocate a 
meiboscore [35]. The system achieved an accuracy of 80.9%, out­
performing annotations by the clinical team. Moreover, hierarchical 
clustering of the extracted features from the CNN could show relation­
ships between meibography images. Another study used a CNN to 
automatically assess meibomian gland characteristics [41]. Images from 
two different devices collected from various hospitals were used to train 
and evaluate the CNN. This is an example of uncommonly good practice, 
as most medical AI systems are developed and evaluated on data from 
only one device and/or hospital. The only study to use a GAN archi­
tecture tested it on infrared 3D images of meibomian glands in order to 
evaluate MGD [33]. Comparing the model output with true labels, the 
performance scores were better than for state of the art segmentation 
methods. The Pearson correlations between the new automated method 
and two clinicians were 0.962 and 0.968. 
Four of the studies did not evaluate their proposed systems on 
external data [34,47,53,55]. Since the number of images used for model 
development was limited, the models can have overfit, and external 
evaluations should be performed to test how well the systems generalize 
to new data. 
4.6. Tear osmolarity 
Tear osmolarity is a measure of tear concentration, and high values 
can indicate dry eyes. Cartes et al. [67] investigated use of machine 
learning to detect DED based on this test. Four different machine 
learning models were compared. Noise was added to osmolarity mea­
surements during the training phase, while original data without noise 
was used for final evaluation. The logistic regression model achieved 
85% accuracy. However, since the models were trained and tested on the 
same data, the reported score is most likely not representative for how 
well the model generalizes to new data. 
4.7. Proteomic analysis 
Proteomic analysis describes the qualitative and quantitative 
composition of proteins present in a sample. Grus et al. compared tear 
proteins in individuals with diabetic DED, non-diabetic DED and healthy 
controls for discrimination between the groups [72]. The authors used 
discriminant analysis and principal component analysis combined with 
k-means clustering. Both models achieved low accuracies when pre­
dicting all three categories. However, classification into DED and 
non-DED achieved accuracies of 72% and 71% for discriminant analysis 
and k-means clustering, respectively. In another study by the same 
group, tear proteins analysed using deep learning discriminated subjects 
as healthy or having DED with an accuracy of 89% [71]. An accuracy of 
71% was achieved using discriminant analysis. A combination of 
discriminant analysis for detecting the most important proteins and a 
deep neural network for classification was also investigated [70]. High 
accuracy, sensitivity and specificity were reported. Discriminant anal­
ysis was also used by Gonzalez et al. in analysis of the tear proteome 
[69]. The most important proteins were selected to train an artificial 
neural network to classify tear samples as aqueous-deficient DED, MGD 
or healthy. The model gave an overall accuracy of 89.3%. Principal 
component analysis yielded good separation of healthy controls, 
aqueous-deficient DED and MGD data-points, indicating that the pro­
teins were good candidates for classification of the three conditions. This 
system achieved the highest accuracy of all the reviewed proteomic 
studies. Considered together, the results from the four studies [69-72] 
suggest that neural networks applied alone or together with other 
techniques perform better than discriminant analysis for detecting 
DED-related protein patterns in the tear proteome. 
Jung et al. used a network model based on modularity analysis to 
describe the tear proteome with respect to immunological and inflam­
matory responses related to DED [68]. In this study, patterns in tears and 
lacrimal fluid were investigated in patients with DED. Since only 10 
subjects were included, the study should be performed on a larger cohort 
of patients to verify the results. 
4.8. Optical coherence tomography 
Thickening of the corneal epithelium can be a sign of abnormalities 
in the cornea. Moreover, corneal thickness could potentially be a marker 
for DED. Kanellopoulos et al. developed a linear regression model to 
look for possible correlations between corneal thickness metrics 
measured using anterior segment optical coherence tomography (AS- 
OCT) and DED [58]. However, neither the model predictions nor per­
formance were reported, making it difficult to assess the usefulness of 
thinnest corneal thickness; r = Pearson’s correlation coefficient; Nan = not available; NN = neural network; RMSE = root mean squared error; CI = confidence interval; 
TBUT = fluorescein tear break-up time; PA = pruning algorithm; SA = skeletonization algorithm; FFA = Flood-fill algorithm; * = standard deviations not included in 
table; ** = 95% confidence intervals not included in table; *** = metrics are calculated as the average of 5 repetitions; **** = metrics are calculated as the average of 
10 repetitions; ***** = metrics are calculated as the average from 10-fold crossvalidation; § = metrics are calculated as the average from 6-fold crossvalidation; §§ =
metrics are calculated as the average of 100 models. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
81
Table 2 
Overview of the reviewed studies using clinical investigations, part 2 of 2.  
Study 
Objective 
N 
Clinical Tests 
Type of Data 
Type of Algorithm 
Performance Score(s) 
Llorens-Quintana 
C et al. (2019) 
[47] 
Evaluate 
meibomian 
gland atrophy 
149 
Oculus Keratograph 
Meibography 
images 
Sobel operator, polynomial 
function, fragmentation 
algorithm, Otsu’s method 
(used sequentially) 
p-values < 0.05 between automatic 
method and clinicians 
Wang J et al. 
(2019) [48] 
Evaluate 
meibomian 
gland atrophy 
706 
(images) 
Oculus Keratograph 
Meibography 
images 
4 CNNs 
Meiboscore grading: accuracy = 95.6%, 
eyelid detection: accuracy = 97.6%, JI =
0.955, atrophy detection: accuracy =
95.4%, JI = 0.667, RMSE = 0.067 
(average across 4 meiboscores) 
Yabusaki K 
(2019) [49] 
Diagnose DED 
138 
(images) 
Tear interferometer 
Tear film lipid 
layer images 
SVM 
KI = 0.820, CTRL: F1 score = 0.845, SD 
= 0.067, aqueous-deficient DED: F1 
score = 0.981, SD = 0.023, evaporative 
DED: F1 score = 0.815, SD = 0.095**** 
Yang J et al. 
(2019) [50] 
Estimate tear 
meniscus 
height for DED 
69 
Slit-lamp images with 
fluorescence staining 
Ocular surface 
images 
Connected component 
labelling 
Mean: p-value < 0.01 (×16 and ×40 
magnification), r = 0.626 (×16) and 
0.711 (×40), max: p-value < 0.001 (×16 
and ×40), r = 0.645 (×16) and 0.847 
(×40) 
Szyperski PD 
(2018) [51] 
Diagnose DED 
110 
Interferometry 
Videos from lateral 
shearing 
interferometry 
4 different fractal 
dimension estimators, 
linear regression 
Best estimator: AUROC = 0.786 
Hwang H et al. 
(2017) [52] 
Estimate tear 
film lipid layer 
thickness 
34 
Lipiscanner 1.0, slit-lamp 
microscope 
Tear film lipid 
layer videos 
Flood-fill algorithm, Canny 
edge detection 
p-value < 0.01 between all MGD groups 
Koprowski R et al. 
(2017) [53] 
Detect MGD 
57 
Oculus Keratograph 
Meibography 
images 
Riesz pyramid (?), Bezier 
curve (used sequentially) 
Accuracy = 99.08%, sensitivity = 1, 
specificity = 0.98 
Peteiro-Barral D 
et al. (2017) 
[54] 
Classify tear 
film patterns 
105 
(images) 
Tearscope plus images 
Tear film lipid 
layer images 
SVM, Decision tree, Naive 
Bayes, simple NN, Fisher¬
¥s linear discriminant 
NN: accuracy = 96%, sensitivity = 92%, 
specificity = 97%, precision = 92%, F1 
score = 0.93, AUCROC = 0.95 
Koprowski et al. 
(2016) [55] 
Detect MGD 
86 
Oculus Keratograph 
Meibography 
images 
Otsu’s method, SA, 
watershed algorithm (used 
sequentially) 
Sensitivity = 0.993, specificity = 0.975 
Remeseiro B et al. 
(2016) [56] 
Classify tear 
film patterns 
128 
(images) 
Tearscope-plus images 
Tear film lipid 
layer images 
SVM 
Accuracy = 96.09%, precision =
92.00%, sensitivity = 89.66%, 
specificity = 97.98%, F1 score =
91.23%, processing time = 0.07 s 
Remeseiro B et al. 
(2016) [57] 
Classify tear 
film patterns 
50 
(images) 
Tearscope-plus images 
Tear film lipid 
layer images 
SVM 
Accuracy = 90.89%, sensitivity =
83.54%, precision = 97.95%, specificity 
= 86.75% 
Kanellopoulos AJ 
et al. (2014) 
[58] 
Diagnose DED 
70 
Fourier-domain AS-OCT 
system: corneal and 
corneal epithelial 
thickness maps 
Corneal 
examination 
Linear regression 
(correlation between DED 
and thickness) 
Nan 
Ramos L et al. 
(2014) [59] 
Estimate TBUT 
18 
(videos) 
Videos from TBUT (slit- 
lamp) 
TBUT videos 
Polynomial function 
Specificity = 89% (parameter b) and 
82% (parameter e), specificity = 84% 
and 80% 
Ramos L et al. 
(2014) [60] 
Estimate TBUT 
18 
(videos) 
Videos from TBUT (slit- 
lamp) 
TBUT videos 
Polynomial function 
Accuracy = ""more than 90%"" 
Remeseiro et al. 
(2014) [61] 
Classify tear 
film patterns 
511 
(images) 
Tearscope-plus images 
Tear film lipid 
layer images 
Markov random field, SVM 
(used sequentially) 
Accuracy = 97.14%, accuracy (noisy 
data) = 92.61%***** 
García-Resúa C 
et al. (2013) 
[62] 
Classify tear 
film patterns 
105 
Tearscope-plus images 
Tear film lipid 
layer images 
K-nearest neighbors 
Cram´er’s V = 0.9, r = 0.94, p-value <
0.001, accuracy = 86.2% §
Rodriquez JD 
(2013) [63] 
Evaluate ocular 
redness 
26 
Slit-lamp, digital camera 
Images of 
conjunctiva 
Sobel operator, MLR (used 
sequentially) 
Accuracy = 100%, r = 0.76, concordance 
correlation = 0.76 (compared to 5 
investigators)* 
Koh YW et al. 
(2012) [64] 
Detect MGD 
55 
Slit-lamp biomicroscope, 
upper eye lid 
IR meibography 
images 
PA, SA, FFA, SVM (used 
sequentially) 
Specificity = 96.1%, SD = 0.4%, 
sensitivity = 97.9%, SD = 0.6% §§
Yedidya T et al. 
(2009) [65] 
Estimate TBUT 
22 
(videos) 
Video from TBUT 
TBUT videos 
Markov random field 
Mean difference in TBUT = 2.34s 
Yedidya T et al. 
(2007) [13] 
Detect dry 
areas 
8 
(videos) 
Video from TBUT 
TBUT videos 
Levenberg-Marquardt 
Accuracy = 91% (84-96%), SD = 4% 
Mathers WD et al. 
(2004) [66] 
Investigate DED 
513 
Schirmer’s test, 
meibomian gland drop- 
out, lipid viscosity and 
volume, tear evaporation 
Clinical test results 
Hierarchical clustering, 
decision tree 
Nan 
Abbreviations: N = number of subjects; DED = dry eye disease; IVCM = in vivo confocal microscopy; DC = dendritic cell; GLM = generalized linear model; MLR =
multiple linear regression; CFS = corneal fluorescein score; AS-OCT = anterior segment optical coherence tomography; CNN = convolutional neural network; AUROC 
= area under reciever operating characteristic curve; AUPRC = area under precision-recall curve; MGD = meibomian gland dysfunction; GAN = generative adversarial 
network; P-HD = average Pompeiu-Hausdorff distance; JI = Jaccard index; KI = Kappa index; CTRL = healthy; FPR = false positive rate; FNR = false negative rate; 
SVM = support vector machine; RF = random forest; RT = random tree; DNN = deep neural network; SD = standard deviation; CCT = central corneal thickness; TCT =
thinnest corneal thickness; r = Pearson’s correlation coefficient; Nan = not available; NN = neural network; RMSE = root mean squared error; CI = confidence interval; 
TBUT = fluorescein tear break-up time; PA = pruning algorithm; SA = skeletonization algorithm; FFA = Flood-fill algorithm; * = standard deviations not included in 
table; ** = 95% confidence intervals not included in table; *** = metrics are calculated as the average of 5 repetitions; **** = metrics are calculated as the average of 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
82
the study. The type of instrument used to determine the corneal thick­
ness was found to affect the results [39]. Measurements from AS-OCT 
and Pentacam were compared and multivariable regression was used 
to detect differences between the two techniques regarding the 
measured central corneal thickness and the thinnest corneal thickness. 
Individuals with mild DED, severe DED and healthy subjects were 
examined. The two techniques gave significantly different results in 
terms of the resulting β-coefficients in the multivariable regression 
model for individuals with severe DED. Images from clinical examina­
tions with AS-OCT were used to diagnose DED [32]. A pretrained VGG19 
CNN [81] was fine-tuned using separate images for training and vali­
dation. Two similar CNN models were developed, and evaluation was 
performed on an external test set. Both achieved impressively high 
performance scores. The AUC values were 0.99 and 0.98. This is one out 
of two studies in this review that used an independent test sets after 
model development. Such practice is essential for a realistic impression 
of how well the model generalizes to new data not used during model 
development. The good performance is likely linked to the large 
amounts of training data (29, 000 images), which is essential for deep 
learning methods. Most of the re-viewed studies use significantly smaller 
data sets, which constitutes a disadvantage. Stegmann et al. analysed 
OCT images from healthy subjects for automatic detection of the lower 
tear meniscus [42]. Two different CNNs were trained and evaluated 
using 5-fold cross validation. The tear menisci detected by the models 
were compared to evaluations from an experienced grader. The best 
CNN achieved an average accuracy of 99.95%, sensitivity of 0.9636 and 
specificity of 0.9998. The system is promising regarding fast and accu­
rate segmentation of OCT images. However, more images from different 
OCT systems, including non-healthy subjects, should be used to verify 
and improve the analysis. 
The two studies [42,81] showed that CNNs could be an appropriate 
tool for image analysis. CNNs are likely to increase in popularity within 
10 repetitions; ***** = metrics are calculated as the average from 10-fold crossvalidation; § = metrics are calculated as the average from 6-fold crossvalidation; §§ =
metrics are calculated as the average of 100 models. 
Table 3 
Overview of the reviewed studies using biochemical investigations.  
Study 
Objective 
N 
Clinical Tests 
Type of Data 
Type of Algorithm 
Performance Score(s) 
Cartes C 
et al. 
(2019) 
[67] 
Diagnose DED 
40 
Tear-Lab Osmometer 
Tear osmolarity 
measurements 
LR, Naive Bayes, SVM, RF 
LR: accuracy = 85% 
Jung JH 
et al. 
(2017) 
[68] 
Detect 
protein 
patterns in 
DED 
10 
Pooled tear and lacrimal fluid, 
analysed with LC-MS, trypsin 
digestion, RP-LC fractionation 
Proteins in tears 
and lacrimal fluid 
""Network model"" based on 
betweenness centrality 
Nan 
Gonzalez N 
(2014) [69 
Diagnose DED 
93 
Peptide/protein analysis: gel 
electrophoresis (SDS-PAGE) 
Peptides and 
proteins in tears 
Discriminant analysis, 
principal component analysis, 
NN 
Accuracy = 89.3%, CTRL: sensitivity = 0.99, 
specificity = 0.96, MGD: sensitivity = 0.85, 
specificity = 0.96, aqueous-deficient DED: 
sensitivity = 0.83, specificity = 0.93* 
Grus FH 
et al. 
(2005) 
[70] 
Diagnose DED 
159 
Schirmer’s test with 
anesthesia, tears analysed by 
LC-MS 
Proteins in tears 
Discriminant analysis, DNN 
(used sequentially) 
AUROC = 0.93, sensitivity and specificity =
‘‘approx. 90% each’’ 
Grus FH 
et al. 
(1999) 
[71] 
Diagnose DED 
60 
Protein analysis: gel 
electrophoresis (SDS-PAGE) 
Proteins in tears 
DNN, discriminant analysis 
DNN: accuracy = 89%, discriminant analysis: 
accuracy = 71% 
Grus FH 
et al. 
(1998) 
[72] 
Diagnose DED 
119 
Protein analysis: gel 
electrophoresis (SDS-PAGE) 
Proteins in tears 
Principal component analysis, 
K-means clustering (used 
sequentially), discriminant 
analysis 
K-means: accuracy = 71% (DED vs CTRL) and 
42% (DED, diabetes-DED, CTRL), 
discriminant analysis: accuracy = 72% (DED 
vs CTRL) and 43% (DED, diabetes-DED, CTRL) 
Abbreviations: N = number of subjects; DED = dry eye disease; LR = logistic regression; SVM = support vector machine; RF = random forest; AUROC = area under 
reciever operating characteristic curve; MGD = meibomian gland dysfunction; CTRL = healthy; DNN = deep neural network; Nan = not available; NN = neural 
network; LC-MS = liquid chromatography mass spectometry; RP-LC = reverse-phase liquid chromatography; SDS-PAGE = sodium dodecyl sulphate-polyacrylamide 
gel electrophoresis; OSDI = ocular surface disease index; * = metrics are calculated as the average of 10 repetitions. 
Table 4 
Overview of the reviewed studies using demographical investigations.  
Study 
Objective 
N 
Clinical Tests 
Type of Data 
Type of Algorithm 
Performance Score(s) 
Choi HR 
et al. 
(2020) 
[73] 
Investigate DED and 
dyslipidemia 
association 
2272 
OSDI score, health 
examination, 
questionnaire 
Population studies, Korea 
GLM, LR 
Nan 
Nam SM 
et al. 
(2020) 
[74] 
Detect risk factors for 
DED 
4391 
Health examination, 
health survey, nutrition 
survey 
National health survey, Korea 
Decision tree, Lasso, 
LR (used sequentially) 
AUROC = 0.70, 95% CI = 0.61- 
0.78, specificity = 68%, 
sensitivity = 66% 
Kaido M 
et al. 
(2015) 
[75] 
Diagnose DED 
369 
Blink frequency, visual 
maintenance ratio, 
questionnaire 
Functional VA measurement and 
questionnaire, Japanese visual 
display terminal workers 
Discriminant analysis 
Sensitivity = 93.1%, 
specificity = 43.7%, precision 
= 83.8%, NPV = 80.8% 
Abbreviations: N = number of subjects; DED = dry eye disease; GLM = generalized linear model; AUROC = area under reciever operating characteristic curve; Nan =
not available; CI = confidence interval; LR = logistic regression; OSDI = ocular surface disease index; VA = visual acuity; NPV = negative predictive value. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
83
the field of DED due to promising results for solving image related tasks, 
including feature extraction. 
4.9. Other clinical tests 
Machine learning models were used to analyse results from a variety 
of clinical tests to expand understanding of the DED process [66]. The 
study included subjects with DED and healthy subjects. Subjective cutoff 
values from clinical tests were used to assign subjects to the DED class. 
Hierarchical clustering and a decision tree were applied sequentially to 
group the subjects based on their clinical test results. The resulting 
groups were compared to the original groups. Because the analysis was 
based on objective measurements, it could be used to develop more 
objective diagnostic criteria. This could lead to earlier detection and 
more effective treatment of DED. 
Table 5 
Overview of the data applied for the analyses.  
Study 
Type of 
Input 
Data 
Training 
Dataset 
Testing 
Dataset 
Reference Standard 
Clinical Investigations 
Aggarwal S et al. 
(2021) [30] 
Tabular 
349 
Nan 
Nan (clinical test 
results, subjective 
report) 
Deng X et al. 
(2021) [31] 
Images 
253 
(images) 
232 
(images) 
Senior clinician 
Elsawy A et al. 
(2021) [32 
Images 
29172 
(train), 
7293 (val) 
23760 
Certified cornea 
specialist 
Khan ZK et al. 
(2021) [33] 
Images 
90 
22 
Clinician 
Xiao P et al. 
(2021) [34] 
Images 
15 
Nan 
2 ophthalmologists 
Yeh C-H et al. 
(2021) [35] 
Images 
398 
(train), 99 
(val) 
209 
Trained clinician 
da Cruz LB et al. 
(2020) [36] 
Tabular 
106 (10- 
fold CV) 
Nan 
Optometrist 
da Cruz LB et al. 
(2020) [37] 
Tabular 
106 (10- 
fold CV) 
Nan 
Optometrist 
Fu P-I et al. 
(2020) [38] 
Tabular 
28 
Nan 
Nan (clinical test 
results, subjective 
report) 
Fujimoto K et al. 
(2020) [39] 
Tabular 
195 
Nan 
Nan (kerato- 
conjunctival staining 
for ac{DED}) 
Maruoka S et al. 
(2020) [40] 
Images 
221 (5- 
fold CV) 
Nan 
3 eyelid specialists 
Prabhu SM et al. 
(2020) [41] 
Images 
600 
200 
Clinical experts 
Stegmann H 
et al. (2020) 
[42] 
Images 
6658 
(images) 
(5-fold 
CV) 
Nan 
Experienced 
investigator 
Wei S et al. 
(2020) [43] 
Images 
5000* 
53 (3-5 
per 
patient) 
Experienced 
investigator 
Giannaccare G 
et al. (2019) 
[44] 
Tabular 
Nan 
69 
Experienced 
investigator ~ cite 
{Chen2017ACCMed} 
Llorens- 
Quintana C 
et al. (2019) 
[47] 
Images 
149 
Nan 
Clinicians 
Wang J et al. 
(2019) [48] 
Images 
398 
(train) 99 
(val) 
209 
Experienced clinician 
Yabusaki K 
(2019) [49] 
Tabular 
93** 
45** 
Skilled 
ophthalmologist 
Yang J et al. 
(2019) [50] 
Images 
520 
Nan 
ImageJ software 
Szyperski PD 
(2018) [51] 
Tabular 
110 
Nan 
Nan 
Hwang H et al. 
(2017) [52] 
Frames 
34 
Nan 
Meibomian gland 
expert 
Koprowski R 
et al. (2017) 
[53] 
Images 
228 
(images) 
Nan 
Specialized clinicians 
Peteiro-Barral D 
et al. (2017) 
[54] 
Tabular 
105 (LOO 
CV) 
Nan 
Experts 
Koprowski et al. 
(2016) [55]  
Images 
172 
(images) 
Nan 
Ophthalmology expert 
Remeseiro B 
et al. (2016) 
[56] 
Tabular 
Nan 
128 
Optometrists 
Remeseiro B 
et al. (2016) 
[57] 
Tabular 
Sampled 
from test 
set 
50 
4 optometrists 
Tabular 
140 
Nan 
Ophthalmologist  
Table 5 (continued) 
Study 
Type of 
Input 
Data 
Training 
Dataset 
Testing 
Dataset 
Reference Standard 
Kanellopoulos 
AJ et al. 
(2014) [58] 
Ramos L et al. 
(2014) [59] 
Videos 
18 
Nan 
2/4 experts 
Ramos L et al. 
(2014) [60] 
Videos 
12 
6 
4 experts 
Remeseiro et al. 
(2014) [61] 
Tabular 
511 (10- 
fold CV) 
Nan 
Experts 
García-Resúa C 
et al. (2013) 
[62] 
Tabular 
105 (6- 
fold CV) 
Nan 
Experienced 
investigator 
Rodriquez JD 
(2013) [63] 
Tabular 
99 
(images) 
Nan 
5 trained investigators 
Koh YW et al. 
(2012) [64] 
Tabular 
28*** 
27*** 
Experts 
Yedidya T et al. 
(2009) [65] 
Videos 
22 
Nan 
Clinician 
Yedidya T et al. 
(2007) [13] 
Frames 
8**** 
Nan 
Optometrist (evaluated 
3 of the 8 patients) 
Mathers WD 
et al. (2004) 
[66] 
Tabular 
513 (10- 
fold CV) 
Nan 
Nan (clinical test 
results) 
Biochemical Investigations 
Cartes C et al. 
(2019) [67] 
Tabular 
40 (noise 
added) 
40 (no 
noise) 
Nan (clinical test 
results, subjective 
report) 
Jung JH et al. 
(2017) [68] 
Tabular 
10 
Nan 
Ophthalmologist 
Gonzalez N 
(2014) [69] 
Tabular 
70% of 
93** 
30% of 
93** 
Nan (clinical tests) 
Grus FH et al. 
(2005) [70] 
Tabular 
50% of 
159 
50% of 
159 
Nan (clinical test 
results, subjective 
report) 
Grus FH et al. 
(1999) [71] 
Tabular 
30 
30 
Nan (clinical test 
results, subjective 
report) 
Grus FH et al. 
(1998) [72] 
Tabular 
119 
§
Nan (clinical test 
results, subjective 
report) 
Demographical Investigations 
Choi HR et al. 
(2020) [73] 
Tabular 
2272 
Nan 
Nan (subjective report) 
Nam SM et al. 
(2020) [74] 
Tabular 
80% of 
4391 
20% of 
4391 
Ophthalmologist 
Kaido M et al. 
(2015) [75] 
Tabular 
369 
Nan 
Dry eye specialists 
Abbreviations: Nan = not available; val = validation; CV = crossvalidation; DED 
= dry eye disease; LOO = leave one out; * = pretraining images; ** = randomly 
selected samples, process repeated 10 times; *** = randomly selected samples, 
process repeated 100 times; **** = 3-5 sequences of video per patient; § = For 
multivariate analysis model, but the number of samples was not mentioned. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
84
4.10. Population surveys 
Population surveys can provide valuable insight regarding the 
prevalence of DED and help detect risk factors for developing the dis­
ease. Japanese visual terminal display workers were surveyed with the 
objective of detecting DED [75]. Dry eye exam data and subjective re­
ports were used for diagnosis. This was passed to a discriminant analysis 
model. When compared to diagnosis by a dry eye specialist, the model 
showed a high sensitivity of 0.931, but low specificity of 0.437. This is a 
very low specificity, but is not necessarily bad if the aim is to detect as 
many cases of DED as possible and there is less concern about misclas­
sification of healthy individuals. Data from a national health survey 
were analysed in order to detect risk factors for DED [74]. Here, in­
dividuals were regarded as having DED if they had been diagnosed by an 
ophthalmologist, and were experiencing dryness. Feature modifications 
were performed by a decision tree, and the most important features were 
selected using lasso. β-coefficients from a logistic regression trained on 
the most important features were used to rank the features. Women, 
individuals who had received refractive surgery and those with 
depression were detected as having the highest risk for developing DED. 
Even though the models in the study were trained on data from more 
than 3500 participants, the reported performance scores were among 
the poorest in this review with a sensitivity of 0.66 and a specificity of 
0.68. A possible reason could be that the selected features were not ideal 
for detecting DED. However, the detected risk factors have previously 
been shown to be associated with DED [3,82,83]. The findings suggest 
that the data quality from population surveys might not be as high as in 
other types of studies, which could lead to misinterpretation by the 
machine learning model. 
The association between DED and dyslipidemia was investigated by 
combining data from two population surveys in Korea in Ref. [73]. A 
generalized linear model was used to investigate linear characteristics 
between features and the severity of DED. The model showed significant 
increase in age, blood pressure and prevalence of hypercholesterolemia 
over the range from no DED to severe DED. Evaluation of the association 
between dyslipidemia and DED using linear regression showed that the 
odds ratio for men with dyslipidemia was higher than 1 compared to 
men without dyslipidemia. This association was not found in women. 
The study results suggest a positive association between DED and dys­
lipidemia in men, but not in women. 
4.11. Future perspectives 
In order to benchmark existing and future models, we advocate that 
the field of DED should have a common, centralized and openly avail­
able data set for testing and evaluation. The data should be fully 
representative for the relevant clinical tests. In order to ensure that 
models are applicable to all populations of patients, medical institutions, 
and types of equipment around the world, they must be evaluated on 
data from different demographic groups of patients across several clinics 
and, if relevant, from different medical devices. Moreover, the test data 
set should not be available for model development, but only for final 
evaluation. A common standard on these processes will increase the 
reproducibility and comparability of studies. Standardized collection 
and handling of clinical data and samples would also facilitate com­
parisons between different instruments and clinics [84]. In addition, a 
cross hospitals/centers data set would solve important challenges of 
applying AI in clinical practice, such as metrics not reflecting clinical 
applicability, difficulties in comparing algorithms, and under­
specification. These have all been identified as being among the main 
obstacles for adoption of any medical AI system in clinical practice [85, 
86]. 
A possible challenge regarding implementation in the clinic is that 
hospitals do not necessarily use the same data platforms, which might 
prevent widespread use of machine learning systems. Consequently, 
solutions for implementing digital applications across hospitals should 
be considered. 
Model explanations are important in order to understand why a 
complex machine learning model produces a certain prediction. For 
healthcare providers to trust the systems and decide to use them in the 
clinic, the systems should provide understandable and sound explana­
tions of the decision-making process. Moreover, they could assist clini­
cians when making medical decisions [18]. When developing new 
machine learning systems within DED, effort should be made to present 
the workings of the resulting models and their predictions in an easy to 
interpret fashion. 
5. Conclusions 
We observed a large variation in the type of clinical tests and the type 
of data used in the reviewed studies. This is also true regarding the 
extent of pre-processing applied to the data before passing it to the 
machine learning models. The studies analysing images can be divided 
into those applying deep learning techniques directly on the images, and 
those performing extensive pre-processing and feature extraction before 
the data is passed to the machine learning model in a tabular format. The 
number of studies belonging to the first group has increased significantly 
over the past 3 years. As deep learning techniques become more estab­
lished, these will probably replace more traditional image pre- 
processing and feature extraction techniques. 
We noted that there was a lack of consensus regarding how best to 
perform model development, including evaluation. This made it difficult 
to estimate how well some models will perform in the clinic and with 
new patients, and also to compare the different models. Comparison was 
further complicated by the use of different types of performance scores. 
In addition there was no culture of data and code sharing, which makes 
reproducibility of the results impossible. For the future, focus should be 
put on establishing data and code sharing as a standard procedure. 
In conclusion, the results from the different studies’ machine 
learning models are promising, although much work is still needed on 
model development, clinical testing and standardisation. AI has a high 
potential for use in many different applications related to DED, 
including automatic detection and classification of DED, investigation of 
the etiology and risk factors for DED, and in the detection of potential 
biomarkers. Effort should be made to create common guidelines for the 
model development process, especially regarding model evaluation. 
Prospective testing is recommended in order to evaluate whether pro­
posed models can improve the diagnostics of DED, and the health and 
quality of life of patients with DED. 
Declaration of competing interest 
The authors report no conflicts of interest. 
Appendix A. Supplementary data 
Supplementary data to this article can be found online at https://doi. 
org/10.1016/j.jtos.2021.11.004. 
References 
[1] Stapleton F, Alves M, Bunya VY, Jalbert I, Lekhanont K, Malet F, Na K-S, 
Schaumberg D, Uchino M, Vehof J, et al. TFOS DEWS II epidemiology report. Ocul 
Surf 2017;15(3):334–65. https://doi.org/10.1016/j.jtos.2017.05.003. 
[2] Geerling G, Tauber J, Baudouin C, Goto E, Matsumoto Y, O’Brien T, Rolando M, 
Tsubota K, Nichols KK. The international workshop on meibomian gland 
dysfunction: report of the subcommittee on management and treatment of 
meibomian gland dysfunction. Investig Ophthalmol Vis Sci 2011;52(4):2050–64. 
https://doi.org/10.1167/iovs.10-6997g. 
[3] Matossian C, McDonald M, Donaldson KE, Nichols KK, MacIver S, Gupta PK. Dry 
eye disease: consideration for women’s health. J Wom Health 2019;28(4):502–14. 
dx.d oi.org/10.1089/jwh.2018.7041. 
[4] Nichols JJ, Ziegler C, Mitchell GL, Nichols KK. Self-reported dry eye disease across 
refractive modalities. Investig Ophthalmol Vis Sci 2005;46(6):1911–4. https://doi. 
org/10.1167/iovs.04-1294. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
85
[5] Zhang X, Zhao L, Deng S, Sun X, Wang N. Dry eye syndrome in patients with 
diabetes mellitus: prevalence, etiology, and clinical characteristics. J Ophthalmol 
2016. https://doi.org/10.1155/2016/8201053. 2016. 
[6] Mandell JT, Idarraga M, Kumar N, Galor A. Impact of air pollution and weather on 
dry eye. J Clin Med 2020;9(11). https://doi.org/10.3390/jcm9113740. 
https://www.mdpi.com/2077-0383/9/11/3740. 
[7] Willcox MD, Argüeso P, Georgiev GA, Holopainen JM, Laurie GW, Millar TJ, 
Papas EB, Rolland JP, Schmidt TA, Stahl U, et al. TFOS DEWS II tear film report. 
Ocul Surf 2017;15(3):366–403. https://doi.org/10.1016/j.jtos.2017.03.006. 
[8] McCarthy J, Minsky ML, Rochester N, Shannon CE. A proposal for the Dartmouth 
summer research project on Artificial Intelligence, august 31, 1955. AI Mag 2006; 
27(4). https://doi.org/10.1609/aimag.v27i4.1904. 12-12. 
[9] Legg S, Hutter M. Universal intelligence: a definition of machine intelligence. 
Minds Mach 2007;17(4):391–444. https://doi.org/10.1007/s11023-007-9079-x. 
[10] Schmidt-Erfurth U, Sadeghipour A, Gerendas BS, Waldstein SM, Bogunovi´c H. 
Artificial Intelli- gence in retina. Prog Retin Eye Res 2018;67:1–29. https://doi. 
org/10.1016/j.preteyeres.2018.07.004. 
[11] De Fauw J, Ledsam JR, Romera-Paredes B, Nikolov S, Tomasev N, Blackwell S, 
Askham H, Glorot X, O’Donoghue B, Visentin D, et al. Clinically applicable deep 
learning for diagnosis and referral in retinal disease. Nat Med 2018;24(9):1342–50. 
https://doi.org/10.1038/s41591-018-0107-6. 
[12] Cię˙zar K, Pochylski M. 2D fourier transform for global analysis and classification of 
meibomian gland images. Ocul Surf 2020;18(4):865–70. https://doi.org/10.1016/ 
j.jtos.2020.09.005. https://www.sciencedirect.com/science/article/pii/S1542012 
420301452. 
[13] Yedidya T, Hartley R, Guillon J-P, Kanagasingam Y. Automatic dry eye detection. 
In: International conference on medical image computing and computer-assisted 
intervention. Springer; 2007. p. 792–9. https://doi.org/10.1007/978-3-540- 
75757-3_96. 
[14] Nielsen KB, Lautrup ML, Andersen JK, Savarimuthu TR, Grauslund J. Deep 
learning-based algorithms in screening of diabetic retinopathy: a systematic review 
of diagnostic performance. Ophthalmol Retina 2019;3(4):294–304. https://doi. 
org/10.1016/j.oret.2018.10.014. 
[15] Pead E, Megaw R, Cameron J, Fleming A, Dhillon B, Trucco E, MacGillivray T. 
Automated detection of age-related macular degeneration in color fundus 
photography: a systematic review. Surv Ophthalmol 2019;64(4):498–511. https:// 
doi.org/10.1016/j.survophthal.2019.02.003. https://www.sciencedirect.com/sci 
ence/article/pii/S0039625718302078. 
[16] Gensure RH, Chiang MF, Campbell JP. Artificial Intelligence for retinopathy of 
prematurity. Curr Opin Ophthalmol 2020;31(5):312–7. https://doi.org/10.1097/ 
ICU.0 000000000000680. 
[17] Esteva A, Kuprel B, Novoa RA, Ko J, Swetter SM, Blau HM, Thrun S. Dermatologist- 
level classification of skin cancer with deep neural networks. Nature (London) 
2017;542:115–8. https://doi.org/10.1038/nature21056. 
[18] Lundberg SM, Nair B, Vavilala MS, Horibe M, Eisses MJ, Adams T, Liston DE, 
Low DK-W, Newman S-F, Kim J, Lee S-I. Explainable machine-learning predictions 
for the prevention of hypoxaemia during surgery. Nat Biomed Eng 2018;2:749–60. 
https://doi.org/10.1038/s41551-018-0304-0. 
[19] Gulshan V, Peng L, Coram M, Stumpe MC, Wu D, Narayanaswamy A, 
Venugopalan S, Widner K, Madams T, Cuadros J, Kim R, Raman R, Nelson PC, 
Mega JL, Webster DR. Development and validation of a deep learning algorithm for 
detection of diabetic retinopathy in retinal fundus pho- tographs. J Am Med Assoc 
2016;316(22):2402–10. https://doi.org/10.1001/jama.2016.17216. 
[20] Yousefi S, Takahashi H, Hayashi T, Tampo H, Inoda S, Arai Y, Tabuchi H, Asbell P. 
Predicting the likelihood of need for future keratoplasty intervention using 
artificial intelligence. Ocul Surf 2020;18(2):320–5. https://doi.org/10.1016/j. 
jtos.2020.02.008. https://www.sciencedirect.com/science/article/pii/S1542012 
420300276. 
[21] Hastie T, Tibshirani R, Friedman J. The elements of statistical learning: data 
mining, inference, and prediction. Springer Science & Business Media; 2009. 
https://doi.org/10.1111/j.1467-985X. 2010.00646_6.x. 
[22] Palacio-Ni˜no J-O, Berzal F. Evaluation metrics for unsupervised learning 
algorithms. 2019, 05667. arXiv: 1905. 
[23] Le Berre C, Sandborn WJ, Aridhi S, Devignes M-D, Fournier L, Smaïl-Tabbone M, 
Danese S, Peyrin-Biroulet L. Application of artificial intelligence to 
gastroenterology and hepatology. Gastroenterology 2020;158(1):76–94. https:// 
doi.org/10.1053/j.gastro.2019.08.058. 
[24] Thrall JH, Li X, Li Q, Cruz C, Do S, Dreyer K, Brink J. Artificial intelligence and 
machine learning in radiology: opportunities, challenges, pitfalls, and criteria for 
success. J Am Coll Radiol 2018;15(3):504–8. https://doi.org/10.1016/j. 
jacr.2017.12.026. 
[25] Thambawita VL, Strümke I, Hicks S, Riegler MA, Halvorsen P, Parasa S. Data 
augmentation using generative adversarial networks for creating realistic artificial 
colon polyp images: validation study by endoscopists. Gastrointest Endosc 2021;93 
(6):AB190. 
[26] Gianfrancesco MA, Tamang S, Yazdany J, Schmajuk G. Potential biases in machine 
learning al- gorithms using electronic health record data. JAMA Int Med 2018;178 
(11):1544–7. https://10.1001/jamainternmed.2018.3763. 
[27] G´eron A. Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: 
concepts, tools, and techniques to build intelligent systems. O’Reilly Media; 2019. 
[28] European Commission. Proposal for a regulation laying down harmonised rules on 
Artificial Intelligence. 4, https://digital-strategy.ec.europa.eu/en/library/propo 
sal-regulation-laying-down-harmonised-rules-artificial-intelligence; 2021. 
[29] U.S. Food & Drug Administration. Artificial intelligence and machine learning (AI/ 
ML) software as a medical device (SaMD) action plan. 2021. 1, https://www.fda. 
gov/medical-devices/software-medical-device-samd/artificial-intelligence-and 
-machine-learning-software-medical-device. 
[30] Aggarwal S, Kheirkhah A, Cavalcanti BM, Cruzat A, Jamali A, Hamrah P. 
Correlation of corneal immune cell changes with clinical severity in dry eye 
disease: an in vivo confocal microscopy study. Ocul Surf 2021;19:183–9. https:// 
doi.org/10.1016/j.jtos.2020.05.012. https://www.sciencedirect.com/science/ 
article/pii/S1542012420300963. 
[31] Deng X, Tian L, Liu Z, Zhou Y, Jie Y. A deep learning approach for the 
quantification of lower tear meniscus height. Biomed Signal Process Control 2021; 
68:102655. https://doi.org/10.1016/j.bspc.2021.102655. https://www.sciencedi 
rect.com/science/article/pii/S1746809421002524. 
[32] Elsawy A, Eleiwa T, Chase C, Ozcan E, Tolba M, Feuer W, Abdel-Mottaleb M, Abou 
Shousha M. Multidisease deep learning neural network for the diagnosis of corneal 
diseases. Am J Ophthalmol 2021;226:252–61. https://doi.org/10.1016/j. 
ajo.2021.01.018. https://www.sciencedirect.com/science/article/pii/S0002939 
421000398. 
[33] Khan ZK, Umar AI, Shirazi SH, Rasheed A, Qadir A, Gul S. Image based analysis of 
meibomian gland dysfunction using conditional generative adversarial neural 
network. BMJ Open Ophthalmol 2021;6(1). https://doi.org/10.1136/bmjophth- 
2020-000436. arXiv:https://bmjophth.bmj.com/content/6/1/e000436.full.pdf, 
https://bmjophth.bmj.com/content/6/1/e000436. 
[34] Xiao P, Luo Z, Deng Y, Wang G, Yuan J. An automated and multiparametric 
algorithm for objective analysis of meibography images. Quant Imag Med Surg 
2021;11(4):1586–99. https://doi.org/10.21037/qims-20-611. 
[35] Yeh C-H, Yu SX, Lin MC. Meibography phenotyping and classification from 
unsupervised discrim- inative feature learning. Transl Vis Sci Technol 2021;10(2). 
https://doi.org/10.1167/tvst.10.2.4. 4-4. arXiv:arvojournals.org/arvo/content 
\_public/journal/tvst/938516/i2164-2591-10-2-4\_16125 19083.80616.pdf. 
[36] da Cruz LB, Souza JC, de Sousa JA, Santos AM, de Paiva AC, de Almeida JDS, 
Silva AC, Junior GB, Gattass M. Interferometer eye image classification for dry eye 
categorization using phylogenetic diversity indexes for texture analysis. Comput 
Methods Progr Biomed 2020;188:105269. https://doi.org/10.1016/j. 
cmpb.2019.105269. https://www.sciencedirect.com/science/article/pii/S0 
169260719310995. 
[37] da Cruz LB, Souza JC, de Paiva AC, de Almeida JDS, Junior GB, Aires KRT, 
Silva AC, Gattass M. Tear film classification in interferometry eye images using 
phylogenetic diversity indexes and ripley’s k function. IEE J Biomed Health Inf 
2020;24(12):3491–8. https://doi.org/10.1109/JBHI.2020.3026940. 
[38] Fu P-I, Fang P-C, Ho R-W, Chao T-L, Cho W-H, Lai H-Y, Hsiao Y-T, Kuo M-T. 
Determina- tion of tear lipid film thickness based on a reflected placido disk tear 
film analyzer. Diagnostics 2020;10(6). https://doi.org/10.3390/ 
diagnostics10060353. https://www.mdpi.com/2075-4418/10/6/353. 
[39] Fujimoto K, Inomata T, Okumura Y, Iwata N, Fujio K, Eguchi A, Nagino K, 
Shokirova H, Kara- sawa M, Murakami A. Comparison of corneal thickness in 
patients with dry eye disease using the pentacam rotating scheimpflug camera and 
anterior segment optical coherence tomography. PLoS One 2020;15(2):e0228567. 
https://doi.org/10.1371/journal.pone.0228567. 
[40] Maruoka S, Tabuchi H, Nagasato D, Masumoto H, Chikama T, Kawai A, Oishi N, 
Maruyama T, Kato Y, Hayashi T, Katakami C. Deep neural network-based method 
for detecting obstructive meibomian gland dysfunction with in vivo laser confocal 
microscopy. Cornea 2020;39(6):720–5. https://doi.org/10.1097/ 
ICO.0000000000002279. 
[41] Prabhu SM, Chakiat A, S S, Vunnava KP, Shetty R. Deep learning segmentation and 
quantification of meibomian glands. Biomed Signal Process Control 2020;57: 
101776. https://doi.org/10.1016/j.bspc.2019.101776. https://www.sciencedirec 
t.com/science/article/pii/S174680941930357X. 
[42] Stegmann H, Werkmeister RM, Pfister M, Garh¨ofer G, Schmetterer L, dos 
Santos VA. Deep learn- ing segmentation for optical coherence tomography 
measurements of the lower tear meniscus. Biomed Opt Express 2020;11(3): 
1539–54. https://doi.org/10.1364/BOE.386228. http://www.osapublishing. 
org/boe/abstract1.JBO.17.8.086008. 
[65] Yedidya T, Carr P, Hartley R, Guillon J-P. Enforcing monotonic temporal evolution 
in dry eye images. In: International conference on medical image computing and 
computer-assisted intervention. Springer; 2009. p. 976–84. https://doi.org/ 
10.1007/978-3-642-04271-3_118. 
[66] Mathers WD, Choi D. Cluster analysis of patients with ocular surface disease, 
blepharitis, and dry eye. Arch Ophthalmol 2004;122(11):1700–4. https://doi.org/ 
10.1001/archo pht.122.11.1700. https://jamanetwork.com/journals/jamaophtha 
lmology/articlepdf/416676/eeb30021.pdf. 
[67] Cartes C, L´opez D, Salinas D, Segovia C, Ahumada C, P´erez N, Valenzuela F, 
Lanza N, Solís RL, Perez V, et al. Dry eye is matched by increased intrasubject 
variability in tear osmolarity as confirmed by machine learning approach. Arch Soc 
Esp Oftalmol 2019;94(7):337–42. https://doi.org/10.1016/j.oftal.2019.03.007. 
[68] Jung JH, Ji YW, Hwang HS, Oh JW, Kim HC, Lee HK, Kim KP. Proteomic analysis 
of human lacrimal and tear fluid in dry eye disease. Sci Rep 2017;7(1):1–11. 
https://doi.org/10.1038/s41598-017-13817-y. 
[69] Gonz´alez N, Iloro I, Soria J, Duran JA, Santamaría A, Elortza F, Su´arez T. Human 
tear pep- tide/protein profiling study of ocular surface diseases by spe-maldi-tof 
mass spectrometry analyses. EuPA Open Proteomics 2014;3:206–15. https://doi. 
org/10.1016/j.euprot.2014.02.016. https://www.sciencedirect.com/science/artic 
le/pii/S221296851400021X. 
[70] Grus FH, Podust VN, Bruns K, Lackner K, Fu S, Dalmasso EA, Wirthlin A, Pfeiffer N. 
SELDI- TOF-MS proteinchip array profiling of tears from patients with dry eye. 
Investig Ophthalmol Vis Sci 2005;46(3):863–76. https://doi.org/10.1167/iovs.04- 
0448. 
[71] Grus F-H, Augustin AJ. Analysis of tear protein patterns by a neural network as a 
diagnostical tool for the detection of dry eyes, ELECTROPHORESIS. Int J 1999;20 
(4-5):875–80. https://doi.org/10.1002/(SICI)1522-2683(19990101)20:4/5<875:: 
AID-ELPS875> 3.0.CO;2-V. 
[72] Grus F, Augustin A, Evangelou N, Toth-Sagi K. Analysis of tear-protein patterns as a 
diagnostic tool for the detection of dry eyes. Eur J Ophthalmol 1998;8(2):90–7. 
https://doi.org/10.1177/112067219800800207. 
[73] Choi HR, Lee JH, Lee HK, Song JS, Kim HC. Association between dyslipidemia and 
dry eye syndrome among the Korean middle-aged population. Cornea 2020;39(2): 
161–7. https://doi.org/10.1097/ICO.0000000000002133. 
[74] Nam SM, Peterson TA, Butte AJ, Seo KY, Han HW. Explanatory model of dry eye 
disease using health and nutrition examinations: machine learning and network- 
based factor analysis from a national survey. JMIR Med Inf 2020;8(2):e16153. 
https://doi.org/10.2196/16153. http://medinform.jmir.org/2020/2/e16153/. 
[75] Kaido M, Kawashima M, Yokoi N, Fukui M, Ichihashi Y, Kato H, Yamatsuji M, 
Nishida M, Fukagawa K, Kinoshita S, Tsubota K. Advanced dry eye screening for 
visual display terminal workers using functional visual acuity measurement: the 
moriguchi study. Br J Ophthalmol 2015;99(11):1488–92. https://doi.org/ 
10.1136/bjophthalmol-2015-306640. 
[76] Gullion J-PC. Tear film structure of the contact lens wearer. Ph.D. thesis. London: 
City University; 1990. 
[77] Holly FJ. Physical chemistry of the normal and disordered tear film. Trans 
Ophthalmol Soc U K 1985;104(Pt 4):374–80. 
[78] Rasband W. Imagej. http://imagej.nih.gov/ij/. 
[79] Cruzat M, Andrea, Qazi M, Yureeda, Hamrah M, Pedram. In vivo confocal 
microscopy of corneal nerves in health and disease. Ocul Surf 2016;15(1):15–47. 
https://doi.org/10.1016/j.jtos.2016.09.004. 
[80] Villani E, Marelli L, Dellavalle A, Serafino M, Nucci P. Latest evidences on 
meibomian gland dysfunction diagnosis and management. Ocul Surf 2020;18(4): 
871–92. https://doi.org/10.1016/j.jtos.2020.09.001. https://www.sciencedirect. 
com/science/article/pii/S1542012420301415. 
[81] Krizhevsky A, Sutskever I, Hinton GE. Imagenet classification with deep 
convolutional neural net- works. Commun ACM 2017;60(6):84–90. https://doi. 
org/10.1145/3065386. 
[82] Dartt DA. Dysfunctional neural regulation of lacrimal gland secretion and its role in 
the pathogenesis of dry eye syndromes. Ocul Surf 2004;2(2):76–91. https://doi. 
org/10.1016/S1542- 0124(12)70146-5. 
[83] Wan K, Chen L, Young A. Depression and anxiety in dry eye disease: a systematic 
review and meta- analysis. Eye 2016;30:1558–67. https://doi.org/10.1038/ 
eye.2016.186. 
[84] Ambaw YA, Timbadia DP, Raida M, Torta F, Wenk MR, Tong L. Profile of tear lipid 
mediator as a biomarker of inflammation for meibomian gland dysfunction and 
ocular surface diseases: standard operating procedures. The Ocular Surface; 2020. 
https://doi.org/10.1016/j.jtos.2020.09.0 08. https://www.sciencedirect.com/sci 
ence/article/pii/S1542012420301488. 
[85] D’Amour A, Heller K, Moldovan D, Adlam B, Alipanahi B, Beutel A, Chen C, 
Deaton J, Eisen- stein J, Hoffman MD, et al. Underspecification presents challenges 
for credibility in modern machine learning. arXiv preprint arXiv:2011.03395. 
2020. 
[86] Kelly CJ, Karthikesalingam A, Suleyman M, Corrado G, King D. Key challenges for 
delivering clinical impact with artificial intelligence. BMC Med 2019;17(1):1–9. 
A.M. Storås et al.                                                                                                                                                                                                                               
",https://doi.org/10.1016/j.jtos.2021.11.004,doc18,".cfm?URI=boe-11-3-1539. 
[43] Wei S, Ren X, Wang Y, Chou Y, Li X. Therapeutic effect of intense pulsed light (ipl) 
combined with meibomian gland expression (mgx) on meibomian gland 
dysfunction (mgd). J Ophthalmol 2020;2020. https://doi.org/10.1155/2020/ 
3684963. 
[44] Giannaccare G, Pellegrini M, Sebastiani S, Moscardelli F, Versura P, Campos EC. In 
vivo confo- cal microscopy morphometric analysis of corneal subbasal nerve plexus 
in dry eye disease using newly developed fully automated system. Graefe’s Arch 
Clin Exp Ophthalmol 2019;257(3):583–9. https://doi-org.ezproxy.uio.no/10.1 
007/s00417-018-04225-7. 
[45] Chen X, Graham J, Dabbah MA, Petropoulos IN, Tavakoli M, Malik RA. An 
automatic tool for quantification of nerve fibers in corneal confocal microscopy 
images. IEEE (Inst Electr Electron Eng) Trans Biomed Eng 2017;64(4):786–94. 
https://doi.org/10.1109/TBME.2016.2573642. 
[46] Dabbah M, Graham J, Petropoulos I, Tavakoli M, Malik R. Automatic analysis of 
diabetic peripheral neuropathy using multi-scale quantitative morphology of nerve 
fibres in corneal confocal microscopy imaging. Med Image Anal 2011;15(5): 
738–47. https://doi.org/10.1016/j.media.20 11.05.016. https://www.sciencedi 
rect.com/science/article/pii/S1361841511000806. 
[47] Llorens-Quintana C, Rico-Del-Viejo L, Syga P, Madrid-Costa D, Iskander DR. 
A novel automated approach for infrared-based assessment of meibomian gland 
morphology. Transl Vis Sci Technol 2019;8(4). https://doi.org/10.1167/ 
tvst.8.4.17. 17-17. 
[48] Wang J, Yeh TN, Chakraborty R, Yu SX, Lin MC. A deep learning approach for 
meibomian gland atrophy evaluation in meibography images. Transl Vis Sci 
Technol 2019;8(6). https://doi.org/10.1167/tvst.8.6.37. 37-37. 
A.M. Storås et al.                                                                                                                                                                                                                               
 The Ocular Surface 23 (2022) 74–86
86
[49] Yabusaki K, Arita R, Yamauchi T. Automated classification of dry eye type 
analyzing interference fringe color images of tear film using machine learning 
techniques. Model Artif Intell Ophthalmol 2019;2(3):28–35. https://doi.org/ 
10.35119/maio.v2i3.90. 
[50] Yang J, Zhu X, Liu Y, Jiang X, Fu J, Ren X, Li K, Qiu W, Li X, Yao J. TMIS: a new 
image-based software application for the measurement of tear meniscus height. 
Acta Ophthalmol 2019;97(7):e973–80. https://doi.org/10.1111/aos.14107. 
https://onlinelibrary.wiley.com/doi/abs/10.1111/aos.14107. 
[51] Szyperski PD. Comparative study on fractal analysis of interferometry images with 
application to tear film surface quality assessment. Appl Opt 2018;57(16):4491–8. 
https://doi.org/10.1364/AO.57.004491. 
[52] Hwang H, Jeon H-J, Yow KC, Hwang HS, Chung E. Image-based quantitative 
analysis of tear film lipid layer thickness for meibomian gland evaluation. Biomed 
Eng Online 2017;16(1):1–15. https://doi.org/10.1186/s12938-017-0426-8. 
[53] Koprowski R, Tian L, Olczyk P. A clinical utility assessment of the automatic 
measurement method of the quality of meibomian glands. Biomed Eng Online 
2017;16(82):1–13. https://doi.org/10.1186/s12938-017-0373-4. 
[54] Peteiro-Barral D, Remeseiro B, M´endez R, Penedo MG. Evaluation of an automatic 
dry eye test using mcdm methods and rank correlation. Med Biol Eng Comput 
2017;55(4):527–36. https://doi.org/10.1007/s11517-016-1534-5. 
[55] Koprowski R, Wilczy´nski S, Olczyk P, Nowi´nska A, Węglarz B, Wylęgała E. 
A quantitative method for assessing the quality of meibomian glands. Comput Biol 
Med 2016;75:130–8. https://doi.org/10.1016/j.compbiomed.2016.06.001. 
https://www.sciencedirect.com/science/article/pii/S0010482516301391. 
[56] Remeseiro B, Barreira N, García-Resúa C, Lira M, Gir´aldez MJ, Yebra-Pimentel E, 
Penedo MG. ideas: a web-based system for dry eye assessment. Comput Methods 
Progr Biomed 2016;130:186–97. https://doi.org/10.1016/j.cmpb.2016.02.015. 
https://www.sciencedirect.com/science/article/pii/S0169260715301644. 
[57] Remeseiro B, Mosquera A, Penedo MG. CASDES: a computer-aided system to 
support dry eye diagnosis based on tear film maps. IEE J Biomed Health Inf 2016; 
20(3):936–43. https://doi.org/10.1109/JBHI.2015.2419316. 
[58] Kanellopoulos AJ, Asimellis G. In vivo 3-dimensional corneal epithelial thickness 
mapping as an indicator of dry eye: preliminary clinical assessment. Am J 
Ophthalmol 2014;157(1):63–8. https://doi.org/10.1016/j.ajo.2013.08.025. e2, 
https://www.sciencedirect.com/science/article/pii/S0002939413005850. 
[59] Ramos L, Barreira N, Pena-Verdeal H, Gir´aldez M. Automatic assessment of tear 
film break-up dynamics. Stud Health Technol Inf 2014;207:173–82. https://doi. 
org/10.3233/978-1-61499-474-9-173. 
[60] Ramos L, Barreira N, Mosquera A, Penedo M, Yebra-Pimentel E, García-Resúa C. 
Analysis of parameters for the automatic computation of the tear film break-up 
time test based on cclru standards. Comput Methods Progr Biomed 2014;113(3): 
715–24. https://doi.org/10.1016/j.cmpb.2013.12.003. https://www.sciencedirec 
t.com/science/article/pii/S0169260713003921. 
[61] Remeseiro B, Bolon-Canedo V, Peteiro-Barral D, Alonso-Betanzos A, Guijarro- 
Berdi˜nas B, Mos- quera A, Penedo MG, S´anchez-Maro˜no N. A methodology for 
improving tear film lipid layer classi- fication. IEE J Biomed Health Inf 2014;18(4): 
1485–93. https://doi.org/10.1109/JBHI.2013.2294732. 
[62] García-Resúa C, Fern´andez MJG, Penedo MFG, Calvo D, Penas M, Yebra- 
Pimentel E. New software application for clarifying tear film lipid layer patterns. 
Cornea 2013;32(4):538–46. https://doi.org/10.1097/ICO.0b013e31824d0d04. 
[63] Rodriguez JD, Johnston PR, Ousler GW, Smith LM, Abelson MB. Automated 
grading system for evaluation of ocular redness associated with dry eye. Clin 
Ophthalmol 2013;7:1197–204. https://doi.org/10.2147/OPTH.S39703. 
[64] Koh YW, Celik T, Lee HK, Petznick A, Tong LH. Detection of meibomian glands and 
classification of meibography images. J Biomed Opt 2012;17(8):086008. https:// 
doi.org/10.1117/","The Ocular Surface 23 74–86 Available online 27 November 2021 1542-0124/© 2021 Elsevier Inc. All rights reserved. Review Article Artificial intelligence in dry eye disease Andrea M. Storås a,e,*, Inga Strümke a, Michael A. Riegler a, Jakob Grauslund b,c,d, Hugo L. Hammer a,e, Anis Yazidi e, Pål Halvorsen a,e, Kjell G. Gundersen h, Tor P. Utheim e,f,g, Catherine J. Jackson h a SimulaMet, Oslo, Norway b Department of Ophthalmology, Odense University Hospital, Odense, Denmark c Department of Clinical Research, University of Southern Denmark, Odense, Denmark d Department of Ophthalmology, Vestfold University Trust, Tønsberg, Norway e Department of Computer Science, Oslo Metropolitan University, Norway f Department of Medical Biochemistry, Oslo University Hospital, Norway g Department of Ophthalmology, Oslo University Hospital, Norway h Ifocus, Haugesund, Norway A R T I C L E I N F O Keywords: Dry eye disease Artificial intelligence Machine learning A B S T R A C T Dry eye disease (DED) has a prevalence of between 5 and 50%, depending on the diagnostic criteria used and population under study. However, it remains one of the most underdiagnosed and undertreated conditions in ophthalmology. Many tests used in the diagnosis of DED rely on an experienced observer for image interpre­ tation, which may be considered subjective and result in variation in diagnosis. Since artificial intelligence (AI) systems are capable of advanced problem solving, use of such techniques could lead to more objective diagnosis. Although the term ‘AI’ is commonly used, recent success in its applications to medicine is mainly due to ad­ vancements in the sub-field of machine learning, which has been used to automatically classify images and predict medical outcomes. Powerful machine learning techniques have been harnessed to understand nuances in patient data and medical images, aiming for consistent diagnosis and stratification of disease severity. This is the first literature review on the use of AI in DED. We provide a brief introduction to AI, report its current use in DED research and its potential for application in the clinic. Our review found that AI has been employed in a wide range of DED clinical tests and research applications, primarily for interpretation of interferometry, slit-lamp and meibography images. While initial results are promising, much work is still needed on model development, clinical testing and standardisation. 1. Introduction Dry eye disease (DED) is one of the most common eye diseases worldwide, with a prevalence of between 5 and 50%, depending on the diagnostic criteria used and study population [1]. Yet, although symp­ toms stemming from DED are reported as the most common reason to seek medical eye care [1], it is considered one of the most under­ diagnosed and undertreated conditions in ophthalmology [2]. Symp­ toms of DED include eye irritation, photophobia and fluctuating vision. The condition can be painful and might result in lasting damage to the cornea through irritation of the ocular surface. Epidemiological studies indicate that DED is most prevalent in women [3] and increases with age [1]. However, the incidence of DED is likely to increase in all age groups in coming years due to longer screen time and more prevalent use of contact lenses, which are both risk factors [4]. Other risk factors include diabetes mellitus [5] and exposure to air-pollution [6]. DED can have a substantial effect on the quality of life, and may impose significant direct and indirect public health costs as well as personal economic burden due to reduced work productivity. DED is divided into two subtypes defined by the underlying mech­ anism of the disease: (i) aqueous deficient DED, where tear production from the lacrimal gland is insufficient and (ii) evaporative DED (the most common form), which is typically caused by dysfunctional mei­ bomian glands in the eyelids. Meibomian glands are responsible for supplying meibum, which is a concentrated substance that normally covers the surface of the cornea to form a protective superficial lipid * Corresponding author. SimulaMet, Oslo, Norway. E-mail address: andrea@simula.no (A.M. Storås). Contents lists available at ScienceDirect The Ocular Surface journal homepage: Received 9 July 2021; Received in revised form 8 November 2021; Accepted 9 November 2021 The Ocular Surface 23 74–86 75 layer that guards against evaporation of the underlying tear film. The ability to reliably distinguish between aqueous deficient and evapora­ tive DED, their respective severity levels and mixed aqueous/evapora­ tive forms is important in deciding the ideal modality of treatment. A fast and accurate diagnosis relieves patient discomfort and also spares them unnecessary expense and exposure to potential side effects asso­ ciated with some treatments. A tailor made treatment plan can yield improved treatment response and maximize health provider efficiency. The main clinical signs of DED are decreased tear volume, more rapid break-up of the tear film (fluorescein tear break-up time (TBUT)) and microwounds of the ocular surface [7]. In the healthy eye, the tear film naturally ‘breaks up’ after 10 s and the protective tear film is reformed with blinking. Available diagnostic tests often do not correlate with the severity of clinical symptoms reported by the patient. No single clinical test is considered definitive in the diagnosis of DED [1]. Therefore, multiple tests are typically used in combination and supplemented by information gathered on patient symptoms, recorded through ques­ tionnaires. These tests demand a significant amount of time and re­ sources at the clinic. Tests for determining the physical parameters of tears include TBUT, the Schirmer’s test, tear osmolarity and tear meniscus height. Other useful tests in DED diagnosis include ocular surface staining, corneal sensibility, interblink frequency, corneal sur­ face topography, interferometry, aberrometry and imaging techniques such as meibography and in vivo confocal microscopy (IVCM), as well as visual function tests. Artificial intelligence (AI) was defined in 1955 as “the science and engineering of making intelligent ma-chines” [8], where intelligence is the “ability to achieve goals in a wide range of environments” [9]. Within AI, machine learning denotes a class of algorithms capable of learning from data rather than being programmed with explicit rules. AI, and particularly machine learning, is increasingly becoming an integral part of health care systems. The sub-field of machine learning known as deep learning uses deep artificial neural networks, and has gained increased attention in recent years, especially for its image and text recognition abilities. In the field of ophthalmology, deep learning has so far mainly been used in the analysis of data from the retina to segment regions of interest in images, automate diagnosis and predict disease outcomes [10]. For instance, the combination of deep learning and op­ tical coherence tomography (OCT) technologies has allowed reliable detection of retinal diseases and improved diagnosis [11]. Machine learning also has potential for use in the diagnosis and treatment of anterior segment diseases, such as DED and has already found its way into the field with methods such as presented by Ciezar et al. [12]. Many of the tests used for DED diagnosis and follow-up rely on the experience of the observer for interpretation of images, which may be considered subjective [13]. AI tools can be used to interpret images automatically and objectively, saving time and providing consistency in diagnosis. Several reviews have been published that discuss the application of AI in eye disease, including screening for diabetic retinopathy [14], detection of age-related macular degeneration [15] and diagnosis of retinopathy of prematurity [16]. We are, however, not aware of any review on AI in DED. In this article, we therefore provide a critical re­ view of the use of AI systems developed within the field of DED, discuss their current use and highlight future work. 2. Artificial intelligence AI is informational technology capable of performing activities that require intelligence. It has gained substantial popularity within the field of medicine due to its ability to solve ubiquitous medical problems, such as classification of skin cancer [17], prediction of hypoxemia during surgeries [18], identification of diabetic retinopathy [19] and prediction of risk for future need of keratoplasty [20]. Machine learning is a sub-field of AI encompassing algorithms capable of learning from data, without being explicitly programmed. All AI systems used in the studies included in this review, fall within the class of machine learning. The process by which a machine learning algorithm learns from data is referred to as training. The outcome of the training process is a machine learning model, and the model’s output is referred to as predictions. Different learning algorithms are categorised according to the type of data they use, and referred to as supervised, unsupervised and rein­ forcement learning. The latter is excluded from this review, as none of the studies use it, while the two former are introduced in this section. A complete overview of the algorithms encountered in the reviewed studies is provided in Fig. 1, sorted according to the categories described below. 2.1. Supervised learning Supervised learning denotes the learning process of an algorithm using labelled data, meaning data that contains the target value for each data instance, e.g., tear film lipid layer category. The learning process involves extracting patterns linking the input variables and the target outcome. The performance of the resulting model is evaluated by letting it predict on a previously unseen data set, and comparing the predictions to the true data labels. See Section 2.5 for a brief discussion of evaluation metrics. Supervised learning algorithms can perform regression and classification, where regression involves predicting a numerical value for a data instance, and classification involves assigning data instances to predefined categories. Fig. 1 contains an overview of supervised learning algorithms encountered in the reviewed studies. 2.2. Unsupervised learning Unsupervised learning denotes the training process of an algorithm using unlabelled data, i.e., data not containing target values. The task of the learning algorithm is to find patterns or data groupings by con­ structing a compact representation of the data. This type of machine learning is commonly used for grouping observations together, detecting relationships between input variables, and for dimensionality reduction. As unsupervised learning data contains no labels, a measure of model performance depends on considerations outside the data [see 21, chap. 14], e.g., how the task would have been solved by someone in the real world. For clustering algorithms, similarity or dissimilarity measures such as the distance between cluster points can be used to measure performance, but whether this is relevant depends on the task [22]. Unsupervised algorithms encountered in the reviewed studies can be divided into those performing clustering and those used for dimen­ sionality reduction, see Fig. 1 for an overview. 2.3. Artificial neural networks and deep learning Artificial neural networks are loosely inspired by the neurological networks in the biological brain, and consist of artificial neurons organised in layers. How the layers are organised within the network is referred to as its architecture. Artificial neural networks have one input layer, responsible for passing the data to the network, and one or more hidden layers. Networks with more than one hidden layer are called deep neural networks. The final layer is the output layer, providing the output of the entire network. Deep learning is a sub-field of machine learning involving training deep neural networks, which can be done both in a supervised and unsupervised manner. We encounter several deep architectures in the reviewed studies. The two more advanced types are convolutional neural networks (CNNs) and generative adver­ sarial networks (GANs). CNN denotes the commonly used architecture for image analysis and object detection problems, named for having so- called convolutional layers that act as filters identifying relevant fea­ tures in images. CNNs have gained popularity recently and all of the reviewed studies that apply CNNs were published in 2019 or later. Advanced deep learning techniques will most likely replace the estab­ lished image analysis methods. This trend has been observed within other medical fields such as gastrointestinal diseases and radiology [23, A.M. Storås et al. The Ocular Surface 23 74–86 76 24]. A GAN is a combination of two neural networks: A generator and a discriminator competing against each other. The goal of the generator is to produce fake data similar to a set of real data. The discriminator re­ ceives both real data and the fake data from the generator, and its goal is to discriminate the two. GANs can among other things be used to generate synthetic medical data, alleviating privacy concerns [25]. 2.4. Workflow for model development and validation The data used for developing machine learning models is ideally divided into three independent parts: A training set, a validation set and a test set. The training set is used to tune the model, the validation set to evaluate performance during training, and the test set to evaluate the final model. A more advanced form of training and validation, is k-fold cross-validation. Here, the data is split into k parts, of which one part is set aside for validation, while the model is trained on the remaining data. This is repeated k times, and each time a different part of the data is used for validation. The model performance can be calculated as the average performance for the k different models [see 21, chap. 7]. It is considered good practice to not use the test data during model devel­ opment and vice versa, the model should not be tuned further once it has been evaluated on the test data [see 21, chap.7]. In cases of class imbalance, i.e., unequal number of instances from the different classes, there is a risk of developing a model that favors the prevalent class. If the data is stratified for training and testing, this might not be captured during testing. Class imbalance is common in medical data sets, as there are for instance usually more healthy than ill people in the population [26]. Whether to choose a class distribution that represents the popu­ lation, a balanced or some other distribution depends on the objective. Various performance scores should regardless always be used to provide a full picture of the model’s performance. 2.5. Performance scores In order to assess how well a machine learning model performs, its performance can be assigned a score. In supervised learning, this is based on the model’s output compared to the desired output. Here, we introduce scores used most frequently in the reviewed studies. Their definitions as well as the remaining scores used are provided in Ap­ pendix A.1. A commonly used performance score in classification is accuracy, Equation (A.3), which denotes the proportion of correctly predicted instances. Its use is inappropriate in cases of strong class imbalance, as it can reach high values if the model always predicts the prevalent class. The sensitivity, also known as recall, Equation (A.4), denotes the true positive rate. If the goal is to detect all positive in­ stances, a high sensitivity indicates success. The precision, Equation (A.5), denotes the positive predictive value. The specificity, Equation (A.6), denotes the true negative rate, and is the negative class version of the sensitivity. The F1 score, Equation (A.7), is the harmonic mean be­ tween the sensitivity and the precision. It is not symmetric between the classes, meaning it is dependent on which class is defined as positive. Image segmentation involves partitioning the pixels in an image into segments [27]. This can for example be used to place all pixels repre­ senting the pupil into the same segment while pixels representing the iris are placed in another segment. The identified segments can then be compared to manual annotations. Performance scores used include the Average Pompeiu-Hausdorff distance, (A.17), the Jaccard index and the support, all described in Appendix A.1. 2.6. AI regulation Approved AI devices will be a major part of the medical service landscape in the future. Currently, many countries are actively working on releasing AI regulations for healthcare, including the European Union (EU), the United States, China, South Korea and Japan. On April 21, 2021, the EU released a proposal for a regulatory framework for AI [28]. The US Food and Drug Administration (FDA) is also working on AI legislation for healthcare [29]. In the framework proposed by the EU, AI systems are divided into the four categories low risk, minimal risk, high risk and unacceptable risk [28]. AI systems that fall into the high risk category are expected to be subject to strict requirements, including data governance, technical documentation, transparency and provision of information to users, human oversight, robustness and cyber security, and accuracy. It is highly likely that medical devices using AI will end up in the high risk category. Looking at the legislation proposals [28,29] from an AI research perspective, it is clear that explainable AI, transparency, un­ certainty assessment, robustness against adversarial attacks, high qual­ ity of data sets, proper performance assessment, continuous post-deployment monitoring, human oversight and interaction be­ tween AI systems and humans, will be major research topics for the development of AI in healthcare. 3. Methods 3.1. Search methods A systematic literature search was performed in PubMed and Embase in the period between March 20 and May 21, 2021. The goal was to retrieve as many studies as possible applying machine learning to DED related data. The following keywords were used: All combinations of “dry eye” and “meibomian gland dysfunction” with “artificial intelli­ gence”, “machine learning”, “computer vision”, “image recognition”, “bayesian network”, “decision tree”, “neural network”, “image based Fig. 1. An overview of the machine learning algorithms used in the reviewed studies. A.M. Storås et al. The Ocular Surface 23 74–86 77 analysis”, “gradient boosting”, “gradient boosting machine” and “auto­ matic detection”. In addition, searches for “ocular surface” combined with both “artificial intelligence” and “machine learning” were made. See also an overview of the search terms and combinations in Fig. 2. No time period limitations were applied for any of the searches. 3.2. Selection criteria The studies to include in the review had to be available in English in full-text. Studies not investigating the medical aspects of DED were excluded (e.g., other ocular diseases and cost analyses of DED). More­ over, the studies had to describe the use of a machine learning model in order to be considered. Reviews were not considered. The studies were selected in a three-step process. One review author screened the titles on the basis of the inclusion criteria. The full-texts were then retrieved and studied for relevance. The search gave 640 studies in total, of which 111 were regarded as relevant according to the selection criteria. After removing duplicates, 45 studies were left. The three-step process is shown in Fig. 3a. 4. Artificial intelligence in dry eye disease 4.1. Summary of the studies Most studies were published in recent years, especially after 2014, see Fig. 3b. An overview of the studies is provided in Tables 1-4 for the clinical, biochemical and demographical studies, respectively. Infor­ mation on the data used in each study is shown in Table 5. We grouped studies according to the type of clinical test or type of study: TBUT, interferometry and slit-lamp images, IVCM, meibography, tear osmo­ larity, proteomics analysis, OCT, population surveys and other clinical tests. We found most studies employed machine learning for interpre­ tation of interferometry, slit-lamp and meibography images. 4.2. Fluorescein tear break-up time Shorter break-up time indicates an unstable tear film and higher probability of DED. Machine learning has been employed to detect dry areas in TBUT videos and estimate TBUT [13,59,60,65]. Use of the Levenberg-Marquardt algorithm to detect dry areas achieved an accu­ racy of 91% compared to assessments by an optometrist [13]. Applica­ tion of Markov random fields to label pixels based on degree of dryness was used to estimate TBUT resulting in an average difference of 2.34 s compared to clinician assessments [65]. Polynomial functions have also been used to determine dry areas, where threshold values were fine-tuned before estimation of TBUT [59]. This method resulted in more than 90% of the videos deviating by less than ±2.5 s compared to analyses done by four experts on videos not used for training [60]. Taken together, these studies indicate that TBUT values obtained using auto­ matic methods are within an acceptable range compared to experts. However, we only found four studies, all of them including a small number of subjects. Further studies are needed to verify the findings and to test models on external data. 4.3. Interferometry and slit-lamp images Interferometry is a useful tool that gives a snapshot of the status of the tear film lipid layer, which can be used to aid diagnosis of DED. Machine learning systems have been applied to interferometry and slit- lamp images for lipid layer classification based on morphological properties [36,37,54,56,57,61,62], estimation of the lipid layer thick­ ness [38,52], diagnosis of DED [49,51], determination of ocular redness [63] and estimation of tear meniscus height [31,50]. Diagnosis of DED can be based on the following morphological properties: open meshwork, closed mesh-work, wave, amorphous and color fringe [76]. Most studies used these properties to automatically classify interferometer lipid layer images using machine learning. Garcia et al. used a K-nearest neighbors model trained to classify images resulting in an accuracy of 86.2% [62]. Remeseiro et al. explored various support vector machine (SVM) models for use in final classification [56, 57,61]. In one of the studies, the same data was used for training and testing, which is not ideal [57]. Another study did not report the data their system was trained on [56]. Peteiro et al. evaluated images using five different machine learning models [54]. In this study, the amor­ phous property was not included as one of possible classifications, as opposed to the other studies. A simple neural network achieved the overall best performance with an accuracy of 96%. However, because leave-one-out cross validation was applied, the model may have over­ fitted on the training data [21]. da Cruz et al. compared six different machine learning models and found that the random forest was the best classifier, regardless of the pre-processing steps used [36,37]. The highest performance was achieved by application of Ripley’s K function in the image pre-processing phase, and Greedy Stepwise technique used simultaneously with the machine learning models for feature selection [37]. Since all models were evaluated with cross validation, the system should be externally evaluated on new images before being considered Fig. 2. Search term combinations used in the literature search. Three of the studies found in the searches including “ocular surface” were also found among the studies in the searches including “dry eye”. A.M. Storås et al. The Ocular Surface 23 74–86 78 for routine use in the clinic. Hwang et al. investigated whether tear film lipid layer thickness can be used to distinguish meibomian gland dysfunction (MGD) severity groups [52]. Machine learning was used to estimate the thickness from Lipiscanner and slit-lamp videos with promising results. Images were pre-processed and the flood-fill algo-rithm and canny edge detection were applied to locate and extract the iris from the pupil. A significant difference between two MGD severity groups was detected, suggesting that the technique could be used for the evaluation of MGD. Keratograph images can also be used to determine tear film lipid layer thickness. Comparison of two different image analysis methods using a generalized linear model showed that there was a high correlation between the two techniques [38]. The authors concluded that the simple technique was sufficient for evaluation of tear film lipid layer thickness. However, only 28 subjects were included in the study. The use of fractal dimension estimation techniques was investigated for feature extraction from interferometer videos for diagnosis of DED [51]. The technique was found to be fast and had an area under the receiver operating characteristic curve (AUC) value of 0.786, compared to a value of 0.824 for an established method (See Appendix A.1 and Figure A.4a for a description of the receiver operating characteristic curve). Tear film lipid interferometer images were analysed using an SVM [49]. Extracted features from the images were passed to the SVM model, which classified the images as either healthy, aqueous-deficient DED, or evaporative DED. The agreement between the model and a trained ophthalmologist was high, with a reported Kappa value of 0.82. The model performed best when detecting aqueous-deficient DED. Ocular redness is an important indicator of dry eyes. Only one of the reviewed studies described an auto-mated system for evaluation of ocular redness associated with DED [63]. Slit-lamp images were ac­ quired from 26 subjects with a history of DED. Features representing the ocular redness intensity and horizontal vascular component were extracted with a Sobel operator. A multiple linear regression model was trained to predict ocular redness based on the extracted features. The system achieved an accuracy of 100%. The authors suggested that an objective system like this could replace subjective gradings by clinicians in multicentered clinical studies. The tear meniscus contains 75-90% of the aqueous tear volume [77]. Consequently, the tear meniscus height can be used as a quantitative indicator for DED caused by aqueous deficiency. When connected component labelling was applied to slit-lamp images, the Pearson’s correlation between the predicted meniscus heights and an established software methodology (ImageJ [78]) was high, ranging between 0.626 and 0.847 [50]. The machine learning system was found to be more accurate than four experienced ophthalmologists. The tear meniscus height can also be estimated from keratography images using a CNN [31]. The automatic machine learning system achieved an accuracy of 82.5% and was found to be more effective and consistent than a well-trained clinician working with limited time. Many of the studies apply SVM as their type of machine learning model without testing how other machine learning models perform. However, three of the studies tested several types of models and found that SVM did not perform the best [36,37,54]. It is difficult to compare the studies due to different applications and evaluation metrics. Despite promising results, most of the studies [36-38,50-52,54,57,61-63] did not evaluate their systems on external data. The systems should be tested on independent data before they can be considered for clinical application. Moreover, some studies were small [38,63] or pilots [31,50], and the suggested models should be tested on a larger number of subjects. 4.4. In vivo confocal microscopy IVCM is a valuable non-invasive tool used to examine the corneal nerves and other features of the cornea [79]. IVCM images were used in a small study to assess characteristics of the corneal subbasal nerve plexus for diagnosis of DED [44]. Application of random forest and a deep neural network [45] gave promising results with an AUC value of 0.828 for detecting DED [44]. IVCM images of corneal nerves can also be analysed by machine learning models to estimate the length of the nerve fiber [43]. Authors used a CNN with a U-net architecture that had been pre-trained on more than 5, 000 IVCM images of corneal nerves. The model showed that nerve fiber length was significantly longer after intense pulsed light treatment in MGD patients, which agreed with manual annotations from an experienced investigator with an AUC value of 0.96 and a sensitivity of 0.96. High-resolution IVCM images were also used to detect obstructive MGD [40]. Combinations of nine different CNNs were trained and tested on the images using 5-fold cross validation. Classification by the models was compared to diagnosis made by three eyelid specialists. The best performance was achieved when four different models were combined, with high sensitivity, specificity and AUC values, see Table 1. These promising results suggest that CNNs can be useful for detection and evaluation of MGD. Deep learning methods such as CNNs have the advantage that feature extraction from the images prior to analysis is not required as this is performed automatically by the model. IVCM images have been investigated for changes in immune cells across different severities of DED for diagnostic purposes [30]. A generalized linear model showed significant differences in dendritic cell density and morphology between DED patients and healthy individuals, but not between the different DED subgroups, see Table 1. While results using machine learning to interpret IVCM images are promising, larger clinical studies are needed to validate findings before clinical use can be considered. 4.5. Meibography The meibomian glands are responsible for producing meibum, important for protecting the tear fluid from evaporation. Reduced Fig. 3. (a) Illustration of the three steps in the study selection process and number of studies (N) included in each step, and (b) the number of studies published over time, counting the studies included in this review. A.M. Storås et al. The Ocular Surface 23 74–86 79 Table 1 Overview of the reviewed studies using clinical investigations, part 1 of 2. Study Objective N Clinical Tests Type of Data Type of Algorithm Performance Score(s) Aggarwal S et al. [30] DED mechanism, effect of therapy 199 Subjective symptoms, Schirmer’s test with anasthesia, TBUT, vital staining of cornea and conjunctiva, laser IVCM images, subbasal layer of cornea: DC density and morphology Images of cornea GLM, MLR GLM: p-values < 0.05 for DC density and number of DCs, MLR: p-values < 0.05 between DC density and CFS, number of DCs and CFS, DC size and CFS, DC density and conjunctival staining, number of DCs and TBUT, corresponding beta-coefficients = 0.20, −0.23, 0.36, 0.24 and −0.18 Deng X et al. [31] Estimate tear meniscus height 217 Oculus Keratograph Tear meniscus images CNN (U-net) Accuracy = 82.5%, sensitivity = 0.899, precision = 0.911, F1 score = 0.901 Elsawy A et al. [32] Diagnose DED 547 AS-OCT Ocular surface images Pretrained CNN (VGG19) AUCROC = 0.99 (model 1) and 0.98 (model 2), AUCPRC = 0.96 (model 1) and 0.94 (model 2), F1 score = 0.90 (model 1) and 0.86 (model 2)* Khan ZK et al. [33] Detect MGD 112 Meibomian gland 3D IR-images, lower and upper eyelid Meibomian gland images GAN F1 score = 0.825, P-HD = 4.611, aggregated JI = 0.664, r = 0.962 (clincian1) and 0.968 (clinician2), p-values < 0.001, mean difference = 0.96 (clincian1) and 0.95 (clincian2) Xiao P et al. [34] Detect MGD 15 (images) Oculus Keratograph IR meibography images Prewitt operator, Graham scan algorithm, fragmentation algorithm and SA (used sequentially) Gland area: KI = 0.94, FPR = 6.02%, FNR = 6.43%. Gland segmentation: KI = 0.87, FPR = 4.35%, FNR = 18.61%* Yeh C-H et al. [35] Detect MGD 706 (images) Oculus Keratograph IR meibography images Nonparametric instance discrimination, pretrained CNN (ImageNet), hierarchical clustering Accuracy: meiboscore grading = 80.9%, 2-class classification = 85.2%, 3-class classification = 81.3%, 4-class classification = 80.8%* da Cruz LB et al. [36] Classify tear film patterns 106 (images) Doane interferometer Tear film lipid layer images SVM, RF, RT, Naive Bayes, DNN, simple NN RF: accuracy = 97.54%, SD = 0.51%, F1 score = 0.97, KI = 0.96, AUCROC = 0.99*** da Cruz LB et al. [37] Classify tear film patterns 106 (images) Doane interferometer Tear film lipid layer images SVM, RF, RT, Naive Bayes, DNN, simple NN RF: accuracy = 99.622%, SD = 0.843%, F1 score = 0.996, KI = 0.995, AUCROC = 0.999*** Fu P-I et al. [38] Compare 2 methods 28 Oculus Keratograph Tear film lipid layer images (with and without preprocessing) GLM beta-coefficients = 0.6, 10 Fujimoto K et al. [39] Compare 2 methods 195 Pentacam vs AS-OCT CCT, TCT, thinnest point of cornea Multivariable regression Severe DED: beta-coefficients = 7.029 (CCT) and 6.958 (TCT), p- values = 0.002 (CCT) and 0.049 (TCT), 95% CI = 2.528-11.530 (CCT) and 0.037-13.879 (TCT) Maruoka S et al. [40] Detect MGD 221 IVCM Meibomian gland images Combinations of 9 CNNs Single CNN: AUROC = 0.966, sensitivity = 0.942, specificity = 0.821, ensemble CNNs: AUROC = 0.981, sensitivity = 0.921, specificity = 0.988 Prabhu SM et al. [41] Quantify and detect MGD 400 (images) Oculus Keratograph, digital camera Meibomian gland images CNN (U-net) p-values > 0.005 between model output and clinical experts Stegmann H et al. [42] Detect tear meniscus in images 10 Optical coherence tomography Tear meniscus images 2 CNNs Meniscus localization: JI = 0.7885, sensitivity = 0.9999, meniscus segmentation best CNN: accuracy = 0.9995, sensitivity = 0.9636, specificity = 0.9998, JI = 0.9324, F1 score = 0.9644, support = 0.0071*, *** Wei S et al. [43] DED mechanism, effect of therapy 53 Corneal IVCM with anesthesia Images of cornea Pretrained CNN (U-net) AUROC = 0.96, sensitivity = 96% Giannaccare G et al. [44] Subbasal nerve plexus characteristics for diagnosing DED 69 IVCM Images of subbasal nerve plexus Earlier developed method involving RF and NN[45,46] Nan Abbreviations: N = number of subjects; DED = dry eye disease; IVCM = in vivo confocal microscopy; DC = dendritic cell; GLM = generalized linear model; MLR = multiple linear regression; CFS = corneal fluorescein score; AS-OCT = anterior segment optical coherence tomography; CNN = convolutional neural network; AUROC = area under reciever operating characteristic curve; AUPRC = area under precision-recall curve; MGD = meibomian gland dysfunction; GAN = generative adversarial network; P-HD = average Pompeiu-Hausdorff distance; JI = Jaccard index; KI = Kappa index; CTRL = healthy; FPR = false positive rate; FNR = false negative rate; SVM = support vector machine; RF = random forest; RT = random tree; DNN = deep neural network; SD = standard deviation; CCT = central corneal thickness; TCT = A.M. Storås et al. The Ocular Surface 23 74–86 80 secretion of meibum due to a reduced number of functional meibomian glands and/or obstruction of the ducts is a major cause of evaporative DED and MGD. Meibography is a common technique for diagnosing MGD [80]. Classification of meibomian glands using meibography is routine for experienced experts, but this is not the case for all clinicians. Moreover, automatic methods can be faster than human assessment. Meibography images may require several pre-processing steps before they can be classified. One study trained an SVM on extracted features from the images [64]. Pre-processing included the dilation, flood-fill, skeletonization and pruning algorithms. The model achieved a sensi­ tivity of 0.979 and specificity of 0.961. However, in contrast to all other image analysis methods, this method is not completely automatic as the images need to be manipulated manually before they are passed on to the system. A combination of Otsu’s method and the skeletonization and watershed algorithms was useful in auto-matically quantifying meibo­ mian glands [55]. This method was faster than an ophthalmologist and achieved a sensitivity and specificity of 0.993 and 0.975, respectively. Another automatic method applied B´ezier curve fitting as part of the analysis [53]. The reported sensitivity was 1.0, while the specificity was 0.98. Xiao et al. sequentially applied a Prewitt operator, Graham scan, fragmentation and skeletonization algorithms for image analysis to quantify meibomian glands [34]. The agreement between the model results and two ophthalmologists was high with Kappa values larger than 0.8 and low false positive rates (< 0.06). The false negative rate was 0.19, suggesting that some glands were missed by the method. A considerable weakness of this study was that only 15 images were used for model development, and consequently it might not work well on unseen data. Another study automatically graded MGD severity using a Sobel operator, polynomial functions, fragmentation algorithm and Otsu’s method [47]. While the method was found to be faster, the results were significantly different from clinician assessments. Deep learning approaches were used by four studies evaluating meibomian gland features [33,35,41,48]. These systems are fully auto­ mated and apply some of the latest technologies within image analysis. Wang et al. used four different CNNs to determine meibomian gland atrophy [48]. The CNNs were trained to identify meibomian gland drop-out areas and estimate the percentage atrophy in a set of images. Comparison of model predictions with experienced clinicians indicated that the best CNN (ResNet50 architecture) was superior. Yeh et al. developed a method to evaluate meibomian gland atrophy by extracting features from meibography images with a special type of unsupervised CNN before application of a K-nearest neighbors model to allocate a meiboscore [35]. The system achieved an accuracy of 80.9%, out­ performing annotations by the clinical team. Moreover, hierarchical clustering of the extracted features from the CNN could show relation­ ships between meibography images. Another study used a CNN to automatically assess meibomian gland characteristics [41]. Images from two different devices collected from various hospitals were used to train and evaluate the CNN. This is an example of uncommonly good practice, as most medical AI systems are developed and evaluated on data from only one device and/or hospital. The only study to use a GAN archi­ tecture tested it on infrared 3D images of meibomian glands in order to evaluate MGD [33]. Comparing the model output with true labels, the performance scores were better than for state of the art segmentation methods. The Pearson correlations between the new automated method and two clinicians were 0.962 and 0.968. Four of the studies did not evaluate their proposed systems on external data [34,47,53,55]. Since the number of images used for model development was limited, the models can have overfit, and external evaluations should be performed to test how well the systems generalize to new data. 4.6. Tear osmolarity Tear osmolarity is a measure of tear concentration, and high values can indicate dry eyes. Cartes et al. [67] investigated use of machine learning to detect DED based on this test. Four different machine learning models were compared. Noise was added to osmolarity mea­ surements during the training phase, while original data without noise was used for final evaluation. The logistic regression model achieved 85% accuracy. However, since the models were trained and tested on the same data, the reported score is most likely not representative for how well the model generalizes to new data. 4.7. Proteomic analysis Proteomic analysis describes the qualitative and quantitative composition of proteins present in a sample. Grus et al. compared tear proteins in individuals with diabetic DED, non-diabetic DED and healthy controls for discrimination between the groups [72]. The authors used discriminant analysis and principal component analysis combined with k-means clustering. Both models achieved low accuracies when pre­ dicting all three categories. However, classification into DED and non-DED achieved accuracies of 72% and 71% for discriminant analysis and k-means clustering, respectively. In another study by the same group, tear proteins analysed using deep learning discriminated subjects as healthy or having DED with an accuracy of 89% [71]. An accuracy of 71% was achieved using discriminant analysis. A combination of discriminant analysis for detecting the most important proteins and a deep neural network for classification was also investigated [70]. High accuracy, sensitivity and specificity were reported. Discriminant anal­ ysis was also used by Gonzalez et al. in analysis of the tear proteome [69]. The most important proteins were selected to train an artificial neural network to classify tear samples as aqueous-deficient DED, MGD or healthy. The model gave an overall accuracy of 89.3%. Principal component analysis yielded good separation of healthy controls, aqueous-deficient DED and MGD data-points, indicating that the pro­ teins were good candidates for classification of the three conditions. This system achieved the highest accuracy of all the reviewed proteomic studies. Considered together, the results from the four studies [69-72] suggest that neural networks applied alone or together with other techniques perform better than discriminant analysis for detecting DED-related protein patterns in the tear proteome. Jung et al. used a network model based on modularity analysis to describe the tear proteome with respect to immunological and inflam­ matory responses related to DED [68]. In this study, patterns in tears and lacrimal fluid were investigated in patients with DED. Since only 10 subjects were included, the study should be performed on a larger cohort of patients to verify the results. 4.8. Optical coherence tomography Thickening of the corneal epithelium can be a sign of abnormalities in the cornea. Moreover, corneal thickness could potentially be a marker for DED. Kanellopoulos et al. developed a linear regression model to look for possible correlations between corneal thickness metrics measured using anterior segment optical coherence tomography (AS- OCT) and DED [58]. However, neither the model predictions nor per­ formance were reported, making it difficult to assess the usefulness of thinnest corneal thickness; r = Pearson’s correlation coefficient; Nan = not available; NN = neural network; RMSE = root mean squared error; CI = confidence interval; TBUT = fluorescein tear break-up time; PA = pruning algorithm; SA = skeletonization algorithm; FFA = Flood-fill algorithm; * = standard deviations not included in table; ** = 95% confidence intervals not included in table; *** = metrics are calculated as the average of 5 repetitions; **** = metrics are calculated as the average of 10 repetitions; ***** = metrics are calculated as the average from 10-fold crossvalidation; § = metrics are calculated as the average from 6-fold crossvalidation; §§ = metrics are calculated as the average of 100 models. A.M. Storås et al. The Ocular Surface 23 74–86 81 Table 2 Overview of the reviewed studies using clinical investigations, part 2 of 2. Study Objective N Clinical Tests Type of Data Type of Algorithm Performance Score(s) Llorens-Quintana C et al. [47] Evaluate meibomian gland atrophy 149 Oculus Keratograph Meibography images Sobel operator, polynomial function, fragmentation algorithm, Otsu’s method (used sequentially) p-values < 0.05 between automatic method and clinicians Wang J et al. [48] Evaluate meibomian gland atrophy 706 (images) Oculus Keratograph Meibography images 4 CNNs Meiboscore grading: accuracy = 95.6%, eyelid detection: accuracy = 97.6%, JI = 0.955, atrophy detection: accuracy = 95.4%, JI = 0.667, RMSE = 0.067 (average across 4 meiboscores) Yabusaki K [49] Diagnose DED 138 (images) Tear interferometer Tear film lipid layer images SVM KI = 0.820, CTRL: F1 score = 0.845, SD = 0.067, aqueous-deficient DED: F1 score = 0.981, SD = 0.023, evaporative DED: F1 score = 0.815, SD = 0.095**** Yang J et al. [50] Estimate tear meniscus height for DED 69 Slit-lamp images with fluorescence staining Ocular surface images Connected component labelling Mean: p-value < 0.01 (×16 and ×40 magnification), r = 0.626 (×16) and 0.711 (×40), max: p-value < 0.001 (×16 and ×40), r = 0.645 (×16) and 0.847 (×40) Szyperski PD [51] Diagnose DED 110 Interferometry Videos from lateral shearing interferometry 4 different fractal dimension estimators, linear regression Best estimator: AUROC = 0.786 Hwang H et al. [52] Estimate tear film lipid layer thickness 34 Lipiscanner 1.0, slit-lamp microscope Tear film lipid layer videos Flood-fill algorithm, Canny edge detection p-value < 0.01 between all MGD groups Koprowski R et al. [53] Detect MGD 57 Oculus Keratograph Meibography images Riesz pyramid (?), Bezier curve (used sequentially) Accuracy = 99.08%, sensitivity = 1, specificity = 0.98 Peteiro-Barral D et al. [54] Classify tear film patterns 105 (images) Tearscope plus images Tear film lipid layer images SVM, Decision tree, Naive Bayes, simple NN, Fisher¬ ¥s linear discriminant NN: accuracy = 96%, sensitivity = 92%, specificity = 97%, precision = 92%, F1 score = 0.93, AUCROC = 0.95 Koprowski et al. [55] Detect MGD 86 Oculus Keratograph Meibography images Otsu’s method, SA, watershed algorithm (used sequentially) Sensitivity = 0.993, specificity = 0.975 Remeseiro B et al. [56] Classify tear film patterns 128 (images) Tearscope-plus images Tear film lipid layer images SVM Accuracy = 96.09%, precision = 92.00%, sensitivity = 89.66%, specificity = 97.98%, F1 score = 91.23%, processing time = 0.07 s Remeseiro B et al. [57] Classify tear film patterns 50 (images) Tearscope-plus images Tear film lipid layer images SVM Accuracy = 90.89%, sensitivity = 83.54%, precision = 97.95%, specificity = 86.75% Kanellopoulos AJ et al. [58] Diagnose DED 70 Fourier-domain AS-OCT system: corneal and corneal epithelial thickness maps Corneal examination Linear regression (correlation between DED and thickness) Nan Ramos L et al. [59] Estimate TBUT 18 (videos) Videos from TBUT (slit- lamp) TBUT videos Polynomial function Specificity = 89% (parameter b) and 82% (parameter e), specificity = 84% and 80% Ramos L et al. [60] Estimate TBUT 18 (videos) Videos from TBUT (slit- lamp) TBUT videos Polynomial function Accuracy = ""more than 90%"" Remeseiro et al. [61] Classify tear film patterns 511 (images) Tearscope-plus images Tear film lipid layer images Markov random field, SVM (used sequentially) Accuracy = 97.14%, accuracy (noisy data) = 92.61%***** García-Resúa C et al. [62] Classify tear film patterns 105 Tearscope-plus images Tear film lipid layer images K-nearest neighbors Cram´er’s V = 0.9, r = 0.94, p-value < 0.001, accuracy = 86.2% § Rodriquez JD [63] Evaluate ocular redness 26 Slit-lamp, digital camera Images of conjunctiva Sobel operator, MLR (used sequentially) Accuracy = 100%, r = 0.76, concordance correlation = 0.76 (compared to 5 investigators)* Koh YW et al. [64] Detect MGD 55 Slit-lamp biomicroscope, upper eye lid IR meibography images PA, SA, FFA, SVM (used sequentially) Specificity = 96.1%, SD = 0.4%, sensitivity = 97.9%, SD = 0.6% §§ Yedidya T et al. [65] Estimate TBUT 22 (videos) Video from TBUT TBUT videos Markov random field Mean difference in TBUT = 2.34s Yedidya T et al. [13] Detect dry areas 8 (videos) Video from TBUT TBUT videos Levenberg-Marquardt Accuracy = 91% (84-96%), SD = 4% Mathers WD et al. [66] Investigate DED 513 Schirmer’s test, meibomian gland drop- out, lipid viscosity and volume, tear evaporation Clinical test results Hierarchical clustering, decision tree Nan Abbreviations: N = number of subjects; DED = dry eye disease; IVCM = in vivo confocal microscopy; DC = dendritic cell; GLM = generalized linear model; MLR = multiple linear regression; CFS = corneal fluorescein score; AS-OCT = anterior segment optical coherence tomography; CNN = convolutional neural network; AUROC = area under reciever operating characteristic curve; AUPRC = area under precision-recall curve; MGD = meibomian gland dysfunction; GAN = generative adversarial network; P-HD = average Pompeiu-Hausdorff distance; JI = Jaccard index; KI = Kappa index; CTRL = healthy; FPR = false positive rate; FNR = false negative rate; SVM = support vector machine; RF = random forest; RT = random tree; DNN = deep neural network; SD = standard deviation; CCT = central corneal thickness; TCT = thinnest corneal thickness; r = Pearson’s correlation coefficient; Nan = not available; NN = neural network; RMSE = root mean squared error; CI = confidence interval; TBUT = fluorescein tear break-up time; PA = pruning algorithm; SA = skeletonization algorithm; FFA = Flood-fill algorithm; * = standard deviations not included in table; ** = 95% confidence intervals not included in table; *** = metrics are calculated as the average of 5 repetitions; **** = metrics are calculated as the average of A.M. Storås et al. The Ocular Surface 23 74–86 82 the study. The type of instrument used to determine the corneal thick­ ness was found to affect the results [39]. Measurements from AS-OCT and Pentacam were compared and multivariable regression was used to detect differences between the two techniques regarding the measured central corneal thickness and the thinnest corneal thickness. Individuals with mild DED, severe DED and healthy subjects were examined. The two techniques gave significantly different results in terms of the resulting β-coefficients in the multivariable regression model for individuals with severe DED. Images from clinical examina­ tions with AS-OCT were used to diagnose DED [32]. A pretrained VGG19 CNN [81] was fine-tuned using separate images for training and vali­ dation. Two similar CNN models were developed, and evaluation was performed on an external test set. Both achieved impressively high performance scores. The AUC values were 0.99 and 0.98. This is one out of two studies in this review that used an independent test sets after model development. Such practice is essential for a realistic impression of how well the model generalizes to new data not used during model development. The good performance is likely linked to the large amounts of training data (29, 000 images), which is essential for deep learning methods. Most of the re-viewed studies use significantly smaller data sets, which constitutes a disadvantage. Stegmann et al. analysed OCT images from healthy subjects for automatic detection of the lower tear meniscus [42]. Two different CNNs were trained and evaluated using 5-fold cross validation. The tear menisci detected by the models were compared to evaluations from an experienced grader. The best CNN achieved an average accuracy of 99.95%, sensitivity of 0.9636 and specificity of 0.9998. The system is promising regarding fast and accu­ rate segmentation of OCT images. However, more images from different OCT systems, including non-healthy subjects, should be used to verify and improve the analysis. The two studies [42,81] showed that CNNs could be an appropriate tool for image analysis. CNNs are likely to increase in popularity within 10 repetitions; ***** = metrics are calculated as the average from 10-fold crossvalidation; § = metrics are calculated as the average from 6-fold crossvalidation; §§ = metrics are calculated as the average of 100 models. Table 3 Overview of the reviewed studies using biochemical investigations. Study Objective N Clinical Tests Type of Data Type of Algorithm Performance Score(s) Cartes C et al. [67] Diagnose DED 40 Tear-Lab Osmometer Tear osmolarity measurements LR, Naive Bayes, SVM, RF LR: accuracy = 85% Jung JH et al. [68] Detect protein patterns in DED 10 Pooled tear and lacrimal fluid, analysed with LC-MS, trypsin digestion, RP-LC fractionation Proteins in tears and lacrimal fluid ""Network model"" based on betweenness centrality Nan Gonzalez N [69 Diagnose DED 93 Peptide/protein analysis: gel electrophoresis (SDS-PAGE) Peptides and proteins in tears Discriminant analysis, principal component analysis, NN Accuracy = 89.3%, CTRL: sensitivity = 0.99, specificity = 0.96, MGD: sensitivity = 0.85, specificity = 0.96, aqueous-deficient DED: sensitivity = 0.83, specificity = 0.93* Grus FH et al. [70] Diagnose DED 159 Schirmer’s test with anesthesia, tears analysed by LC-MS Proteins in tears Discriminant analysis, DNN (used sequentially) AUROC = 0.93, sensitivity and specificity = ‘‘approx. 90% each’’ Grus FH et al. [71] Diagnose DED 60 Protein analysis: gel electrophoresis (SDS-PAGE) Proteins in tears DNN, discriminant analysis DNN: accuracy = 89%, discriminant analysis: accuracy = 71% Grus FH et al. [72] Diagnose DED 119 Protein analysis: gel electrophoresis (SDS-PAGE) Proteins in tears Principal component analysis, K-means clustering (used sequentially), discriminant analysis K-means: accuracy = 71% (DED vs CTRL) and 42% (DED, diabetes-DED, CTRL), discriminant analysis: accuracy = 72% (DED vs CTRL) and 43% (DED, diabetes-DED, CTRL) Abbreviations: N = number of subjects; DED = dry eye disease; LR = logistic regression; SVM = support vector machine; RF = random forest; AUROC = area under reciever operating characteristic curve; MGD = meibomian gland dysfunction; CTRL = healthy; DNN = deep neural network; Nan = not available; NN = neural network; LC-MS = liquid chromatography mass spectometry; RP-LC = reverse-phase liquid chromatography; SDS-PAGE = sodium dodecyl sulphate-polyacrylamide gel electrophoresis; OSDI = ocular surface disease index; * = metrics are calculated as the average of 10 repetitions. Table 4 Overview of the reviewed studies using demographical investigations. Study Objective N Clinical Tests Type of Data Type of Algorithm Performance Score(s) Choi HR et al. [73] Investigate DED and dyslipidemia association 2272 OSDI score, health examination, questionnaire Population studies, Korea GLM, LR Nan Nam SM et al. [74] Detect risk factors for DED 4391 Health examination, health survey, nutrition survey National health survey, Korea Decision tree, Lasso, LR (used sequentially) AUROC = 0.70, 95% CI = 0.61- 0.78, specificity = 68%, sensitivity = 66% Kaido M et al. [75] Diagnose DED 369 Blink frequency, visual maintenance ratio, questionnaire Functional VA measurement and questionnaire, Japanese visual display terminal workers Discriminant analysis Sensitivity = 93.1%, specificity = 43.7%, precision = 83.8%, NPV = 80.8% Abbreviations: N = number of subjects; DED = dry eye disease; GLM = generalized linear model; AUROC = area under reciever operating characteristic curve; Nan = not available; CI = confidence interval; LR = logistic regression; OSDI = ocular surface disease index; VA = visual acuity; NPV = negative predictive value. A.M. Storås et al. The Ocular Surface 23 74–86 83 the field of DED due to promising results for solving image related tasks, including feature extraction. 4.9. Other clinical tests Machine learning models were used to analyse results from a variety of clinical tests to expand understanding of the DED process [66]. The study included subjects with DED and healthy subjects. Subjective cutoff values from clinical tests were used to assign subjects to the DED class. Hierarchical clustering and a decision tree were applied sequentially to group the subjects based on their clinical test results. The resulting groups were compared to the original groups. Because the analysis was based on objective measurements, it could be used to develop more objective diagnostic criteria. This could lead to earlier detection and more effective treatment of DED. Table 5 Overview of the data applied for the analyses. Study Type of Input Data Training Dataset Testing Dataset Reference Standard Clinical Investigations Aggarwal S et al. [30] Tabular 349 Nan Nan (clinical test results, subjective report) Deng X et al. [31] Images 253 (images) 232 (images) Senior clinician Elsawy A et al. [32 Images 29172 (train), 7293 (val) 23760 Certified cornea specialist Khan ZK et al. [33] Images 90 22 Clinician Xiao P et al. [34] Images 15 Nan 2 ophthalmologists Yeh C-H et al. [35] Images 398 (train), 99 (val) 209 Trained clinician da Cruz LB et al. [36] Tabular 106 (10- fold CV) Nan Optometrist da Cruz LB et al. [37] Tabular 106 (10- fold CV) Nan Optometrist Fu P-I et al. [38] Tabular 28 Nan Nan (clinical test results, subjective report) Fujimoto K et al. [39] Tabular 195 Nan Nan (kerato- conjunctival staining for ac{DED}) Maruoka S et al. [40] Images 221 (5- fold CV) Nan 3 eyelid specialists Prabhu SM et al. [41] Images 600 200 Clinical experts Stegmann H et al. [42] Images 6658 (images) (5-fold CV) Nan Experienced investigator Wei S et al. [43] Images 5000* 53 (3-5 per patient) Experienced investigator Giannaccare G et al. [44] Tabular Nan 69 Experienced investigator ~ cite {Chen2017ACCMed} Llorens- Quintana C et al. [47] Images 149 Nan Clinicians Wang J et al. [48] Images 398 (train) 99 (val) 209 Experienced clinician Yabusaki K [49] Tabular 93** 45** Skilled ophthalmologist Yang J et al. [50] Images 520 Nan ImageJ software Szyperski PD [51] Tabular 110 Nan Nan Hwang H et al. [52] Frames 34 Nan Meibomian gland expert Koprowski R et al. [53] Images 228 (images) Nan Specialized clinicians Peteiro-Barral D et al. [54] Tabular 105 (LOO CV) Nan Experts Koprowski et al. [55] Images 172 (images) Nan Ophthalmology expert Remeseiro B et al. [56] Tabular Nan 128 Optometrists Remeseiro B et al. [57] Tabular Sampled from test set 50 4 optometrists Tabular 140 Nan Ophthalmologist Table 5 (continued) Study Type of Input Data Training Dataset Testing Dataset Reference Standard Kanellopoulos AJ et al. [58] Ramos L et al. [59] Videos 18 Nan 2/4 experts Ramos L et al. [60] Videos 12 6 4 experts Remeseiro et al. [61] Tabular 511 (10- fold CV) Nan Experts García-Resúa C et al. [62] Tabular 105 (6- fold CV) Nan Experienced investigator Rodriquez JD [63] Tabular 99 (images) Nan 5 trained investigators Koh YW et al. [64] Tabular 28*** 27*** Experts Yedidya T et al. [65] Videos 22 Nan Clinician Yedidya T et al. [13] Frames 8**** Nan Optometrist (evaluated 3 of the 8 patients) Mathers WD et al. [66] Tabular 513 (10- fold CV) Nan Nan (clinical test results) Biochemical Investigations Cartes C et al. [67] Tabular 40 (noise added) 40 (no noise) Nan (clinical test results, subjective report) Jung JH et al. [68] Tabular 10 Nan Ophthalmologist Gonzalez N [69] Tabular 70% of 93** 30% of 93** Nan (clinical tests) Grus FH et al. [70] Tabular 50% of 159 50% of 159 Nan (clinical test results, subjective report) Grus FH et al. [71] Tabular 30 30 Nan (clinical test results, subjective report) Grus FH et al. [72] Tabular 119 § Nan (clinical test results, subjective report) Demographical Investigations Choi HR et al. [73] Tabular 2272 Nan Nan (subjective report) Nam SM et al. [74] Tabular 80% of 4391 20% of 4391 Ophthalmologist Kaido M et al. [75] Tabular 369 Nan Dry eye specialists Abbreviations: Nan = not available; val = validation; CV = crossvalidation; DED = dry eye disease; LOO = leave one out; * = pretraining images; ** = randomly selected samples, process repeated 10 times; *** = randomly selected samples, process repeated 100 times; **** = 3-5 sequences of video per patient; § = For multivariate analysis model, but the number of samples was not mentioned. A.M. Storås et al. The Ocular Surface 23 74–86 84 4.10. Population surveys Population surveys can provide valuable insight regarding the prevalence of DED and help detect risk factors for developing the dis­ ease. Japanese visual terminal display workers were surveyed with the objective of detecting DED [75]. Dry eye exam data and subjective re­ ports were used for diagnosis. This was passed to a discriminant analysis model. When compared to diagnosis by a dry eye specialist, the model showed a high sensitivity of 0.931, but low specificity of 0.437. This is a very low specificity, but is not necessarily bad if the aim is to detect as many cases of DED as possible and there is less concern about misclas­ sification of healthy individuals. Data from a national health survey were analysed in order to detect risk factors for DED [74]. Here, in­ dividuals were regarded as having DED if they had been diagnosed by an ophthalmologist, and were experiencing dryness. Feature modifications were performed by a decision tree, and the most important features were selected using lasso. β-coefficients from a logistic regression trained on the most important features were used to rank the features. Women, individuals who had received refractive surgery and those with depression were detected as having the highest risk for developing DED. Even though the models in the study were trained on data from more than 3500 participants, the reported performance scores were among the poorest in this review with a sensitivity of 0.66 and a specificity of 0.68. A possible reason could be that the selected features were not ideal for detecting DED. However, the detected risk factors have previously been shown to be associated with DED [3,82,83]. The findings suggest that the data quality from population surveys might not be as high as in other types of studies, which could lead to misinterpretation by the machine learning model. The association between DED and dyslipidemia was investigated by combining data from two population surveys in Korea in Ref. [73]. A generalized linear model was used to investigate linear characteristics between features and the severity of DED. The model showed significant increase in age, blood pressure and prevalence of hypercholesterolemia over the range from no DED to severe DED. Evaluation of the association between dyslipidemia and DED using linear regression showed that the odds ratio for men with dyslipidemia was higher than 1 compared to men without dyslipidemia. This association was not found in women. The study results suggest a positive association between DED and dys­ lipidemia in men, but not in women. 4.11. Future perspectives In order to benchmark existing and future models, we advocate that the field of DED should have a common, centralized and openly avail­ able data set for testing and evaluation. The data should be fully representative for the relevant clinical tests. In order to ensure that models are applicable to all populations of patients, medical institutions, and types of equipment around the world, they must be evaluated on data from different demographic groups of patients across several clinics and, if relevant, from different medical devices. Moreover, the test data set should not be available for model development, but only for final evaluation. A common standard on these processes will increase the reproducibility and comparability of studies. Standardized collection and handling of clinical data and samples would also facilitate com­ parisons between different instruments and clinics [84]. In addition, a cross hospitals/centers data set would solve important challenges of applying AI in clinical practice, such as metrics not reflecting clinical applicability, difficulties in comparing algorithms, and under­ specification. These have all been identified as being among the main obstacles for adoption of any medical AI system in clinical practice [85, 86]. A possible challenge regarding implementation in the clinic is that hospitals do not necessarily use the same data platforms, which might prevent widespread use of machine learning systems. Consequently, solutions for implementing digital applications across hospitals should be considered. Model explanations are important in order to understand why a complex machine learning model produces a certain prediction. For healthcare providers to trust the systems and decide to use them in the clinic, the systems should provide understandable and sound explana­ tions of the decision-making process. Moreover, they could assist clini­ cians when making medical decisions [18]. When developing new machine learning systems within DED, effort should be made to present the workings of the resulting models and their predictions in an easy to interpret fashion. 5. Conclusions We observed a large variation in the type of clinical tests and the type of data used in the reviewed studies. This is also true regarding the extent of pre-processing applied to the data before passing it to the machine learning models. The studies analysing images can be divided into those applying deep learning techniques directly on the images, and those performing extensive pre-processing and feature extraction before the data is passed to the machine learning model in a tabular format. The number of studies belonging to the first group has increased significantly over the past 3 years. As deep learning techniques become more estab­ lished, these will probably replace more traditional image pre- processing and feature extraction techniques. We noted that there was a lack of consensus regarding how best to perform model development, including evaluation. This made it difficult to estimate how well some models will perform in the clinic and with new patients, and also to compare the different models. Comparison was further complicated by the use of different types of performance scores. In addition there was no culture of data and code sharing, which makes reproducibility of the results impossible. For the future, focus should be put on establishing data and code sharing as a standard procedure. In conclusion, the results from the different studies’ machine learning models are promising, although much work is still needed on model development, clinical testing and standardisation. AI has a high potential for use in many different applications related to DED, including automatic detection and classification of DED, investigation of the etiology and risk factors for DED, and in the detection of potential biomarkers. Effort should be made to create common guidelines for the model development process, especially regarding model evaluation. Prospective testing is recommended in order to evaluate whether pro­ posed models can improve the diagnostics of DED, and the health and quality of life of patients with DED. Declaration of competing interest The authors report no conflicts of interest. Appendix A. Supplementary data Supplementary data to this article can be found online at org/10.1016/j.jtos.2021.11.004. References [1] Stapleton F, Alves M, Bunya VY, Jalbert I, Lekhanont K, Malet F, Na K-S, Schaumberg D, Uchino M, Vehof J, et al. TFOS DEWS II epidemiology report. Ocul Surf 2017;15:334–65. [2] Geerling G, Tauber J, Baudouin C, Goto E, Matsumoto Y, O’Brien T, Rolando M, Tsubota K, Nichols KK. The international workshop on meibomian gland dysfunction: report of the subcommittee on management and treatment of meibomian gland dysfunction. Investig Ophthalmol Vis Sci 2011;52:2050–64. [3] Matossian C, McDonald M, Donaldson KE, Nichols KK, MacIver S, Gupta PK. Dry eye disease: consideration for women’s health. J Wom Health 2019;28:502–14. dx.d oi.org/10.1089/jwh.2018.7041. [4] Nichols JJ, Ziegler C, Mitchell GL, Nichols KK. Self-reported dry eye disease across refractive modalities. Investig Ophthalmol Vis Sci 2005;46:1911–4. org/10.1167/iovs.04-1294. A.M. Storås et al. The Ocular Surface 23 74–86 85 [5] Zhang X, Zhao L, Deng S, Sun X, Wang N. Dry eye syndrome in patients with diabetes mellitus: prevalence, etiology, and clinical characteristics. J Ophthalmol 2016. 2016. [6] Mandell JT, Idarraga M, Kumar N, Galor A. Impact of air pollution and weather on dry eye. J Clin Med 2020;9. [7] Willcox MD, Argüeso P, Georgiev GA, Holopainen JM, Laurie GW, Millar TJ, Papas EB, Rolland JP, Schmidt TA, Stahl U, et al. TFOS DEWS II tear film report. Ocul Surf 2017;15:366–403. [8] McCarthy J, Minsky ML, Rochester N, Shannon CE. A proposal for the Dartmouth summer research project on Artificial Intelligence, august 31, 1955. AI Mag 2006; 27. 12-12. [9] Legg S, Hutter M. Universal intelligence: a definition of machine intelligence. Minds Mach 2007;17:391–444. [10] Schmidt-Erfurth U, Sadeghipour A, Gerendas BS, Waldstein SM, Bogunovi´c H. Artificial Intelli- gence in retina. Prog Retin Eye Res 2018;67:1–29. org/10.1016/j.preteyeres.2018.07.004. [11] De Fauw J, Ledsam JR, Romera-Paredes B, Nikolov S, Tomasev N, Blackwell S, Askham H, Glorot X, O’Donoghue B, Visentin D, et al. Clinically applicable deep learning for diagnosis and referral in retinal disease. Nat Med 2018;24:1342–50. [12] Cię˙zar K, Pochylski M. 2D fourier transform for global analysis and classification of meibomian gland images. Ocul Surf 2020;18:865–70. j.jtos.2020.09.005. 420301452. [13] Yedidya T, Hartley R, Guillon J-P, Kanagasingam Y. Automatic dry eye detection. In: International conference on medical image computing and computer-assisted intervention. Springer; 2007. p. 792–9. 75757-3_96. [14] Nielsen KB, Lautrup ML, Andersen JK, Savarimuthu TR, Grauslund J. Deep learning-based algorithms in screening of diabetic retinopathy: a systematic review of diagnostic performance. Ophthalmol Retina 2019;3:294–304. org/10.1016/j.oret.2018.10.014. [15] Pead E, Megaw R, Cameron J, Fleming A, Dhillon B, Trucco E, MacGillivray T. Automated detection of age-related macular degeneration in color fundus photography: a systematic review. Surv Ophthalmol 2019;64:498–511. https:// doi.org/10.1016/j.survophthal.2019.02.003. ence/article/pii/S0039625718302078. [16] Gensure RH, Chiang MF, Campbell JP. Artificial Intelligence for retinopathy of prematurity. Curr Opin Ophthalmol 2020;31:312–7. ICU.0 000000000000680. [17] Esteva A, Kuprel B, Novoa RA, Ko J, Swetter SM, Blau HM, Thrun S. Dermatologist- level classification of skin cancer with deep neural networks. Nature (London) 2017;542:115–8. [18] Lundberg SM, Nair B, Vavilala MS, Horibe M, Eisses MJ, Adams T, Liston DE, Low DK-W, Newman S-F, Kim J, Lee S-I. Explainable machine-learning predictions for the prevention of hypoxaemia during surgery. Nat Biomed Eng 2018;2:749–60. [19] Gulshan V, Peng L, Coram M, Stumpe MC, Wu D, Narayanaswamy A, Venugopalan S, Widner K, Madams T, Cuadros J, Kim R, Raman R, Nelson PC, Mega JL, Webster DR. Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus pho- tographs. J Am Med Assoc 2016;316:2402–10. [20] Yousefi S, Takahashi H, Hayashi T, Tampo H, Inoda S, Arai Y, Tabuchi H, Asbell P. Predicting the likelihood of need for future keratoplasty intervention using artificial intelligence. Ocul Surf 2020;18:320–5. jtos.2020.02.008. 420300276. [21] Hastie T, Tibshirani R, Friedman J. The elements of statistical learning: data mining, inference, and prediction. Springer Science & Business Media; 2009. 2010.00646_6.x. [22] Palacio-Ni˜no J-O, Berzal F. Evaluation metrics for unsupervised learning algorithms. 2019, 05667. arXiv: 1905. [23] Le Berre C, Sandborn WJ, Aridhi S, Devignes M-D, Fournier L, Smaïl-Tabbone M, Danese S, Peyrin-Biroulet L. Application of artificial intelligence to gastroenterology and hepatology. Gastroenterology 2020;158:76–94. https:// doi.org/10.1053/j.gastro.2019.08.058. [24] Thrall JH, Li X, Li Q, Cruz C, Do S, Dreyer K, Brink J. Artificial intelligence and machine learning in radiology: opportunities, challenges, pitfalls, and criteria for success. J Am Coll Radiol 2018;15:504–8. jacr.2017.12.026. [25] Thambawita VL, Strümke I, Hicks S, Riegler MA, Halvorsen P, Parasa S. Data augmentation using generative adversarial networks for creating realistic artificial colon polyp images: validation study by endoscopists. Gastrointest Endosc 2021;93 :AB190. [26] Gianfrancesco MA, Tamang S, Yazdany J, Schmajuk G. Potential biases in machine learning al- gorithms using electronic health record data. JAMA Int Med 2018;178 :1544–7. [27] G´eron A. Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: concepts, tools, and techniques to build intelligent systems. O’Reilly Media; 2019. [28] European Commission. Proposal for a regulation laying down harmonised rules on Artificial Intelligence. 4, sal-regulation-laying-down-harmonised-rules-artificial-intelligence; 2021. [29] U.S. Food & Drug Administration. Artificial intelligence and machine learning (AI/ ML) software as a medical device (SaMD) action plan. 2021. 1, gov/medical-devices/software-medical-device-samd/artificial-intelligence-and -machine-learning-software-medical-device. [30] Aggarwal S, Kheirkhah A, Cavalcanti BM, Cruzat A, Jamali A, Hamrah P. Correlation of corneal immune cell changes with clinical severity in dry eye disease: an in vivo confocal microscopy study. Ocul Surf 2021;19:183–9. https:// doi.org/10.1016/j.jtos.2020.05.012. article/pii/S1542012420300963. [31] Deng X, Tian L, Liu Z, Zhou Y, Jie Y. A deep learning approach for the quantification of lower tear meniscus height. Biomed Signal Process Control 2021; 68:102655. rect.com/science/article/pii/S1746809421002524. [32] Elsawy A, Eleiwa T, Chase C, Ozcan E, Tolba M, Feuer W, Abdel-Mottaleb M, Abou Shousha M. Multidisease deep learning neural network for the diagnosis of corneal diseases. Am J Ophthalmol 2021;226:252–61. ajo.2021.01.018. 421000398. [33] Khan ZK, Umar AI, Shirazi SH, Rasheed A, Qadir A, Gul S. Image based analysis of meibomian gland dysfunction using conditional generative adversarial neural network. BMJ Open Ophthalmol 2021;6. 2020-000436. arXiv: [34] Xiao P, Luo Z, Deng Y, Wang G, Yuan J. An automated and multiparametric algorithm for objective analysis of meibography images. Quant Imag Med Surg 2021;11:1586–99. [35] Yeh C-H, Yu SX, Lin MC. Meibography phenotyping and classification from unsupervised discrim- inative feature learning. Transl Vis Sci Technol 2021;10. 4-4. arXiv:arvojournals.org/arvo/content \_public/journal/tvst/938516/i2164-2591-10-2-4\_16125 19083.80616.pdf. [36] da Cruz LB, Souza JC, de Sousa JA, Santos AM, de Paiva AC, de Almeida JDS, Silva AC, Junior GB, Gattass M. Interferometer eye image classification for dry eye categorization using phylogenetic diversity indexes for texture analysis. Comput Methods Progr Biomed 2020;188:105269. cmpb.2019.105269. 169260719310995. [37] da Cruz LB, Souza JC, de Paiva AC, de Almeida JDS, Junior GB, Aires KRT, Silva AC, Gattass M. Tear film classification in interferometry eye images using phylogenetic diversity indexes and ripley’s k function. IEE J Biomed Health Inf 2020;24:3491–8. [38] Fu P-I, Fang P-C, Ho R-W, Chao T-L, Cho W-H, Lai H-Y, Hsiao Y-T, Kuo M-T. Determina- tion of tear lipid film thickness based on a reflected placido disk tear film analyzer. Diagnostics 2020;10. diagnostics10060353. [39] Fujimoto K, Inomata T, Okumura Y, Iwata N, Fujio K, Eguchi A, Nagino K, Shokirova H, Kara- sawa M, Murakami A. Comparison of corneal thickness in patients with dry eye disease using the pentacam rotating scheimpflug camera and anterior segment optical coherence tomography. PLoS One 2020;15:e0228567. [40] Maruoka S, Tabuchi H, Nagasato D, Masumoto H, Chikama T, Kawai A, Oishi N, Maruyama T, Kato Y, Hayashi T, Katakami C. Deep neural network-based method for detecting obstructive meibomian gland dysfunction with in vivo laser confocal microscopy. Cornea 2020;39:720–5. ICO.0000000000002279. [41] Prabhu SM, Chakiat A, S S, Vunnava KP, Shetty R. Deep learning segmentation and quantification of meibomian glands. Biomed Signal Process Control 2020;57: 101776. t.com/science/article/pii/S174680941930357X. [42] Stegmann H, Werkmeister RM, Pfister M, Garh¨ofer G, Schmetterer L, dos Santos VA. Deep learn- ing segmentation for optical coherence tomography measurements of the lower tear meniscus. Biomed Opt Express 2020;11: 1539–54. org/boe/abstract1.JBO.17.8.086008. [65] Yedidya T, Carr P, Hartley R, Guillon J-P. Enforcing monotonic temporal evolution in dry eye images. In: International conference on medical image computing and computer-assisted intervention. Springer; 2009. p. 976–84. 10.1007/978-3-642-04271-3_118. [66] Mathers WD, Choi D. Cluster analysis of patients with ocular surface disease, blepharitis, and dry eye. Arch Ophthalmol 2004;122:1700–4. 10.1001/archo pht.122.11.1700. lmology/articlepdf/416676/eeb30021.pdf. [67] Cartes C, L´opez D, Salinas D, Segovia C, Ahumada C, P´erez N, Valenzuela F, Lanza N, Solís RL, Perez V, et al. Dry eye is matched by increased intrasubject variability in tear osmolarity as confirmed by machine learning approach. Arch Soc Esp Oftalmol 2019;94:337–42. [68] Jung JH, Ji YW, Hwang HS, Oh JW, Kim HC, Lee HK, Kim KP. Proteomic analysis of human lacrimal and tear fluid in dry eye disease. Sci Rep 2017;7:1–11. [69] Gonz´alez N, Iloro I, Soria J, Duran JA, Santamaría A, Elortza F, Su´arez T. Human tear pep- tide/protein profiling study of ocular surface diseases by spe-maldi-tof mass spectrometry analyses. EuPA Open Proteomics 2014;3:206–15. org/10.1016/j.euprot.2014.02.016. le/pii/S221296851400021X. [70] Grus FH, Podust VN, Bruns K, Lackner K, Fu S, Dalmasso EA, Wirthlin A, Pfeiffer N. SELDI- TOF-MS proteinchip array profiling of tears from patients with dry eye. Investig Ophthalmol Vis Sci 2005;46:863–76. 0448. [71] Grus F-H, Augustin AJ. Analysis of tear protein patterns by a neural network as a diagnostical tool for the detection of dry eyes, ELECTROPHORESIS. Int J 1999;20 (4-5):875–80. AID-ELPS875> 3.0.CO;2-V. [72] Grus F, Augustin A, Evangelou N, Toth-Sagi K. Analysis of tear-protein patterns as a diagnostic tool for the detection of dry eyes. Eur J Ophthalmol 1998;8:90–7. [73] Choi HR, Lee JH, Lee HK, Song JS, Kim HC. Association between dyslipidemia and dry eye syndrome among the Korean middle-aged population. Cornea 2020;39: 161–7. [74] Nam SM, Peterson TA, Butte AJ, Seo KY, Han HW. Explanatory model of dry eye disease using health and nutrition examinations: machine learning and network- based factor analysis from a national survey. JMIR Med Inf 2020;8:e16153. [75] Kaido M, Kawashima M, Yokoi N, Fukui M, Ichihashi Y, Kato H, Yamatsuji M, Nishida M, Fukagawa K, Kinoshita S, Tsubota K. Advanced dry eye screening for visual display terminal workers using functional visual acuity measurement: the moriguchi study. Br J Ophthalmol 2015;99:1488–92. 10.1136/bjophthalmol-2015-306640. [76] Gullion J-PC. Tear film structure of the contact lens wearer. Ph.D. thesis. London: City University; 1990. [77] Holly FJ. Physical chemistry of the normal and disordered tear film. Trans Ophthalmol Soc U K 1985;104(Pt 4):374–80. [78] Rasband W. Imagej. [79] Cruzat M, Andrea, Qazi M, Yureeda, Hamrah M, Pedram. In vivo confocal microscopy of corneal nerves in health and disease. Ocul Surf 2016;15:15–47. [80] Villani E, Marelli L, Dellavalle A, Serafino M, Nucci P. Latest evidences on meibomian gland dysfunction diagnosis and management. Ocul Surf 2020;18: 871–92. com/science/article/pii/S1542012420301415. [81] Krizhevsky A, Sutskever I, Hinton GE. Imagenet classification with deep convolutional neural net- works. Commun ACM 2017;60:84–90. org/10.1145/3065386. [82] Dartt DA. Dysfunctional neural regulation of lacrimal gland secretion and its role in the pathogenesis of dry eye syndromes. Ocul Surf 2004;2:76–91. org/10.1016/S1542- 012470146-5. [83] Wan K, Chen L, Young A. Depression and anxiety in dry eye disease: a systematic review and meta- analysis. Eye 2016;30:1558–67. eye.2016.186. [84] Ambaw YA, Timbadia DP, Raida M, Torta F, Wenk MR, Tong L. Profile of tear lipid mediator as a biomarker of inflammation for meibomian gland dysfunction and ocular surface diseases: standard operating procedures. The Ocular Surface; 2020. 08. ence/article/pii/S1542012420301488. [85] D’Amour A, Heller K, Moldovan D, Adlam B, Alipanahi B, Beutel A, Chen C, Deaton J, Eisen- stein J, Hoffman MD, et al. Underspecification presents challenges for credibility in modern machine learning. arXiv preprint arXiv:2011.03395. 2020. [86] Kelly CJ, Karthikesalingam A, Suleyman M, Corrado G, King D. Key challenges for delivering clinical impact with artificial intelligence. BMC Med 2019;17:1–9. A.M. Storås et al.",".cfm?URI=boe-11-3-1539. [43] Wei S, Ren X, Wang Y, Chou Y, Li X. Therapeutic effect of intense pulsed light (ipl) combined with meibomian gland expression (mgx) on meibomian gland dysfunction (mgd). J Ophthalmol 2020;2020. 3684963. [44] Giannaccare G, Pellegrini M, Sebastiani S, Moscardelli F, Versura P, Campos EC. In vivo confo- cal microscopy morphometric analysis of corneal subbasal nerve plexus in dry eye disease using newly developed fully automated system. Graefe’s Arch Clin Exp Ophthalmol 2019;257:583–9. 007/s00417-018-04225-7. [45] Chen X, Graham J, Dabbah MA, Petropoulos IN, Tavakoli M, Malik RA. An automatic tool for quantification of nerve fibers in corneal confocal microscopy images. IEEE (Inst Electr Electron Eng) Trans Biomed Eng 2017;64:786–94. [46] Dabbah M, Graham J, Petropoulos I, Tavakoli M, Malik R. Automatic analysis of diabetic peripheral neuropathy using multi-scale quantitative morphology of nerve fibres in corneal confocal microscopy imaging. Med Image Anal 2011;15: 738–47. 11.05.016. rect.com/science/article/pii/S1361841511000806. [47] Llorens-Quintana C, Rico-Del-Viejo L, Syga P, Madrid-Costa D, Iskander DR. A novel automated approach for infrared-based assessment of meibomian gland morphology. Transl Vis Sci Technol 2019;8. tvst.8.4.17. 17-17. [48] Wang J, Yeh TN, Chakraborty R, Yu SX, Lin MC. A deep learning approach for meibomian gland atrophy evaluation in meibography images. Transl Vis Sci Technol 2019;8. 37-37. A.M. Storås et al. The Ocular Surface 23 74–86 86 [49] Yabusaki K, Arita R, Yamauchi T. Automated classification of dry eye type analyzing interference fringe color images of tear film using machine learning techniques. Model Artif Intell Ophthalmol 2019;2:28–35. 10.35119/maio.v2i3.90. [50] Yang J, Zhu X, Liu Y, Jiang X, Fu J, Ren X, Li K, Qiu W, Li X, Yao J. TMIS: a new image-based software application for the measurement of tear meniscus height. Acta Ophthalmol 2019;97:e973–80. [51] Szyperski PD. Comparative study on fractal analysis of interferometry images with application to tear film surface quality assessment. Appl Opt 2018;57:4491–8. [52] Hwang H, Jeon H-J, Yow KC, Hwang HS, Chung E. Image-based quantitative analysis of tear film lipid layer thickness for meibomian gland evaluation. Biomed Eng Online 2017;16:1–15. [53] Koprowski R, Tian L, Olczyk P. A clinical utility assessment of the automatic measurement method of the quality of meibomian glands. Biomed Eng Online 2017;16:1–13. [54] Peteiro-Barral D, Remeseiro B, M´endez R, Penedo MG. Evaluation of an automatic dry eye test using mcdm methods and rank correlation. Med Biol Eng Comput 2017;55:527–36. [55] Koprowski R, Wilczy´nski S, Olczyk P, Nowi´nska A, Węglarz B, Wylęgała E. A quantitative method for assessing the quality of meibomian glands. Comput Biol Med 2016;75:130–8. [56] Remeseiro B, Barreira N, García-Resúa C, Lira M, Gir´aldez MJ, Yebra-Pimentel E, Penedo MG. ideas: a web-based system for dry eye assessment. Comput Methods Progr Biomed 2016;130:186–97. [57] Remeseiro B, Mosquera A, Penedo MG. CASDES: a computer-aided system to support dry eye diagnosis based on tear film maps. IEE J Biomed Health Inf 2016; 20:936–43. [58] Kanellopoulos AJ, Asimellis G. In vivo 3-dimensional corneal epithelial thickness mapping as an indicator of dry eye: preliminary clinical assessment. Am J Ophthalmol 2014;157:63–8. e2, [59] Ramos L, Barreira N, Pena-Verdeal H, Gir´aldez M. Automatic assessment of tear film break-up dynamics. Stud Health Technol Inf 2014;207:173–82. org/10.3233/978-1-61499-474-9-173. [60] Ramos L, Barreira N, Mosquera A, Penedo M, Yebra-Pimentel E, García-Resúa C. Analysis of parameters for the automatic computation of the tear film break-up time test based on cclru standards. Comput Methods Progr Biomed 2014;113: 715–24. t.com/science/article/pii/S0169260713003921. [61] Remeseiro B, Bolon-Canedo V, Peteiro-Barral D, Alonso-Betanzos A, Guijarro- Berdi˜nas B, Mos- quera A, Penedo MG, S´anchez-Maro˜no N. A methodology for improving tear film lipid layer classi- fication. IEE J Biomed Health Inf 2014;18: 1485–93. [62] García-Resúa C, Fern´andez MJG, Penedo MFG, Calvo D, Penas M, Yebra- Pimentel E. New software application for clarifying tear film lipid layer patterns. Cornea 2013;32:538–46. [63] Rodriguez JD, Johnston PR, Ousler GW, Smith LM, Abelson MB. Automated grading system for evaluation of ocular redness associated with dry eye. Clin Ophthalmol 2013;7:1197–204. [64] Koh YW, Celik T, Lee HK, Petznick A, Tong LH. Detection of meibomian glands and classification of meibography images. J Biomed Opt 2012;17:086008. https:// doi.org/10.1117/","['Andrea M. Storås', 'Inga Strümke', 'Michael A. Riegler', 'Jakob Grauslund', 'Hugo L. Hammer', 'Anis Yazidi', 'Pål Halvorsen', 'Kjell G. Gundersen', 'Tor P. Utheim', 'Catherine J. Jackson']"
Achieving Fair Load Balancing by Invoking a Learning Automata-Based Two-Time-Scale Separation Paradigm,"Yazidi, Anis and Hassan, Ismail and Hammer, Hugo L. and Oommen, B. John",2021,8.0,32,IEEE Transactions on Neural Networks and Learning Systems,article,"3444
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
Achieving Fair Load Balancing by Invoking a
Learning Automata-Based Two-Time-Scale
Separation Paradigm
Anis Yazidi
, Senior Member, IEEE, Ismail Hassan, Hugo L. Hammer
,
and B. John Oommen
, Life Fellow, IEEE
Abstract INTRODUCTION
I
N THIS article, we consider the problem of load balanc-
ing (LB), which is extremely pertinent in today’s highly
connected world. To put the problem in the right perspec-
tive, we observe that, unarguably, computers, and information
technology have experienced enormous growth and devel-
opment over the past three decades. This unalterable trend
Manuscript received December 18, 2019; revised June 3, 2020; accepted
July 12, 2020. Date of publication August 5, 2020; date of current version
August 4, 2021. The work of B. John Oommen was supported in part
by the Natural Sciences and Engineering Council of Canada (NSERC).
(Corresponding author: B. John Oommen.)
Anis Yazidi, Ismail Hassan, and Hugo L. Hammer are with the Department
of Computer Science, Oslo Metropolitan University, 0130 Oslo, Norway.
B. John Oommen is with the School of Computer Science, Carleton
University, Ottawa, ON K1S5B6, Canada, and also with the IKT Department,
University
of
Agder,
4879
Grimstad,
Norway
(e-mail:
oommen@
scs.carleton.ca).
Color versions of one or more of the ﬁgures in this article are available
online at https://ieeexplore.ieee.org.
Digital Object Identiﬁer 10.1109/TNNLS.2020.3010888
has profoundly affected societies worldwide, in every sense
of the word. Products and services that were traditionally
delivered through other means are, currently, online services.
Unlike the scenario a few decades ago, where one “con-
nected” directly to an institution’s machine, most of these
services are now being executed on the internet. Since more
than 50 billion devices will be connected to the Internet
by 2020 [28], one understands that the traditional model of
having in-house computers and resources is not going to be
a sustainable and viable option. Rather, to cope with the
sheer increase in the number of users and devices inter-
acting with the machines, the respective services delivered
online, government, and business institutions are reducing their
investments in on-premise IT infrastructure. Indeed, to mit-
igate the super-exponential increases in the corresponding
communication and computational costs, they are moving to,
and increasing their spending on, cloud-based services [33].
In this context, we mention that the National Institute of
Standards and Technology (NIST) deﬁnes “cloud computing”
as a model for enabling ubiquitous, convenient, on-demand
network access to a shared pool of conﬁgurable comput-
ing resources (e.g., networks, servers, storage, applications,
and services) that can be rapidly provisioned and released
with minimal management effort or service provider interac-
tion [19]. It is clear that one has to now consider how all these
services can be distributed over the cloud of computers. This,
precisely, involves the problem of LB.
LB is like many other related problems [13]; many instances
of LB are considered NP-Hard problems [31]. Thus, we will
never be able to solve the problem, so as to allocate
the resources in a perfectly balanced manner. Unlike the
approaches that have been proposed in the literature [11],
such as round-robin (RR), weighted RR (WRR), power-
of-two choices (Po2), least connection, and weighted least
connection, we attempt to resolve the problem in an “almost
fair” manner, and we shall refer to such an allocation as an
ϵ-fair balance. In other words, we attempt to achieve this by
being “as close to fair as possible.” While one can attempt
to do this intelligently using any of the available AI-based
paradigms, the solution that we propose invokes a novel
stochastic learning automaton (LA) scheme. Our LA-based
solution distributes the load to a number of nodes, where
the performance level at the different nodes is approximately
2162-237X © 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3445
equal and each user experiences approximately the same
Quality of the Service (QoS) irrespective of the node that
he/she is connected to. Although LA has been applied, in a
classical sense, to solve many resource allocation problems
including LB, to the best of our knowledge, this work is
distinct in two aspects. First, to the best of our knowledge,
there is no theoretical analysis of any LB algorithm in the ﬁeld
of LA. LB usually induces the dynamicity of the environment
as the LA actions will continuously alter the load distribution,
and consequently, render the Environment to be nonstationary.
Thus, such settings deviate from the classical multiarmed
bandit settings where the environment is rather static, and
the reward distribution is not inﬂuenced by the actions of
the LA. The analysis of such cases is much more involved than
stationary cases. The reader should also note that, probably,
the most notable example of a theoretical treatment is found
in [31] and [47], where the LB problem is mapped into a
coordinated strategic game. Second, the success of adopting
LA for solving a real-life problem is dependent on an appro-
priate choice, or more precisely, appropriate engineering of
the reward function. Most of the engineered reward functions
in the context of LA-based LB solutions solely rely on “the
response time” of a server. In this article, we have used a
modiﬁed version of the reward that can infer fairness based
on a dynamic comparison threshold.
How then should a cloud-based service model differ from
a more traditional model? From the reported literature [12],
we submit that a cloud-based infrastructure should make it
easy for a customer to request a resource and to have that
resource provisioned and ready for use, in minutes, rather than
days or weeks. The ability to scale the available resources
on demand, with little or no downtime, is another factor that
makes the cloud preferable over traditional enterprise data
centers.
The cloud-based computing paradigm has transformed the
IT industry profoundly, paving the way to foster new concepts,
such as DevOps and microservices. However, to stay com-
petitive and to also ensure customer satisfaction, companies
offering online services aim to quickly deliver new features
to their customers. Developing and deploying software as
a monolithic application do not fully take advantage of the
beneﬁts of a “cloud computing” paradigm, and many compa-
nies are considering migrating toward microservices [7] and a
cloud-native application approach.
While having many beneﬁts, cloud computing still has some
challenges when it comes to offering an optimized system
and a fair allocation of resources. Available cloud models
do not adequately capture uncertainty, nonhomogeneity, and
dynamic performance changes that are inherent to nonuniform
and shared infrastructures [41]. One of the viable ways to
address challenges related to dynamic performance changes
associated with any uncertainties in the load distribution is to
employ an LB technique.
LB is the process of distributing workloads fairly among
multiple hosts. The major advantage of deploying an LB
solution is to be able to handle more trafﬁc than a single
host can tackle. Another advantage of LB is that such a
system offers high availability such that if one service fails,
others are available to ensure that the application stays up and
running.
In order to achieve an optimal distribution of workloads to
any number of hosts, several algorithms have been developed
throughout the years. LB algorithms are mainly classiﬁed as
being static or dynamic.
Static LB schemes assume that the information governing
the LB-oriented decisions is known in advance [32]. The
LB decisions are made deterministically or probabilistically
when the system starts or boots and remain constant during
runtime. Every time the system restarts, the same values get
loaded. Static LB algorithms are mostly suitable for stable
environments with homogeneous systems.
The nature of a data center or of a cloud implicitly requires
dealing with a mixture of stochastic processes [40]. In contrast
to static algorithms, dynamic LB algorithms do not require
prior knowledge or conﬁguration of the system. To make fairer
load distribution decisions, dynamic LB algorithms monitor
the current runtime state of the system and adapt to changing
loads. The experiments that we report tacitly imply that the
servers are not homogenous, as they need not necessarily be
homogenous, especially in cloud environment. Indeed, one of
the reasons for this is that the types of hardware used for the
servers may be different as well as the unpredictability of the
resources in a cloud environment.
A. Distinctive Properties of Our Solution
Without going into any details of the arguments presented in
the body of this article, it is prudent to mention the distinctive
properties of our proposed solution when it concerns the
learning mechanism itself and the associated analysis. In all
brevity, they can be listed as follows.
1) By virtue of the “fair balance” paradigm, the learning
algorithm initiated by the LA proposed here is distinct
from all the families of LA described in the LA-based
LB literature, such as in [23]. This includes those
from the previously reported families of ﬁxed structure,
variable structure, discretized, and estimator-based LA.
2) To achieve a fair load balance, we encounter an irony.
Thus, it is, indeed, the fact that the more often an
“action” is chosen, the likelihood of the LA choos-
ing it, even more, must subsequently decrease. In other
words, the rewards that are received for any action must
decrease as the action is chosen more frequently. This is
contrary to what the properties of absolute expedience
and ϵ-optimality entail, especially since, in these cases,
the LA aims to converge to an absorbing barrier in the
probability space. To the best of our knowledge, LA that
possesses the phenomenon mentioned here has not been
proposed in the literature.
3) Our solution is characterized by the amazing property
that as any speciﬁc pi(t) increases, the corresponding
reward probability of the action in question decreases.
We refer to this phenomenon as the “stochastic dimin-
ishing return property.” Informally, this means that the
more an action is chosen, the less it will be rewarded.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 3446
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
This involves the two-time-scale LA with barriers, as we
shall explain presently, and also facilitates fair LB.
4) The analysis methods that we use here are both distinct
and unique. The mathematical techniques used for the
various families of LA described in the literature are
each distinct in their own right. The methodology for
the family of ﬁxed structure stochastic automata (FSSA)
involves formulating the Markov chain for the LA,
computing its equilibrium probabilities, and then com-
puting the asymptotic action selection probabilities. The
proofs of convergence for variable structure stochastic
automata (VSSAs) involve the theory of small-step
Markov processes, distance diminishing operators, and
the theory of regular functions. The proofs for dis-
cretized LA involve the asymptotic analysis of the
Markov chain that represents the LA in the discretized
space, whence the
total probability of convergence to
the various actions is evaluated. The proof of estima-
tor/pursuit algorithms concerns two intertwined phenom-
ena, i.e., the convergence of the reward estimates and
the convergence of the action probabilities themselves.
The proof methodology considered in this article utilizes
the theory of small-step Markov processes and distance
diminishing operators, but, unlike the existing LA, they
do not converge to absorbing barriers but ﬁxed points in
the corresponding probability vector space.
5) Historically, the metric for analyzing LA has gener-
ally been ϵ-optimality and absolute expedience. Indeed,
the concept of the Lyapunov stability of an LA solution
has been rarely used with few exceptions [9]. This is,
indeed, the metric that we have invoked.
B. Contributions of This Article
The contributions of this article can be summarized as
follows.
1) We present an LA solution for ensuring the fairness of
load distribution in the ﬁeld of LB.
2) We present deep theoretical results that prove the con-
vergence of our scheme.
3) We use some of the most recent advances in the ﬁeld of
LA that combines the time-separation paradigm and the
phenomenon of artiﬁcial barriers, introduced by Yazidi
and Hammer [51] and Yazidi et al. [52], respectively.
4) We prove that the equilibrium point which the algorithm
converges to is asymptotically Lyapunov stable. The
concept of the Lyapunov stability of an LA solution
has been rarely used, except for a very few reported
results [9].
5) We provide some experimental results that conﬁrm and
justify our theoretical assertions.
C. Organization of This Article
This article is organized as follows. The background and
related work are ﬁrst presented in Section II. In Section III,
we give an introduction to the theory of LA that is central to
this article. Section IV includes the details of our proposed
solution, where we present the scheme itself in Section IV-C
and report the theoretical results proving its convergence to an
optimal equilibrium in Section IV-D. Thereafter, in Section V,
we include the results of rigorous simulations that conﬁrm the
theoretical results. Section VI concludes this article.
II. BACKGROUND AND RELATED WORK
Historically, LB and task scheduling have been two closely
related research areas that have been widely investigated.
However, the literature that reports the use of stochastic LA
to achieve these has been limited.
A stochastic LA model for the decentralized control of job
scheduling in distributed processing systems was presented
by [22]. The algorithm proposed by these authors operates
with absolutely no prior knowledge about the job but rather
adapts to the changing loads of the hosts. The aim of the
proposed algorithm was to provide load-balanced jobs to a
number of hosts and to improve the response time while
achieving this.
To minimize the response time, a heuristic LB scheme
based on the concept of a stochastic LA was implemented
by Kunz [15]. Depending on the status of the current load
distribution, a new task would be scheduled to be executed
either locally or on a remote host. This article employed a
learning scheme with a reward constant A of 0.25 and a
penalty constant B of 0.3. Although many ﬁne details were
not reported in this article, the author claimed to also have
examined other inﬂuences on different numbers of automa-
ton states and the behavior of the scheduler under different
network sizes.
Misra et al. [23] presented a framework based on LA that is
capable of addressing some of the challenges and demands of
various cloud applications. The proposed framework analysis
invoked various performance metrics, such as response time,
parallel execution speed, and job priority. These metrics were
then used to select the appropriate resources, using LA.
A Cost Aware S-model (CA-S) Reward Epsilon-Penalty
method was proposed in [46]. The authors employed an
LA-based solution that sought to reduce the average cost in
serving web requests with replicated web servers, deployed in
different geographical regions. To minimize the cost, the LA
made routing decisions for each incoming request by assess-
ing response times and energy prices at the different server
locations through action selection probabilities. This article
reported very promising experimental results by using the
proposed CA-S method. These results demonstrated that the
total average cost of serving web responses could be reduced
up to 33% compared with the minimum cost ﬂow dynamic
server selection algorithm and up to 49.2% compared with
the traditional RR method.
The problem of optimal priority assignment among two
streams of jobs with unknown characteristics, each with ran-
dom service time and a random arrival time, was addressed
in the doctoral thesis of Meybodi [20]. A threshold was
computed, which was the average service time taken over
both streams, and the response time of a served dispatched
request from the chosen stream by the LA was compared
with that threshold for the inferred LA response. This idea
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3447
of using response time-based threshold in a queuing system
as a mechanism for inferring the response of LA to constitute
the rewards/penalties appeared also in [3]. Similarly, in this
work, we resort to a dynamic threshold computed using a
type of moving average, in contrast to a stationary type of
estimator found in the seminal work of Meybodi [20] and
Meybodi and Lakshmivarhan [21]. Apart from the queuing
system model, this article is different from the work in [20].
Indeed, the LA proposed by Meybodi [20] was absorbing
because the optimal solution was to be exclusively chosen
from one of the priority streams. Furthermore, the dynamics
of the reward probabilities addressed here are much more
complicated in our problem setting. An alternative solution to
the priority assignment problem based on FSSA was proposed
by Srikanta Kumar [14]. The problem was revisited recently
using the theory of Petri Nets and LA in [43] and [44].
However, as our model and solution are distinct, in the interest
of brevity, we shall not expand on these articles any further.
Finally, we emphasize that although LA has been applied in
a few instances in the literature for solving LB problems,
we are not aware of any theoretical analyses of the problems.
The theoretical analysis for this type of LA application is
intrinsically hard due to the dynamic nature of the environment
as the reward dynamics are coupled with the changes in the
actions. LA algorithms in this vein are rather presented as
heuristics with no theoretical guarantees. The only possible
attempt to cast an LA-based LB algorithm into a theoretical
framework was reported in a series of works by the same
research group [31], [47], where the LB problem was mapped
onto a coordinated game.
III. STOCHASTIC LEARNING AUTOMATA
We shall now proceed to present a brief overview of LA [1],
which is the toolkit that we will use to solve the problem.
In psychology, learning is characterized as the act of modi-
fying one’s behavior as a result of acquiring knowledge from
past experience. In the ﬁeld of automata theory, an automaton
can be described as a self-operating machine or control mech-
anism consisting of a set of states, a set of outputs or actions,
an input, a function that maps the current state and input to
the next state, and a function that maps a current state (and
input) to the current output.
The term LA was ﬁrst presented in the survey article by
Narendra and Thathachar (see [27]). LA is well suited for sys-
tems with noisy and incomplete information about the environ-
ment in which they function [1], [16], [26], [27], [29], [34].
The environment is generally stochastic, and the LA lacks
prior knowledge as to which action is the optimal one.
Stochastic LA, which is the probabilistic ﬁnite state machine,
attempts to solve this problem by choosing an initial action
randomly and then updating the action probabilities based on
the response received. The action chosen is dependent on the
action probability distribution vector, which, in turn, is updated
based on the reward/penalty input that the LA receives from
the random environment. This process is repeated until the
optimal action is, hopefully, achieved.
The research on LA is comprehensive, and over the past
decades, several classes have been proposed. LA is mainly
categorized as being FSSA or VSSA. In FSSA, the mapping
between transition and output functions is time-invariant.
Initial research into LA was mainly focused on FSSA.
Tsetlin et al. [42] demonstrated several models of this class
of automata. Gradually, research into LA has been advanced
toward VSSA. LA schemes in this category possess transition
and output functions that evolve as the learning process
proceeds [30]. In VSSA, the state transitions or the action
probabilities are updated at every time step. This class of
automata was introduced by Varshavskii and Vorontsova [45]
in the early 1960s.
LA can further be classiﬁed as either ergodic or endowed
with absorbing barriers based on their Markovian properties.
In an ergodic LA system, the ﬁnal steady state is independent
of the initial state. As opposed to this, for LA with absorbing
barriers, the steady state depends on the initial state, and
once the LA has converged, it will be locked into a so-called
absorbing barrier. Furthermore, while ergodic VSSA is suitable
for nonstationary environments, absorbing barrier VSSA is
preferred in stationary environments. As opposed to these,
a unique property of the work in [53] is that the action with
the highest probability may not be the same one being chosen
most frequently.
Stochastic LA had been utilized in many applications
over the years. Recent applications of LA include resource
usage prediction algorithm for cloud computing environ-
ment [35], channel selection in cognitive radio/dynamic spec-
trum access for WiMAX networks [24], distributed network
formation [6], solutions to the single elevator problem [10],
efﬁcient decision making mechanism for stochastic nonlinear
resource allocation [52], dynamic cost-aware routing of web
requests [46], learning periodic spatiotemporal patterns [50],
content placement in cooperative caching [49], resource selec-
tion in computational grids [8], determining proper subset size
in high-dimensional spaces [38], and image segmentation [37],
to mention a few.
IV. LA LOAD-BALANCING MODEL
In this section, we present our LA model for LB, as well
as the theoretical proofs for the solution’s convergence.
A. Model
We consider a scenario where we have a set of r servers.
Each server is modeled as an M/M/1 queue, which means
that arrivals are modeled by a Poisson process with some
intensity λi, and the job service times have an exponential
distribution with a service rate μi.
In our model, we assume that an LA is responsible for dis-
patching the request. The LA sends the request to server i with
probability pi(t). We will later deﬁne the update equations for
the LA. However, for the sake of simplicity, we shall give, ﬁrst,
the overall idea for the different updates involved here at the
two time scales, and subsequently, in Section IV-B, we shall
delve into the LA’s detailed update equations.
By virtue of the M/M/1 queue, the mean-response time at
server i is
MRTi(t) =
1
μi −λi(t)
(1)
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 3448
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
where λi(t) is the average arrival rate at server i. If {pi}
are constant or vary slowly over time, then λi(t) can be
approximated using λi(t) = pi(t)λ, which is a consequence
of the M/M/1 queue model [17].
Let si(t) be the instantaneous response time of server i
at time t. In order to estimate the average response time of
each server (i.e., ˆsi), we merely use the exponential mov-
ing average approach with the learning parameter α. The
parameter α is the learning parameter of the scheme and is
similar to the parameter used in any learning algorithm. It is a
hyperparameter determined by a “rule of thumb” or trial and
error for the particular setting. A larger value of α implies
a larger step away from the current value, and vice versa.
This, in turn, illustrates the speed-accuracy dilemma of the
estimate.
Let ˆsi(t) be the estimate of the average response time of
server i.
Once the action i is polled, i.e., the request is dispatched to
server i, the estimate ˆsi(t + 1) of the average is immediately
updated using an adaptive estimator, namely, the exponential
moving average given by
ˆsi(t + 1) = ˆsi(t) + α(si(t) −ˆsi(t)).
(2)
The average response time for the other severs (actions) are
left unchanged. In other words
ˆs j(t + 1) = ˆs j(t) for j ̸= i,
j ∈[1, n].
(3)
We now consider how the corresponding rewards and
penalties are constructed. If action i is chosen, the reward
or penalty is constructed as following using some type of
dynamic threshold:
1) reward if ˆsi ≤(1/r) r
k=1 ˆsk;
2) penalty if ˆsi > (1/r) r
k=1 ˆsk.
With these deﬁnitions as a backdrop, we are able to formally
present the steps of our algorithm.
B. Initialization Criteria
Without any knowledge of ˆsi, which is estimated using
an exponential moving average as per (2), we have opted
to initialize ˆsi to a random low value of response time
close to zero. As in any exponential moving average scheme,
the value that we use for this initialization is not critical.
In our experiments, we assigned this value as ˆsi(0) for all
the r servers. This is in line with the spirit of what is done
in LA, where the initialization is achieved by values that are
equal. In fact, without the accurate knowledge of initial LA’s
action probability, the initial probability for each action i is
usually set to (pi(0) = (1/r)). In our case, we have also
veriﬁed experimentally that the initial value of ˆsi does not
have any effect on the long-term convergence behavior of the
scheme that is an observation consistent with the behavior of
the exponential moving average schemes that are ergodic by
nature. However, in real-life settings, the experimenter might
assign an initial value of ˆsi that is more informed based on an
a priori knowledge of server i. In this case, one might also
alter the initial LA probabilities, so as to move away from the
uniform distribution, i.e., pi(0) = (1/r).
C. Details of Our Solution: Two-Time-Scale LA With Barriers
The ﬁrst step in our solution process is to see how we
can transform the Markov process given by the probability
space from being absorbing to being ergodic. The reader
who is aware of the ﬁeld of Markov chains will immediately
recognize that this is, actually, the converse of what the
literature [5], [39]1 reports when an ergodic chain is rendered
artiﬁcially absorbing, as in the families of artiﬁcially absorbing
discretized LA, such as ADLRP and ADLIP [30]. Rather than
using the actual limits of the probability space to be zero and
unity, we work with the constraint that no probability value can
take on value below a prespeciﬁed lower threshold of pmin or
a value above a prespeciﬁed upper threshold of pmax [51]. The
action-choosing probability values, which traditionally move
proportionally toward zero and unity for the LRI scheme, for
example, are now made to move toward the respective values
of pmin and pmax, respectively. Interestingly enough, this minor
modiﬁcation renders the scheme to be ergodic, making the
analysis also to be correspondingly distinct from that of LRI
and similar schemes.
To achieve this, we enforce a minimal value pmin, where 0 <
pmin < 1 for each selection probability xi, where 1 ≤i ≤r
and r is the number of actions. As a result, the maximum value
any selection probability pi, where 1 ≤i ≤r, can achieve is
pmax = 1 −(r −1)pmin. This happens when the other r −1
actions take their minimum value pmin, while the action with
the highest probability takes the value pmax. Consequently, pi,
for 1 ≤i ≤r, will take values in the interval [pmin, pmax].
To proceed with the formulation, let α(t) be the index of
the chosen action at time instant t. Then, the value of pi(t) is
updated as per the following simple rule (the rules for other
values of p j(t), j ̸= i, are analogous):
pi(t + 1) ←pi(t) + θ(pmax −pi(t))
when α(t) = i and vi = 1
pi(t + 1) ←pi(t) + θ(pmin −pi(t))
when α(t) = j,
j ̸= i and vi = 1
where θ is a user-deﬁned parameter 0 < θ < 1, typically close
to zero. Furthermore, vi is a reward function indicator deﬁned
as follows.
1) vi = 1, reward, if the instantaneous response of the
chosen server is under the running moving average of
the mean response time si ≤(1/r) r
k=1 ˆsk.
2) vi = 0, penalty, if the instantaneous response of the
chosen server exceeds the running moving average of
the mean response time ˆsi > (1/r) r
k=1 ˆsk.
In our algorithm, we avoid using a classical projection
method to map the solution to our feasible space, implying that
all components of the probability vector are within the interval
[pmin, pmax]. Projection methods have been earlier used in
the ﬁeld of LA for enforcing artiﬁcial barriers. A prominent
example of this is given by Simha and Kurose [39] who tackled
a number of actions r > 2, which is a more challenging
1The projection method is a classical method in constrained optimization
[5] that ensures that the solution is mapped back in the feasible search space
whenever it falls outside. The relative reward LA devised [39] adopts artiﬁcial
barriers for more than two actions using the projection method.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3449
Algorithm 1 Two-Time-Scale-Based LA Solution
Loop
1. Poll an action at time instant t according to the probability
vector [p1, p2, . . . , pr].
2. Updating the response time estimates.
• Update the response time of the chosen action
ˆsi(t + 1) = ˆsi(t) + α(si(t) −ˆsi(t))
• The response estimates for the other actions are kept
unchanged, and so
ˆs j(t + 1) = ˆs j(t) for j ̸= i, j ∈[1,r]
3. Environment response: Reward/Penalty.
• vi = 1 (Reward) if ˆsi ≤1
r
r
k=1 ˆsk;
• Otherwise, vi = 0 (Penalty).
4. Let α(t) be the index of the chosen action at time instant t.
The value of pi(t) is updated as per the following simple
rule below, (where the update rules for other values of
p j(t), j ̸= i, are similar)
pi(t + 1) ←pi(t) + θ(pmax −pi(t))
when α(t) = i
and vi = 1
pi(t + 1) ←pi(t) + θ(pmin −pi(t))
when α(t) = j, j ̸= i
and vi = 1.
scenario than he two-action scenario. However, our approach
does not involve projection methods as the update equations
will always ensure that the probabilities will be in our feasible
space. Furthermore, in contrast to projection methods, our
LA update methodology naturally ensures that the probability
vector will always sum to unity in a manner that can be seen
to be a generalization of the LRI LA. The classical LRI LA
can be seen as an instance of our algorithm with pmax = 1.
Let the average of all the instantaneous response times of
all the nodes at time t be given by ˆs(t) deﬁned by
ˆs(t) = 1
r
r

k=1
ˆsk(t).
(4)
We also introduce the following notation:
Di(t) = Prob(si(t) ≤ˆs(t))
(5)
where ˆs(t) is given by (4).
A consequence of these assignments is a scheme formalized
by the pseudocode given in Algorithm 1. The algorithm
proceeds as follows in a loop. Each time a request is received,
the LA probability vector is used to choose a server by
polling an action, which corresponds here to a server among
the r severs. The server choice corresponds to Step 1 in
the pseudocode given in Algorithm 1. Once the server is
chosen, the instantaneous response time of the chosen server
for that requested is observed. Then, in step 2, based on
this observation, we update the average response time of the
chosen server of the pseudocode using the exponential moving
average. The estimates for the other “unchosen” servers will be
kept unchanged. In Step 3, the chosen action receives a reward
or a penalty by comparing the estimated response time of the
chosen server to a dynamic threshold and the mean of the
individual average response times of the r servers. In Step 4,
we operate with the same rules of the classical LRI LA but
with the exception of accommodating artiﬁcial barriers. If the
chosen action resulted in a reward, its probability is increased,
while the probabilities of the rest of the r −1 actions are
decreased. However, if the chosen action results into a penalty,
the probability vector is kept unchanged as per the LRI LA
philosophy.
With these deﬁnitions in place, we are in a position to
analyze the scheme and give theoretical results. This is done in
Section IV-D. We show that as pi(t) increases this quantity,
Prob(si(t) > ˆs(t)) decreases. This is an extremely interest-
ing observation because the latter quantity is, quite simply,
the reward probability when choosing action i. This is referred
to as the “stochastic diminishing return” property, which,
informally, means that the more an action is chosen, the less
its reward will be. Thereafter, we will prove the scheme’s
convergence.
D. Theoretical Analysis
In this section, we shall investigate and analyze the asymp-
totic behavior of our LA-based two-time-scale separation
solution with artiﬁcial barriers. We shall analyze our scheme
in terms of both its convergence and stability.
Theorem 1: For a sufﬁciently small α and θ ≪α, ˆsi(t) can
be approximated by M RTi(pi(t)) = (1/μi −λi pi(t)) for all
1 ≤i ≤r.
Proof: We will prove that for 1 ≤i ≤r, ˆsi(t) converges
to ¯si(pi(t)), where ¯si denotes MRTi.
The proof is based on the theory of stochastic approx-
imation [2]. Since θ is much smaller than α, pi’s evolve
at a slower time scale compared with ˆsi’s, which, in turn,
guarantees the two-time-scale separation. Using the notation
that α(t) = i means that action i is chosen at time t, we can
write
ˆsi(t + M) = ˆsi(t) + α
M−1

k=0
I{α(t+k+1)=i}(si(t + k) −ˆsi(t + k)).
As per the theory of small step processes, we can
assume that whenever α is small enough, the vector [ˆs1(t),
ˆs2(t), . . . , ˆsr(t)] remains almost unchanged in the discrete
interval {t, t +1, . . ., t +M}. Thus, we can write the following
approximate equations for 1 ≤i ≤r:
ˆsi(t + M) ≈ˆsi(t) + Mα(Ri(t, M) −Qi(t, M)ˆsi(t)).
(6)
For i ∈[1,r], when the values of the estimates {ˆs1(.),
ˆs2(.), . . . , ˆsr(.)} are, respectively, considered ﬁxed at {ˆs1(t),
ˆs2(t), . . . , ˆsr(t)}, and M is large, we now approximate the
quantities
Ri(t, M) =
M−1
k=0 I{α(t+k+1)=i}si(t + k)
M
as well as
Qi(t, M) =
M−1
k=0 I{α(t+k+1)=i}
M
.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 3450
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
The probability vector p1(.), p2(.), . . . , pr(.), too, can be
regarded to be essentially constant in the interval {t, t +
1, . . . , t + M} because we have afﬁrmed that pi evolves at
a slower time scale compared with ˆsi. Note that the fact that
θ is much smaller than α permits the separation at this time
scale.
Now, assuming that M is large enough such that the law of
large numbers is in effect, the average
Qi(t, M) =
M−1
k=0 I{α(t+k+1)=i}
M
that is the fraction of time the action i was chosen in the
interval [t, t + M] and converges to pi(t).
By
reckoning the
actions’
probabilities to
be
ﬁxed,
the response time processes si(.)can converge to a stationary
distribution, with the mean being denoted by ¯si(pi(t)).
Furthermore, the quantities
Ri(t, M) =
M−1
k=0 I{α(t+k+1)=i}si(t + k)
M
can be approximated by pi(t)¯si(pi(t)).
Employing
the
approximations
as
described
earlier,
we
notice
from
(6)
that
the
evolution
of
the
vector
[ˆs1(.), ˆs2(.), . . . , ˆsr(.)] reduces to the following ODE system
when α is sufﬁciently small:
ˆsi(t)
dt
= pi(t).(¯si(pi(t)) −ˆsi(t)).
(7)
One observes that (7) reduces to having the running
response time estimates, given by [ˆs1(.), ˆs2(.), . . . , ˆsr(.)],
converging to a steady-state vector [¯s1(p1(t)), ¯s2(p2(t)),
¯sr(pr(t))] whenever α tends to 0.
We now invoke the properties of the M/M/1 queue model,
alluded to above. As per the properties of the M/M/1 queue
model, we know that
¯si(pi(t)) = MRTi(pi(t)) =
1
μi −λi pi(t).
(8)
This, indeed, concludes the proof.
□
In Theorem 2, we shall prove the diminishing property
of our designed feedback mechanism. In fact, our reward
is deﬁned by the fact that the instantaneous response time
observed when we choose a server is smaller than ˆs(t), which
is the arithmetic mean of ˆsi(t) for 1 ≤i ≤n, where ˆsi(t) is the
running estimate (i.e., the exponential moving average) of the
response time at server i. Using the notation of (5), we will
show that the reward probability decreases as we increase pi.
Theorem 2: Di(t) is monotonically strictly decreasing as a
function of pi.
Proof:
We consider the reward probability Di(t) =
Prob(si(t) ≤ˆs(t)), where ˆs(t) is given by (4).
As a consequence of the previous result from Theorem 1,
if the ˆsi’s evolve at a slower time scale than the pi’s, we can
approximate ˆs(t) by the sum of the mean response times of
each server, i.e., sum of MRTi(t), 1 ≤i ≤r. In other words,
ˆs(t) ≈(r
k=i ¯si(pi(t))/r) = (r
k=i MRTi(pi(t))/r).
The probability that the response time of server i, si(t),
exceeds ˆs(t) is [36]
Di(t) = Prob(si(t) ≤ˆs(t)) = 1 −exp(−ˆs(t)(μi −λi(t))).
(9)
We need to show that as pi(t) increases, this quantity
decreases. To achieve this, consider (d Di(t)/dpi) given by
(d Di(t)/dpi) = (δDi(t)/δpi) + r
j=1
j̸=i
(δDi(t)/δp j)(δp j/δp j).
In order to apply the chain rule for the derivation, we resort
to a subtle mathematical trick similar to the one used in [18]
and [48]. We deﬁne arbitrary constants b j ≥0 for j ̸= i,
whence, following a derivation similar to the one in [18]
and [48], we have
p1 = b1 pi, p2 = b2 pi, . . . pr = br pi,
with b j ≥0 for j ̸= i.
Consequently
p1 = b1(1 −pi)

m bm
· · · = · · ·
p j = b j(1 −pi)

m bm
· · · = · · ·
pr = br(1 −pi)

m bm
.
(10)
Now, since 
m pm = 1, we can obtain (dp j/dpi) =
(−b j/
m̸= j bm) < 0 for all j ̸= i.
Considering the expression for Di(t), we see that
Di(t) = 1 −exp(−ˆs(t)(μi −λi(t))
= 1 −exp

−μi −λi(t)
r

k
1
μk −λk(t)

= 1 −exp
⎛
⎜⎝−1
r −
r

k=1
k̸=i
1
r(μk −λpk(t))
⎞
⎟⎠.
This expression is independent of pi, which implies that
(δDi(t)/δpi) = 0. Consequently, (δDi(t)/δpi) reduces to
(d Di(t)/dpi) = r
j=1
j̸=i
(δDi/δp j)(δp j/δpi).
Algebraic simpliﬁcation leads to
δDi
δp j
=
λ
r(μi −λpi(t))2 exp(−ˆs(t)(μi −λi(t))).
Furthermore, since (dp j/dpi)
<
0, (δDi(t)/δpi)
=
r
j=1
j̸=i
(δDi/δp j)(dp j/dpi) < 0 since all the terms in the
above-mentioned sum are strictly negative.
Hence, the theorem!
□
Theorem 3: For a sufﬁciently small pmin approaching 0,
the system of update equations characterizing the LA has a
unique ﬁxed point equilibrium.
Proof:
E[pi(t + 1) −pi(t)|p(t)] = pi Di(pi)[θ(1 −pi)]
+
r

j=1
j̸=i
p j D j(p j).[θ(pmin −pi)].
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3451
Then
E[pi(t + 1) −pi(t)|p(t) = p]
= pi Di(pi).[θ(1 −pmax + 1 −pi)]
+
r

j=1
j̸=i
p j D j(p j)[θ(pmin −pi)]
(11)
= pi Di(pi).
⎡
⎢⎢⎣θ(1 −pmax +
r

j=1
j̸=i
p j)
⎤
⎥⎥⎦
+
r

j=1
j̸=i
p j D j(p j)[θ(pmin −pi)].
(12)
By taking into account the fact that 1−pmax = (r −1)pmin,
(12) can be simpliﬁed (after some algebraic manipulations)
and written as
E[pi(t + 1) −pi(t)|p(t) = p]
= θ
r

j=1
j̸=i
pi p j(Di(pi) −D j(p j))
+ θpmin
⎛
⎜⎜⎝
r

j=1
j̸=i
p j D j(p j)
⎞
⎟⎟⎠
−θ(r −1)pmin pi Di(pi)
= θ
r

j=1
j̸=i
pi p j(Di(pi) −D j(p j))
+ θpmin
r

j=1
j̸=i
(p j D j(p j) −pi Di(pi))
≈θwi(p)
where wi(p) is deﬁned by wi(p) = r
j=1
j̸=i
pi p j(Di(pi) −
D j(p j)).
For small values of pmin, i.e., as pmin →0, we can
approximate E[pi(t + 1) −pi(t)|p(t) = p] by
E[pi(t + 1) −pi(t)|p(t) = p] = θwi(p).
(13)
We can, thus, write
dpi(t + 1)
dt
= θwi(p).
(14)
Using the above-mentioned result, we shall now proceed
with the details of the proof.
1) Existence and Uniqueness: We will show that w(p) =
(w1(p), w2(p), . . ., wr(p)) has a unique zero in the neighbor-
hood of p∗= (p∗
1, . . . , p∗
r ), which means that we have a ﬁxed
point.
The above-mentioned assertions imply the system of r
equalities
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
r

j=1
j̸=1
p1 p j(D1(p1) −D j(p j)) = 0
r

j=1
j̸=2
p2 p j(D2(p2) −D j(p j)) = 0
...
r

j=1
j̸=r
pn p j(Dr(pr) −D j(p j)) = 0.
⇔
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
p1
r

j=1
j̸=2
p j(D1(p1) −D j(p j)) = 0
p2
r

j=1
j̸=2
p j(D2(p2) −D j(p j)) = 0
...
pn
r

j=1
j̸=r
p j(Dr(pr) −D j(p j)) = 0.
The reader should observe that a crucial concept in our
approach is that we are using the barrier pmin, which ensures
that p1 ̸= 0, p2 ̸= 0, . . . , pr ̸= 0. We can, thus, conﬁdently
divide the ﬁrst equation by p1, the second equation by p2, and
so on, yielding
⇔
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
r

j=1
j̸=1
p j(D1(p1) −D j(p j)) = 0
...
r

j=1
j̸=2
p j(D2(p2) −D j(p j)) = 0
...
r

j=1
j̸=r
p j(Dr(pr) −D j(p j)) = 0.
After invoking some algebraic manipulations, we obtain that
⇔
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
D1(p1) =
r

j=1
p j D j(p j)
...
D2(p2) =
r

j=1
p j D j(p j)
...
Dr(pr) =
r

j=1
p j D j(p j)
which guarantees that D1(p1) = D2(p2) = . . . = Dr(pr).
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 3452
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
Now, we will show that the solution is unique.
2) Uniqueness: The uniqueness of p∗is proven by contra-
diction. Suppose there exists q∗= (q∗
1, q∗
2, . . . , q∗
n) that is a
zero of w(q) such that q∗̸= p∗.
Without loss of generality since p∗and q∗are two probabil-
ity vectors such that p∗̸= q∗, we can conﬁdently afﬁrm that
they have at least two components i and j such that p∗
i > q∗
i
and p∗
j < q∗
j . Observe that the result is general and that it
applies for any two distinct probability vectors. Intuitively, this
means that if we increase any one component of a probability
vector, we should decrease another component, so as to ensure
that the sum of the components is unity.
Suppose now that p∗
i
>
q∗
i . Then, by invoking the
monotonicity of the function Di(.), we obtain that Di(p∗
i ) <
Di(q∗
i ). On the other hand, the condition p∗
j < q∗
j implies
that D j(p∗
j) > D j(q∗
j ), where this is obtained by virtue of
the monotonicity of D j(.). However, since p∗and q∗are
equilibrium points, we know that Di(p∗
i ) = D j(p∗
j) and that
Di(q∗
i ) = D j(q∗
j ). This forces a contradiction since it is
impossible to simultaneously maintain that Di(p∗
i ) < Di(q∗
i )
that is equivalent to D j(p∗
j) < D j(q∗
j ) and D j(p∗
j) > D j(q∗
j ).
Therefore, p∗is unique.
□
Theorem 4: The equilibrium point to which the algorithm
converges is asymptotically Lyapunov stable.
Proof: Consider the following Lyapunov function:
V (p(t)) =
r

k=i
 pt
0
Dk(z)dz.
Consider now its derivative
dV (p(t))
dt
=
r

i=1
dV(p(t))
dpi
dpi
dt .
(15)
It is easy to note that by virtue of the integral derivation,
(dV(p(t))/dpi) = Di(t). Furthermore, according to (14),
(dpi/dt) = θwi(p).
Thus
dV (p(t))
dt
= θ
r

k=1
Dk(t)wk(p)
(16)
where wi(p) is deﬁned by wi(p) = r
j=1
j̸=i
pi p j(Di(pi) −
D j(p j)). Therefore
dV(p(t))
dt
= θ
r

i=1
Di
r

j=1
pi p j(Di −D j)
= θ
r

i=1
r

j=1
pi p j(D2
i −Di D j)
= −θ
2
r

i=1
r

j=1
pi p j(Di −D j)2.
Therefore, (dV(p(t))/dt) ≤0.
Observe though that the Lyapunov function must be zero
at its equilibrium point, and thus, (dV(p(t))/dt) = 0. This,
in turn, means that for every i, j, we have p∗
i p∗
j(D∗
i −
D∗
j)2 = 0. However, since p∗
i
> pmin and p∗
j > pmin,
the equality D∗
i (p∗
i ) −D∗
j(p∗
j) = 0 must necessarily be true,
and consequently, for all i, j
D∗
i (p∗
i ) = D∗
j(p∗
j) = 0.
The result follows, since, by the Lyapunov theorem, we have
shown that p∗is an asymptotically Lyapunov stable equilib-
rium point of the scheme.
□
E. Summary Outlining of the Theoretical Results
In Theorem 1, we show that by imposing a two-time-scale
separation, where we slowly update the LA probabilities, while
we update the response times in a faster scale, we are able to
approximate the estimated response times at each server. For
any probability vector that is slowly varying, the response
time estimates converge to a steady state depending on the
probability vector given by (8). Once we have characterized
the response times, we can analyze the behavior of the reward
probabilities of our LA. This is treated in Theorem 2, where
we show an intuitive property, which states that the reward
probability of action is monotonically strictly decreasing as
a function of its respective action probability. Theorem 3
characterizes the ﬁxed point of the LA update equations. The
artiﬁcial barriers as well as the monotonicity of the reward
functions yield a unique ﬁxed point. Interestingly, the ﬁxed
point achieves fairness as the reward probabilities of the action
are “equalized,” and thus, the LA will be indifferent between
the choices of the servers at this point. Theorem 4 shows that
the algorithm converges to asymptotically Lyapunov stable
state by deﬁning an appropriate Lyapunov function.
V. EXPERIMENTAL VERIFICATION
In this section, we will brieﬂy conﬁrm that the theoretical
results that were derived in Section IV hold true. To achieve
this, we conducted two types of experiments. The intent of
the ﬁrst set of experiments was to prove the claims for a
small-scale system, namely, for one with only three servers.
The second, and more extensive testing, involved a larger pool
of servers, i.e., 15. It is clear that such a setting is well in-line
with real-life LB problems. Furthermore, we tested both of the
scenarios in two types of environments: static and dynamic.
For the dynamic case, we report experiments where we either
changed the serving rates of the services or the arrival rate of
the requests.
A. Experiments With Three Servers
1) Static Environment With Three Servers: In this ﬁrst set
of experiments, we simulated three servers characterized by
the parameters, μ1 = 50, μ2 = 33.33, and μ3 = 25,
respectively. We assumed that the total arrival rate was λ1 +
λ2 + λ3 = 50. Furthermore, we used pmin = 0.01. For
the time scale separation, we used two values θ = 0.001
for updating the LA action probabilities and α = 0.01 for
the estimation of the response times. The intention of our
experiments was to observe the action probabilities and the
corresponding response times when the protocol was tested
for 9000 iterations for an ensemble of 1000 experiments.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3453
Fig. 1.
Evolution of the action selection probabilities in a static environment.
Fig. 2.
Evolution of the response times of the different servers in a static
environment.
Fig. 3.
Evolution of the action selection probabilities in an environment with
dynamic serving rates.
The evolution of the probability and response time are
plotted in Figs. 1 and 2, respectively. Interestingly, from Fig. 2,
we observed that the response time was equalized on the
different servers. The results are quite amazing because even
though the corresponding action probabilities converged to
different values, the composite effect of the convergence was
to make the overall response times to be almost equal.
2) Dynamic Serving Rates With Three Servers: To investi-
gate the performance of the scheme for time-varying systems,
we also ran another experiment where we dynamically shufﬂed
the serving rates of the three servers every 5000 iterations.
In this case, the experiments were run for 15000 iterations,
and the number of experiments (over which the ensemble
average was obtained) was 1000. We again observed that the
system stabilized after some time and that it was again capable
of equalizing the response times. Figs. 3 and 4, respectively,
depict the evolution of the action probabilities of each server,
as well as the evolution of the estimated response times.
It is clear that the results demonstrated that even though the
corresponding action probabilities converged to completely
Fig. 4.
Evolution of the response times of the different servers in an
environment with dynamic serving rates.
Fig. 5.
Evolution of the action selection probabilities in an environment with
varying arrival rates and with three servers.
Fig. 6.
Evolution of the response times of the different servers in an
environment with varying arrival rate with three servers.
different values, the overall effect of the scheme’s convergence
was to make the overall response times to be almost equal.
The power of the scheme to balance the loads in an
ϵ-optimal manner is obvious!
3) Dynamic Arrival Rate With Three Servers: In real-life
scenarios, it is more common that the arrival rate of the trafﬁc
changes over time, while the serving rate is usually stable over
time. This is because the latter is an intrinsic characteristic of
the server and does not, usually, change due to extrinsic factors
related to the environment.2 In our simulations, we adjusted
the arrival rate every 6000 iterations. We started with a total
arrival rate of 50, and after the ﬁrst switch, this number was
increased to 60. It was then lowered to 54 after the second
switch. Figs. 5 and 6 report, respectively, the evolution of
the probabilities and the evolution of the response time esti-
mates for this dynamic environment characterized by varying
2The serving rate of a server might degrade slightly over time due to
hardware issues. It is also possible to upgrade the servers for improved
performance. However, such changes are beyond the scope of this work and
are still rare within the lifetime of a server.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 3454
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
Fig. 7.
Evolution of the action selection probabilities in a static environment
with 15 servers.
Fig. 8.
Evolution of the response times of the different servers in a static
environment with 15 servers.
arrival rates. One should observe that our scheme is able
to equalize the response times of the servers after around
3000 iterations.
B. Larger Scale Experiments
1) Static Environment With 15 Servers: In the second set
of experiments, we increased the number of servers to 15 as
per the following parameters: ﬁve servers with μ = 50,
ﬁve servers with μ = 60, and ﬁve servers with μ = 80.
We assumed that the total arrival rate was λ
=
350.
Figs. 7 and 8 illustrate, respectively, the evolution of the prob-
abilities and the evolution of the response time estimates for
a static environment. When it comes to the parameters of
the algorithm, we use the same tuning parameters as in the
previous experiment involving three servers, i.e., θ = 0.001
and α = 0.01. Interestingly, even though the environment was
intrinsically more challenging than the case of having three
servers, we observed that our scheme was able to stabilize the
response times of the 15 servers after around 5000 iterations.
2) Dynamic Serving Rates With 15 Servers: In order to
test the adaptivity of our scheme in large-scale settings,
we executed a “switch” in the environment by modifying
the serving rates every 30000 iterations. The switch was a
right-circular shift of a single position of the serving rate
vector. For example, before the ﬁrst switch, the serving rate
vector of the 15 servers was (μ1 =50, μ2 =60, μ3 =80,
μ4 =50, μ5 =60, μ6 =80, . . ., μ13 =50, μ14 =60, and
μ15 =80), respectively, and after the ﬁrst switch, the serving
rates became (60, 80,50, . . ., 60, 80, and 50). Figs. 9 and 10,
respectively, depict the evolution of the action probabilities of
each server, as well as the evolution of the estimated response
times.
Fig. 9.
Evolution of the action selection probabilities in a dynamic
environment with dynamic serving rates and with 15 servers.
Fig. 10.
Evolution of the response times of the different servers in a dynamic
varying environment with dynamic serving rates and with 15 servers.
However, with such a large number of servers, it is clear that
we could run into stability issues of the queues whenever the
arrival rate at a given server became higher than its serving rate
as a consequence of the shift in the serving rates. Formally,
this instability can be seen to be a consequence of violating
the condition μi −λi > 0, where λi = λpi. For instance,
this happens after the ﬁrst switch, as we can easily observe.
Consider, in this case, the third server. Before the switch,
p3 stabilized to 0.152, while the processing rate was as high
as 80. Abruptly, however, after the switch, in the serving
rates, the same server, i.e., 3, obtained a new processing rate
50, which was much lower than before, while p3 was 0.152.
This, clearly, led to a queue instability since, in this case,
μ3 −λ3 = 50 −350 × 0.152 = −3.2 < 0 because the server
was receiving more trafﬁc than it could serve, which it, clearly,
could not handle.
3) Dynamic Arrival Rate With 15 Servers: In order to
test the adaptivity of our scheme when facing changes in
the arrival rate, we executed an environment switch every
30000 iterations. We started with an arrival rate of 350,
and after the ﬁrst switch, we dropped it to 280, and then,
we invoked a further drop to 252.
Figs. 11 and 12, respectively, depict the evolution of the
action probabilities of each server, as well as the evolution of
the estimated response times.
C. Comparison Results in Terms of Fairness
In this article, we claimed that our algorithm is fair in
the sense that the response times from the different servers
are equalized, and thus, a client will experience, on average,
the same QoS, measured in terms of the average response time,
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3455
Fig. 11.
Evolution of the action selection probabilities in a dynamic
environment with varying arrival rate and with 15 servers.
Fig. 12.
Evolution of the response times of the different servers in a dynamic
environment with varying arrival rate and with 15 servers.
Fig. 13.
Fairness comparison of the different LB algorithms in a static
environment with varying arrival rate and with three servers.
independent of the chosen server. It is not our place to compare
the presented algorithm to other LB algorithms in the literature
in terms of fairness. To this end, we resort to three commonly
deployed LB algorithms: RR, WRR, and Po2 algorithm [25].
When it comes to WRR, each server’s weight is proportional
to the service rate of the server. The fairness will be measured
utilizing Jain’s fairness index [4], using the formula
JFI =
r
i=1 ˆsi(t)
2
r r
i=1 ˆsi(t)2 .
(17)
If the estimated response times of the different servers
are equalized, the JFI will be equal to unity, its maximum
value. The JFI by deﬁnition ranges between zero and unity.
In Fig. 13, we report the ensemble average over 1000 experi-
ments of the fairness index (JFI) for our LA algorithm against
the aforementioned comparison algorithms for the case of
three servers. The environment is static, and the settings of
the environment are the same settings as in Section V-A1.
From Fig. 13, we see that our LA algorithm achieves the
highest JFI followed by the WRR. The reader should note
Fig. 14.
Fairness comparison of the different LB algorithms in a static
environment with varying arrival rate and with 15 servers.
that the WRR operates with extra knowledge than the LA
algorithm, in which it assumes complete knowledge of the
servers’ serving rates to deﬁne its weights. Thus, we state that
the LA algorithm is a superior solution in the sense that it
achieves almost optimal JFI values, around unity, with little
information, i.e., with no knowledge of the serving rates of the
servers. Similarly, we conducted an experiment with 15 servers
using the same settings as in Section V-B1. Fig. 14 shows
the behavior of our LA algorithms versus the state-of-the-art
comparison algorithms. We observe similar remarks to those of
the case of three servers reported in Fig. 13. In fact, the LA
algorithms are the most superior algorithm in terms of JFI
followed by WRR. However, the Po2 achieves the lowest
performance, which was not the case when we used three
servers (see Fig. 13). The primary reason for this is that, as the
number of servers increases, the Po2 will by deﬁnition select
among two random servers among 15 servers, which gives it a
limited view of the environment composed of a high number
of servers, in this case, 15, and, consequently, leads to poor
performance.
VI. CONCLUSION
With the proliferation of network-based services, the
increasing popularity of the cloud approaches that allow fair
LB is becoming more important than before. Cloud computing
is characterized by the volatility of resources and the vari-
ability that makes static LB approaches inefﬁcient. In this
article, we presented a dynamic LB approach that aspires to
achieve “almost optimal” fairness between different servers
in terms of a QoS-based metric. We used the theory of LA
to deal with the problem and designed a sophisticated LA
that combined the time-separation paradigm and the concept
of “artiﬁcial” ergodic (i.e., nonabsorbing) barriers, which was
recently introduced by Yazidi and Hammer [51] and Yazidi
et al. [52], respectively. In contrast to classical LA, the envi-
ronment considered was modeled to be nonstationary, and the
reward probabilities were shown to be characterized by a law
of diminishing returns.
As a future research endeavor, we intend to implement our
solution in a real-life cloud setting and to test its efﬁciency
and fairness compared with other classical approaches.
ACKNOWLEDGMENT
The authors are very grateful for the feedback from the
anonymous referees of the original submission. Their input
signiﬁcantly improved the quality of this ﬁnal version.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 3456
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021
REFERENCES
[1] M. Agache and B. J. Oommen, “Generalized pursuit learning schemes:
New families of continuous and discretized learning automata,” IEEE
Trans. Syst., Man, Cybern. B. Cybern., vol. 32, no. 6, pp. 738–749,
Dec. 2002.
[2] A. Benveniste, P. Priouret, and M. Métivier, Adaptive Algorithms and
Stochastic Approximations. New York, NY, USA: Springer-Verlag, 1990.
[3] E. A. Billard, “Stabilizing distributed queuing systems using feedback
based on diversity,” IEEE Trans. Syst., Man, Cybern. A, Syst. Humans,
vol. 27, no. 2, pp. 251–256, Mar. 1997.
[4] P.
N.
D.
Bukh
and
R.
Jain,
The
Art
of
Computer
Systems
Performance Analysis: Techniques for Experimental Design, Mea-
surement,
Simulation,
and
Modeling.
1992.
[Online].
Available:
https://www.jstor.org/stable/25061650?seq=1
[5] P. H. Calamai and J. J. Moré, “Projected gradient methods for linearly
constrained problems,” Math. Program., vol. 39, no. 1, pp. 93–116,
Sep. 1987.
[6] G. C. Chasparis and J. S. Shamma, “Network formation: Neighborhood
structures, establishment costs, and distributed learning,” IEEE Trans.
Cybern., vol. 43, no. 6, pp. 1950–1962, Dec. 2013.
[7] N. Dragoni et al., “Microservices: Yesterday, today, and tomorrow,”
in Present and Ulterior Software Engineering. Cham, Switzerland:
Springer, 2017, pp. 195–216. [Online]. Available: https://link.springer.
com/chapter/10.1007/978-3-319-67425-4_12
[8] A. Enami, J. A. Torkestani, and A. Karimi, “Resource selection in
computational grids based on learning automata,” Expert Syst. Appl.,
vol. 125, pp. 369–377, Jul. 2019.
[9] M. Fahimi and A. Ghasemi, “A distributed learning automata scheme
for spectrum management in self-organized cognitive radio network,”
IEEE Trans. Mobile Comput., vol. 16, no. 6, pp. 1490–1501, Jun. 2017.
[10] O. Ghaleb and B. J. Oommen, “Learning automata-based solutions
to the single elevator problem,” in Proc. IFIP Int. Conf. Artif. Intell.
Appl. Innov. Cham, Switzerland: Springer, 2019, pp. 439–450. [Online].
Available:
https://link.springer.com/chapter/10.1007/978-3-030-19823-
7_37
[11] E. J. Ghomi, A. M. Rahmani, and N. N. Qader, “Load-balancing
algorithms in cloud computing: A survey,” J. Netw. Comput. Appl.,
vol. 88, pp. 50–71, Jun. 2017.
[12] R. L. Grossman, “The case for cloud computing,” IT Prof., vol. 11, no. 2,
pp. 23–27, Mar./Apr. 2009.
[13] J. Kleinberg and E. Tardos, Algorithm Design: Pearson New Interna-
tional Edition. London, U.K.: Pearson Higher Ed, 2013.
[14] P. S. Kumar, “A simple learning scheme for priority assignment at a
single-server queue,” IEEE Trans. Syst., Man, Cybern., vol. 16, no. 5,
pp. 751–754, Sep. 1986.
[15] T. Kunz, “The inﬂuence of different workload descriptions on a heuristic
load balancing scheme,” IEEE Trans. Softw. Eng., vol. 17, no. 7,
pp. 725–730, Jul. 1991.
[16] S. Lakshmivarahan, Learning Algorithms Theory and Applications.
New York, NY, USA: Springer-Verlag, 1981.
[17] J. D. Little and S. C. Graves, “Little’s law,” in Building Intuition.
Boston, MA, USA: Springer, 2008, pp. 81–100. [Online]. Available:
https://link.springer.com/chapter/10.1007/978-0-387-73699-0_5
[18] L. Mason, “An optimal learning algorithm for S-model environments,”
IEEE Trans. Autom. Control, vol. AC-18, no. 5, pp. 493–496, Oct. 1973.
[19] P. Mell and T. Grance. (2018). The NIST Deﬁnition of Cloud Com-
puting. Accessed: Sep. 16, 2019. [Online]. Available: https://csrc.
nist.gov/publications/detail/sp/800-145/ﬁnal
[20] M. R. Meybodi, “Learning automata and its application to prior-
ity assignment in a queueing system with unknown characteristics,”
Ph.D. dissertation, School Elect. Eng. Comput. Sci., Univ. Oklahoma,
Norman, OK, USA, 1983. [Online]. Available: https://shareok.org/
bitstream/handle/11244/5130/8314780.PDF?sequence=1&isAllowed=y
[21] M. Meybodi and S. Lakshmivarhan, “A learning approach to prior-
ity assignment in a two class m/m/1 queuing system with unknown
parameters,” in Proc. 3rd Yale Workshop Appl. Adapt. Syst. Theory.
New Haven, CT, USA: Yale Univ., 1983, pp. 106–109.
[22] R. Mirchandaney
and J. A. Stankovic,
“Using stochastic
learn-
ing automata for job scheduling in distributed processing systems,”
J. Parallel Distrib. Comput., vol. 3, no. 4, pp. 527–552, Dec. 1986.
[23] S. Misra, P. V. Krishna, K. Kalaiselvan, V. Saritha, and M. S. Obaidat,
“Learning automata-based QoS framework for cloud IaaS,” IEEE Trans.
Netw. Service Manag., vol. 11, no. 1, pp. 15–24, Mar. 2014.
[24] S. Misra, S. S. Chatterjee, and M. Guizani, “Stochastic learning
automata-based channel selection in cognitive radio/dynamic spectrum
access for WiMAX networks,” Int. J. Commun. Syst., vol. 28, no. 5,
pp. 801–817, 2015.
[25] M. Mitzenmacher, “The power of two choices in randomized load
balancing,” IEEE Trans. Parallel Distrib. Syst., vol. 12, no. 10,
pp. 1094–1104, Oct. 2001.
[26] K. Najim and A. S. Poznyak, Learning Automata: Theory and Applica-
tions. Oxford, U.K.: Pergamon Press, 1994.
[27] K. S. Narendra and M. A. L. Thathachar, Learning Automata:
An Introduction. Upper Saddle River, NJ, USA: Prentice-Hall, 1989.
[28] A. Nordrum. Popular Internet of Things Forecast of 50 Billion Devices
by 2020 is Outdated, 2018. Accessed: Sep. 16, 2019. [Online].
Available:
https://spectrum.ieee.org/tech-talk/telecom/internet/popular-
internet-of-things-forecast-of-50-billion-devices-by-2020-is-outdated
[29] M. S. Obaidat, G. I. Papadimitriou, and A. S. Pomportsis, “Learning
automata: Theory, paradigms, and applications,” IEEE Trans. Syst., Man,
Cybern. B. Cybern., vol. 32, no. 6, pp. 706–709, Dec. 2002.
[30] B. J. Oommen, “Absorbing and ergodic discretized two-action learning
automata,” IEEE Trans. Syst., Man, Cybern., vol. SMC-16, no. 2,
pp. 282–293, Mar. 1986.
[31] J. Parent, K. Verbeeck, J. Lemeire, A. Nowe, K. Steenhaut, and E. Dirkx,
“Adaptive load balancing of parallel applications with multi-agent rein-
forcement learning on heterogeneous systems,” Sci. Program., vol. 12,
no. 2, pp. 71–79, 2004.
[32] D. K. Patel, D. Tripathy, and C. R. Tripathy, “Survey of load balancing
techniques for grid,” J. Netw. Comput. Appl., vol. 65, pp. 103–119,
Apr. 2016.
[33] C. Pettey. (2019). Cloud Shift Impacts all it Markets. Accessed:
Sep.
16,
2019.
[Online].
Available:
https://www.gartner.com/
smarterwithgartner/cloud-shift-impacts-all-it-markets/
[34] A. S. Poznyak and K. Najim, Learning Automata and Stochastic
Optimization. Berlin, Germany: Springer-Verlag, 1997.
[35] A. A. Rahmanian, M. Ghobaei-Arani, and S. Toﬁghy, “A learn-
ing automata-based ensemble resource usage prediction algorithm for
cloud computing environment,” Future Gener. Comput. Syst., vol. 79,
pp. 54–71, Feb. 2018.
[36] H. Roh, C. Jung, W. Lee, and D.-Z. Du, “Resource pricing game
in geo-distributed clouds,” in Proc. IEEE INFOCOM, Apr. 2013,
pp. 1519–1527.
[37] Q. Sang, Z. Lin, and S. T. Acton, “Learning automata for image
segmentation,” Pattern Recognit. Lett., vol. 74, pp. 46–52, Apr. 2016.
[38] S. H. Seyyedi and B. Minaei-Bidgoli, “Using learning automata to
determine proper subset size in high-dimensional spaces,” J. Exp. Theor.
Artif. Intell., vol. 29, no. 2, pp. 415–432, Mar. 2017.
[39] R. Simha and J. F. Kurose, “Relative reward strength algorithms for
learning automata,” IEEE Trans. Syst., Man, Cybern., vol. 19, no. 2,
pp. 388–398, Mar./Apr. 1989.
[40] A.-A.
Tantar,
A.
Q.
Nguyen,
P.
Bouvry,
B.
Dorronsoro,
and
E.-G. Talbi, “Computational intelligence for cloud management cur-
rent trends and opportunities,” in Proc. IEEE Congr. Evol. Comput.,
Jun. 2013, pp. 1286–1293.
[41] A. Tchernykh, U. Schwiegelsohn, V. Alexandrov, and E.-G. Talbi,
“Towards understanding uncertainty in cloud computing resource provi-
sioning,” Procedia Comput. Sci., vol. 51, pp. 1772–1781, 2015. [Online].
Available:
https://www.sciencedirect.com/journal/procedia-computer-
science/issues
and
https://www.sciencedirect.com/journal/procedia-
computer-science/vol/51/suppl/C
[42] M. L. Tsetlin, Automaton Theory and Modeling of Biological Systems.
New York, NY, USA: Academic, 1973.
[43] S. M. Vahidipour and M. Esnaashari, “Priority assignment in queuing
systems with unknown characteristics using learning automata and
adaptive stochastic Petri nets,” J. Comput. Sci., vol. 24, pp. 343–357,
Jan. 2018.
[44] S. M. Vahidipour, M. R. Meybodi, and M. Esnaashari, “Learning
automata-based adaptive Petri net and its application to priority assign-
ment in queuing systems with unknown parameters,” IEEE Trans. Syst.,
Man, Cybern. Syst., vol. 45, no. 10, pp. 1373–1384, Oct. 2015.
[45] V. I. Varshavskii and I. P. Vorontsova, “On the behavior of stochastic
automata with a variable structure,” Autom. Remote Control, vol. 24,
no. 3, pp. 327–333, 1963.
[46] G. Velusamy and R. Lent, “Dynamic cost-aware routing of Web
requests,” Future Internet, vol. 10, no. 7, p. 57, Jun. 2018.
[47] K. Verbeeck, A. Nowé, and K. Tuyls, “Coordinated exploration in multi-
agent reinforcement learning: An application to load-balancing,” in Proc.
4th Int. Joint Conf. Auto. Agents Multiagent Syst. (AAMAS), 2005,
pp. 1105–1106.
[48] R. Wheeler and K. Narendra, “Decentralized learning in ﬁnite Markov
chains,” IEEE Trans. Autom. Control, vol. 31, no. 6, pp. 519–526,
Jun. 1986.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
 YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM
3457
[49] Z. Yang, Y. Liu, Y. Chen, and L. Jiao, “Learning automata based
Q-learning for content placement in cooperative
caching,” 2019,
arXiv:1903.06235. [Online]. Available: http://arxiv.org/abs/1903.06235
[50] A. Yazidi, O.-C. Granmo, and B. J. Oommen, “Learning-automaton-
based online discovery and tracking of spatiotemporal event patterns,”
IEEE Trans. Cybern., vol. 43, no. 3, pp. 1118–1130, Jun. 2013.
[51] A. Yazidi and H. L. Hammer, “Solving stochastic nonlinear resource
allocation problems using continuous learning automata,” Appl. Intell.,
vol. 48, no. 11, pp. 4392–4411, 2018.
[52] A. Yazidi, H. L. Hammer, and T. M. Jonassen, “Two-time scale learning
automata: An efﬁcient decision making mechanism for stochastic nonlin-
ear resource allocation,” Appl. Intell., vol. 49, pp. 3392–3405, Apr. 2019.
[53] J. Zhang, C. Wang, D. Zang, and M. Zhou, “Incorporation of optimal
computing budget allocation for ordinal optimization into learning
automata,” IEEE Trans. Autom. Sci. Eng., vol. 13, no. 2, pp. 1008–1017,
Apr. 2016.
Anis Yazidi (Senior Member, IEEE) received the
M.Sc. and Ph.D. degrees from the University of
Agder, Grimstad,
Norway, in 2008 and 2012,
respectively.
He was a Researcher with Teknova AS, Grimstad.
From 2014 to 2019, he was an Associate Professor
with the Department of Computer Science, Oslo
Metropolitan University, Oslo, Norway, where he is
currently a Full Professor and leading the Research
Group in Applied Artiﬁcial Intelligence. He is also
Professor II with the Norwegian University of Sci-
ence and Technology (NTNU), Trondheim, Norway. His current research
interests include machine learning, learning automata, stochastic optimization,
and autonomous computing.
Ismail Hassan received the M.Sc. degree in network
and system administration from the University of
Oslo, Oslo, Norway, in 2005.
In 2005, he joined the Oslo University College
(OsloMet), Oslo Metropolitan University, Oslo, as a
Senior System and a Network Engineer, and after
four years, transitioned to the position of Assistant
Professor. He is currently an Assistant Professor
with OsloMet. His ﬁeld of interests includes cyberse-
curity, networking technologies, operating systems,
DevSecOps, teaching, and learning methods.
Hugo L. Hammer received the M.Sc. and Ph.D.
degrees from the Norwegian University of Science
and Technology, Trondheim, Norway, in 2003 and
2008, respectively.
He is currently a Full Professor of statistics
with the Department of Computer Science, Oslo
Metropolitan University, Oslo, Norway. His current
research interests include computer-intensive sta-
tistical methods, Bayesian statistics, and learning
systems.
B. John Oommen
(Life Fellow, IEEE) was born
in Coonoor, India, in September 1953. He received
the B.Tech. degree from IIT Madras, Chennai, India,
in 1975, the M.E. degree from the Indian Institute
of Science, Bengaluru, India, in 1977, and the M.S.
and Ph.D. degrees from Purdue University, West
Lafayette, IN, USA, in 1979 and 1982, respectively.
He was with the School of Computer Science, Car-
leton University, Ottawa, ON, Canada, from 1981 to
1982, where he is currently a Full Professor and,
since July 2006, has been the Chancellor’s Professor,
which is a lifetime award from Carleton University. He is the author of more
than 485 refereed journal and conference publications. His research interests
include automata learning, adaptive data structures, statistical and syntactic
pattern recognition, stochastic algorithms, and partitioning algorithms.
Dr. Oommen is also a fellow of the International Association for Pat-
tern Recognition (IAPR). He has served on the Editorial Board of the
IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS and Pattern
Recognition.
Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore.  Restrictions apply. 
",10.1109/TNNLS.2020.3010888,doc26,"—In this article, we consider the problem of load bal-
ancing (LB), but, unlike the approaches that have been proposed
earlier, we attempt to resolve the problem in a
fair manner
(or rather, it would probably be more appropriate to describe
it as an ϵ-fair manner because, although the LB can, probably,
never be totally fair, we achieve this by being “as close to fair as
possible”). The solution that we propose invokes a novel stochastic
learning automaton (LA) scheme, so as to attain a distribution
of the load to a number of nodes, where the performance level
at the different nodes is approximately equal and each user
experiences approximately the same Quality of the Service (QoS)
irrespective of which node that he/she is connected to. Since the
load is dynamically varying, static resource allocation schemes
are doomed to underperform. This is further relevant in cloud
environments, where we need dynamic approaches because the
available resources are unpredictable (or rather, uncertain) by
virtue of the shared nature of the resource pool. Furthermore,
we prove here that there is a coupling involving LA’s probabilities
and the dynamics of the rewards themselves, which renders the
environments to be nonstationary. This leads to the emergence
of the so-called property of “stochastic diminishing rewards.”
Our newly proposed novel LA algorithm ϵ-optimally solves the
problem, and this is done by resorting to a two-time-scale-based
stochastic learning paradigm. As far as we know, the results
presented here are of a pioneering sort, and we are unaware of
any comparable results.
Index Terms—Continuous learning automaton (LA), fair load
balancing (LB), resource allocation.
I.","3444 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 Achieving Fair Load Balancing by Invoking a Learning Automata-Based Two-Time-Scale Separation Paradigm Anis Yazidi , Senior Member, IEEE, Ismail Hassan, Hugo L. Hammer , and B. John Oommen , Life Fellow, IEEE Abstract INTRODUCTION I N THIS article, we consider the problem of load balanc- ing (LB), which is extremely pertinent in today’s highly connected world. To put the problem in the right perspec- tive, we observe that, unarguably, computers, and information technology have experienced enormous growth and devel- opment over the past three decades. This unalterable trend Manuscript received December 18, 2019; revised June 3, 2020; accepted July 12, 2020. Date of publication August 5, 2020; date of current version August 4, 2021. The work of B. John Oommen was supported in part by the Natural Sciences and Engineering Council of Canada (NSERC). (Corresponding author: B. John Oommen.) Anis Yazidi, Ismail Hassan, and Hugo L. Hammer are with the Department of Computer Science, Oslo Metropolitan University, 0130 Oslo, Norway. B. John Oommen is with the School of Computer Science, Carleton University, Ottawa, ON K1S5B6, Canada, and also with the IKT Department, University of Agder, 4879 Grimstad, Norway (e-mail: oommen@ scs.carleton.ca). Color versions of one or more of the ﬁgures in this article are available online at Digital Object Identiﬁer 10.1109/TNNLS.2020.3010888 has profoundly affected societies worldwide, in every sense of the word. Products and services that were traditionally delivered through other means are, currently, online services. Unlike the scenario a few decades ago, where one “con- nected” directly to an institution’s machine, most of these services are now being executed on the internet. Since more than 50 billion devices will be connected to the Internet by 2020 [28], one understands that the traditional model of having in-house computers and resources is not going to be a sustainable and viable option. Rather, to cope with the sheer increase in the number of users and devices inter- acting with the machines, the respective services delivered online, government, and business institutions are reducing their investments in on-premise IT infrastructure. Indeed, to mit- igate the super-exponential increases in the corresponding communication and computational costs, they are moving to, and increasing their spending on, cloud-based services [33]. In this context, we mention that the National Institute of Standards and Technology (NIST) deﬁnes “cloud computing” as a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of conﬁgurable comput- ing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interac- tion [19]. It is clear that one has to now consider how all these services can be distributed over the cloud of computers. This, precisely, involves the problem of LB. LB is like many other related problems [13]; many instances of LB are considered NP-Hard problems [31]. Thus, we will never be able to solve the problem, so as to allocate the resources in a perfectly balanced manner. Unlike the approaches that have been proposed in the literature [11], such as round-robin (RR), weighted RR (WRR), power- of-two choices (Po2), least connection, and weighted least connection, we attempt to resolve the problem in an “almost fair” manner, and we shall refer to such an allocation as an ϵ-fair balance. In other words, we attempt to achieve this by being “as close to fair as possible.” While one can attempt to do this intelligently using any of the available AI-based paradigms, the solution that we propose invokes a novel stochastic learning automaton (LA) scheme. Our LA-based solution distributes the load to a number of nodes, where the performance level at the different nodes is approximately 2162-237X © 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3445 equal and each user experiences approximately the same Quality of the Service (QoS) irrespective of the node that he/she is connected to. Although LA has been applied, in a classical sense, to solve many resource allocation problems including LB, to the best of our knowledge, this work is distinct in two aspects. First, to the best of our knowledge, there is no theoretical analysis of any LB algorithm in the ﬁeld of LA. LB usually induces the dynamicity of the environment as the LA actions will continuously alter the load distribution, and consequently, render the Environment to be nonstationary. Thus, such settings deviate from the classical multiarmed bandit settings where the environment is rather static, and the reward distribution is not inﬂuenced by the actions of the LA. The analysis of such cases is much more involved than stationary cases. The reader should also note that, probably, the most notable example of a theoretical treatment is found in [31] and [47], where the LB problem is mapped into a coordinated strategic game. Second, the success of adopting LA for solving a real-life problem is dependent on an appro- priate choice, or more precisely, appropriate engineering of the reward function. Most of the engineered reward functions in the context of LA-based LB solutions solely rely on “the response time” of a server. In this article, we have used a modiﬁed version of the reward that can infer fairness based on a dynamic comparison threshold. How then should a cloud-based service model differ from a more traditional model? From the reported literature [12], we submit that a cloud-based infrastructure should make it easy for a customer to request a resource and to have that resource provisioned and ready for use, in minutes, rather than days or weeks. The ability to scale the available resources on demand, with little or no downtime, is another factor that makes the cloud preferable over traditional enterprise data centers. The cloud-based computing paradigm has transformed the IT industry profoundly, paving the way to foster new concepts, such as DevOps and microservices. However, to stay com- petitive and to also ensure customer satisfaction, companies offering online services aim to quickly deliver new features to their customers. Developing and deploying software as a monolithic application do not fully take advantage of the beneﬁts of a “cloud computing” paradigm, and many compa- nies are considering migrating toward microservices [7] and a cloud-native application approach. While having many beneﬁts, cloud computing still has some challenges when it comes to offering an optimized system and a fair allocation of resources. Available cloud models do not adequately capture uncertainty, nonhomogeneity, and dynamic performance changes that are inherent to nonuniform and shared infrastructures [41]. One of the viable ways to address challenges related to dynamic performance changes associated with any uncertainties in the load distribution is to employ an LB technique. LB is the process of distributing workloads fairly among multiple hosts. The major advantage of deploying an LB solution is to be able to handle more trafﬁc than a single host can tackle. Another advantage of LB is that such a system offers high availability such that if one service fails, others are available to ensure that the application stays up and running. In order to achieve an optimal distribution of workloads to any number of hosts, several algorithms have been developed throughout the years. LB algorithms are mainly classiﬁed as being static or dynamic. Static LB schemes assume that the information governing the LB-oriented decisions is known in advance [32]. The LB decisions are made deterministically or probabilistically when the system starts or boots and remain constant during runtime. Every time the system restarts, the same values get loaded. Static LB algorithms are mostly suitable for stable environments with homogeneous systems. The nature of a data center or of a cloud implicitly requires dealing with a mixture of stochastic processes [40]. In contrast to static algorithms, dynamic LB algorithms do not require prior knowledge or conﬁguration of the system. To make fairer load distribution decisions, dynamic LB algorithms monitor the current runtime state of the system and adapt to changing loads. The experiments that we report tacitly imply that the servers are not homogenous, as they need not necessarily be homogenous, especially in cloud environment. Indeed, one of the reasons for this is that the types of hardware used for the servers may be different as well as the unpredictability of the resources in a cloud environment. A. Distinctive Properties of Our Solution Without going into any details of the arguments presented in the body of this article, it is prudent to mention the distinctive properties of our proposed solution when it concerns the learning mechanism itself and the associated analysis. In all brevity, they can be listed as follows. 1) By virtue of the “fair balance” paradigm, the learning algorithm initiated by the LA proposed here is distinct from all the families of LA described in the LA-based LB literature, such as in [23]. This includes those from the previously reported families of ﬁxed structure, variable structure, discretized, and estimator-based LA. 2) To achieve a fair load balance, we encounter an irony. Thus, it is, indeed, the fact that the more often an “action” is chosen, the likelihood of the LA choos- ing it, even more, must subsequently decrease. In other words, the rewards that are received for any action must decrease as the action is chosen more frequently. This is contrary to what the properties of absolute expedience and ϵ-optimality entail, especially since, in these cases, the LA aims to converge to an absorbing barrier in the probability space. To the best of our knowledge, LA that possesses the phenomenon mentioned here has not been proposed in the literature. 3) Our solution is characterized by the amazing property that as any speciﬁc pi(t) increases, the corresponding reward probability of the action in question decreases. We refer to this phenomenon as the “stochastic dimin- ishing return property.” Informally, this means that the more an action is chosen, the less it will be rewarded. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. 3446 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 This involves the two-time-scale LA with barriers, as we shall explain presently, and also facilitates fair LB. 4) The analysis methods that we use here are both distinct and unique. The mathematical techniques used for the various families of LA described in the literature are each distinct in their own right. The methodology for the family of ﬁxed structure stochastic automata (FSSA) involves formulating the Markov chain for the LA, computing its equilibrium probabilities, and then com- puting the asymptotic action selection probabilities. The proofs of convergence for variable structure stochastic automata (VSSAs) involve the theory of small-step Markov processes, distance diminishing operators, and the theory of regular functions. The proofs for dis- cretized LA involve the asymptotic analysis of the Markov chain that represents the LA in the discretized space, whence the total probability of convergence to the various actions is evaluated. The proof of estima- tor/pursuit algorithms concerns two intertwined phenom- ena, i.e., the convergence of the reward estimates and the convergence of the action probabilities themselves. The proof methodology considered in this article utilizes the theory of small-step Markov processes and distance diminishing operators, but, unlike the existing LA, they do not converge to absorbing barriers but ﬁxed points in the corresponding probability vector space. 5) Historically, the metric for analyzing LA has gener- ally been ϵ-optimality and absolute expedience. Indeed, the concept of the Lyapunov stability of an LA solution has been rarely used with few exceptions [9]. This is, indeed, the metric that we have invoked. B. Contributions of This Article The contributions of this article can be summarized as follows. 1) We present an LA solution for ensuring the fairness of load distribution in the ﬁeld of LB. 2) We present deep theoretical results that prove the con- vergence of our scheme. 3) We use some of the most recent advances in the ﬁeld of LA that combines the time-separation paradigm and the phenomenon of artiﬁcial barriers, introduced by Yazidi and Hammer [51] and Yazidi et al. [52], respectively. 4) We prove that the equilibrium point which the algorithm converges to is asymptotically Lyapunov stable. The concept of the Lyapunov stability of an LA solution has been rarely used, except for a very few reported results [9]. 5) We provide some experimental results that conﬁrm and justify our theoretical assertions. C. Organization of This Article This article is organized as follows. The background and related work are ﬁrst presented in Section II. In Section III, we give an introduction to the theory of LA that is central to this article. Section IV includes the details of our proposed solution, where we present the scheme itself in Section IV-C and report the theoretical results proving its convergence to an optimal equilibrium in Section IV-D. Thereafter, in Section V, we include the results of rigorous simulations that conﬁrm the theoretical results. Section VI concludes this article. II. BACKGROUND AND RELATED WORK Historically, LB and task scheduling have been two closely related research areas that have been widely investigated. However, the literature that reports the use of stochastic LA to achieve these has been limited. A stochastic LA model for the decentralized control of job scheduling in distributed processing systems was presented by [22]. The algorithm proposed by these authors operates with absolutely no prior knowledge about the job but rather adapts to the changing loads of the hosts. The aim of the proposed algorithm was to provide load-balanced jobs to a number of hosts and to improve the response time while achieving this. To minimize the response time, a heuristic LB scheme based on the concept of a stochastic LA was implemented by Kunz [15]. Depending on the status of the current load distribution, a new task would be scheduled to be executed either locally or on a remote host. This article employed a learning scheme with a reward constant A of 0.25 and a penalty constant B of 0.3. Although many ﬁne details were not reported in this article, the author claimed to also have examined other inﬂuences on different numbers of automa- ton states and the behavior of the scheduler under different network sizes. Misra et al. [23] presented a framework based on LA that is capable of addressing some of the challenges and demands of various cloud applications. The proposed framework analysis invoked various performance metrics, such as response time, parallel execution speed, and job priority. These metrics were then used to select the appropriate resources, using LA. A Cost Aware S-model (CA-S) Reward Epsilon-Penalty method was proposed in [46]. The authors employed an LA-based solution that sought to reduce the average cost in serving web requests with replicated web servers, deployed in different geographical regions. To minimize the cost, the LA made routing decisions for each incoming request by assess- ing response times and energy prices at the different server locations through action selection probabilities. This article reported very promising experimental results by using the proposed CA-S method. These results demonstrated that the total average cost of serving web responses could be reduced up to 33% compared with the minimum cost ﬂow dynamic server selection algorithm and up to 49.2% compared with the traditional RR method. The problem of optimal priority assignment among two streams of jobs with unknown characteristics, each with ran- dom service time and a random arrival time, was addressed in the doctoral thesis of Meybodi [20]. A threshold was computed, which was the average service time taken over both streams, and the response time of a served dispatched request from the chosen stream by the LA was compared with that threshold for the inferred LA response. This idea Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3447 of using response time-based threshold in a queuing system as a mechanism for inferring the response of LA to constitute the rewards/penalties appeared also in [3]. Similarly, in this work, we resort to a dynamic threshold computed using a type of moving average, in contrast to a stationary type of estimator found in the seminal work of Meybodi [20] and Meybodi and Lakshmivarhan [21]. Apart from the queuing system model, this article is different from the work in [20]. Indeed, the LA proposed by Meybodi [20] was absorbing because the optimal solution was to be exclusively chosen from one of the priority streams. Furthermore, the dynamics of the reward probabilities addressed here are much more complicated in our problem setting. An alternative solution to the priority assignment problem based on FSSA was proposed by Srikanta Kumar [14]. The problem was revisited recently using the theory of Petri Nets and LA in [43] and [44]. However, as our model and solution are distinct, in the interest of brevity, we shall not expand on these articles any further. Finally, we emphasize that although LA has been applied in a few instances in the literature for solving LB problems, we are not aware of any theoretical analyses of the problems. The theoretical analysis for this type of LA application is intrinsically hard due to the dynamic nature of the environment as the reward dynamics are coupled with the changes in the actions. LA algorithms in this vein are rather presented as heuristics with no theoretical guarantees. The only possible attempt to cast an LA-based LB algorithm into a theoretical framework was reported in a series of works by the same research group [31], [47], where the LB problem was mapped onto a coordinated game. III. STOCHASTIC LEARNING AUTOMATA We shall now proceed to present a brief overview of LA [1], which is the toolkit that we will use to solve the problem. In psychology, learning is characterized as the act of modi- fying one’s behavior as a result of acquiring knowledge from past experience. In the ﬁeld of automata theory, an automaton can be described as a self-operating machine or control mech- anism consisting of a set of states, a set of outputs or actions, an input, a function that maps the current state and input to the next state, and a function that maps a current state (and input) to the current output. The term LA was ﬁrst presented in the survey article by Narendra and Thathachar (see [27]). LA is well suited for sys- tems with noisy and incomplete information about the environ- ment in which they function [1], [16], [26], [27], [29], [34]. The environment is generally stochastic, and the LA lacks prior knowledge as to which action is the optimal one. Stochastic LA, which is the probabilistic ﬁnite state machine, attempts to solve this problem by choosing an initial action randomly and then updating the action probabilities based on the response received. The action chosen is dependent on the action probability distribution vector, which, in turn, is updated based on the reward/penalty input that the LA receives from the random environment. This process is repeated until the optimal action is, hopefully, achieved. The research on LA is comprehensive, and over the past decades, several classes have been proposed. LA is mainly categorized as being FSSA or VSSA. In FSSA, the mapping between transition and output functions is time-invariant. Initial research into LA was mainly focused on FSSA. Tsetlin et al. [42] demonstrated several models of this class of automata. Gradually, research into LA has been advanced toward VSSA. LA schemes in this category possess transition and output functions that evolve as the learning process proceeds [30]. In VSSA, the state transitions or the action probabilities are updated at every time step. This class of automata was introduced by Varshavskii and Vorontsova [45] in the early 1960s. LA can further be classiﬁed as either ergodic or endowed with absorbing barriers based on their Markovian properties. In an ergodic LA system, the ﬁnal steady state is independent of the initial state. As opposed to this, for LA with absorbing barriers, the steady state depends on the initial state, and once the LA has converged, it will be locked into a so-called absorbing barrier. Furthermore, while ergodic VSSA is suitable for nonstationary environments, absorbing barrier VSSA is preferred in stationary environments. As opposed to these, a unique property of the work in [53] is that the action with the highest probability may not be the same one being chosen most frequently. Stochastic LA had been utilized in many applications over the years. Recent applications of LA include resource usage prediction algorithm for cloud computing environ- ment [35], channel selection in cognitive radio/dynamic spec- trum access for WiMAX networks [24], distributed network formation [6], solutions to the single elevator problem [10], efﬁcient decision making mechanism for stochastic nonlinear resource allocation [52], dynamic cost-aware routing of web requests [46], learning periodic spatiotemporal patterns [50], content placement in cooperative caching [49], resource selec- tion in computational grids [8], determining proper subset size in high-dimensional spaces [38], and image segmentation [37], to mention a few. IV. LA LOAD-BALANCING MODEL In this section, we present our LA model for LB, as well as the theoretical proofs for the solution’s convergence. A. Model We consider a scenario where we have a set of r servers. Each server is modeled as an M/M/1 queue, which means that arrivals are modeled by a Poisson process with some intensity λi, and the job service times have an exponential distribution with a service rate μi. In our model, we assume that an LA is responsible for dis- patching the request. The LA sends the request to server i with probability pi(t). We will later deﬁne the update equations for the LA. However, for the sake of simplicity, we shall give, ﬁrst, the overall idea for the different updates involved here at the two time scales, and subsequently, in Section IV-B, we shall delve into the LA’s detailed update equations. By virtue of the M/M/1 queue, the mean-response time at server i is MRTi(t) = 1 μi −λi(t) Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. 3448 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 where λi(t) is the average arrival rate at server i. If {pi} are constant or vary slowly over time, then λi(t) can be approximated using λi(t) = pi(t)λ, which is a consequence of the M/M/1 queue model [17]. Let si(t) be the instantaneous response time of server i at time t. In order to estimate the average response time of each server (i.e., ˆsi), we merely use the exponential mov- ing average approach with the learning parameter α. The parameter α is the learning parameter of the scheme and is similar to the parameter used in any learning algorithm. It is a hyperparameter determined by a “rule of thumb” or trial and error for the particular setting. A larger value of α implies a larger step away from the current value, and vice versa. This, in turn, illustrates the speed-accuracy dilemma of the estimate. Let ˆsi(t) be the estimate of the average response time of server i. Once the action i is polled, i.e., the request is dispatched to server i, the estimate ˆsi(t + 1) of the average is immediately updated using an adaptive estimator, namely, the exponential moving average given by ˆsi(t + 1) = ˆsi(t) + α(si(t) −ˆsi(t)). The average response time for the other severs (actions) are left unchanged. In other words ˆs j(t + 1) = ˆs j(t) for j ̸= i, j ∈[1, n]. We now consider how the corresponding rewards and penalties are constructed. If action i is chosen, the reward or penalty is constructed as following using some type of dynamic threshold: 1) reward if ˆsi ≤(1/r) r k=1 ˆsk; 2) penalty if ˆsi > (1/r) r k=1 ˆsk. With these deﬁnitions as a backdrop, we are able to formally present the steps of our algorithm. B. Initialization Criteria Without any knowledge of ˆsi, which is estimated using an exponential moving average as per , we have opted to initialize ˆsi to a random low value of response time close to zero. As in any exponential moving average scheme, the value that we use for this initialization is not critical. In our experiments, we assigned this value as ˆsi for all the r servers. This is in line with the spirit of what is done in LA, where the initialization is achieved by values that are equal. In fact, without the accurate knowledge of initial LA’s action probability, the initial probability for each action i is usually set to (pi = (1/r)). In our case, we have also veriﬁed experimentally that the initial value of ˆsi does not have any effect on the long-term convergence behavior of the scheme that is an observation consistent with the behavior of the exponential moving average schemes that are ergodic by nature. However, in real-life settings, the experimenter might assign an initial value of ˆsi that is more informed based on an a priori knowledge of server i. In this case, one might also alter the initial LA probabilities, so as to move away from the uniform distribution, i.e., pi = (1/r). C. Details of Our Solution: Two-Time-Scale LA With Barriers The ﬁrst step in our solution process is to see how we can transform the Markov process given by the probability space from being absorbing to being ergodic. The reader who is aware of the ﬁeld of Markov chains will immediately recognize that this is, actually, the converse of what the literature [5], [39]1 reports when an ergodic chain is rendered artiﬁcially absorbing, as in the families of artiﬁcially absorbing discretized LA, such as ADLRP and ADLIP [30]. Rather than using the actual limits of the probability space to be zero and unity, we work with the constraint that no probability value can take on value below a prespeciﬁed lower threshold of pmin or a value above a prespeciﬁed upper threshold of pmax [51]. The action-choosing probability values, which traditionally move proportionally toward zero and unity for the LRI scheme, for example, are now made to move toward the respective values of pmin and pmax, respectively. Interestingly enough, this minor modiﬁcation renders the scheme to be ergodic, making the analysis also to be correspondingly distinct from that of LRI and similar schemes. To achieve this, we enforce a minimal value pmin, where 0 < pmin < 1 for each selection probability xi, where 1 ≤i ≤r and r is the number of actions. As a result, the maximum value any selection probability pi, where 1 ≤i ≤r, can achieve is pmax = 1 −(r −1)pmin. This happens when the other r −1 actions take their minimum value pmin, while the action with the highest probability takes the value pmax. Consequently, pi, for 1 ≤i ≤r, will take values in the interval [pmin, pmax]. To proceed with the formulation, let α(t) be the index of the chosen action at time instant t. Then, the value of pi(t) is updated as per the following simple rule (the rules for other values of p j(t), j ̸= i, are analogous): pi(t + 1) ←pi(t) + θ(pmax −pi(t)) when α(t) = i and vi = 1 pi(t + 1) ←pi(t) + θ(pmin −pi(t)) when α(t) = j, j ̸= i and vi = 1 where θ is a user-deﬁned parameter 0 < θ < 1, typically close to zero. Furthermore, vi is a reward function indicator deﬁned as follows. 1) vi = 1, reward, if the instantaneous response of the chosen server is under the running moving average of the mean response time si ≤(1/r) r k=1 ˆsk. 2) vi = 0, penalty, if the instantaneous response of the chosen server exceeds the running moving average of the mean response time ˆsi > (1/r) r k=1 ˆsk. In our algorithm, we avoid using a classical projection method to map the solution to our feasible space, implying that all components of the probability vector are within the interval [pmin, pmax]. Projection methods have been earlier used in the ﬁeld of LA for enforcing artiﬁcial barriers. A prominent example of this is given by Simha and Kurose [39] who tackled a number of actions r > 2, which is a more challenging 1The projection method is a classical method in constrained optimization [5] that ensures that the solution is mapped back in the feasible search space whenever it falls outside. The relative reward LA devised [39] adopts artiﬁcial barriers for more than two actions using the projection method. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3449 Algorithm 1 Two-Time-Scale-Based LA Solution Loop 1. Poll an action at time instant t according to the probability vector [p1, p2, . . . , pr]. 2. Updating the response time estimates. • Update the response time of the chosen action ˆsi(t + 1) = ˆsi(t) + α(si(t) −ˆsi(t)) • The response estimates for the other actions are kept unchanged, and so ˆs j(t + 1) = ˆs j(t) for j ̸= i, j ∈[1,r] 3. Environment response: Reward/Penalty. • vi = 1 (Reward) if ˆsi ≤1 r r k=1 ˆsk; • Otherwise, vi = 0 (Penalty). 4. Let α(t) be the index of the chosen action at time instant t. The value of pi(t) is updated as per the following simple rule below, (where the update rules for other values of p j(t), j ̸= i, are similar) pi(t + 1) ←pi(t) + θ(pmax −pi(t)) when α(t) = i and vi = 1 pi(t + 1) ←pi(t) + θ(pmin −pi(t)) when α(t) = j, j ̸= i and vi = 1. scenario than he two-action scenario. However, our approach does not involve projection methods as the update equations will always ensure that the probabilities will be in our feasible space. Furthermore, in contrast to projection methods, our LA update methodology naturally ensures that the probability vector will always sum to unity in a manner that can be seen to be a generalization of the LRI LA. The classical LRI LA can be seen as an instance of our algorithm with pmax = 1. Let the average of all the instantaneous response times of all the nodes at time t be given by ˆs(t) deﬁned by ˆs(t) = 1 r r  k=1 ˆsk(t). We also introduce the following notation: Di(t) = Prob(si(t) ≤ˆs(t)) where ˆs(t) is given by . A consequence of these assignments is a scheme formalized by the pseudocode given in Algorithm 1. The algorithm proceeds as follows in a loop. Each time a request is received, the LA probability vector is used to choose a server by polling an action, which corresponds here to a server among the r severs. The server choice corresponds to Step 1 in the pseudocode given in Algorithm 1. Once the server is chosen, the instantaneous response time of the chosen server for that requested is observed. Then, in step 2, based on this observation, we update the average response time of the chosen server of the pseudocode using the exponential moving average. The estimates for the other “unchosen” servers will be kept unchanged. In Step 3, the chosen action receives a reward or a penalty by comparing the estimated response time of the chosen server to a dynamic threshold and the mean of the individual average response times of the r servers. In Step 4, we operate with the same rules of the classical LRI LA but with the exception of accommodating artiﬁcial barriers. If the chosen action resulted in a reward, its probability is increased, while the probabilities of the rest of the r −1 actions are decreased. However, if the chosen action results into a penalty, the probability vector is kept unchanged as per the LRI LA philosophy. With these deﬁnitions in place, we are in a position to analyze the scheme and give theoretical results. This is done in Section IV-D. We show that as pi(t) increases this quantity, Prob(si(t) > ˆs(t)) decreases. This is an extremely interest- ing observation because the latter quantity is, quite simply, the reward probability when choosing action i. This is referred to as the “stochastic diminishing return” property, which, informally, means that the more an action is chosen, the less its reward will be. Thereafter, we will prove the scheme’s convergence. D. Theoretical Analysis In this section, we shall investigate and analyze the asymp- totic behavior of our LA-based two-time-scale separation solution with artiﬁcial barriers. We shall analyze our scheme in terms of both its convergence and stability. Theorem 1: For a sufﬁciently small α and θ ≪α, ˆsi(t) can be approximated by M RTi(pi(t)) = (1/μi −λi pi(t)) for all 1 ≤i ≤r. Proof: We will prove that for 1 ≤i ≤r, ˆsi(t) converges to ¯si(pi(t)), where ¯si denotes MRTi. The proof is based on the theory of stochastic approx- imation [2]. Since θ is much smaller than α, pi’s evolve at a slower time scale compared with ˆsi’s, which, in turn, guarantees the two-time-scale separation. Using the notation that α(t) = i means that action i is chosen at time t, we can write ˆsi(t + M) = ˆsi(t) + α M−1  k=0 I{α(t+k+1)=i}(si(t + k) −ˆsi(t + k)). As per the theory of small step processes, we can assume that whenever α is small enough, the vector [ˆs1(t), ˆs2(t), . . . , ˆsr(t)] remains almost unchanged in the discrete interval {t, t +1, . . ., t +M}. Thus, we can write the following approximate equations for 1 ≤i ≤r: ˆsi(t + M) ≈ˆsi(t) + Mα(Ri(t, M) −Qi(t, M)ˆsi(t)). For i ∈[1,r], when the values of the estimates {ˆs1(.), ˆs2(.), . . . , ˆsr(.)} are, respectively, considered ﬁxed at {ˆs1(t), ˆs2(t), . . . , ˆsr(t)}, and M is large, we now approximate the quantities Ri(t, M) = M−1 k=0 I{α(t+k+1)=i}si(t + k) M as well as Qi(t, M) = M−1 k=0 I{α(t+k+1)=i} M . Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. 3450 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 The probability vector p1(.), p2(.), . . . , pr(.), too, can be regarded to be essentially constant in the interval {t, t + 1, . . . , t + M} because we have afﬁrmed that pi evolves at a slower time scale compared with ˆsi. Note that the fact that θ is much smaller than α permits the separation at this time scale. Now, assuming that M is large enough such that the law of large numbers is in effect, the average Qi(t, M) = M−1 k=0 I{α(t+k+1)=i} M that is the fraction of time the action i was chosen in the interval [t, t + M] and converges to pi(t). By reckoning the actions’ probabilities to be ﬁxed, the response time processes si(.)can converge to a stationary distribution, with the mean being denoted by ¯si(pi(t)). Furthermore, the quantities Ri(t, M) = M−1 k=0 I{α(t+k+1)=i}si(t + k) M can be approximated by pi(t)¯si(pi(t)). Employing the approximations as described earlier, we notice from that the evolution of the vector [ˆs1(.), ˆs2(.), . . . , ˆsr(.)] reduces to the following ODE system when α is sufﬁciently small: ˆsi(t) dt = pi(t).(¯si(pi(t)) −ˆsi(t)). One observes that reduces to having the running response time estimates, given by [ˆs1(.), ˆs2(.), . . . , ˆsr(.)], converging to a steady-state vector [¯s1(p1(t)), ¯s2(p2(t)), ¯sr(pr(t))] whenever α tends to 0. We now invoke the properties of the M/M/1 queue model, alluded to above. As per the properties of the M/M/1 queue model, we know that ¯si(pi(t)) = MRTi(pi(t)) = 1 μi −λi pi(t). This, indeed, concludes the proof. □ In Theorem 2, we shall prove the diminishing property of our designed feedback mechanism. In fact, our reward is deﬁned by the fact that the instantaneous response time observed when we choose a server is smaller than ˆs(t), which is the arithmetic mean of ˆsi(t) for 1 ≤i ≤n, where ˆsi(t) is the running estimate (i.e., the exponential moving average) of the response time at server i. Using the notation of , we will show that the reward probability decreases as we increase pi. Theorem 2: Di(t) is monotonically strictly decreasing as a function of pi. Proof: We consider the reward probability Di(t) = Prob(si(t) ≤ˆs(t)), where ˆs(t) is given by . As a consequence of the previous result from Theorem 1, if the ˆsi’s evolve at a slower time scale than the pi’s, we can approximate ˆs(t) by the sum of the mean response times of each server, i.e., sum of MRTi(t), 1 ≤i ≤r. In other words, ˆs(t) ≈(r k=i ¯si(pi(t))/r) = (r k=i MRTi(pi(t))/r). The probability that the response time of server i, si(t), exceeds ˆs(t) is [36] Di(t) = Prob(si(t) ≤ˆs(t)) = 1 −exp(−ˆs(t)(μi −λi(t))). We need to show that as pi(t) increases, this quantity decreases. To achieve this, consider (d Di(t)/dpi) given by (d Di(t)/dpi) = (δDi(t)/δpi) + r j=1 j̸=i (δDi(t)/δp j)(δp j/δp j). In order to apply the chain rule for the derivation, we resort to a subtle mathematical trick similar to the one used in [18] and [48]. We deﬁne arbitrary constants b j ≥0 for j ̸= i, whence, following a derivation similar to the one in [18] and [48], we have p1 = b1 pi, p2 = b2 pi, . . . pr = br pi, with b j ≥0 for j ̸= i. Consequently p1 = b1(1 −pi)  m bm · · · = · · · p j = b j(1 −pi)  m bm · · · = · · · pr = br(1 −pi)  m bm . Now, since  m pm = 1, we can obtain (dp j/dpi) = (−b j/ m̸= j bm) < 0 for all j ̸= i. Considering the expression for Di(t), we see that Di(t) = 1 −exp(−ˆs(t)(μi −λi(t)) = 1 −exp  −μi −λi(t) r  k 1 μk −λk(t)  = 1 −exp ⎛ ⎜⎝−1 r − r  k=1 k̸=i 1 r(μk −λpk(t)) ⎞ ⎟⎠. This expression is independent of pi, which implies that (δDi(t)/δpi) = 0. Consequently, (δDi(t)/δpi) reduces to (d Di(t)/dpi) = r j=1 j̸=i (δDi/δp j)(δp j/δpi). Algebraic simpliﬁcation leads to δDi δp j = λ r(μi −λpi(t))2 exp(−ˆs(t)(μi −λi(t))). Furthermore, since (dp j/dpi) < 0, (δDi(t)/δpi) = r j=1 j̸=i (δDi/δp j)(dp j/dpi) < 0 since all the terms in the above-mentioned sum are strictly negative. Hence, the theorem! □ Theorem 3: For a sufﬁciently small pmin approaching 0, the system of update equations characterizing the LA has a unique ﬁxed point equilibrium. Proof: E[pi(t + 1) −pi(t)|p(t)] = pi Di(pi)[θ(1 −pi)] + r  j=1 j̸=i p j D j(p j).[θ(pmin −pi)]. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3451 Then E[pi(t + 1) −pi(t)|p(t) = p] = pi Di(pi).[θ(1 −pmax + 1 −pi)] + r  j=1 j̸=i p j D j(p j)[θ(pmin −pi)] = pi Di(pi). ⎡ ⎢⎢⎣θ(1 −pmax + r  j=1 j̸=i p j) ⎤ ⎥⎥⎦ + r  j=1 j̸=i p j D j(p j)[θ(pmin −pi)]. By taking into account the fact that 1−pmax = (r −1)pmin, can be simpliﬁed (after some algebraic manipulations) and written as E[pi(t + 1) −pi(t)|p(t) = p] = θ r  j=1 j̸=i pi p j(Di(pi) −D j(p j)) + θpmin ⎛ ⎜⎜⎝ r  j=1 j̸=i p j D j(p j) ⎞ ⎟⎟⎠ −θ(r −1)pmin pi Di(pi) = θ r  j=1 j̸=i pi p j(Di(pi) −D j(p j)) + θpmin r  j=1 j̸=i (p j D j(p j) −pi Di(pi)) ≈θwi(p) where wi(p) is deﬁned by wi(p) = r j=1 j̸=i pi p j(Di(pi) − D j(p j)). For small values of pmin, i.e., as pmin →0, we can approximate E[pi(t + 1) −pi(t)|p(t) = p] by E[pi(t + 1) −pi(t)|p(t) = p] = θwi(p). We can, thus, write dpi(t + 1) dt = θwi(p). Using the above-mentioned result, we shall now proceed with the details of the proof. 1) Existence and Uniqueness: We will show that w(p) = (w1(p), w2(p), . . ., wr(p)) has a unique zero in the neighbor- hood of p∗= (p∗ 1, . . . , p∗ r ), which means that we have a ﬁxed point. The above-mentioned assertions imply the system of r equalities ⎧ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩ r  j=1 j̸=1 p1 p j(D1(p1) −D j(p j)) = 0 r  j=1 j̸=2 p2 p j(D2(p2) −D j(p j)) = 0 ... r  j=1 j̸=r pn p j(Dr(pr) −D j(p j)) = 0. ⇔ ⎧ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩ p1 r  j=1 j̸=2 p j(D1(p1) −D j(p j)) = 0 p2 r  j=1 j̸=2 p j(D2(p2) −D j(p j)) = 0 ... pn r  j=1 j̸=r p j(Dr(pr) −D j(p j)) = 0. The reader should observe that a crucial concept in our approach is that we are using the barrier pmin, which ensures that p1 ̸= 0, p2 ̸= 0, . . . , pr ̸= 0. We can, thus, conﬁdently divide the ﬁrst equation by p1, the second equation by p2, and so on, yielding ⇔ ⎧ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩ r  j=1 j̸=1 p j(D1(p1) −D j(p j)) = 0 ... r  j=1 j̸=2 p j(D2(p2) −D j(p j)) = 0 ... r  j=1 j̸=r p j(Dr(pr) −D j(p j)) = 0. After invoking some algebraic manipulations, we obtain that ⇔ ⎧ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩ D1(p1) = r  j=1 p j D j(p j) ... D2(p2) = r  j=1 p j D j(p j) ... Dr(pr) = r  j=1 p j D j(p j) which guarantees that D1(p1) = D2(p2) = . . . = Dr(pr). Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. 3452 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 Now, we will show that the solution is unique. 2) Uniqueness: The uniqueness of p∗is proven by contra- diction. Suppose there exists q∗= (q∗ 1, q∗ 2, . . . , q∗ n) that is a zero of w(q) such that q∗̸= p∗. Without loss of generality since p∗and q∗are two probabil- ity vectors such that p∗̸= q∗, we can conﬁdently afﬁrm that they have at least two components i and j such that p∗ i > q∗ i and p∗ j < q∗ j . Observe that the result is general and that it applies for any two distinct probability vectors. Intuitively, this means that if we increase any one component of a probability vector, we should decrease another component, so as to ensure that the sum of the components is unity. Suppose now that p∗ i > q∗ i . Then, by invoking the monotonicity of the function Di(.), we obtain that Di(p∗ i ) < Di(q∗ i ). On the other hand, the condition p∗ j < q∗ j implies that D j(p∗ j) > D j(q∗ j ), where this is obtained by virtue of the monotonicity of D j(.). However, since p∗and q∗are equilibrium points, we know that Di(p∗ i ) = D j(p∗ j) and that Di(q∗ i ) = D j(q∗ j ). This forces a contradiction since it is impossible to simultaneously maintain that Di(p∗ i ) < Di(q∗ i ) that is equivalent to D j(p∗ j) < D j(q∗ j ) and D j(p∗ j) > D j(q∗ j ). Therefore, p∗is unique. □ Theorem 4: The equilibrium point to which the algorithm converges is asymptotically Lyapunov stable. Proof: Consider the following Lyapunov function: V (p(t)) = r  k=i  pt 0 Dk(z)dz. Consider now its derivative dV (p(t)) dt = r  i=1 dV(p(t)) dpi dpi dt . It is easy to note that by virtue of the integral derivation, (dV(p(t))/dpi) = Di(t). Furthermore, according to , (dpi/dt) = θwi(p). Thus dV (p(t)) dt = θ r  k=1 Dk(t)wk(p) where wi(p) is deﬁned by wi(p) = r j=1 j̸=i pi p j(Di(pi) − D j(p j)). Therefore dV(p(t)) dt = θ r  i=1 Di r  j=1 pi p j(Di −D j) = θ r  i=1 r  j=1 pi p j(D2 i −Di D j) = −θ 2 r  i=1 r  j=1 pi p j(Di −D j)2. Therefore, (dV(p(t))/dt) ≤0. Observe though that the Lyapunov function must be zero at its equilibrium point, and thus, (dV(p(t))/dt) = 0. This, in turn, means that for every i, j, we have p∗ i p∗ j(D∗ i − D∗ j)2 = 0. However, since p∗ i > pmin and p∗ j > pmin, the equality D∗ i (p∗ i ) −D∗ j(p∗ j) = 0 must necessarily be true, and consequently, for all i, j D∗ i (p∗ i ) = D∗ j(p∗ j) = 0. The result follows, since, by the Lyapunov theorem, we have shown that p∗is an asymptotically Lyapunov stable equilib- rium point of the scheme. □ E. Summary Outlining of the Theoretical Results In Theorem 1, we show that by imposing a two-time-scale separation, where we slowly update the LA probabilities, while we update the response times in a faster scale, we are able to approximate the estimated response times at each server. For any probability vector that is slowly varying, the response time estimates converge to a steady state depending on the probability vector given by . Once we have characterized the response times, we can analyze the behavior of the reward probabilities of our LA. This is treated in Theorem 2, where we show an intuitive property, which states that the reward probability of action is monotonically strictly decreasing as a function of its respective action probability. Theorem 3 characterizes the ﬁxed point of the LA update equations. The artiﬁcial barriers as well as the monotonicity of the reward functions yield a unique ﬁxed point. Interestingly, the ﬁxed point achieves fairness as the reward probabilities of the action are “equalized,” and thus, the LA will be indifferent between the choices of the servers at this point. Theorem 4 shows that the algorithm converges to asymptotically Lyapunov stable state by deﬁning an appropriate Lyapunov function. V. EXPERIMENTAL VERIFICATION In this section, we will brieﬂy conﬁrm that the theoretical results that were derived in Section IV hold true. To achieve this, we conducted two types of experiments. The intent of the ﬁrst set of experiments was to prove the claims for a small-scale system, namely, for one with only three servers. The second, and more extensive testing, involved a larger pool of servers, i.e., 15. It is clear that such a setting is well in-line with real-life LB problems. Furthermore, we tested both of the scenarios in two types of environments: static and dynamic. For the dynamic case, we report experiments where we either changed the serving rates of the services or the arrival rate of the requests. A. Experiments With Three Servers 1) Static Environment With Three Servers: In this ﬁrst set of experiments, we simulated three servers characterized by the parameters, μ1 = 50, μ2 = 33.33, and μ3 = 25, respectively. We assumed that the total arrival rate was λ1 + λ2 + λ3 = 50. Furthermore, we used pmin = 0.01. For the time scale separation, we used two values θ = 0.001 for updating the LA action probabilities and α = 0.01 for the estimation of the response times. The intention of our experiments was to observe the action probabilities and the corresponding response times when the protocol was tested for 9000 iterations for an ensemble of 1000 experiments. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3453 Fig. 1. Evolution of the action selection probabilities in a static environment. Fig. 2. Evolution of the response times of the different servers in a static environment. Fig. 3. Evolution of the action selection probabilities in an environment with dynamic serving rates. The evolution of the probability and response time are plotted in Figs. 1 and 2, respectively. Interestingly, from Fig. 2, we observed that the response time was equalized on the different servers. The results are quite amazing because even though the corresponding action probabilities converged to different values, the composite effect of the convergence was to make the overall response times to be almost equal. 2) Dynamic Serving Rates With Three Servers: To investi- gate the performance of the scheme for time-varying systems, we also ran another experiment where we dynamically shufﬂed the serving rates of the three servers every 5000 iterations. In this case, the experiments were run for 15000 iterations, and the number of experiments (over which the ensemble average was obtained) was 1000. We again observed that the system stabilized after some time and that it was again capable of equalizing the response times. Figs. 3 and 4, respectively, depict the evolution of the action probabilities of each server, as well as the evolution of the estimated response times. It is clear that the results demonstrated that even though the corresponding action probabilities converged to completely Fig. 4. Evolution of the response times of the different servers in an environment with dynamic serving rates. Fig. 5. Evolution of the action selection probabilities in an environment with varying arrival rates and with three servers. Fig. 6. Evolution of the response times of the different servers in an environment with varying arrival rate with three servers. different values, the overall effect of the scheme’s convergence was to make the overall response times to be almost equal. The power of the scheme to balance the loads in an ϵ-optimal manner is obvious! 3) Dynamic Arrival Rate With Three Servers: In real-life scenarios, it is more common that the arrival rate of the trafﬁc changes over time, while the serving rate is usually stable over time. This is because the latter is an intrinsic characteristic of the server and does not, usually, change due to extrinsic factors related to the environment.2 In our simulations, we adjusted the arrival rate every 6000 iterations. We started with a total arrival rate of 50, and after the ﬁrst switch, this number was increased to 60. It was then lowered to 54 after the second switch. Figs. 5 and 6 report, respectively, the evolution of the probabilities and the evolution of the response time esti- mates for this dynamic environment characterized by varying 2The serving rate of a server might degrade slightly over time due to hardware issues. It is also possible to upgrade the servers for improved performance. However, such changes are beyond the scope of this work and are still rare within the lifetime of a server. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. 3454 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 Fig. 7. Evolution of the action selection probabilities in a static environment with 15 servers. Fig. 8. Evolution of the response times of the different servers in a static environment with 15 servers. arrival rates. One should observe that our scheme is able to equalize the response times of the servers after around 3000 iterations. B. Larger Scale Experiments 1) Static Environment With 15 Servers: In the second set of experiments, we increased the number of servers to 15 as per the following parameters: ﬁve servers with μ = 50, ﬁve servers with μ = 60, and ﬁve servers with μ = 80. We assumed that the total arrival rate was λ = 350. Figs. 7 and 8 illustrate, respectively, the evolution of the prob- abilities and the evolution of the response time estimates for a static environment. When it comes to the parameters of the algorithm, we use the same tuning parameters as in the previous experiment involving three servers, i.e., θ = 0.001 and α = 0.01. Interestingly, even though the environment was intrinsically more challenging than the case of having three servers, we observed that our scheme was able to stabilize the response times of the 15 servers after around 5000 iterations. 2) Dynamic Serving Rates With 15 Servers: In order to test the adaptivity of our scheme in large-scale settings, we executed a “switch” in the environment by modifying the serving rates every 30000 iterations. The switch was a right-circular shift of a single position of the serving rate vector. For example, before the ﬁrst switch, the serving rate vector of the 15 servers was (μ1 =50, μ2 =60, μ3 =80, μ4 =50, μ5 =60, μ6 =80, . . ., μ13 =50, μ14 =60, and μ15 =80), respectively, and after the ﬁrst switch, the serving rates became (60, 80,50, . . ., 60, 80, and 50). Figs. 9 and 10, respectively, depict the evolution of the action probabilities of each server, as well as the evolution of the estimated response times. Fig. 9. Evolution of the action selection probabilities in a dynamic environment with dynamic serving rates and with 15 servers. Fig. 10. Evolution of the response times of the different servers in a dynamic varying environment with dynamic serving rates and with 15 servers. However, with such a large number of servers, it is clear that we could run into stability issues of the queues whenever the arrival rate at a given server became higher than its serving rate as a consequence of the shift in the serving rates. Formally, this instability can be seen to be a consequence of violating the condition μi −λi > 0, where λi = λpi. For instance, this happens after the ﬁrst switch, as we can easily observe. Consider, in this case, the third server. Before the switch, p3 stabilized to 0.152, while the processing rate was as high as 80. Abruptly, however, after the switch, in the serving rates, the same server, i.e., 3, obtained a new processing rate 50, which was much lower than before, while p3 was 0.152. This, clearly, led to a queue instability since, in this case, μ3 −λ3 = 50 −350 × 0.152 = −3.2 < 0 because the server was receiving more trafﬁc than it could serve, which it, clearly, could not handle. 3) Dynamic Arrival Rate With 15 Servers: In order to test the adaptivity of our scheme when facing changes in the arrival rate, we executed an environment switch every 30000 iterations. We started with an arrival rate of 350, and after the ﬁrst switch, we dropped it to 280, and then, we invoked a further drop to 252. Figs. 11 and 12, respectively, depict the evolution of the action probabilities of each server, as well as the evolution of the estimated response times. C. Comparison Results in Terms of Fairness In this article, we claimed that our algorithm is fair in the sense that the response times from the different servers are equalized, and thus, a client will experience, on average, the same QoS, measured in terms of the average response time, Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3455 Fig. 11. Evolution of the action selection probabilities in a dynamic environment with varying arrival rate and with 15 servers. Fig. 12. Evolution of the response times of the different servers in a dynamic environment with varying arrival rate and with 15 servers. Fig. 13. Fairness comparison of the different LB algorithms in a static environment with varying arrival rate and with three servers. independent of the chosen server. It is not our place to compare the presented algorithm to other LB algorithms in the literature in terms of fairness. To this end, we resort to three commonly deployed LB algorithms: RR, WRR, and Po2 algorithm [25]. When it comes to WRR, each server’s weight is proportional to the service rate of the server. The fairness will be measured utilizing Jain’s fairness index [4], using the formula JFI = r i=1 ˆsi(t) 2 r r i=1 ˆsi(t)2 . If the estimated response times of the different servers are equalized, the JFI will be equal to unity, its maximum value. The JFI by deﬁnition ranges between zero and unity. In Fig. 13, we report the ensemble average over 1000 experi- ments of the fairness index (JFI) for our LA algorithm against the aforementioned comparison algorithms for the case of three servers. The environment is static, and the settings of the environment are the same settings as in Section V-A1. From Fig. 13, we see that our LA algorithm achieves the highest JFI followed by the WRR. The reader should note Fig. 14. Fairness comparison of the different LB algorithms in a static environment with varying arrival rate and with 15 servers. that the WRR operates with extra knowledge than the LA algorithm, in which it assumes complete knowledge of the servers’ serving rates to deﬁne its weights. Thus, we state that the LA algorithm is a superior solution in the sense that it achieves almost optimal JFI values, around unity, with little information, i.e., with no knowledge of the serving rates of the servers. Similarly, we conducted an experiment with 15 servers using the same settings as in Section V-B1. Fig. 14 shows the behavior of our LA algorithms versus the state-of-the-art comparison algorithms. We observe similar remarks to those of the case of three servers reported in Fig. 13. In fact, the LA algorithms are the most superior algorithm in terms of JFI followed by WRR. However, the Po2 achieves the lowest performance, which was not the case when we used three servers (see Fig. 13). The primary reason for this is that, as the number of servers increases, the Po2 will by deﬁnition select among two random servers among 15 servers, which gives it a limited view of the environment composed of a high number of servers, in this case, 15, and, consequently, leads to poor performance. VI. CONCLUSION With the proliferation of network-based services, the increasing popularity of the cloud approaches that allow fair LB is becoming more important than before. Cloud computing is characterized by the volatility of resources and the vari- ability that makes static LB approaches inefﬁcient. In this article, we presented a dynamic LB approach that aspires to achieve “almost optimal” fairness between different servers in terms of a QoS-based metric. We used the theory of LA to deal with the problem and designed a sophisticated LA that combined the time-separation paradigm and the concept of “artiﬁcial” ergodic (i.e., nonabsorbing) barriers, which was recently introduced by Yazidi and Hammer [51] and Yazidi et al. [52], respectively. In contrast to classical LA, the envi- ronment considered was modeled to be nonstationary, and the reward probabilities were shown to be characterized by a law of diminishing returns. As a future research endeavor, we intend to implement our solution in a real-life cloud setting and to test its efﬁciency and fairness compared with other classical approaches. ACKNOWLEDGMENT The authors are very grateful for the feedback from the anonymous referees of the original submission. Their input signiﬁcantly improved the quality of this ﬁnal version. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. 3456 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. 32, NO. 8, AUGUST 2021 REFERENCES [1] M. Agache and B. J. Oommen, “Generalized pursuit learning schemes: New families of continuous and discretized learning automata,” IEEE Trans. Syst., Man, Cybern. B. Cybern., vol. 32, no. 6, pp. 738–749, Dec. 2002. [2] A. Benveniste, P. Priouret, and M. Métivier, Adaptive Algorithms and Stochastic Approximations. New York, NY, USA: Springer-Verlag, 1990. [3] E. A. Billard, “Stabilizing distributed queuing systems using feedback based on diversity,” IEEE Trans. Syst., Man, Cybern. A, Syst. Humans, vol. 27, no. 2, pp. 251–256, Mar. 1997. [4] P. N. D. Bukh and R. Jain, The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Mea- surement, Simulation, and Modeling. 1992. [Online]. Available: [5] P. H. Calamai and J. J. Moré, “Projected gradient methods for linearly constrained problems,” Math. Program., vol. 39, no. 1, pp. 93–116, Sep. 1987. [6] G. C. Chasparis and J. S. Shamma, “Network formation: Neighborhood structures, establishment costs, and distributed learning,” IEEE Trans. Cybern., vol. 43, no. 6, pp. 1950–1962, Dec. 2013. [7] N. Dragoni et al., “Microservices: Yesterday, today, and tomorrow,” in Present and Ulterior Software Engineering. Cham, Switzerland: Springer, 2017, pp. 195–216. [Online]. Available: com/chapter/10.1007/978-3-319-67425-4_12 [8] A. Enami, J. A. Torkestani, and A. Karimi, “Resource selection in computational grids based on learning automata,” Expert Syst. Appl., vol. 125, pp. 369–377, Jul. 2019. [9] M. Fahimi and A. Ghasemi, “A distributed learning automata scheme for spectrum management in self-organized cognitive radio network,” IEEE Trans. Mobile Comput., vol. 16, no. 6, pp. 1490–1501, Jun. 2017. [10] O. Ghaleb and B. J. Oommen, “Learning automata-based solutions to the single elevator problem,” in Proc. IFIP Int. Conf. Artif. Intell. Appl. Innov. Cham, Switzerland: Springer, 2019, pp. 439–450. [Online]. Available: 7_37 [11] E. J. Ghomi, A. M. Rahmani, and N. N. Qader, “Load-balancing algorithms in cloud computing: A survey,” J. Netw. Comput. Appl., vol. 88, pp. 50–71, Jun. 2017. [12] R. L. Grossman, “The case for cloud computing,” IT Prof., vol. 11, no. 2, pp. 23–27, Mar./Apr. 2009. [13] J. Kleinberg and E. Tardos, Algorithm Design: Pearson New Interna- tional Edition. London, U.K.: Pearson Higher Ed, 2013. [14] P. S. Kumar, “A simple learning scheme for priority assignment at a single-server queue,” IEEE Trans. Syst., Man, Cybern., vol. 16, no. 5, pp. 751–754, Sep. 1986. [15] T. Kunz, “The inﬂuence of different workload descriptions on a heuristic load balancing scheme,” IEEE Trans. Softw. Eng., vol. 17, no. 7, pp. 725–730, Jul. 1991. [16] S. Lakshmivarahan, Learning Algorithms Theory and Applications. New York, NY, USA: Springer-Verlag, 1981. [17] J. D. Little and S. C. Graves, “Little’s law,” in Building Intuition. Boston, MA, USA: Springer, 2008, pp. 81–100. [Online]. Available: [18] L. Mason, “An optimal learning algorithm for S-model environments,” IEEE Trans. Autom. Control, vol. AC-18, no. 5, pp. 493–496, Oct. 1973. [19] P. Mell and T. Grance. . The NIST Deﬁnition of Cloud Com- puting. Accessed: Sep. 16, 2019. [Online]. Available: nist.gov/publications/detail/sp/800-145/ﬁnal [20] M. R. Meybodi, “Learning automata and its application to prior- ity assignment in a queueing system with unknown characteristics,” Ph.D. dissertation, School Elect. Eng. Comput. Sci., Univ. Oklahoma, Norman, OK, USA, 1983. [Online]. Available: bitstream/handle/11244/5130/8314780.PDF?sequence=1&isAllowed=y [21] M. Meybodi and S. Lakshmivarhan, “A learning approach to prior- ity assignment in a two class m/m/1 queuing system with unknown parameters,” in Proc. 3rd Yale Workshop Appl. Adapt. Syst. Theory. New Haven, CT, USA: Yale Univ., 1983, pp. 106–109. [22] R. Mirchandaney and J. A. Stankovic, “Using stochastic learn- ing automata for job scheduling in distributed processing systems,” J. Parallel Distrib. Comput., vol. 3, no. 4, pp. 527–552, Dec. 1986. [23] S. Misra, P. V. Krishna, K. Kalaiselvan, V. Saritha, and M. S. Obaidat, “Learning automata-based QoS framework for cloud IaaS,” IEEE Trans. Netw. Service Manag., vol. 11, no. 1, pp. 15–24, Mar. 2014. [24] S. Misra, S. S. Chatterjee, and M. Guizani, “Stochastic learning automata-based channel selection in cognitive radio/dynamic spectrum access for WiMAX networks,” Int. J. Commun. Syst., vol. 28, no. 5, pp. 801–817, 2015. [25] M. Mitzenmacher, “The power of two choices in randomized load balancing,” IEEE Trans. Parallel Distrib. Syst., vol. 12, no. 10, pp. 1094–1104, Oct. 2001. [26] K. Najim and A. S. Poznyak, Learning Automata: Theory and Applica- tions. Oxford, U.K.: Pergamon Press, 1994. [27] K. S. Narendra and M. A. L. Thathachar, Learning Automata: An Introduction. Upper Saddle River, NJ, USA: Prentice-Hall, 1989. [28] A. Nordrum. Popular Internet of Things Forecast of 50 Billion Devices by 2020 is Outdated, 2018. Accessed: Sep. 16, 2019. [Online]. Available: internet-of-things-forecast-of-50-billion-devices-by-2020-is-outdated [29] M. S. Obaidat, G. I. Papadimitriou, and A. S. Pomportsis, “Learning automata: Theory, paradigms, and applications,” IEEE Trans. Syst., Man, Cybern. B. Cybern., vol. 32, no. 6, pp. 706–709, Dec. 2002. [30] B. J. Oommen, “Absorbing and ergodic discretized two-action learning automata,” IEEE Trans. Syst., Man, Cybern., vol. SMC-16, no. 2, pp. 282–293, Mar. 1986. [31] J. Parent, K. Verbeeck, J. Lemeire, A. Nowe, K. Steenhaut, and E. Dirkx, “Adaptive load balancing of parallel applications with multi-agent rein- forcement learning on heterogeneous systems,” Sci. Program., vol. 12, no. 2, pp. 71–79, 2004. [32] D. K. Patel, D. Tripathy, and C. R. Tripathy, “Survey of load balancing techniques for grid,” J. Netw. Comput. Appl., vol. 65, pp. 103–119, Apr. 2016. [33] C. Pettey. . Cloud Shift Impacts all it Markets. Accessed: Sep. 16, 2019. [Online]. Available: smarterwithgartner/cloud-shift-impacts-all-it-markets/ [34] A. S. Poznyak and K. Najim, Learning Automata and Stochastic Optimization. Berlin, Germany: Springer-Verlag, 1997. [35] A. A. Rahmanian, M. Ghobaei-Arani, and S. Toﬁghy, “A learn- ing automata-based ensemble resource usage prediction algorithm for cloud computing environment,” Future Gener. Comput. Syst., vol. 79, pp. 54–71, Feb. 2018. [36] H. Roh, C. Jung, W. Lee, and D.-Z. Du, “Resource pricing game in geo-distributed clouds,” in Proc. IEEE INFOCOM, Apr. 2013, pp. 1519–1527. [37] Q. Sang, Z. Lin, and S. T. Acton, “Learning automata for image segmentation,” Pattern Recognit. Lett., vol. 74, pp. 46–52, Apr. 2016. [38] S. H. Seyyedi and B. Minaei-Bidgoli, “Using learning automata to determine proper subset size in high-dimensional spaces,” J. Exp. Theor. Artif. Intell., vol. 29, no. 2, pp. 415–432, Mar. 2017. [39] R. Simha and J. F. Kurose, “Relative reward strength algorithms for learning automata,” IEEE Trans. Syst., Man, Cybern., vol. 19, no. 2, pp. 388–398, Mar./Apr. 1989. [40] A.-A. Tantar, A. Q. Nguyen, P. Bouvry, B. Dorronsoro, and E.-G. Talbi, “Computational intelligence for cloud management cur- rent trends and opportunities,” in Proc. IEEE Congr. Evol. Comput., Jun. 2013, pp. 1286–1293. [41] A. Tchernykh, U. Schwiegelsohn, V. Alexandrov, and E.-G. Talbi, “Towards understanding uncertainty in cloud computing resource provi- sioning,” Procedia Comput. Sci., vol. 51, pp. 1772–1781, 2015. [Online]. Available: science/issues and computer-science/vol/51/suppl/C [42] M. L. Tsetlin, Automaton Theory and Modeling of Biological Systems. New York, NY, USA: Academic, 1973. [43] S. M. Vahidipour and M. Esnaashari, “Priority assignment in queuing systems with unknown characteristics using learning automata and adaptive stochastic Petri nets,” J. Comput. Sci., vol. 24, pp. 343–357, Jan. 2018. [44] S. M. Vahidipour, M. R. Meybodi, and M. Esnaashari, “Learning automata-based adaptive Petri net and its application to priority assign- ment in queuing systems with unknown parameters,” IEEE Trans. Syst., Man, Cybern. Syst., vol. 45, no. 10, pp. 1373–1384, Oct. 2015. [45] V. I. Varshavskii and I. P. Vorontsova, “On the behavior of stochastic automata with a variable structure,” Autom. Remote Control, vol. 24, no. 3, pp. 327–333, 1963. [46] G. Velusamy and R. Lent, “Dynamic cost-aware routing of Web requests,” Future Internet, vol. 10, no. 7, p. 57, Jun. 2018. [47] K. Verbeeck, A. Nowé, and K. Tuyls, “Coordinated exploration in multi- agent reinforcement learning: An application to load-balancing,” in Proc. 4th Int. Joint Conf. Auto. Agents Multiagent Syst. (AAMAS), 2005, pp. 1105–1106. [48] R. Wheeler and K. Narendra, “Decentralized learning in ﬁnite Markov chains,” IEEE Trans. Autom. Control, vol. 31, no. 6, pp. 519–526, Jun. 1986. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply. YAZIDI et al.: ACHIEVING FAIR LB BY INVOKING A LA-BASED TWO-TIME-SCALE SEPARATION PARADIGM 3457 [49] Z. Yang, Y. Liu, Y. Chen, and L. Jiao, “Learning automata based Q-learning for content placement in cooperative caching,” 2019, arXiv:1903.06235. [Online]. Available: [50] A. Yazidi, O.-C. Granmo, and B. J. Oommen, “Learning-automaton- based online discovery and tracking of spatiotemporal event patterns,” IEEE Trans. Cybern., vol. 43, no. 3, pp. 1118–1130, Jun. 2013. [51] A. Yazidi and H. L. Hammer, “Solving stochastic nonlinear resource allocation problems using continuous learning automata,” Appl. Intell., vol. 48, no. 11, pp. 4392–4411, 2018. [52] A. Yazidi, H. L. Hammer, and T. M. Jonassen, “Two-time scale learning automata: An efﬁcient decision making mechanism for stochastic nonlin- ear resource allocation,” Appl. Intell., vol. 49, pp. 3392–3405, Apr. 2019. [53] J. Zhang, C. Wang, D. Zang, and M. Zhou, “Incorporation of optimal computing budget allocation for ordinal optimization into learning automata,” IEEE Trans. Autom. Sci. Eng., vol. 13, no. 2, pp. 1008–1017, Apr. 2016. Anis Yazidi (Senior Member, IEEE) received the M.Sc. and Ph.D. degrees from the University of Agder, Grimstad, Norway, in 2008 and 2012, respectively. He was a Researcher with Teknova AS, Grimstad. From 2014 to 2019, he was an Associate Professor with the Department of Computer Science, Oslo Metropolitan University, Oslo, Norway, where he is currently a Full Professor and leading the Research Group in Applied Artiﬁcial Intelligence. He is also Professor II with the Norwegian University of Sci- ence and Technology (NTNU), Trondheim, Norway. His current research interests include machine learning, learning automata, stochastic optimization, and autonomous computing. Ismail Hassan received the M.Sc. degree in network and system administration from the University of Oslo, Oslo, Norway, in 2005. In 2005, he joined the Oslo University College (OsloMet), Oslo Metropolitan University, Oslo, as a Senior System and a Network Engineer, and after four years, transitioned to the position of Assistant Professor. He is currently an Assistant Professor with OsloMet. His ﬁeld of interests includes cyberse- curity, networking technologies, operating systems, DevSecOps, teaching, and learning methods. Hugo L. Hammer received the M.Sc. and Ph.D. degrees from the Norwegian University of Science and Technology, Trondheim, Norway, in 2003 and 2008, respectively. He is currently a Full Professor of statistics with the Department of Computer Science, Oslo Metropolitan University, Oslo, Norway. His current research interests include computer-intensive sta- tistical methods, Bayesian statistics, and learning systems. B. John Oommen (Life Fellow, IEEE) was born in Coonoor, India, in September 1953. He received the B.Tech. degree from IIT Madras, Chennai, India, in 1975, the M.E. degree from the Indian Institute of Science, Bengaluru, India, in 1977, and the M.S. and Ph.D. degrees from Purdue University, West Lafayette, IN, USA, in 1979 and 1982, respectively. He was with the School of Computer Science, Car- leton University, Ottawa, ON, Canada, from 1981 to 1982, where he is currently a Full Professor and, since July 2006, has been the Chancellor’s Professor, which is a lifetime award from Carleton University. He is the author of more than 485 refereed journal and conference publications. His research interests include automata learning, adaptive data structures, statistical and syntactic pattern recognition, stochastic algorithms, and partitioning algorithms. Dr. Oommen is also a fellow of the International Association for Pat- tern Recognition (IAPR). He has served on the Editorial Board of the IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS and Pattern Recognition. Authorized licensed use limited to: OsloMet - Oslo Metropolitan University. Downloaded on February 12,2025 at 20:11:13 UTC from IEEE Xplore. Restrictions apply.","—In this article, we consider the problem of load bal- ancing (LB), but, unlike the approaches that have been proposed earlier, we attempt to resolve the problem in a fair manner (or rather, it would probably be more appropriate to describe it as an ϵ-fair manner because, although the LB can, probably, never be totally fair, we achieve this by being “as close to fair as possible”). The solution that we propose invokes a novel stochastic learning automaton (LA) scheme, so as to attain a distribution of the load to a number of nodes, where the performance level at the different nodes is approximately equal and each user experiences approximately the same Quality of the Service (QoS) irrespective of which node that he/she is connected to. Since the load is dynamically varying, static resource allocation schemes are doomed to underperform. This is further relevant in cloud environments, where we need dynamic approaches because the available resources are unpredictable (or rather, uncertain) by virtue of the shared nature of the resource pool. Furthermore, we prove here that there is a coupling involving LA’s probabilities and the dynamics of the rewards themselves, which renders the environments to be nonstationary. This leads to the emergence of the so-called property of “stochastic diminishing rewards.” Our newly proposed novel LA algorithm ϵ-optimally solves the problem, and this is done by resorting to a two-time-scale-based stochastic learning paradigm. As far as we know, the results presented here are of a pioneering sort, and we are unaware of any comparable results. Index Terms—Continuous learning automaton (LA), fair load balancing (LB), resource allocation. I.","['Anis Yazidi', 'Ismail Hassan', 'Hugo L. Hammer', 'B. John Oommen']"
Normal Behaviour Models for Wind Turbine Vibrations: Comparison of Neural Networks and a Stochastic Approach,"Lind, Pedro G. and Vera-Tudela, Luis and Wächter, Matthias and Kühn, Martin and Peinke, Joachim",2017,12.0,10,Energies,article,"energies
Article
Normal Behaviour Models for Wind Turbine
Vibrations: Comparison of Neural Networks
and a Stochastic Approach
Pedro G. Lind 1,* ID , Luis Vera-Tudela 2, Matthias Wächter 2, Martin Kühn 2 ID and Joachim Peinke 2
1
Institut für Physik, Universität Osnabrück, Barbarastrasse 7, 49076 Osnabrück, Germany
2
ForWind—Center for Wind Energy Research, Institute of Physics, Carl von Ossietzky University of Oldenburg,
Küpkersweg 70, 26129 Oldenburg, Germany; luis.vera.tudela@forwind.de (L.V.-T.);
matthias.waechter@uni-oldenburg.de (M.W.); Martin.Kuehn@forwind.de (M.K.);
joachim.peinke@uni-oldenburg.de (J.P.)
*
Correspondence: pedro.g.lind@gmail.com; Tel.: +49-(0)541-969-2586; Fax: +49-(0)541-969-3472
Received: 29 October 2017; Accepted: 17 November 2017; Published: 23 November 2017
Abstract
Keywords: wind turbine; tower acceleration; condition monitoring; signal reconstruction; neural
networks; stochastic modelling
1. Introduction
As the number of wind turbines installed worldwide increases, the reduction of operational and
maintenance cost by enhanced surveillance gains on importance [1]. Recent reviews on condition
monitoring of wind turbines [2–4], recognize the importance that a reliability based maintenance
system has on reducing the cost of energy. Although it is possible to monitor wind turbine functioning
with 10-min average SCADA data, part of the information is lost when data is averaged; a mixed
system, combining SCADA data and conventional high frequency sensors is expected in the future [3].
Zaher et al. [5] described the lack of failure records as the main challenge for early failure detection,
which emphasizes the importance of normal behaviour modelling. Such models are built empirically,
i.e., using only measured signals, and refer to the expected value the signal should have based on its
own historical records. An anomaly in the signal is detected when the error on its prediction, made by
the normal behaviour model, increases over several subsequent values.
Vibrations in wind turbines reduce their performance and their expected lifetime; thus, strategies
developed for large structures, as buildings and brigdes, are applied and optimised to control their
Energies 2017, 10, 1944; doi:10.3390/en10121944
www.mdpi.com/journal/energies
 Energies 2017, 10, 1944
2 of 14
vibration. Dampers are incorporated to wind turbines as part of a passive, active or semi-active
strategy [6]. Also, their structural behaviour is recorded with sensors, which serve to assess its
normal functioning, which is a challenge on its own due to the non-stationary nature of the excitation.
Metamodels are foreseen to model short-term variations, which are governed by the rotation of
components, as well as long-term variations, which are governed by the changing nature of excitation
loads [7].
Previous investigations have built normal behaviour models with data-mining algorithms on
SCADA data. Most of them are based on 10-min data [8]. In Ref. [9], the authors presented their
application to detect anomalies in wind turbine gearboxes. In Ref. [5] the authors proposed a
framework for their combination into a single user interface to facilitate their use, while Ref. [10]
shows that a normal behaviour model based on neural networks (NN) outperforms a regression based
one. However, some scientists also evaluate data with higher sampling frequency, e.g., in [11] the
authors analysed the performance of various NN algorithms to detect bearing faults on wind turbines.
In Refs. [12,13], they evaluated wind turbine vibrations in time domain with 10-s sampling signals
from drive-train vibrations and tower top accelerations.
Furthermore, the capability of NN as means to monitor normal behaviour models for condition
monitoring of wind turbines can be further enhanced updating preprocessing and post-processing
steps, and so improving their training and to reducing their false alarms [14].
In contrast to existing methods, signals can also be reconstructed based on a stochastic approach,
which has not been assessed so far for the creation of normal behaviour models. In a previous work [15],
we demonstrated its value to estimate fatigue loads for wind turbines based on reconstructed signals.
Though this stochastic approach was already combined with NN models [16] for improving forecast
of air quality, there is no systematic investigation for evaluating whether the stochastic approach
alone can be used as an alternative to other standard monitoring procedures, namely using NN.
We focus speciﬁcally on assessing the stochastic approach as basis for normal behaviour models.
We evaluate the performance of such model to monitor vibrations on wind turbines and compare it
versus one based on a NN, which was found the most suitable NN model to reconstruct the tower top
acceleration [13]. Our goal is to present the stochastic approach in terms than can be understood by a
larger audience, and thus the comparison is not intended to ﬁnd the optimum model, by building and
comparing several regression models, as it was carried out in [11], but to build upon their ﬁndings
and communicate accordingly. We focus our assessment on the similarities and differences between
both approaches, and then discuss our ﬁndings with respect to the limitations imposed by the speciﬁc
case evaluated.
We start in Section 2 by describing in detail the data used in this investigation, obtained from one
wind turbine in an offshore wind farm. In Section 3 both the NN model and our stochastic approach
are introduced; then, the results obtained from them are properly presented. In Section 4 we compare
the results of both approaches when reconstructing one month of the tower acceleration measured at
one turbine. Section 5 concludes the paper.
2. Data Description
Wind turbine vibrations can easily be assessed monitoring two standard operational signals:
drive-train and tower top acceleration [13]. In this paper, we limited the analysis to the second one to
assess the reconstruction of signals with both the neural network model and the stochastic approach.
The data analysed in this paper correspond to measurements carried out in one 5 MW Senvion
wind turbine AV-04 of the offshore wind farm Alpha Ventus [17]. Alpha Ventus is the ﬁrst offshore
wind farm in Germany, located at Borkum West in the North Sea, 54.3◦N–6.5◦W. See Figure 1.
 Energies 2017, 10, 1944
3 of 14
0
0.05
0.1
0.15
0.2
0.25
v / vmax
0.001
0.01
0.1
Sv
0
200
400
600
800
1000
t (s)
-0.04
-0.02
0
0.02
a / amax
0.001
0.01
0.1
f (Hz)
0.0001
0.001
Sa
v
a
(a)
(b)
(c)
(d)
Figure 1. Location of the Alpha Ventus wind farm at Borkum West in the North Sea (54.3◦N–6.5◦W)
together with a picture of turbine AV04. Examples of (a,b) wind speed and (c,d) tower acceleration
signals in Alpha Ventus wind farm. The left ones ilustrate the time-domain of both quantities while
in the right the frequency domain is shown for the full datasets of October 2014. Scatter plot v × a
is shown in the inset of (a). All data were normalized to fulﬁll all conﬁdentiality protocols, namely
normalization to maximal values (see text). Both wind velocity and tower acceleration are normalized
to maximal observed values, vmax and amax respectively.
The turbine is subjected most of the time to undisturbed inﬂow due to its position in the ﬁrst
row of turbines, located at the western past of the wind farm. The support structure of the turbine
combines a rather stiff and hydrodynamically transparent jacket structure with a tubular tower on
top. In such a design the tower top acceleration signal is dominated by the dynamic response on
aerodynamic excitation mainly at the ﬁrst bending natural frequency of the system and at multiples of
the blade passing frequency. Wave excitation plays only a minor role. The blade passing frequency is
0.175 Hz, while the ﬁrst eigenfrequency of the tower is 0.34 Hz [18].
Data include all wind speed and tower top acceleration values recorded in October and November
2014, regardless of the operational and wind ﬂow conditions. Therefore, 29 days were available in
October (2,555,805 values) and 21 days in November (1,859,179 values). We only removed incorrect
measurements from the data collected, either because they were identiﬁed by the recording system
with a ﬂag (‘99999’ in our case) or because their values were out of reasonable physical values, namely
x > ¯x ± 5σ. Wind speed and tower acceleration values were available with sampling ratios of 1 Hz and
50 Hz respectively, thus the latter one was down-sampled to 1 Hz in order to complete the analysis.
 Energies 2017, 10, 1944
4 of 14
From measurements, 1434 and 992 records were ﬂagged as ‘99999’ (equivalent to less than 24 min)
while 1 and 45 (less than a minute) were found outside reasonable physical values and removed from
datasets representing the whole months for October and November respectively.
Wind speeds were measured by a cup anemometer included in the meteorological station located
on top of the nacelle. Tower top longitudinal accelerations were recorded by an accelerometer
positioned at the bottom of the nacelle, near its connection to the upper part of the tower. Figure 1
illustrates the characteristics of the data in time and frequency domain. All measurements are
normalized to maximal values.
The cup anemometer is suitable for 1 Hz sampling, similar to previous studies [15,19,20] to
analyse fatigue loads, dynamic power curves and damages on wind turbines. It turned out that this
sampling frequency is indeed sufﬁcient to resolve the response dynamics of turbine quantities with
respect to the wind ﬂuctuations.
Since we aimed to construct a model for prediction and not to explain or ﬁnd causality, we did
not perform any correction on the signals reconstructed. Although models that explain are assumed
to have good predictive characterstics, the ﬁrst one is not a requirement to have the second one,
as discussed in Ref. [21].
To protect sensitive manufacturer information we normalized the values. Wind speeds recorded
included the whole operational range of the wind turbine. Furthermore, we divided measurements in
two sets according to different purposes: data collected in October were used to estimate the parameters
in each model, while data collected in November were used to test each model’s performance.
3. Methods and Results
Each approach to construct a normal behaviour model is introduced in a concise manner.
Where convenient, we provide references to literature with extensive details about neural networks
and the stochastic approach. At the end of the section, we describe the performance metrics utilised
for the assessment.
In [13], the authors evaluated a pool of potential input variables to predict tower top acceleration
signal with a wrapper algorithm [22], which includes the predictor model to search for the variables
that reduce prediction error (a posteriori approach). They found wind speed, tower acceleration and
wind direction relevant. Since our evaluation focused on the approaches themselves, we limited the
pool of potential input variables to a single external signal (wind speed) and previous values of the
tower top acceleration to have the same number of inputs for each approach.
3.1. Neural Networks: A Deterministic Approach
Neural networks transform input variables with a linear coefﬁcient and a non-linear function.
This is repeated, in a chain, over a variable number of layers, where each output layer becomes the
input of the next one. The output of the last layer is the ﬁnal prediction made for the target value. In this
analysis, we utilised a non-linear auto-regressive with exogenous inputs (NARX) neural network,
which is a recurrent network, i.e., it includes one or more feedback loops. Thus, the approach followed
to estimate the predicted value of the tower top acceleration, given by:
ˆa(t) = f [a(t −∆t), . . . , a(t −na∆t), v(t −∆t), . . . , v(t −nv∆t)] + e(t),
(1)
involves the use of its na previous values (a(t −∆t), · · · , a(t −na∆t)) and those of the nv previous
wind speeds (v(t −∆t), · · · , v(t −nv∆t)) through a smooth unknown function f (). An extra random
component e(t) represents a random error, which has a zero mean and is independent of v and a [23].
The time-dependent predicting function ˆa(t) can be taken as an evolution equation.
To create the baseline normal behaviour model we used a NN to approximate f (), which is a
recursive non-linear transformation of its inputs. In Ref. [13], the authors demonstrated that NNs were
the most suitable algorithm to create a normal behaviour model for the tower top acceleration of a
 Energies 2017, 10, 1944
5 of 14
wind turbine when compared with neural network ensemble, boosting regression trees, support vector
machine, random forest with regression, standard classiﬁcation and regression tree and K-nearest
neighbour. In our investigation, we used a NN with two layers (two transformations). The ﬁrst
one (hidden layer) consisted of nh neurons, which apply non-linear transformations via a sigmoid
function; the second one (output layer) was formed by a single neuron, which performed an extra
linear transformation, with given weights wi.
To optimize the neural network we can also include a ﬁnite number of feedback loops for previous
values of the tower top accelerations (a, na) and wind speeds (v, nv), thus we have three parameters to
determine (nh, nv, na).
First, we divided data from October 2014 using the hold out method [22] in sub-sets for model
training (70%), validation (20%) and test (10%). Hold out was selected also at this stage [16] because
of the large number of points available in October and the data hold out from November. This was
meant to be in agreement with our intention to keep the inter model variations as small as possible.
Then, we selected the number of neurons in the hidden layer (nh), the number nv of input delays for
the wind speed v and the number na of output delays for the tower top acceleration a with a wrapper
algorithm [24], which searched for optimum prediction in the ranges nh, na, nv ∈{1, · · · , 50}.
The optimization of the unknown function f was set to minimize mean squared error:
MSE = 1
n
n
∑
i=1
( ˆyi −yi)2,
(2)
using the Levenberg-Marquardt algorithm. As a result, the architecture of the NARX network consisted
on 25 neurons in the hidden layer (nh = 25), three input delays (nv = 3) and one output delay (na = 1).
Figure 2 depicts the development and utilization of the NN model investigated. From left to right,
ﬁrst we used the three previous wind speeds and tower top accelerations collected in October 2014 to
deﬁne the constitutive components of the model, which is named a neural net black box in Figure 2.
Once the evolution equation ˆa(t) was deﬁned, we used wind speeds and the previous acceleration
value collected in November 2014 to predict the tower top acceleration signal, as well as to evaluate
the performance of the model.
Training
Training
EVOLUTION EQUATION
NEURAL NETWORK
APPROACH
NEURAL NET BLACK BOX
October
Hidden Layer
(non−linear functions)
f h
Output Layer
(linear combination):
w i
FOR a(t)  [Eq.(1)]
Prediction of
November
in November
wind speed
    v(t)
tower accel.
   a(t)
Wind speed
tower accel.
Figure 2. Schematic illustration of the neural network (NN) approach, indicating the development
and test of neural networks for signal reconstruction. Here the particular case of tower acceleration
reconstruction is given.
3.2. Stochastic Approach: The Langevin Model
The Langevin model is a framework developed from the pioneering work in Refs. [25,26],
which consists of a direct method for extracting the evolution equation of stochastic series of
measurements. Several applications were proposed and developed, e.g., in turbulence modelling,
in medical EEG monitoring and in stock markets. See Ref. [27] for a review. In the context of wind
 Energies 2017, 10, 1944
6 of 14
energy, this framework has shown the ability for predicting power curves of single wind turbines as
well as of equivalent power curves for entire wind farms, and also to properly reproduce the increment
statistics of power and torque in single wind turbines from wind speed measurements [19].
Figure 3 depicts the development and utilization of the stochastic approach investigated.
Our stochastic framework, instead of computing non-linear functions and weights, which optimize a
set of output compared to input data, retrieves two single functions of the variables involved. One of
such functions, below symbolized by D(1), governs the deterministic contribution for the time variation
of the output variable, while the other function, D(2), accounts for the stochastic ﬂuctuations that
include all the non-observable degrees of freedom present in the system. See the illustration in Figure 4.
Training
Training
Deterministic part
of the evolution 
      of L(t):
Stochastic part
of the evolution
     of L(t):
THE LANGEVIN
EVOLUTION EQUATION
APPROACH
LANGEVIN BLACK BOX
October
FOR a(t)  [Eq.(4)]
November
in November
D
D
(2)
Wind speed
Prediction of
tower accel.
wind speed
    v(t)
tower accel.
   a(t)
(1)
Figure 3. Schematic illustration of the Langevin (stochastic) approach. Here the particular case of tower
acceleration reconstruction at Alpha Ventus is given.
0
500
1000
t
0
0.5
1
1.5
2
a
990
1000
1010
1020
t
1.2
1.4
1.6
1.8
∆t
D
(1)∆t+(D
(2)∆t)
1/2rN(0,2)
∆a =
∆a
Figure 4. Illustration of the stochastic approach, while integrating the evolution Equation (4), composed
by its two contributions, the deterministic contribution D(1) which governes the tendency of the
evolving observable (blue), and the stochastic ﬂuctuations accounted by D(2) (red) added to the
deterministic part.
Having wind speeds v(t) and tower accelerations a(t), the following evolution equation for the
latter quantity is used:
da
dt = D(1)(a, v) +
q
D(2)(a, v)Γt,
(3)
with Γt representing a Gaussian δ-correlated white noise, i.e., ⟨Γt⟩= 0 and ⟨ΓtΓt′⟩= 2δ(t −t′).
The reconstruction of the tower acceleration a(t) follows therefore directly from the stochastic
integration of Equation (3) which yields:
a(t + ∆t) = a(t) + D(1)(a, v)∆t +
q
D(2)(a, v)∆t rN(0,2),
(4)
where rN(0,2) is a random number from a Gaussian distribution with zero mean and variance equal to
two. Details are illustrated in Figure 4 and can be found in Ref. [27].
 Energies 2017, 10, 1944
7 of 14
Function D(1) is also called drift function, while function D(2) is typically named as the diffusion
function. Since the drift and diffusion functions have a physical interpretation, one could apply the
model in Equation (3) to a particular system and deﬁne ad hoc the functional shape of both functions
from physical reasoning. Next we explain how to compute these both functions.
The derivation is performed through the computation of the corresponding ﬁrst and second
conditional moments [15], respectively:
M(1)
v∗(a, τ)
=
⟨a(t + τ) −a(t)⟩|a(t)=a,v(t)=v∗,
(5a)
M(2)
v∗(a, τ)
=
D
(a(t + τ) −a(t))2E
|a(t)=a,v(t)=v∗.
(5b)
where ⟨·⟩|X(t)=x indicates the average over the full time series, whenever X(t) takes the value x,
deﬁned within an interval.
Figure 5a shows the ﬁrst conditional moment for different values of the tower acceleration,
namely for a = 0.0075amax (bin 1), a = −0.0025amax (bin 2), a = 0.01amax (bin 3), computed as given in
Equation (5). Typically, for the lowest values of τ one observes a linear dependence of the conditional
moments with τ. Since it can be shown that drift (D(1)) and diffusion functions (D(2)) in Equation (3)
are, apart from a multiplicative constant (1/k!), the derivative with respect to the time-gap τ of the
ﬁrst and second conditional moments respectively, we can deﬁne both functions directly from the
conditional moments, namely:
D(k)(a, v) = lim
τ→0
1
k!
M(k)
v (a, τ)
τ
.
(6)
0
3
6
9
τ (s)
-0.03
-0.02
-0.01
0
0.01
0.02
M1(abin,   )
bin 1
bin 2
bin 3
τ
D1(abin2)
(a)
-0.1
-0.05
0
0.05
0.1
a / amax
-0.01
-0.005
0
0.005
0.01
D1
-0.1 -0.05
0
0.05
0.1
a / amax
0
0.0003
0.0006
0.0009
D2
(b)
(c)
Figure 5. Illustration of (a) the ﬁrst conditional moment for three different bin values of the tower
acceleration as deﬁned in Equation (5). Here v∗is given by the average velocity found during October.
Numerical result for (b) the drift D(1)(a, v) and (c) the diffusion D(2)(a, v) in the Langevin equation
given by Equation (6), plotted as function of a alone, i.e., they are projected at the a-axis to emphasize
the linear and quadratic dependency of D(1) and D(2) respectively for the largest range of acceleration
values. In red a polynomial ﬁt of both functions is shown. We use bins for the velocity with a width
of 0.017 in units of maximal velocity while acceleration was taken in bins of width 0.017 of maximal
tower acceleration.
In other words, by taking the slope of the linear regression for each conditional moment one
arrives to the corresponding value of function D(1) and D(2). Indeed, as sketched in Figure 5a, within a
sufﬁciently low range of τ values, here three time-steps of the set of measurements, the conditional
moments M(1) and M(2) depend linearly on τ. Figure 5b,c show both drift and diffusion functions,
(D(1)) and (D(2)) respectively, for a range of a-values at different velocities. Notice that while the
diffusion function shows a quadratic dependence on the tower acceleration, the drift function exhibits
a cubic dependence with a dominant linear term having one single ﬁxed point at a∗= 0 which
corresponds to the equilibrium position of tower vibrations.
 Energies 2017, 10, 1944
8 of 14
More precisely, a polynomial ﬁt of D(1) yields:
D(1)(a) = α −ka

1 + βa + γa2
(7)
with α = −1.75 × 10−4 us−1, u taken in units of amax, with k = 0.061 s−1, β = 0.67 u−1 and γ = 4.9 u−2.
Since the values of tower acceleration in units of u are typically of the order of 10−1 the dominant term
in the cubic ﬁt is clearly the linear one, yielding:
D(1)(a) ∼−ka.
(8)
In other words, the “force” D(1) governing the drift of tower acceleration can be interpreted as a
spring force with spring constant k around a stationary state with no acceleration that corresponds
obviously to the vertical position of the tower. This interpretation of the stochastic model will be of
importance below, where we discuss the possibility to use the stochastic modelling for monitoring
tower vibrations and eventual structural defects of the tower. The ﬁt of diffusion yields a quadratic
polynomial D(2)(a) = d0 + d1a + d2a2 with d0 = 7 × 10−6, d1 = 5.4 × 10−4 and d2 = 4.6 × 10−2.
It is important to stress that our framework is based on the assumption that the observable follows
a Markov process, which means nothing else than that the noise Γt is δ-correlated as mentioned above.
Though, one advantage of this Langevin data reconstruction is that it also works in some cases where
the Markov test fails [28]. The full implementation in one- and two-dimensions of this approach is
already public available [29]. Improvements on the noise term are beyond this paper, but were already
addressed previously [30,31].
3.3. Performance Evaluation
To compare both approaches, we consider the distribution of all values predicted from each model
for November 2015, in particular their four ﬁrst statistical moments, namely the mean, the standard
deviation, the skewness and the kurtosis. Notice that, while mean and standard deviation are sufﬁcient
for characterizing the distribution of Gaussian processes, in general, higher-order moments should be
checked for ascertaining if the process is non-Gaussian or not. The corresponding results are shown in
Figure 6 and Table 1.
-0.2
-0.1
0
0.1
0.2
a / amax
0.001
0.01
0.1
1
10
100
1,000
10,000
Measurements
Neural Nets
Langevin
-0.06
-0.03
0
0.03
0.06
a / amax
16,500
16,600
16,700
16,800
16,900
17,000
t (s)
-0.06
-0.03
0
0.03
0.06
a / amax
(a)
(b)
(c)
Neural Network
Stochastic
Figure 6. Sample of data series of tower acceleration from measurements at AV04 in Alpha Ventus
and the acceleration reconstruction models using (a) NARX neural networks and (b) the Langevin
model. In both cases, one also plots (black lines) the corresponding series of measurements for better
comparison. The corresponding value distribution of these series is displayed in (c) with symbols for
the full month of November 2014.
 Energies 2017, 10, 1944
9 of 14
Table 1. First four statistical moments of the value distributions shown in Figure 6d for the normalised
measurements and the reconstructed signals with each one of both models.
Signal
Mean
Std. Dev.
Skewness
Kurtosis
Measurements
−2.07 × 10−3
24.7 × 10−3
11.6 × 10−3
5.07
NN
−2.15 × 10−3
7.39 × 10−3
−30.1 × 10−3
6.31
Langevin model
−1.71 × 10−3
25.6 × 10−3
−3.59 × 10−3
2.37
Additionally, to evaluate the prediction of both models we use four different metrics, namely the
mean absolute error:
MAE = 1
n
n
∑
i=1
| ˆyi −yi|,
(9)
its standard deviation:
SDofAE =
v
u
u
t 1
n
n
∑
i=1
 
| ˆyi −yi| −1
n
n
∑
i=1
| ˆyi −yi|
!2
,
(10)
the mean square error (already presented in Section 3, Equation (2)) and its standard deviation:
SDofSE =
v
u
u
t 1
n
n
∑
i=1
""
( ˆyi −yi)2 −
n
∑
i=1
( ˆyi −yi)2
#2
,
(11)
where ˆyi denotes the ith measured value of the property y, and yi the corresponding modelled value,
either with NN or with the Langevin model.
Notice that the standard coefﬁcient of determination deﬁned as:
R2 = 1 −∑n
i=1( ˆyi −yi)2
∑n
i=1( ˆyi −¯y)2 ,
(12)
with ¯y = (1/n) ∑n
i=1 ˆyi, is related to MSE by:
MSE = 1 −R2
n
n
∑
i=1
( ˆyi −¯y)2.
(13)
References [13,32] reported these metrics to select the best data-mining technique and to derive
models for the normal behaviour of wind turbine vibration and to detect faults in wind turbine
gearboxes. Moreover, they have been commonly used to evaluate the accuracy of models utilised for
regression analysis in wind energy applications [11–13,32]. The correspondig results comparing the
NN and the stochastic approach are summarized in Table 2.
Table 2. Performance of both models, using the metrics deﬁned in Equations (2), (9)–(11), namely the
mean of the absolute error, Equation (9), its standard deviation, Equation (10), the mean square error,
Equation (2) and its standard deviation, Equation (11).
Signal
MAE
SDofAE
MSE
SDofSE
NN
0.031
0.032
2.0 × 10−3
65.6 × 10−3
Langevin model
0.027
0.031
1.6 × 10−3
0.7 × 10−3
 Energies 2017, 10, 1944
10 of 14
Finally, we also analyse the temporal correlations of the data. Therefore we use two methods,
namely we calculate the power spectra and analyse the statistics of the temporal increments:
∆a(t, τ) = a(t + τ) −a(t),
(14)
where τ = n∆t is an integer number n of consecutive time-steps ∆t. Note that the second moment
of the increments ∆a, given by ⟨(∆a)2⟩, corresponds to the power spectrum. The power spectrum
of the reconstructed signals are plotted in Figure 7, showing how the frequency components are
reconstructed. The statistics of the increments is given in Figure 8, from which we will ascertain how
good the model retrieves the evolution of the process throughout the succession of measurements [27].
0.0001
0.001
a / amax
0.0001
0.001
1e-05
0.0001
a / amax
1e-05
0.0001
0.001
0.01
0.1
f (Hz)
0.0001
0.001
a / amax
0.0001
0.001
Low freqs.
High freqs.
Observations
Neural Networks
Stochastic
Figure 7. Spectrum of original signal (top) and the corresponding reconstructed signals, one using the
neural network (middle) and the other using our proposed stochastic approach (bottom). Notice that
the high frequency domain is plotted in a linear frequency scale, while the low frequency domain is
plotted in the logarithmic scale.
-0.3
-0.2
-0.1
0
0.1
0.2
0.3
∆a
1×10-10
1×10-5
1
1×105
1×1010
1×1015
1×1020
Probability Density Function
Observations
Neural Net
Langevin
/σ∆a
Figure 8. Two-point statistics of the tower acceleration (lines) and the corresponding reconstructed
signals, i.e., value distributions of ∆a(t) = a(t + τ) −a(t). From top to bottom one has τ = 1, 2, 4, 8
and 16 s. The vertical shift of the distribution is for better visualization.
 Energies 2017, 10, 1944
11 of 14
4. Discussion
4.1. Comparing Both Approaches
To evaluate the suitability of the stochastic approach, described above, for modelling normal
behaviour of wind turbine vibrations, we compare it with the neural network [13].
Figure 6a,b shows normalized samples of the original tower top acceleration and its two
reconstructions. Already in these plots it is clear the stronger resemblance between the reconstructed
data from the stochastic approach and the set of tower acceleration measurements. While the NN
reconstruction keeps the average value of the tower oscillations, their range of amplitudes is not as
well reproduced as with the stochastic approach.
This feature is more evident in the plot of Figure 6c: both the stochastic and the NN models
retrieve the approximate distribution of values of the original signal (symbols), but the full range of the
tower acceleration values observed in measured distribution (bullets) is reproduced by the distribution
obtained from the Langevin model (diamonds) but not from the NN model (squares).
Furthermore, the empirical distribution is clearly non-Gaussian, showing exponential tails. Table 1
compares the ﬁrst four moments of all three distributions in Figure 6c. While NN reproduces the
mean more accurately, the standard deviation is much better modelled with the stochastic approach.
In other words, while the average behaviour is better modelled with NN, for properly reproduced the
amplitude of tower vibrations the stochastic approach is better suited.
Curiously however, while the (weak) skewness is also better approximated by the stochastic
approach, the value of the kurtosis is better reproduced by the NN model. Additionally, the response
obtained with NN had a smaller amplitude, as the optimization of its parameters reduce its cost
function, the mean square error, thus it tends to center its prediction to improve its accuracy.
These statistics are important to better describe the shape of distributions and thus, indicate their
symmetry and the weight of the tails, respectively. Our distribution is fairly symmetrical but with tails
that differ from a normal distribution.
The performance of both models was also assessed using the metrics introduced above,
Equations (9)–(11) and results are given in Table 2: one clearly sees a tendency for lower values
of MAE, SDofAE, MSE and SDofSE. For such metrics, one concludes that the stochastic approach
results have comparable accuracy or are even more accurate than the results from NN models, in what
concerns the predictions for the tower top acceleration.
As for the temporal correlations of the signals, the results plotted in Figure 7 show the spectral
behaviour of the two models compared with the measurements of the tower acceleration. While NN
better reproduces the periodic modes (peaks in the spectrum) present in the measurements, it is worse
for the low-frequency range and for the overall amplitudes of the spectrum. Notice the different
vertical scale used for plotting the NN results. The stochastic approach smoothes out the periodic
modes, but reproduces the overall shape of the empirical power spectrum.
The metrics chosen indicate that the stochastic approach is a good alternative to model the
normal behaviour of a signal. However, for certain situations other approaches dealing with the
identiﬁcation of normal and abnormal behaviour may also be suited. For example, were we in
posession of abnormalities in our data set, we could have also used a classiﬁcation algorithm to mark
records into either one of two classes (normal, abnormal). In such a case, care must been taken to
account for the imbalance of instances in one of the classes [22], and as a consequence, we would
have had to select other metrics, such as the F-measure as recommended by the investigation of fault
diagnosis in gearboxes [33].
A better reconstruction of two-point statistics is also obtained through the stochastic approach,
as shown in Figure 8. It is clear that the stochastic approach better reconstructs the differences ∆a
between consecutive values in the tower acceleration series, only with some small deviations for the
largest differences. This shows furthermore that the assumption of Markovian process with Langevin
noise is considerably reliable for these data sets.
 Energies 2017, 10, 1944
12 of 14
4.2. Stochastic Modelling Applied to the Monitoring of Tower Vibrations
Having shown the better performance of the stochastic approach with higher frequency sampling
data, in this section we brieﬂy discuss how the approach can be applied to speciﬁc monitoring of tower
vibrations. The discussion is based on the approximation derived in Equation (8) and follows from the
recent ﬁndings reported in Ref. [20].
The Ansatz of the stochastic modelling proposed above for tower vibrations, describes the
evolution of short-time vibrations as the superposition of two contributions, being one deterministic
(governed by function D(1)), and the other stochastic (governed by function D(2)). In parallel, tower
vibrations result from the interplay of a mass of wind acting on the tower and the tower itself reacting
back to the wind. Though there is no clear-cut match between the two contributions in our Ansatz and
the physical reality of tower vibrations, we may regard the deterministic contribution (D(1)) as the
one describing the tower response to wind loads and the stochastic part (D(2)) as the one describing
the (turbulent) dynamics of wind. Consequently, from such an interpretation of the stochastic model
introduced in Equation (3) we conclude that for monitoring normal functioning of tower vibrations we
should focus on D(1).
As derived above in Equation (8), function D(1) can be interpreted as an elastic force,
parameterized by a spring constant k. This spring constant characterizes the vibrating tower and
therefore, in case structural defects occur, one expects that the vibrations will be qualitatively different
from there on, showing a different D(1) in a way that a plot of it similar to Figure 5b will show a different
slope, i.e., different value of the spring constant.
Before concluding, one additional point needs to be discussed. The absolute quality of the wind
speed measurement is not crucial to our method. Most important for our method is the wind speed
that the rotor is exposed to. In this sense it is even preferable to let the anemometer share the same
tower oscillations as the rotor. However, we believe that the inﬂuence of tower oscillations on the
wind speed measurement is small anyway. A very coarse estimation of nacelle oscillations leads to
amplitudes in the order of 1 m at a frequency clearly below 1 Hz. This may give rise to wind speed
measurement deviations below 1 m/s. As for our analysis we use wind speed classes of 0.5 m/s width,
most of these tower oscillations would not have any effect. Moreover, these deviations will average out
due to their periodic nature. As our analysis is of statistical nature, a signiﬁcant effect is not expected.
5. Conclusions
We have presented a stochastic approach which is capable of modelling the normal behaviour
of wind turbine tower acceleration for its monitoring. Our results demonstrate that, compared to
neural network (NN) models and using a single input, the Langevin model is able to better reconstruct
non-Gaussian ﬂuctuations of signals. In general both models provide a good estimate for the central
part of the original signal, but the stochastic approach also reconstructs its complete variance.
We have also shown that a normal behaviour model based on the stochastic approach provides
more information about the original signal than one based on NNs. Still, one should emphasize that
previous publications on normal behaviour models, to monitor vibration of wind turbines based on
SCADA [12,13] using 10-s sampling signals, demonstrated the suitability of NNs and control charts
as a method to monitor signals in time-domain. Our results for NN match the applications found
in the literature, where they have been used with 10-min sampling time-series [10]. When using
low-frequency data, the NN is as good as our stochastic approach.
Putting our results in perspective, we state that NNs are a good choice to predict average values
or less ﬂuctuating signals. For situations where 10-min data is not sufﬁciently, namely when dealing
with cumulative loads for which the large wind ﬂuctuations of short intervals play an important role,
NNs seem to retrieve not so good results as the stochastic approach.
All in all, in those cases where the sampling rate is low, the NNs remain as a good option to
take into account, as the monitoring is sufﬁcient in time-domain and the requirements to apply the
stochastic approach are not always fulﬁlled. In cases where the sampling rate of the signal is high
 Energies 2017, 10, 1944
13 of 14
(1 Hz in our case), the stochastic approach is clearly a better choice. It allows for monitoring normal
behaviour in time-domain as with NNs, but also extends the possibilities to the frequency-domain.
As discussed above, to notice that a central advantage of the stochastic approach is that deterministic
and noisy contributions can be separated leading to improvements in the statistical reproduction
of the output ﬂuctuations. The study of the long time behaviour of the deterministic part of the
Langevin equation used in the stochastic approach can also provide information about the health of the
structure, in a similar direction as previous work [20]. From this paper, one can now use the available
routines [28,29] and extend the stochastic approach here applied to other wind turbine properties, in
particular to other loads.
Acknowledgments:
This work was partly funded by the German Federal Ministry of Economic Affairs and
Energy and the State of Lower Saxony as part of the research project “Probabilistic load description, monitoring,
and reduction for the next generation of offshore wind turbines (OWEA Loads)”, grant number 0325577B, and also
by the Ministry of Science and Culture of Lower Saxony in the project “Ventus Efﬁciens” (ZN3024). Additionally,
ﬁnancial support from the Deutsche Forschungsgemeinschaft (MA 1636/9-1) and the Open Access Publishing
Fund of Osnabrück University is gratefully acknowledged. The authors also thank Senvion SE for providing the
data here analyzed.
Author Contributions: Pedro G. Lind and Luis Vera-Tudela performed the simulations. Pedro G. Lind and
Luis Vera-Tudela prepared the manuscript. Matthias Wächter, Martin Kühn and Joachim Peinke proposed the
ideas and methodologies. All authors revised the text and output results.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
References
1.
Yang, W.; Tavner, P.J.; Crabtree, C.J.; Feng, Y.; Qiu, Y. Wind turbine condition monitoring: Technical and
commercial challenges. Wind Energy 2014, 17, 673–693.
2.
Kusiak, A.; Zhang, Z.; Verma, A. Prediction, operations, and condition monitoring in wind energy. Energy
2013, 60, 1–12.
3.
Wang, K.S.; Sharma, V.S.; Zhang, Z.Y. SCADA data based condition monitoring of wind turbines. Adv. Manuf.
2014, 2, 61–69.
4.
Tchakoua, P.; Wamkeue, R.; Ouhrouche, M.; Slaoui-Hasnaoui, F.; Tameghe, T.; Ekemb, G. Wind Turbine
Condition Monitoring: State-of-the-Art Review, New Trends, and Future Challenges.
Energies 2014,
7, 2595–2630.
5.
Zaher, A.; McArthur, S.; Inﬁeld, D. Online wind turbine fault detection through automated SCADA data
analysis. Wind Energy 2009, 12, 574–593.
6.
Rahman, M.; Ong, Z.; Chong, T.; Julai, S.; Khoo, S. Performance enhancement of wind turbine systems with
vibration control: A review. Renew. Sustain. Energy Rev. 2015, 51, 43–54.
7.
Bogoevska, S.; Spiridonakos, M.; Chatzi, E.; Dumova-Jovanoska, E.; Höffer, R. A Data-Driven Diagnostic
Framework for Wind Turbine Structures: A Holistic Approach. Sensors 2017, 17, 720.
8.
Wang, J.; Heng, J.; Xiao, L.; Wang, C. Research and application of a combined model based on multi-objective
optimization for multi-step ahead wind speed forecasting. Energy 2017, 125, 591–613.
9.
Cruz Garcia, M.; Sanz-Bobi, M.A.; del Pico, J. SIMAP: Intelligent System for Predictive Maintenance.
Application to the health condition monitoring of a windturbine gearbox. Comput. Ind. 2006, 57, 552–568.
10.
Schlechtingen, M.; Ferreira Santos, I. Comparative analysis of neural network and regression based condition
monitoring approaches for wind turbine fault detection. Mech. Syst. Signal Process. 2011, 25, 1849–1875.
11.
Kusiak, A.; Verma, A. Analyzing bearing faults in wind turbines: A data-mining approach. Renew. Energy
2012, 48, 110–116.
12.
Kusiak, A.; Zhang, Z. Analysis of Wind Turbine Vibrations Based on SCADA Data. J. Sol. Energy Eng. 2010,
132, 031008.
13.
Zhang, Z.; Kusiak, A. Monitoring Wind Turbine Vibration Based on SCADA Data. J. Sol. Energy Eng. 2012,
134, 021004.
14.
Bangalore, P.; Letzgus, S.; Karlsson, D.; Patriksson, M.
An artiﬁcial neural network-based condition
monitoring method for wind turbines, with application to the monitoring of the gearbox. Wind Energy 2017,
20, 1421–1438.
 Energies 2017, 10, 1944
14 of 14
15.
Lind, P.G.; Herráez, I.; Wächter, M.; Peinke, J. Fatigue Load Estimation through a Simple Stochastic Model.
Energies 2014, 7, 8279–8293.
16.
Russo, A.; Raischel, F.; Lind, P.G. Air quality prediction using optimal neural networks with stochastic
variables. Atmos. Environ. 2013, 79, 822–830.
17.
Müller, K.; Cheng, P.W. Validation of uncertainty in IEC damage calculations based on measurements from
alpha ventus. Energy Procedia 2016, 94, 133–145.
18.
Cheng, W.; Lutz, T.; Kühn, M.; Bartsch, J.; Kruse, J.; Schaumann, P.; Bange, J. Probabilistische Lastbeschreibung,
Monitoring und Reduktion der Lasten zukünftiger Offshore-Windenergieanlagen (OWEA Loads); Technical Report;
WindForS and ForWind and Adwen GmbH and Senvion: Oldenburg/Stuttgart, Germany, 2017.
19.
Mücke, T.; Wächter, M.; Milan, P.; Peinke, J. Langevin power curve analysis for numerical wind energy
converter models with new insights on high frequency power performance. Wind Energy 2015, 18, 1953–1971.
20.
Rinn, P.; Heißelmann, H.; Wächter, M.; Peinke, J. Stochastic method for in-situ damage analysis. Eur. Phys.
J. B 2013, 86, 3.
21.
Shmueli, G. To Explain or to Predict? Stat. Sci. 2010, 25, 289–310.
22.
Borovicka, T.; Jirina, M.J.; Kordik, P.; Jirina, M. Selecting representative data sets. In Advances in Data Mining
Knowledge Discovery and Applications; Karahoca, A., Ed.; InTech: Rijeka, Croatia, 2012; pp. 43–70.
23.
Hastie, T.; Tibshirani, R.; Friedman, J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction,
2nd ed.; Springer: New York, NY, USA, 2013; p. 759.
24.
May, R.; Dandy, G.; Maier, H. Review of input variable selection methods for artiﬁcial neural networks.
In Artiﬁcial Neural Networks—Methodological Advances and Biomedical Applications; Suzuki, K., Ed.; InTech
Europe: Rijeka, Croatia, 2011; pp. 19–44.
25.
Friedrich, R.; Peinke, J. Description of a Turbulent Cascade by a Fokker-Planck Equation. Phys. Rev. Lett.
1997, 78, 863.
26.
Siegert, S.; Friedrich, R.; Peinke, J. Analysis of Data of Stochastic Systems. Phys. Lett. A 1998, 243, 275–280.
27.
Friedrich, R.; Peinke, J.; Sahimi, M.; Tabar, M. Approaching complexity by stochastic methods: From
biological systems to turbulence. Phys. Rep. 2011, 506, 87–167.
28.
Rinn, P.; Lind, P.; Wächter, M.; Peinke, J. The Langevin Approach: An R Package for Modeling Stochastic
Processes. J. Open Res. Softw. 2016, 4, e34.
29.
Rinn, P.; Lind, P.G.; Bastine, D. Langevin 1D and 2D. 2015. Available online: https://cran.r-project.org/
web/packages/Langevin/ (accessed on 28 October 2017 ).
30.
Lehle, B. Analysis of stochastic time series in the presence of strong measurement noise. Phys. Rev. E 2011,
83, 021113.
31.
Anvari, M.; Tabar, R.R.; Peinke, J.; Lehnertz, K. Disentangling the stochastic behaviour of complex time
series. Nat. Sci. Rep. 2016, 6, 35435.
32.
Zhang, Z.; Verma, A.; Member, S.; Kusiak, A. Fault Analysis and Condition Monitoring of the Wind Turbine
Gearbox. IEEE Trans. Energy Convers. 2012, 27, 526–535.
33.
Santos, P.; Maudes, J.; Bustillo, A. Identifying maximum imbalance in datasets for fault diagnosis of
gearboxes. J. Intell. Manuf. 2015, doi:10.1007/s10845-015-1110-0.
c⃝2017 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).
",10.3390/en10121944,doc33,": To monitor wind turbine vibrations, normal behaviour models are built to predict tower
top accelerations and drive-train vibrations. Signal deviations from model prediction are labelled as
anomalies and are further investigated. In this paper we assess a stochastic approach to reconstruct
the 1 Hz tower top acceleration signal, which was measured in a wind turbine located at the wind
farm Alpha Ventus in the German North Sea. We compare the resulting data reconstruction with
that of a model based on a neural network, which has been previously reported as a data-mining
algorithm suitable for reconstructing this signal. Our results present evidence that the stochastic
approach outperforms the neural network in the high frequency domain (1 Hz). Although neural
network retrieves accurate step-forward predictions, with low mean square errors, the stochastic
approach predictions better preserve the statistics and the frequency components of the original signal,
retaining high accuracy levels. The implementation of our stochastic approach is available as open
source code and can easily be adapted for other situations involving stochastic data reconstruction.
Based on our ﬁndings we argue that such an approach could be implemented in signal reconstruction
for monitoring purposes or for abnormal behaviour detection.","energies Article Normal Behaviour Models for Wind Turbine Vibrations: Comparison of Neural Networks and a Stochastic Approach Pedro G. Lind 1,* ID , Luis Vera-Tudela 2, Matthias Wächter 2, Martin Kühn 2 ID and Joachim Peinke 2 1 Institut für Physik, Universität Osnabrück, Barbarastrasse 7, 49076 Osnabrück, Germany 2 ForWind—Center for Wind Energy Research, Institute of Physics, Carl von Ossietzky University of Oldenburg, Küpkersweg 70, 26129 Oldenburg, Germany; luis.vera.tudela@forwind.de (L.V.-T.); matthias.waechter@uni-oldenburg.de (M.W.); Martin.Kuehn@forwind.de (M.K.); joachim.peinke@uni-oldenburg.de (J.P.) * Correspondence: pedro.g.lind@gmail.com; Tel.: +49-541-969-2586; Fax: +49-541-969-3472 Received: 29 October 2017; Accepted: 17 November 2017; Published: 23 November 2017 Abstract Keywords: wind turbine; tower acceleration; condition monitoring; signal reconstruction; neural networks; stochastic modelling 1. Introduction As the number of wind turbines installed worldwide increases, the reduction of operational and maintenance cost by enhanced surveillance gains on importance [1]. Recent reviews on condition monitoring of wind turbines [2–4], recognize the importance that a reliability based maintenance system has on reducing the cost of energy. Although it is possible to monitor wind turbine functioning with 10-min average SCADA data, part of the information is lost when data is averaged; a mixed system, combining SCADA data and conventional high frequency sensors is expected in the future [3]. Zaher et al. [5] described the lack of failure records as the main challenge for early failure detection, which emphasizes the importance of normal behaviour modelling. Such models are built empirically, i.e., using only measured signals, and refer to the expected value the signal should have based on its own historical records. An anomaly in the signal is detected when the error on its prediction, made by the normal behaviour model, increases over several subsequent values. Vibrations in wind turbines reduce their performance and their expected lifetime; thus, strategies developed for large structures, as buildings and brigdes, are applied and optimised to control their Energies 2017, 10, 1944; doi:10.3390/en10121944 Energies 2017, 10, 1944 2 of 14 vibration. Dampers are incorporated to wind turbines as part of a passive, active or semi-active strategy [6]. Also, their structural behaviour is recorded with sensors, which serve to assess its normal functioning, which is a challenge on its own due to the non-stationary nature of the excitation. Metamodels are foreseen to model short-term variations, which are governed by the rotation of components, as well as long-term variations, which are governed by the changing nature of excitation loads [7]. Previous investigations have built normal behaviour models with data-mining algorithms on SCADA data. Most of them are based on 10-min data [8]. In Ref. [9], the authors presented their application to detect anomalies in wind turbine gearboxes. In Ref. [5] the authors proposed a framework for their combination into a single user interface to facilitate their use, while Ref. [10] shows that a normal behaviour model based on neural networks (NN) outperforms a regression based one. However, some scientists also evaluate data with higher sampling frequency, e.g., in [11] the authors analysed the performance of various NN algorithms to detect bearing faults on wind turbines. In Refs. [12,13], they evaluated wind turbine vibrations in time domain with 10-s sampling signals from drive-train vibrations and tower top accelerations. Furthermore, the capability of NN as means to monitor normal behaviour models for condition monitoring of wind turbines can be further enhanced updating preprocessing and post-processing steps, and so improving their training and to reducing their false alarms [14]. In contrast to existing methods, signals can also be reconstructed based on a stochastic approach, which has not been assessed so far for the creation of normal behaviour models. In a previous work [15], we demonstrated its value to estimate fatigue loads for wind turbines based on reconstructed signals. Though this stochastic approach was already combined with NN models [16] for improving forecast of air quality, there is no systematic investigation for evaluating whether the stochastic approach alone can be used as an alternative to other standard monitoring procedures, namely using NN. We focus speciﬁcally on assessing the stochastic approach as basis for normal behaviour models. We evaluate the performance of such model to monitor vibrations on wind turbines and compare it versus one based on a NN, which was found the most suitable NN model to reconstruct the tower top acceleration [13]. Our goal is to present the stochastic approach in terms than can be understood by a larger audience, and thus the comparison is not intended to ﬁnd the optimum model, by building and comparing several regression models, as it was carried out in [11], but to build upon their ﬁndings and communicate accordingly. We focus our assessment on the similarities and differences between both approaches, and then discuss our ﬁndings with respect to the limitations imposed by the speciﬁc case evaluated. We start in Section 2 by describing in detail the data used in this investigation, obtained from one wind turbine in an offshore wind farm. In Section 3 both the NN model and our stochastic approach are introduced; then, the results obtained from them are properly presented. In Section 4 we compare the results of both approaches when reconstructing one month of the tower acceleration measured at one turbine. Section 5 concludes the paper. 2. Data Description Wind turbine vibrations can easily be assessed monitoring two standard operational signals: drive-train and tower top acceleration [13]. In this paper, we limited the analysis to the second one to assess the reconstruction of signals with both the neural network model and the stochastic approach. The data analysed in this paper correspond to measurements carried out in one 5 MW Senvion wind turbine AV-04 of the offshore wind farm Alpha Ventus [17]. Alpha Ventus is the ﬁrst offshore wind farm in Germany, located at Borkum West in the North Sea, 54.3◦N–6.5◦W. See Figure 1. Energies 2017, 10, 1944 3 of 14 0 0.05 0.1 0.15 0.2 0.25 v / vmax 0.001 0.01 0.1 Sv 0 200 400 600 800 1000 t (s) -0.04 -0.02 0 0.02 a / amax 0.001 0.01 0.1 f (Hz) 0.0001 0.001 Sa v a (a) (b) (c) (d) Figure 1. Location of the Alpha Ventus wind farm at Borkum West in the North Sea (54.3◦N–6.5◦W) together with a picture of turbine AV04. Examples of (a,b) wind speed and (c,d) tower acceleration signals in Alpha Ventus wind farm. The left ones ilustrate the time-domain of both quantities while in the right the frequency domain is shown for the full datasets of October 2014. Scatter plot v × a is shown in the inset of (a). All data were normalized to fulﬁll all conﬁdentiality protocols, namely normalization to maximal values (see text). Both wind velocity and tower acceleration are normalized to maximal observed values, vmax and amax respectively. The turbine is subjected most of the time to undisturbed inﬂow due to its position in the ﬁrst row of turbines, located at the western past of the wind farm. The support structure of the turbine combines a rather stiff and hydrodynamically transparent jacket structure with a tubular tower on top. In such a design the tower top acceleration signal is dominated by the dynamic response on aerodynamic excitation mainly at the ﬁrst bending natural frequency of the system and at multiples of the blade passing frequency. Wave excitation plays only a minor role. The blade passing frequency is 0.175 Hz, while the ﬁrst eigenfrequency of the tower is 0.34 Hz [18]. Data include all wind speed and tower top acceleration values recorded in October and November 2014, regardless of the operational and wind ﬂow conditions. Therefore, 29 days were available in October (2,555,805 values) and 21 days in November (1,859,179 values). We only removed incorrect measurements from the data collected, either because they were identiﬁed by the recording system with a ﬂag (‘99999’ in our case) or because their values were out of reasonable physical values, namely x > ¯x ± 5σ. Wind speed and tower acceleration values were available with sampling ratios of 1 Hz and 50 Hz respectively, thus the latter one was down-sampled to 1 Hz in order to complete the analysis. Energies 2017, 10, 1944 4 of 14 From measurements, 1434 and 992 records were ﬂagged as ‘99999’ (equivalent to less than 24 min) while 1 and 45 (less than a minute) were found outside reasonable physical values and removed from datasets representing the whole months for October and November respectively. Wind speeds were measured by a cup anemometer included in the meteorological station located on top of the nacelle. Tower top longitudinal accelerations were recorded by an accelerometer positioned at the bottom of the nacelle, near its connection to the upper part of the tower. Figure 1 illustrates the characteristics of the data in time and frequency domain. All measurements are normalized to maximal values. The cup anemometer is suitable for 1 Hz sampling, similar to previous studies [15,19,20] to analyse fatigue loads, dynamic power curves and damages on wind turbines. It turned out that this sampling frequency is indeed sufﬁcient to resolve the response dynamics of turbine quantities with respect to the wind ﬂuctuations. Since we aimed to construct a model for prediction and not to explain or ﬁnd causality, we did not perform any correction on the signals reconstructed. Although models that explain are assumed to have good predictive characterstics, the ﬁrst one is not a requirement to have the second one, as discussed in Ref. [21]. To protect sensitive manufacturer information we normalized the values. Wind speeds recorded included the whole operational range of the wind turbine. Furthermore, we divided measurements in two sets according to different purposes: data collected in October were used to estimate the parameters in each model, while data collected in November were used to test each model’s performance. 3. Methods and Results Each approach to construct a normal behaviour model is introduced in a concise manner. Where convenient, we provide references to literature with extensive details about neural networks and the stochastic approach. At the end of the section, we describe the performance metrics utilised for the assessment. In [13], the authors evaluated a pool of potential input variables to predict tower top acceleration signal with a wrapper algorithm [22], which includes the predictor model to search for the variables that reduce prediction error (a posteriori approach). They found wind speed, tower acceleration and wind direction relevant. Since our evaluation focused on the approaches themselves, we limited the pool of potential input variables to a single external signal (wind speed) and previous values of the tower top acceleration to have the same number of inputs for each approach. 3.1. Neural Networks: A Deterministic Approach Neural networks transform input variables with a linear coefﬁcient and a non-linear function. This is repeated, in a chain, over a variable number of layers, where each output layer becomes the input of the next one. The output of the last layer is the ﬁnal prediction made for the target value. In this analysis, we utilised a non-linear auto-regressive with exogenous inputs (NARX) neural network, which is a recurrent network, i.e., it includes one or more feedback loops. Thus, the approach followed to estimate the predicted value of the tower top acceleration, given by: ˆa(t) = f [a(t −∆t), . . . , a(t −na∆t), v(t −∆t), . . . , v(t −nv∆t)] + e(t), involves the use of its na previous values (a(t −∆t), · · · , a(t −na∆t)) and those of the nv previous wind speeds (v(t −∆t), · · · , v(t −nv∆t)) through a smooth unknown function f (). An extra random component e(t) represents a random error, which has a zero mean and is independent of v and a [23]. The time-dependent predicting function ˆa(t) can be taken as an evolution equation. To create the baseline normal behaviour model we used a NN to approximate f (), which is a recursive non-linear transformation of its inputs. In Ref. [13], the authors demonstrated that NNs were the most suitable algorithm to create a normal behaviour model for the tower top acceleration of a Energies 2017, 10, 1944 5 of 14 wind turbine when compared with neural network ensemble, boosting regression trees, support vector machine, random forest with regression, standard classiﬁcation and regression tree and K-nearest neighbour. In our investigation, we used a NN with two layers (two transformations). The ﬁrst one (hidden layer) consisted of nh neurons, which apply non-linear transformations via a sigmoid function; the second one (output layer) was formed by a single neuron, which performed an extra linear transformation, with given weights wi. To optimize the neural network we can also include a ﬁnite number of feedback loops for previous values of the tower top accelerations (a, na) and wind speeds (v, nv), thus we have three parameters to determine (nh, nv, na). First, we divided data from October 2014 using the hold out method [22] in sub-sets for model training (70%), validation (20%) and test (10%). Hold out was selected also at this stage [16] because of the large number of points available in October and the data hold out from November. This was meant to be in agreement with our intention to keep the inter model variations as small as possible. Then, we selected the number of neurons in the hidden layer (nh), the number nv of input delays for the wind speed v and the number na of output delays for the tower top acceleration a with a wrapper algorithm [24], which searched for optimum prediction in the ranges nh, na, nv ∈{1, · · · , 50}. The optimization of the unknown function f was set to minimize mean squared error: MSE = 1 n n ∑ i=1 ( ˆyi −yi)2, using the Levenberg-Marquardt algorithm. As a result, the architecture of the NARX network consisted on 25 neurons in the hidden layer (nh = 25), three input delays (nv = 3) and one output delay (na = 1). Figure 2 depicts the development and utilization of the NN model investigated. From left to right, ﬁrst we used the three previous wind speeds and tower top accelerations collected in October 2014 to deﬁne the constitutive components of the model, which is named a neural net black box in Figure 2. Once the evolution equation ˆa(t) was deﬁned, we used wind speeds and the previous acceleration value collected in November 2014 to predict the tower top acceleration signal, as well as to evaluate the performance of the model. Training Training EVOLUTION EQUATION NEURAL NETWORK APPROACH NEURAL NET BLACK BOX October Hidden Layer (non−linear functions) f h Output Layer (linear combination): w i FOR a(t) [Eq.] Prediction of November in November wind speed v(t) tower accel. a(t) Wind speed tower accel. Figure 2. Schematic illustration of the neural network (NN) approach, indicating the development and test of neural networks for signal reconstruction. Here the particular case of tower acceleration reconstruction is given. 3.2. Stochastic Approach: The Langevin Model The Langevin model is a framework developed from the pioneering work in Refs. [25,26], which consists of a direct method for extracting the evolution equation of stochastic series of measurements. Several applications were proposed and developed, e.g., in turbulence modelling, in medical EEG monitoring and in stock markets. See Ref. [27] for a review. In the context of wind Energies 2017, 10, 1944 6 of 14 energy, this framework has shown the ability for predicting power curves of single wind turbines as well as of equivalent power curves for entire wind farms, and also to properly reproduce the increment statistics of power and torque in single wind turbines from wind speed measurements [19]. Figure 3 depicts the development and utilization of the stochastic approach investigated. Our stochastic framework, instead of computing non-linear functions and weights, which optimize a set of output compared to input data, retrieves two single functions of the variables involved. One of such functions, below symbolized by D, governs the deterministic contribution for the time variation of the output variable, while the other function, D, accounts for the stochastic ﬂuctuations that include all the non-observable degrees of freedom present in the system. See the illustration in Figure 4. Training Training Deterministic part of the evolution of L(t): Stochastic part of the evolution of L(t): THE LANGEVIN EVOLUTION EQUATION APPROACH LANGEVIN BLACK BOX October FOR a(t) [Eq.] November in November D D Wind speed Prediction of tower accel. wind speed v(t) tower accel. a(t) Figure 3. Schematic illustration of the Langevin (stochastic) approach. Here the particular case of tower acceleration reconstruction at Alpha Ventus is given. 0 500 1000 t 0 0.5 1 1.5 2 a 990 1000 1010 1020 t 1.2 1.4 1.6 1.8 ∆t D ∆t+(D ∆t) 1/2rN(0,2) ∆a = ∆a Figure 4. Illustration of the stochastic approach, while integrating the evolution Equation , composed by its two contributions, the deterministic contribution D which governes the tendency of the evolving observable (blue), and the stochastic ﬂuctuations accounted by D (red) added to the deterministic part. Having wind speeds v(t) and tower accelerations a(t), the following evolution equation for the latter quantity is used: da dt = D(a, v) + q D(a, v)Γt, with Γt representing a Gaussian δ-correlated white noise, i.e., ⟨Γt⟩= 0 and ⟨ΓtΓt′⟩= 2δ(t −t′). The reconstruction of the tower acceleration a(t) follows therefore directly from the stochastic integration of Equation which yields: a(t + ∆t) = a(t) + D(a, v)∆t + q D(a, v)∆t rN(0,2), where rN(0,2) is a random number from a Gaussian distribution with zero mean and variance equal to two. Details are illustrated in Figure 4 and can be found in Ref. [27]. Energies 2017, 10, 1944 7 of 14 Function D is also called drift function, while function D is typically named as the diffusion function. Since the drift and diffusion functions have a physical interpretation, one could apply the model in Equation to a particular system and deﬁne ad hoc the functional shape of both functions from physical reasoning. Next we explain how to compute these both functions. The derivation is performed through the computation of the corresponding ﬁrst and second conditional moments [15], respectively: M v∗(a, τ) = ⟨a(t + τ) −a(t)⟩|a(t)=a,v(t)=v∗, (5a) M v∗(a, τ) = D (a(t + τ) −a(t))2E |a(t)=a,v(t)=v∗. (5b) where ⟨·⟩|X(t)=x indicates the average over the full time series, whenever X(t) takes the value x, deﬁned within an interval. Figure 5a shows the ﬁrst conditional moment for different values of the tower acceleration, namely for a = 0.0075amax (bin 1), a = −0.0025amax (bin 2), a = 0.01amax (bin 3), computed as given in Equation . Typically, for the lowest values of τ one observes a linear dependence of the conditional moments with τ. Since it can be shown that drift (D) and diffusion functions (D) in Equation are, apart from a multiplicative constant (1/k!), the derivative with respect to the time-gap τ of the ﬁrst and second conditional moments respectively, we can deﬁne both functions directly from the conditional moments, namely: D(k)(a, v) = lim τ→0 1 k! M(k) v (a, τ) τ . 0 3 6 9 τ (s) -0.03 -0.02 -0.01 0 0.01 0.02 M1(abin, ) bin 1 bin 2 bin 3 τ D1(abin2) (a) -0.1 -0.05 0 0.05 0.1 a / amax -0.01 -0.005 0 0.005 0.01 D1 -0.1 -0.05 0 0.05 0.1 a / amax 0 0.0003 0.0006 0.0009 D2 (b) (c) Figure 5. Illustration of (a) the ﬁrst conditional moment for three different bin values of the tower acceleration as deﬁned in Equation . Here v∗is given by the average velocity found during October. Numerical result for (b) the drift D(a, v) and (c) the diffusion D(a, v) in the Langevin equation given by Equation , plotted as function of a alone, i.e., they are projected at the a-axis to emphasize the linear and quadratic dependency of D and D respectively for the largest range of acceleration values. In red a polynomial ﬁt of both functions is shown. We use bins for the velocity with a width of 0.017 in units of maximal velocity while acceleration was taken in bins of width 0.017 of maximal tower acceleration. In other words, by taking the slope of the linear regression for each conditional moment one arrives to the corresponding value of function D and D. Indeed, as sketched in Figure 5a, within a sufﬁciently low range of τ values, here three time-steps of the set of measurements, the conditional moments M and M depend linearly on τ. Figure 5b,c show both drift and diffusion functions, (D) and (D) respectively, for a range of a-values at different velocities. Notice that while the diffusion function shows a quadratic dependence on the tower acceleration, the drift function exhibits a cubic dependence with a dominant linear term having one single ﬁxed point at a∗= 0 which corresponds to the equilibrium position of tower vibrations. Energies 2017, 10, 1944 8 of 14 More precisely, a polynomial ﬁt of D yields: D(a) = α −ka  1 + βa + γa2 with α = −1.75 × 10−4 us−1, u taken in units of amax, with k = 0.061 s−1, β = 0.67 u−1 and γ = 4.9 u−2. Since the values of tower acceleration in units of u are typically of the order of 10−1 the dominant term in the cubic ﬁt is clearly the linear one, yielding: D(a) ∼−ka. In other words, the “force” D governing the drift of tower acceleration can be interpreted as a spring force with spring constant k around a stationary state with no acceleration that corresponds obviously to the vertical position of the tower. This interpretation of the stochastic model will be of importance below, where we discuss the possibility to use the stochastic modelling for monitoring tower vibrations and eventual structural defects of the tower. The ﬁt of diffusion yields a quadratic polynomial D(a) = d0 + d1a + d2a2 with d0 = 7 × 10−6, d1 = 5.4 × 10−4 and d2 = 4.6 × 10−2. It is important to stress that our framework is based on the assumption that the observable follows a Markov process, which means nothing else than that the noise Γt is δ-correlated as mentioned above. Though, one advantage of this Langevin data reconstruction is that it also works in some cases where the Markov test fails [28]. The full implementation in one- and two-dimensions of this approach is already public available [29]. Improvements on the noise term are beyond this paper, but were already addressed previously [30,31]. 3.3. Performance Evaluation To compare both approaches, we consider the distribution of all values predicted from each model for November 2015, in particular their four ﬁrst statistical moments, namely the mean, the standard deviation, the skewness and the kurtosis. Notice that, while mean and standard deviation are sufﬁcient for characterizing the distribution of Gaussian processes, in general, higher-order moments should be checked for ascertaining if the process is non-Gaussian or not. The corresponding results are shown in Figure 6 and Table 1. -0.2 -0.1 0 0.1 0.2 a / amax 0.001 0.01 0.1 1 10 100 1,000 10,000 Measurements Neural Nets Langevin -0.06 -0.03 0 0.03 0.06 a / amax 16,500 16,600 16,700 16,800 16,900 17,000 t (s) -0.06 -0.03 0 0.03 0.06 a / amax (a) (b) (c) Neural Network Stochastic Figure 6. Sample of data series of tower acceleration from measurements at AV04 in Alpha Ventus and the acceleration reconstruction models using (a) NARX neural networks and (b) the Langevin model. In both cases, one also plots (black lines) the corresponding series of measurements for better comparison. The corresponding value distribution of these series is displayed in (c) with symbols for the full month of November 2014. Energies 2017, 10, 1944 9 of 14 Table 1. First four statistical moments of the value distributions shown in Figure 6d for the normalised measurements and the reconstructed signals with each one of both models. Signal Mean Std. Dev. Skewness Kurtosis Measurements −2.07 × 10−3 24.7 × 10−3 11.6 × 10−3 5.07 NN −2.15 × 10−3 7.39 × 10−3 −30.1 × 10−3 6.31 Langevin model −1.71 × 10−3 25.6 × 10−3 −3.59 × 10−3 2.37 Additionally, to evaluate the prediction of both models we use four different metrics, namely the mean absolute error: MAE = 1 n n ∑ i=1 | ˆyi −yi|, its standard deviation: SDofAE = v u u t 1 n n ∑ i=1 | ˆyi −yi| −1 n n ∑ i=1 | ˆyi −yi| !2 , the mean square error (already presented in Section 3, Equation ) and its standard deviation: SDofSE = v u u t 1 n n ∑ i=1 "" ( ˆyi −yi)2 − n ∑ i=1 ( ˆyi −yi)2 #2 , where ˆyi denotes the ith measured value of the property y, and yi the corresponding modelled value, either with NN or with the Langevin model. Notice that the standard coefﬁcient of determination deﬁned as: R2 = 1 −∑n i=1( ˆyi −yi)2 ∑n i=1( ˆyi −¯y)2 , with ¯y = (1/n) ∑n i=1 ˆyi, is related to MSE by: MSE = 1 −R2 n n ∑ i=1 ( ˆyi −¯y)2. References [13,32] reported these metrics to select the best data-mining technique and to derive models for the normal behaviour of wind turbine vibration and to detect faults in wind turbine gearboxes. Moreover, they have been commonly used to evaluate the accuracy of models utilised for regression analysis in wind energy applications [11–13,32]. The correspondig results comparing the NN and the stochastic approach are summarized in Table 2. Table 2. Performance of both models, using the metrics deﬁned in Equations , –, namely the mean of the absolute error, Equation , its standard deviation, Equation , the mean square error, Equation and its standard deviation, Equation . Signal MAE SDofAE MSE SDofSE NN 0.031 0.032 2.0 × 10−3 65.6 × 10−3 Langevin model 0.027 0.031 1.6 × 10−3 0.7 × 10−3 Energies 2017, 10, 1944 10 of 14 Finally, we also analyse the temporal correlations of the data. Therefore we use two methods, namely we calculate the power spectra and analyse the statistics of the temporal increments: ∆a(t, τ) = a(t + τ) −a(t), where τ = n∆t is an integer number n of consecutive time-steps ∆t. Note that the second moment of the increments ∆a, given by ⟨(∆a)2⟩, corresponds to the power spectrum. The power spectrum of the reconstructed signals are plotted in Figure 7, showing how the frequency components are reconstructed. The statistics of the increments is given in Figure 8, from which we will ascertain how good the model retrieves the evolution of the process throughout the succession of measurements [27]. 0.0001 0.001 a / amax 0.0001 0.001 1e-05 0.0001 a / amax 1e-05 0.0001 0.001 0.01 0.1 f (Hz) 0.0001 0.001 a / amax 0.0001 0.001 Low freqs. High freqs. Observations Neural Networks Stochastic Figure 7. Spectrum of original signal (top) and the corresponding reconstructed signals, one using the neural network (middle) and the other using our proposed stochastic approach (bottom). Notice that the high frequency domain is plotted in a linear frequency scale, while the low frequency domain is plotted in the logarithmic scale. -0.3 -0.2 -0.1 0 0.1 0.2 0.3 ∆a 1×10-10 1×10-5 1 1×105 1×1010 1×1015 1×1020 Probability Density Function Observations Neural Net Langevin /σ∆a Figure 8. Two-point statistics of the tower acceleration (lines) and the corresponding reconstructed signals, i.e., value distributions of ∆a(t) = a(t + τ) −a(t). From top to bottom one has τ = 1, 2, 4, 8 and 16 s. The vertical shift of the distribution is for better visualization. Energies 2017, 10, 1944 11 of 14 4. Discussion 4.1. Comparing Both Approaches To evaluate the suitability of the stochastic approach, described above, for modelling normal behaviour of wind turbine vibrations, we compare it with the neural network [13]. Figure 6a,b shows normalized samples of the original tower top acceleration and its two reconstructions. Already in these plots it is clear the stronger resemblance between the reconstructed data from the stochastic approach and the set of tower acceleration measurements. While the NN reconstruction keeps the average value of the tower oscillations, their range of amplitudes is not as well reproduced as with the stochastic approach. This feature is more evident in the plot of Figure 6c: both the stochastic and the NN models retrieve the approximate distribution of values of the original signal (symbols), but the full range of the tower acceleration values observed in measured distribution (bullets) is reproduced by the distribution obtained from the Langevin model (diamonds) but not from the NN model (squares). Furthermore, the empirical distribution is clearly non-Gaussian, showing exponential tails. Table 1 compares the ﬁrst four moments of all three distributions in Figure 6c. While NN reproduces the mean more accurately, the standard deviation is much better modelled with the stochastic approach. In other words, while the average behaviour is better modelled with NN, for properly reproduced the amplitude of tower vibrations the stochastic approach is better suited. Curiously however, while the (weak) skewness is also better approximated by the stochastic approach, the value of the kurtosis is better reproduced by the NN model. Additionally, the response obtained with NN had a smaller amplitude, as the optimization of its parameters reduce its cost function, the mean square error, thus it tends to center its prediction to improve its accuracy. These statistics are important to better describe the shape of distributions and thus, indicate their symmetry and the weight of the tails, respectively. Our distribution is fairly symmetrical but with tails that differ from a normal distribution. The performance of both models was also assessed using the metrics introduced above, Equations – and results are given in Table 2: one clearly sees a tendency for lower values of MAE, SDofAE, MSE and SDofSE. For such metrics, one concludes that the stochastic approach results have comparable accuracy or are even more accurate than the results from NN models, in what concerns the predictions for the tower top acceleration. As for the temporal correlations of the signals, the results plotted in Figure 7 show the spectral behaviour of the two models compared with the measurements of the tower acceleration. While NN better reproduces the periodic modes (peaks in the spectrum) present in the measurements, it is worse for the low-frequency range and for the overall amplitudes of the spectrum. Notice the different vertical scale used for plotting the NN results. The stochastic approach smoothes out the periodic modes, but reproduces the overall shape of the empirical power spectrum. The metrics chosen indicate that the stochastic approach is a good alternative to model the normal behaviour of a signal. However, for certain situations other approaches dealing with the identiﬁcation of normal and abnormal behaviour may also be suited. For example, were we in posession of abnormalities in our data set, we could have also used a classiﬁcation algorithm to mark records into either one of two classes (normal, abnormal). In such a case, care must been taken to account for the imbalance of instances in one of the classes [22], and as a consequence, we would have had to select other metrics, such as the F-measure as recommended by the investigation of fault diagnosis in gearboxes [33]. A better reconstruction of two-point statistics is also obtained through the stochastic approach, as shown in Figure 8. It is clear that the stochastic approach better reconstructs the differences ∆a between consecutive values in the tower acceleration series, only with some small deviations for the largest differences. This shows furthermore that the assumption of Markovian process with Langevin noise is considerably reliable for these data sets. Energies 2017, 10, 1944 12 of 14 4.2. Stochastic Modelling Applied to the Monitoring of Tower Vibrations Having shown the better performance of the stochastic approach with higher frequency sampling data, in this section we brieﬂy discuss how the approach can be applied to speciﬁc monitoring of tower vibrations. The discussion is based on the approximation derived in Equation and follows from the recent ﬁndings reported in Ref. [20]. The Ansatz of the stochastic modelling proposed above for tower vibrations, describes the evolution of short-time vibrations as the superposition of two contributions, being one deterministic (governed by function D), and the other stochastic (governed by function D). In parallel, tower vibrations result from the interplay of a mass of wind acting on the tower and the tower itself reacting back to the wind. Though there is no clear-cut match between the two contributions in our Ansatz and the physical reality of tower vibrations, we may regard the deterministic contribution (D) as the one describing the tower response to wind loads and the stochastic part (D) as the one describing the (turbulent) dynamics of wind. Consequently, from such an interpretation of the stochastic model introduced in Equation we conclude that for monitoring normal functioning of tower vibrations we should focus on D. As derived above in Equation , function D can be interpreted as an elastic force, parameterized by a spring constant k. This spring constant characterizes the vibrating tower and therefore, in case structural defects occur, one expects that the vibrations will be qualitatively different from there on, showing a different D in a way that a plot of it similar to Figure 5b will show a different slope, i.e., different value of the spring constant. Before concluding, one additional point needs to be discussed. The absolute quality of the wind speed measurement is not crucial to our method. Most important for our method is the wind speed that the rotor is exposed to. In this sense it is even preferable to let the anemometer share the same tower oscillations as the rotor. However, we believe that the inﬂuence of tower oscillations on the wind speed measurement is small anyway. A very coarse estimation of nacelle oscillations leads to amplitudes in the order of 1 m at a frequency clearly below 1 Hz. This may give rise to wind speed measurement deviations below 1 m/s. As for our analysis we use wind speed classes of 0.5 m/s width, most of these tower oscillations would not have any effect. Moreover, these deviations will average out due to their periodic nature. As our analysis is of statistical nature, a signiﬁcant effect is not expected. 5. Conclusions We have presented a stochastic approach which is capable of modelling the normal behaviour of wind turbine tower acceleration for its monitoring. Our results demonstrate that, compared to neural network (NN) models and using a single input, the Langevin model is able to better reconstruct non-Gaussian ﬂuctuations of signals. In general both models provide a good estimate for the central part of the original signal, but the stochastic approach also reconstructs its complete variance. We have also shown that a normal behaviour model based on the stochastic approach provides more information about the original signal than one based on NNs. Still, one should emphasize that previous publications on normal behaviour models, to monitor vibration of wind turbines based on SCADA [12,13] using 10-s sampling signals, demonstrated the suitability of NNs and control charts as a method to monitor signals in time-domain. Our results for NN match the applications found in the literature, where they have been used with 10-min sampling time-series [10]. When using low-frequency data, the NN is as good as our stochastic approach. Putting our results in perspective, we state that NNs are a good choice to predict average values or less ﬂuctuating signals. For situations where 10-min data is not sufﬁciently, namely when dealing with cumulative loads for which the large wind ﬂuctuations of short intervals play an important role, NNs seem to retrieve not so good results as the stochastic approach. All in all, in those cases where the sampling rate is low, the NNs remain as a good option to take into account, as the monitoring is sufﬁcient in time-domain and the requirements to apply the stochastic approach are not always fulﬁlled. In cases where the sampling rate of the signal is high Energies 2017, 10, 1944 13 of 14 (1 Hz in our case), the stochastic approach is clearly a better choice. It allows for monitoring normal behaviour in time-domain as with NNs, but also extends the possibilities to the frequency-domain. As discussed above, to notice that a central advantage of the stochastic approach is that deterministic and noisy contributions can be separated leading to improvements in the statistical reproduction of the output ﬂuctuations. The study of the long time behaviour of the deterministic part of the Langevin equation used in the stochastic approach can also provide information about the health of the structure, in a similar direction as previous work [20]. From this paper, one can now use the available routines [28,29] and extend the stochastic approach here applied to other wind turbine properties, in particular to other loads. Acknowledgments: This work was partly funded by the German Federal Ministry of Economic Affairs and Energy and the State of Lower Saxony as part of the research project “Probabilistic load description, monitoring, and reduction for the next generation of offshore wind turbines (OWEA Loads)”, grant number 0325577B, and also by the Ministry of Science and Culture of Lower Saxony in the project “Ventus Efﬁciens” (ZN3024). Additionally, ﬁnancial support from the Deutsche Forschungsgemeinschaft (MA 1636/9-1) and the Open Access Publishing Fund of Osnabrück University is gratefully acknowledged. The authors also thank Senvion SE for providing the data here analyzed. Author Contributions: Pedro G. Lind and Luis Vera-Tudela performed the simulations. Pedro G. Lind and Luis Vera-Tudela prepared the manuscript. Matthias Wächter, Martin Kühn and Joachim Peinke proposed the ideas and methodologies. All authors revised the text and output results. Conﬂicts of Interest: The authors declare no conﬂict of interest. References 1. Yang, W.; Tavner, P.J.; Crabtree, C.J.; Feng, Y.; Qiu, Y. Wind turbine condition monitoring: Technical and commercial challenges. Wind Energy 2014, 17, 673–693. 2. Kusiak, A.; Zhang, Z.; Verma, A. Prediction, operations, and condition monitoring in wind energy. Energy 2013, 60, 1–12. 3. Wang, K.S.; Sharma, V.S.; Zhang, Z.Y. SCADA data based condition monitoring of wind turbines. Adv. Manuf. 2014, 2, 61–69. 4. Tchakoua, P.; Wamkeue, R.; Ouhrouche, M.; Slaoui-Hasnaoui, F.; Tameghe, T.; Ekemb, G. Wind Turbine Condition Monitoring: State-of-the-Art Review, New Trends, and Future Challenges. Energies 2014, 7, 2595–2630. 5. Zaher, A.; McArthur, S.; Inﬁeld, D. Online wind turbine fault detection through automated SCADA data analysis. Wind Energy 2009, 12, 574–593. 6. Rahman, M.; Ong, Z.; Chong, T.; Julai, S.; Khoo, S. Performance enhancement of wind turbine systems with vibration control: A review. Renew. Sustain. Energy Rev. 2015, 51, 43–54. 7. Bogoevska, S.; Spiridonakos, M.; Chatzi, E.; Dumova-Jovanoska, E.; Höffer, R. A Data-Driven Diagnostic Framework for Wind Turbine Structures: A Holistic Approach. Sensors 2017, 17, 720. 8. Wang, J.; Heng, J.; Xiao, L.; Wang, C. Research and application of a combined model based on multi-objective optimization for multi-step ahead wind speed forecasting. Energy 2017, 125, 591–613. 9. Cruz Garcia, M.; Sanz-Bobi, M.A.; del Pico, J. SIMAP: Intelligent System for Predictive Maintenance. Application to the health condition monitoring of a windturbine gearbox. Comput. Ind. 2006, 57, 552–568. 10. Schlechtingen, M.; Ferreira Santos, I. Comparative analysis of neural network and regression based condition monitoring approaches for wind turbine fault detection. Mech. Syst. Signal Process. 2011, 25, 1849–1875. 11. Kusiak, A.; Verma, A. Analyzing bearing faults in wind turbines: A data-mining approach. Renew. Energy 2012, 48, 110–116. 12. Kusiak, A.; Zhang, Z. Analysis of Wind Turbine Vibrations Based on SCADA Data. J. Sol. Energy Eng. 2010, 132, 031008. 13. Zhang, Z.; Kusiak, A. Monitoring Wind Turbine Vibration Based on SCADA Data. J. Sol. Energy Eng. 2012, 134, 021004. 14. Bangalore, P.; Letzgus, S.; Karlsson, D.; Patriksson, M. An artiﬁcial neural network-based condition monitoring method for wind turbines, with application to the monitoring of the gearbox. Wind Energy 2017, 20, 1421–1438. Energies 2017, 10, 1944 14 of 14 15. Lind, P.G.; Herráez, I.; Wächter, M.; Peinke, J. Fatigue Load Estimation through a Simple Stochastic Model. Energies 2014, 7, 8279–8293. 16. Russo, A.; Raischel, F.; Lind, P.G. Air quality prediction using optimal neural networks with stochastic variables. Atmos. Environ. 2013, 79, 822–830. 17. Müller, K.; Cheng, P.W. Validation of uncertainty in IEC damage calculations based on measurements from alpha ventus. Energy Procedia 2016, 94, 133–145. 18. Cheng, W.; Lutz, T.; Kühn, M.; Bartsch, J.; Kruse, J.; Schaumann, P.; Bange, J. Probabilistische Lastbeschreibung, Monitoring und Reduktion der Lasten zukünftiger Offshore-Windenergieanlagen (OWEA Loads); Technical Report; WindForS and ForWind and Adwen GmbH and Senvion: Oldenburg/Stuttgart, Germany, 2017. 19. Mücke, T.; Wächter, M.; Milan, P.; Peinke, J. Langevin power curve analysis for numerical wind energy converter models with new insights on high frequency power performance. Wind Energy 2015, 18, 1953–1971. 20. Rinn, P.; Heißelmann, H.; Wächter, M.; Peinke, J. Stochastic method for in-situ damage analysis. Eur. Phys. J. B 2013, 86, 3. 21. Shmueli, G. To Explain or to Predict? Stat. Sci. 2010, 25, 289–310. 22. Borovicka, T.; Jirina, M.J.; Kordik, P.; Jirina, M. Selecting representative data sets. In Advances in Data Mining Knowledge Discovery and Applications; Karahoca, A., Ed.; InTech: Rijeka, Croatia, 2012; pp. 43–70. 23. Hastie, T.; Tibshirani, R.; Friedman, J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd ed.; Springer: New York, NY, USA, 2013; p. 759. 24. May, R.; Dandy, G.; Maier, H. Review of input variable selection methods for artiﬁcial neural networks. In Artiﬁcial Neural Networks—Methodological Advances and Biomedical Applications; Suzuki, K., Ed.; InTech Europe: Rijeka, Croatia, 2011; pp. 19–44. 25. Friedrich, R.; Peinke, J. Description of a Turbulent Cascade by a Fokker-Planck Equation. Phys. Rev. Lett. 1997, 78, 863. 26. Siegert, S.; Friedrich, R.; Peinke, J. Analysis of Data of Stochastic Systems. Phys. Lett. A 1998, 243, 275–280. 27. Friedrich, R.; Peinke, J.; Sahimi, M.; Tabar, M. Approaching complexity by stochastic methods: From biological systems to turbulence. Phys. Rep. 2011, 506, 87–167. 28. Rinn, P.; Lind, P.; Wächter, M.; Peinke, J. The Langevin Approach: An R Package for Modeling Stochastic Processes. J. Open Res. Softw. 2016, 4, e34. 29. Rinn, P.; Lind, P.G.; Bastine, D. Langevin 1D and 2D. 2015. Available online: web/packages/Langevin/ (accessed on 28 October 2017 ). 30. Lehle, B. Analysis of stochastic time series in the presence of strong measurement noise. Phys. Rev. E 2011, 83, 021113. 31. Anvari, M.; Tabar, R.R.; Peinke, J.; Lehnertz, K. Disentangling the stochastic behaviour of complex time series. Nat. Sci. Rep. 2016, 6, 35435. 32. Zhang, Z.; Verma, A.; Member, S.; Kusiak, A. Fault Analysis and Condition Monitoring of the Wind Turbine Gearbox. IEEE Trans. Energy Convers. 2012, 27, 526–535. 33. Santos, P.; Maudes, J.; Bustillo, A. Identifying maximum imbalance in datasets for fault diagnosis of gearboxes. J. Intell. Manuf. 2015, doi:10.1007/s10845-015-1110-0. c⃝2017 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (",": To monitor wind turbine vibrations, normal behaviour models are built to predict tower top accelerations and drive-train vibrations. Signal deviations from model prediction are labelled as anomalies and are further investigated. In this paper we assess a stochastic approach to reconstruct the 1 Hz tower top acceleration signal, which was measured in a wind turbine located at the wind farm Alpha Ventus in the German North Sea. We compare the resulting data reconstruction with that of a model based on a neural network, which has been previously reported as a data-mining algorithm suitable for reconstructing this signal. Our results present evidence that the stochastic approach outperforms the neural network in the high frequency domain (1 Hz). Although neural network retrieves accurate step-forward predictions, with low mean square errors, the stochastic approach predictions better preserve the statistics and the frequency components of the original signal, retaining high accuracy levels. The implementation of our stochastic approach is available as open source code and can easily be adapted for other situations involving stochastic data reconstruction. Based on our ﬁndings we argue that such an approach could be implemented in signal reconstruction for monitoring purposes or for abnormal behaviour detection.","['Pedro G. Lind', 'Luis Vera-Tudela', 'Matthias Wächter', 'Martin Kühn', 'Joachim Peinke']"

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules needed\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import bibtexparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set option for visability\n",
    "pd.set_option('display.max_colwidth', 200)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure src/ is in the Python path\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(os.path.join(BASE_DIR, \"src\"))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import function from file\n",
    "from retrieval import extract_text_from_pdf\n",
    "\n",
    "# define path to documents\n",
    "documents_dir = os.path.join(BASE_DIR, \"data\", \"documents\")\n",
    "\n",
    "# list all PDF files in the folder\n",
    "pdf_files = [f for f in os.listdir(documents_dir) if f.endswith('.pdf')]\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store the text for each document\n",
    "texts = []\n",
    "\n",
    "# loop through all PDF files and extract text\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(documents_dir, pdf_file)\n",
    "    df_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # combine the text content from all pages \n",
    "    combined_content = df_text['content'].str.cat(sep=' ')\n",
    "    \n",
    "    # extract only doc name\n",
    "    doc_name = os.path.splitext(pdf_file)[0]\n",
    "\n",
    "    # create df for document\n",
    "    df_text = pd.DataFrame([[combined_content, doc_name]], columns=[\"content\", \"file\"])\n",
    "    \n",
    "    # append df to list\n",
    "    texts.append(df_text)\n",
    "\n",
    "# concatenate all individual dfs into one combined df\n",
    "df_text = pd.concat(texts, ignore_index=True)\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to metadata\n",
    "metadata_dir = os.path.join(BASE_DIR, \"data\", \"metadata\")\n",
    "\n",
    "# list all BibTeX files in the\n",
    "bib_files = [f for f in os.listdir(metadata_dir) if f.endswith('.bib')]\n",
    "bib_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bibtex(bibtex_file_path):\n",
    "    ''' \n",
    "    Parses a single BibTeX file and returns a df\n",
    "    '''\n",
    "    with open(bibtex_file_path, 'r') as bibtex_file:\n",
    "        \n",
    "        # parse the BibTeX file\n",
    "        bib_database = bibtexparser.load(bibtex_file)\n",
    "    \n",
    "    # convert the BibTeX entries into a list of dictionaries\n",
    "    bib_entries = bib_database.entries\n",
    "    \n",
    "    # convert list of dictionaries into a df\n",
    "    df_bibtex = pd.DataFrame(bib_entries)\n",
    "    \n",
    "    return df_bibtex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store dfs\n",
    "bib_dataframes = []\n",
    "\n",
    "# loop through all BibTeX files and load them into dfs\n",
    "for bib_file in bib_files:\n",
    "    bib_file_path = os.path.join(metadata_dir, bib_file)\n",
    "    df_bibtex = load_bibtex(bib_file_path)\n",
    "    \n",
    "    # extract only doc name\n",
    "    doc_name = os.path.splitext(bib_file)[0]\n",
    "    \n",
    "    # add column to identify the source BibTeX file\n",
    "    df_bibtex['file'] = doc_name\n",
    "    \n",
    "    # append the df to the list\n",
    "    bib_dataframes.append(df_bibtex)\n",
    "\n",
    "# concatenate all the dfs into one combined df\n",
    "df_bibtex = pd.concat(bib_dataframes, ignore_index=True)\n",
    "df_bibtex.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only relevant columns\n",
    "df_bibtex = df_bibtex[['file', 'title', 'author', 'year', 'number', 'volume', 'journal', 'ENTRYTYPE', 'doi']]\n",
    "df_bibtex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the df_text and df_bibtex on the index columns\n",
    "df_combined = pd.merge(df_text, df_bibtex, on='file', how='left')\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange column order\n",
    "df_combined = df_combined[['title', 'author', 'year', 'number', 'volume', 'journal', 'ENTRYTYPE', 'content', 'doi', 'file']]\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df_combined = df_combined.rename(columns={'ENTRYTYPE':'type', 'author':'authors', 'year':'year_published'})\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df as csv file\n",
    "df_combined.to_csv('df_combined.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
